{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deParaClassifierName(textDe):\n",
    "  if textDe == 'MLPClassifier':\n",
    "    return 'MLP'\n",
    "  elif textDe == 'Reg_Logistica':\n",
    "    return 'LR'\n",
    "  elif textDe == 'Random_Forest':\n",
    "    return 'RF'\n",
    "  elif textDe == 'XGboost':\n",
    "    return 'Xgb'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1595009919129,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "J4oWDmB6inaO"
   },
   "outputs": [],
   "source": [
    "def deParaEmbeddingName(textDe):\n",
    "  if textDe == 'W2V-GN':\n",
    "    return 'w2v-GN'\n",
    "  elif textDe == 'GloveWP':\n",
    "    return 'GloVe-WP'\n",
    "  elif textDe == 'FastText':\n",
    "    return 'fastText'\n",
    "  elif textDe == 'GloveTW':\n",
    "    return 'GloVe-TWT'\n",
    "  elif textDe == 'Bert: bert-base-uncased / STATIC_AVG':\n",
    "    return 'Bert-static'\n",
    "  elif textDe == 'TFIDF':\n",
    "    return 'TF-IDF'\n",
    "  elif textDe == 'W2VAraque':\n",
    "    return 'w2v-Araque'\n",
    "  elif textDe == 'W2VEdin':\n",
    "    return 'w2v-Edin'\n",
    "  elif textDe == 'Roberta: roberta-base / STATIC_AVG':\n",
    "    return 'Roberta-static'\n",
    "\n",
    "  elif textDe == 'Roberta: roberta-base / CONTEXT_CONCAT':\n",
    "    return 'Roberta-context'\n",
    "  elif textDe == 'Bert: bert-base-uncased / CONTEXT_CONCAT':\n",
    "    return 'Bert-context'\n",
    "  elif textDe == 'BERTweet_base_transformers_STATIC':\n",
    "    return 'Bertweet-static'\n",
    "  \n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-05-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-0.5K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-1-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-1K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-5-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-5K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-10-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-10K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-25-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-25K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-50-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-50K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-250-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-250K'\n",
    "  elif textDe == \"Roberta: ./Seed/RoBERTa-500-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBERTa-500K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-1500-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-1.5M'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-6600-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-6.6M'\n",
    "  \n",
    "\n",
    "  elif textDe == 'Bert: ./Seed/BERT-05-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-0.5K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-1-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-1K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-5-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-5K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-10-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-10K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-25-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-25K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-50-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-50K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-250-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-250K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-500-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-500K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-1500-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-1.5M'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-6600-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-6.6M'\n",
    "\n",
    "  elif textDe == \"BERTweet_base_transformers_CONTEXT\":\n",
    "    return 'Bertweet-context'\n",
    "  elif textDe == \"./Seed/BERTweet-05-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-0.5K'\n",
    "  elif textDe == \"./Seed/BERTweet-1-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-1K'\n",
    "  elif textDe == \"./Seed/BERTweet-5-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-5K'\n",
    "  elif textDe == \"./Seed/BERTweet-10-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-10K'\n",
    "  elif textDe == \"./Seed/BERTweet-50-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-50K'\n",
    "  elif textDe == \"./Seed/BERTweet-25-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-25K'\n",
    "  elif textDe == \"./Seed/BERTweet-250-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-250K'\n",
    "  elif textDe == \"./Seed/BERTweet-500-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-500K'\n",
    "  elif textDe == \"./Seed/BERTweet-1500-12-LM_CONTEXT\":\n",
    "    return 'BERTweet\\_1.5M'\n",
    "  elif textDe == \"./Seed/BERTweet-6600-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-6.6M'\n",
    "\n",
    "\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1624,
     "status": "ok",
     "timestamp": 1595009919494,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "9qVLCGH69TdW"
   },
   "outputs": [],
   "source": [
    "def deParaDatasetName(textDe):\n",
    "  if textDe == 'ntua':\n",
    "    return 'ntu'\n",
    "  elif textDe == 'SemEval15-Task11':\n",
    "    return 'S15'\n",
    "  elif textDe == 'iphone':\n",
    "    return 'iph'\n",
    "  elif textDe == 'Narr-KDML-2012':\n",
    "    return 'Nar'\n",
    "  elif textDe == 'VADER':\n",
    "    return 'Vad'\n",
    "  elif textDe == 'SemEval17-test':\n",
    "    return 'S17'\n",
    "  elif textDe == 'debate08':\n",
    "    return 'OMD'\n",
    "  elif textDe == 'irony':\n",
    "    return 'iro'\n",
    "  elif textDe == 'sarcasm':\n",
    "    return 'sar'\n",
    "  elif textDe == 'sentiment140':\n",
    "    return 'stm'\n",
    "  elif textDe == 'person':\n",
    "    return 'per'\n",
    "  elif textDe == 'hobbit':\n",
    "    return 'hob'\n",
    "  elif textDe == 'movie':\n",
    "    return 'mov'\n",
    "  elif textDe == 'sanders':\n",
    "    return 'san'\n",
    "  elif textDe == 'archeage':\n",
    "    return 'arc'\n",
    "  elif textDe == 'SemEval18':\n",
    "    return 'S18'\n",
    "  elif textDe == 'STS-gold':\n",
    "    return 'STS'\n",
    "  elif textDe == 'SentiStrength':\n",
    "    return 'SSt'\n",
    "  elif textDe == 'Target-dependent':\n",
    "    return 'Tar'\n",
    "  elif textDe == 'SemEval13':\n",
    "    return 'S13'\n",
    "  elif textDe == 'SemEval16':\n",
    "    return 'S16'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "'''[0.73,'S16','Generic',12216]'''\n",
    "data=[[0.34,'iro','Irony',65],\n",
    "      [0.46,'sar','Sarcasm',71],\n",
    "      [0.57,'ntu','Generic',278],\n",
    "      [0.15,'S15','Metaphors',321],\n",
    "      [0.51,'stm','Generic',359],\n",
    "      [0.71,'per','Person',439],\n",
    "      [0.68,'hob','Movies',522],\n",
    "      [0.70,'iph','Product',532],\n",
    "      [0.82,'mov','Movies',561],\n",
    "      [0.47,'san','Business',1224],\n",
    "      [0.60,'Nar','Generic',1227],\n",
    "      [0.42,'arc','Games',1718],\n",
    "      [0.47,'S18','Equity',1859],\n",
    "      [0.37,'OMD','Debate',1906],\n",
    "      [0.28,'HCR','Reform',1908],\n",
    "      [0.31,'STS','Generic',2034],\n",
    "      [0.59,'SSt','Generic',2289],\n",
    "      [0.50,'Tar','Celebrities',3467],\n",
    "      [0.69,'Vad','Generic',4196],\n",
    "      [0.73,'S13','Generic',4378],\n",
    "      [0.37,'S17','Generic',6347],\n",
    "     [0.73,'S16','Generic',12216]]\n",
    "balance=pd.DataFrame(data,columns=['Positive','Data_Set','Type','Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1585,
     "status": "ok",
     "timestamp": 1595009919495,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "PhS6C9E152Xr"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "########## Estatico ##########\n",
    "dfstatic = pd.read_csv(glob.glob(\"staticLM/Pivot_tables/Final_Result_staticLM_*.csv\")[0], sep=\",\")\n",
    "df_btw_static = pd.read_csv(glob.glob(\"staticLM/Pivot_tables/Final_Result_StaticLM_*.csv\")[0], sep=\",\")\n",
    "df_btw_static = df_btw_static[df_btw_static['Embedding']=='BERTweet_base_transformers_STATIC']\n",
    "\n",
    "########## Contextualizado ##########\n",
    "df_roberta = pd.read_csv(glob.glob(\"./RoBERTa/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "df_bert = pd.read_csv(glob.glob(\"./BERT/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "df_bertweet = pd.read_csv(glob.glob(\"./BERTweet/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "tag=''\n",
    "\n",
    "############## FT LOO ##################\n",
    "df_LOO_bt = pd.read_csv(glob.glob(\"./LOO/BERTweet-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_LOO_bt['accuracy'] = round(df_LOO_bt['accuracy']/100,2)\n",
    "df_LOO_bt['f1_macro'] = round(df_LOO_bt['f1_macro']/100,2)\n",
    "\n",
    "df_LOO_br = pd.read_csv(glob.glob(\"./LOO/BERT-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_LOO_br['accuracy'] = round(df_LOO_br['accuracy']/100,2)\n",
    "df_LOO_br['f1_macro'] = round(df_LOO_br['f1_macro']/100,2)\n",
    "\n",
    "df_LOO_rb = pd.read_csv(glob.glob(\"./LOO/RoBERTa-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_LOO_rb['accuracy'] = round(df_LOO_rb['accuracy']/100,2)\n",
    "df_LOO_rb['f1_macro'] = round(df_LOO_rb['f1_macro']/100,2)\n",
    "\n",
    "\n",
    "############### FT 22DT ##############3\n",
    "\n",
    "df_22dt_rb = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/RoBERTa-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_22dt_br = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/BERT-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_22dt_bt = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/BERTweet-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "\n",
    "############## FT Indata #################\n",
    "\n",
    "df_Indata_bt = pd.read_csv(glob.glob(\"./InData/BERTweet-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_Indata_br = pd.read_csv(glob.glob(\"./InData/BERT-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_Indata_rb = pd.read_csv(glob.glob(\"./InData/RoBERTa-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "############# FT RoBERTa ##############\n",
    "\n",
    "df_edin_bt_05 = pd.read_csv(glob.glob(\"./Edin/BERTweet-05-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_1 = pd.read_csv(glob.glob(\"./Edin/BERTweet-1-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_5 = pd.read_csv(glob.glob(\"./Edin/BERTweet-5-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_10 = pd.read_csv(glob.glob(\"./Edin/BERTweet-10-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_25 = pd.read_csv(glob.glob(\"./Edin/BERTweet-25-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_50 = pd.read_csv(glob.glob(\"./Edin/BERTweet-50-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_250 = pd.read_csv(glob.glob(\"./Edin/BERTweet-250-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_500 = pd.read_csv(glob.glob(\"./Edin/BERTweet-500-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bt_1500 = pd.read_csv(glob.glob(\"./Edin/BERTweet-1500-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_6600 = pd.read_csv(glob.glob(\"./Edin/BERTweet-6600-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "\n",
    "df_edin_bert_05 = pd.read_csv(glob.glob(\"./Edin/BERT-05-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_1 = pd.read_csv(glob.glob(\"./Edin/BERT-1-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_5 = pd.read_csv(glob.glob(\"./Edin/BERT-5-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_10 = pd.read_csv(glob.glob(\"./Edin/BERT-10-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_25 = pd.read_csv(glob.glob(\"./Edin/BERT-25-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_50 = pd.read_csv(glob.glob(\"./Edin/BERT-50-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_250 = pd.read_csv(glob.glob(\"./Edin/BERT-250-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bert_500 = pd.read_csv(glob.glob(\"./Edin/BERT-500-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_1500 = pd.read_csv(glob.glob(\"./Edin/BERT-1500-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bert_6600 = pd.read_csv(glob.glob(\"./Edin/BERT-6600-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "\n",
    "df_edin_rob_05 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-05-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_1 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-1-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_5 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-5-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_10 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-10-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_25 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-25-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_50 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-50-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_250 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-250-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_rob_500 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-500-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_1500 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-1500-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_rob_6600 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-6600-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1595009919500,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "NCf2vK6MNjkR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frames = [dfstatic,df_btw_static,df_roberta,df_bert,df_bertweet,           df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600,           df_LOO_bt,df_Indata_bt,df_22dt_bt,           df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,           df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,           df_Indata_rb,df_Indata_br,df_LOO_br,df_LOO_rb,df_22dt_br,df_22dt_rb]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frames = [dfstatic,df_btw_static,df_roberta,df_bert,df_bertweet,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_1500,df_edin_bt_6600,df_Indata_rb,df_Indata_br,df_Indata_bt,df_LOO_br,df_LOO_rb,df_LOO_bt,df_22dt_br,df_22dt_rb,df_22dt_bt]\n",
    "#frames = [df_bertweet,df_22dt_bt,df_22dt_br,df_22dt_rb,df_LOO_bt,df_LOO_br,df_LOO_rb,df_Indata_br,df_Indata_rb,df_Indata_bt,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_1500,df_edin_bt_6600]\n",
    "\n",
    "#best context vs static\n",
    "#frames = [dfstatic,df_btw_static,df_roberta,df_bert,df_bertweet]\n",
    "\n",
    "#best static\n",
    "frames = [dfstatic,df_btw_static]\n",
    "\n",
    "#roberta vs roberta tunado\n",
    "#frames = [df_roberta,df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,df_LOO_rb,df_Indata_rb,df_22dt_rb]\n",
    "\n",
    "#bert vs bert tunado\n",
    "#frames = [df_bert,df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,df_LOO_br,df_Indata_br,df_22dt_br]\n",
    "\n",
    "#bertweet vs bertweet tunado\n",
    "#frames = [df_bertweet,df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600,df_LOO_bt,df_Indata_bt,df_22dt_bt]\n",
    "\n",
    "#bertweet vs todos modelos\n",
    "#frames = [df_bertweet,df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,df_Indata_rb,df_Indata_br,df_LOO_br,df_LOO_rb,df_22dt_br,df_22dt_rb]\n",
    "\n",
    "#Best indata, LOO, 22dataset\n",
    "#frames = [df_Indata_rb,df_Indata_br,df_Indata_bt,df_LOO_br,df_LOO_bt,df_LOO_rb,df_22dt_br,df_22dt_rb,df_22dt_bt]\n",
    "#frames = [df_Indata_bt,df_LOO_bt,df_22dt_bt]\n",
    "\n",
    "#BEST OVER ALL FINE TUNING sem sentimento\n",
    "'''frames = [df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600, \\\n",
    "          df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600, \\\n",
    "          df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600]\n",
    "'''\n",
    "\n",
    "#BEST OVER ALL FINE TUNING\n",
    "'''frames = [df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600, \\\n",
    "          df_LOO_bt,df_Indata_bt,df_22dt_bt, \\\n",
    "          df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600, \\\n",
    "          df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600, \\\n",
    "          df_Indata_rb,df_Indata_br,df_LOO_br,df_LOO_rb,df_22dt_br,df_22dt_rb]'''\n",
    "\n",
    "#BEST OVER ALL MODELS\n",
    "'''frames = [dfstatic,df_btw_static,df_roberta,df_bert,df_bertweet, \\\n",
    "          df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600, \\\n",
    "          df_LOO_bt,df_Indata_bt,df_22dt_bt, \\\n",
    "          df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600, \\\n",
    "          df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600, \\\n",
    "          df_Indata_rb,df_Indata_br,df_LOO_br,df_LOO_rb,df_22dt_br,df_22dt_rb]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1595009919501,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "IwrQ3coXNuIe"
   },
   "outputs": [],
   "source": [
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1595009919502,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "SkBoFHgNwndl"
   },
   "outputs": [],
   "source": [
    "result[[\"accuracy\", \"f1_macro\"]] = result[[\"accuracy\", \"f1_macro\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1595009919504,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "05WFV64O2zJN"
   },
   "outputs": [],
   "source": [
    "result[\"Data_Set\"] = result[\"Data_Set\"].apply(deParaDatasetName)\n",
    "result[\"Embedding\"] = result[\"Embedding\"].apply(deParaEmbeddingName)\n",
    "result[\"Classifier_Model\"] = result[\"Classifier_Model\"].apply(deParaClassifierName)\n",
    "result['model_class'] = result['Embedding'].map(str) + \"-\" + result['Classifier_Model'].map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Data_Set</th>\n",
       "      <th>model_class</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.11</td>\n",
       "      <td>60.60</td>\n",
       "      <td>LR</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>STS</td>\n",
       "      <td>w2v-Edin-LR</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Generic</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.42</td>\n",
       "      <td>54.26</td>\n",
       "      <td>RF</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>STS</td>\n",
       "      <td>w2v-Edin-RF</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Generic</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.37</td>\n",
       "      <td>64.68</td>\n",
       "      <td>SVM</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>STS</td>\n",
       "      <td>w2v-Edin-SVM</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Generic</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.86</td>\n",
       "      <td>61.99</td>\n",
       "      <td>MLP</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>STS</td>\n",
       "      <td>w2v-Edin-MLP</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Generic</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>STS</td>\n",
       "      <td>w2v-Edin-Xgb</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Generic</td>\n",
       "      <td>2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>57.68</td>\n",
       "      <td>56.63</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>sar</td>\n",
       "      <td>Bertweet-static-LR</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>60.54</td>\n",
       "      <td>56.72</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>sar</td>\n",
       "      <td>Bertweet-static-RF</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>60.54</td>\n",
       "      <td>57.74</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>sar</td>\n",
       "      <td>Bertweet-static-SVM</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>54.82</td>\n",
       "      <td>52.87</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>sar</td>\n",
       "      <td>Bertweet-static-MLP</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>56.43</td>\n",
       "      <td>52.32</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>sar</td>\n",
       "      <td>Bertweet-static-Xgb</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1540 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy  f1_macro Classifier_Model        Embedding Data_Set  \\\n",
       "0        64.11     60.60               LR         w2v-Edin      STS   \n",
       "1        69.42     54.26               RF         w2v-Edin      STS   \n",
       "2        69.37     64.68              SVM         w2v-Edin      STS   \n",
       "3        69.86     61.99              MLP         w2v-Edin      STS   \n",
       "4         0.00      0.00              Xgb         w2v-Edin      STS   \n",
       "...        ...       ...              ...              ...      ...   \n",
       "1535     57.68     56.63               LR  Bertweet-static      sar   \n",
       "1536     60.54     56.72               RF  Bertweet-static      sar   \n",
       "1537     60.54     57.74              SVM  Bertweet-static      sar   \n",
       "1538     54.82     52.87              MLP  Bertweet-static      sar   \n",
       "1539     56.43     52.32              Xgb  Bertweet-static      sar   \n",
       "\n",
       "              model_class  Positive     Type  Size  \n",
       "0             w2v-Edin-LR      0.31  Generic  2034  \n",
       "1             w2v-Edin-RF      0.31  Generic  2034  \n",
       "2            w2v-Edin-SVM      0.31  Generic  2034  \n",
       "3            w2v-Edin-MLP      0.31  Generic  2034  \n",
       "4            w2v-Edin-Xgb      0.31  Generic  2034  \n",
       "...                   ...       ...      ...   ...  \n",
       "1535   Bertweet-static-LR      0.46  Sarcasm    71  \n",
       "1536   Bertweet-static-RF      0.46  Sarcasm    71  \n",
       "1537  Bertweet-static-SVM      0.46  Sarcasm    71  \n",
       "1538  Bertweet-static-MLP      0.46  Sarcasm    71  \n",
       "1539  Bertweet-static-Xgb      0.46  Sarcasm    71  \n",
       "\n",
       "[1540 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.merge(balance,how='left')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acc=\\'accuracy\\'\\nroberta = result[(result[\\'Embedding\\']==\\'Roberta-static\\')]\\nbertweet = result[(result[\\'Embedding\\']==\\'Bertweet-static\\')]\\nfig=plt.figure(figsize=(12,8), dpi= 100)\\nplt.scatter(roberta[\\'Size\\'],roberta[acc])\\nfor models in roberta[\\'model_class\\'].unique(): plt.scatter(roberta[roberta[\\'model_class\\']==models][\\'Positive\\'],roberta[roberta[\\'model_class\\']==models][acc], label=models)\\nplt.scatter(bertweet[\\'Size\\'],bertweet[acc])\\nfor models in bertweet[\\'model_class\\'].unique(): plt.scatter(bertweet[bertweet[\\'model_class\\']==models][\\'Positive\\'],bertweet[bertweet[\\'model_class\\']==models][acc], label=models)\\nplt.title(\"RoBERTa_BERTweet_Classifier_Metric.png\")\\nplt.xlabel(\"%Positive\")\\nplt.ylabel(acc)\\nplt.legend()\\nplt.grid()\\nplt.savefig(\"RoBERTa_BERTweet_Classifier_Metric.png\")\\nplt.close()'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Classifier_Model= \"SVM\"\n",
    "'''acc='accuracy'\n",
    "roberta = result[(result['Embedding']=='Roberta-static')]\n",
    "bertweet = result[(result['Embedding']=='Bertweet-static')]\n",
    "fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "plt.scatter(roberta['Size'],roberta[acc])\n",
    "for models in roberta['model_class'].unique(): plt.scatter(roberta[roberta['model_class']==models]['Positive'],roberta[roberta['model_class']==models][acc], label=models)\n",
    "plt.scatter(bertweet['Size'],bertweet[acc])\n",
    "for models in bertweet['model_class'].unique(): plt.scatter(bertweet[bertweet['model_class']==models]['Positive'],bertweet[bertweet['model_class']==models][acc], label=models)\n",
    "plt.title(\"RoBERTa_BERTweet_Classifier_Metric.png\")\n",
    "plt.xlabel(\"%Positive\")\n",
    "plt.ylabel(acc)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"RoBERTa_BERTweet_Classifier_Metric.png\")\n",
    "plt.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Classifier_Model= \"SVM\"\\n#metric=\\'f1_macro\\'\\nfor tp in list(result[\\'Type\\'].unique()):\\n    for metric in [\\'accuracy\\',\\'f1_macro\\']:\\n        for Classifier_Model in [\\'SVM\\',\\'LR\\',\\'RF\\', \\'Xgb\\',\\'MLP\\']:\\n            roberta = result[(result[\\'Embedding\\']==\\'Roberta-static\\') &                              (result[\\'Classifier_Model\\']==Classifier_Model)&                             (result[\\'Type\\']==tp)]\\n            bertweet = result[(result[\\'Embedding\\']==\\'Bertweet-static\\') &                              (result[\\'Classifier_Model\\']==Classifier_Model)&                             (result[\\'Type\\']==tp)]\\n            fig=plt.figure(figsize=(12,8), dpi= 100)\\n            plt.scatter(roberta[\\'Positive\\'],roberta[metric], label=\\'Rob\\', marker=\\'o\\')\\n            for i,row in roberta.iterrows(): plt.text(row[\\'Positive\\'],row[metric], s=row[\\'Data_Set\\'])\\n            plt.scatter(bertweet[\\'Positive\\'],bertweet[metric], label=\\'Btw\\', marker=\\'*\\')\\n            plt.title(\"RoBERTa_BERTweet_Classifier{}_Metric_{}_{}.png\".format(Classifier_Model,metric,tp))\\n            plt.xlabel(\"%Positive\")\\n            plt.ylabel(metric)\\n            plt.legend()\\n            plt.grid()\\n            plt.savefig(\"RoBERTa_BERTweet_Classifier{}_Metric_{}_{}.png\".format(Classifier_Model,metric,tp))\\n            plt.close()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''#Classifier_Model= \"SVM\"\n",
    "#metric='f1_macro'\n",
    "for tp in list(result['Type'].unique()):\n",
    "    for metric in ['accuracy','f1_macro']:\n",
    "        for Classifier_Model in ['SVM','LR','RF', 'Xgb','MLP']:\n",
    "            roberta = result[(result['Embedding']=='Roberta-static') & \\\n",
    "                             (result['Classifier_Model']==Classifier_Model)& \\\n",
    "                            (result['Type']==tp)]\n",
    "            bertweet = result[(result['Embedding']=='Bertweet-static') & \\\n",
    "                             (result['Classifier_Model']==Classifier_Model)& \\\n",
    "                            (result['Type']==tp)]\n",
    "            fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "            plt.scatter(roberta['Positive'],roberta[metric], label='Rob', marker='o')\n",
    "            for i,row in roberta.iterrows(): plt.text(row['Positive'],row[metric], s=row['Data_Set'])\n",
    "            plt.scatter(bertweet['Positive'],bertweet[metric], label='Btw', marker='*')\n",
    "            plt.title(\"RoBERTa_BERTweet_Classifier{}_Metric_{}_{}.png\".format(Classifier_Model,metric,tp))\n",
    "            plt.xlabel(\"%Positive\")\n",
    "            plt.ylabel(metric)\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(\"RoBERTa_BERTweet_Classifier{}_Metric_{}_{}.png\".format(Classifier_Model,metric,tp))\n",
    "            plt.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1595009919507,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "1Idi3E1ehTaV",
    "outputId": "622eaffa-be5a-41f1-aee2-ebdd40a36ff8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#Classifier_Model= \"SVM\"\n",
    "#metric='f1_macro'\n",
    "markers = {\"Roberta-static\": \"o\", \"Bertweet-static\": \"X\"}\n",
    "for metric in ['accuracy','f1_macro']:\n",
    "    for Classifier_Model in ['SVM','LR','RF', 'Xgb','MLP']:\n",
    "        roberta = result[(result['Embedding'].isin(['Roberta-static','Bertweet-static'])) \\\n",
    "                          & (result['Classifier_Model']==Classifier_Model)]\n",
    "        \n",
    "        fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "        \n",
    "        ax=sns.scatterplot(data=roberta,x='Positive', y = metric, \\\n",
    "                        hue='Embedding',size='Size', legend=\"full\")\n",
    "        \n",
    "        for i,row in roberta.iterrows(): ax.text(row['Positive'],row[metric], \\\n",
    "                                                 row['Data_Set'], size='medium', \\\n",
    "                                                 color='black', weight='semibold')\n",
    "\n",
    "        for i,row in roberta.iterrows(): \n",
    "            if row['Embedding'] == \"Roberta-static\":\n",
    "                ax.vlines(row['Positive'], roberta[(roberta['Embedding']=='Bertweet-static') & (roberta['Data_Set']==row['Data_Set'])][metric], \\\n",
    "                                                   row[metric],color='gray', linestyles=\"dashed\")\n",
    "        plt.title(\"RoBERTa vs BERTweet Classifier: {}\".format(Classifier_Model))\n",
    "        plt.xlabel(\"%Positive\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        legend_labels, _= ax.get_legend_handles_labels()\n",
    "        ax.legend(legend_labels[:3], ['','Roberta','Bertweet'], bbox_to_anchor=(1,1))\n",
    "\n",
    "        #plt.grid()\n",
    "        plt.savefig(\"RoBERTa_BERTweet_Classifier{}_Metric_{}_size.png\".format(Classifier_Model,metric))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Classifier_Model= \"SVM\"\\n#metric=\\'f1_macro\\'\\nfor metric in [\\'accuracy\\',\\'f1_macro\\']:\\n    for Classifier_Model in [\\'SVM\\',\\'LR\\',\\'RF\\', \\'Xgb\\',\\'MLP\\']:\\n        delta = pd.DataFrame()\\n        roberta = result[(result[\\'Embedding\\']==\\'Roberta-static\\') & (result[\\'Classifier_Model\\']==Classifier_Model)].sort_values(by=[\\'Classifier_Model\\',\\'Embedding\\',\\'Data_Set\\',\\'Positive\\']).reset_index(drop=True)\\n        bertweet = result[(result[\\'Embedding\\']==\\'Bertweet-static\\') & (result[\\'Classifier_Model\\']==Classifier_Model)].sort_values(by=[\\'Classifier_Model\\',\\'Embedding\\',\\'Data_Set\\',\\'Positive\\']).reset_index(drop=True)\\n        delta[metric] = roberta[metric]-bertweet[metric]\\n        delta[roberta.columns[-4:]] = roberta.iloc[:,-4:]\\n        fig=plt.figure(figsize=(12,8), dpi= 100)\\n        plt.scatter(delta[\\'Positive\\'],delta[metric], marker=\\'o\\')\\n        for i,row in delta.iterrows(): plt.text(row[\\'Positive\\'],row[metric], s=row[\\'Data_Set\\'])\\n        #plt.scatter(bertweet[\\'Positive\\'],bertweet[metric], label=\\'Btw\\', marker=\\'*\\')\\n        plt.title(\"RoBERTa_BERTweet_Classifier{}_Metric_{}.png\".format(Classifier_Model,metric))\\n        plt.xlabel(\"%Positive\")\\n        plt.ylabel(\"Diferença de {}\".format(metric))\\n        plt.grid()\\n        plt.savefig(\"Delta_RoBERTa_BERTweet_Classifier{}_Metric_{}.png\".format(Classifier_Model,metric))\\n        plt.close()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Classifier_Model= \"SVM\"\n",
    "#metric='f1_macro'\n",
    "for metric in ['accuracy','f1_macro']:\n",
    "    for Classifier_Model in ['SVM','LR','RF', 'Xgb','MLP']:\n",
    "        delta = pd.DataFrame()\n",
    "        roberta = result[(result['Embedding']=='Roberta-static') & (result['Classifier_Model']==Classifier_Model)].sort_values(by=['Classifier_Model','Embedding','Data_Set','Positive']).reset_index(drop=True)\n",
    "        bertweet = result[(result['Embedding']=='Bertweet-static') & (result['Classifier_Model']==Classifier_Model)].sort_values(by=['Classifier_Model','Embedding','Data_Set','Positive']).reset_index(drop=True)\n",
    "        delta[metric] = roberta[metric]-bertweet[metric]\n",
    "        delta[roberta.columns[-4:]] = roberta.iloc[:,-4:]\n",
    "        fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "        plt.scatter(delta['Positive'],delta[metric], marker='o')\n",
    "        for i,row in delta.iterrows(): plt.text(row['Positive'],row[metric], s=row['Data_Set'])\n",
    "        #plt.scatter(bertweet['Positive'],bertweet[metric], label='Btw', marker='*')\n",
    "        plt.title(\"RoBERTa_BERTweet_Classifier{}_Metric_{}.png\".format(Classifier_Model,metric))\n",
    "        plt.xlabel(\"%Positive\")\n",
    "        plt.ylabel(\"Diferença de {}\".format(metric))\n",
    "        plt.grid()\n",
    "        plt.savefig(\"Delta_RoBERTa_BERTweet_Classifier{}_Metric_{}.png\".format(Classifier_Model,metric))\n",
    "        plt.close()'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNu7AB0kwJRPr+r17jbMTv3",
   "collapsed_sections": [],
   "mount_file_id": "18YqNJ9EiloCFcgw03FIBpEvdUpPY5fCt",
   "name": "organize_result_bestoverall.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
