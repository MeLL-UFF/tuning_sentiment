{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montaTabelaLatexNew(df_acc, df_f1):\n",
    "  first = True\n",
    "  for ind in df_acc.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.8ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df_acc[\"Data_Set\"][ind])+'&'+str(df_acc['accuracy'][ind])+'&'+str(df_acc[\"Classifier_Model\"][ind])+'&'+str(df_acc[\"Embedding\"][ind])+'&'+str(df_f1['f1_macro'][ind])+'&'+str(df_f1[\"Classifier_Model\"][ind])+'&'+str(df_f1[\"Embedding\"][ind])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deParaClassifierName(textDe):\n",
    "  if textDe == 'MLPClassifier':\n",
    "    return 'MLP'\n",
    "  elif textDe == 'Reg_Logistica':\n",
    "    return 'LR'\n",
    "  elif textDe == 'Random_Forest':\n",
    "    return 'RF'\n",
    "  elif textDe == 'XGboost':\n",
    "    return 'Xgb'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deParaDatasetName(textDe):\n",
    "  if textDe == 'ntua':\n",
    "    return 'ntu'\n",
    "  elif textDe == 'SemEval15-Task11':\n",
    "    return 'S15'\n",
    "  elif textDe == 'iphone':\n",
    "    return 'iph'\n",
    "  elif textDe == 'Narr-KDML-2012':\n",
    "    return 'Nar'\n",
    "  elif textDe == 'VADER':\n",
    "    return 'Vad'\n",
    "  elif textDe == 'SemEval17-test':\n",
    "    return 'S17'\n",
    "  elif textDe == 'debate08':\n",
    "    return 'OMD'\n",
    "  elif textDe == 'irony':\n",
    "    return 'iro'\n",
    "  elif textDe == 'sarcasm':\n",
    "    return 'sar'\n",
    "  elif textDe == 'sentiment140':\n",
    "    return 'stm'\n",
    "  elif textDe == 'person':\n",
    "    return 'per'\n",
    "  elif textDe == 'hobbit':\n",
    "    return 'hob'\n",
    "  elif textDe == 'movie':\n",
    "    return 'mov'\n",
    "  elif textDe == 'sanders':\n",
    "    return 'san'\n",
    "  elif textDe == 'archeage':\n",
    "    return 'arc'\n",
    "  elif textDe == 'SemEval18':\n",
    "    return 'S18'\n",
    "  elif textDe == 'STS-gold':\n",
    "    return 'STS'\n",
    "  elif textDe == 'SentiStrength':\n",
    "    return 'SST'\n",
    "  elif textDe == 'Target-dependent':\n",
    "    return 'Tar'\n",
    "  elif textDe == 'SemEval13':\n",
    "    return 'S13'\n",
    "  elif textDe == 'SemEval16':\n",
    "    return 'S16'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deParaEmbeddingNameIndata(textDe):\n",
    "    if textDe == \"Bert: bert-base-uncased / CONTEXT_CONCAT\":\n",
    "        return 'Bert-edin1500'\n",
    "    elif textDe == 'BERTweet_base_transformers_CONTEXT':\n",
    "        return 'Bertweet-Indata'\n",
    "    elif textDe == 'Roberta: roberta-base / CONTEXT_CONCAT':\n",
    "        return 'Roberta-Indata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deParaEmbeddingName(textDe):\n",
    "  if textDe == 'W2V-GN':\n",
    "    return 'w2v-GN'\n",
    "  elif textDe == 'GloveWP':\n",
    "    return 'GloVe-WP'\n",
    "  elif textDe == 'FastText':\n",
    "    return 'fastText'\n",
    "  elif textDe == 'GloveTW':\n",
    "    return 'GloVe-TWT'\n",
    "  elif textDe == 'Bert: bert-base-uncased / STATIC_AVG':\n",
    "    return 'Bert-static'\n",
    "  elif textDe == 'TFIDF':\n",
    "    return 'TF-IDF'\n",
    "  elif textDe == 'W2VAraque':\n",
    "    return 'w2v-Araque'\n",
    "  elif textDe == 'W2VEdin':\n",
    "    return 'w2v-Edin'\n",
    "  elif textDe == 'Roberta: roberta-base / STATIC_AVG':\n",
    "    return 'Roberta-static'\n",
    "  elif textDe == 'Roberta: roberta-base / CONTEXT_CONCAT':\n",
    "    return 'Roberta-context'\n",
    "  elif textDe == 'Bert: bert-base-uncased / CONTEXT_CONCAT':\n",
    "    return 'Bert-context'\n",
    "  elif textDe == 'Roberta: RoBERTa_sentiment_tuned/ / CONTEXT_CONCAT':\n",
    "    return 'Roberta-sent140'\n",
    "  elif textDe == 'Bert: BERT_sentiment_tuned/ / CONTEXT_CONCAT':\n",
    "    return 'Bert-sent140'\n",
    "  elif textDe == 'Roberta: ./RoBERTaedinV2LM / CONTEXT_CONCAT':\n",
    "    return 'Roberta-edin'\n",
    "  elif textDe == 'Bert: ./BERTedinV2 / CONTEXT_CONCAT':\n",
    "    return 'Bert-edin'\n",
    "  elif textDe == 'Roberta: ./RoBER50kLM / CONTEXT_CONCAT':\n",
    "    return 'RoBerta-edin50'\n",
    "  elif textDe == 'Roberta: ./RoBER250kLM / CONTEXT_CONCAT':\n",
    "    return 'RoBerta-edin250'\n",
    "  elif textDe == \"Roberta: ./RoBER500kLM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin500'\n",
    "  elif textDe == \"Roberta: ./RoBER1500kLM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin1500'\n",
    "  elif textDe == \"Roberta: ./RoBER22DTLM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-Dataset'\n",
    "  elif textDe == \"Bert: ./BERT22DT / CONTEXT_CONCAT\":\n",
    "    return 'Bert-Dataset'\n",
    "  elif textDe == 'Bert: ./BERT50K / CONTEXT_CONCAT':\n",
    "    return 'Bert-edin50'\n",
    "  elif textDe == 'Bert: ./BERT250K / CONTEXT_CONCAT':\n",
    "    return 'Bert-edin250'\n",
    "  elif textDe == \"Bert: ./BERT500K / CONTEXT_CONCAT\":\n",
    "    return 'Bert-edin500'\n",
    "  elif textDe == \"Bert: ./BERT1500K / CONTEXT_CONCAT\":\n",
    "    return 'Bert-edin1500'\n",
    "  elif textDe == 'Roberta: ./RoBERTaToken250LM / CONTEXT_CONCAT':\n",
    "    return 'RoBerta-edin250-token'\n",
    "  elif textDe == \"Roberta: ./RoBERTaToken500LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin500-token'\n",
    "  elif textDe == \"Roberta: ./RoBERTaToken1500LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin1500-token'\n",
    "  elif textDe == \"Roberta: ./RoBERTaToken6600LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin-token'\n",
    "  elif textDe == \"BERTweet_base_transformers_CONTEXT\":\n",
    "    return 'Bertweet'\n",
    "  elif textDe == \"./BERTweetFinetuning_CONTEXT\":\n",
    "    return 'Bertweet-edin-50'\n",
    "  elif textDe == \"./BERTweetFinetuning250_CONTEXT\":\n",
    "    return 'Bertweet-edin-250'\n",
    "  elif textDe == \"./BERTweetFinetuning500_CONTEXT\":\n",
    "    return 'Bertweet-edin-500'\n",
    "  elif textDe == \"./BERTweetFinetuning1500_CONTEXT\":\n",
    "    return 'Bertweet-edin-150'\n",
    "  elif textDe == \"./BERTweetFinetuning22DT_CONTEXT\":\n",
    "    return 'Bertweet-Dataset'\n",
    "  else:\n",
    "    return textDe.split('./')[-1].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets=['HCR',\n",
    "                  'Narr-KDML-2012',\n",
    "                  'STS-gold',\n",
    "                  'SemEval13',\n",
    "                  'SemEval15-Task11',\n",
    "                  'SemEval16',\n",
    "                  'SemEval17-test',\n",
    "                  'SemEval18',\n",
    "                  'SentiStrength',\n",
    "                  'Target-dependent',\n",
    "                  'VADER',\n",
    "                  'archeage',\n",
    "                  'debate08',\n",
    "                  'hobbit',\n",
    "                  'iphone',\n",
    "                  'irony',\n",
    "                  'movie',\n",
    "                  'ntua',\n",
    "                  'person',\n",
    "                  'sanders',\n",
    "                  'sarcasm',\n",
    "                  'sentiment140']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montaTabelaLatex(df, metrica):\n",
    "  first = True\n",
    "  for ind in df.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.8ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df[\"Data_Set\"][ind])+'&'+str(df[metrica][ind])+'&'+str(df[\"Classifier_Model\"][ind])+'&'+str(df[\"Embedding\"][ind])+'\\\\\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.DataFrame(columns=['accuracy', 'f1_macro', 'Classifier_Model', 'Embedding', 'Data_Set'])\n",
    "df_dataset_rob = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/RoBERTa-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_rob['Embedding'] = df_dataset_rob['Embedding'].apply(lambda x: \"Roberta-22DT\")\n",
    "df_dataset_rob['accuracy'] = df_dataset_rob['accuracy'].apply(lambda x: round(x*100,2))\n",
    "df_dataset_rob['f1_macro'] = df_dataset_rob['f1_macro'].apply(lambda x: round(x*100,2))\n",
    "\n",
    "df_dataset_ber = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/BERT-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_ber['Embedding'] = df_dataset_ber['Embedding'].apply(lambda x: \"Bert-22DT\")\n",
    "df_dataset_ber['accuracy'] = df_dataset_ber['accuracy'].apply(lambda x: round(x*100,2))\n",
    "df_dataset_ber['f1_macro'] = df_dataset_ber['f1_macro'].apply(lambda x: round(x*100,2))\n",
    "\n",
    "df_dataset_bt = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/BERTweet-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_bt['Embedding'] = df_dataset_bt['Embedding'].apply(lambda x: \"Bertweet-22DT\")\n",
    "df_dataset_bt['accuracy'] = df_dataset_bt['accuracy'].apply(lambda x: round(x*100,2))\n",
    "df_dataset_bt['f1_macro'] = df_dataset_bt['f1_macro'].apply(lambda x: round(x*100,2))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "df_dataset_rob_in = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/InData/BERT-*/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_rob_in['Embedding'] = df_dataset_rob_in['Embedding'].apply(lambda x: \"Roberta-InData\")\n",
    "df_dataset_rob_in['accuracy'] = df_dataset_rob_in['accuracy'].apply(lambda x: round(x*100,2))\n",
    "df_dataset_rob_in['f1_macro'] = df_dataset_rob_in['f1_macro'].apply(lambda x: round(x*100,2))\n",
    "\n",
    "df_dataset_ber_in = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/InData/RoBERTa*/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_ber_in['Embedding'] = df_dataset_ber_in['Embedding'].apply(lambda x: \"Bert-InData\")\n",
    "df_dataset_ber_in['accuracy'] = df_dataset_ber_in['accuracy'].apply(lambda x: round(x*100,2))\n",
    "df_dataset_ber_in['f1_macro'] = df_dataset_ber_in['f1_macro'].apply(lambda x: round(x*100,2))\n",
    "\n",
    "df_dataset_bt_in = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/InData/BERTweet*/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_bt_in['Embedding'] = df_dataset_bt_in['Embedding'].apply(lambda x: \"Bertweet-InData\")\n",
    "df_dataset_bt_in['accuracy'] = df_dataset_bt_in['accuracy'].apply(lambda x: round(x*100,2))\n",
    "df_dataset_bt_in['f1_macro'] = df_dataset_bt_in['f1_macro'].apply(lambda x: round(x*100,2))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "df_dataset_rob_LOO = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/LOO/BERT-*/Final_Result*.csv\")[0], sep=\",\")\n",
    "del df_dataset_rob_LOO['Unnamed: 0']\n",
    "df_dataset_rob_LOO['Embedding'] = df_dataset_rob_LOO['Embedding'].apply(lambda x: \"Roberta-LOO\")\n",
    "\n",
    "df_dataset_ber_LOO = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/LOO/RoBERTa*/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_ber_LOO['Embedding'] = df_dataset_ber_LOO['Embedding'].apply(lambda x: \"Bert-LOO\")\n",
    "del df_dataset_ber_LOO['Unnamed: 0']\n",
    "\n",
    "df_dataset_bt_LOO = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/LOO/BERTweet*/Final_Result*.csv\")[0], sep=\",\")\n",
    "df_dataset_bt_LOO['Embedding'] = df_dataset_bt_LOO['Embedding'].apply(lambda x: \"Bertweet-LOO\")\n",
    "del df_dataset_bt_LOO['Unnamed: 0']\n",
    "\n",
    "final=pd.concat([df_dataset_rob,df_dataset_ber,df_dataset_bt,df_dataset_ber_in,df_dataset_rob_in,df_dataset_bt_in,df_dataset_rob_LOO,df_dataset_ber_LOO,df_dataset_bt_LOO],axis=0)\n",
    "final['Data_Set'] = final[\"Data_Set\"].apply(deParaDatasetName)\n",
    "final['Classifier_Model'] = final[\"Classifier_Model\"].apply(deParaClassifierName)\n",
    "final = final.reset_index(drop=True)\n",
    "#final = final.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Set</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Classifier_Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HCR</td>\n",
       "      <td>87.20</td>\n",
       "      <td>Bertweet-22DT</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nar</td>\n",
       "      <td>96.70</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OMD</td>\n",
       "      <td>91.50</td>\n",
       "      <td>Bertweet-InData</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S13</td>\n",
       "      <td>89.70</td>\n",
       "      <td>Bertweet-InData</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S15</td>\n",
       "      <td>87.80</td>\n",
       "      <td>Bertweet-22DT</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S16</td>\n",
       "      <td>89.90</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S17</td>\n",
       "      <td>93.17</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S18</td>\n",
       "      <td>92.00</td>\n",
       "      <td>Bertweet-22DT</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SST</td>\n",
       "      <td>88.40</td>\n",
       "      <td>Roberta-InData</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STS</td>\n",
       "      <td>94.21</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tar</td>\n",
       "      <td>89.60</td>\n",
       "      <td>Bert-InData</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vad</td>\n",
       "      <td>92.05</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>arc</td>\n",
       "      <td>91.67</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hob</td>\n",
       "      <td>88.00</td>\n",
       "      <td>Bertweet-22DT</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iph</td>\n",
       "      <td>89.50</td>\n",
       "      <td>Bertweet-22DT</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>iro</td>\n",
       "      <td>83.40</td>\n",
       "      <td>Bert-22DT</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iro</td>\n",
       "      <td>83.40</td>\n",
       "      <td>Bertweet-22DT</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mov</td>\n",
       "      <td>87.20</td>\n",
       "      <td>Bert-InData</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ntu</td>\n",
       "      <td>93.66</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>per</td>\n",
       "      <td>86.41</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>san</td>\n",
       "      <td>91.80</td>\n",
       "      <td>Bert-InData</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sar</td>\n",
       "      <td>83.40</td>\n",
       "      <td>Roberta-22DT</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stm</td>\n",
       "      <td>92.73</td>\n",
       "      <td>Bertweet-LOO</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data_Set  f1_macro        Embedding Classifier_Model\n",
       "0       HCR     87.20    Bertweet-22DT              SVM\n",
       "1       Nar     96.70     Bertweet-LOO               LR\n",
       "2       OMD     91.50  Bertweet-InData              SVM\n",
       "3       S13     89.70  Bertweet-InData               LR\n",
       "4       S15     87.80    Bertweet-22DT               LR\n",
       "5       S16     89.90     Bertweet-LOO              SVM\n",
       "6       S17     93.17     Bertweet-LOO              SVM\n",
       "7       S18     92.00    Bertweet-22DT              SVM\n",
       "8       SST     88.40   Roberta-InData               LR\n",
       "9       STS     94.21     Bertweet-LOO              SVM\n",
       "10      Tar     89.60      Bert-InData               LR\n",
       "11      Vad     92.05     Bertweet-LOO               LR\n",
       "12      arc     91.67     Bertweet-LOO              MLP\n",
       "13      hob     88.00    Bertweet-22DT               LR\n",
       "14      iph     89.50    Bertweet-22DT               LR\n",
       "15      iro     83.40        Bert-22DT               LR\n",
       "16      iro     83.40    Bertweet-22DT               LR\n",
       "17      mov     87.20      Bert-InData              MLP\n",
       "18      ntu     93.66     Bertweet-LOO               LR\n",
       "19      per     86.41     Bertweet-LOO              MLP\n",
       "20      san     91.80      Bert-InData               LR\n",
       "21      sar     83.40     Roberta-22DT              MLP\n",
       "22      stm     92.73     Bertweet-LOO              SVM"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_acc = final[['Data_Set','accuracy']].groupby(by=['Data_Set']).max().reset_index()\n",
    "max_acc = max_acc.merge(final[['Data_Set','accuracy','Embedding','Classifier_Model']],left_on=['Data_Set','accuracy'],right_on=['Data_Set','accuracy'])\n",
    "\n",
    "\n",
    "max_f1 = final[['Data_Set','f1_macro']].groupby(by=['Data_Set']).max().reset_index()\n",
    "max_f1 = max_f1.merge(final[['Data_Set','f1_macro','Embedding','Classifier_Model']],left_on=['Data_Set','f1_macro'],right_on=['Data_Set','f1_macro'])\n",
    "\n",
    "max_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCR&88.5&SVM&Bertweet-22DT&87.2&SVM&Bertweet-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Nar&96.82&LR&Bertweet-LOO&96.7&LR&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "OMD&91.8&SVM&Bertweet-InData&91.5&SVM&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S13&91.3&LR&Bertweet-InData&89.7&LR&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S15&94.39299999999999&MLP&Bertweet-LOO&87.8&LR&Bertweet-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S16&91.62&SVM&Bertweet-LOO&89.9&SVM&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S17&93.59&SVM&Bertweet-LOO&93.17&SVM&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S18&92.1&SVM&Bertweet-22DT&92.0&SVM&Bertweet-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SST&88.6&LR&Roberta-InData&88.4&LR&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "STS&94.99&LR&Bertweet-LOO&94.21&SVM&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "STS&94.99&SVM&Bertweet-LOO&89.6&LR&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Tar&90.4&LR&Bert-InData&92.05&LR&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Vad&93.14&LR&Bertweet-LOO&91.67&MLP&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "arc&91.85&Xgb&Bertweet-LOO&88.0&LR&Bertweet-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "hob&89.47&LR&Bertweet-LOO&89.5&LR&Bertweet-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "iph&90.9&LR&Bertweet-22DT&83.4&LR&Bert-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "iro&86.1&LR&Bertweet-22DT&83.4&LR&Bertweet-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "mov&90.84700000000001&MLP&Bertweet-LOO&87.2&MLP&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "ntu&93.89&LR&Bertweet-LOO&93.66&LR&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "per&90.9&LR&Bertweet-InData&86.41&MLP&Bertweet-LOO\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "san&91.9&LR&Bert-InData&91.8&LR&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sar&86.5&MLP&Roberta-22DT&83.4&MLP&Roberta-22DT\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "stm&92.75&SVM&Bertweet-LOO&92.73&SVM&Bertweet-LOO\\\\\n"
     ]
    }
   ],
   "source": [
    "montaTabelaLatexNew(max_acc,max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summarization(acc,f1):\n",
    "    acc = acc.merge(f1,how='outer',left_on=['index'],right_on=['index'])\n",
    "    print(acc)\n",
    "    for i,row in acc.iterrows():\n",
    "        print(str(row['index'])+\"&\"+str(row['Embedding_x'])+\"&\"+str(row['Embedding_y'])+\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             index  Embedding_x  Embedding_y\n",
      "0     Bertweet-LOO         12.0            9\n",
      "1    Bertweet-22DT          4.0            6\n",
      "2  Bertweet-InData          3.0            2\n",
      "3      Bert-InData          2.0            3\n",
      "4   Roberta-InData          1.0            1\n",
      "5     Roberta-22DT          1.0            1\n",
      "6        Bert-22DT          NaN            1\n",
      "Bertweet-LOO&12.0&9\\\\\n",
      "Bertweet-22DT&4.0&6\\\\\n",
      "Bertweet-InData&3.0&2\\\\\n",
      "Bert-InData&2.0&3\\\\\n",
      "Roberta-InData&1.0&1\\\\\n",
      "Roberta-22DT&1.0&1\\\\\n",
      "Bert-22DT&nan&1\\\\\n"
     ]
    }
   ],
   "source": [
    "acc = pd.DataFrame(max_acc['Embedding'].value_counts()).reset_index()\n",
    "f1 = pd.DataFrame(max_f1['Embedding'].value_counts()).reset_index()\n",
    "print_summarization(acc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR     12\n",
      "SVM     7\n",
      "MLP     3\n",
      "Xgb     1\n",
      "Name: Classifier_Model, dtype: int64\n",
      "LR     12\n",
      "SVM     7\n",
      "MLP     4\n",
      "Name: Classifier_Model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(max_acc['Classifier_Model'].value_counts())\n",
    "print(max_f1['Classifier_Model'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([df_dataset_rob,df_dataset_ber,df_dataset_bt,df_dataset_ber_in,df_dataset_rob_in,df_dataset_bt_in,df_dataset_rob_LOO,df_dataset_ber_LOO,df_dataset_bt_LOO],axis=0)\n",
    "df_loo = pd.concat([df_dataset_rob_LOO,df_dataset_ber_LOO,df_dataset_bt_LOO],axis=0)\n",
    "#df_loo['Embedding'] = df_loo[\"Embedding\"].apply(deParaEmbeddingName)\n",
    "#df_loo['Data_Set'] = df_loo[\"Data_Set\"].apply(deParaDatasetName)\n",
    "#df_loo['Classifier_Model'] = df_loo[\"Classifier_Model\"].apply(deParaClassifierName)\n",
    "\n",
    "df_inData = pd.concat([df_dataset_rob,df_dataset_ber,df_dataset_bt],axis=0)\n",
    "#df_inData['Embedding'] = df_inData[\"Embedding\"].apply(deParaEmbeddingName)\n",
    "#df_inData['Data_Set'] = df_inData[\"Data_Set\"].apply(deParaDatasetName)\n",
    "#df_inData['Classifier_Model'] = df_inData[\"Classifier_Model\"].apply(deParaClassifierName)\n",
    "\n",
    "df_22dt = pd.concat([df_dataset_ber_in,df_dataset_rob_in,df_dataset_bt_in],axis=0)\n",
    "#df_22dt['Embedding'] = df_22dt[\"Embedding\"].apply(deParaEmbeddingName)\n",
    "#df_22dt['Data_Set'] = df_22dt[\"Data_Set\"].apply(deParaDatasetName)\n",
    "#df_22dt['Classifier_Model'] = df_22dt[\"Classifier_Model\"].apply(deParaClassifierName)\n",
    "\n",
    "df_22dt.columns=['Acc 22DT','F1 22DT','Classifier_Model','Embedding 22DT','Data_Set 22DT']\n",
    "df_inData.columns=['Acc InData','F1 InData','Classifier_Model','Embedding InData','Data_Set InData']\n",
    "df_loo.columns=['Acc Leave1out','F1 Leave1out','Classifier_Model','Embedding Leave1out','Data_Set Leave1out']\n",
    "\n",
    "#df_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_22dt_acc = df_22dt.sort_values(by=['Data_Set 22DT', 'Acc 22DT'], ascending=False).drop_duplicates(subset='Data_Set 22DT', keep=\"first\")\n",
    "df_22dt_acc = df_22dt_acc.reset_index(drop=True)\n",
    "df_22dt_acc = df_22dt_acc.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])\n",
    "\n",
    "df_22dt_f1 = df_22dt.sort_values(by=['Data_Set 22DT', 'F1 22DT'], ascending=False).drop_duplicates(subset='Data_Set 22DT', keep=\"first\")\n",
    "df_22dt_f1 = df_22dt_f1.reset_index(drop=True)\n",
    "df_22dt_f1 = df_22dt_f1.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])\n",
    "\n",
    "df_loo_acc = df_loo.sort_values(by=['Data_Set Leave1out', 'Acc Leave1out'], ascending=False).drop_duplicates(subset='Data_Set Leave1out', keep=\"first\")\n",
    "df_loo_acc = df_loo_acc.reset_index(drop=True)\n",
    "df_loo_acc = df_loo_acc.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])\n",
    "\n",
    "df_loo_f1 = df_loo.sort_values(by=['Data_Set Leave1out', 'F1 Leave1out'], ascending=False).drop_duplicates(subset='Data_Set Leave1out', keep=\"first\")\n",
    "df_loo_f1 = df_loo_f1.reset_index(drop=True)\n",
    "df_loo_f1 = df_loo_f1.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])\n",
    "\n",
    "df_inData_acc = df_inData.sort_values(by=['Data_Set InData', 'Acc InData'], ascending=False)\n",
    "df_inData_acc = df_inData_acc.drop_duplicates(subset='Data_Set InData', keep=\"first\")\n",
    "df_inData_acc = df_inData_acc.reset_index(drop=True)\n",
    "df_inData_acc = df_inData_acc.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])\n",
    "\n",
    "df_inData_f1 = df_inData.sort_values(by=['Data_Set InData', 'F1 InData'], ascending=False).drop_duplicates(subset='Data_Set InData', keep=\"first\")\n",
    "df_inData_f1 = df_inData_f1.reset_index(drop=True)\n",
    "df_inData_f1 = df_inData_f1.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montaTabelaLatexComp(df, metrica):\n",
    "  first = True\n",
    "  for ind in df.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.8ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print(str(df[\"Data_Set InData\"][ind])+'&'\n",
    "          +str(df[metrica+' Leave1out'][ind])+'&'\n",
    "          +str(df[\"Embedding Leave1out\"][ind])+'&'\n",
    "          +str(df[metrica+' InData'][ind])+'&'\n",
    "          +str(df[\"Embedding InData\"][ind])+'&'\n",
    "          +str(df[metrica+' 22DT'][ind])+'&'\n",
    "          +str(df[\"Embedding 22DT\"][ind])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irony&83.33&Bertweet-LOO&86.1&Bertweet-22DT&82.0&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sarcasm&80.657&Bert-LOO&86.5&Roberta-22DT&83.6&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "ntua&93.89&Bertweet-LOO&91.3&Bert-22DT&92.2&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval15-Task11&94.39299999999999&Bertweet-LOO&93.2&Bertweet-22DT&91.7&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sentiment140&92.75&Bertweet-LOO&92.3&Bertweet-22DT&90.3&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "person&88.51700000000001&Bertweet-LOO&88.9&Roberta-22DT&90.9&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "hobbit&89.47&Bertweet-LOO&89.1&Bert-22DT&88.8&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "iphone&87.723&Bert-LOO&90.9&Bertweet-22DT&88.2&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "movie&90.84700000000001&Bertweet-LOO&88.1&Bert-22DT&89.7&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sanders&91.34&Bertweet-LOO&89.1&Roberta-22DT&91.9&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Narr-KDML-2012&96.82&Bertweet-LOO&93.5&Bertweet-22DT&91.4&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "debate08&89.77&Bertweet-LOO&90.0&Bertweet-22DT&91.8&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval18&90.26&Bertweet-LOO&92.1&Bertweet-22DT&89.3&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "STS-gold&94.99&Bertweet-LOO&93.8&Bertweet-22DT&93.2&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "HCR&82.213&Bertweet-LOO&88.5&Bertweet-22DT&88.3&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Target-dependent&87.63&Bertweet-LOO&89.7&Bertweet-22DT&90.4&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SentiStrength&88.55&Bertweet-LOO&87.8&Roberta-22DT&88.6&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "VADER&93.14&Bertweet-LOO&88.3&Roberta-22DT&91.9&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "archeage&91.85&Bertweet-LOO&91.8&Bert-22DT&89.5&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval13&89.70700000000001&Bertweet-LOO&90.2&Bert-22DT&91.3&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval17-test&93.59&Bertweet-LOO&92.1&Bertweet-22DT&92.5&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval16&91.62&Bertweet-LOO&90.4&Bert-22DT&89.7&Bert-InData\\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#final_acc = final_acc.reset_index(drop=True)\n",
    "#final_acc = final_acc.reindex([5,1,9,17,0,3,7,6,4,2,20,8,13,19,21,18,12,11,10,16,14,15])\n",
    "#print(final_acc['Data_Set'].iloc[1])\n",
    "concat = pd.concat([df_loo_acc,df_inData_acc,df_22dt_acc],axis=1)\n",
    "montaTabelaLatexComp(concat, \"Acc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertweet-LOO    20\n",
      "Bert-LOO         2\n",
      "Name: Embedding Leave1out, dtype: int64\n",
      "Bertweet-22DT    11\n",
      "Bert-22DT         6\n",
      "Roberta-22DT      5\n",
      "Name: Embedding InData, dtype: int64\n",
      "Bertweet-InData    8\n",
      "Bert-InData        8\n",
      "Roberta-InData     6\n",
      "Name: Embedding 22DT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_loo_acc['Embedding Leave1out'].value_counts())\n",
    "print(df_inData_acc['Embedding InData'].value_counts())\n",
    "print(df_22dt_f1['Embedding 22DT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM              7\n",
      "Reg_Logistica    7\n",
      "MLPClassifier    6\n",
      "XGboost          2\n",
      "Name: Classifier_Model, dtype: int64\n",
      "Reg_Logistica    8\n",
      "SVM              7\n",
      "MLPClassifier    6\n",
      "XGboost          1\n",
      "Name: Classifier_Model, dtype: int64\n",
      "Reg_Logistica    14\n",
      "MLPClassifier     5\n",
      "SVM               3\n",
      "Name: Classifier_Model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_loo_acc['Classifier_Model'].value_counts())\n",
    "print(df_inData_acc['Classifier_Model'].value_counts())\n",
    "print(df_22dt_acc['Classifier_Model'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irony&77.24&Bertweet-LOO&83.4&Bert-22DT&78.5&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sarcasm&78.96&Bert-LOO&83.4&Roberta-22DT&82.0&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "ntua&93.66&Bertweet-LOO&90.4&Bertweet-22DT&91.3&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval15-Task11&87.29&Bertweet-LOO&87.8&Bertweet-22DT&87.3&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sentiment140&92.73&Bertweet-LOO&92.2&Bertweet-22DT&89.5&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "person&86.41&Bertweet-LOO&81.4&Bertweet-22DT&86.2&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "hobbit&87.96&Bertweet-LOO&88.0&Bertweet-22DT&87.8&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "iphone&85.57&Bert-LOO&89.5&Bertweet-22DT&87.4&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "movie&83.34&Bertweet-LOO&84.8&Bert-22DT&87.2&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sanders&91.27&Bertweet-LOO&87.5&Roberta-22DT&91.8&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Narr-KDML-2012&96.7&Bertweet-LOO&92.6&Bertweet-22DT&91.0&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "debate08&88.99&Bertweet-LOO&86.5&Bertweet-22DT&91.5&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval18&90.19&Bertweet-LOO&92.0&Bertweet-22DT&89.1&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "STS-gold&94.21&Bertweet-LOO&93.4&Bertweet-22DT&92.6&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "HCR&78.19&Bertweet-LOO&87.2&Bertweet-22DT&87.0&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Target-dependent&87.62&Bertweet-LOO&89.1&Bertweet-22DT&89.6&Bert-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SentiStrength&88.25&Bertweet-LOO&87.0&Roberta-22DT&88.4&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "VADER&92.05&Bertweet-LOO&86.1&Roberta-22DT&88.4&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "archeage&91.67&Bertweet-LOO&90.6&Roberta-22DT&89.0&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval13&87.49&Bertweet-LOO&88.1&Bert-22DT&89.7&Bertweet-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval17-test&93.17&Bertweet-LOO&89.8&Bertweet-22DT&91.8&Roberta-InData\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SemEval16&89.9&Bertweet-LOO&89.6&Bert-22DT&88.8&Bert-InData\\\\\n"
     ]
    }
   ],
   "source": [
    "concat_f1 = pd.concat([df_loo_f1,df_inData_f1,df_22dt_f1],axis=1)\n",
    "montaTabelaLatexComp(concat_f1, \"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertweet-LOO    20\n",
      "Bert-LOO         2\n",
      "Name: Embedding Leave1out, dtype: int64\n",
      "Bertweet-22DT    13\n",
      "Roberta-22DT      5\n",
      "Bert-22DT         4\n",
      "Name: Embedding InData, dtype: int64\n",
      "Bertweet-InData    8\n",
      "Bert-InData        8\n",
      "Roberta-InData     6\n",
      "Name: Embedding 22DT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_loo_f1['Embedding Leave1out'].value_counts())\n",
    "print(df_inData_f1['Embedding InData'].value_counts())\n",
    "print(df_22dt_f1['Embedding 22DT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM              11\n",
      "MLPClassifier     6\n",
      "Reg_Logistica     5\n",
      "Name: Classifier_Model, dtype: int64\n",
      "Reg_Logistica    11\n",
      "SVM               8\n",
      "MLPClassifier     2\n",
      "XGboost           1\n",
      "Name: Classifier_Model, dtype: int64\n",
      "Reg_Logistica    15\n",
      "SVM               4\n",
      "MLPClassifier     3\n",
      "Name: Classifier_Model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_loo_f1['Classifier_Model'].value_counts())\n",
    "print(df_inData_f1['Classifier_Model'].value_counts())\n",
    "print(df_22dt_f1['Classifier_Model'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
