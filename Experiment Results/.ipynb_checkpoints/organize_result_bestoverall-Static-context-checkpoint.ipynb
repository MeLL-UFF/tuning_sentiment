{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1595009918773,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "9dywRoFT5UnK",
    "outputId": "368e4966-ad6f-4c72-971f-d93dd4e9001c"
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#from google.colab import drive\n",
    "#drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1595009919116,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "Iiq-FUPF7SE2",
    "outputId": "a47f5e00-b017-47c1-dfe7-d198b161e864"
   },
   "outputs": [],
   "source": [
    "#%cd /gdrive/My Drive/Colab Notebooks/estudo-orientado/relatorio/expr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deParaClassifierName(textDe):\n",
    "  if textDe == 'MLPClassifier':\n",
    "    return 'MLP'\n",
    "  elif textDe == 'Reg_Logistica':\n",
    "    return 'LR'\n",
    "  elif textDe == 'Random_Forest':\n",
    "    return 'RF'\n",
    "  elif textDe == 'XGboost':\n",
    "    return 'Xgb'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets=['HCR',\n",
    "                  'Narr-KDML-2012',\n",
    "                  'STS-gold',\n",
    "                  'SemEval13',\n",
    "                  'SemEval15-Task11',\n",
    "                  'SemEval16',\n",
    "                  'SemEval17-test',\n",
    "                  'SemEval18',\n",
    "                  'SentiStrength',\n",
    "                  'Target-dependent',\n",
    "                  'VADER',\n",
    "                  'archeage',\n",
    "                  'debate08',\n",
    "                  'hobbit',\n",
    "                  'iphone',\n",
    "                  'irony',\n",
    "                  'movie',\n",
    "                  'ntua',\n",
    "                  'person',\n",
    "                  'sanders',\n",
    "                  'sarcasm',\n",
    "                  'sentiment140']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1316,
     "status": "ok",
     "timestamp": 1595009919117,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "XAW3uCp27ptx"
   },
   "outputs": [],
   "source": [
    "dict = {\n",
    "    \"fileNames\" : [\n",
    "                   \"irony\",\n",
    "                   \"sarcasm\",\n",
    "                   \"aisopos\",\n",
    "                   \"SemEval-Fig\",\n",
    "                   \"sentiment140\",\n",
    "                   \"person\",\n",
    "                   \"hobbit\",\n",
    "                   \"iphone6\",\n",
    "                   \"movie\",\n",
    "                   \"sanders\",\n",
    "                   \"Narr\",\n",
    "                   \"archeage\",\n",
    "                   \"SemEval18\",\n",
    "                   \"OMD\",\n",
    "                   \"HCR\",\n",
    "                   \"STS-gold\",\n",
    "                   \"SentiStrength\",\n",
    "                   \"Target-dependent\",\n",
    "                   \"Vader\",\n",
    "                   \"SemEval13\",\n",
    "                   \"SemEval17\",\n",
    "                   \"SemEval16\"\n",
    "                  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1595009919128,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "UsamTZP99FUW"
   },
   "outputs": [],
   "source": [
    "def deParaDatasetName(textDe):\n",
    "  if textDe == 'ntua':\n",
    "    return 'aisopos'\n",
    "  elif textDe == 'SemEval15-Task11':\n",
    "    return 'SemEval-Fig'\n",
    "  elif textDe == 'iphone':\n",
    "    return 'iphone6'\n",
    "  elif textDe == 'Narr-KDML-2012':\n",
    "    return 'Narr'\n",
    "  elif textDe == 'VADER':\n",
    "    return 'Vader'\n",
    "  elif textDe == 'SemEval17-test':\n",
    "    return 'SemEval17'\n",
    "  elif textDe == 'debate08':\n",
    "    return 'OMD'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1595009919129,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "J4oWDmB6inaO"
   },
   "outputs": [],
   "source": [
    "def deParaEmbeddingName(textDe):\n",
    "  if textDe == 'W2V-GN':\n",
    "    return 'w2v-GN'\n",
    "  elif textDe == 'GloveWP':\n",
    "    return 'GloVe-WP'\n",
    "  elif textDe == 'FastText':\n",
    "    return 'fastText'\n",
    "  elif textDe == 'GloveTW':\n",
    "    return 'GloVe-TWT'\n",
    "  elif textDe == 'Bert: bert-base-uncased / STATIC_AVG':\n",
    "    return 'Bert-static'\n",
    "  elif textDe == \"BERTweet_base_transformers_STATIC\":\n",
    "    return 'Bertweet-static'\n",
    "  elif textDe == 'TFIDF':\n",
    "    return 'TF-IDF'\n",
    "  elif textDe == 'W2VAraque':\n",
    "    return 'w2v-Araque'\n",
    "  elif textDe == 'W2VEdin':\n",
    "    return 'w2v-Edin'\n",
    "  elif textDe == 'Roberta: roberta-base / STATIC_AVG':\n",
    "    return 'Roberta-static'\n",
    "  elif textDe == 'Roberta: roberta-base / CONTEXT_CONCAT':\n",
    "    return 'Roberta-context'\n",
    "  elif textDe == 'Bert: bert-base-uncased / CONTEXT_CONCAT':\n",
    "    return 'Bert-context'\n",
    "  elif textDe == 'Roberta: RoBERTa_sentiment_tuned/ / CONTEXT_CONCAT':\n",
    "    return 'Roberta-sent140'\n",
    "  elif textDe == 'Bert: BERT_sentiment_tuned/ / CONTEXT_CONCAT':\n",
    "    return 'Bert-sent140'\n",
    "  elif textDe == 'Roberta: ./RoBERTaedinV2LM / CONTEXT_CONCAT':\n",
    "    return 'Roberta-edin'\n",
    "  elif textDe == 'Bert: ./BERTedinV2 / CONTEXT_CONCAT':\n",
    "    return 'Bert-edin'\n",
    "  elif textDe == 'Roberta: ./RoBER50kLM / CONTEXT_CONCAT':\n",
    "    return 'RoBerta-edin50'\n",
    "  elif textDe == 'Roberta: ./RoBER250kLM / CONTEXT_CONCAT':\n",
    "    return 'RoBerta-edin250'\n",
    "  elif textDe == \"Roberta: ./RoBER500kLM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin500'\n",
    "  elif textDe == \"Roberta: ./RoBER1500kLM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin1500'\n",
    "  elif textDe == \"Roberta: ./RoBER22DTLM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-Dataset'\n",
    "  elif textDe == \"Bert: ./BERT22DT / CONTEXT_CONCAT\":\n",
    "    return 'Bert-Dataset'\n",
    "  elif textDe == 'Bert: ./BERT50K / CONTEXT_CONCAT':\n",
    "    return 'Bert-edin50'\n",
    "  elif textDe == 'Bert: ./BERT250K / CONTEXT_CONCAT':\n",
    "    return 'Bert-edin250'\n",
    "  elif textDe == \"Bert: ./BERT500K / CONTEXT_CONCAT\":\n",
    "    return 'Bert-edin500'\n",
    "  elif textDe == \"Bert: ./BERT1500K / CONTEXT_CONCAT\":\n",
    "    return 'Bert-edin1500'\n",
    "  elif textDe == 'Roberta: ./RoBERTaToken250LM / CONTEXT_CONCAT':\n",
    "    return 'RoBerta-edin250-token'\n",
    "  elif textDe == \"Roberta: ./RoBERTaToken500LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin500-token'\n",
    "  elif textDe == \"Roberta: ./RoBERTaToken1500LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin1500-token'\n",
    "  elif textDe == \"Roberta: ./RoBERTaToken6600LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBerta-edin-token'\n",
    "  elif textDe == \"BERTweet_base_transformers_CONTEXT\":\n",
    "    return 'Bertweet-context'\n",
    "  elif textDe == \"./BERTweetFinetuning_CONTEXT\":\n",
    "    return 'Bertweet-edin-50'\n",
    "  elif textDe == \"./BERTweetFinetuning250_CONTEXT\":\n",
    "    return 'Bertweet-edin-250'\n",
    "  elif textDe == \"./BERTweetFinetuning500_CONTEXT\":\n",
    "    return 'Bertweet-edin-500'\n",
    "  elif textDe == \"./BERTweetFinetuning1500_CONTEXT\":\n",
    "    return 'Bertweet-edin-150'\n",
    "  elif textDe == \"./BERTweetFinetuning22DT_CONTEXT\":\n",
    "    return 'Bertweet-22DT'\n",
    "\n",
    "\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1624,
     "status": "ok",
     "timestamp": 1595009919494,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "9qVLCGH69TdW"
   },
   "outputs": [],
   "source": [
    "def deParaDatasetName(textDe):\n",
    "  if textDe == 'ntua':\n",
    "    return 'ntu'\n",
    "  elif textDe == 'SemEval15-Task11':\n",
    "    return 'S15'\n",
    "  elif textDe == 'iphone':\n",
    "    return 'iph'\n",
    "  elif textDe == 'Narr-KDML-2012':\n",
    "    return 'Nar'\n",
    "  elif textDe == 'VADER':\n",
    "    return 'Vad'\n",
    "  elif textDe == 'SemEval17-test':\n",
    "    return 'S17'\n",
    "  elif textDe == 'debate08':\n",
    "    return 'OMD'\n",
    "  elif textDe == 'irony':\n",
    "    return 'iro'\n",
    "  elif textDe == 'sarcasm':\n",
    "    return 'sar'\n",
    "  elif textDe == 'sentiment140':\n",
    "    return 'stm'\n",
    "  elif textDe == 'person':\n",
    "    return 'per'\n",
    "  elif textDe == 'hobbit':\n",
    "    return 'hob'\n",
    "  elif textDe == 'movie':\n",
    "    return 'mov'\n",
    "  elif textDe == 'sanders':\n",
    "    return 'san'\n",
    "  elif textDe == 'archeage':\n",
    "    return 'arc'\n",
    "  elif textDe == 'SemEval18':\n",
    "    return 'S18'\n",
    "  elif textDe == 'STS-gold':\n",
    "    return 'STS'\n",
    "  elif textDe == 'SentiStrength':\n",
    "    return 'SST'\n",
    "  elif textDe == 'Target-dependent':\n",
    "    return 'Tar'\n",
    "  elif textDe == 'SemEval13':\n",
    "    return 'S13'\n",
    "  elif textDe == 'SemEval16':\n",
    "    return 'S16'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1585,
     "status": "ok",
     "timestamp": 1595009919495,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "PhS6C9E152Xr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Data_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.83</td>\n",
       "      <td>72.47</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>STS-gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>72.32</td>\n",
       "      <td>52.94</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>STS-gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>82.50</td>\n",
       "      <td>80.16</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>STS-gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>85.35</td>\n",
       "      <td>82.53</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>STS-gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>77.83</td>\n",
       "      <td>69.28</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>STS-gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>67.58</td>\n",
       "      <td>67.34</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SentiStrength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>65.44</td>\n",
       "      <td>60.27</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SentiStrength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>72.30</td>\n",
       "      <td>72.07</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SentiStrength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>74.62</td>\n",
       "      <td>73.64</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SentiStrength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>68.89</td>\n",
       "      <td>66.61</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SentiStrength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>66.96</td>\n",
       "      <td>63.25</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>71.07</td>\n",
       "      <td>44.91</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>67.41</td>\n",
       "      <td>65.89</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>77.21</td>\n",
       "      <td>70.61</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>70.62</td>\n",
       "      <td>54.26</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>73.36</td>\n",
       "      <td>72.84</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Narr-KDML-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>71.48</td>\n",
       "      <td>65.43</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Narr-KDML-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>79.79</td>\n",
       "      <td>79.30</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Narr-KDML-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>82.89</td>\n",
       "      <td>82.11</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Narr-KDML-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>75.88</td>\n",
       "      <td>73.77</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Narr-KDML-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>72.71</td>\n",
       "      <td>72.68</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Target-dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>71.04</td>\n",
       "      <td>71.01</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Target-dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>79.78</td>\n",
       "      <td>79.74</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Target-dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>79.29</td>\n",
       "      <td>79.28</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Target-dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>76.67</td>\n",
       "      <td>76.65</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>Target-dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>70.74</td>\n",
       "      <td>67.95</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>73.69</td>\n",
       "      <td>46.17</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>77.02</td>\n",
       "      <td>73.97</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>81.36</td>\n",
       "      <td>76.69</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>77.23</td>\n",
       "      <td>63.52</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>74.76</td>\n",
       "      <td>72.39</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>debate08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>76.55</td>\n",
       "      <td>70.52</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>debate08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>82.37</td>\n",
       "      <td>80.54</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>debate08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>79.12</td>\n",
       "      <td>77.71</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>debate08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>79.33</td>\n",
       "      <td>76.33</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>debate08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>74.56</td>\n",
       "      <td>74.22</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>69.72</td>\n",
       "      <td>68.06</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>79.02</td>\n",
       "      <td>78.75</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>79.93</td>\n",
       "      <td>79.80</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>74.77</td>\n",
       "      <td>74.33</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>SemEval18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>75.69</td>\n",
       "      <td>73.45</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>VADER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>72.05</td>\n",
       "      <td>50.72</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>VADER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>81.53</td>\n",
       "      <td>79.44</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>VADER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>85.65</td>\n",
       "      <td>83.17</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>VADER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>77.50</td>\n",
       "      <td>69.48</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>VADER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>76.04</td>\n",
       "      <td>74.72</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>hobbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>79.31</td>\n",
       "      <td>69.69</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>hobbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>88.69</td>\n",
       "      <td>87.65</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>hobbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>92.34</td>\n",
       "      <td>91.10</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>hobbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>84.86</td>\n",
       "      <td>81.74</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>hobbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>69.94</td>\n",
       "      <td>69.27</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>75.49</td>\n",
       "      <td>74.77</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>78.03</td>\n",
       "      <td>77.57</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>82.10</td>\n",
       "      <td>82.01</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>76.15</td>\n",
       "      <td>75.79</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>57.68</td>\n",
       "      <td>56.63</td>\n",
       "      <td>Reg_Logistica</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>60.54</td>\n",
       "      <td>56.72</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>60.54</td>\n",
       "      <td>57.74</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>54.82</td>\n",
       "      <td>52.87</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>56.43</td>\n",
       "      <td>52.32</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>BERTweet_base_transformers_STATIC</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  f1_macro Classifier_Model                          Embedding  \\\n",
       "15      74.83     72.47    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "16      72.32     52.94    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "17      82.50     80.16              SVM  BERTweet_base_transformers_STATIC   \n",
       "18      85.35     82.53    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "19      77.83     69.28          XGboost  BERTweet_base_transformers_STATIC   \n",
       "35      67.58     67.34    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "36      65.44     60.27    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "37      72.30     72.07              SVM  BERTweet_base_transformers_STATIC   \n",
       "38      74.62     73.64    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "39      68.89     66.61          XGboost  BERTweet_base_transformers_STATIC   \n",
       "55      66.96     63.25    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "56      71.07     44.91    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "57      67.41     65.89              SVM  BERTweet_base_transformers_STATIC   \n",
       "58      77.21     70.61    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "59      70.62     54.26          XGboost  BERTweet_base_transformers_STATIC   \n",
       "75      73.36     72.84    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "76      71.48     65.43    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "77      79.79     79.30              SVM  BERTweet_base_transformers_STATIC   \n",
       "78      82.89     82.11    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "79      75.88     73.77          XGboost  BERTweet_base_transformers_STATIC   \n",
       "95      72.71     72.68    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "96      71.04     71.01    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "97      79.78     79.74              SVM  BERTweet_base_transformers_STATIC   \n",
       "98      79.29     79.28    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "99      76.67     76.65          XGboost  BERTweet_base_transformers_STATIC   \n",
       "115     70.74     67.95    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "116     73.69     46.17    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "117     77.02     73.97              SVM  BERTweet_base_transformers_STATIC   \n",
       "118     81.36     76.69    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "119     77.23     63.52          XGboost  BERTweet_base_transformers_STATIC   \n",
       "..        ...       ...              ...                                ...   \n",
       "335     74.76     72.39    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "336     76.55     70.52    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "337     82.37     80.54              SVM  BERTweet_base_transformers_STATIC   \n",
       "338     79.12     77.71    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "339     79.33     76.33          XGboost  BERTweet_base_transformers_STATIC   \n",
       "355     74.56     74.22    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "356     69.72     68.06    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "357     79.02     78.75              SVM  BERTweet_base_transformers_STATIC   \n",
       "358     79.93     79.80    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "359     74.77     74.33          XGboost  BERTweet_base_transformers_STATIC   \n",
       "375     75.69     73.45    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "376     72.05     50.72    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "377     81.53     79.44              SVM  BERTweet_base_transformers_STATIC   \n",
       "378     85.65     83.17    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "379     77.50     69.48          XGboost  BERTweet_base_transformers_STATIC   \n",
       "395     76.04     74.72    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "396     79.31     69.69    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "397     88.69     87.65              SVM  BERTweet_base_transformers_STATIC   \n",
       "398     92.34     91.10    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "399     84.86     81.74          XGboost  BERTweet_base_transformers_STATIC   \n",
       "415     69.94     69.27    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "416     75.49     74.77    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "417     78.03     77.57              SVM  BERTweet_base_transformers_STATIC   \n",
       "418     82.10     82.01    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "419     76.15     75.79          XGboost  BERTweet_base_transformers_STATIC   \n",
       "435     57.68     56.63    Reg_Logistica  BERTweet_base_transformers_STATIC   \n",
       "436     60.54     56.72    Random_Forest  BERTweet_base_transformers_STATIC   \n",
       "437     60.54     57.74              SVM  BERTweet_base_transformers_STATIC   \n",
       "438     54.82     52.87    MLPClassifier  BERTweet_base_transformers_STATIC   \n",
       "439     56.43     52.32          XGboost  BERTweet_base_transformers_STATIC   \n",
       "\n",
       "             Data_Set  \n",
       "15           STS-gold  \n",
       "16           STS-gold  \n",
       "17           STS-gold  \n",
       "18           STS-gold  \n",
       "19           STS-gold  \n",
       "35      SentiStrength  \n",
       "36      SentiStrength  \n",
       "37      SentiStrength  \n",
       "38      SentiStrength  \n",
       "39      SentiStrength  \n",
       "55             person  \n",
       "56             person  \n",
       "57             person  \n",
       "58             person  \n",
       "59             person  \n",
       "75     Narr-KDML-2012  \n",
       "76     Narr-KDML-2012  \n",
       "77     Narr-KDML-2012  \n",
       "78     Narr-KDML-2012  \n",
       "79     Narr-KDML-2012  \n",
       "95   Target-dependent  \n",
       "96   Target-dependent  \n",
       "97   Target-dependent  \n",
       "98   Target-dependent  \n",
       "99   Target-dependent  \n",
       "115         SemEval13  \n",
       "116         SemEval13  \n",
       "117         SemEval13  \n",
       "118         SemEval13  \n",
       "119         SemEval13  \n",
       "..                ...  \n",
       "335          debate08  \n",
       "336          debate08  \n",
       "337          debate08  \n",
       "338          debate08  \n",
       "339          debate08  \n",
       "355         SemEval18  \n",
       "356         SemEval18  \n",
       "357         SemEval18  \n",
       "358         SemEval18  \n",
       "359         SemEval18  \n",
       "375             VADER  \n",
       "376             VADER  \n",
       "377             VADER  \n",
       "378             VADER  \n",
       "379             VADER  \n",
       "395            hobbit  \n",
       "396            hobbit  \n",
       "397            hobbit  \n",
       "398            hobbit  \n",
       "399            hobbit  \n",
       "415           sanders  \n",
       "416           sanders  \n",
       "417           sanders  \n",
       "418           sanders  \n",
       "419           sanders  \n",
       "435           sarcasm  \n",
       "436           sarcasm  \n",
       "437           sarcasm  \n",
       "438           sarcasm  \n",
       "439           sarcasm  \n",
       "\n",
       "[110 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "########## Estatico ##########\n",
    "dfStatic = pd.read_csv(glob.glob(\"staticLM/Pivot_tables/Final_Result_StaticLM_*.csv\")[0], sep=\",\")\n",
    "dfStatic = dfStatic[dfStatic['Embedding']=='BERTweet_base_transformers_STATIC']\n",
    "\n",
    "dfstatic_ = pd.read_csv(glob.glob(\"staticLM/Pivot_tables/Final_Result_staticLM_*.csv\")[0], sep=\",\")\n",
    "dfstatic = dfstatic_[(dfstatic_['Embedding']!='BERTweet_base_transformers_STATIC') &\n",
    "                    (dfstatic_['Classifier_Model']!='XGboost')]\n",
    "\n",
    "df_btw_static = pd.read_csv(glob.glob(\"staticXgbLM/Pivot_tables/Final_Result_staticXgbLM_*.csv\")[0], sep=\",\")\n",
    "df_btw_static = df_btw_static[df_btw_static['Embedding']!='BERTweet_base_transformers_STATIC']\n",
    "\n",
    "\n",
    "\n",
    "########## Contextualizado ##########\n",
    "df_roberta = pd.read_csv(glob.glob(\"./RoBERTaXgboostLM/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "df_bert = pd.read_csv(glob.glob(\"./BERTXgboost/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "df_bertweet = pd.read_csv(glob.glob(\"./BERTweetXgboost/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1595009919500,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "NCf2vK6MNjkR"
   },
   "outputs": [],
   "source": [
    "frames = [dfstatic, dfStatic,df_btw_static,df_roberta,df_bert,df_bertweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1595009919501,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "IwrQ3coXNuIe"
   },
   "outputs": [],
   "source": [
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1595009919502,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "SkBoFHgNwndl"
   },
   "outputs": [],
   "source": [
    "result[[\"accuracy\", \"f1_macro\"]] = result[[\"accuracy\", \"f1_macro\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1595009919504,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "05WFV64O2zJN"
   },
   "outputs": [],
   "source": [
    "result[\"Data_Set\"] = result[\"Data_Set\"].apply(deParaDatasetName)\n",
    "result[\"Embedding\"] = result[\"Embedding\"].apply(deParaEmbeddingName)\n",
    "result[\"Classifier_Model\"] = result[\"Classifier_Model\"].apply(deParaClassifierName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1595009919507,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "1Idi3E1ehTaV",
    "outputId": "622eaffa-be5a-41f1-aee2-ebdd40a36ff8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Data_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>51.90</td>\n",
       "      <td>46.92</td>\n",
       "      <td>LR</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>65.95</td>\n",
       "      <td>45.15</td>\n",
       "      <td>RF</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>48.33</td>\n",
       "      <td>41.55</td>\n",
       "      <td>SVM</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>60.24</td>\n",
       "      <td>50.29</td>\n",
       "      <td>MLP</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>65.71</td>\n",
       "      <td>57.73</td>\n",
       "      <td>LR</td>\n",
       "      <td>w2v-Araque</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>64.52</td>\n",
       "      <td>39.11</td>\n",
       "      <td>RF</td>\n",
       "      <td>w2v-Araque</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>63.10</td>\n",
       "      <td>48.35</td>\n",
       "      <td>SVM</td>\n",
       "      <td>w2v-Araque</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>63.10</td>\n",
       "      <td>49.79</td>\n",
       "      <td>MLP</td>\n",
       "      <td>w2v-Araque</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>w2v-Araque</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>70.71</td>\n",
       "      <td>65.27</td>\n",
       "      <td>LR</td>\n",
       "      <td>GloVe-WP</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>64.76</td>\n",
       "      <td>39.24</td>\n",
       "      <td>RF</td>\n",
       "      <td>GloVe-WP</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>69.52</td>\n",
       "      <td>64.46</td>\n",
       "      <td>SVM</td>\n",
       "      <td>GloVe-WP</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>75.71</td>\n",
       "      <td>68.78</td>\n",
       "      <td>MLP</td>\n",
       "      <td>GloVe-WP</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>GloVe-WP</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>57.38</td>\n",
       "      <td>50.57</td>\n",
       "      <td>LR</td>\n",
       "      <td>GloVe-TWT</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>57.62</td>\n",
       "      <td>45.91</td>\n",
       "      <td>RF</td>\n",
       "      <td>GloVe-TWT</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>60.00</td>\n",
       "      <td>53.08</td>\n",
       "      <td>SVM</td>\n",
       "      <td>GloVe-TWT</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>55.95</td>\n",
       "      <td>46.84</td>\n",
       "      <td>MLP</td>\n",
       "      <td>GloVe-TWT</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>GloVe-TWT</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>66.90</td>\n",
       "      <td>62.40</td>\n",
       "      <td>LR</td>\n",
       "      <td>fastText</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>67.86</td>\n",
       "      <td>43.55</td>\n",
       "      <td>RF</td>\n",
       "      <td>fastText</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>67.86</td>\n",
       "      <td>60.78</td>\n",
       "      <td>SVM</td>\n",
       "      <td>fastText</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>74.52</td>\n",
       "      <td>63.98</td>\n",
       "      <td>MLP</td>\n",
       "      <td>fastText</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>fastText</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>56.90</td>\n",
       "      <td>50.02</td>\n",
       "      <td>LR</td>\n",
       "      <td>SSWE</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>60.00</td>\n",
       "      <td>37.38</td>\n",
       "      <td>RF</td>\n",
       "      <td>SSWE</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>58.33</td>\n",
       "      <td>47.88</td>\n",
       "      <td>SVM</td>\n",
       "      <td>SSWE</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>66.43</td>\n",
       "      <td>59.45</td>\n",
       "      <td>MLP</td>\n",
       "      <td>SSWE</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>SSWE</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>62.62</td>\n",
       "      <td>56.27</td>\n",
       "      <td>LR</td>\n",
       "      <td>Roberta-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>66.19</td>\n",
       "      <td>39.77</td>\n",
       "      <td>RF</td>\n",
       "      <td>Roberta-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>70.48</td>\n",
       "      <td>61.16</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Roberta-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>72.38</td>\n",
       "      <td>62.33</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Roberta-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>55.24</td>\n",
       "      <td>41.13</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Roberta-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>60.95</td>\n",
       "      <td>56.53</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bert-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>66.19</td>\n",
       "      <td>39.77</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bert-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>63.33</td>\n",
       "      <td>56.21</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bert-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>64.29</td>\n",
       "      <td>52.77</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bert-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>61.43</td>\n",
       "      <td>46.58</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bert-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>47.62</td>\n",
       "      <td>41.83</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>66.19</td>\n",
       "      <td>39.77</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>44.29</td>\n",
       "      <td>39.60</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>66.19</td>\n",
       "      <td>51.78</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>69.29</td>\n",
       "      <td>53.85</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bertweet-static</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65.95</td>\n",
       "      <td>57.55</td>\n",
       "      <td>LR</td>\n",
       "      <td>Roberta-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66.19</td>\n",
       "      <td>39.77</td>\n",
       "      <td>RF</td>\n",
       "      <td>Roberta-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46.67</td>\n",
       "      <td>31.00</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Roberta-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70.71</td>\n",
       "      <td>63.36</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Roberta-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61.67</td>\n",
       "      <td>48.30</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Roberta-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>80.48</td>\n",
       "      <td>73.08</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bert-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>67.62</td>\n",
       "      <td>43.48</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bert-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>71.43</td>\n",
       "      <td>66.51</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bert-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>80.48</td>\n",
       "      <td>70.87</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bert-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>60.24</td>\n",
       "      <td>48.24</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bert-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>72.14</td>\n",
       "      <td>65.10</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>67.62</td>\n",
       "      <td>43.48</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>69.52</td>\n",
       "      <td>61.22</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>73.33</td>\n",
       "      <td>64.96</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bertweet-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>61.90</td>\n",
       "      <td>47.05</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bertweet-context</td>\n",
       "      <td>iro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  f1_macro Classifier_Model         Embedding Data_Set\n",
       "715     51.90     46.92               LR          w2v-Edin      iro\n",
       "716     65.95     45.15               RF          w2v-Edin      iro\n",
       "717     48.33     41.55              SVM          w2v-Edin      iro\n",
       "718     60.24     50.29              MLP          w2v-Edin      iro\n",
       "719      0.00      0.00              Xgb          w2v-Edin      iro\n",
       "720     65.71     57.73               LR        w2v-Araque      iro\n",
       "721     64.52     39.11               RF        w2v-Araque      iro\n",
       "722     63.10     48.35              SVM        w2v-Araque      iro\n",
       "723     63.10     49.79              MLP        w2v-Araque      iro\n",
       "724      0.00      0.00              Xgb        w2v-Araque      iro\n",
       "725     70.71     65.27               LR          GloVe-WP      iro\n",
       "726     64.76     39.24               RF          GloVe-WP      iro\n",
       "727     69.52     64.46              SVM          GloVe-WP      iro\n",
       "728     75.71     68.78              MLP          GloVe-WP      iro\n",
       "729      0.00      0.00              Xgb          GloVe-WP      iro\n",
       "730     57.38     50.57               LR         GloVe-TWT      iro\n",
       "731     57.62     45.91               RF         GloVe-TWT      iro\n",
       "732     60.00     53.08              SVM         GloVe-TWT      iro\n",
       "733     55.95     46.84              MLP         GloVe-TWT      iro\n",
       "734      0.00      0.00              Xgb         GloVe-TWT      iro\n",
       "735     66.90     62.40               LR          fastText      iro\n",
       "736     67.86     43.55               RF          fastText      iro\n",
       "737     67.86     60.78              SVM          fastText      iro\n",
       "738     74.52     63.98              MLP          fastText      iro\n",
       "739      0.00      0.00              Xgb          fastText      iro\n",
       "740     56.90     50.02               LR              SSWE      iro\n",
       "741     60.00     37.38               RF              SSWE      iro\n",
       "742     58.33     47.88              SVM              SSWE      iro\n",
       "743     66.43     59.45              MLP              SSWE      iro\n",
       "744      0.00      0.00              Xgb              SSWE      iro\n",
       "..        ...       ...              ...               ...      ...\n",
       "770     62.62     56.27               LR    Roberta-static      iro\n",
       "771     66.19     39.77               RF    Roberta-static      iro\n",
       "772     70.48     61.16              SVM    Roberta-static      iro\n",
       "773     72.38     62.33              MLP    Roberta-static      iro\n",
       "774     55.24     41.13              Xgb    Roberta-static      iro\n",
       "775     60.95     56.53               LR       Bert-static      iro\n",
       "776     66.19     39.77               RF       Bert-static      iro\n",
       "777     63.33     56.21              SVM       Bert-static      iro\n",
       "778     64.29     52.77              MLP       Bert-static      iro\n",
       "779     61.43     46.58              Xgb       Bert-static      iro\n",
       "155     47.62     41.83               LR   Bertweet-static      iro\n",
       "156     66.19     39.77               RF   Bertweet-static      iro\n",
       "157     44.29     39.60              SVM   Bertweet-static      iro\n",
       "158     66.19     51.78              MLP   Bertweet-static      iro\n",
       "159     69.29     53.85              Xgb   Bertweet-static      iro\n",
       "5       65.95     57.55               LR   Roberta-context      iro\n",
       "6       66.19     39.77               RF   Roberta-context      iro\n",
       "7       46.67     31.00              SVM   Roberta-context      iro\n",
       "8       70.71     63.36              MLP   Roberta-context      iro\n",
       "9       61.67     48.30              Xgb   Roberta-context      iro\n",
       "105     80.48     73.08               LR      Bert-context      iro\n",
       "106     67.62     43.48               RF      Bert-context      iro\n",
       "107     71.43     66.51              SVM      Bert-context      iro\n",
       "108     80.48     70.87              MLP      Bert-context      iro\n",
       "109     60.24     48.24              Xgb      Bert-context      iro\n",
       "75      72.14     65.10               LR  Bertweet-context      iro\n",
       "76      67.62     43.48               RF  Bertweet-context      iro\n",
       "77      69.52     61.22              SVM  Bertweet-context      iro\n",
       "78      73.33     64.96              MLP  Bertweet-context      iro\n",
       "79      61.90     47.05              Xgb  Bertweet-context      iro\n",
       "\n",
       "[85 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by='Data_Set')\n",
    "result[result['Data_Set']=='iro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1595009919507,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "dP9oWlPFxk4X"
   },
   "outputs": [],
   "source": [
    "#result[(result['Classifier_Model'] == 'MLPClassifier') & (result['Embedding'] == 'Bert-context')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1595009919508,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "n2i9Vw-ahUnG"
   },
   "outputs": [],
   "source": [
    "result_acc = result.sort_values(by=['Data_Set', 'accuracy'], ascending=False)\n",
    "result_f1 = result.sort_values(by=['Data_Set', 'f1_macro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1288,
     "status": "ok",
     "timestamp": 1595009919509,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "Mq6A-3oomtFD"
   },
   "outputs": [],
   "source": [
    "result_acc = result_acc.drop_duplicates(subset='Data_Set', keep=\"first\")\n",
    "result_acc=result_acc.reset_index(drop=True)\n",
    "result_f1 = result_f1.drop_duplicates(subset='Data_Set', keep=\"first\")\n",
    "result_f1=result_f1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDcdc-rZ7G8b"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "dict = {\n",
    "    \"fileNames\" : [\n",
    "                   \"irony\",\n",
    "                   \"sarcasm\",\n",
    "                   \"aisopos\",\n",
    "                   \"SemEval-Fig\",\n",
    "                   \"sentiment140\",\n",
    "                   \"person\",\n",
    "                   \"hobbit\",\n",
    "                   \"iphone6\",\n",
    "                   \"movie\",\n",
    "                   \"sanders\",\n",
    "                   \"Narr\",\n",
    "                   \"archeage\",\n",
    "                   \"SemEval18\",\n",
    "                   \"OMD\",\n",
    "                   \"HCR\",\n",
    "                   \"STS-gold\",\n",
    "                   \"SentiStrength\",\n",
    "                   \"Target-dependent\",\n",
    "                   \"Vader\",\n",
    "                   \"SemEval13\",\n",
    "                   \"SemEval17\",\n",
    "                   \"SemEval16\"\n",
    "                  ]\n",
    "}```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1595009919509,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "yRP2Qkz3-Wwq"
   },
   "outputs": [],
   "source": [
    "def montaTabelaLatex(df, metrica):\n",
    "  first = True\n",
    "  for ind in df.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.8ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df[\"Data_Set\"][ind])+'&'+str(df[metrica][ind])+'&'+str(df[\"Classifier_Model\"][ind])+'&'+str(df[\"Embedding\"][ind])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montaTabelaLatexNew(df_acc, df_f1):\n",
    "  first = True\n",
    "  for ind in df_acc.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.8ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df_acc[\"Data_Set\"][ind])+'&'+str(df_acc['accuracy'][ind])+'&'+str(df_acc[\"Classifier_Model\"][ind])+'&'+str(df_acc[\"Embedding\"][ind])+'&'+str(df_f1['f1_macro'][ind])+'&'+str(df_f1[\"Classifier_Model\"][ind])+'&'+str(df_f1[\"Embedding\"][ind])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1595009919510,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "QgBvWDTI4wG8"
   },
   "outputs": [],
   "source": [
    "result_acc = result_acc.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1483,
     "status": "ok",
     "timestamp": 1595009919788,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "4-024kz-8Hz5"
   },
   "outputs": [],
   "source": [
    "result_f1 = result_f1.reindex([5,1,9,17,0,3,7,6,4,2,20,8,13,19,21,18,12,11,10,16,14,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1466,
     "status": "ok",
     "timestamp": 1595009919790,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "Xvx_pVuj0VOX",
    "outputId": "56ea5af9-f85e-4e18-fd63-6b9e15fb9d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iro&80.48&LR&Bert-context&73.34&LR&Emo2Vec\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sar&76.25&SVM&SSWE&75.83&SVM&SSWE\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "ntu&92.82&SVM&DeepMoji&92.66&SVM&DeepMoji\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S15&92.23&LR&Bertweet-context&83.33&LR&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "stm&90.79&LR&Roberta-context&90.75&LR&Roberta-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "per&87.69&LR&Bertweet-context&85.29&LR&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "hob&95.01&MLP&Roberta-static&94.27&MLP&Roberta-static\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "iph&87.59&MLP&Bertweet-context&84.72&MLP&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "mov&89.47&MLP&Roberta-context&82.12&LR&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "san&91.17&MLP&Bertweet-context&91.11&MLP&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Nar&95.6&MLP&Bertweet-context&95.43&MLP&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "arc&90.74&MLP&Bertweet-context&90.51&MLP&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S18&88.97&SVM&Bertweet-context&88.87&SVM&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "OMD&87.36&SVM&Bertweet-context&86.4&SVM&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "HCR&81.55&Xgb&Bertweet-context&76.77&LR&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "STS&93.9&LR&Bertweet-context&92.98&LR&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SST&86.76&SVM&Bertweet-context&86.53&SVM&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Tar&86.93&SVM&Bertweet-context&86.92&SVM&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Vad&90.8&LR&Bertweet-context&89.38&LR&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S13&89.61&LR&Bertweet-context&87.37&LR&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S17&92.56&SVM&Bertweet-context&92.08&SVM&Bertweet-context\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S16&91.03&LR&Bertweet-context&89.05&LR&Bertweet-context\\\\\n"
     ]
    }
   ],
   "source": [
    "montaTabelaLatexNew(result_acc,result_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertweet-context    16\n",
      "Roberta-context      2\n",
      "Bert-context         1\n",
      "Roberta-static       1\n",
      "SSWE                 1\n",
      "DeepMoji             1\n",
      "Name: Embedding, dtype: int64\n",
      "Bertweet-context    17\n",
      "Roberta-static       1\n",
      "Roberta-context      1\n",
      "Emo2Vec              1\n",
      "SSWE                 1\n",
      "DeepMoji             1\n",
      "Name: Embedding, dtype: int64\n",
      "LR     8\n",
      "SVM    7\n",
      "MLP    6\n",
      "Xgb    1\n",
      "Name: Classifier_Model, dtype: int64\n",
      "LR     10\n",
      "SVM     7\n",
      "MLP     5\n",
      "Name: Classifier_Model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_acc['Embedding'].value_counts())\n",
    "print(result_f1['Embedding'].value_counts())\n",
    "print(result_acc['Classifier_Model'].value_counts())\n",
    "print(result_f1['Classifier_Model'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNu7AB0kwJRPr+r17jbMTv3",
   "collapsed_sections": [],
   "mount_file_id": "18YqNJ9EiloCFcgw03FIBpEvdUpPY5fCt",
   "name": "organize_result_bestoverall.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
