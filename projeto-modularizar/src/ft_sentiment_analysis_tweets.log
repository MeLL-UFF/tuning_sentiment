INFO:__main__:Lendo parametros
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/roberta-base-vocab.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140587683788688 on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock
INFO:filelock:Lock 140587683788688 acquired on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock
INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmppc9396ut
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "GET /models.huggingface.co/bert/roberta-base-vocab.json HTTP/1.1" 200 898823
INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
DEBUG:filelock:Attempting to release lock 140587683788688 on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock
INFO:filelock:Lock 140587683788688 released on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/roberta-base-merges.txt HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140587683790272 on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock
INFO:filelock:Lock 140587683790272 acquired on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock
INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpiar23saj
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "GET /models.huggingface.co/bert/roberta-base-merges.txt HTTP/1.1" 200 456318
INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
DEBUG:filelock:Attempting to release lock 140587683790272 on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock
INFO:filelock:Lock 140587683790272 released on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/roberta-base-config.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140587683393696 on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock
INFO:filelock:Lock 140587683393696 acquired on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock
INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpw8_98_sk
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "GET /models.huggingface.co/bert/roberta-base-config.json HTTP/1.1" 200 481
INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json in cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
DEBUG:filelock:Attempting to release lock 140587683393696 on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock
INFO:filelock:Lock 140587683393696 released on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
INFO:transformers.configuration_utils:Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "HEAD /roberta-base-pytorch_model.bin HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140587683393840 on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock
INFO:filelock:Lock 140587683393840 acquired on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock
INFO:transformers.file_utils:https://cdn.huggingface.co/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpba9y5gqu
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "GET /roberta-base-pytorch_model.bin HTTP/1.1" 200 501200538
INFO:transformers.file_utils:storing https://cdn.huggingface.co/roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
DEBUG:filelock:Attempting to release lock 140587683393840 on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock
INFO:filelock:Lock 140587683393840 released on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock
INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing RobertaModel.

INFO:transformers.modeling_utils:All the weights of RobertaModel were initialized from the model checkpoint at roberta-base.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/roberta-base-vocab.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/roberta-base-merges.txt HTTP/1.1" 200 0
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/roberta-base-config.json HTTP/1.1" 200 0
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
INFO:transformers.configuration_utils:Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "HEAD /roberta-base-pytorch_model.bin HTTP/1.1" 200 0
INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing RobertaForMaskedLM.

WARNING:transformers.modeling_utils:Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
INFO:transformers.data.datasets.language_modeling:Creating features from dataset file at ../../language-detector/fasttext/twitter_edin_50_en
INFO:transformers.training_args:PyTorch: setting up devices
INFO:transformers.trainer:You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.
WARNING:transformers.training_args:Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.
WARNING:transformers.training_args:Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.
INFO:transformers.trainer:***** Running training *****
INFO:transformers.trainer:  Num examples = 44417966
INFO:transformers.trainer:  Num Epochs = 3
INFO:transformers.trainer:  Instantaneous batch size per device = 8
INFO:transformers.trainer:  Total train batch size (w. parallel, distributed & accumulation) = 8
INFO:transformers.trainer:  Gradient Accumulation steps = 1
INFO:transformers.trainer:  Total optimization steps = 16656738
INFO:transformers.trainer:{'loss': 3.4242013931274413, 'learning_rate': 4.999849910588736e-05, 'epoch': 9.005364675844694e-05, 'step': 500}
INFO:transformers.trainer:{'loss': 3.3227782196998596, 'learning_rate': 4.999699821177472e-05, 'epoch': 0.00018010729351689388, 'step': 1000}
INFO:transformers.trainer:{'loss': 3.2932486469745634, 'learning_rate': 4.999549731766208e-05, 'epoch': 0.00027016094027534085, 'step': 1500}
INFO:transformers.trainer:{'loss': 3.3241676909923554, 'learning_rate': 4.999399642354944e-05, 'epoch': 0.00036021458703378777, 'step': 2000}
INFO:transformers.trainer:{'loss': 3.248763565182686, 'learning_rate': 4.99924955294368e-05, 'epoch': 0.00045026823379223474, 'step': 2500}
INFO:transformers.trainer:{'loss': 3.289231466293335, 'learning_rate': 4.999099463532416e-05, 'epoch': 0.0005403218805506817, 'step': 3000}
INFO:transformers.trainer:{'loss': 3.3574344358444215, 'learning_rate': 4.9989493741211516e-05, 'epoch': 0.0006303755273091286, 'step': 3500}
INFO:transformers.trainer:{'loss': 3.2654320831298826, 'learning_rate': 4.9987992847098875e-05, 'epoch': 0.0007204291740675755, 'step': 4000}
INFO:transformers.trainer:{'loss': 3.2975426630973814, 'learning_rate': 4.9986491952986234e-05, 'epoch': 0.0008104828208260225, 'step': 4500}
INFO:transformers.trainer:{'loss': 3.329760004758835, 'learning_rate': 4.998499105887359e-05, 'epoch': 0.0009005364675844695, 'step': 5000}
INFO:transformers.trainer:{'loss': 3.231107495546341, 'learning_rate': 4.998349016476095e-05, 'epoch': 0.0009905901143429164, 'step': 5500}
INFO:transformers.trainer:{'loss': 3.2336128673553466, 'learning_rate': 4.998198927064831e-05, 'epoch': 0.0010806437611013634, 'step': 6000}
INFO:transformers.trainer:{'loss': 3.247791201591492, 'learning_rate': 4.998048837653567e-05, 'epoch': 0.0011706974078598102, 'step': 6500}
INFO:transformers.trainer:{'loss': 3.289418055534363, 'learning_rate': 4.9978987482423036e-05, 'epoch': 0.0012607510546182572, 'step': 7000}
INFO:transformers.trainer:{'loss': 3.248895721912384, 'learning_rate': 4.997748658831039e-05, 'epoch': 0.001350804701376704, 'step': 7500}
INFO:transformers.trainer:{'loss': 3.2625815185308458, 'learning_rate': 4.9975985694197754e-05, 'epoch': 0.001440858348135151, 'step': 8000}
INFO:transformers.trainer:{'loss': 3.247875717163086, 'learning_rate': 4.9974484800085106e-05, 'epoch': 0.001530911994893598, 'step': 8500}
INFO:transformers.trainer:{'loss': 3.233481053709984, 'learning_rate': 4.997298390597247e-05, 'epoch': 0.001620965641652045, 'step': 9000}
INFO:transformers.trainer:{'loss': 3.2065631844997404, 'learning_rate': 4.9971483011859824e-05, 'epoch': 0.001711019288410492, 'step': 9500}
INFO:transformers.trainer:{'loss': 3.247942594766617, 'learning_rate': 4.996998211774719e-05, 'epoch': 0.001801072935168939, 'step': 10000}
INFO:transformers.trainer:{'loss': 3.1489834477901457, 'learning_rate': 4.996848122363454e-05, 'epoch': 0.0018911265819273858, 'step': 10500}
INFO:transformers.trainer:{'loss': 3.2735370762348177, 'learning_rate': 4.996698032952191e-05, 'epoch': 0.0019811802286858328, 'step': 11000}
INFO:transformers.trainer:{'loss': 3.212554768323898, 'learning_rate': 4.996547943540926e-05, 'epoch': 0.0020712338754442796, 'step': 11500}
INFO:transformers.trainer:{'loss': 3.232784165620804, 'learning_rate': 4.9963978541296626e-05, 'epoch': 0.002161287522202727, 'step': 12000}
INFO:transformers.trainer:{'loss': 3.2564379234313963, 'learning_rate': 4.996247764718398e-05, 'epoch': 0.0022513411689611736, 'step': 12500}
INFO:transformers.trainer:{'loss': 3.233989496588707, 'learning_rate': 4.9960976753071344e-05, 'epoch': 0.0023413948157196204, 'step': 13000}
INFO:transformers.trainer:{'loss': 3.22694052028656, 'learning_rate': 4.99594758589587e-05, 'epoch': 0.0024314484624780672, 'step': 13500}
INFO:transformers.trainer:{'loss': 3.283780898571014, 'learning_rate': 4.995797496484606e-05, 'epoch': 0.0025215021092365145, 'step': 14000}
INFO:transformers.trainer:{'loss': 3.242125279426575, 'learning_rate': 4.995647407073342e-05, 'epoch': 0.0026115557559949613, 'step': 14500}
INFO:transformers.trainer:{'loss': 3.2018149411678314, 'learning_rate': 4.995497317662078e-05, 'epoch': 0.002701609402753408, 'step': 15000}
INFO:transformers.trainer:{'loss': 3.17591160094738, 'learning_rate': 4.995347228250814e-05, 'epoch': 0.0027916630495118553, 'step': 15500}
INFO:transformers.trainer:{'loss': 3.2317984082698823, 'learning_rate': 4.99519713883955e-05, 'epoch': 0.002881716696270302, 'step': 16000}
INFO:transformers.trainer:{'loss': 3.252311926841736, 'learning_rate': 4.995047049428286e-05, 'epoch': 0.002971770343028749, 'step': 16500}
INFO:transformers.trainer:{'loss': 3.1945210556983947, 'learning_rate': 4.994896960017022e-05, 'epoch': 0.003061823989787196, 'step': 17000}
INFO:transformers.trainer:{'loss': 3.2109563257694242, 'learning_rate': 4.9947468706057576e-05, 'epoch': 0.003151877636545643, 'step': 17500}
INFO:transformers.trainer:{'loss': 3.1661506373882293, 'learning_rate': 4.9945967811944935e-05, 'epoch': 0.00324193128330409, 'step': 18000}
INFO:transformers.trainer:{'loss': 3.2186690685749055, 'learning_rate': 4.9944466917832294e-05, 'epoch': 0.003331984930062537, 'step': 18500}
INFO:transformers.trainer:{'loss': 3.250980241537094, 'learning_rate': 4.994296602371965e-05, 'epoch': 0.003422038576820984, 'step': 19000}
INFO:transformers.trainer:{'loss': 3.1884034930467604, 'learning_rate': 4.994146512960701e-05, 'epoch': 0.0035120922235794307, 'step': 19500}
INFO:transformers.trainer:{'loss': 3.212201861858368, 'learning_rate': 4.993996423549437e-05, 'epoch': 0.003602145870337878, 'step': 20000}
INFO:transformers.trainer:{'loss': 3.1858889276981355, 'learning_rate': 4.993846334138173e-05, 'epoch': 0.0036921995170963247, 'step': 20500}
INFO:transformers.trainer:{'loss': 3.2451338522434234, 'learning_rate': 4.993696244726909e-05, 'epoch': 0.0037822531638547715, 'step': 21000}
INFO:transformers.trainer:{'loss': 3.1643746118545533, 'learning_rate': 4.993546155315645e-05, 'epoch': 0.0038723068106132183, 'step': 21500}
INFO:transformers.trainer:{'loss': 3.2178227462768554, 'learning_rate': 4.993396065904381e-05, 'epoch': 0.0039623604573716656, 'step': 22000}
INFO:transformers.trainer:{'loss': 3.1458304171562195, 'learning_rate': 4.9932459764931166e-05, 'epoch': 0.004052414104130112, 'step': 22500}
INFO:transformers.trainer:{'loss': 3.2236534707546234, 'learning_rate': 4.9930958870818525e-05, 'epoch': 0.004142467750888559, 'step': 23000}
INFO:transformers.trainer:{'loss': 3.2254096806049346, 'learning_rate': 4.9929457976705885e-05, 'epoch': 0.004232521397647006, 'step': 23500}
INFO:transformers.trainer:{'loss': 3.239007402420044, 'learning_rate': 4.9927957082593244e-05, 'epoch': 0.004322575044405454, 'step': 24000}
INFO:transformers.trainer:{'loss': 3.2317224056720733, 'learning_rate': 4.99264561884806e-05, 'epoch': 0.0044126286911639005, 'step': 24500}
INFO:transformers.trainer:{'loss': 3.2017690589427947, 'learning_rate': 4.992495529436796e-05, 'epoch': 0.004502682337922347, 'step': 25000}
INFO:transformers.trainer:{'loss': 3.2006105120182036, 'learning_rate': 4.992345440025532e-05, 'epoch': 0.004592735984680794, 'step': 25500}
INFO:transformers.trainer:{'loss': 3.1720853177309034, 'learning_rate': 4.992195350614268e-05, 'epoch': 0.004682789631439241, 'step': 26000}
INFO:transformers.trainer:{'loss': 3.172483932733536, 'learning_rate': 4.992045261203004e-05, 'epoch': 0.004772843278197688, 'step': 26500}
INFO:transformers.trainer:{'loss': 3.2013601977825163, 'learning_rate': 4.99189517179174e-05, 'epoch': 0.0048628969249561345, 'step': 27000}
INFO:transformers.trainer:{'loss': 3.2590436375141145, 'learning_rate': 4.991745082380476e-05, 'epoch': 0.004952950571714582, 'step': 27500}
INFO:transformers.trainer:{'loss': 3.21725990152359, 'learning_rate': 4.9915949929692116e-05, 'epoch': 0.005043004218473029, 'step': 28000}
INFO:transformers.trainer:{'loss': 3.1630822241306307, 'learning_rate': 4.991444903557948e-05, 'epoch': 0.005133057865231476, 'step': 28500}
INFO:transformers.trainer:{'loss': 3.170837859392166, 'learning_rate': 4.9912948141466834e-05, 'epoch': 0.005223111511989923, 'step': 29000}
INFO:transformers.trainer:{'loss': 3.218435856103897, 'learning_rate': 4.99114472473542e-05, 'epoch': 0.005313165158748369, 'step': 29500}
INFO:transformers.trainer:{'loss': 3.2115325177907943, 'learning_rate': 4.990994635324155e-05, 'epoch': 0.005403218805506816, 'step': 30000}
INFO:transformers.trainer:{'loss': 3.209096932888031, 'learning_rate': 4.990844545912892e-05, 'epoch': 0.005493272452265264, 'step': 30500}
INFO:transformers.trainer:{'loss': 3.237970176458359, 'learning_rate': 4.990694456501627e-05, 'epoch': 0.005583326099023711, 'step': 31000}
INFO:transformers.trainer:{'loss': 3.2308795590400696, 'learning_rate': 4.9905443670903636e-05, 'epoch': 0.0056733797457821575, 'step': 31500}
INFO:transformers.trainer:{'loss': 3.194552723646164, 'learning_rate': 4.990394277679099e-05, 'epoch': 0.005763433392540604, 'step': 32000}
INFO:transformers.trainer:{'loss': 3.20099271273613, 'learning_rate': 4.9902441882678354e-05, 'epoch': 0.005853487039299051, 'step': 32500}
INFO:transformers.trainer:{'loss': 3.2350577127933504, 'learning_rate': 4.9900940988565706e-05, 'epoch': 0.005943540686057498, 'step': 33000}
INFO:transformers.trainer:{'loss': 3.1742754200696943, 'learning_rate': 4.989944009445307e-05, 'epoch': 0.006033594332815945, 'step': 33500}
INFO:transformers.trainer:{'loss': 3.2117698860168455, 'learning_rate': 4.9897939200340425e-05, 'epoch': 0.006123647979574392, 'step': 34000}
INFO:transformers.trainer:{'loss': 3.2065862436294554, 'learning_rate': 4.989643830622779e-05, 'epoch': 0.006213701626332839, 'step': 34500}
INFO:transformers.trainer:{'loss': 3.229555370092392, 'learning_rate': 4.989493741211515e-05, 'epoch': 0.006303755273091286, 'step': 35000}
INFO:transformers.trainer:{'loss': 3.172198695898056, 'learning_rate': 4.989343651800251e-05, 'epoch': 0.006393808919849733, 'step': 35500}
INFO:transformers.trainer:{'loss': 3.1901802339553833, 'learning_rate': 4.989193562388987e-05, 'epoch': 0.00648386256660818, 'step': 36000}
INFO:transformers.trainer:{'loss': 3.2185236670970916, 'learning_rate': 4.9890434729777227e-05, 'epoch': 0.006573916213366626, 'step': 36500}
INFO:transformers.trainer:{'loss': 3.1806472344398498, 'learning_rate': 4.9888933835664586e-05, 'epoch': 0.006663969860125074, 'step': 37000}
INFO:transformers.trainer:{'loss': 3.2371658153533938, 'learning_rate': 4.9887432941551945e-05, 'epoch': 0.006754023506883521, 'step': 37500}
INFO:transformers.trainer:{'loss': 3.1910345435142515, 'learning_rate': 4.9885932047439304e-05, 'epoch': 0.006844077153641968, 'step': 38000}
INFO:transformers.trainer:{'loss': 3.1389710178375245, 'learning_rate': 4.988443115332666e-05, 'epoch': 0.0069341308004004145, 'step': 38500}
INFO:transformers.trainer:{'loss': 3.2255690815448763, 'learning_rate': 4.988293025921402e-05, 'epoch': 0.007024184447158861, 'step': 39000}
INFO:transformers.trainer:{'loss': 3.1775395295619964, 'learning_rate': 4.988142936510138e-05, 'epoch': 0.007114238093917308, 'step': 39500}
INFO:transformers.trainer:{'loss': 3.2120239396095274, 'learning_rate': 4.987992847098874e-05, 'epoch': 0.007204291740675756, 'step': 40000}
INFO:transformers.trainer:{'loss': 3.096447210788727, 'learning_rate': 4.98784275768761e-05, 'epoch': 0.007294345387434203, 'step': 40500}
INFO:transformers.trainer:{'loss': 3.2235746495723725, 'learning_rate': 4.987692668276346e-05, 'epoch': 0.007384399034192649, 'step': 41000}
INFO:transformers.trainer:{'loss': 3.2301634829044343, 'learning_rate': 4.987542578865082e-05, 'epoch': 0.007474452680951096, 'step': 41500}
INFO:transformers.trainer:{'loss': 3.2109840871095656, 'learning_rate': 4.9873924894538176e-05, 'epoch': 0.007564506327709543, 'step': 42000}
INFO:transformers.trainer:{'loss': 3.2167151491642, 'learning_rate': 4.9872424000425535e-05, 'epoch': 0.00765455997446799, 'step': 42500}
INFO:transformers.trainer:{'loss': 3.1688781774044035, 'learning_rate': 4.9870923106312894e-05, 'epoch': 0.007744613621226437, 'step': 43000}
INFO:transformers.trainer:{'loss': 3.227975093960762, 'learning_rate': 4.986942221220025e-05, 'epoch': 0.007834667267984884, 'step': 43500}
INFO:transformers.trainer:{'loss': 3.188868100166321, 'learning_rate': 4.986792131808761e-05, 'epoch': 0.007924720914743331, 'step': 44000}
INFO:transformers.trainer:{'loss': 3.229957612991333, 'learning_rate': 4.986642042397497e-05, 'epoch': 0.008014774561501778, 'step': 44500}
INFO:transformers.trainer:{'loss': 3.2055102231502532, 'learning_rate': 4.986491952986233e-05, 'epoch': 0.008104828208260225, 'step': 45000}
INFO:transformers.trainer:{'loss': 3.2028572856187822, 'learning_rate': 4.986341863574969e-05, 'epoch': 0.008194881855018672, 'step': 45500}
INFO:transformers.trainer:{'loss': 3.152525859117508, 'learning_rate': 4.986191774163705e-05, 'epoch': 0.008284935501777118, 'step': 46000}
INFO:transformers.trainer:{'loss': 3.2120924261808397, 'learning_rate': 4.986041684752441e-05, 'epoch': 0.008374989148535565, 'step': 46500}
INFO:transformers.trainer:{'loss': 3.133719531774521, 'learning_rate': 4.985891595341177e-05, 'epoch': 0.008465042795294012, 'step': 47000}
INFO:transformers.trainer:{'loss': 3.2067701976299285, 'learning_rate': 4.9857415059299126e-05, 'epoch': 0.008555096442052459, 'step': 47500}
INFO:transformers.trainer:{'loss': 3.1424822335243223, 'learning_rate': 4.9855914165186485e-05, 'epoch': 0.008645150088810907, 'step': 48000}
INFO:transformers.trainer:{'loss': 3.1864279301166536, 'learning_rate': 4.9854413271073844e-05, 'epoch': 0.008735203735569354, 'step': 48500}
INFO:transformers.trainer:{'loss': 3.1699922683238984, 'learning_rate': 4.985291237696121e-05, 'epoch': 0.008825257382327801, 'step': 49000}
INFO:transformers.trainer:{'loss': 3.2007964701652525, 'learning_rate': 4.985141148284856e-05, 'epoch': 0.008915311029086248, 'step': 49500}
INFO:transformers.trainer:{'loss': 3.182869777202606, 'learning_rate': 4.984991058873593e-05, 'epoch': 0.009005364675844695, 'step': 50000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-50000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-50000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-50000/pytorch_model.bin
INFO:transformers.trainer:{'loss': 3.1923031225204466, 'learning_rate': 4.984840969462328e-05, 'epoch': 0.009095418322603141, 'step': 50500}
INFO:transformers.trainer:{'loss': 3.1969847514629364, 'learning_rate': 4.9846908800510646e-05, 'epoch': 0.009185471969361588, 'step': 51000}
INFO:transformers.trainer:{'loss': 3.2327783918380737, 'learning_rate': 4.9845407906398e-05, 'epoch': 0.009275525616120035, 'step': 51500}
INFO:transformers.trainer:{'loss': 3.2059962413311003, 'learning_rate': 4.9843907012285364e-05, 'epoch': 0.009365579262878482, 'step': 52000}
INFO:transformers.trainer:{'loss': 3.1814105343818664, 'learning_rate': 4.9842406118172716e-05, 'epoch': 0.009455632909636929, 'step': 52500}
INFO:transformers.trainer:{'loss': 3.2033860259056093, 'learning_rate': 4.984090522406008e-05, 'epoch': 0.009545686556395375, 'step': 53000}
INFO:transformers.trainer:{'loss': 3.161749673604965, 'learning_rate': 4.9839404329947434e-05, 'epoch': 0.009635740203153822, 'step': 53500}
INFO:transformers.trainer:{'loss': 3.205532332777977, 'learning_rate': 4.98379034358348e-05, 'epoch': 0.009725793849912269, 'step': 54000}
INFO:transformers.trainer:{'loss': 3.196871191263199, 'learning_rate': 4.983640254172215e-05, 'epoch': 0.009815847496670718, 'step': 54500}
INFO:transformers.trainer:{'loss': 3.1953373606204987, 'learning_rate': 4.983490164760952e-05, 'epoch': 0.009905901143429164, 'step': 55000}
INFO:transformers.trainer:{'loss': 3.1931998927593233, 'learning_rate': 4.983340075349688e-05, 'epoch': 0.009995954790187611, 'step': 55500}
INFO:transformers.trainer:{'loss': 3.1798065259456636, 'learning_rate': 4.9831899859384236e-05, 'epoch': 0.010086008436946058, 'step': 56000}
INFO:transformers.trainer:{'loss': 3.1885356662273407, 'learning_rate': 4.9830398965271595e-05, 'epoch': 0.010176062083704505, 'step': 56500}
INFO:transformers.trainer:{'loss': 3.191942591071129, 'learning_rate': 4.9828898071158954e-05, 'epoch': 0.010266115730462952, 'step': 57000}
INFO:transformers.trainer:{'loss': 3.222957707166672, 'learning_rate': 4.9827397177046313e-05, 'epoch': 0.010356169377221398, 'step': 57500}
INFO:transformers.trainer:{'loss': 3.189102262020111, 'learning_rate': 4.982589628293367e-05, 'epoch': 0.010446223023979845, 'step': 58000}
INFO:transformers.trainer:{'loss': 3.2487018636465073, 'learning_rate': 4.982439538882103e-05, 'epoch': 0.010536276670738292, 'step': 58500}
INFO:transformers.trainer:{'loss': 3.12731941986084, 'learning_rate': 4.982289449470839e-05, 'epoch': 0.010626330317496739, 'step': 59000}
INFO:transformers.trainer:{'loss': 3.1794783020019532, 'learning_rate': 4.982139360059575e-05, 'epoch': 0.010716383964255186, 'step': 59500}
INFO:transformers.trainer:{'loss': 3.141674582362175, 'learning_rate': 4.981989270648311e-05, 'epoch': 0.010806437611013632, 'step': 60000}
INFO:transformers.trainer:{'loss': 3.112556275844574, 'learning_rate': 4.981839181237047e-05, 'epoch': 0.01089649125777208, 'step': 60500}
INFO:transformers.trainer:{'loss': 3.200834043741226, 'learning_rate': 4.981689091825783e-05, 'epoch': 0.010986544904530528, 'step': 61000}
INFO:transformers.trainer:{'loss': 3.1697319457530977, 'learning_rate': 4.9815390024145186e-05, 'epoch': 0.011076598551288975, 'step': 61500}
INFO:transformers.trainer:{'loss': 3.184281044006348, 'learning_rate': 4.9813889130032545e-05, 'epoch': 0.011166652198047421, 'step': 62000}
INFO:transformers.trainer:{'loss': 3.1507071726322176, 'learning_rate': 4.9812388235919904e-05, 'epoch': 0.011256705844805868, 'step': 62500}
INFO:transformers.trainer:{'loss': 3.222219972848892, 'learning_rate': 4.981088734180726e-05, 'epoch': 0.011346759491564315, 'step': 63000}
INFO:transformers.trainer:{'loss': 3.164399649620056, 'learning_rate': 4.980938644769462e-05, 'epoch': 0.011436813138322762, 'step': 63500}
INFO:transformers.trainer:{'loss': 3.2281552805900575, 'learning_rate': 4.980788555358198e-05, 'epoch': 0.011526866785081209, 'step': 64000}
INFO:transformers.trainer:{'loss': 3.205109954595566, 'learning_rate': 4.980638465946934e-05, 'epoch': 0.011616920431839655, 'step': 64500}
INFO:transformers.trainer:{'loss': 3.1509402997493745, 'learning_rate': 4.98048837653567e-05, 'epoch': 0.011706974078598102, 'step': 65000}
INFO:transformers.trainer:{'loss': 3.2114052283763885, 'learning_rate': 4.980338287124406e-05, 'epoch': 0.011797027725356549, 'step': 65500}
INFO:transformers.trainer:{'loss': 3.2033502950668336, 'learning_rate': 4.980188197713142e-05, 'epoch': 0.011887081372114996, 'step': 66000}
INFO:transformers.trainer:{'loss': 3.2308183376789095, 'learning_rate': 4.9800381083018776e-05, 'epoch': 0.011977135018873443, 'step': 66500}
INFO:transformers.trainer:{'loss': 3.1749552998542785, 'learning_rate': 4.9798880188906135e-05, 'epoch': 0.01206718866563189, 'step': 67000}
INFO:transformers.trainer:{'loss': 3.1485341626405714, 'learning_rate': 4.9797379294793494e-05, 'epoch': 0.012157242312390338, 'step': 67500}
INFO:transformers.trainer:{'loss': 3.1424073312282563, 'learning_rate': 4.9795878400680854e-05, 'epoch': 0.012247295959148785, 'step': 68000}
INFO:transformers.trainer:{'loss': 3.165055952310562, 'learning_rate': 4.979437750656821e-05, 'epoch': 0.012337349605907232, 'step': 68500}
INFO:transformers.trainer:{'loss': 3.1914518694877625, 'learning_rate': 4.979287661245557e-05, 'epoch': 0.012427403252665678, 'step': 69000}
INFO:transformers.trainer:{'loss': 3.1803899059295655, 'learning_rate': 4.979137571834294e-05, 'epoch': 0.012517456899424125, 'step': 69500}
INFO:transformers.trainer:{'loss': 3.143355499982834, 'learning_rate': 4.978987482423029e-05, 'epoch': 0.012607510546182572, 'step': 70000}
INFO:transformers.trainer:{'loss': 3.1572066054344177, 'learning_rate': 4.9788373930117656e-05, 'epoch': 0.012697564192941019, 'step': 70500}
INFO:transformers.trainer:{'loss': 3.1177647960186006, 'learning_rate': 4.978687303600501e-05, 'epoch': 0.012787617839699466, 'step': 71000}
INFO:transformers.trainer:{'loss': 3.1738163974285127, 'learning_rate': 4.9785372141892374e-05, 'epoch': 0.012877671486457912, 'step': 71500}
INFO:transformers.trainer:{'loss': 3.2341812243461607, 'learning_rate': 4.9783871247779726e-05, 'epoch': 0.01296772513321636, 'step': 72000}
INFO:transformers.trainer:{'loss': 3.181746284723282, 'learning_rate': 4.978237035366709e-05, 'epoch': 0.013057778779974806, 'step': 72500}
INFO:transformers.trainer:{'loss': 3.1741999871730804, 'learning_rate': 4.9780869459554444e-05, 'epoch': 0.013147832426733253, 'step': 73000}
INFO:transformers.trainer:{'loss': 3.1732149624824526, 'learning_rate': 4.977936856544181e-05, 'epoch': 0.0132378860734917, 'step': 73500}
INFO:transformers.trainer:{'loss': 3.1499436166286467, 'learning_rate': 4.977786767132916e-05, 'epoch': 0.013327939720250148, 'step': 74000}
INFO:transformers.trainer:{'loss': 3.1841156809329987, 'learning_rate': 4.977636677721653e-05, 'epoch': 0.013417993367008595, 'step': 74500}
INFO:transformers.trainer:{'loss': 3.2043210899829866, 'learning_rate': 4.977486588310388e-05, 'epoch': 0.013508047013767042, 'step': 75000}
INFO:transformers.trainer:{'loss': 3.178840150356293, 'learning_rate': 4.9773364988991246e-05, 'epoch': 0.013598100660525489, 'step': 75500}
INFO:transformers.trainer:{'loss': 3.1309373257160185, 'learning_rate': 4.97718640948786e-05, 'epoch': 0.013688154307283935, 'step': 76000}
INFO:transformers.trainer:{'loss': 3.1787920038700106, 'learning_rate': 4.9770363200765964e-05, 'epoch': 0.013778207954042382, 'step': 76500}
INFO:transformers.trainer:{'loss': 3.182874852657318, 'learning_rate': 4.976886230665332e-05, 'epoch': 0.013868261600800829, 'step': 77000}
INFO:transformers.trainer:{'loss': 3.1581714196205137, 'learning_rate': 4.976736141254068e-05, 'epoch': 0.013958315247559276, 'step': 77500}
INFO:transformers.trainer:{'loss': 3.2079005761146546, 'learning_rate': 4.976586051842804e-05, 'epoch': 0.014048368894317723, 'step': 78000}
INFO:transformers.trainer:{'loss': 3.1579328780174256, 'learning_rate': 4.97643596243154e-05, 'epoch': 0.01413842254107617, 'step': 78500}
INFO:transformers.trainer:{'loss': 3.2185723111629487, 'learning_rate': 4.976285873020276e-05, 'epoch': 0.014228476187834616, 'step': 79000}
INFO:transformers.trainer:{'loss': 3.212356117248535, 'learning_rate': 4.976135783609012e-05, 'epoch': 0.014318529834593063, 'step': 79500}
INFO:transformers.trainer:{'loss': 3.172831285238266, 'learning_rate': 4.975985694197748e-05, 'epoch': 0.014408583481351512, 'step': 80000}
INFO:transformers.trainer:{'loss': 3.1824027247428894, 'learning_rate': 4.9758356047864837e-05, 'epoch': 0.014498637128109958, 'step': 80500}
INFO:transformers.trainer:{'loss': 3.1771203866004942, 'learning_rate': 4.9756855153752196e-05, 'epoch': 0.014588690774868405, 'step': 81000}
INFO:transformers.trainer:{'loss': 3.192067638874054, 'learning_rate': 4.9755354259639555e-05, 'epoch': 0.014678744421626852, 'step': 81500}
INFO:transformers.trainer:{'loss': 3.205775882720947, 'learning_rate': 4.9753853365526914e-05, 'epoch': 0.014768798068385299, 'step': 82000}
INFO:transformers.trainer:{'loss': 3.1764403178691865, 'learning_rate': 4.975235247141427e-05, 'epoch': 0.014858851715143746, 'step': 82500}
INFO:transformers.trainer:{'loss': 3.162042191505432, 'learning_rate': 4.975085157730163e-05, 'epoch': 0.014948905361902192, 'step': 83000}
INFO:transformers.trainer:{'loss': 3.1949924552440643, 'learning_rate': 4.9749350683189e-05, 'epoch': 0.01503895900866064, 'step': 83500}
INFO:transformers.trainer:{'loss': 3.1869075877666475, 'learning_rate': 4.974784978907635e-05, 'epoch': 0.015129012655419086, 'step': 84000}
INFO:transformers.trainer:{'loss': 3.188184980630875, 'learning_rate': 4.9746348894963716e-05, 'epoch': 0.015219066302177533, 'step': 84500}
INFO:transformers.trainer:{'loss': 3.1650379123687746, 'learning_rate': 4.974484800085107e-05, 'epoch': 0.01530911994893598, 'step': 85000}
INFO:transformers.trainer:{'loss': 3.187475878715515, 'learning_rate': 4.9743347106738434e-05, 'epoch': 0.015399173595694426, 'step': 85500}
INFO:transformers.trainer:{'loss': 3.177048356294632, 'learning_rate': 4.9741846212625786e-05, 'epoch': 0.015489227242452873, 'step': 86000}
INFO:transformers.trainer:{'loss': 3.1950650317668914, 'learning_rate': 4.9740345318513145e-05, 'epoch': 0.015579280889211322, 'step': 86500}
INFO:transformers.trainer:{'loss': 3.210574945449829, 'learning_rate': 4.9738844424400504e-05, 'epoch': 0.01566933453596977, 'step': 87000}
INFO:transformers.trainer:{'loss': 3.153276698231697, 'learning_rate': 4.973734353028786e-05, 'epoch': 0.015759388182728214, 'step': 87500}
INFO:transformers.trainer:{'loss': 3.2014977482557296, 'learning_rate': 4.973584263617522e-05, 'epoch': 0.015849441829486662, 'step': 88000}
INFO:transformers.trainer:{'loss': 3.2056946136951447, 'learning_rate': 4.973434174206258e-05, 'epoch': 0.015939495476245107, 'step': 88500}
INFO:transformers.trainer:{'loss': 3.250838123559952, 'learning_rate': 4.973284084794994e-05, 'epoch': 0.016029549123003556, 'step': 89000}
INFO:transformers.trainer:{'loss': 3.172953802347183, 'learning_rate': 4.97313399538373e-05, 'epoch': 0.016119602769762, 'step': 89500}
INFO:transformers.trainer:{'loss': 3.2308556334972383, 'learning_rate': 4.972983905972466e-05, 'epoch': 0.01620965641652045, 'step': 90000}
INFO:transformers.trainer:{'loss': 3.1597099418640138, 'learning_rate': 4.972833816561202e-05, 'epoch': 0.016299710063278898, 'step': 90500}
INFO:transformers.trainer:{'loss': 3.20838308763504, 'learning_rate': 4.972683727149938e-05, 'epoch': 0.016389763710037343, 'step': 91000}
INFO:transformers.trainer:{'loss': 3.177692432165146, 'learning_rate': 4.9725336377386736e-05, 'epoch': 0.01647981735679579, 'step': 91500}
INFO:transformers.trainer:{'loss': 3.256329704284668, 'learning_rate': 4.97238354832741e-05, 'epoch': 0.016569871003554237, 'step': 92000}
INFO:transformers.trainer:{'loss': 3.1512613224983217, 'learning_rate': 4.9722334589161454e-05, 'epoch': 0.016659924650312685, 'step': 92500}
INFO:transformers.trainer:{'loss': 3.2006961841583252, 'learning_rate': 4.972083369504882e-05, 'epoch': 0.01674997829707113, 'step': 93000}
INFO:transformers.trainer:{'loss': 3.177525237560272, 'learning_rate': 4.971933280093617e-05, 'epoch': 0.01684003194382958, 'step': 93500}
INFO:transformers.trainer:{'loss': 3.2050752267837526, 'learning_rate': 4.971783190682354e-05, 'epoch': 0.016930085590588024, 'step': 94000}
INFO:transformers.trainer:{'loss': 3.1863529996871947, 'learning_rate': 4.971633101271089e-05, 'epoch': 0.017020139237346472, 'step': 94500}
INFO:transformers.trainer:{'loss': 3.155743281364441, 'learning_rate': 4.9714830118598256e-05, 'epoch': 0.017110192884104918, 'step': 95000}
INFO:transformers.trainer:{'loss': 3.2134942593574523, 'learning_rate': 4.971332922448561e-05, 'epoch': 0.017200246530863366, 'step': 95500}
INFO:transformers.trainer:{'loss': 3.202291006088257, 'learning_rate': 4.9711828330372974e-05, 'epoch': 0.017290300177621815, 'step': 96000}
INFO:transformers.trainer:{'loss': 3.155847360610962, 'learning_rate': 4.9710327436260326e-05, 'epoch': 0.01738035382438026, 'step': 96500}
INFO:transformers.trainer:{'loss': 3.219891526699066, 'learning_rate': 4.970882654214769e-05, 'epoch': 0.017470407471138708, 'step': 97000}
INFO:transformers.trainer:{'loss': 3.2035841612815856, 'learning_rate': 4.970732564803505e-05, 'epoch': 0.017560461117897153, 'step': 97500}
INFO:transformers.trainer:{'loss': 3.2142273263931274, 'learning_rate': 4.970582475392241e-05, 'epoch': 0.017650514764655602, 'step': 98000}
INFO:transformers.trainer:{'loss': 3.1506408307552336, 'learning_rate': 4.970432385980977e-05, 'epoch': 0.017740568411414047, 'step': 98500}
INFO:transformers.trainer:{'loss': 3.1253135979175566, 'learning_rate': 4.970282296569713e-05, 'epoch': 0.017830622058172495, 'step': 99000}
INFO:transformers.trainer:{'loss': 3.2122891595363616, 'learning_rate': 4.970132207158449e-05, 'epoch': 0.01792067570493094, 'step': 99500}
INFO:transformers.trainer:{'loss': 3.143746717453003, 'learning_rate': 4.9699821177471846e-05, 'epoch': 0.01801072935168939, 'step': 100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-100000/pytorch_model.bin
INFO:transformers.trainer:{'loss': 3.2407921236753463, 'learning_rate': 4.9698320283359205e-05, 'epoch': 0.018100782998447834, 'step': 100500}
INFO:transformers.trainer:{'loss': 3.2344452080726622, 'learning_rate': 4.9696819389246564e-05, 'epoch': 0.018190836645206283, 'step': 101000}
INFO:transformers.trainer:{'loss': 3.196005230665207, 'learning_rate': 4.9695318495133923e-05, 'epoch': 0.018280890291964728, 'step': 101500}
INFO:transformers.trainer:{'loss': 3.168895712852478, 'learning_rate': 4.969381760102128e-05, 'epoch': 0.018370943938723176, 'step': 102000}
INFO:transformers.trainer:{'loss': 3.232661144256592, 'learning_rate': 4.969231670690864e-05, 'epoch': 0.018460997585481625, 'step': 102500}
INFO:transformers.trainer:{'loss': 3.220767506837845, 'learning_rate': 4.9690815812796e-05, 'epoch': 0.01855105123224007, 'step': 103000}
INFO:transformers.trainer:{'loss': 3.2186828002929686, 'learning_rate': 4.968931491868336e-05, 'epoch': 0.01864110487899852, 'step': 103500}
INFO:transformers.trainer:{'loss': 3.24457980132103, 'learning_rate': 4.968781402457072e-05, 'epoch': 0.018731158525756963, 'step': 104000}
INFO:transformers.trainer:{'loss': 3.1913945865631104, 'learning_rate': 4.968631313045808e-05, 'epoch': 0.018821212172515412, 'step': 104500}
INFO:transformers.trainer:{'loss': 3.2350923404693606, 'learning_rate': 4.9684812236345444e-05, 'epoch': 0.018911265819273857, 'step': 105000}
INFO:transformers.trainer:{'loss': 3.2376854877471923, 'learning_rate': 4.9683311342232796e-05, 'epoch': 0.019001319466032306, 'step': 105500}
INFO:transformers.trainer:{'loss': 3.188351699590683, 'learning_rate': 4.968181044812016e-05, 'epoch': 0.01909137311279075, 'step': 106000}
INFO:transformers.trainer:{'loss': 3.1957636986970903, 'learning_rate': 4.9680309554007514e-05, 'epoch': 0.0191814267595492, 'step': 106500}
INFO:transformers.trainer:{'loss': 3.227014922380447, 'learning_rate': 4.967880865989488e-05, 'epoch': 0.019271480406307644, 'step': 107000}
INFO:transformers.trainer:{'loss': 3.2041173691749574, 'learning_rate': 4.967730776578223e-05, 'epoch': 0.019361534053066093, 'step': 107500}
INFO:transformers.trainer:{'loss': 3.1818008012771606, 'learning_rate': 4.96758068716696e-05, 'epoch': 0.019451587699824538, 'step': 108000}
INFO:transformers.trainer:{'loss': 3.1612828533649444, 'learning_rate': 4.967430597755695e-05, 'epoch': 0.019541641346582986, 'step': 108500}
INFO:transformers.trainer:{'loss': 3.1728617930412293, 'learning_rate': 4.9672805083444316e-05, 'epoch': 0.019631694993341435, 'step': 109000}
INFO:transformers.trainer:{'loss': 3.2469845385551452, 'learning_rate': 4.967130418933167e-05, 'epoch': 0.01972174864009988, 'step': 109500}
INFO:transformers.trainer:{'loss': 3.26371062207222, 'learning_rate': 4.966980329521903e-05, 'epoch': 0.01981180228685833, 'step': 110000}
INFO:transformers.trainer:{'loss': 3.247098460674286, 'learning_rate': 4.9668302401106386e-05, 'epoch': 0.019901855933616774, 'step': 110500}
INFO:transformers.trainer:{'loss': 3.1864829692840577, 'learning_rate': 4.9666801506993745e-05, 'epoch': 0.019991909580375222, 'step': 111000}
INFO:transformers.trainer:{'loss': 3.2173273787498475, 'learning_rate': 4.966530061288111e-05, 'epoch': 0.020081963227133667, 'step': 111500}
INFO:transformers.trainer:{'loss': 3.183872189640999, 'learning_rate': 4.9663799718768463e-05, 'epoch': 0.020172016873892116, 'step': 112000}
INFO:transformers.trainer:{'loss': 3.2185577685832976, 'learning_rate': 4.966229882465583e-05, 'epoch': 0.02026207052065056, 'step': 112500}
INFO:transformers.trainer:{'loss': 3.2165862417221067, 'learning_rate': 4.966079793054318e-05, 'epoch': 0.02035212416740901, 'step': 113000}
INFO:transformers.trainer:{'loss': 3.2018107063770294, 'learning_rate': 4.965929703643055e-05, 'epoch': 0.020442177814167455, 'step': 113500}
INFO:transformers.trainer:{'loss': 3.1829239664077758, 'learning_rate': 4.96577961423179e-05, 'epoch': 0.020532231460925903, 'step': 114000}
INFO:transformers.trainer:{'loss': 3.211671224117279, 'learning_rate': 4.9656295248205266e-05, 'epoch': 0.020622285107684348, 'step': 114500}
INFO:transformers.trainer:{'loss': 3.255720121383667, 'learning_rate': 4.965479435409262e-05, 'epoch': 0.020712338754442797, 'step': 115000}
INFO:transformers.trainer:{'loss': 3.250017701625824, 'learning_rate': 4.9653293459979984e-05, 'epoch': 0.020802392401201245, 'step': 115500}
INFO:transformers.trainer:{'loss': 3.178082291603088, 'learning_rate': 4.9651792565867336e-05, 'epoch': 0.02089244604795969, 'step': 116000}
INFO:transformers.trainer:{'loss': 3.1883542890548706, 'learning_rate': 4.96502916717547e-05, 'epoch': 0.02098249969471814, 'step': 116500}
INFO:transformers.trainer:{'loss': 3.2663235738277434, 'learning_rate': 4.9648790777642054e-05, 'epoch': 0.021072553341476584, 'step': 117000}
INFO:transformers.trainer:{'loss': 3.1883179924488068, 'learning_rate': 4.964728988352942e-05, 'epoch': 0.021162606988235032, 'step': 117500}
INFO:transformers.trainer:{'loss': 3.1879266974925993, 'learning_rate': 4.964578898941678e-05, 'epoch': 0.021252660634993478, 'step': 118000}
INFO:transformers.trainer:{'loss': 3.1499102745056153, 'learning_rate': 4.964428809530414e-05, 'epoch': 0.021342714281751926, 'step': 118500}
INFO:transformers.trainer:{'loss': 3.246043623805046, 'learning_rate': 4.96427872011915e-05, 'epoch': 0.02143276792851037, 'step': 119000}
INFO:transformers.trainer:{'loss': 3.2398960493803024, 'learning_rate': 4.9641286307078856e-05, 'epoch': 0.02152282157526882, 'step': 119500}
INFO:transformers.trainer:{'loss': 3.236745549440384, 'learning_rate': 4.9639785412966215e-05, 'epoch': 0.021612875222027265, 'step': 120000}
INFO:transformers.trainer:{'loss': 3.1896910393238067, 'learning_rate': 4.9638284518853574e-05, 'epoch': 0.021702928868785713, 'step': 120500}
INFO:transformers.trainer:{'loss': 3.2372988078594207, 'learning_rate': 4.963678362474093e-05, 'epoch': 0.02179298251554416, 'step': 121000}
INFO:transformers.trainer:{'loss': 3.22648051571846, 'learning_rate': 4.963528273062829e-05, 'epoch': 0.021883036162302607, 'step': 121500}
INFO:transformers.trainer:{'loss': 3.228527297973633, 'learning_rate': 4.963378183651565e-05, 'epoch': 0.021973089809061055, 'step': 122000}
INFO:transformers.trainer:{'loss': 3.1551455022096633, 'learning_rate': 4.963228094240301e-05, 'epoch': 0.0220631434558195, 'step': 122500}
INFO:transformers.trainer:{'loss': 3.2557558720111848, 'learning_rate': 4.963078004829037e-05, 'epoch': 0.02215319710257795, 'step': 123000}
INFO:transformers.trainer:{'loss': 3.1912496366500855, 'learning_rate': 4.962927915417773e-05, 'epoch': 0.022243250749336394, 'step': 123500}
INFO:transformers.trainer:{'loss': 3.2136195785999297, 'learning_rate': 4.962777826006509e-05, 'epoch': 0.022333304396094843, 'step': 124000}
INFO:transformers.trainer:{'loss': 3.1789823982715606, 'learning_rate': 4.9626277365952447e-05, 'epoch': 0.022423358042853288, 'step': 124500}
INFO:transformers.trainer:{'loss': 3.157321370601654, 'learning_rate': 4.9624776471839806e-05, 'epoch': 0.022513411689611736, 'step': 125000}
INFO:transformers.trainer:{'loss': 3.2052685253620146, 'learning_rate': 4.962327557772717e-05, 'epoch': 0.02260346533637018, 'step': 125500}
INFO:transformers.trainer:{'loss': 3.213848427057266, 'learning_rate': 4.9621774683614524e-05, 'epoch': 0.02269351898312863, 'step': 126000}
INFO:transformers.trainer:{'loss': 3.208968856573105, 'learning_rate': 4.962027378950189e-05, 'epoch': 0.022783572629887075, 'step': 126500}
INFO:transformers.trainer:{'loss': 3.303312956571579, 'learning_rate': 4.961877289538924e-05, 'epoch': 0.022873626276645524, 'step': 127000}
INFO:transformers.trainer:{'loss': 3.1933840408325196, 'learning_rate': 4.961727200127661e-05, 'epoch': 0.02296367992340397, 'step': 127500}
INFO:transformers.trainer:{'loss': 3.2616047185659407, 'learning_rate': 4.961577110716396e-05, 'epoch': 0.023053733570162417, 'step': 128000}
INFO:transformers.trainer:{'loss': 3.2773560860157014, 'learning_rate': 4.9614270213051326e-05, 'epoch': 0.023143787216920866, 'step': 128500}
INFO:transformers.trainer:{'loss': 3.2134876737594604, 'learning_rate': 4.961276931893868e-05, 'epoch': 0.02323384086367931, 'step': 129000}
INFO:transformers.trainer:{'loss': 3.2070698721408846, 'learning_rate': 4.9611268424826044e-05, 'epoch': 0.02332389451043776, 'step': 129500}
INFO:transformers.trainer:{'loss': 3.1957806859016418, 'learning_rate': 4.9609767530713396e-05, 'epoch': 0.023413948157196204, 'step': 130000}
INFO:transformers.trainer:{'loss': 3.2508052988052367, 'learning_rate': 4.960826663660076e-05, 'epoch': 0.023504001803954653, 'step': 130500}
INFO:transformers.trainer:{'loss': 3.226056614160538, 'learning_rate': 4.9606765742488114e-05, 'epoch': 0.023594055450713098, 'step': 131000}
INFO:transformers.trainer:{'loss': 3.197472583293915, 'learning_rate': 4.960526484837548e-05, 'epoch': 0.023684109097471547, 'step': 131500}
INFO:transformers.trainer:{'loss': 3.210610348701477, 'learning_rate': 4.960376395426284e-05, 'epoch': 0.02377416274422999, 'step': 132000}
INFO:transformers.trainer:{'loss': 3.207705124616623, 'learning_rate': 4.96022630601502e-05, 'epoch': 0.02386421639098844, 'step': 132500}
INFO:transformers.trainer:{'loss': 3.222534717321396, 'learning_rate': 4.960076216603756e-05, 'epoch': 0.023954270037746885, 'step': 133000}
INFO:transformers.trainer:{'loss': 3.2518151671886444, 'learning_rate': 4.959926127192491e-05, 'epoch': 0.024044323684505334, 'step': 133500}
INFO:transformers.trainer:{'loss': 3.1775397391319276, 'learning_rate': 4.9597760377812275e-05, 'epoch': 0.02413437733126378, 'step': 134000}
INFO:transformers.trainer:{'loss': 3.1904769062995912, 'learning_rate': 4.959625948369963e-05, 'epoch': 0.024224430978022227, 'step': 134500}
INFO:transformers.trainer:{'loss': 3.257363906502724, 'learning_rate': 4.959475858958699e-05, 'epoch': 0.024314484624780676, 'step': 135000}
INFO:transformers.trainer:{'loss': 3.2071034967899323, 'learning_rate': 4.9593257695474346e-05, 'epoch': 0.02440453827153912, 'step': 135500}
INFO:transformers.trainer:{'loss': 3.214116495847702, 'learning_rate': 4.959175680136171e-05, 'epoch': 0.02449459191829757, 'step': 136000}
INFO:transformers.trainer:{'loss': 3.191928649187088, 'learning_rate': 4.9590255907249064e-05, 'epoch': 0.024584645565056015, 'step': 136500}
INFO:transformers.trainer:{'loss': 3.1786227197647094, 'learning_rate': 4.958875501313643e-05, 'epoch': 0.024674699211814463, 'step': 137000}
INFO:transformers.trainer:{'loss': 3.250718139886856, 'learning_rate': 4.958725411902378e-05, 'epoch': 0.024764752858572908, 'step': 137500}
INFO:transformers.trainer:{'loss': 3.2645171523094176, 'learning_rate': 4.958575322491115e-05, 'epoch': 0.024854806505331357, 'step': 138000}
INFO:transformers.trainer:{'loss': 3.2373578572273254, 'learning_rate': 4.95842523307985e-05, 'epoch': 0.024944860152089802, 'step': 138500}
INFO:transformers.trainer:{'loss': 3.188869268655777, 'learning_rate': 4.9582751436685866e-05, 'epoch': 0.02503491379884825, 'step': 139000}
INFO:transformers.trainer:{'loss': 3.216229967355728, 'learning_rate': 4.9581250542573225e-05, 'epoch': 0.025124967445606695, 'step': 139500}
INFO:transformers.trainer:{'loss': 3.2700550632476806, 'learning_rate': 4.9579749648460584e-05, 'epoch': 0.025215021092365144, 'step': 140000}
INFO:transformers.trainer:{'loss': 3.252418537378311, 'learning_rate': 4.957824875434794e-05, 'epoch': 0.02530507473912359, 'step': 140500}
INFO:transformers.trainer:{'loss': 3.259356495141983, 'learning_rate': 4.95767478602353e-05, 'epoch': 0.025395128385882038, 'step': 141000}
INFO:transformers.trainer:{'loss': 3.2476717250347136, 'learning_rate': 4.957524696612266e-05, 'epoch': 0.025485182032640486, 'step': 141500}
INFO:transformers.trainer:{'loss': 3.2846256766319275, 'learning_rate': 4.957374607201002e-05, 'epoch': 0.02557523567939893, 'step': 142000}
INFO:transformers.trainer:{'loss': 3.2450745854377745, 'learning_rate': 4.957224517789738e-05, 'epoch': 0.02566528932615738, 'step': 142500}
INFO:transformers.trainer:{'loss': 3.190400587797165, 'learning_rate': 4.957074428378474e-05, 'epoch': 0.025755342972915825, 'step': 143000}
INFO:transformers.trainer:{'loss': 3.225420836210251, 'learning_rate': 4.95692433896721e-05, 'epoch': 0.025845396619674273, 'step': 143500}
INFO:transformers.trainer:{'loss': 3.2121005342006685, 'learning_rate': 4.9567742495559456e-05, 'epoch': 0.02593545026643272, 'step': 144000}
INFO:transformers.trainer:{'loss': 3.230302127122879, 'learning_rate': 4.9566241601446815e-05, 'epoch': 0.026025503913191167, 'step': 144500}
INFO:transformers.trainer:{'loss': 3.223518396139145, 'learning_rate': 4.9564740707334174e-05, 'epoch': 0.026115557559949612, 'step': 145000}
INFO:transformers.trainer:{'loss': 3.2538245084285737, 'learning_rate': 4.9563239813221533e-05, 'epoch': 0.02620561120670806, 'step': 145500}
INFO:transformers.trainer:{'loss': 3.215776997089386, 'learning_rate': 4.95617389191089e-05, 'epoch': 0.026295664853466506, 'step': 146000}
INFO:transformers.trainer:{'loss': 3.2172598965167998, 'learning_rate': 4.956023802499625e-05, 'epoch': 0.026385718500224954, 'step': 146500}
INFO:transformers.trainer:{'loss': 3.185611044406891, 'learning_rate': 4.955873713088362e-05, 'epoch': 0.0264757721469834, 'step': 147000}
INFO:transformers.trainer:{'loss': 3.223315552473068, 'learning_rate': 4.955723623677097e-05, 'epoch': 0.026565825793741848, 'step': 147500}
INFO:transformers.trainer:{'loss': 3.2774759600162504, 'learning_rate': 4.9555735342658335e-05, 'epoch': 0.026655879440500296, 'step': 148000}
INFO:transformers.trainer:{'loss': 3.2176830365657807, 'learning_rate': 4.955423444854569e-05, 'epoch': 0.02674593308725874, 'step': 148500}
INFO:transformers.trainer:{'loss': 3.235912705898285, 'learning_rate': 4.9552733554433054e-05, 'epoch': 0.02683598673401719, 'step': 149000}
INFO:transformers.trainer:{'loss': 3.191988380908966, 'learning_rate': 4.9551232660320406e-05, 'epoch': 0.026926040380775635, 'step': 149500}
INFO:transformers.trainer:{'loss': 3.270119669675827, 'learning_rate': 4.954973176620777e-05, 'epoch': 0.027016094027534084, 'step': 150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-50000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.201105288028717, 'learning_rate': 4.9548230872095124e-05, 'epoch': 0.02710614767429253, 'step': 150500}
INFO:transformers.trainer:{'loss': 3.2742179613113405, 'learning_rate': 4.954672997798249e-05, 'epoch': 0.027196201321050977, 'step': 151000}
INFO:transformers.trainer:{'loss': 3.2527851605415345, 'learning_rate': 4.954522908386984e-05, 'epoch': 0.027286254967809422, 'step': 151500}
INFO:transformers.trainer:{'loss': 3.233237999677658, 'learning_rate': 4.954372818975721e-05, 'epoch': 0.02737630861456787, 'step': 152000}
INFO:transformers.trainer:{'loss': 3.2485608448982237, 'learning_rate': 4.954222729564456e-05, 'epoch': 0.027466362261326316, 'step': 152500}
INFO:transformers.trainer:{'loss': 3.2578403637409212, 'learning_rate': 4.9540726401531926e-05, 'epoch': 0.027556415908084764, 'step': 153000}
INFO:transformers.trainer:{'loss': 3.202001260280609, 'learning_rate': 4.9539225507419285e-05, 'epoch': 0.02764646955484321, 'step': 153500}
INFO:transformers.trainer:{'loss': 3.2147551560401917, 'learning_rate': 4.9537724613306644e-05, 'epoch': 0.027736523201601658, 'step': 154000}
INFO:transformers.trainer:{'loss': 3.250840440750122, 'learning_rate': 4.9536223719194e-05, 'epoch': 0.027826576848360107, 'step': 154500}
INFO:transformers.trainer:{'loss': 3.2441649878025056, 'learning_rate': 4.953472282508136e-05, 'epoch': 0.02791663049511855, 'step': 155000}
INFO:transformers.trainer:{'loss': 3.211321803331375, 'learning_rate': 4.953322193096872e-05, 'epoch': 0.028006684141877, 'step': 155500}
INFO:transformers.trainer:{'loss': 3.223121333837509, 'learning_rate': 4.953172103685608e-05, 'epoch': 0.028096737788635445, 'step': 156000}
INFO:transformers.trainer:{'loss': 3.1999526801109313, 'learning_rate': 4.953022014274344e-05, 'epoch': 0.028186791435393894, 'step': 156500}
INFO:transformers.trainer:{'loss': 3.251127564191818, 'learning_rate': 4.95287192486308e-05, 'epoch': 0.02827684508215234, 'step': 157000}
INFO:transformers.trainer:{'loss': 3.236944807052612, 'learning_rate': 4.952721835451816e-05, 'epoch': 0.028366898728910787, 'step': 157500}
INFO:transformers.trainer:{'loss': 3.2736521270275114, 'learning_rate': 4.952571746040551e-05, 'epoch': 0.028456952375669232, 'step': 158000}
INFO:transformers.trainer:{'loss': 3.2083149709701537, 'learning_rate': 4.9524216566292875e-05, 'epoch': 0.02854700602242768, 'step': 158500}
INFO:transformers.trainer:{'loss': 3.26135290646553, 'learning_rate': 4.952271567218023e-05, 'epoch': 0.028637059669186126, 'step': 159000}
INFO:transformers.trainer:{'loss': 3.2436819558143615, 'learning_rate': 4.9521214778067594e-05, 'epoch': 0.028727113315944575, 'step': 159500}
INFO:transformers.trainer:{'loss': 3.2493006048202515, 'learning_rate': 4.951971388395495e-05, 'epoch': 0.028817166962703023, 'step': 160000}
INFO:transformers.trainer:{'loss': 3.22844562125206, 'learning_rate': 4.951821298984231e-05, 'epoch': 0.028907220609461468, 'step': 160500}
INFO:transformers.trainer:{'loss': 3.289090029001236, 'learning_rate': 4.951671209572967e-05, 'epoch': 0.028997274256219917, 'step': 161000}
INFO:transformers.trainer:{'loss': 3.2191621317863466, 'learning_rate': 4.951521120161703e-05, 'epoch': 0.029087327902978362, 'step': 161500}
INFO:transformers.trainer:{'loss': 3.185481512069702, 'learning_rate': 4.951371030750439e-05, 'epoch': 0.02917738154973681, 'step': 162000}
INFO:transformers.trainer:{'loss': 3.3396182615756986, 'learning_rate': 4.951220941339175e-05, 'epoch': 0.029267435196495255, 'step': 162500}
INFO:transformers.trainer:{'loss': 3.232123199224472, 'learning_rate': 4.951070851927911e-05, 'epoch': 0.029357488843253704, 'step': 163000}
INFO:transformers.trainer:{'loss': 3.239202623605728, 'learning_rate': 4.9509207625166466e-05, 'epoch': 0.02944754249001215, 'step': 163500}
INFO:transformers.trainer:{'loss': 3.2274096546173094, 'learning_rate': 4.9507706731053825e-05, 'epoch': 0.029537596136770598, 'step': 164000}
INFO:transformers.trainer:{'loss': 3.303912320137024, 'learning_rate': 4.9506205836941184e-05, 'epoch': 0.029627649783529043, 'step': 164500}
INFO:transformers.trainer:{'loss': 3.2667568485736846, 'learning_rate': 4.950470494282854e-05, 'epoch': 0.02971770343028749, 'step': 165000}
INFO:transformers.trainer:{'loss': 3.2387934703826904, 'learning_rate': 4.95032040487159e-05, 'epoch': 0.029807757077045936, 'step': 165500}
INFO:transformers.trainer:{'loss': 3.236718361854553, 'learning_rate': 4.950170315460326e-05, 'epoch': 0.029897810723804385, 'step': 166000}
INFO:transformers.trainer:{'loss': 3.237357648253441, 'learning_rate': 4.950020226049063e-05, 'epoch': 0.029987864370562833, 'step': 166500}
INFO:transformers.trainer:{'loss': 3.240847364425659, 'learning_rate': 4.949870136637798e-05, 'epoch': 0.03007791801732128, 'step': 167000}
INFO:transformers.trainer:{'loss': 3.24824862074852, 'learning_rate': 4.9497200472265345e-05, 'epoch': 0.030167971664079727, 'step': 167500}
INFO:transformers.trainer:{'loss': 3.272438799262047, 'learning_rate': 4.94956995781527e-05, 'epoch': 0.030258025310838172, 'step': 168000}
INFO:transformers.trainer:{'loss': 3.252108754634857, 'learning_rate': 4.949419868404006e-05, 'epoch': 0.03034807895759662, 'step': 168500}
INFO:transformers.trainer:{'loss': 3.2160559742450716, 'learning_rate': 4.9492697789927416e-05, 'epoch': 0.030438132604355066, 'step': 169000}
INFO:transformers.trainer:{'loss': 3.2649803669452666, 'learning_rate': 4.949119689581478e-05, 'epoch': 0.030528186251113514, 'step': 169500}
INFO:transformers.trainer:{'loss': 3.3101624937057497, 'learning_rate': 4.9489696001702134e-05, 'epoch': 0.03061823989787196, 'step': 170000}
INFO:transformers.trainer:{'loss': 3.2599869186878205, 'learning_rate': 4.94881951075895e-05, 'epoch': 0.030708293544630408, 'step': 170500}
INFO:transformers.trainer:{'loss': 3.2863750140666963, 'learning_rate': 4.948669421347685e-05, 'epoch': 0.030798347191388853, 'step': 171000}
INFO:transformers.trainer:{'loss': 3.3014557769298554, 'learning_rate': 4.948519331936422e-05, 'epoch': 0.0308884008381473, 'step': 171500}
INFO:transformers.trainer:{'loss': 3.2208285579681397, 'learning_rate': 4.948369242525157e-05, 'epoch': 0.030978454484905747, 'step': 172000}
INFO:transformers.trainer:{'loss': 3.2662608730793, 'learning_rate': 4.9482191531138936e-05, 'epoch': 0.031068508131664195, 'step': 172500}
INFO:transformers.trainer:{'loss': 3.302480852007866, 'learning_rate': 4.948069063702629e-05, 'epoch': 0.031158561778422644, 'step': 173000}
INFO:transformers.trainer:{'loss': 3.2319847917556763, 'learning_rate': 4.9479189742913654e-05, 'epoch': 0.03124861542518109, 'step': 173500}
INFO:transformers.trainer:{'loss': 3.2838182084560392, 'learning_rate': 4.947768884880101e-05, 'epoch': 0.03133866907193954, 'step': 174000}
INFO:transformers.trainer:{'loss': 3.322018545150757, 'learning_rate': 4.947618795468837e-05, 'epoch': 0.03142872271869798, 'step': 174500}
INFO:transformers.trainer:{'loss': 3.265751107931137, 'learning_rate': 4.947468706057573e-05, 'epoch': 0.03151877636545643, 'step': 175000}
INFO:transformers.trainer:{'loss': 3.218543603897095, 'learning_rate': 4.947318616646309e-05, 'epoch': 0.03160883001221488, 'step': 175500}
INFO:transformers.trainer:{'loss': 3.2575137202739715, 'learning_rate': 4.947168527235045e-05, 'epoch': 0.031698883658973324, 'step': 176000}
INFO:transformers.trainer:{'loss': 3.2654023489952086, 'learning_rate': 4.947018437823781e-05, 'epoch': 0.03178893730573177, 'step': 176500}
INFO:transformers.trainer:{'loss': 3.3062546682357787, 'learning_rate': 4.946868348412517e-05, 'epoch': 0.031878990952490215, 'step': 177000}
INFO:transformers.trainer:{'loss': 3.2280281769037247, 'learning_rate': 4.9467182590012526e-05, 'epoch': 0.03196904459924867, 'step': 177500}
INFO:transformers.trainer:{'loss': 3.266912535190582, 'learning_rate': 4.9465681695899885e-05, 'epoch': 0.03205909824600711, 'step': 178000}
INFO:transformers.trainer:{'loss': 3.289998799920082, 'learning_rate': 4.9464180801787244e-05, 'epoch': 0.03214915189276556, 'step': 178500}
INFO:transformers.trainer:{'loss': 3.292469524383545, 'learning_rate': 4.94626799076746e-05, 'epoch': 0.032239205539524, 'step': 179000}
INFO:transformers.trainer:{'loss': 3.21700651884079, 'learning_rate': 4.946117901356196e-05, 'epoch': 0.032329259186282454, 'step': 179500}
INFO:transformers.trainer:{'loss': 3.2561058793067934, 'learning_rate': 4.945967811944932e-05, 'epoch': 0.0324193128330409, 'step': 180000}
INFO:transformers.trainer:{'loss': 3.3471465528011324, 'learning_rate': 4.945817722533668e-05, 'epoch': 0.032509366479799344, 'step': 180500}
INFO:transformers.trainer:{'loss': 3.236327339887619, 'learning_rate': 4.945667633122404e-05, 'epoch': 0.032599420126557796, 'step': 181000}
INFO:transformers.trainer:{'loss': 3.2621087143421175, 'learning_rate': 4.94551754371114e-05, 'epoch': 0.03268947377331624, 'step': 181500}
INFO:transformers.trainer:{'loss': 3.21004745054245, 'learning_rate': 4.945367454299876e-05, 'epoch': 0.032779527420074686, 'step': 182000}
INFO:transformers.trainer:{'loss': 3.2114732248783113, 'learning_rate': 4.945217364888612e-05, 'epoch': 0.03286958106683313, 'step': 182500}
INFO:transformers.trainer:{'loss': 3.279274850845337, 'learning_rate': 4.9450672754773476e-05, 'epoch': 0.03295963471359158, 'step': 183000}
INFO:transformers.trainer:{'loss': 3.293182894706726, 'learning_rate': 4.9449171860660835e-05, 'epoch': 0.03304968836035003, 'step': 183500}
INFO:transformers.trainer:{'loss': 3.25972655916214, 'learning_rate': 4.9447670966548194e-05, 'epoch': 0.03313974200710847, 'step': 184000}
INFO:transformers.trainer:{'loss': 3.280784420490265, 'learning_rate': 4.944617007243555e-05, 'epoch': 0.03322979565386692, 'step': 184500}
INFO:transformers.trainer:{'loss': 3.229234738588333, 'learning_rate': 4.944466917832291e-05, 'epoch': 0.03331984930062537, 'step': 185000}
INFO:transformers.trainer:{'loss': 3.2565147800445557, 'learning_rate': 4.944316828421027e-05, 'epoch': 0.033409902947383815, 'step': 185500}
INFO:transformers.trainer:{'loss': 3.2425606009960175, 'learning_rate': 4.944166739009763e-05, 'epoch': 0.03349995659414226, 'step': 186000}
INFO:transformers.trainer:{'loss': 3.3347971165180206, 'learning_rate': 4.944016649598499e-05, 'epoch': 0.03359001024090071, 'step': 186500}
INFO:transformers.trainer:{'loss': 3.3045360465049742, 'learning_rate': 4.943866560187235e-05, 'epoch': 0.03368006388765916, 'step': 187000}
INFO:transformers.trainer:{'loss': 3.2858284373283384, 'learning_rate': 4.943716470775971e-05, 'epoch': 0.0337701175344176, 'step': 187500}
INFO:transformers.trainer:{'loss': 3.259447739124298, 'learning_rate': 4.943566381364707e-05, 'epoch': 0.03386017118117605, 'step': 188000}
INFO:transformers.trainer:{'loss': 3.257450049877167, 'learning_rate': 4.9434162919534425e-05, 'epoch': 0.0339502248279345, 'step': 188500}
INFO:transformers.trainer:{'loss': 3.2880490455627442, 'learning_rate': 4.943266202542179e-05, 'epoch': 0.034040278474692945, 'step': 189000}
INFO:transformers.trainer:{'loss': 3.2838760840892793, 'learning_rate': 4.943116113130914e-05, 'epoch': 0.03413033212145139, 'step': 189500}
INFO:transformers.trainer:{'loss': 3.276864447593689, 'learning_rate': 4.942966023719651e-05, 'epoch': 0.034220385768209835, 'step': 190000}
INFO:transformers.trainer:{'loss': 3.2515236258506777, 'learning_rate': 4.942815934308386e-05, 'epoch': 0.03431043941496829, 'step': 190500}
INFO:transformers.trainer:{'loss': 3.270421149253845, 'learning_rate': 4.942665844897123e-05, 'epoch': 0.03440049306172673, 'step': 191000}
INFO:transformers.trainer:{'loss': 3.2793526601791383, 'learning_rate': 4.942515755485858e-05, 'epoch': 0.03449054670848518, 'step': 191500}
INFO:transformers.trainer:{'loss': 3.2599267410039903, 'learning_rate': 4.9423656660745945e-05, 'epoch': 0.03458060035524363, 'step': 192000}
INFO:transformers.trainer:{'loss': 3.2522671744823457, 'learning_rate': 4.94221557666333e-05, 'epoch': 0.034670654002002074, 'step': 192500}
INFO:transformers.trainer:{'loss': 3.291281069278717, 'learning_rate': 4.9420654872520663e-05, 'epoch': 0.03476070764876052, 'step': 193000}
INFO:transformers.trainer:{'loss': 3.2685454345941545, 'learning_rate': 4.9419153978408016e-05, 'epoch': 0.034850761295518964, 'step': 193500}
INFO:transformers.trainer:{'loss': 3.240209501743317, 'learning_rate': 4.941765308429538e-05, 'epoch': 0.034940814942277416, 'step': 194000}
INFO:transformers.trainer:{'loss': 3.2893891907930373, 'learning_rate': 4.941615219018274e-05, 'epoch': 0.03503086858903586, 'step': 194500}
INFO:transformers.trainer:{'loss': 3.3274082300662995, 'learning_rate': 4.94146512960701e-05, 'epoch': 0.03512092223579431, 'step': 195000}
INFO:transformers.trainer:{'loss': 3.308005462169647, 'learning_rate': 4.941315040195746e-05, 'epoch': 0.03521097588255275, 'step': 195500}
INFO:transformers.trainer:{'loss': 3.287966357946396, 'learning_rate': 4.941164950784482e-05, 'epoch': 0.035301029529311204, 'step': 196000}
INFO:transformers.trainer:{'loss': 3.2876372888088228, 'learning_rate': 4.941014861373218e-05, 'epoch': 0.03539108317606965, 'step': 196500}
INFO:transformers.trainer:{'loss': 3.2352410926818846, 'learning_rate': 4.9408647719619536e-05, 'epoch': 0.035481136822828094, 'step': 197000}
INFO:transformers.trainer:{'loss': 3.252606363296509, 'learning_rate': 4.9407146825506895e-05, 'epoch': 0.03557119046958654, 'step': 197500}
INFO:transformers.trainer:{'loss': 3.225321331501007, 'learning_rate': 4.9405645931394254e-05, 'epoch': 0.03566124411634499, 'step': 198000}
INFO:transformers.trainer:{'loss': 3.238731214761734, 'learning_rate': 4.940414503728161e-05, 'epoch': 0.035751297763103436, 'step': 198500}
INFO:transformers.trainer:{'loss': 3.2544715514183045, 'learning_rate': 4.940264414316897e-05, 'epoch': 0.03584135140986188, 'step': 199000}
INFO:transformers.trainer:{'loss': 3.2683243160247804, 'learning_rate': 4.940114324905633e-05, 'epoch': 0.03593140505662033, 'step': 199500}
INFO:transformers.trainer:{'loss': 3.289714264392853, 'learning_rate': 4.939964235494369e-05, 'epoch': 0.03602145870337878, 'step': 200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.339932447195053, 'learning_rate': 4.939814146083105e-05, 'epoch': 0.03611151235013722, 'step': 200500}
INFO:transformers.trainer:{'loss': 3.3114424996376037, 'learning_rate': 4.939664056671841e-05, 'epoch': 0.03620156599689567, 'step': 201000}
INFO:transformers.trainer:{'loss': 3.216118030548096, 'learning_rate': 4.939513967260577e-05, 'epoch': 0.03629161964365412, 'step': 201500}
INFO:transformers.trainer:{'loss': 3.2699067122936247, 'learning_rate': 4.9393638778493126e-05, 'epoch': 0.036381673290412565, 'step': 202000}
INFO:transformers.trainer:{'loss': 3.280535128355026, 'learning_rate': 4.9392137884380485e-05, 'epoch': 0.03647172693717101, 'step': 202500}
INFO:transformers.trainer:{'loss': 3.26854912340641, 'learning_rate': 4.9390636990267844e-05, 'epoch': 0.036561780583929455, 'step': 203000}
INFO:transformers.trainer:{'loss': 3.2585240259170534, 'learning_rate': 4.9389136096155204e-05, 'epoch': 0.03665183423068791, 'step': 203500}
INFO:transformers.trainer:{'loss': 3.270857266664505, 'learning_rate': 4.938763520204256e-05, 'epoch': 0.03674188787744635, 'step': 204000}
INFO:transformers.trainer:{'loss': 3.2750492017269135, 'learning_rate': 4.938613430792992e-05, 'epoch': 0.0368319415242048, 'step': 204500}
INFO:transformers.trainer:{'loss': 3.231371668100357, 'learning_rate': 4.938463341381728e-05, 'epoch': 0.03692199517096325, 'step': 205000}
INFO:transformers.trainer:{'loss': 3.262262333393097, 'learning_rate': 4.938313251970464e-05, 'epoch': 0.037012048817721695, 'step': 205500}
INFO:transformers.trainer:{'loss': 3.292320758461952, 'learning_rate': 4.9381631625592e-05, 'epoch': 0.03710210246448014, 'step': 206000}
INFO:transformers.trainer:{'loss': 3.2426175413131713, 'learning_rate': 4.938013073147936e-05, 'epoch': 0.037192156111238585, 'step': 206500}
INFO:transformers.trainer:{'loss': 3.361804389953613, 'learning_rate': 4.937862983736672e-05, 'epoch': 0.03728220975799704, 'step': 207000}
INFO:transformers.trainer:{'loss': 3.3068418210744857, 'learning_rate': 4.9377128943254076e-05, 'epoch': 0.03737226340475548, 'step': 207500}
INFO:transformers.trainer:{'loss': 3.3561353958845137, 'learning_rate': 4.9375628049141435e-05, 'epoch': 0.03746231705151393, 'step': 208000}
INFO:transformers.trainer:{'loss': 3.331606893777847, 'learning_rate': 4.93741271550288e-05, 'epoch': 0.03755237069827237, 'step': 208500}
INFO:transformers.trainer:{'loss': 3.309749294757843, 'learning_rate': 4.937262626091615e-05, 'epoch': 0.037642424345030824, 'step': 209000}
INFO:transformers.trainer:{'loss': 3.270546054124832, 'learning_rate': 4.937112536680352e-05, 'epoch': 0.03773247799178927, 'step': 209500}
INFO:transformers.trainer:{'loss': 3.314755166530609, 'learning_rate': 4.936962447269087e-05, 'epoch': 0.037822531638547714, 'step': 210000}
INFO:transformers.trainer:{'loss': 3.3410354406833647, 'learning_rate': 4.936812357857824e-05, 'epoch': 0.03791258528530616, 'step': 210500}
INFO:transformers.trainer:{'loss': 3.274879898071289, 'learning_rate': 4.936662268446559e-05, 'epoch': 0.03800263893206461, 'step': 211000}
INFO:transformers.trainer:{'loss': 3.3010200803279877, 'learning_rate': 4.9365121790352955e-05, 'epoch': 0.038092692578823056, 'step': 211500}
INFO:transformers.trainer:{'loss': 3.2393893110752106, 'learning_rate': 4.936362089624031e-05, 'epoch': 0.0381827462255815, 'step': 212000}
INFO:transformers.trainer:{'loss': 3.3175109400749205, 'learning_rate': 4.936212000212767e-05, 'epoch': 0.03827279987233995, 'step': 212500}
INFO:transformers.trainer:{'loss': 3.2850910658836363, 'learning_rate': 4.9360619108015025e-05, 'epoch': 0.0383628535190984, 'step': 213000}
INFO:transformers.trainer:{'loss': 3.303544041633606, 'learning_rate': 4.935911821390239e-05, 'epoch': 0.038452907165856844, 'step': 213500}
INFO:transformers.trainer:{'loss': 3.324364565372467, 'learning_rate': 4.9357617319789744e-05, 'epoch': 0.03854296081261529, 'step': 214000}
INFO:transformers.trainer:{'loss': 3.2727149820327757, 'learning_rate': 4.935611642567711e-05, 'epoch': 0.03863301445937374, 'step': 214500}
INFO:transformers.trainer:{'loss': 3.3314105339050295, 'learning_rate': 4.935461553156447e-05, 'epoch': 0.038723068106132186, 'step': 215000}
INFO:transformers.trainer:{'loss': 3.312156294107437, 'learning_rate': 4.935311463745183e-05, 'epoch': 0.03881312175289063, 'step': 215500}
INFO:transformers.trainer:{'loss': 3.323868734359741, 'learning_rate': 4.9351613743339187e-05, 'epoch': 0.038903175399649076, 'step': 216000}
INFO:transformers.trainer:{'loss': 3.2846845960617066, 'learning_rate': 4.9350112849226546e-05, 'epoch': 0.03899322904640753, 'step': 216500}
INFO:transformers.trainer:{'loss': 3.3031088769435883, 'learning_rate': 4.9348611955113905e-05, 'epoch': 0.03908328269316597, 'step': 217000}
INFO:transformers.trainer:{'loss': 3.3800097727775573, 'learning_rate': 4.9347111061001264e-05, 'epoch': 0.03917333633992442, 'step': 217500}
INFO:transformers.trainer:{'loss': 3.33098850941658, 'learning_rate': 4.934561016688862e-05, 'epoch': 0.03926338998668287, 'step': 218000}
INFO:transformers.trainer:{'loss': 3.262369478225708, 'learning_rate': 4.934410927277598e-05, 'epoch': 0.039353443633441315, 'step': 218500}
INFO:transformers.trainer:{'loss': 3.299620143175125, 'learning_rate': 4.934260837866334e-05, 'epoch': 0.03944349728019976, 'step': 219000}
INFO:transformers.trainer:{'loss': 3.2381379861831663, 'learning_rate': 4.93411074845507e-05, 'epoch': 0.039533550926958205, 'step': 219500}
INFO:transformers.trainer:{'loss': 3.312766555786133, 'learning_rate': 4.933960659043806e-05, 'epoch': 0.03962360457371666, 'step': 220000}
INFO:transformers.trainer:{'loss': 3.293976704120636, 'learning_rate': 4.933810569632542e-05, 'epoch': 0.0397136582204751, 'step': 220500}
INFO:transformers.trainer:{'loss': 3.290533616781235, 'learning_rate': 4.933660480221278e-05, 'epoch': 0.03980371186723355, 'step': 221000}
INFO:transformers.trainer:{'loss': 3.2756142899990084, 'learning_rate': 4.9335103908100136e-05, 'epoch': 0.03989376551399199, 'step': 221500}
INFO:transformers.trainer:{'loss': 3.3176421093940736, 'learning_rate': 4.9333603013987495e-05, 'epoch': 0.039983819160750445, 'step': 222000}
INFO:transformers.trainer:{'loss': 3.2653050050735475, 'learning_rate': 4.9332102119874854e-05, 'epoch': 0.04007387280750889, 'step': 222500}
INFO:transformers.trainer:{'loss': 3.2670130960941313, 'learning_rate': 4.933060122576221e-05, 'epoch': 0.040163926454267335, 'step': 223000}
INFO:transformers.trainer:{'loss': 3.320525030851364, 'learning_rate': 4.932910033164957e-05, 'epoch': 0.04025398010102578, 'step': 223500}
INFO:transformers.trainer:{'loss': 3.270511213541031, 'learning_rate': 4.932759943753693e-05, 'epoch': 0.04034403374778423, 'step': 224000}
INFO:transformers.trainer:{'loss': 3.3161218309402467, 'learning_rate': 4.932609854342429e-05, 'epoch': 0.04043408739454268, 'step': 224500}
INFO:transformers.trainer:{'loss': 3.319505912542343, 'learning_rate': 4.932459764931165e-05, 'epoch': 0.04052414104130112, 'step': 225000}
INFO:transformers.trainer:{'loss': 3.291853152036667, 'learning_rate': 4.932309675519901e-05, 'epoch': 0.040614194688059574, 'step': 225500}
INFO:transformers.trainer:{'loss': 3.316144956588745, 'learning_rate': 4.932159586108637e-05, 'epoch': 0.04070424833481802, 'step': 226000}
INFO:transformers.trainer:{'loss': 3.3255965676307677, 'learning_rate': 4.9320094966973727e-05, 'epoch': 0.040794301981576464, 'step': 226500}
INFO:transformers.trainer:{'loss': 3.295111628770828, 'learning_rate': 4.9318594072861086e-05, 'epoch': 0.04088435562833491, 'step': 227000}
INFO:transformers.trainer:{'loss': 3.322358834505081, 'learning_rate': 4.9317093178748445e-05, 'epoch': 0.04097440927509336, 'step': 227500}
INFO:transformers.trainer:{'loss': 3.322383660197258, 'learning_rate': 4.9315592284635804e-05, 'epoch': 0.041064462921851806, 'step': 228000}
INFO:transformers.trainer:{'loss': 3.267717646718025, 'learning_rate': 4.931409139052316e-05, 'epoch': 0.04115451656861025, 'step': 228500}
INFO:transformers.trainer:{'loss': 3.2989027326107023, 'learning_rate': 4.931259049641053e-05, 'epoch': 0.041244570215368696, 'step': 229000}
INFO:transformers.trainer:{'loss': 3.323982270002365, 'learning_rate': 4.931108960229788e-05, 'epoch': 0.04133462386212715, 'step': 229500}
INFO:transformers.trainer:{'loss': 3.3203443615436554, 'learning_rate': 4.930958870818525e-05, 'epoch': 0.04142467750888559, 'step': 230000}
INFO:transformers.trainer:{'loss': 3.3011392545700073, 'learning_rate': 4.93080878140726e-05, 'epoch': 0.04151473115564404, 'step': 230500}
INFO:transformers.trainer:{'loss': 3.348222985506058, 'learning_rate': 4.9306586919959965e-05, 'epoch': 0.04160478480240249, 'step': 231000}
INFO:transformers.trainer:{'loss': 3.331007430315018, 'learning_rate': 4.930508602584732e-05, 'epoch': 0.041694838449160936, 'step': 231500}
INFO:transformers.trainer:{'loss': 3.2929775722026826, 'learning_rate': 4.930358513173468e-05, 'epoch': 0.04178489209591938, 'step': 232000}
INFO:transformers.trainer:{'loss': 3.261474349498749, 'learning_rate': 4.9302084237622035e-05, 'epoch': 0.041874945742677826, 'step': 232500}
INFO:transformers.trainer:{'loss': 3.3289213087558744, 'learning_rate': 4.93005833435094e-05, 'epoch': 0.04196499938943628, 'step': 233000}
INFO:transformers.trainer:{'loss': 3.2590165321826934, 'learning_rate': 4.929908244939675e-05, 'epoch': 0.04205505303619472, 'step': 233500}
INFO:transformers.trainer:{'loss': 3.283029246330261, 'learning_rate': 4.929758155528412e-05, 'epoch': 0.04214510668295317, 'step': 234000}
INFO:transformers.trainer:{'loss': 3.323102640867233, 'learning_rate': 4.929608066117147e-05, 'epoch': 0.04223516032971161, 'step': 234500}
INFO:transformers.trainer:{'loss': 3.3454709441661836, 'learning_rate': 4.929457976705884e-05, 'epoch': 0.042325213976470065, 'step': 235000}
INFO:transformers.trainer:{'loss': 3.2929145205020904, 'learning_rate': 4.929307887294619e-05, 'epoch': 0.04241526762322851, 'step': 235500}
INFO:transformers.trainer:{'loss': 3.3351826124191284, 'learning_rate': 4.9291577978833555e-05, 'epoch': 0.042505321269986955, 'step': 236000}
INFO:transformers.trainer:{'loss': 3.29319157743454, 'learning_rate': 4.9290077084720914e-05, 'epoch': 0.0425953749167454, 'step': 236500}
INFO:transformers.trainer:{'loss': 3.2913367886543274, 'learning_rate': 4.9288576190608273e-05, 'epoch': 0.04268542856350385, 'step': 237000}
INFO:transformers.trainer:{'loss': 3.3334220621585846, 'learning_rate': 4.928707529649563e-05, 'epoch': 0.0427754822102623, 'step': 237500}
INFO:transformers.trainer:{'loss': 3.332285131454468, 'learning_rate': 4.928557440238299e-05, 'epoch': 0.04286553585702074, 'step': 238000}
INFO:transformers.trainer:{'loss': 3.3255713326931, 'learning_rate': 4.928407350827035e-05, 'epoch': 0.042955589503779194, 'step': 238500}
INFO:transformers.trainer:{'loss': 3.3239158244132994, 'learning_rate': 4.928257261415771e-05, 'epoch': 0.04304564315053764, 'step': 239000}
INFO:transformers.trainer:{'loss': 3.3228570392131807, 'learning_rate': 4.928107172004507e-05, 'epoch': 0.043135696797296084, 'step': 239500}
INFO:transformers.trainer:{'loss': 3.2912175945043565, 'learning_rate': 4.927957082593243e-05, 'epoch': 0.04322575044405453, 'step': 240000}
INFO:transformers.trainer:{'loss': 3.3394628775119783, 'learning_rate': 4.927806993181979e-05, 'epoch': 0.04331580409081298, 'step': 240500}
INFO:transformers.trainer:{'loss': 3.3179427094459535, 'learning_rate': 4.9276569037707146e-05, 'epoch': 0.04340585773757143, 'step': 241000}
INFO:transformers.trainer:{'loss': 3.34643750166893, 'learning_rate': 4.9275068143594505e-05, 'epoch': 0.04349591138432987, 'step': 241500}
INFO:transformers.trainer:{'loss': 3.3299058603048324, 'learning_rate': 4.9273567249481864e-05, 'epoch': 0.04358596503108832, 'step': 242000}
INFO:transformers.trainer:{'loss': 3.3103238191604616, 'learning_rate': 4.927206635536922e-05, 'epoch': 0.04367601867784677, 'step': 242500}
INFO:transformers.trainer:{'loss': 3.244733041763306, 'learning_rate': 4.927056546125658e-05, 'epoch': 0.043766072324605214, 'step': 243000}
INFO:transformers.trainer:{'loss': 3.3174403274059294, 'learning_rate': 4.926906456714394e-05, 'epoch': 0.04385612597136366, 'step': 243500}
INFO:transformers.trainer:{'loss': 3.2993707921504973, 'learning_rate': 4.92675636730313e-05, 'epoch': 0.04394617961812211, 'step': 244000}
INFO:transformers.trainer:{'loss': 3.311430077075958, 'learning_rate': 4.926606277891866e-05, 'epoch': 0.044036233264880556, 'step': 244500}
INFO:transformers.trainer:{'loss': 3.3298513514995576, 'learning_rate': 4.926456188480602e-05, 'epoch': 0.044126286911639, 'step': 245000}
INFO:transformers.trainer:{'loss': 3.3172612738609315, 'learning_rate': 4.926306099069338e-05, 'epoch': 0.044216340558397446, 'step': 245500}
INFO:transformers.trainer:{'loss': 3.3288570613861084, 'learning_rate': 4.9261560096580736e-05, 'epoch': 0.0443063942051559, 'step': 246000}
INFO:transformers.trainer:{'loss': 3.298831428766251, 'learning_rate': 4.9260059202468095e-05, 'epoch': 0.04439644785191434, 'step': 246500}
INFO:transformers.trainer:{'loss': 3.261486245274544, 'learning_rate': 4.9258558308355454e-05, 'epoch': 0.04448650149867279, 'step': 247000}
INFO:transformers.trainer:{'loss': 3.292817407131195, 'learning_rate': 4.9257057414242813e-05, 'epoch': 0.04457655514543123, 'step': 247500}
INFO:transformers.trainer:{'loss': 3.312474051952362, 'learning_rate': 4.925555652013017e-05, 'epoch': 0.044666608792189685, 'step': 248000}
INFO:transformers.trainer:{'loss': 3.3299419384002684, 'learning_rate': 4.925405562601753e-05, 'epoch': 0.04475666243894813, 'step': 248500}
INFO:transformers.trainer:{'loss': 3.3323683502674104, 'learning_rate': 4.925255473190489e-05, 'epoch': 0.044846716085706576, 'step': 249000}
INFO:transformers.trainer:{'loss': 3.293313383936882, 'learning_rate': 4.925105383779225e-05, 'epoch': 0.04493676973246502, 'step': 249500}
INFO:transformers.trainer:{'loss': 3.3228601312637327, 'learning_rate': 4.924955294367961e-05, 'epoch': 0.04502682337922347, 'step': 250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3164254467487337, 'learning_rate': 4.9248052049566975e-05, 'epoch': 0.04511687702598192, 'step': 250500}
INFO:transformers.trainer:{'loss': 3.355572321176529, 'learning_rate': 4.924655115545433e-05, 'epoch': 0.04520693067274036, 'step': 251000}
INFO:transformers.trainer:{'loss': 3.325117065668106, 'learning_rate': 4.924505026134169e-05, 'epoch': 0.045296984319498815, 'step': 251500}
INFO:transformers.trainer:{'loss': 3.3690365242958067, 'learning_rate': 4.9243549367229045e-05, 'epoch': 0.04538703796625726, 'step': 252000}
INFO:transformers.trainer:{'loss': 3.2650970063209535, 'learning_rate': 4.924204847311641e-05, 'epoch': 0.045477091613015705, 'step': 252500}
INFO:transformers.trainer:{'loss': 3.323092750787735, 'learning_rate': 4.924054757900376e-05, 'epoch': 0.04556714525977415, 'step': 253000}
INFO:transformers.trainer:{'loss': 3.3466899049282075, 'learning_rate': 4.923904668489113e-05, 'epoch': 0.0456571989065326, 'step': 253500}
INFO:transformers.trainer:{'loss': 3.4053060092926026, 'learning_rate': 4.923754579077848e-05, 'epoch': 0.04574725255329105, 'step': 254000}
INFO:transformers.trainer:{'loss': 3.3406621482372283, 'learning_rate': 4.923604489666585e-05, 'epoch': 0.04583730620004949, 'step': 254500}
INFO:transformers.trainer:{'loss': 3.2762424144744875, 'learning_rate': 4.92345440025532e-05, 'epoch': 0.04592735984680794, 'step': 255000}
INFO:transformers.trainer:{'loss': 3.3123057866096497, 'learning_rate': 4.9233043108440565e-05, 'epoch': 0.04601741349356639, 'step': 255500}
INFO:transformers.trainer:{'loss': 3.3064508450031282, 'learning_rate': 4.923154221432792e-05, 'epoch': 0.046107467140324834, 'step': 256000}
INFO:transformers.trainer:{'loss': 3.375691997051239, 'learning_rate': 4.923004132021528e-05, 'epoch': 0.04619752078708328, 'step': 256500}
INFO:transformers.trainer:{'loss': 3.3539282755851745, 'learning_rate': 4.922854042610264e-05, 'epoch': 0.04628757443384173, 'step': 257000}
INFO:transformers.trainer:{'loss': 3.2715346055030823, 'learning_rate': 4.922703953199e-05, 'epoch': 0.046377628080600176, 'step': 257500}
INFO:transformers.trainer:{'loss': 3.344242547750473, 'learning_rate': 4.922553863787736e-05, 'epoch': 0.04646768172735862, 'step': 258000}
INFO:transformers.trainer:{'loss': 3.2872151379585266, 'learning_rate': 4.922403774376472e-05, 'epoch': 0.04655773537411707, 'step': 258500}
INFO:transformers.trainer:{'loss': 3.325695875287056, 'learning_rate': 4.922253684965208e-05, 'epoch': 0.04664778902087552, 'step': 259000}
INFO:transformers.trainer:{'loss': 3.2596449506282807, 'learning_rate': 4.922103595553944e-05, 'epoch': 0.046737842667633964, 'step': 259500}
INFO:transformers.trainer:{'loss': 3.35570143699646, 'learning_rate': 4.9219535061426797e-05, 'epoch': 0.04682789631439241, 'step': 260000}
INFO:transformers.trainer:{'loss': 3.3239896211624145, 'learning_rate': 4.9218034167314156e-05, 'epoch': 0.046917949961150854, 'step': 260500}
INFO:transformers.trainer:{'loss': 3.320599862098694, 'learning_rate': 4.9216533273201515e-05, 'epoch': 0.047008003607909306, 'step': 261000}
INFO:transformers.trainer:{'loss': 3.300988089323044, 'learning_rate': 4.9215032379088874e-05, 'epoch': 0.04709805725466775, 'step': 261500}
INFO:transformers.trainer:{'loss': 3.213497279405594, 'learning_rate': 4.921353148497623e-05, 'epoch': 0.047188110901426196, 'step': 262000}
INFO:transformers.trainer:{'loss': 3.328931163072586, 'learning_rate': 4.921203059086359e-05, 'epoch': 0.04727816454818465, 'step': 262500}
INFO:transformers.trainer:{'loss': 3.2757344417572023, 'learning_rate': 4.921052969675095e-05, 'epoch': 0.04736821819494309, 'step': 263000}
INFO:transformers.trainer:{'loss': 3.3359931408166887, 'learning_rate': 4.920902880263831e-05, 'epoch': 0.04745827184170154, 'step': 263500}
INFO:transformers.trainer:{'loss': 3.3039858798980712, 'learning_rate': 4.920752790852567e-05, 'epoch': 0.04754832548845998, 'step': 264000}
INFO:transformers.trainer:{'loss': 3.326992640256882, 'learning_rate': 4.920602701441303e-05, 'epoch': 0.047638379135218435, 'step': 264500}
INFO:transformers.trainer:{'loss': 3.3487847702503206, 'learning_rate': 4.920452612030039e-05, 'epoch': 0.04772843278197688, 'step': 265000}
INFO:transformers.trainer:{'loss': 3.35224081158638, 'learning_rate': 4.9203025226187746e-05, 'epoch': 0.047818486428735325, 'step': 265500}
INFO:transformers.trainer:{'loss': 3.324327300786972, 'learning_rate': 4.9201524332075105e-05, 'epoch': 0.04790854007549377, 'step': 266000}
INFO:transformers.trainer:{'loss': 3.278584198474884, 'learning_rate': 4.9200023437962464e-05, 'epoch': 0.04799859372225222, 'step': 266500}
INFO:transformers.trainer:{'loss': 3.313623105764389, 'learning_rate': 4.919852254384982e-05, 'epoch': 0.04808864736901067, 'step': 267000}
INFO:transformers.trainer:{'loss': 3.266604696750641, 'learning_rate': 4.919702164973718e-05, 'epoch': 0.04817870101576911, 'step': 267500}
INFO:transformers.trainer:{'loss': 3.336663516283035, 'learning_rate': 4.919552075562454e-05, 'epoch': 0.04826875466252756, 'step': 268000}
INFO:transformers.trainer:{'loss': 3.2855665349960326, 'learning_rate': 4.91940198615119e-05, 'epoch': 0.04835880830928601, 'step': 268500}
INFO:transformers.trainer:{'loss': 3.2662424850463867, 'learning_rate': 4.919251896739926e-05, 'epoch': 0.048448861956044455, 'step': 269000}
INFO:transformers.trainer:{'loss': 3.3256678488254545, 'learning_rate': 4.919101807328662e-05, 'epoch': 0.0485389156028029, 'step': 269500}
INFO:transformers.trainer:{'loss': 3.255941314935684, 'learning_rate': 4.918951717917398e-05, 'epoch': 0.04862896924956135, 'step': 270000}
INFO:transformers.trainer:{'loss': 3.3573313640356064, 'learning_rate': 4.9188016285061337e-05, 'epoch': 0.0487190228963198, 'step': 270500}
INFO:transformers.trainer:{'loss': 3.32428848195076, 'learning_rate': 4.91865153909487e-05, 'epoch': 0.04880907654307824, 'step': 271000}
INFO:transformers.trainer:{'loss': 3.375608444213867, 'learning_rate': 4.9185014496836055e-05, 'epoch': 0.04889913018983669, 'step': 271500}
INFO:transformers.trainer:{'loss': 3.327989897966385, 'learning_rate': 4.918351360272342e-05, 'epoch': 0.04898918383659514, 'step': 272000}
INFO:transformers.trainer:{'loss': 3.2977141897678375, 'learning_rate': 4.918201270861077e-05, 'epoch': 0.049079237483353584, 'step': 272500}
INFO:transformers.trainer:{'loss': 3.3284664962291717, 'learning_rate': 4.918051181449814e-05, 'epoch': 0.04916929113011203, 'step': 273000}
INFO:transformers.trainer:{'loss': 3.316185689210892, 'learning_rate': 4.917901092038549e-05, 'epoch': 0.049259344776870474, 'step': 273500}
INFO:transformers.trainer:{'loss': 3.353646680355072, 'learning_rate': 4.917751002627286e-05, 'epoch': 0.049349398423628926, 'step': 274000}
INFO:transformers.trainer:{'loss': 3.349817747116089, 'learning_rate': 4.917600913216021e-05, 'epoch': 0.04943945207038737, 'step': 274500}
INFO:transformers.trainer:{'loss': 3.347346946954727, 'learning_rate': 4.9174508238047575e-05, 'epoch': 0.049529505717145816, 'step': 275000}
INFO:transformers.trainer:{'loss': 3.3366673231124877, 'learning_rate': 4.917300734393493e-05, 'epoch': 0.04961955936390427, 'step': 275500}
INFO:transformers.trainer:{'loss': 3.3552779133319857, 'learning_rate': 4.917150644982229e-05, 'epoch': 0.049709613010662713, 'step': 276000}
INFO:transformers.trainer:{'loss': 3.373053451061249, 'learning_rate': 4.9170005555709645e-05, 'epoch': 0.04979966665742116, 'step': 276500}
INFO:transformers.trainer:{'loss': 3.3340333557128905, 'learning_rate': 4.916850466159701e-05, 'epoch': 0.049889720304179604, 'step': 277000}
INFO:transformers.trainer:{'loss': 3.3953797724246977, 'learning_rate': 4.916700376748437e-05, 'epoch': 0.049979773950938056, 'step': 277500}
INFO:transformers.trainer:{'loss': 3.321634569644928, 'learning_rate': 4.916550287337173e-05, 'epoch': 0.0500698275976965, 'step': 278000}
INFO:transformers.trainer:{'loss': 3.3357529532909393, 'learning_rate': 4.916400197925909e-05, 'epoch': 0.050159881244454946, 'step': 278500}
INFO:transformers.trainer:{'loss': 3.410138203382492, 'learning_rate': 4.916250108514645e-05, 'epoch': 0.05024993489121339, 'step': 279000}
INFO:transformers.trainer:{'loss': 3.384499444961548, 'learning_rate': 4.9161000191033806e-05, 'epoch': 0.05033998853797184, 'step': 279500}
INFO:transformers.trainer:{'loss': 3.3501428339481354, 'learning_rate': 4.9159499296921165e-05, 'epoch': 0.05043004218473029, 'step': 280000}
INFO:transformers.trainer:{'loss': 3.3482862319946287, 'learning_rate': 4.9157998402808524e-05, 'epoch': 0.05052009583148873, 'step': 280500}
INFO:transformers.trainer:{'loss': 3.2520272409915925, 'learning_rate': 4.915649750869588e-05, 'epoch': 0.05061014947824718, 'step': 281000}
INFO:transformers.trainer:{'loss': 3.307300533294678, 'learning_rate': 4.915499661458324e-05, 'epoch': 0.05070020312500563, 'step': 281500}
INFO:transformers.trainer:{'loss': 3.377296860575676, 'learning_rate': 4.91534957204706e-05, 'epoch': 0.050790256771764075, 'step': 282000}
INFO:transformers.trainer:{'loss': 3.297476710796356, 'learning_rate': 4.915199482635796e-05, 'epoch': 0.05088031041852252, 'step': 282500}
INFO:transformers.trainer:{'loss': 3.314348278999329, 'learning_rate': 4.915049393224532e-05, 'epoch': 0.05097036406528097, 'step': 283000}
INFO:transformers.trainer:{'loss': 3.354691370010376, 'learning_rate': 4.914899303813268e-05, 'epoch': 0.05106041771203942, 'step': 283500}
INFO:transformers.trainer:{'loss': 3.3518185312747955, 'learning_rate': 4.914749214402004e-05, 'epoch': 0.05115047135879786, 'step': 284000}
INFO:transformers.trainer:{'loss': 3.3250273782014848, 'learning_rate': 4.91459912499074e-05, 'epoch': 0.05124052500555631, 'step': 284500}
INFO:transformers.trainer:{'loss': 3.3712416350841523, 'learning_rate': 4.9144490355794756e-05, 'epoch': 0.05133057865231476, 'step': 285000}
INFO:transformers.trainer:{'loss': 3.3192762540578844, 'learning_rate': 4.9142989461682115e-05, 'epoch': 0.051420632299073205, 'step': 285500}
INFO:transformers.trainer:{'loss': 3.3133327813148497, 'learning_rate': 4.9141488567569474e-05, 'epoch': 0.05151068594583165, 'step': 286000}
INFO:transformers.trainer:{'loss': 3.3791549544334414, 'learning_rate': 4.913998767345683e-05, 'epoch': 0.051600739592590095, 'step': 286500}
INFO:transformers.trainer:{'loss': 3.3168259778022766, 'learning_rate': 4.913848677934419e-05, 'epoch': 0.05169079323934855, 'step': 287000}
INFO:transformers.trainer:{'loss': 3.3674447951316835, 'learning_rate': 4.913698588523155e-05, 'epoch': 0.05178084688610699, 'step': 287500}
INFO:transformers.trainer:{'loss': 3.3320122034549713, 'learning_rate': 4.913548499111891e-05, 'epoch': 0.05187090053286544, 'step': 288000}
INFO:transformers.trainer:{'loss': 3.3374089596271515, 'learning_rate': 4.913398409700627e-05, 'epoch': 0.05196095417962389, 'step': 288500}
INFO:transformers.trainer:{'loss': 3.359157302618027, 'learning_rate': 4.913248320289363e-05, 'epoch': 0.052051007826382334, 'step': 289000}
INFO:transformers.trainer:{'loss': 3.2817023768424987, 'learning_rate': 4.913098230878099e-05, 'epoch': 0.05214106147314078, 'step': 289500}
INFO:transformers.trainer:{'loss': 3.362879540681839, 'learning_rate': 4.9129481414668346e-05, 'epoch': 0.052231115119899224, 'step': 290000}
INFO:transformers.trainer:{'loss': 3.310410658121109, 'learning_rate': 4.9127980520555705e-05, 'epoch': 0.052321168766657676, 'step': 290500}
INFO:transformers.trainer:{'loss': 3.2681834995746613, 'learning_rate': 4.9126479626443064e-05, 'epoch': 0.05241122241341612, 'step': 291000}
INFO:transformers.trainer:{'loss': 3.410787584543228, 'learning_rate': 4.912497873233043e-05, 'epoch': 0.052501276060174566, 'step': 291500}
INFO:transformers.trainer:{'loss': 3.3211692452430723, 'learning_rate': 4.912347783821778e-05, 'epoch': 0.05259132970693301, 'step': 292000}
INFO:transformers.trainer:{'loss': 3.3314426119327547, 'learning_rate': 4.912197694410515e-05, 'epoch': 0.05268138335369146, 'step': 292500}
INFO:transformers.trainer:{'loss': 3.321645767450333, 'learning_rate': 4.91204760499925e-05, 'epoch': 0.05277143700044991, 'step': 293000}
INFO:transformers.trainer:{'loss': 3.3939468941688538, 'learning_rate': 4.9118975155879866e-05, 'epoch': 0.05286149064720835, 'step': 293500}
INFO:transformers.trainer:{'loss': 3.306259050130844, 'learning_rate': 4.911747426176722e-05, 'epoch': 0.0529515442939668, 'step': 294000}
INFO:transformers.trainer:{'loss': 3.380287364721298, 'learning_rate': 4.9115973367654585e-05, 'epoch': 0.05304159794072525, 'step': 294500}
INFO:transformers.trainer:{'loss': 3.3121935217380525, 'learning_rate': 4.911447247354194e-05, 'epoch': 0.053131651587483696, 'step': 295000}
INFO:transformers.trainer:{'loss': 3.2889295793771742, 'learning_rate': 4.91129715794293e-05, 'epoch': 0.05322170523424214, 'step': 295500}
INFO:transformers.trainer:{'loss': 3.3640232477188112, 'learning_rate': 4.9111470685316655e-05, 'epoch': 0.05331175888100059, 'step': 296000}
INFO:transformers.trainer:{'loss': 3.373809308052063, 'learning_rate': 4.910996979120402e-05, 'epoch': 0.05340181252775904, 'step': 296500}
INFO:transformers.trainer:{'loss': 3.3035772218704222, 'learning_rate': 4.910846889709137e-05, 'epoch': 0.05349186617451748, 'step': 297000}
INFO:transformers.trainer:{'loss': 3.366694836974144, 'learning_rate': 4.910696800297874e-05, 'epoch': 0.05358191982127593, 'step': 297500}
INFO:transformers.trainer:{'loss': 3.356692196369171, 'learning_rate': 4.910546710886609e-05, 'epoch': 0.05367197346803438, 'step': 298000}
INFO:transformers.trainer:{'loss': 3.3458962914943693, 'learning_rate': 4.910396621475346e-05, 'epoch': 0.053762027114792825, 'step': 298500}
INFO:transformers.trainer:{'loss': 3.4205631194114683, 'learning_rate': 4.9102465320640816e-05, 'epoch': 0.05385208076155127, 'step': 299000}
INFO:transformers.trainer:{'loss': 3.3576867158412935, 'learning_rate': 4.9100964426528175e-05, 'epoch': 0.053942134408309715, 'step': 299500}
INFO:transformers.trainer:{'loss': 3.368037240743637, 'learning_rate': 4.9099463532415534e-05, 'epoch': 0.05403218805506817, 'step': 300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.4339080572128298, 'learning_rate': 4.909796263830289e-05, 'epoch': 0.05412224170182661, 'step': 300500}
INFO:transformers.trainer:{'loss': 3.352943114042282, 'learning_rate': 4.909646174419025e-05, 'epoch': 0.05421229534858506, 'step': 301000}
INFO:transformers.trainer:{'loss': 3.3384068880081177, 'learning_rate': 4.909496085007761e-05, 'epoch': 0.05430234899534351, 'step': 301500}
INFO:transformers.trainer:{'loss': 3.360287495136261, 'learning_rate': 4.909345995596497e-05, 'epoch': 0.054392402642101954, 'step': 302000}
INFO:transformers.trainer:{'loss': 3.272460114002228, 'learning_rate': 4.909195906185233e-05, 'epoch': 0.0544824562888604, 'step': 302500}
INFO:transformers.trainer:{'loss': 3.325437796354294, 'learning_rate': 4.909045816773969e-05, 'epoch': 0.054572509935618845, 'step': 303000}
INFO:transformers.trainer:{'loss': 3.285695750236511, 'learning_rate': 4.908895727362705e-05, 'epoch': 0.054662563582377297, 'step': 303500}
INFO:transformers.trainer:{'loss': 3.375501738548279, 'learning_rate': 4.9087456379514406e-05, 'epoch': 0.05475261722913574, 'step': 304000}
INFO:transformers.trainer:{'loss': 3.3953320298194885, 'learning_rate': 4.9085955485401766e-05, 'epoch': 0.05484267087589419, 'step': 304500}
INFO:transformers.trainer:{'loss': 3.310699782848358, 'learning_rate': 4.9084454591289125e-05, 'epoch': 0.05493272452265263, 'step': 305000}
INFO:transformers.trainer:{'loss': 3.3035363736152648, 'learning_rate': 4.9082953697176484e-05, 'epoch': 0.055022778169411084, 'step': 305500}
INFO:transformers.trainer:{'loss': 3.3920919311046602, 'learning_rate': 4.908145280306384e-05, 'epoch': 0.05511283181616953, 'step': 306000}
INFO:transformers.trainer:{'loss': 3.2782873587608337, 'learning_rate': 4.90799519089512e-05, 'epoch': 0.055202885462927974, 'step': 306500}
INFO:transformers.trainer:{'loss': 3.3558405916690828, 'learning_rate': 4.907845101483856e-05, 'epoch': 0.05529293910968642, 'step': 307000}
INFO:transformers.trainer:{'loss': 3.33110592007637, 'learning_rate': 4.907695012072592e-05, 'epoch': 0.05538299275644487, 'step': 307500}
INFO:transformers.trainer:{'loss': 3.362631493806839, 'learning_rate': 4.907544922661328e-05, 'epoch': 0.055473046403203316, 'step': 308000}
INFO:transformers.trainer:{'loss': 3.365307820320129, 'learning_rate': 4.907394833250064e-05, 'epoch': 0.05556310004996176, 'step': 308500}
INFO:transformers.trainer:{'loss': 3.3598178087472914, 'learning_rate': 4.9072447438388e-05, 'epoch': 0.05565315369672021, 'step': 309000}
INFO:transformers.trainer:{'loss': 3.3812741527557373, 'learning_rate': 4.9070946544275356e-05, 'epoch': 0.05574320734347866, 'step': 309500}
INFO:transformers.trainer:{'loss': 3.3272070434093477, 'learning_rate': 4.9069445650162715e-05, 'epoch': 0.0558332609902371, 'step': 310000}
INFO:transformers.trainer:{'loss': 3.296811750411987, 'learning_rate': 4.9067944756050074e-05, 'epoch': 0.05592331463699555, 'step': 310500}
INFO:transformers.trainer:{'loss': 3.388855613708496, 'learning_rate': 4.906644386193743e-05, 'epoch': 0.056013368283754, 'step': 311000}
INFO:transformers.trainer:{'loss': 3.363471208572388, 'learning_rate': 4.906494296782479e-05, 'epoch': 0.056103421930512445, 'step': 311500}
INFO:transformers.trainer:{'loss': 3.3089378097057343, 'learning_rate': 4.906344207371215e-05, 'epoch': 0.05619347557727089, 'step': 312000}
INFO:transformers.trainer:{'loss': 3.2774359362125396, 'learning_rate': 4.906194117959951e-05, 'epoch': 0.056283529224029336, 'step': 312500}
INFO:transformers.trainer:{'loss': 3.337177023410797, 'learning_rate': 4.9060440285486876e-05, 'epoch': 0.05637358287078779, 'step': 313000}
INFO:transformers.trainer:{'loss': 3.3758455702066423, 'learning_rate': 4.905893939137423e-05, 'epoch': 0.05646363651754623, 'step': 313500}
INFO:transformers.trainer:{'loss': 3.297096647977829, 'learning_rate': 4.9057438497261594e-05, 'epoch': 0.05655369016430468, 'step': 314000}
INFO:transformers.trainer:{'loss': 3.369292776107788, 'learning_rate': 4.9055937603148947e-05, 'epoch': 0.05664374381106313, 'step': 314500}
INFO:transformers.trainer:{'loss': 3.355366149187088, 'learning_rate': 4.905443670903631e-05, 'epoch': 0.056733797457821575, 'step': 315000}
INFO:transformers.trainer:{'loss': 3.3280172817707063, 'learning_rate': 4.9052935814923665e-05, 'epoch': 0.05682385110458002, 'step': 315500}
INFO:transformers.trainer:{'loss': 3.3135822682380676, 'learning_rate': 4.905143492081103e-05, 'epoch': 0.056913904751338465, 'step': 316000}
INFO:transformers.trainer:{'loss': 3.3303430118560793, 'learning_rate': 4.904993402669838e-05, 'epoch': 0.05700395839809692, 'step': 316500}
INFO:transformers.trainer:{'loss': 3.304485283613205, 'learning_rate': 4.904843313258575e-05, 'epoch': 0.05709401204485536, 'step': 317000}
INFO:transformers.trainer:{'loss': 3.2764557218551635, 'learning_rate': 4.90469322384731e-05, 'epoch': 0.05718406569161381, 'step': 317500}
INFO:transformers.trainer:{'loss': 3.323229970932007, 'learning_rate': 4.904543134436047e-05, 'epoch': 0.05727411933837225, 'step': 318000}
INFO:transformers.trainer:{'loss': 3.382775848031044, 'learning_rate': 4.904393045024782e-05, 'epoch': 0.057364172985130704, 'step': 318500}
INFO:transformers.trainer:{'loss': 3.3395699560642242, 'learning_rate': 4.9042429556135185e-05, 'epoch': 0.05745422663188915, 'step': 319000}
INFO:transformers.trainer:{'loss': 3.404252319574356, 'learning_rate': 4.9040928662022544e-05, 'epoch': 0.057544280278647594, 'step': 319500}
INFO:transformers.trainer:{'loss': 3.276422126531601, 'learning_rate': 4.90394277679099e-05, 'epoch': 0.057634333925406046, 'step': 320000}
INFO:transformers.trainer:{'loss': 3.3959792108535765, 'learning_rate': 4.903792687379726e-05, 'epoch': 0.05772438757216449, 'step': 320500}
INFO:transformers.trainer:{'loss': 3.357749176979065, 'learning_rate': 4.903642597968462e-05, 'epoch': 0.057814441218922936, 'step': 321000}
INFO:transformers.trainer:{'loss': 3.3315157625675202, 'learning_rate': 4.903492508557198e-05, 'epoch': 0.05790449486568138, 'step': 321500}
INFO:transformers.trainer:{'loss': 3.3099680367708206, 'learning_rate': 4.903342419145934e-05, 'epoch': 0.057994548512439834, 'step': 322000}
INFO:transformers.trainer:{'loss': 3.304714133501053, 'learning_rate': 4.90319232973467e-05, 'epoch': 0.05808460215919828, 'step': 322500}
INFO:transformers.trainer:{'loss': 3.347868546485901, 'learning_rate': 4.903042240323406e-05, 'epoch': 0.058174655805956724, 'step': 323000}
INFO:transformers.trainer:{'loss': 3.3461855925321577, 'learning_rate': 4.9028921509121416e-05, 'epoch': 0.05826470945271517, 'step': 323500}
INFO:transformers.trainer:{'loss': 3.3603595318794253, 'learning_rate': 4.9027420615008775e-05, 'epoch': 0.05835476309947362, 'step': 324000}
INFO:transformers.trainer:{'loss': 3.3407144824266433, 'learning_rate': 4.9025919720896134e-05, 'epoch': 0.058444816746232066, 'step': 324500}
INFO:transformers.trainer:{'loss': 3.366243319988251, 'learning_rate': 4.902441882678349e-05, 'epoch': 0.05853487039299051, 'step': 325000}
INFO:transformers.trainer:{'loss': 3.3667778325080873, 'learning_rate': 4.902291793267085e-05, 'epoch': 0.058624924039748956, 'step': 325500}
INFO:transformers.trainer:{'loss': 3.3567236907482148, 'learning_rate': 4.902141703855822e-05, 'epoch': 0.05871497768650741, 'step': 326000}
INFO:transformers.trainer:{'loss': 3.322277937889099, 'learning_rate': 4.901991614444557e-05, 'epoch': 0.05880503133326585, 'step': 326500}
INFO:transformers.trainer:{'loss': 3.376309446334839, 'learning_rate': 4.9018415250332936e-05, 'epoch': 0.0588950849800243, 'step': 327000}
INFO:transformers.trainer:{'loss': 3.403585719585419, 'learning_rate': 4.901691435622029e-05, 'epoch': 0.05898513862678275, 'step': 327500}
INFO:transformers.trainer:{'loss': 3.3512485563755035, 'learning_rate': 4.9015413462107654e-05, 'epoch': 0.059075192273541195, 'step': 328000}
INFO:transformers.trainer:{'loss': 3.3986234905719757, 'learning_rate': 4.901391256799501e-05, 'epoch': 0.05916524592029964, 'step': 328500}
INFO:transformers.trainer:{'loss': 3.284341187477112, 'learning_rate': 4.9012411673882366e-05, 'epoch': 0.059255299567058085, 'step': 329000}
INFO:transformers.trainer:{'loss': 3.414149708271027, 'learning_rate': 4.9010910779769725e-05, 'epoch': 0.05934535321381654, 'step': 329500}
INFO:transformers.trainer:{'loss': 3.361451943397522, 'learning_rate': 4.9009409885657084e-05, 'epoch': 0.05943540686057498, 'step': 330000}
INFO:transformers.trainer:{'loss': 3.314010260224342, 'learning_rate': 4.900790899154444e-05, 'epoch': 0.05952546050733343, 'step': 330500}
INFO:transformers.trainer:{'loss': 3.3617239091396334, 'learning_rate': 4.90064080974318e-05, 'epoch': 0.05961551415409187, 'step': 331000}
INFO:transformers.trainer:{'loss': 3.505089503526688, 'learning_rate': 4.900490720331916e-05, 'epoch': 0.059705567800850325, 'step': 331500}
INFO:transformers.trainer:{'loss': 3.414858144283295, 'learning_rate': 4.900340630920652e-05, 'epoch': 0.05979562144760877, 'step': 332000}
INFO:transformers.trainer:{'loss': 3.365364607095718, 'learning_rate': 4.900190541509388e-05, 'epoch': 0.059885675094367215, 'step': 332500}
INFO:transformers.trainer:{'loss': 3.3534374713897703, 'learning_rate': 4.900040452098124e-05, 'epoch': 0.05997572874112567, 'step': 333000}
INFO:transformers.trainer:{'loss': 3.356760055780411, 'learning_rate': 4.8998903626868604e-05, 'epoch': 0.06006578238788411, 'step': 333500}
INFO:transformers.trainer:{'loss': 3.364514077782631, 'learning_rate': 4.8997402732755956e-05, 'epoch': 0.06015583603464256, 'step': 334000}
INFO:transformers.trainer:{'loss': 3.3278719775676726, 'learning_rate': 4.899590183864332e-05, 'epoch': 0.060245889681401, 'step': 334500}
INFO:transformers.trainer:{'loss': 3.3549557104110717, 'learning_rate': 4.8994400944530674e-05, 'epoch': 0.060335943328159454, 'step': 335000}
INFO:transformers.trainer:{'loss': 3.405043838262558, 'learning_rate': 4.899290005041804e-05, 'epoch': 0.0604259969749179, 'step': 335500}
INFO:transformers.trainer:{'loss': 3.3987772953510285, 'learning_rate': 4.899139915630539e-05, 'epoch': 0.060516050621676344, 'step': 336000}
INFO:transformers.trainer:{'loss': 3.3835053870677947, 'learning_rate': 4.898989826219276e-05, 'epoch': 0.06060610426843479, 'step': 336500}
INFO:transformers.trainer:{'loss': 3.3306762125492098, 'learning_rate': 4.898839736808011e-05, 'epoch': 0.06069615791519324, 'step': 337000}
INFO:transformers.trainer:{'loss': 3.3294810962677004, 'learning_rate': 4.8986896473967476e-05, 'epoch': 0.060786211561951686, 'step': 337500}
INFO:transformers.trainer:{'loss': 3.401591256856918, 'learning_rate': 4.898539557985483e-05, 'epoch': 0.06087626520871013, 'step': 338000}
INFO:transformers.trainer:{'loss': 3.3302993085384367, 'learning_rate': 4.8983894685742194e-05, 'epoch': 0.060966318855468576, 'step': 338500}
INFO:transformers.trainer:{'loss': 3.310103890657425, 'learning_rate': 4.898239379162955e-05, 'epoch': 0.06105637250222703, 'step': 339000}
INFO:transformers.trainer:{'loss': 3.371391422986984, 'learning_rate': 4.898089289751691e-05, 'epoch': 0.061146426148985474, 'step': 339500}
INFO:transformers.trainer:{'loss': 3.4325914121866226, 'learning_rate': 4.897939200340427e-05, 'epoch': 0.06123647979574392, 'step': 340000}
INFO:transformers.trainer:{'loss': 3.3254221053123474, 'learning_rate': 4.897789110929163e-05, 'epoch': 0.06132653344250237, 'step': 340500}
INFO:transformers.trainer:{'loss': 3.402316960096359, 'learning_rate': 4.897639021517899e-05, 'epoch': 0.061416587089260816, 'step': 341000}
INFO:transformers.trainer:{'loss': 3.3710433700084685, 'learning_rate': 4.897488932106635e-05, 'epoch': 0.06150664073601926, 'step': 341500}
INFO:transformers.trainer:{'loss': 3.326430367946625, 'learning_rate': 4.897338842695371e-05, 'epoch': 0.061596694382777706, 'step': 342000}
INFO:transformers.trainer:{'loss': 3.3772956132888794, 'learning_rate': 4.897188753284107e-05, 'epoch': 0.06168674802953616, 'step': 342500}
INFO:transformers.trainer:{'loss': 3.3567818224430086, 'learning_rate': 4.8970386638728426e-05, 'epoch': 0.0617768016762946, 'step': 343000}
INFO:transformers.trainer:{'loss': 3.371760177850723, 'learning_rate': 4.8968885744615785e-05, 'epoch': 0.06186685532305305, 'step': 343500}
INFO:transformers.trainer:{'loss': 3.3064756224155425, 'learning_rate': 4.8967384850503144e-05, 'epoch': 0.06195690896981149, 'step': 344000}
INFO:transformers.trainer:{'loss': 3.369070964574814, 'learning_rate': 4.89658839563905e-05, 'epoch': 0.062046962616569945, 'step': 344500}
INFO:transformers.trainer:{'loss': 3.4129656000137327, 'learning_rate': 4.896438306227786e-05, 'epoch': 0.06213701626332839, 'step': 345000}
INFO:transformers.trainer:{'loss': 3.384816786289215, 'learning_rate': 4.896288216816522e-05, 'epoch': 0.062227069910086835, 'step': 345500}
INFO:transformers.trainer:{'loss': 3.360897522687912, 'learning_rate': 4.896138127405258e-05, 'epoch': 0.06231712355684529, 'step': 346000}
INFO:transformers.trainer:{'loss': 3.331064485788345, 'learning_rate': 4.895988037993994e-05, 'epoch': 0.06240717720360373, 'step': 346500}
INFO:transformers.trainer:{'loss': 3.3255046927928924, 'learning_rate': 4.89583794858273e-05, 'epoch': 0.06249723085036218, 'step': 347000}
INFO:transformers.trainer:{'loss': 3.3209882810115814, 'learning_rate': 4.8956878591714664e-05, 'epoch': 0.06258728449712063, 'step': 347500}
INFO:transformers.trainer:{'loss': 3.3800892028808596, 'learning_rate': 4.8955377697602016e-05, 'epoch': 0.06267733814387907, 'step': 348000}
INFO:transformers.trainer:{'loss': 3.3440250582695006, 'learning_rate': 4.895387680348938e-05, 'epoch': 0.06276739179063752, 'step': 348500}
INFO:transformers.trainer:{'loss': 3.344187815606594, 'learning_rate': 4.8952375909376735e-05, 'epoch': 0.06285744543739596, 'step': 349000}
INFO:transformers.trainer:{'loss': 3.354985051751137, 'learning_rate': 4.89508750152641e-05, 'epoch': 0.06294749908415441, 'step': 349500}
INFO:transformers.trainer:{'loss': 3.341971842288971, 'learning_rate': 4.894937412115145e-05, 'epoch': 0.06303755273091285, 'step': 350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3945647690296172, 'learning_rate': 4.894787322703882e-05, 'epoch': 0.0631276063776713, 'step': 350500}
INFO:transformers.trainer:{'loss': 3.418336883068085, 'learning_rate': 4.894637233292617e-05, 'epoch': 0.06321766002442976, 'step': 351000}
INFO:transformers.trainer:{'loss': 3.339215041875839, 'learning_rate': 4.8944871438813537e-05, 'epoch': 0.0633077136711882, 'step': 351500}
INFO:transformers.trainer:{'loss': 3.3329455456733705, 'learning_rate': 4.894337054470089e-05, 'epoch': 0.06339776731794665, 'step': 352000}
INFO:transformers.trainer:{'loss': 3.4003822717666625, 'learning_rate': 4.894186965058825e-05, 'epoch': 0.0634878209647051, 'step': 352500}
INFO:transformers.trainer:{'loss': 3.3396282861232756, 'learning_rate': 4.894036875647561e-05, 'epoch': 0.06357787461146354, 'step': 353000}
INFO:transformers.trainer:{'loss': 3.3730761914253233, 'learning_rate': 4.8938867862362966e-05, 'epoch': 0.06366792825822198, 'step': 353500}
INFO:transformers.trainer:{'loss': 3.371778373003006, 'learning_rate': 4.893736696825033e-05, 'epoch': 0.06375798190498043, 'step': 354000}
INFO:transformers.trainer:{'loss': 3.3778265805244447, 'learning_rate': 4.8935866074137684e-05, 'epoch': 0.06384803555173889, 'step': 354500}
INFO:transformers.trainer:{'loss': 3.337999972343445, 'learning_rate': 4.893436518002505e-05, 'epoch': 0.06393808919849733, 'step': 355000}
INFO:transformers.trainer:{'loss': 3.359962376117706, 'learning_rate': 4.89328642859124e-05, 'epoch': 0.06402814284525578, 'step': 355500}
INFO:transformers.trainer:{'loss': 3.4269543232917785, 'learning_rate': 4.893136339179977e-05, 'epoch': 0.06411819649201422, 'step': 356000}
INFO:transformers.trainer:{'loss': 3.3295130150318144, 'learning_rate': 4.892986249768712e-05, 'epoch': 0.06420825013877267, 'step': 356500}
INFO:transformers.trainer:{'loss': 3.314787935256958, 'learning_rate': 4.8928361603574486e-05, 'epoch': 0.06429830378553111, 'step': 357000}
INFO:transformers.trainer:{'loss': 3.3824613938331605, 'learning_rate': 4.892686070946184e-05, 'epoch': 0.06438835743228956, 'step': 357500}
INFO:transformers.trainer:{'loss': 3.4394243767261505, 'learning_rate': 4.8925359815349204e-05, 'epoch': 0.064478411079048, 'step': 358000}
INFO:transformers.trainer:{'loss': 3.3612303087711335, 'learning_rate': 4.8923858921236556e-05, 'epoch': 0.06456846472580646, 'step': 358500}
INFO:transformers.trainer:{'loss': 3.399884283065796, 'learning_rate': 4.892235802712392e-05, 'epoch': 0.06465851837256491, 'step': 359000}
INFO:transformers.trainer:{'loss': 3.323161990642548, 'learning_rate': 4.8920857133011275e-05, 'epoch': 0.06474857201932335, 'step': 359500}
INFO:transformers.trainer:{'loss': 3.346233220338821, 'learning_rate': 4.891935623889864e-05, 'epoch': 0.0648386256660818, 'step': 360000}
INFO:transformers.trainer:{'loss': 3.3870154666900634, 'learning_rate': 4.891785534478599e-05, 'epoch': 0.06492867931284024, 'step': 360500}
INFO:transformers.trainer:{'loss': 3.3382966692447664, 'learning_rate': 4.891635445067336e-05, 'epoch': 0.06501873295959869, 'step': 361000}
INFO:transformers.trainer:{'loss': 3.37518941283226, 'learning_rate': 4.891485355656072e-05, 'epoch': 0.06510878660635713, 'step': 361500}
INFO:transformers.trainer:{'loss': 3.243386127471924, 'learning_rate': 4.8913352662448077e-05, 'epoch': 0.06519884025311559, 'step': 362000}
INFO:transformers.trainer:{'loss': 3.361642693519592, 'learning_rate': 4.8911851768335436e-05, 'epoch': 0.06528889389987404, 'step': 362500}
INFO:transformers.trainer:{'loss': 3.3599304832220076, 'learning_rate': 4.8910350874222795e-05, 'epoch': 0.06537894754663248, 'step': 363000}
INFO:transformers.trainer:{'loss': 3.2798559892177583, 'learning_rate': 4.8908849980110154e-05, 'epoch': 0.06546900119339093, 'step': 363500}
INFO:transformers.trainer:{'loss': 3.383395474433899, 'learning_rate': 4.890734908599751e-05, 'epoch': 0.06555905484014937, 'step': 364000}
INFO:transformers.trainer:{'loss': 3.3574666001796722, 'learning_rate': 4.890584819188487e-05, 'epoch': 0.06564910848690782, 'step': 364500}
INFO:transformers.trainer:{'loss': 3.3239966905117035, 'learning_rate': 4.890434729777223e-05, 'epoch': 0.06573916213366626, 'step': 365000}
INFO:transformers.trainer:{'loss': 3.334637040615082, 'learning_rate': 4.890284640365959e-05, 'epoch': 0.06582921578042472, 'step': 365500}
INFO:transformers.trainer:{'loss': 3.358355595111847, 'learning_rate': 4.890134550954695e-05, 'epoch': 0.06591926942718317, 'step': 366000}
INFO:transformers.trainer:{'loss': 3.417224223136902, 'learning_rate': 4.889984461543431e-05, 'epoch': 0.06600932307394161, 'step': 366500}
INFO:transformers.trainer:{'loss': 3.3489912934303283, 'learning_rate': 4.889834372132167e-05, 'epoch': 0.06609937672070006, 'step': 367000}
INFO:transformers.trainer:{'loss': 3.3786780979633333, 'learning_rate': 4.8896842827209026e-05, 'epoch': 0.0661894303674585, 'step': 367500}
INFO:transformers.trainer:{'loss': 3.3830531601905824, 'learning_rate': 4.889534193309639e-05, 'epoch': 0.06627948401421695, 'step': 368000}
INFO:transformers.trainer:{'loss': 3.361521809339523, 'learning_rate': 4.8893841038983744e-05, 'epoch': 0.06636953766097539, 'step': 368500}
INFO:transformers.trainer:{'loss': 3.388613132953644, 'learning_rate': 4.889234014487111e-05, 'epoch': 0.06645959130773384, 'step': 369000}
INFO:transformers.trainer:{'loss': 3.306197158575058, 'learning_rate': 4.889083925075846e-05, 'epoch': 0.0665496449544923, 'step': 369500}
INFO:transformers.trainer:{'loss': 3.3671793327331545, 'learning_rate': 4.888933835664583e-05, 'epoch': 0.06663969860125074, 'step': 370000}
INFO:transformers.trainer:{'loss': 3.4120746879577637, 'learning_rate': 4.888783746253318e-05, 'epoch': 0.06672975224800919, 'step': 370500}
INFO:transformers.trainer:{'loss': 3.4121922118663788, 'learning_rate': 4.8886336568420546e-05, 'epoch': 0.06681980589476763, 'step': 371000}
INFO:transformers.trainer:{'loss': 3.368379219532013, 'learning_rate': 4.88848356743079e-05, 'epoch': 0.06690985954152608, 'step': 371500}
INFO:transformers.trainer:{'loss': 3.35189820766449, 'learning_rate': 4.8883334780195264e-05, 'epoch': 0.06699991318828452, 'step': 372000}
INFO:transformers.trainer:{'loss': 3.3387738847732544, 'learning_rate': 4.888183388608262e-05, 'epoch': 0.06708996683504297, 'step': 372500}
INFO:transformers.trainer:{'loss': 3.3942248542308806, 'learning_rate': 4.888033299196998e-05, 'epoch': 0.06718002048180143, 'step': 373000}
INFO:transformers.trainer:{'loss': 3.3954812327623367, 'learning_rate': 4.8878832097857335e-05, 'epoch': 0.06727007412855987, 'step': 373500}
INFO:transformers.trainer:{'loss': 3.3798821611404417, 'learning_rate': 4.88773312037447e-05, 'epoch': 0.06736012777531832, 'step': 374000}
INFO:transformers.trainer:{'loss': 3.4153591763973234, 'learning_rate': 4.887583030963206e-05, 'epoch': 0.06745018142207676, 'step': 374500}
INFO:transformers.trainer:{'loss': 3.3672614576816557, 'learning_rate': 4.887432941551942e-05, 'epoch': 0.0675402350688352, 'step': 375000}
INFO:transformers.trainer:{'loss': 3.28422154545784, 'learning_rate': 4.887282852140678e-05, 'epoch': 0.06763028871559365, 'step': 375500}
INFO:transformers.trainer:{'loss': 3.3258737037181856, 'learning_rate': 4.887132762729414e-05, 'epoch': 0.0677203423623521, 'step': 376000}
INFO:transformers.trainer:{'loss': 3.390075335264206, 'learning_rate': 4.8869826733181496e-05, 'epoch': 0.06781039600911054, 'step': 376500}
INFO:transformers.trainer:{'loss': 3.343609444260597, 'learning_rate': 4.886832583906885e-05, 'epoch': 0.067900449655869, 'step': 377000}
INFO:transformers.trainer:{'loss': 3.3656465480327604, 'learning_rate': 4.8866824944956214e-05, 'epoch': 0.06799050330262744, 'step': 377500}
INFO:transformers.trainer:{'loss': 3.3918285892009736, 'learning_rate': 4.8865324050843566e-05, 'epoch': 0.06808055694938589, 'step': 378000}
INFO:transformers.trainer:{'loss': 3.291734288215637, 'learning_rate': 4.886382315673093e-05, 'epoch': 0.06817061059614433, 'step': 378500}
INFO:transformers.trainer:{'loss': 3.3009301776885986, 'learning_rate': 4.8862322262618284e-05, 'epoch': 0.06826066424290278, 'step': 379000}
INFO:transformers.trainer:{'loss': 3.3414371342658997, 'learning_rate': 4.886082136850565e-05, 'epoch': 0.06835071788966122, 'step': 379500}
INFO:transformers.trainer:{'loss': 3.3388976581096648, 'learning_rate': 4.8859320474393e-05, 'epoch': 0.06844077153641967, 'step': 380000}
INFO:transformers.trainer:{'loss': 3.412509778261185, 'learning_rate': 4.885781958028037e-05, 'epoch': 0.06853082518317813, 'step': 380500}
INFO:transformers.trainer:{'loss': 3.2772688460350037, 'learning_rate': 4.885631868616772e-05, 'epoch': 0.06862087882993657, 'step': 381000}
INFO:transformers.trainer:{'loss': 3.320437024831772, 'learning_rate': 4.8854817792055086e-05, 'epoch': 0.06871093247669502, 'step': 381500}
INFO:transformers.trainer:{'loss': 3.4144044139385223, 'learning_rate': 4.8853316897942445e-05, 'epoch': 0.06880098612345346, 'step': 382000}
INFO:transformers.trainer:{'loss': 3.3075221177339555, 'learning_rate': 4.8851816003829804e-05, 'epoch': 0.06889103977021191, 'step': 382500}
INFO:transformers.trainer:{'loss': 3.338390073299408, 'learning_rate': 4.8850315109717163e-05, 'epoch': 0.06898109341697035, 'step': 383000}
INFO:transformers.trainer:{'loss': 3.3303617324829102, 'learning_rate': 4.884881421560452e-05, 'epoch': 0.0690711470637288, 'step': 383500}
INFO:transformers.trainer:{'loss': 3.3690299038887024, 'learning_rate': 4.884731332149188e-05, 'epoch': 0.06916120071048726, 'step': 384000}
INFO:transformers.trainer:{'loss': 3.374425504565239, 'learning_rate': 4.884581242737924e-05, 'epoch': 0.0692512543572457, 'step': 384500}
INFO:transformers.trainer:{'loss': 3.416568172931671, 'learning_rate': 4.88443115332666e-05, 'epoch': 0.06934130800400415, 'step': 385000}
INFO:transformers.trainer:{'loss': 3.331314994096756, 'learning_rate': 4.884281063915396e-05, 'epoch': 0.0694313616507626, 'step': 385500}
INFO:transformers.trainer:{'loss': 3.374519159793854, 'learning_rate': 4.884130974504132e-05, 'epoch': 0.06952141529752104, 'step': 386000}
INFO:transformers.trainer:{'loss': 3.3404489531517028, 'learning_rate': 4.883980885092868e-05, 'epoch': 0.06961146894427948, 'step': 386500}
INFO:transformers.trainer:{'loss': 3.3450114059448244, 'learning_rate': 4.8838307956816036e-05, 'epoch': 0.06970152259103793, 'step': 387000}
INFO:transformers.trainer:{'loss': 3.386869884729385, 'learning_rate': 4.8836807062703395e-05, 'epoch': 0.06979157623779637, 'step': 387500}
INFO:transformers.trainer:{'loss': 3.3359705572128298, 'learning_rate': 4.8835306168590754e-05, 'epoch': 0.06988162988455483, 'step': 388000}
INFO:transformers.trainer:{'loss': 3.373125836133957, 'learning_rate': 4.883380527447812e-05, 'epoch': 0.06997168353131328, 'step': 388500}
INFO:transformers.trainer:{'loss': 3.3000732851028443, 'learning_rate': 4.883230438036547e-05, 'epoch': 0.07006173717807172, 'step': 389000}
INFO:transformers.trainer:{'loss': 3.3451236021518707, 'learning_rate': 4.883080348625284e-05, 'epoch': 0.07015179082483017, 'step': 389500}
INFO:transformers.trainer:{'loss': 3.3532650089263916, 'learning_rate': 4.882930259214019e-05, 'epoch': 0.07024184447158861, 'step': 390000}
INFO:transformers.trainer:{'loss': 3.3813346494436263, 'learning_rate': 4.8827801698027556e-05, 'epoch': 0.07033189811834706, 'step': 390500}
INFO:transformers.trainer:{'loss': 3.401650151014328, 'learning_rate': 4.882630080391491e-05, 'epoch': 0.0704219517651055, 'step': 391000}
INFO:transformers.trainer:{'loss': 3.389394960641861, 'learning_rate': 4.8824799909802274e-05, 'epoch': 0.07051200541186396, 'step': 391500}
INFO:transformers.trainer:{'loss': 3.387920414566994, 'learning_rate': 4.8823299015689626e-05, 'epoch': 0.07060205905862241, 'step': 392000}
INFO:transformers.trainer:{'loss': 3.339443389892578, 'learning_rate': 4.882179812157699e-05, 'epoch': 0.07069211270538085, 'step': 392500}
INFO:transformers.trainer:{'loss': 3.3278712339401246, 'learning_rate': 4.8820297227464344e-05, 'epoch': 0.0707821663521393, 'step': 393000}
INFO:transformers.trainer:{'loss': 3.3386953644752504, 'learning_rate': 4.881879633335171e-05, 'epoch': 0.07087221999889774, 'step': 393500}
INFO:transformers.trainer:{'loss': 3.3394307076931, 'learning_rate': 4.881729543923906e-05, 'epoch': 0.07096227364565619, 'step': 394000}
INFO:transformers.trainer:{'loss': 3.387643864154816, 'learning_rate': 4.881579454512643e-05, 'epoch': 0.07105232729241463, 'step': 394500}
INFO:transformers.trainer:{'loss': 3.3701329951286314, 'learning_rate': 4.881429365101378e-05, 'epoch': 0.07114238093917308, 'step': 395000}
INFO:transformers.trainer:{'loss': 3.326679127931595, 'learning_rate': 4.8812792756901146e-05, 'epoch': 0.07123243458593154, 'step': 395500}
INFO:transformers.trainer:{'loss': 3.340460068941116, 'learning_rate': 4.8811291862788506e-05, 'epoch': 0.07132248823268998, 'step': 396000}
INFO:transformers.trainer:{'loss': 3.3883142565488815, 'learning_rate': 4.8809790968675865e-05, 'epoch': 0.07141254187944843, 'step': 396500}
INFO:transformers.trainer:{'loss': 3.348576737642288, 'learning_rate': 4.8808290074563224e-05, 'epoch': 0.07150259552620687, 'step': 397000}
INFO:transformers.trainer:{'loss': 3.334364720106125, 'learning_rate': 4.880678918045058e-05, 'epoch': 0.07159264917296532, 'step': 397500}
INFO:transformers.trainer:{'loss': 3.3637877761125563, 'learning_rate': 4.880528828633794e-05, 'epoch': 0.07168270281972376, 'step': 398000}
INFO:transformers.trainer:{'loss': 3.3816793196201322, 'learning_rate': 4.88037873922253e-05, 'epoch': 0.07177275646648221, 'step': 398500}
INFO:transformers.trainer:{'loss': 3.3906374592781066, 'learning_rate': 4.880228649811266e-05, 'epoch': 0.07186281011324067, 'step': 399000}
INFO:transformers.trainer:{'loss': 3.3654184114933012, 'learning_rate': 4.880078560400002e-05, 'epoch': 0.07195286375999911, 'step': 399500}
INFO:transformers.trainer:{'loss': 3.4236087691783905, 'learning_rate': 4.879928470988738e-05, 'epoch': 0.07204291740675756, 'step': 400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.430339071750641, 'learning_rate': 4.879778381577473e-05, 'epoch': 0.072132971053516, 'step': 400500}
INFO:transformers.trainer:{'loss': 3.3610907537937162, 'learning_rate': 4.8796282921662096e-05, 'epoch': 0.07222302470027445, 'step': 401000}
INFO:transformers.trainer:{'loss': 3.332782480478287, 'learning_rate': 4.879478202754945e-05, 'epoch': 0.07231307834703289, 'step': 401500}
INFO:transformers.trainer:{'loss': 3.3845389573574067, 'learning_rate': 4.8793281133436814e-05, 'epoch': 0.07240313199379134, 'step': 402000}
INFO:transformers.trainer:{'loss': 3.3617391090393065, 'learning_rate': 4.879178023932417e-05, 'epoch': 0.07249318564054978, 'step': 402500}
INFO:transformers.trainer:{'loss': 3.392173533439636, 'learning_rate': 4.879027934521153e-05, 'epoch': 0.07258323928730824, 'step': 403000}
INFO:transformers.trainer:{'loss': 3.3573373024463655, 'learning_rate': 4.878877845109889e-05, 'epoch': 0.07267329293406669, 'step': 403500}
INFO:transformers.trainer:{'loss': 3.3110616490840914, 'learning_rate': 4.878727755698625e-05, 'epoch': 0.07276334658082513, 'step': 404000}
INFO:transformers.trainer:{'loss': 3.357489826440811, 'learning_rate': 4.878577666287361e-05, 'epoch': 0.07285340022758358, 'step': 404500}
INFO:transformers.trainer:{'loss': 3.3713872940540313, 'learning_rate': 4.878427576876097e-05, 'epoch': 0.07294345387434202, 'step': 405000}
INFO:transformers.trainer:{'loss': 3.336076490879059, 'learning_rate': 4.878277487464833e-05, 'epoch': 0.07303350752110047, 'step': 405500}
INFO:transformers.trainer:{'loss': 3.363241734266281, 'learning_rate': 4.8781273980535687e-05, 'epoch': 0.07312356116785891, 'step': 406000}
INFO:transformers.trainer:{'loss': 3.33415812510252, 'learning_rate': 4.8779773086423046e-05, 'epoch': 0.07321361481461737, 'step': 406500}
INFO:transformers.trainer:{'loss': 3.321820083141327, 'learning_rate': 4.8778272192310405e-05, 'epoch': 0.07330366846137581, 'step': 407000}
INFO:transformers.trainer:{'loss': 3.393796441078186, 'learning_rate': 4.8776771298197764e-05, 'epoch': 0.07339372210813426, 'step': 407500}
INFO:transformers.trainer:{'loss': 3.367074858427048, 'learning_rate': 4.877527040408512e-05, 'epoch': 0.0734837757548927, 'step': 408000}
INFO:transformers.trainer:{'loss': 3.290073354244232, 'learning_rate': 4.877376950997248e-05, 'epoch': 0.07357382940165115, 'step': 408500}
INFO:transformers.trainer:{'loss': 3.3910537484884262, 'learning_rate': 4.877226861585984e-05, 'epoch': 0.0736638830484096, 'step': 409000}
INFO:transformers.trainer:{'loss': 3.4187514214515686, 'learning_rate': 4.87707677217472e-05, 'epoch': 0.07375393669516804, 'step': 409500}
INFO:transformers.trainer:{'loss': 3.354863297700882, 'learning_rate': 4.8769266827634566e-05, 'epoch': 0.0738439903419265, 'step': 410000}
INFO:transformers.trainer:{'loss': 3.375913690328598, 'learning_rate': 4.876776593352192e-05, 'epoch': 0.07393404398868494, 'step': 410500}
INFO:transformers.trainer:{'loss': 3.3573139412403106, 'learning_rate': 4.8766265039409284e-05, 'epoch': 0.07402409763544339, 'step': 411000}
INFO:transformers.trainer:{'loss': 3.402382316112518, 'learning_rate': 4.8764764145296636e-05, 'epoch': 0.07411415128220183, 'step': 411500}
INFO:transformers.trainer:{'loss': 3.374288554906845, 'learning_rate': 4.8763263251184e-05, 'epoch': 0.07420420492896028, 'step': 412000}
INFO:transformers.trainer:{'loss': 3.410484705686569, 'learning_rate': 4.8761762357071354e-05, 'epoch': 0.07429425857571872, 'step': 412500}
INFO:transformers.trainer:{'loss': 3.379077826499939, 'learning_rate': 4.876026146295872e-05, 'epoch': 0.07438431222247717, 'step': 413000}
INFO:transformers.trainer:{'loss': 3.351522936105728, 'learning_rate': 4.875876056884607e-05, 'epoch': 0.07447436586923561, 'step': 413500}
INFO:transformers.trainer:{'loss': 3.370356549739838, 'learning_rate': 4.875725967473344e-05, 'epoch': 0.07456441951599407, 'step': 414000}
INFO:transformers.trainer:{'loss': 3.3646516349315645, 'learning_rate': 4.875575878062079e-05, 'epoch': 0.07465447316275252, 'step': 414500}
INFO:transformers.trainer:{'loss': 3.377753143787384, 'learning_rate': 4.8754257886508156e-05, 'epoch': 0.07474452680951096, 'step': 415000}
INFO:transformers.trainer:{'loss': 3.3258432726860048, 'learning_rate': 4.875275699239551e-05, 'epoch': 0.07483458045626941, 'step': 415500}
INFO:transformers.trainer:{'loss': 3.4234911305904387, 'learning_rate': 4.8751256098282874e-05, 'epoch': 0.07492463410302785, 'step': 416000}
INFO:transformers.trainer:{'loss': 3.385102025151253, 'learning_rate': 4.874975520417023e-05, 'epoch': 0.0750146877497863, 'step': 416500}
INFO:transformers.trainer:{'loss': 3.357022624015808, 'learning_rate': 4.874825431005759e-05, 'epoch': 0.07510474139654474, 'step': 417000}
INFO:transformers.trainer:{'loss': 3.350106295824051, 'learning_rate': 4.874675341594495e-05, 'epoch': 0.0751947950433032, 'step': 417500}
INFO:transformers.trainer:{'loss': 3.373534072637558, 'learning_rate': 4.874525252183231e-05, 'epoch': 0.07528484869006165, 'step': 418000}
INFO:transformers.trainer:{'loss': 3.3899695591926573, 'learning_rate': 4.874375162771967e-05, 'epoch': 0.0753749023368201, 'step': 418500}
INFO:transformers.trainer:{'loss': 3.3826208856105806, 'learning_rate': 4.874225073360703e-05, 'epoch': 0.07546495598357854, 'step': 419000}
INFO:transformers.trainer:{'loss': 3.352513880491257, 'learning_rate': 4.874074983949439e-05, 'epoch': 0.07555500963033698, 'step': 419500}
INFO:transformers.trainer:{'loss': 3.3957686190605165, 'learning_rate': 4.873924894538175e-05, 'epoch': 0.07564506327709543, 'step': 420000}
INFO:transformers.trainer:{'loss': 3.3915330295562742, 'learning_rate': 4.8737748051269106e-05, 'epoch': 0.07573511692385387, 'step': 420500}
INFO:transformers.trainer:{'loss': 3.3049634556770324, 'learning_rate': 4.8736247157156465e-05, 'epoch': 0.07582517057061232, 'step': 421000}
INFO:transformers.trainer:{'loss': 3.3781116015911103, 'learning_rate': 4.8734746263043824e-05, 'epoch': 0.07591522421737078, 'step': 421500}
INFO:transformers.trainer:{'loss': 3.3573916667699812, 'learning_rate': 4.873324536893118e-05, 'epoch': 0.07600527786412922, 'step': 422000}
INFO:transformers.trainer:{'loss': 3.3698710434436796, 'learning_rate': 4.873174447481854e-05, 'epoch': 0.07609533151088767, 'step': 422500}
INFO:transformers.trainer:{'loss': 3.3920111713409424, 'learning_rate': 4.87302435807059e-05, 'epoch': 0.07618538515764611, 'step': 423000}
INFO:transformers.trainer:{'loss': 3.388131854057312, 'learning_rate': 4.872874268659326e-05, 'epoch': 0.07627543880440456, 'step': 423500}
INFO:transformers.trainer:{'loss': 3.3898388657569885, 'learning_rate': 4.872724179248062e-05, 'epoch': 0.076365492451163, 'step': 424000}
INFO:transformers.trainer:{'loss': 3.3500205318927767, 'learning_rate': 4.872574089836798e-05, 'epoch': 0.07645554609792145, 'step': 424500}
INFO:transformers.trainer:{'loss': 3.3327228803634643, 'learning_rate': 4.872424000425534e-05, 'epoch': 0.0765455997446799, 'step': 425000}
INFO:transformers.trainer:{'loss': 3.4110663733482363, 'learning_rate': 4.8722739110142696e-05, 'epoch': 0.07663565339143835, 'step': 425500}
INFO:transformers.trainer:{'loss': 3.3859338994026182, 'learning_rate': 4.8721238216030055e-05, 'epoch': 0.0767257070381968, 'step': 426000}
INFO:transformers.trainer:{'loss': 3.342204428911209, 'learning_rate': 4.8719737321917414e-05, 'epoch': 0.07681576068495524, 'step': 426500}
INFO:transformers.trainer:{'loss': 3.440397367477417, 'learning_rate': 4.8718236427804773e-05, 'epoch': 0.07690581433171369, 'step': 427000}
INFO:transformers.trainer:{'loss': 3.4302106137275694, 'learning_rate': 4.871673553369213e-05, 'epoch': 0.07699586797847213, 'step': 427500}
INFO:transformers.trainer:{'loss': 3.352741052031517, 'learning_rate': 4.871523463957949e-05, 'epoch': 0.07708592162523058, 'step': 428000}
INFO:transformers.trainer:{'loss': 3.3965637946128844, 'learning_rate': 4.871373374546685e-05, 'epoch': 0.07717597527198902, 'step': 428500}
INFO:transformers.trainer:{'loss': 3.3668764626979826, 'learning_rate': 4.871223285135421e-05, 'epoch': 0.07726602891874748, 'step': 429000}
INFO:transformers.trainer:{'loss': 3.3506512372493744, 'learning_rate': 4.871073195724157e-05, 'epoch': 0.07735608256550593, 'step': 429500}
INFO:transformers.trainer:{'loss': 3.3997238795757294, 'learning_rate': 4.870923106312893e-05, 'epoch': 0.07744613621226437, 'step': 430000}
INFO:transformers.trainer:{'loss': 3.3965720279216765, 'learning_rate': 4.8707730169016294e-05, 'epoch': 0.07753618985902282, 'step': 430500}
INFO:transformers.trainer:{'loss': 3.3703527851104735, 'learning_rate': 4.8706229274903646e-05, 'epoch': 0.07762624350578126, 'step': 431000}
INFO:transformers.trainer:{'loss': 3.380631761074066, 'learning_rate': 4.870472838079101e-05, 'epoch': 0.0777162971525397, 'step': 431500}
INFO:transformers.trainer:{'loss': 3.3424762020111083, 'learning_rate': 4.8703227486678364e-05, 'epoch': 0.07780635079929815, 'step': 432000}
INFO:transformers.trainer:{'loss': 3.4144731559753416, 'learning_rate': 4.870172659256573e-05, 'epoch': 0.07789640444605661, 'step': 432500}
INFO:transformers.trainer:{'loss': 3.30527525138855, 'learning_rate': 4.870022569845308e-05, 'epoch': 0.07798645809281506, 'step': 433000}
INFO:transformers.trainer:{'loss': 3.3966927993297578, 'learning_rate': 4.869872480434045e-05, 'epoch': 0.0780765117395735, 'step': 433500}
INFO:transformers.trainer:{'loss': 3.377137666940689, 'learning_rate': 4.86972239102278e-05, 'epoch': 0.07816656538633195, 'step': 434000}
INFO:transformers.trainer:{'loss': 3.3375534060001373, 'learning_rate': 4.8695723016115166e-05, 'epoch': 0.07825661903309039, 'step': 434500}
INFO:transformers.trainer:{'loss': 3.4193480501174927, 'learning_rate': 4.869422212200252e-05, 'epoch': 0.07834667267984884, 'step': 435000}
INFO:transformers.trainer:{'loss': 3.3993626625537874, 'learning_rate': 4.8692721227889884e-05, 'epoch': 0.07843672632660728, 'step': 435500}
INFO:transformers.trainer:{'loss': 3.3314290455579756, 'learning_rate': 4.8691220333777236e-05, 'epoch': 0.07852677997336574, 'step': 436000}
INFO:transformers.trainer:{'loss': 3.3531223475933074, 'learning_rate': 4.86897194396646e-05, 'epoch': 0.07861683362012419, 'step': 436500}
INFO:transformers.trainer:{'loss': 3.3562002947330476, 'learning_rate': 4.868821854555196e-05, 'epoch': 0.07870688726688263, 'step': 437000}
INFO:transformers.trainer:{'loss': 3.331387221813202, 'learning_rate': 4.868671765143932e-05, 'epoch': 0.07879694091364108, 'step': 437500}
INFO:transformers.trainer:{'loss': 3.3678809335231783, 'learning_rate': 4.868521675732668e-05, 'epoch': 0.07888699456039952, 'step': 438000}
INFO:transformers.trainer:{'loss': 3.3711008462905885, 'learning_rate': 4.868371586321404e-05, 'epoch': 0.07897704820715797, 'step': 438500}
INFO:transformers.trainer:{'loss': 3.3879611353874206, 'learning_rate': 4.86822149691014e-05, 'epoch': 0.07906710185391641, 'step': 439000}
INFO:transformers.trainer:{'loss': 3.3623949363231658, 'learning_rate': 4.8680714074988756e-05, 'epoch': 0.07915715550067486, 'step': 439500}
INFO:transformers.trainer:{'loss': 3.401543650150299, 'learning_rate': 4.8679213180876116e-05, 'epoch': 0.07924720914743331, 'step': 440000}
INFO:transformers.trainer:{'loss': 3.338328627586365, 'learning_rate': 4.8677712286763475e-05, 'epoch': 0.07933726279419176, 'step': 440500}
INFO:transformers.trainer:{'loss': 3.3281642696857454, 'learning_rate': 4.8676211392650834e-05, 'epoch': 0.0794273164409502, 'step': 441000}
INFO:transformers.trainer:{'loss': 3.384994333267212, 'learning_rate': 4.867471049853819e-05, 'epoch': 0.07951737008770865, 'step': 441500}
INFO:transformers.trainer:{'loss': 3.3663530242443085, 'learning_rate': 4.867320960442555e-05, 'epoch': 0.0796074237344671, 'step': 442000}
INFO:transformers.trainer:{'loss': 3.357563999414444, 'learning_rate': 4.867170871031291e-05, 'epoch': 0.07969747738122554, 'step': 442500}
INFO:transformers.trainer:{'loss': 3.354279420852661, 'learning_rate': 4.867020781620027e-05, 'epoch': 0.07978753102798398, 'step': 443000}
INFO:transformers.trainer:{'loss': 3.4858290059566497, 'learning_rate': 4.866870692208763e-05, 'epoch': 0.07987758467474244, 'step': 443500}
INFO:transformers.trainer:{'loss': 3.42139113175869, 'learning_rate': 4.866720602797499e-05, 'epoch': 0.07996763832150089, 'step': 444000}
INFO:transformers.trainer:{'loss': 3.392062719345093, 'learning_rate': 4.866570513386235e-05, 'epoch': 0.08005769196825933, 'step': 444500}
INFO:transformers.trainer:{'loss': 3.3779768233299254, 'learning_rate': 4.8664204239749706e-05, 'epoch': 0.08014774561501778, 'step': 445000}
INFO:transformers.trainer:{'loss': 3.3336677477359773, 'learning_rate': 4.8662703345637065e-05, 'epoch': 0.08023779926177622, 'step': 445500}
INFO:transformers.trainer:{'loss': 3.3731695294380186, 'learning_rate': 4.8661202451524424e-05, 'epoch': 0.08032785290853467, 'step': 446000}
INFO:transformers.trainer:{'loss': 3.3691598315238953, 'learning_rate': 4.865970155741178e-05, 'epoch': 0.08041790655529311, 'step': 446500}
INFO:transformers.trainer:{'loss': 3.3808294467926023, 'learning_rate': 4.865820066329914e-05, 'epoch': 0.08050796020205156, 'step': 447000}
INFO:transformers.trainer:{'loss': 3.3574105994701386, 'learning_rate': 4.86566997691865e-05, 'epoch': 0.08059801384881002, 'step': 447500}
INFO:transformers.trainer:{'loss': 3.4379891531467437, 'learning_rate': 4.865519887507386e-05, 'epoch': 0.08068806749556846, 'step': 448000}
INFO:transformers.trainer:{'loss': 3.3687166588306425, 'learning_rate': 4.865369798096122e-05, 'epoch': 0.08077812114232691, 'step': 448500}
INFO:transformers.trainer:{'loss': 3.3782039905786516, 'learning_rate': 4.865219708684858e-05, 'epoch': 0.08086817478908535, 'step': 449000}
INFO:transformers.trainer:{'loss': 3.357245037317276, 'learning_rate': 4.865069619273594e-05, 'epoch': 0.0809582284358438, 'step': 449500}
INFO:transformers.trainer:{'loss': 3.4432168118953705, 'learning_rate': 4.8649195298623297e-05, 'epoch': 0.08104828208260224, 'step': 450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3925664415359496, 'learning_rate': 4.8647694404510656e-05, 'epoch': 0.08113833572936069, 'step': 450500}
INFO:transformers.trainer:{'loss': 3.380766684770584, 'learning_rate': 4.864619351039802e-05, 'epoch': 0.08122838937611915, 'step': 451000}
INFO:transformers.trainer:{'loss': 3.3844169063568117, 'learning_rate': 4.8644692616285374e-05, 'epoch': 0.08131844302287759, 'step': 451500}
INFO:transformers.trainer:{'loss': 3.4588821034431456, 'learning_rate': 4.864319172217274e-05, 'epoch': 0.08140849666963604, 'step': 452000}
INFO:transformers.trainer:{'loss': 3.34180614900589, 'learning_rate': 4.864169082806009e-05, 'epoch': 0.08149855031639448, 'step': 452500}
INFO:transformers.trainer:{'loss': 3.3746816363334657, 'learning_rate': 4.864018993394746e-05, 'epoch': 0.08158860396315293, 'step': 453000}
INFO:transformers.trainer:{'loss': 3.3945565268993376, 'learning_rate': 4.863868903983481e-05, 'epoch': 0.08167865760991137, 'step': 453500}
INFO:transformers.trainer:{'loss': 3.3317398896217347, 'learning_rate': 4.8637188145722176e-05, 'epoch': 0.08176871125666982, 'step': 454000}
INFO:transformers.trainer:{'loss': 3.4032980711460112, 'learning_rate': 4.863568725160953e-05, 'epoch': 0.08185876490342828, 'step': 454500}
INFO:transformers.trainer:{'loss': 3.407073590040207, 'learning_rate': 4.8634186357496894e-05, 'epoch': 0.08194881855018672, 'step': 455000}
INFO:transformers.trainer:{'loss': 3.3769407974481584, 'learning_rate': 4.8632685463384246e-05, 'epoch': 0.08203887219694517, 'step': 455500}
INFO:transformers.trainer:{'loss': 3.3495902016162873, 'learning_rate': 4.863118456927161e-05, 'epoch': 0.08212892584370361, 'step': 456000}
INFO:transformers.trainer:{'loss': 3.3806193227767944, 'learning_rate': 4.8629683675158964e-05, 'epoch': 0.08221897949046206, 'step': 456500}
INFO:transformers.trainer:{'loss': 3.3428807060718535, 'learning_rate': 4.862818278104633e-05, 'epoch': 0.0823090331372205, 'step': 457000}
INFO:transformers.trainer:{'loss': 3.3010608522891998, 'learning_rate': 4.862668188693368e-05, 'epoch': 0.08239908678397895, 'step': 457500}
INFO:transformers.trainer:{'loss': 3.3291636953353883, 'learning_rate': 4.862518099282105e-05, 'epoch': 0.08248914043073739, 'step': 458000}
INFO:transformers.trainer:{'loss': 3.347546337842941, 'learning_rate': 4.862368009870841e-05, 'epoch': 0.08257919407749585, 'step': 458500}
INFO:transformers.trainer:{'loss': 3.386350653409958, 'learning_rate': 4.8622179204595766e-05, 'epoch': 0.0826692477242543, 'step': 459000}
INFO:transformers.trainer:{'loss': 3.368879891872406, 'learning_rate': 4.8620678310483125e-05, 'epoch': 0.08275930137101274, 'step': 459500}
INFO:transformers.trainer:{'loss': 3.400978932380676, 'learning_rate': 4.8619177416370484e-05, 'epoch': 0.08284935501777119, 'step': 460000}
INFO:transformers.trainer:{'loss': 3.4445780372619628, 'learning_rate': 4.861767652225784e-05, 'epoch': 0.08293940866452963, 'step': 460500}
INFO:transformers.trainer:{'loss': 3.3430988433361053, 'learning_rate': 4.86161756281452e-05, 'epoch': 0.08302946231128808, 'step': 461000}
INFO:transformers.trainer:{'loss': 3.3453153960704802, 'learning_rate': 4.861467473403256e-05, 'epoch': 0.08311951595804652, 'step': 461500}
INFO:transformers.trainer:{'loss': 3.391918244481087, 'learning_rate': 4.861317383991992e-05, 'epoch': 0.08320956960480498, 'step': 462000}
INFO:transformers.trainer:{'loss': 3.3684465296268464, 'learning_rate': 4.861167294580728e-05, 'epoch': 0.08329962325156343, 'step': 462500}
INFO:transformers.trainer:{'loss': 3.4265946576595305, 'learning_rate': 4.861017205169464e-05, 'epoch': 0.08338967689832187, 'step': 463000}
INFO:transformers.trainer:{'loss': 3.363752071142197, 'learning_rate': 4.8608671157582e-05, 'epoch': 0.08347973054508032, 'step': 463500}
INFO:transformers.trainer:{'loss': 3.370712583065033, 'learning_rate': 4.860717026346936e-05, 'epoch': 0.08356978419183876, 'step': 464000}
INFO:transformers.trainer:{'loss': 3.387115329027176, 'learning_rate': 4.8605669369356716e-05, 'epoch': 0.0836598378385972, 'step': 464500}
INFO:transformers.trainer:{'loss': 3.384562546491623, 'learning_rate': 4.8604168475244075e-05, 'epoch': 0.08374989148535565, 'step': 465000}
INFO:transformers.trainer:{'loss': 3.3836007764339446, 'learning_rate': 4.8602667581131434e-05, 'epoch': 0.0838399451321141, 'step': 465500}
INFO:transformers.trainer:{'loss': 3.382786678314209, 'learning_rate': 4.860116668701879e-05, 'epoch': 0.08392999877887256, 'step': 466000}
INFO:transformers.trainer:{'loss': 3.348653228998184, 'learning_rate': 4.859966579290615e-05, 'epoch': 0.084020052425631, 'step': 466500}
INFO:transformers.trainer:{'loss': 3.3781361918449404, 'learning_rate': 4.859816489879351e-05, 'epoch': 0.08411010607238945, 'step': 467000}
INFO:transformers.trainer:{'loss': 3.333832927942276, 'learning_rate': 4.859666400468087e-05, 'epoch': 0.08420015971914789, 'step': 467500}
INFO:transformers.trainer:{'loss': 3.37111003613472, 'learning_rate': 4.859516311056823e-05, 'epoch': 0.08429021336590634, 'step': 468000}
INFO:transformers.trainer:{'loss': 3.3348607313632965, 'learning_rate': 4.859366221645559e-05, 'epoch': 0.08438026701266478, 'step': 468500}
INFO:transformers.trainer:{'loss': 3.3839757318496706, 'learning_rate': 4.859216132234295e-05, 'epoch': 0.08447032065942323, 'step': 469000}
INFO:transformers.trainer:{'loss': 3.375214832544327, 'learning_rate': 4.8590660428230306e-05, 'epoch': 0.08456037430618168, 'step': 469500}
INFO:transformers.trainer:{'loss': 3.3498082122802733, 'learning_rate': 4.8589159534117665e-05, 'epoch': 0.08465042795294013, 'step': 470000}
INFO:transformers.trainer:{'loss': 3.399638088941574, 'learning_rate': 4.8587658640005024e-05, 'epoch': 0.08474048159969857, 'step': 470500}
INFO:transformers.trainer:{'loss': 3.3736306269168854, 'learning_rate': 4.858615774589238e-05, 'epoch': 0.08483053524645702, 'step': 471000}
INFO:transformers.trainer:{'loss': 3.3065838723182677, 'learning_rate': 4.858465685177974e-05, 'epoch': 0.08492058889321547, 'step': 471500}
INFO:transformers.trainer:{'loss': 3.337343410015106, 'learning_rate': 4.85831559576671e-05, 'epoch': 0.08501064253997391, 'step': 472000}
INFO:transformers.trainer:{'loss': 3.336403685569763, 'learning_rate': 4.858165506355447e-05, 'epoch': 0.08510069618673236, 'step': 472500}
INFO:transformers.trainer:{'loss': 3.4389595514535904, 'learning_rate': 4.858015416944182e-05, 'epoch': 0.0851907498334908, 'step': 473000}
INFO:transformers.trainer:{'loss': 3.3949650189876555, 'learning_rate': 4.8578653275329185e-05, 'epoch': 0.08528080348024926, 'step': 473500}
INFO:transformers.trainer:{'loss': 3.4369209742546083, 'learning_rate': 4.857715238121654e-05, 'epoch': 0.0853708571270077, 'step': 474000}
INFO:transformers.trainer:{'loss': 3.3621386075019837, 'learning_rate': 4.8575651487103904e-05, 'epoch': 0.08546091077376615, 'step': 474500}
INFO:transformers.trainer:{'loss': 3.3257863335609437, 'learning_rate': 4.8574150592991256e-05, 'epoch': 0.0855509644205246, 'step': 475000}
INFO:transformers.trainer:{'loss': 3.339958196282387, 'learning_rate': 4.857264969887862e-05, 'epoch': 0.08564101806728304, 'step': 475500}
INFO:transformers.trainer:{'loss': 3.4257071528434753, 'learning_rate': 4.8571148804765974e-05, 'epoch': 0.08573107171404148, 'step': 476000}
INFO:transformers.trainer:{'loss': 3.4052959518432617, 'learning_rate': 4.856964791065334e-05, 'epoch': 0.08582112536079993, 'step': 476500}
INFO:transformers.trainer:{'loss': 3.348270693063736, 'learning_rate': 4.856814701654069e-05, 'epoch': 0.08591117900755839, 'step': 477000}
INFO:transformers.trainer:{'loss': 3.401353216648102, 'learning_rate': 4.856664612242806e-05, 'epoch': 0.08600123265431683, 'step': 477500}
INFO:transformers.trainer:{'loss': 3.4353851432800293, 'learning_rate': 4.856514522831541e-05, 'epoch': 0.08609128630107528, 'step': 478000}
INFO:transformers.trainer:{'loss': 3.4194991207122802, 'learning_rate': 4.8563644334202776e-05, 'epoch': 0.08618133994783372, 'step': 478500}
INFO:transformers.trainer:{'loss': 3.363615997314453, 'learning_rate': 4.8562143440090135e-05, 'epoch': 0.08627139359459217, 'step': 479000}
INFO:transformers.trainer:{'loss': 3.3586197504997255, 'learning_rate': 4.8560642545977494e-05, 'epoch': 0.08636144724135061, 'step': 479500}
INFO:transformers.trainer:{'loss': 3.30477574467659, 'learning_rate': 4.855914165186485e-05, 'epoch': 0.08645150088810906, 'step': 480000}
INFO:transformers.trainer:{'loss': 3.398595639228821, 'learning_rate': 4.855764075775221e-05, 'epoch': 0.08654155453486752, 'step': 480500}
INFO:transformers.trainer:{'loss': 3.31053596329689, 'learning_rate': 4.855613986363957e-05, 'epoch': 0.08663160818162596, 'step': 481000}
INFO:transformers.trainer:{'loss': 3.3817740244865417, 'learning_rate': 4.855463896952693e-05, 'epoch': 0.08672166182838441, 'step': 481500}
INFO:transformers.trainer:{'loss': 3.362175749063492, 'learning_rate': 4.855313807541429e-05, 'epoch': 0.08681171547514285, 'step': 482000}
INFO:transformers.trainer:{'loss': 3.325153577327728, 'learning_rate': 4.855163718130165e-05, 'epoch': 0.0869017691219013, 'step': 482500}
INFO:transformers.trainer:{'loss': 3.362351181268692, 'learning_rate': 4.855013628718901e-05, 'epoch': 0.08699182276865974, 'step': 483000}
INFO:transformers.trainer:{'loss': 3.327213464021683, 'learning_rate': 4.8548635393076366e-05, 'epoch': 0.08708187641541819, 'step': 483500}
INFO:transformers.trainer:{'loss': 3.437266522884369, 'learning_rate': 4.8547134498963725e-05, 'epoch': 0.08717193006217663, 'step': 484000}
INFO:transformers.trainer:{'loss': 3.4000316252708433, 'learning_rate': 4.8545633604851085e-05, 'epoch': 0.08726198370893509, 'step': 484500}
INFO:transformers.trainer:{'loss': 3.352182208657265, 'learning_rate': 4.8544132710738444e-05, 'epoch': 0.08735203735569354, 'step': 485000}
INFO:transformers.trainer:{'loss': 3.413022458553314, 'learning_rate': 4.85426318166258e-05, 'epoch': 0.08744209100245198, 'step': 485500}
INFO:transformers.trainer:{'loss': 3.3560943403244017, 'learning_rate': 4.854113092251316e-05, 'epoch': 0.08753214464921043, 'step': 486000}
INFO:transformers.trainer:{'loss': 3.391194437265396, 'learning_rate': 4.853963002840052e-05, 'epoch': 0.08762219829596887, 'step': 486500}
INFO:transformers.trainer:{'loss': 3.411989558696747, 'learning_rate': 4.853812913428788e-05, 'epoch': 0.08771225194272732, 'step': 487000}
INFO:transformers.trainer:{'loss': 3.360827253103256, 'learning_rate': 4.853662824017524e-05, 'epoch': 0.08780230558948576, 'step': 487500}
INFO:transformers.trainer:{'loss': 3.380840092897415, 'learning_rate': 4.85351273460626e-05, 'epoch': 0.08789235923624422, 'step': 488000}
INFO:transformers.trainer:{'loss': 3.350900766968727, 'learning_rate': 4.853362645194996e-05, 'epoch': 0.08798241288300267, 'step': 488500}
INFO:transformers.trainer:{'loss': 3.330447821378708, 'learning_rate': 4.8532125557837316e-05, 'epoch': 0.08807246652976111, 'step': 489000}
INFO:transformers.trainer:{'loss': 3.395139575481415, 'learning_rate': 4.8530624663724675e-05, 'epoch': 0.08816252017651956, 'step': 489500}
INFO:transformers.trainer:{'loss': 3.3995642836093904, 'learning_rate': 4.8529123769612034e-05, 'epoch': 0.088252573823278, 'step': 490000}
INFO:transformers.trainer:{'loss': 3.4377085609436033, 'learning_rate': 4.852762287549939e-05, 'epoch': 0.08834262747003645, 'step': 490500}
INFO:transformers.trainer:{'loss': 3.4063742830753325, 'learning_rate': 4.852612198138675e-05, 'epoch': 0.08843268111679489, 'step': 491000}
INFO:transformers.trainer:{'loss': 3.344198165178299, 'learning_rate': 4.852462108727411e-05, 'epoch': 0.08852273476355334, 'step': 491500}
INFO:transformers.trainer:{'loss': 3.376726140499115, 'learning_rate': 4.852312019316147e-05, 'epoch': 0.0886127884103118, 'step': 492000}
INFO:transformers.trainer:{'loss': 3.3370218908786775, 'learning_rate': 4.852161929904883e-05, 'epoch': 0.08870284205707024, 'step': 492500}
INFO:transformers.trainer:{'loss': 3.4029078116416933, 'learning_rate': 4.8520118404936195e-05, 'epoch': 0.08879289570382869, 'step': 493000}
INFO:transformers.trainer:{'loss': 3.3573480052947997, 'learning_rate': 4.851861751082355e-05, 'epoch': 0.08888294935058713, 'step': 493500}
INFO:transformers.trainer:{'loss': 3.330124174118042, 'learning_rate': 4.851711661671091e-05, 'epoch': 0.08897300299734558, 'step': 494000}
INFO:transformers.trainer:{'loss': 3.359396473646164, 'learning_rate': 4.8515615722598266e-05, 'epoch': 0.08906305664410402, 'step': 494500}
INFO:transformers.trainer:{'loss': 3.3100465714931486, 'learning_rate': 4.851411482848563e-05, 'epoch': 0.08915311029086247, 'step': 495000}
INFO:transformers.trainer:{'loss': 3.4166461939811708, 'learning_rate': 4.8512613934372984e-05, 'epoch': 0.08924316393762093, 'step': 495500}
INFO:transformers.trainer:{'loss': 3.313297559976578, 'learning_rate': 4.851111304026035e-05, 'epoch': 0.08933321758437937, 'step': 496000}
INFO:transformers.trainer:{'loss': 3.3220711381435395, 'learning_rate': 4.85096121461477e-05, 'epoch': 0.08942327123113782, 'step': 496500}
INFO:transformers.trainer:{'loss': 3.3753931357860565, 'learning_rate': 4.850811125203507e-05, 'epoch': 0.08951332487789626, 'step': 497000}
INFO:transformers.trainer:{'loss': 3.3830175111293794, 'learning_rate': 4.850661035792242e-05, 'epoch': 0.0896033785246547, 'step': 497500}
INFO:transformers.trainer:{'loss': 3.369742480278015, 'learning_rate': 4.8505109463809786e-05, 'epoch': 0.08969343217141315, 'step': 498000}
INFO:transformers.trainer:{'loss': 3.3297027928829195, 'learning_rate': 4.850360856969714e-05, 'epoch': 0.0897834858181716, 'step': 498500}
INFO:transformers.trainer:{'loss': 3.3990982501506806, 'learning_rate': 4.8502107675584504e-05, 'epoch': 0.08987353946493004, 'step': 499000}
INFO:transformers.trainer:{'loss': 3.387156826257706, 'learning_rate': 4.850060678147186e-05, 'epoch': 0.0899635931116885, 'step': 499500}
INFO:transformers.trainer:{'loss': 3.3932447245121002, 'learning_rate': 4.849910588735922e-05, 'epoch': 0.09005364675844695, 'step': 500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3430202209949496, 'learning_rate': 4.849760499324658e-05, 'epoch': 0.09014370040520539, 'step': 500500}
INFO:transformers.trainer:{'loss': 3.3882911512851717, 'learning_rate': 4.849610409913394e-05, 'epoch': 0.09023375405196384, 'step': 501000}
INFO:transformers.trainer:{'loss': 3.376338890314102, 'learning_rate': 4.84946032050213e-05, 'epoch': 0.09032380769872228, 'step': 501500}
INFO:transformers.trainer:{'loss': 3.3913657793998717, 'learning_rate': 4.849310231090866e-05, 'epoch': 0.09041386134548073, 'step': 502000}
INFO:transformers.trainer:{'loss': 3.385531871795654, 'learning_rate': 4.849160141679602e-05, 'epoch': 0.09050391499223917, 'step': 502500}
INFO:transformers.trainer:{'loss': 3.383314985871315, 'learning_rate': 4.8490100522683376e-05, 'epoch': 0.09059396863899763, 'step': 503000}
INFO:transformers.trainer:{'loss': 3.376763629436493, 'learning_rate': 4.8488599628570735e-05, 'epoch': 0.09068402228575607, 'step': 503500}
INFO:transformers.trainer:{'loss': 3.3764956123828886, 'learning_rate': 4.8487098734458094e-05, 'epoch': 0.09077407593251452, 'step': 504000}
INFO:transformers.trainer:{'loss': 3.358308181762695, 'learning_rate': 4.848559784034545e-05, 'epoch': 0.09086412957927296, 'step': 504500}
INFO:transformers.trainer:{'loss': 3.4170522015094758, 'learning_rate': 4.848409694623281e-05, 'epoch': 0.09095418322603141, 'step': 505000}
INFO:transformers.trainer:{'loss': 3.3473128910064696, 'learning_rate': 4.848259605212017e-05, 'epoch': 0.09104423687278985, 'step': 505500}
INFO:transformers.trainer:{'loss': 3.3771558430194855, 'learning_rate': 4.848109515800753e-05, 'epoch': 0.0911342905195483, 'step': 506000}
INFO:transformers.trainer:{'loss': 3.4119761362075804, 'learning_rate': 4.847959426389489e-05, 'epoch': 0.09122434416630676, 'step': 506500}
INFO:transformers.trainer:{'loss': 3.3398053138256074, 'learning_rate': 4.847809336978225e-05, 'epoch': 0.0913143978130652, 'step': 507000}
INFO:transformers.trainer:{'loss': 3.3665712292194367, 'learning_rate': 4.847659247566961e-05, 'epoch': 0.09140445145982365, 'step': 507500}
INFO:transformers.trainer:{'loss': 3.3756213705539704, 'learning_rate': 4.847509158155697e-05, 'epoch': 0.0914945051065821, 'step': 508000}
INFO:transformers.trainer:{'loss': 3.359915720701218, 'learning_rate': 4.8473590687444326e-05, 'epoch': 0.09158455875334054, 'step': 508500}
INFO:transformers.trainer:{'loss': 3.3583129606246946, 'learning_rate': 4.8472089793331685e-05, 'epoch': 0.09167461240009898, 'step': 509000}
INFO:transformers.trainer:{'loss': 3.3100855207443236, 'learning_rate': 4.8470588899219044e-05, 'epoch': 0.09176466604685743, 'step': 509500}
INFO:transformers.trainer:{'loss': 3.332367158174515, 'learning_rate': 4.84690880051064e-05, 'epoch': 0.09185471969361587, 'step': 510000}
INFO:transformers.trainer:{'loss': 3.4024029994010925, 'learning_rate': 4.846758711099376e-05, 'epoch': 0.09194477334037433, 'step': 510500}
INFO:transformers.trainer:{'loss': 3.4247839326858522, 'learning_rate': 4.846608621688112e-05, 'epoch': 0.09203482698713278, 'step': 511000}
INFO:transformers.trainer:{'loss': 3.376474399089813, 'learning_rate': 4.846458532276848e-05, 'epoch': 0.09212488063389122, 'step': 511500}
INFO:transformers.trainer:{'loss': 3.366811127662659, 'learning_rate': 4.846308442865584e-05, 'epoch': 0.09221493428064967, 'step': 512000}
INFO:transformers.trainer:{'loss': 3.4313619911670683, 'learning_rate': 4.84615835345432e-05, 'epoch': 0.09230498792740811, 'step': 512500}
INFO:transformers.trainer:{'loss': 3.373512698173523, 'learning_rate': 4.846008264043056e-05, 'epoch': 0.09239504157416656, 'step': 513000}
INFO:transformers.trainer:{'loss': 3.3497344596385954, 'learning_rate': 4.845858174631792e-05, 'epoch': 0.092485095220925, 'step': 513500}
INFO:transformers.trainer:{'loss': 3.386053937911987, 'learning_rate': 4.8457080852205275e-05, 'epoch': 0.09257514886768346, 'step': 514000}
INFO:transformers.trainer:{'loss': 3.4301376399993897, 'learning_rate': 4.845557995809264e-05, 'epoch': 0.09266520251444191, 'step': 514500}
INFO:transformers.trainer:{'loss': 3.3935636781454086, 'learning_rate': 4.845407906397999e-05, 'epoch': 0.09275525616120035, 'step': 515000}
INFO:transformers.trainer:{'loss': 3.4455038828849793, 'learning_rate': 4.845257816986736e-05, 'epoch': 0.0928453098079588, 'step': 515500}
INFO:transformers.trainer:{'loss': 3.3916575474739075, 'learning_rate': 4.845107727575471e-05, 'epoch': 0.09293536345471724, 'step': 516000}
INFO:transformers.trainer:{'loss': 3.358747712135315, 'learning_rate': 4.844957638164208e-05, 'epoch': 0.09302541710147569, 'step': 516500}
INFO:transformers.trainer:{'loss': 3.413030112028122, 'learning_rate': 4.844807548752943e-05, 'epoch': 0.09311547074823413, 'step': 517000}
INFO:transformers.trainer:{'loss': 3.3579425303936006, 'learning_rate': 4.8446574593416795e-05, 'epoch': 0.09320552439499258, 'step': 517500}
INFO:transformers.trainer:{'loss': 3.351118997335434, 'learning_rate': 4.844507369930415e-05, 'epoch': 0.09329557804175104, 'step': 518000}
INFO:transformers.trainer:{'loss': 3.402465271949768, 'learning_rate': 4.8443572805191513e-05, 'epoch': 0.09338563168850948, 'step': 518500}
INFO:transformers.trainer:{'loss': 3.3764512422084807, 'learning_rate': 4.8442071911078866e-05, 'epoch': 0.09347568533526793, 'step': 519000}
INFO:transformers.trainer:{'loss': 3.3431137447357178, 'learning_rate': 4.844057101696623e-05, 'epoch': 0.09356573898202637, 'step': 519500}
INFO:transformers.trainer:{'loss': 3.3367179429531095, 'learning_rate': 4.8439070122853584e-05, 'epoch': 0.09365579262878482, 'step': 520000}
INFO:transformers.trainer:{'loss': 3.324664778828621, 'learning_rate': 4.843756922874095e-05, 'epoch': 0.09374584627554326, 'step': 520500}
INFO:transformers.trainer:{'loss': 3.443121623516083, 'learning_rate': 4.843606833462831e-05, 'epoch': 0.09383589992230171, 'step': 521000}
INFO:transformers.trainer:{'loss': 3.423831081390381, 'learning_rate': 4.843456744051567e-05, 'epoch': 0.09392595356906017, 'step': 521500}
INFO:transformers.trainer:{'loss': 3.3623388822078706, 'learning_rate': 4.843306654640303e-05, 'epoch': 0.09401600721581861, 'step': 522000}
INFO:transformers.trainer:{'loss': 3.3747287249565123, 'learning_rate': 4.8431565652290386e-05, 'epoch': 0.09410606086257706, 'step': 522500}
INFO:transformers.trainer:{'loss': 3.3768061912059784, 'learning_rate': 4.8430064758177745e-05, 'epoch': 0.0941961145093355, 'step': 523000}
INFO:transformers.trainer:{'loss': 3.3325996067523955, 'learning_rate': 4.8428563864065104e-05, 'epoch': 0.09428616815609395, 'step': 523500}
INFO:transformers.trainer:{'loss': 3.351027891397476, 'learning_rate': 4.842706296995246e-05, 'epoch': 0.09437622180285239, 'step': 524000}
INFO:transformers.trainer:{'loss': 3.3976650154590606, 'learning_rate': 4.842556207583982e-05, 'epoch': 0.09446627544961084, 'step': 524500}
INFO:transformers.trainer:{'loss': 3.3470604546070097, 'learning_rate': 4.842406118172718e-05, 'epoch': 0.0945563290963693, 'step': 525000}
INFO:transformers.trainer:{'loss': 3.4097730128765105, 'learning_rate': 4.842256028761454e-05, 'epoch': 0.09464638274312774, 'step': 525500}
INFO:transformers.trainer:{'loss': 3.4415552763938906, 'learning_rate': 4.84210593935019e-05, 'epoch': 0.09473643638988619, 'step': 526000}
INFO:transformers.trainer:{'loss': 3.329157769680023, 'learning_rate': 4.841955849938926e-05, 'epoch': 0.09482649003664463, 'step': 526500}
INFO:transformers.trainer:{'loss': 3.4008875844478608, 'learning_rate': 4.841805760527662e-05, 'epoch': 0.09491654368340308, 'step': 527000}
INFO:transformers.trainer:{'loss': 3.3902078623771668, 'learning_rate': 4.8416556711163976e-05, 'epoch': 0.09500659733016152, 'step': 527500}
INFO:transformers.trainer:{'loss': 3.456724487781525, 'learning_rate': 4.8415055817051335e-05, 'epoch': 0.09509665097691997, 'step': 528000}
INFO:transformers.trainer:{'loss': 3.3387563675642014, 'learning_rate': 4.8413554922938694e-05, 'epoch': 0.09518670462367841, 'step': 528500}
INFO:transformers.trainer:{'loss': 3.359508883714676, 'learning_rate': 4.8412054028826054e-05, 'epoch': 0.09527675827043687, 'step': 529000}
INFO:transformers.trainer:{'loss': 3.365555637359619, 'learning_rate': 4.841055313471341e-05, 'epoch': 0.09536681191719532, 'step': 529500}
INFO:transformers.trainer:{'loss': 3.3807761247158052, 'learning_rate': 4.840905224060077e-05, 'epoch': 0.09545686556395376, 'step': 530000}
INFO:transformers.trainer:{'loss': 3.3371916239261625, 'learning_rate': 4.840755134648813e-05, 'epoch': 0.0955469192107122, 'step': 530500}
INFO:transformers.trainer:{'loss': 3.4089019684791566, 'learning_rate': 4.840605045237549e-05, 'epoch': 0.09563697285747065, 'step': 531000}
INFO:transformers.trainer:{'loss': 3.355962548971176, 'learning_rate': 4.840454955826285e-05, 'epoch': 0.0957270265042291, 'step': 531500}
INFO:transformers.trainer:{'loss': 3.326386858701706, 'learning_rate': 4.840304866415021e-05, 'epoch': 0.09581708015098754, 'step': 532000}
INFO:transformers.trainer:{'loss': 3.38653459751606, 'learning_rate': 4.840154777003757e-05, 'epoch': 0.095907133797746, 'step': 532500}
INFO:transformers.trainer:{'loss': 3.391768310070038, 'learning_rate': 4.8400046875924926e-05, 'epoch': 0.09599718744450444, 'step': 533000}
INFO:transformers.trainer:{'loss': 3.3705090427398683, 'learning_rate': 4.8398545981812285e-05, 'epoch': 0.09608724109126289, 'step': 533500}
INFO:transformers.trainer:{'loss': 3.3355933065414427, 'learning_rate': 4.839704508769965e-05, 'epoch': 0.09617729473802133, 'step': 534000}
INFO:transformers.trainer:{'loss': 3.381072814702988, 'learning_rate': 4.8395544193587e-05, 'epoch': 0.09626734838477978, 'step': 534500}
INFO:transformers.trainer:{'loss': 3.3959780144691467, 'learning_rate': 4.839404329947437e-05, 'epoch': 0.09635740203153823, 'step': 535000}
INFO:transformers.trainer:{'loss': 3.4146181221008303, 'learning_rate': 4.839254240536172e-05, 'epoch': 0.09644745567829667, 'step': 535500}
INFO:transformers.trainer:{'loss': 3.416241145372391, 'learning_rate': 4.839104151124909e-05, 'epoch': 0.09653750932505512, 'step': 536000}
INFO:transformers.trainer:{'loss': 3.4076749036312104, 'learning_rate': 4.838954061713644e-05, 'epoch': 0.09662756297181357, 'step': 536500}
INFO:transformers.trainer:{'loss': 3.3877605113983154, 'learning_rate': 4.8388039723023805e-05, 'epoch': 0.09671761661857202, 'step': 537000}
INFO:transformers.trainer:{'loss': 3.3572709906101226, 'learning_rate': 4.838653882891116e-05, 'epoch': 0.09680767026533046, 'step': 537500}
INFO:transformers.trainer:{'loss': 3.348128121137619, 'learning_rate': 4.838503793479852e-05, 'epoch': 0.09689772391208891, 'step': 538000}
INFO:transformers.trainer:{'loss': 3.392449977874756, 'learning_rate': 4.8383537040685875e-05, 'epoch': 0.09698777755884735, 'step': 538500}
INFO:transformers.trainer:{'loss': 3.3685690903663636, 'learning_rate': 4.838203614657324e-05, 'epoch': 0.0970778312056058, 'step': 539000}
INFO:transformers.trainer:{'loss': 3.3766794254779815, 'learning_rate': 4.8380535252460594e-05, 'epoch': 0.09716788485236424, 'step': 539500}
INFO:transformers.trainer:{'loss': 3.394836047887802, 'learning_rate': 4.837903435834796e-05, 'epoch': 0.0972579384991227, 'step': 540000}
INFO:transformers.trainer:{'loss': 3.4096066048145293, 'learning_rate': 4.837753346423531e-05, 'epoch': 0.09734799214588115, 'step': 540500}
INFO:transformers.trainer:{'loss': 3.3353551881313326, 'learning_rate': 4.837603257012268e-05, 'epoch': 0.0974380457926396, 'step': 541000}
INFO:transformers.trainer:{'loss': 3.3343962144851687, 'learning_rate': 4.8374531676010037e-05, 'epoch': 0.09752809943939804, 'step': 541500}
INFO:transformers.trainer:{'loss': 3.351213804244995, 'learning_rate': 4.8373030781897396e-05, 'epoch': 0.09761815308615648, 'step': 542000}
INFO:transformers.trainer:{'loss': 3.389467980623245, 'learning_rate': 4.8371529887784755e-05, 'epoch': 0.09770820673291493, 'step': 542500}
INFO:transformers.trainer:{'loss': 3.444636309862137, 'learning_rate': 4.8370028993672114e-05, 'epoch': 0.09779826037967337, 'step': 543000}
INFO:transformers.trainer:{'loss': 3.348763330936432, 'learning_rate': 4.836852809955947e-05, 'epoch': 0.09788831402643182, 'step': 543500}
INFO:transformers.trainer:{'loss': 3.379353452205658, 'learning_rate': 4.836702720544683e-05, 'epoch': 0.09797836767319028, 'step': 544000}
INFO:transformers.trainer:{'loss': 3.3889794661998747, 'learning_rate': 4.836552631133419e-05, 'epoch': 0.09806842131994872, 'step': 544500}
INFO:transformers.trainer:{'loss': 3.36529975438118, 'learning_rate': 4.836402541722155e-05, 'epoch': 0.09815847496670717, 'step': 545000}
INFO:transformers.trainer:{'loss': 3.342871728181839, 'learning_rate': 4.836252452310891e-05, 'epoch': 0.09824852861346561, 'step': 545500}
INFO:transformers.trainer:{'loss': 3.3458638231754305, 'learning_rate': 4.836102362899627e-05, 'epoch': 0.09833858226022406, 'step': 546000}
INFO:transformers.trainer:{'loss': 3.373585409283638, 'learning_rate': 4.835952273488363e-05, 'epoch': 0.0984286359069825, 'step': 546500}
INFO:transformers.trainer:{'loss': 3.353098460674286, 'learning_rate': 4.8358021840770986e-05, 'epoch': 0.09851868955374095, 'step': 547000}
INFO:transformers.trainer:{'loss': 3.36982856631279, 'learning_rate': 4.8356520946658345e-05, 'epoch': 0.09860874320049941, 'step': 547500}
INFO:transformers.trainer:{'loss': 3.3372090854644774, 'learning_rate': 4.8355020052545704e-05, 'epoch': 0.09869879684725785, 'step': 548000}
INFO:transformers.trainer:{'loss': 3.38787335562706, 'learning_rate': 4.835351915843306e-05, 'epoch': 0.0987888504940163, 'step': 548500}
INFO:transformers.trainer:{'loss': 3.3212994861602785, 'learning_rate': 4.835201826432042e-05, 'epoch': 0.09887890414077474, 'step': 549000}
INFO:transformers.trainer:{'loss': 3.3363721915483473, 'learning_rate': 4.835051737020778e-05, 'epoch': 0.09896895778753319, 'step': 549500}
INFO:transformers.trainer:{'loss': 3.36908744764328, 'learning_rate': 4.834901647609514e-05, 'epoch': 0.09905901143429163, 'step': 550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.450245965242386, 'learning_rate': 4.83475155819825e-05, 'epoch': 0.09914906508105008, 'step': 550500}
INFO:transformers.trainer:{'loss': 3.4406217994689943, 'learning_rate': 4.834601468786986e-05, 'epoch': 0.09923911872780854, 'step': 551000}
INFO:transformers.trainer:{'loss': 3.399027291059494, 'learning_rate': 4.834451379375722e-05, 'epoch': 0.09932917237456698, 'step': 551500}
INFO:transformers.trainer:{'loss': 3.340806569576263, 'learning_rate': 4.8343012899644577e-05, 'epoch': 0.09941922602132543, 'step': 552000}
INFO:transformers.trainer:{'loss': 3.3914276201725007, 'learning_rate': 4.8341512005531936e-05, 'epoch': 0.09950927966808387, 'step': 552500}
INFO:transformers.trainer:{'loss': 3.3529700217247007, 'learning_rate': 4.8340011111419295e-05, 'epoch': 0.09959933331484232, 'step': 553000}
INFO:transformers.trainer:{'loss': 3.377636064529419, 'learning_rate': 4.8338510217306654e-05, 'epoch': 0.09968938696160076, 'step': 553500}
INFO:transformers.trainer:{'loss': 3.3607377552986146, 'learning_rate': 4.833700932319401e-05, 'epoch': 0.09977944060835921, 'step': 554000}
INFO:transformers.trainer:{'loss': 3.3871468544006347, 'learning_rate': 4.833550842908137e-05, 'epoch': 0.09986949425511765, 'step': 554500}
INFO:transformers.trainer:{'loss': 3.3202811326980592, 'learning_rate': 4.833400753496873e-05, 'epoch': 0.09995954790187611, 'step': 555000}
INFO:transformers.trainer:{'loss': 3.405344266653061, 'learning_rate': 4.83325066408561e-05, 'epoch': 0.10004960154863456, 'step': 555500}
INFO:transformers.trainer:{'loss': 3.368813969373703, 'learning_rate': 4.833100574674345e-05, 'epoch': 0.100139655195393, 'step': 556000}
INFO:transformers.trainer:{'loss': 3.3919852063655855, 'learning_rate': 4.8329504852630815e-05, 'epoch': 0.10022970884215145, 'step': 556500}
INFO:transformers.trainer:{'loss': 3.357740359544754, 'learning_rate': 4.832800395851817e-05, 'epoch': 0.10031976248890989, 'step': 557000}
INFO:transformers.trainer:{'loss': 3.4119267404079436, 'learning_rate': 4.832650306440553e-05, 'epoch': 0.10040981613566834, 'step': 557500}
INFO:transformers.trainer:{'loss': 3.352307897090912, 'learning_rate': 4.8325002170292885e-05, 'epoch': 0.10049986978242678, 'step': 558000}
INFO:transformers.trainer:{'loss': 3.3472719202041628, 'learning_rate': 4.832350127618025e-05, 'epoch': 0.10058992342918524, 'step': 558500}
INFO:transformers.trainer:{'loss': 3.3960625467300414, 'learning_rate': 4.83220003820676e-05, 'epoch': 0.10067997707594369, 'step': 559000}
INFO:transformers.trainer:{'loss': 3.332286696910858, 'learning_rate': 4.832049948795497e-05, 'epoch': 0.10077003072270213, 'step': 559500}
INFO:transformers.trainer:{'loss': 3.3972790122032164, 'learning_rate': 4.831899859384232e-05, 'epoch': 0.10086008436946058, 'step': 560000}
INFO:transformers.trainer:{'loss': 3.381583930015564, 'learning_rate': 4.831749769972969e-05, 'epoch': 0.10095013801621902, 'step': 560500}
INFO:transformers.trainer:{'loss': 3.414484533071518, 'learning_rate': 4.831599680561704e-05, 'epoch': 0.10104019166297747, 'step': 561000}
INFO:transformers.trainer:{'loss': 3.3691491622924805, 'learning_rate': 4.8314495911504405e-05, 'epoch': 0.10113024530973591, 'step': 561500}
INFO:transformers.trainer:{'loss': 3.413689974308014, 'learning_rate': 4.8312995017391764e-05, 'epoch': 0.10122029895649436, 'step': 562000}
INFO:transformers.trainer:{'loss': 3.3667390007972715, 'learning_rate': 4.8311494123279123e-05, 'epoch': 0.10131035260325282, 'step': 562500}
INFO:transformers.trainer:{'loss': 3.394099833726883, 'learning_rate': 4.830999322916648e-05, 'epoch': 0.10140040625001126, 'step': 563000}
INFO:transformers.trainer:{'loss': 3.318664323806763, 'learning_rate': 4.830849233505384e-05, 'epoch': 0.1014904598967697, 'step': 563500}
INFO:transformers.trainer:{'loss': 3.3514034209251404, 'learning_rate': 4.83069914409412e-05, 'epoch': 0.10158051354352815, 'step': 564000}
INFO:transformers.trainer:{'loss': 3.3562119863033293, 'learning_rate': 4.830549054682856e-05, 'epoch': 0.1016705671902866, 'step': 564500}
INFO:transformers.trainer:{'loss': 3.3834033749103547, 'learning_rate': 4.830398965271592e-05, 'epoch': 0.10176062083704504, 'step': 565000}
INFO:transformers.trainer:{'loss': 3.3614191670417783, 'learning_rate': 4.830248875860328e-05, 'epoch': 0.10185067448380349, 'step': 565500}
INFO:transformers.trainer:{'loss': 3.3001270570755006, 'learning_rate': 4.830098786449064e-05, 'epoch': 0.10194072813056194, 'step': 566000}
INFO:transformers.trainer:{'loss': 3.404208399772644, 'learning_rate': 4.8299486970377996e-05, 'epoch': 0.10203078177732039, 'step': 566500}
INFO:transformers.trainer:{'loss': 3.3422659957408904, 'learning_rate': 4.8297986076265355e-05, 'epoch': 0.10212083542407883, 'step': 567000}
INFO:transformers.trainer:{'loss': 3.4305025326013565, 'learning_rate': 4.8296485182152714e-05, 'epoch': 0.10221088907083728, 'step': 567500}
INFO:transformers.trainer:{'loss': 3.348363649606705, 'learning_rate': 4.829498428804007e-05, 'epoch': 0.10230094271759572, 'step': 568000}
INFO:transformers.trainer:{'loss': 3.371267035484314, 'learning_rate': 4.829348339392743e-05, 'epoch': 0.10239099636435417, 'step': 568500}
INFO:transformers.trainer:{'loss': 3.3417718873023987, 'learning_rate': 4.829198249981479e-05, 'epoch': 0.10248105001111261, 'step': 569000}
INFO:transformers.trainer:{'loss': 3.3629326243400572, 'learning_rate': 4.829048160570216e-05, 'epoch': 0.10257110365787107, 'step': 569500}
INFO:transformers.trainer:{'loss': 3.3691957738399507, 'learning_rate': 4.828898071158951e-05, 'epoch': 0.10266115730462952, 'step': 570000}
INFO:transformers.trainer:{'loss': 3.325701512813568, 'learning_rate': 4.8287479817476875e-05, 'epoch': 0.10275121095138796, 'step': 570500}
INFO:transformers.trainer:{'loss': 3.3447877275943756, 'learning_rate': 4.828597892336423e-05, 'epoch': 0.10284126459814641, 'step': 571000}
INFO:transformers.trainer:{'loss': 3.389800364255905, 'learning_rate': 4.8284478029251586e-05, 'epoch': 0.10293131824490485, 'step': 571500}
INFO:transformers.trainer:{'loss': 3.333106073617935, 'learning_rate': 4.8282977135138945e-05, 'epoch': 0.1030213718916633, 'step': 572000}
INFO:transformers.trainer:{'loss': 3.358979185342789, 'learning_rate': 4.8281476241026304e-05, 'epoch': 0.10311142553842174, 'step': 572500}
INFO:transformers.trainer:{'loss': 3.3696657593250277, 'learning_rate': 4.8279975346913663e-05, 'epoch': 0.10320147918518019, 'step': 573000}
INFO:transformers.trainer:{'loss': 3.3385844266414644, 'learning_rate': 4.827847445280102e-05, 'epoch': 0.10329153283193865, 'step': 573500}
INFO:transformers.trainer:{'loss': 3.3439725885391236, 'learning_rate': 4.827697355868838e-05, 'epoch': 0.1033815864786971, 'step': 574000}
INFO:transformers.trainer:{'loss': 3.3313946404457093, 'learning_rate': 4.827547266457574e-05, 'epoch': 0.10347164012545554, 'step': 574500}
INFO:transformers.trainer:{'loss': 3.3764901313781737, 'learning_rate': 4.82739717704631e-05, 'epoch': 0.10356169377221398, 'step': 575000}
INFO:transformers.trainer:{'loss': 3.455426701068878, 'learning_rate': 4.827247087635046e-05, 'epoch': 0.10365174741897243, 'step': 575500}
INFO:transformers.trainer:{'loss': 3.42697984790802, 'learning_rate': 4.8270969982237825e-05, 'epoch': 0.10374180106573087, 'step': 576000}
INFO:transformers.trainer:{'loss': 3.381090544939041, 'learning_rate': 4.826946908812518e-05, 'epoch': 0.10383185471248932, 'step': 576500}
INFO:transformers.trainer:{'loss': 3.4133727407455443, 'learning_rate': 4.826796819401254e-05, 'epoch': 0.10392190835924778, 'step': 577000}
INFO:transformers.trainer:{'loss': 3.359429219961166, 'learning_rate': 4.8266467299899895e-05, 'epoch': 0.10401196200600622, 'step': 577500}
INFO:transformers.trainer:{'loss': 3.39831090927124, 'learning_rate': 4.826496640578726e-05, 'epoch': 0.10410201565276467, 'step': 578000}
INFO:transformers.trainer:{'loss': 3.4217358396053315, 'learning_rate': 4.826346551167461e-05, 'epoch': 0.10419206929952311, 'step': 578500}
INFO:transformers.trainer:{'loss': 3.369991091489792, 'learning_rate': 4.826196461756198e-05, 'epoch': 0.10428212294628156, 'step': 579000}
INFO:transformers.trainer:{'loss': 3.355826536655426, 'learning_rate': 4.826046372344933e-05, 'epoch': 0.10437217659304, 'step': 579500}
INFO:transformers.trainer:{'loss': 3.3463521819114685, 'learning_rate': 4.82589628293367e-05, 'epoch': 0.10446223023979845, 'step': 580000}
INFO:transformers.trainer:{'loss': 3.3457191474437713, 'learning_rate': 4.825746193522405e-05, 'epoch': 0.1045522838865569, 'step': 580500}
INFO:transformers.trainer:{'loss': 3.3388089337348936, 'learning_rate': 4.8255961041111415e-05, 'epoch': 0.10464233753331535, 'step': 581000}
INFO:transformers.trainer:{'loss': 3.362480374097824, 'learning_rate': 4.825446014699877e-05, 'epoch': 0.1047323911800738, 'step': 581500}
INFO:transformers.trainer:{'loss': 3.3989068691730497, 'learning_rate': 4.825295925288613e-05, 'epoch': 0.10482244482683224, 'step': 582000}
INFO:transformers.trainer:{'loss': 3.393697844862938, 'learning_rate': 4.8251458358773485e-05, 'epoch': 0.10491249847359069, 'step': 582500}
INFO:transformers.trainer:{'loss': 3.418132896900177, 'learning_rate': 4.824995746466085e-05, 'epoch': 0.10500255212034913, 'step': 583000}
INFO:transformers.trainer:{'loss': 3.376379022836685, 'learning_rate': 4.824845657054821e-05, 'epoch': 0.10509260576710758, 'step': 583500}
INFO:transformers.trainer:{'loss': 3.359949340105057, 'learning_rate': 4.824695567643557e-05, 'epoch': 0.10518265941386602, 'step': 584000}
INFO:transformers.trainer:{'loss': 3.4243983809947967, 'learning_rate': 4.824545478232293e-05, 'epoch': 0.10527271306062448, 'step': 584500}
INFO:transformers.trainer:{'loss': 3.3592594780921936, 'learning_rate': 4.824395388821029e-05, 'epoch': 0.10536276670738293, 'step': 585000}
INFO:transformers.trainer:{'loss': 3.3223180236816408, 'learning_rate': 4.8242452994097646e-05, 'epoch': 0.10545282035414137, 'step': 585500}
INFO:transformers.trainer:{'loss': 3.3557400209903716, 'learning_rate': 4.8240952099985006e-05, 'epoch': 0.10554287400089982, 'step': 586000}
INFO:transformers.trainer:{'loss': 3.3303399064540864, 'learning_rate': 4.8239451205872365e-05, 'epoch': 0.10563292764765826, 'step': 586500}
INFO:transformers.trainer:{'loss': 3.417301100254059, 'learning_rate': 4.8237950311759724e-05, 'epoch': 0.1057229812944167, 'step': 587000}
INFO:transformers.trainer:{'loss': 3.3770087568759917, 'learning_rate': 4.823644941764708e-05, 'epoch': 0.10581303494117515, 'step': 587500}
INFO:transformers.trainer:{'loss': 3.310904139995575, 'learning_rate': 4.823494852353444e-05, 'epoch': 0.1059030885879336, 'step': 588000}
INFO:transformers.trainer:{'loss': 3.3897754863500595, 'learning_rate': 4.82334476294218e-05, 'epoch': 0.10599314223469206, 'step': 588500}
INFO:transformers.trainer:{'loss': 3.38812149310112, 'learning_rate': 4.823194673530916e-05, 'epoch': 0.1060831958814505, 'step': 589000}
INFO:transformers.trainer:{'loss': 3.398891995191574, 'learning_rate': 4.823044584119652e-05, 'epoch': 0.10617324952820895, 'step': 589500}
INFO:transformers.trainer:{'loss': 3.559672278404236, 'learning_rate': 4.8228944947083885e-05, 'epoch': 0.10626330317496739, 'step': 590000}
INFO:transformers.trainer:{'loss': 3.384078204154968, 'learning_rate': 4.822744405297124e-05, 'epoch': 0.10635335682172584, 'step': 590500}
INFO:transformers.trainer:{'loss': 3.428869674682617, 'learning_rate': 4.82259431588586e-05, 'epoch': 0.10644341046848428, 'step': 591000}
INFO:transformers.trainer:{'loss': 3.3407491850852966, 'learning_rate': 4.8224442264745955e-05, 'epoch': 0.10653346411524273, 'step': 591500}
INFO:transformers.trainer:{'loss': 3.410853083729744, 'learning_rate': 4.822294137063332e-05, 'epoch': 0.10662351776200119, 'step': 592000}
INFO:transformers.trainer:{'loss': 3.331466471195221, 'learning_rate': 4.822144047652067e-05, 'epoch': 0.10671357140875963, 'step': 592500}
INFO:transformers.trainer:{'loss': 3.3829999454021453, 'learning_rate': 4.821993958240804e-05, 'epoch': 0.10680362505551808, 'step': 593000}
INFO:transformers.trainer:{'loss': 3.3602823889255524, 'learning_rate': 4.821843868829539e-05, 'epoch': 0.10689367870227652, 'step': 593500}
INFO:transformers.trainer:{'loss': 3.3795617735385894, 'learning_rate': 4.821693779418276e-05, 'epoch': 0.10698373234903497, 'step': 594000}
INFO:transformers.trainer:{'loss': 3.390952864408493, 'learning_rate': 4.821543690007011e-05, 'epoch': 0.10707378599579341, 'step': 594500}
INFO:transformers.trainer:{'loss': 3.404192314863205, 'learning_rate': 4.8213936005957475e-05, 'epoch': 0.10716383964255186, 'step': 595000}
INFO:transformers.trainer:{'loss': 3.373780059695244, 'learning_rate': 4.821243511184483e-05, 'epoch': 0.10725389328931031, 'step': 595500}
INFO:transformers.trainer:{'loss': 3.3804880625009535, 'learning_rate': 4.8210934217732187e-05, 'epoch': 0.10734394693606876, 'step': 596000}
INFO:transformers.trainer:{'loss': 3.357597511291504, 'learning_rate': 4.820943332361955e-05, 'epoch': 0.1074340005828272, 'step': 596500}
INFO:transformers.trainer:{'loss': 3.3691561646461485, 'learning_rate': 4.8207932429506905e-05, 'epoch': 0.10752405422958565, 'step': 597000}
INFO:transformers.trainer:{'loss': 3.36362620806694, 'learning_rate': 4.820643153539427e-05, 'epoch': 0.1076141078763441, 'step': 597500}
INFO:transformers.trainer:{'loss': 3.376618376493454, 'learning_rate': 4.820493064128162e-05, 'epoch': 0.10770416152310254, 'step': 598000}
INFO:transformers.trainer:{'loss': 3.383828959226608, 'learning_rate': 4.820342974716899e-05, 'epoch': 0.10779421516986099, 'step': 598500}
INFO:transformers.trainer:{'loss': 3.416170372724533, 'learning_rate': 4.820192885305634e-05, 'epoch': 0.10788426881661943, 'step': 599000}
INFO:transformers.trainer:{'loss': 3.354728962898254, 'learning_rate': 4.820042795894371e-05, 'epoch': 0.10797432246337789, 'step': 599500}
INFO:transformers.trainer:{'loss': 3.3542652806043627, 'learning_rate': 4.819892706483106e-05, 'epoch': 0.10806437611013633, 'step': 600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.394873788833618, 'learning_rate': 4.8197426170718425e-05, 'epoch': 0.10815442975689478, 'step': 600500}
INFO:transformers.trainer:{'loss': 3.3864239420890807, 'learning_rate': 4.819592527660578e-05, 'epoch': 0.10824448340365322, 'step': 601000}
INFO:transformers.trainer:{'loss': 3.4110264105796815, 'learning_rate': 4.819442438249314e-05, 'epoch': 0.10833453705041167, 'step': 601500}
INFO:transformers.trainer:{'loss': 3.439251650094986, 'learning_rate': 4.8192923488380495e-05, 'epoch': 0.10842459069717011, 'step': 602000}
INFO:transformers.trainer:{'loss': 3.381397463083267, 'learning_rate': 4.819142259426786e-05, 'epoch': 0.10851464434392856, 'step': 602500}
INFO:transformers.trainer:{'loss': 3.3638212230205538, 'learning_rate': 4.818992170015521e-05, 'epoch': 0.10860469799068702, 'step': 603000}
INFO:transformers.trainer:{'loss': 3.422495204210281, 'learning_rate': 4.818842080604258e-05, 'epoch': 0.10869475163744546, 'step': 603500}
INFO:transformers.trainer:{'loss': 3.3400986108779906, 'learning_rate': 4.818691991192994e-05, 'epoch': 0.10878480528420391, 'step': 604000}
INFO:transformers.trainer:{'loss': 3.3985995213985443, 'learning_rate': 4.81854190178173e-05, 'epoch': 0.10887485893096235, 'step': 604500}
INFO:transformers.trainer:{'loss': 3.3150293576717376, 'learning_rate': 4.8183918123704656e-05, 'epoch': 0.1089649125777208, 'step': 605000}
INFO:transformers.trainer:{'loss': 3.400481883764267, 'learning_rate': 4.8182417229592015e-05, 'epoch': 0.10905496622447924, 'step': 605500}
INFO:transformers.trainer:{'loss': 3.4196604590415953, 'learning_rate': 4.8180916335479374e-05, 'epoch': 0.10914501987123769, 'step': 606000}
INFO:transformers.trainer:{'loss': 3.401981132984161, 'learning_rate': 4.817941544136673e-05, 'epoch': 0.10923507351799613, 'step': 606500}
INFO:transformers.trainer:{'loss': 3.3192123656272887, 'learning_rate': 4.817791454725409e-05, 'epoch': 0.10932512716475459, 'step': 607000}
INFO:transformers.trainer:{'loss': 3.428955114841461, 'learning_rate': 4.817641365314145e-05, 'epoch': 0.10941518081151304, 'step': 607500}
INFO:transformers.trainer:{'loss': 3.3607481665611267, 'learning_rate': 4.817491275902881e-05, 'epoch': 0.10950523445827148, 'step': 608000}
INFO:transformers.trainer:{'loss': 3.429881681919098, 'learning_rate': 4.817341186491617e-05, 'epoch': 0.10959528810502993, 'step': 608500}
INFO:transformers.trainer:{'loss': 3.427680113554001, 'learning_rate': 4.817191097080353e-05, 'epoch': 0.10968534175178837, 'step': 609000}
INFO:transformers.trainer:{'loss': 3.412097075223923, 'learning_rate': 4.817041007669089e-05, 'epoch': 0.10977539539854682, 'step': 609500}
INFO:transformers.trainer:{'loss': 3.3917637498378754, 'learning_rate': 4.816890918257825e-05, 'epoch': 0.10986544904530526, 'step': 610000}
INFO:transformers.trainer:{'loss': 3.356432129383087, 'learning_rate': 4.816740828846561e-05, 'epoch': 0.10995550269206372, 'step': 610500}
INFO:transformers.trainer:{'loss': 3.4357969777584074, 'learning_rate': 4.8165907394352965e-05, 'epoch': 0.11004555633882217, 'step': 611000}
INFO:transformers.trainer:{'loss': 3.4027046005725863, 'learning_rate': 4.816440650024033e-05, 'epoch': 0.11013560998558061, 'step': 611500}
INFO:transformers.trainer:{'loss': 3.337835127592087, 'learning_rate': 4.816290560612768e-05, 'epoch': 0.11022566363233906, 'step': 612000}
INFO:transformers.trainer:{'loss': 3.3827352921962737, 'learning_rate': 4.816140471201505e-05, 'epoch': 0.1103157172790975, 'step': 612500}
INFO:transformers.trainer:{'loss': 3.3720030949115753, 'learning_rate': 4.81599038179024e-05, 'epoch': 0.11040577092585595, 'step': 613000}
INFO:transformers.trainer:{'loss': 3.3911408712863924, 'learning_rate': 4.815840292378977e-05, 'epoch': 0.11049582457261439, 'step': 613500}
INFO:transformers.trainer:{'loss': 3.33393584728241, 'learning_rate': 4.815690202967712e-05, 'epoch': 0.11058587821937284, 'step': 614000}
INFO:transformers.trainer:{'loss': 3.3384907953739167, 'learning_rate': 4.8155401135564485e-05, 'epoch': 0.1106759318661313, 'step': 614500}
INFO:transformers.trainer:{'loss': 3.3643083741664888, 'learning_rate': 4.815390024145184e-05, 'epoch': 0.11076598551288974, 'step': 615000}
INFO:transformers.trainer:{'loss': 3.3839206714630126, 'learning_rate': 4.81523993473392e-05, 'epoch': 0.11085603915964819, 'step': 615500}
INFO:transformers.trainer:{'loss': 3.3430210621356964, 'learning_rate': 4.8150898453226555e-05, 'epoch': 0.11094609280640663, 'step': 616000}
INFO:transformers.trainer:{'loss': 3.3450337977409363, 'learning_rate': 4.814939755911392e-05, 'epoch': 0.11103614645316508, 'step': 616500}
INFO:transformers.trainer:{'loss': 3.355414035320282, 'learning_rate': 4.8147896665001273e-05, 'epoch': 0.11112620009992352, 'step': 617000}
INFO:transformers.trainer:{'loss': 3.353825397014618, 'learning_rate': 4.814639577088864e-05, 'epoch': 0.11121625374668197, 'step': 617500}
INFO:transformers.trainer:{'loss': 3.324119004011154, 'learning_rate': 4.8144894876776e-05, 'epoch': 0.11130630739344043, 'step': 618000}
INFO:transformers.trainer:{'loss': 3.3345557177066802, 'learning_rate': 4.814339398266336e-05, 'epoch': 0.11139636104019887, 'step': 618500}
INFO:transformers.trainer:{'loss': 3.3390292370319368, 'learning_rate': 4.8141893088550716e-05, 'epoch': 0.11148641468695732, 'step': 619000}
INFO:transformers.trainer:{'loss': 3.3574627075195314, 'learning_rate': 4.814039219443807e-05, 'epoch': 0.11157646833371576, 'step': 619500}
INFO:transformers.trainer:{'loss': 3.3808435304164886, 'learning_rate': 4.8138891300325435e-05, 'epoch': 0.1116665219804742, 'step': 620000}
INFO:transformers.trainer:{'loss': 3.332213690042496, 'learning_rate': 4.813739040621279e-05, 'epoch': 0.11175657562723265, 'step': 620500}
INFO:transformers.trainer:{'loss': 3.418543354988098, 'learning_rate': 4.813588951210015e-05, 'epoch': 0.1118466292739911, 'step': 621000}
INFO:transformers.trainer:{'loss': 3.3515317964553835, 'learning_rate': 4.8134388617987505e-05, 'epoch': 0.11193668292074956, 'step': 621500}
INFO:transformers.trainer:{'loss': 3.3433562576770783, 'learning_rate': 4.813288772387487e-05, 'epoch': 0.112026736567508, 'step': 622000}
INFO:transformers.trainer:{'loss': 3.2970161858797074, 'learning_rate': 4.813138682976222e-05, 'epoch': 0.11211679021426645, 'step': 622500}
INFO:transformers.trainer:{'loss': 3.3239440779685974, 'learning_rate': 4.812988593564959e-05, 'epoch': 0.11220684386102489, 'step': 623000}
INFO:transformers.trainer:{'loss': 3.4342456517219544, 'learning_rate': 4.812838504153694e-05, 'epoch': 0.11229689750778334, 'step': 623500}
INFO:transformers.trainer:{'loss': 3.428217433691025, 'learning_rate': 4.812688414742431e-05, 'epoch': 0.11238695115454178, 'step': 624000}
INFO:transformers.trainer:{'loss': 3.437666904449463, 'learning_rate': 4.8125383253311666e-05, 'epoch': 0.11247700480130023, 'step': 624500}
INFO:transformers.trainer:{'loss': 3.2771588962078093, 'learning_rate': 4.8123882359199025e-05, 'epoch': 0.11256705844805867, 'step': 625000}
INFO:transformers.trainer:{'loss': 3.35230556511879, 'learning_rate': 4.8122381465086384e-05, 'epoch': 0.11265711209481713, 'step': 625500}
INFO:transformers.trainer:{'loss': 3.391259037256241, 'learning_rate': 4.812088057097374e-05, 'epoch': 0.11274716574157558, 'step': 626000}
INFO:transformers.trainer:{'loss': 3.3969539389610293, 'learning_rate': 4.81193796768611e-05, 'epoch': 0.11283721938833402, 'step': 626500}
INFO:transformers.trainer:{'loss': 3.39676140666008, 'learning_rate': 4.811787878274846e-05, 'epoch': 0.11292727303509247, 'step': 627000}
INFO:transformers.trainer:{'loss': 3.306430373668671, 'learning_rate': 4.811637788863582e-05, 'epoch': 0.11301732668185091, 'step': 627500}
INFO:transformers.trainer:{'loss': 3.369634297132492, 'learning_rate': 4.811487699452318e-05, 'epoch': 0.11310738032860936, 'step': 628000}
INFO:transformers.trainer:{'loss': 3.3709995794296264, 'learning_rate': 4.811337610041054e-05, 'epoch': 0.1131974339753678, 'step': 628500}
INFO:transformers.trainer:{'loss': 3.3229405708312987, 'learning_rate': 4.81118752062979e-05, 'epoch': 0.11328748762212626, 'step': 629000}
INFO:transformers.trainer:{'loss': 3.2995572457313536, 'learning_rate': 4.8110374312185256e-05, 'epoch': 0.1133775412688847, 'step': 629500}
INFO:transformers.trainer:{'loss': 3.362351798534393, 'learning_rate': 4.8108873418072616e-05, 'epoch': 0.11346759491564315, 'step': 630000}
INFO:transformers.trainer:{'loss': 3.373496605873108, 'learning_rate': 4.8107372523959975e-05, 'epoch': 0.1135576485624016, 'step': 630500}
INFO:transformers.trainer:{'loss': 3.3406282484531404, 'learning_rate': 4.8105871629847334e-05, 'epoch': 0.11364770220916004, 'step': 631000}
INFO:transformers.trainer:{'loss': 3.3511622016429903, 'learning_rate': 4.810437073573469e-05, 'epoch': 0.11373775585591848, 'step': 631500}
INFO:transformers.trainer:{'loss': 3.432756076335907, 'learning_rate': 4.810286984162206e-05, 'epoch': 0.11382780950267693, 'step': 632000}
INFO:transformers.trainer:{'loss': 3.43058962893486, 'learning_rate': 4.810136894750941e-05, 'epoch': 0.11391786314943537, 'step': 632500}
INFO:transformers.trainer:{'loss': 3.39731988799572, 'learning_rate': 4.8099868053396777e-05, 'epoch': 0.11400791679619383, 'step': 633000}
INFO:transformers.trainer:{'loss': 3.347881195783615, 'learning_rate': 4.809836715928413e-05, 'epoch': 0.11409797044295228, 'step': 633500}
INFO:transformers.trainer:{'loss': 3.3575905344486237, 'learning_rate': 4.8096866265171495e-05, 'epoch': 0.11418802408971072, 'step': 634000}
INFO:transformers.trainer:{'loss': 3.4051492109298707, 'learning_rate': 4.809536537105885e-05, 'epoch': 0.11427807773646917, 'step': 634500}
INFO:transformers.trainer:{'loss': 3.346480164051056, 'learning_rate': 4.809386447694621e-05, 'epoch': 0.11436813138322761, 'step': 635000}
INFO:transformers.trainer:{'loss': 3.341771966457367, 'learning_rate': 4.8092363582833565e-05, 'epoch': 0.11445818502998606, 'step': 635500}
INFO:transformers.trainer:{'loss': 3.35080273771286, 'learning_rate': 4.809086268872093e-05, 'epoch': 0.1145482386767445, 'step': 636000}
INFO:transformers.trainer:{'loss': 3.383694023489952, 'learning_rate': 4.808936179460828e-05, 'epoch': 0.11463829232350296, 'step': 636500}
INFO:transformers.trainer:{'loss': 3.39274499297142, 'learning_rate': 4.808786090049565e-05, 'epoch': 0.11472834597026141, 'step': 637000}
INFO:transformers.trainer:{'loss': 3.324443769693375, 'learning_rate': 4.8086360006383e-05, 'epoch': 0.11481839961701985, 'step': 637500}
INFO:transformers.trainer:{'loss': 3.356727464199066, 'learning_rate': 4.808485911227037e-05, 'epoch': 0.1149084532637783, 'step': 638000}
INFO:transformers.trainer:{'loss': 3.371255133152008, 'learning_rate': 4.8083358218157726e-05, 'epoch': 0.11499850691053674, 'step': 638500}
INFO:transformers.trainer:{'loss': 3.3658203549385073, 'learning_rate': 4.8081857324045085e-05, 'epoch': 0.11508856055729519, 'step': 639000}
INFO:transformers.trainer:{'loss': 3.3509128077030184, 'learning_rate': 4.8080356429932444e-05, 'epoch': 0.11517861420405363, 'step': 639500}
INFO:transformers.trainer:{'loss': 3.292954481601715, 'learning_rate': 4.80788555358198e-05, 'epoch': 0.11526866785081209, 'step': 640000}
INFO:transformers.trainer:{'loss': 3.371401365041733, 'learning_rate': 4.807735464170716e-05, 'epoch': 0.11535872149757054, 'step': 640500}
INFO:transformers.trainer:{'loss': 3.3001081547737123, 'learning_rate': 4.807585374759452e-05, 'epoch': 0.11544877514432898, 'step': 641000}
INFO:transformers.trainer:{'loss': 3.370500319480896, 'learning_rate': 4.807435285348188e-05, 'epoch': 0.11553882879108743, 'step': 641500}
INFO:transformers.trainer:{'loss': 3.353205198287964, 'learning_rate': 4.807285195936924e-05, 'epoch': 0.11562888243784587, 'step': 642000}
INFO:transformers.trainer:{'loss': 3.3317679982185364, 'learning_rate': 4.80713510652566e-05, 'epoch': 0.11571893608460432, 'step': 642500}
INFO:transformers.trainer:{'loss': 3.3237814967632295, 'learning_rate': 4.806985017114395e-05, 'epoch': 0.11580898973136276, 'step': 643000}
INFO:transformers.trainer:{'loss': 3.3822404404878617, 'learning_rate': 4.806834927703132e-05, 'epoch': 0.11589904337812121, 'step': 643500}
INFO:transformers.trainer:{'loss': 3.3700818440914153, 'learning_rate': 4.806684838291867e-05, 'epoch': 0.11598909702487967, 'step': 644000}
INFO:transformers.trainer:{'loss': 3.393313550710678, 'learning_rate': 4.8065347488806035e-05, 'epoch': 0.11607915067163811, 'step': 644500}
INFO:transformers.trainer:{'loss': 3.3490547761917115, 'learning_rate': 4.8063846594693394e-05, 'epoch': 0.11616920431839656, 'step': 645000}
INFO:transformers.trainer:{'loss': 3.336510067462921, 'learning_rate': 4.806234570058075e-05, 'epoch': 0.116259257965155, 'step': 645500}
INFO:transformers.trainer:{'loss': 3.383690465927124, 'learning_rate': 4.806084480646811e-05, 'epoch': 0.11634931161191345, 'step': 646000}
INFO:transformers.trainer:{'loss': 3.3734511518478394, 'learning_rate': 4.805934391235547e-05, 'epoch': 0.11643936525867189, 'step': 646500}
INFO:transformers.trainer:{'loss': 3.356253635644913, 'learning_rate': 4.805784301824283e-05, 'epoch': 0.11652941890543034, 'step': 647000}
INFO:transformers.trainer:{'loss': 3.3684407780170442, 'learning_rate': 4.805634212413019e-05, 'epoch': 0.1166194725521888, 'step': 647500}
INFO:transformers.trainer:{'loss': 3.3924535942077636, 'learning_rate': 4.805484123001755e-05, 'epoch': 0.11670952619894724, 'step': 648000}
INFO:transformers.trainer:{'loss': 3.4005897011756896, 'learning_rate': 4.805334033590491e-05, 'epoch': 0.11679957984570569, 'step': 648500}
INFO:transformers.trainer:{'loss': 3.4074850544929505, 'learning_rate': 4.8051839441792266e-05, 'epoch': 0.11688963349246413, 'step': 649000}
INFO:transformers.trainer:{'loss': 3.380776326417923, 'learning_rate': 4.8050338547679625e-05, 'epoch': 0.11697968713922258, 'step': 649500}
INFO:transformers.trainer:{'loss': 3.2921290204524993, 'learning_rate': 4.8048837653566984e-05, 'epoch': 0.11706974078598102, 'step': 650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.436491597175598, 'learning_rate': 4.804733675945434e-05, 'epoch': 0.11715979443273947, 'step': 650500}
INFO:transformers.trainer:{'loss': 3.37169691824913, 'learning_rate': 4.80458358653417e-05, 'epoch': 0.11724984807949791, 'step': 651000}
INFO:transformers.trainer:{'loss': 3.323731520652771, 'learning_rate': 4.804433497122906e-05, 'epoch': 0.11733990172625637, 'step': 651500}
INFO:transformers.trainer:{'loss': 3.3280837872028353, 'learning_rate': 4.804283407711642e-05, 'epoch': 0.11742995537301482, 'step': 652000}
INFO:transformers.trainer:{'loss': 3.4191268068552017, 'learning_rate': 4.8041333183003786e-05, 'epoch': 0.11752000901977326, 'step': 652500}
INFO:transformers.trainer:{'loss': 3.3588530123233795, 'learning_rate': 4.803983228889114e-05, 'epoch': 0.1176100626665317, 'step': 653000}
INFO:transformers.trainer:{'loss': 3.3567692699432374, 'learning_rate': 4.8038331394778504e-05, 'epoch': 0.11770011631329015, 'step': 653500}
INFO:transformers.trainer:{'loss': 3.36171235537529, 'learning_rate': 4.803683050066586e-05, 'epoch': 0.1177901699600486, 'step': 654000}
INFO:transformers.trainer:{'loss': 3.4010625140666964, 'learning_rate': 4.803532960655322e-05, 'epoch': 0.11788022360680704, 'step': 654500}
INFO:transformers.trainer:{'loss': 3.402624776363373, 'learning_rate': 4.8033828712440575e-05, 'epoch': 0.1179702772535655, 'step': 655000}
INFO:transformers.trainer:{'loss': 3.358940753221512, 'learning_rate': 4.803232781832794e-05, 'epoch': 0.11806033090032395, 'step': 655500}
INFO:transformers.trainer:{'loss': 3.386258638381958, 'learning_rate': 4.803082692421529e-05, 'epoch': 0.11815038454708239, 'step': 656000}
INFO:transformers.trainer:{'loss': 3.3928514239788057, 'learning_rate': 4.802932603010266e-05, 'epoch': 0.11824043819384084, 'step': 656500}
INFO:transformers.trainer:{'loss': 3.3122469584941863, 'learning_rate': 4.802782513599001e-05, 'epoch': 0.11833049184059928, 'step': 657000}
INFO:transformers.trainer:{'loss': 3.3493751072883606, 'learning_rate': 4.802632424187738e-05, 'epoch': 0.11842054548735773, 'step': 657500}
INFO:transformers.trainer:{'loss': 3.342210972428322, 'learning_rate': 4.802482334776473e-05, 'epoch': 0.11851059913411617, 'step': 658000}
INFO:transformers.trainer:{'loss': 3.440457960605621, 'learning_rate': 4.8023322453652095e-05, 'epoch': 0.11860065278087462, 'step': 658500}
INFO:transformers.trainer:{'loss': 3.361898449420929, 'learning_rate': 4.8021821559539454e-05, 'epoch': 0.11869070642763307, 'step': 659000}
INFO:transformers.trainer:{'loss': 3.3156276404857636, 'learning_rate': 4.802032066542681e-05, 'epoch': 0.11878076007439152, 'step': 659500}
INFO:transformers.trainer:{'loss': 3.3402714712619783, 'learning_rate': 4.801881977131417e-05, 'epoch': 0.11887081372114996, 'step': 660000}
INFO:transformers.trainer:{'loss': 3.3290944646596907, 'learning_rate': 4.801731887720153e-05, 'epoch': 0.11896086736790841, 'step': 660500}
INFO:transformers.trainer:{'loss': 3.369539690732956, 'learning_rate': 4.801581798308889e-05, 'epoch': 0.11905092101466686, 'step': 661000}
INFO:transformers.trainer:{'loss': 3.3523467519283296, 'learning_rate': 4.801431708897625e-05, 'epoch': 0.1191409746614253, 'step': 661500}
INFO:transformers.trainer:{'loss': 3.3511933608055116, 'learning_rate': 4.801281619486361e-05, 'epoch': 0.11923102830818375, 'step': 662000}
INFO:transformers.trainer:{'loss': 3.386267976999283, 'learning_rate': 4.801131530075097e-05, 'epoch': 0.1193210819549422, 'step': 662500}
INFO:transformers.trainer:{'loss': 3.363638335466385, 'learning_rate': 4.8009814406638326e-05, 'epoch': 0.11941113560170065, 'step': 663000}
INFO:transformers.trainer:{'loss': 3.4106033113002776, 'learning_rate': 4.8008313512525685e-05, 'epoch': 0.1195011892484591, 'step': 663500}
INFO:transformers.trainer:{'loss': 3.4323169593811036, 'learning_rate': 4.8006812618413044e-05, 'epoch': 0.11959124289521754, 'step': 664000}
INFO:transformers.trainer:{'loss': 3.4036221804618836, 'learning_rate': 4.8005311724300404e-05, 'epoch': 0.11968129654197598, 'step': 664500}
INFO:transformers.trainer:{'loss': 3.378039073944092, 'learning_rate': 4.800381083018776e-05, 'epoch': 0.11977135018873443, 'step': 665000}
INFO:transformers.trainer:{'loss': 3.343587543129921, 'learning_rate': 4.800230993607512e-05, 'epoch': 0.11986140383549287, 'step': 665500}
INFO:transformers.trainer:{'loss': 3.3306110489368437, 'learning_rate': 4.800080904196248e-05, 'epoch': 0.11995145748225133, 'step': 666000}
INFO:transformers.trainer:{'loss': 3.3199825718402862, 'learning_rate': 4.799930814784984e-05, 'epoch': 0.12004151112900978, 'step': 666500}
INFO:transformers.trainer:{'loss': 3.329786269664764, 'learning_rate': 4.79978072537372e-05, 'epoch': 0.12013156477576822, 'step': 667000}
INFO:transformers.trainer:{'loss': 3.3645557124614713, 'learning_rate': 4.799630635962456e-05, 'epoch': 0.12022161842252667, 'step': 667500}
INFO:transformers.trainer:{'loss': 3.407261323928833, 'learning_rate': 4.799480546551192e-05, 'epoch': 0.12031167206928511, 'step': 668000}
INFO:transformers.trainer:{'loss': 3.3923800327777864, 'learning_rate': 4.7993304571399276e-05, 'epoch': 0.12040172571604356, 'step': 668500}
INFO:transformers.trainer:{'loss': 3.3543976888656615, 'learning_rate': 4.7991803677286635e-05, 'epoch': 0.120491779362802, 'step': 669000}
INFO:transformers.trainer:{'loss': 3.387106608390808, 'learning_rate': 4.7990302783173994e-05, 'epoch': 0.12058183300956045, 'step': 669500}
INFO:transformers.trainer:{'loss': 3.4108305518627167, 'learning_rate': 4.798880188906135e-05, 'epoch': 0.12067188665631891, 'step': 670000}
INFO:transformers.trainer:{'loss': 3.341088460564613, 'learning_rate': 4.798730099494871e-05, 'epoch': 0.12076194030307735, 'step': 670500}
INFO:transformers.trainer:{'loss': 3.3567153520584108, 'learning_rate': 4.798580010083607e-05, 'epoch': 0.1208519939498358, 'step': 671000}
INFO:transformers.trainer:{'loss': 3.373856423377991, 'learning_rate': 4.798429920672343e-05, 'epoch': 0.12094204759659424, 'step': 671500}
INFO:transformers.trainer:{'loss': 3.3329086906909944, 'learning_rate': 4.798279831261079e-05, 'epoch': 0.12103210124335269, 'step': 672000}
INFO:transformers.trainer:{'loss': 3.453482838153839, 'learning_rate': 4.798129741849815e-05, 'epoch': 0.12112215489011113, 'step': 672500}
INFO:transformers.trainer:{'loss': 3.3787794482707976, 'learning_rate': 4.7979796524385514e-05, 'epoch': 0.12121220853686958, 'step': 673000}
INFO:transformers.trainer:{'loss': 3.3850563085079193, 'learning_rate': 4.7978295630272866e-05, 'epoch': 0.12130226218362804, 'step': 673500}
INFO:transformers.trainer:{'loss': 3.3726503961086274, 'learning_rate': 4.797679473616023e-05, 'epoch': 0.12139231583038648, 'step': 674000}
INFO:transformers.trainer:{'loss': 3.296801059961319, 'learning_rate': 4.7975293842047585e-05, 'epoch': 0.12148236947714493, 'step': 674500}
INFO:transformers.trainer:{'loss': 3.3724257850646975, 'learning_rate': 4.797379294793495e-05, 'epoch': 0.12157242312390337, 'step': 675000}
INFO:transformers.trainer:{'loss': 3.415234782934189, 'learning_rate': 4.79722920538223e-05, 'epoch': 0.12166247677066182, 'step': 675500}
INFO:transformers.trainer:{'loss': 3.4130859882831572, 'learning_rate': 4.797079115970967e-05, 'epoch': 0.12175253041742026, 'step': 676000}
INFO:transformers.trainer:{'loss': 3.3438642399311065, 'learning_rate': 4.796929026559702e-05, 'epoch': 0.12184258406417871, 'step': 676500}
INFO:transformers.trainer:{'loss': 3.380876736164093, 'learning_rate': 4.7967789371484387e-05, 'epoch': 0.12193263771093715, 'step': 677000}
INFO:transformers.trainer:{'loss': 3.3343242354393006, 'learning_rate': 4.796628847737174e-05, 'epoch': 0.12202269135769561, 'step': 677500}
INFO:transformers.trainer:{'loss': 3.393729730606079, 'learning_rate': 4.7964787583259105e-05, 'epoch': 0.12211274500445406, 'step': 678000}
INFO:transformers.trainer:{'loss': 3.3792040984630587, 'learning_rate': 4.796328668914646e-05, 'epoch': 0.1222027986512125, 'step': 678500}
INFO:transformers.trainer:{'loss': 3.358441759824753, 'learning_rate': 4.796178579503382e-05, 'epoch': 0.12229285229797095, 'step': 679000}
INFO:transformers.trainer:{'loss': 3.4407181096076966, 'learning_rate': 4.7960284900921175e-05, 'epoch': 0.12238290594472939, 'step': 679500}
INFO:transformers.trainer:{'loss': 3.3666845433712007, 'learning_rate': 4.795878400680854e-05, 'epoch': 0.12247295959148784, 'step': 680000}
INFO:transformers.trainer:{'loss': 3.3776730744838717, 'learning_rate': 4.79572831126959e-05, 'epoch': 0.12256301323824628, 'step': 680500}
INFO:transformers.trainer:{'loss': 3.387554597377777, 'learning_rate': 4.795578221858326e-05, 'epoch': 0.12265306688500474, 'step': 681000}
INFO:transformers.trainer:{'loss': 3.3523372876644135, 'learning_rate': 4.795428132447062e-05, 'epoch': 0.12274312053176319, 'step': 681500}
INFO:transformers.trainer:{'loss': 3.3375361325740815, 'learning_rate': 4.795278043035798e-05, 'epoch': 0.12283317417852163, 'step': 682000}
INFO:transformers.trainer:{'loss': 3.3097575027942656, 'learning_rate': 4.7951279536245336e-05, 'epoch': 0.12292322782528008, 'step': 682500}
INFO:transformers.trainer:{'loss': 3.361257802963257, 'learning_rate': 4.7949778642132695e-05, 'epoch': 0.12301328147203852, 'step': 683000}
INFO:transformers.trainer:{'loss': 3.3758320972919464, 'learning_rate': 4.7948277748020054e-05, 'epoch': 0.12310333511879697, 'step': 683500}
INFO:transformers.trainer:{'loss': 3.3738719263076784, 'learning_rate': 4.794677685390741e-05, 'epoch': 0.12319338876555541, 'step': 684000}
INFO:transformers.trainer:{'loss': 3.347029401779175, 'learning_rate': 4.794527595979477e-05, 'epoch': 0.12328344241231386, 'step': 684500}
INFO:transformers.trainer:{'loss': 3.3214424681663512, 'learning_rate': 4.794377506568213e-05, 'epoch': 0.12337349605907232, 'step': 685000}
INFO:transformers.trainer:{'loss': 3.3165772503614424, 'learning_rate': 4.794227417156949e-05, 'epoch': 0.12346354970583076, 'step': 685500}
INFO:transformers.trainer:{'loss': 3.375884391784668, 'learning_rate': 4.794077327745685e-05, 'epoch': 0.1235536033525892, 'step': 686000}
INFO:transformers.trainer:{'loss': 3.3348030581474304, 'learning_rate': 4.793927238334421e-05, 'epoch': 0.12364365699934765, 'step': 686500}
INFO:transformers.trainer:{'loss': 3.3567933754920958, 'learning_rate': 4.793777148923157e-05, 'epoch': 0.1237337106461061, 'step': 687000}
INFO:transformers.trainer:{'loss': 3.3438640851974486, 'learning_rate': 4.7936270595118927e-05, 'epoch': 0.12382376429286454, 'step': 687500}
INFO:transformers.trainer:{'loss': 3.37126029419899, 'learning_rate': 4.7934769701006286e-05, 'epoch': 0.12391381793962299, 'step': 688000}
INFO:transformers.trainer:{'loss': 3.3555090389251707, 'learning_rate': 4.7933268806893645e-05, 'epoch': 0.12400387158638145, 'step': 688500}
INFO:transformers.trainer:{'loss': 3.392797390937805, 'learning_rate': 4.7931767912781004e-05, 'epoch': 0.12409392523313989, 'step': 689000}
INFO:transformers.trainer:{'loss': 3.368089033126831, 'learning_rate': 4.793026701866836e-05, 'epoch': 0.12418397887989834, 'step': 689500}
INFO:transformers.trainer:{'loss': 3.322314437627792, 'learning_rate': 4.792876612455572e-05, 'epoch': 0.12427403252665678, 'step': 690000}
INFO:transformers.trainer:{'loss': 3.347096240758896, 'learning_rate': 4.792726523044308e-05, 'epoch': 0.12436408617341523, 'step': 690500}
INFO:transformers.trainer:{'loss': 3.327349659204483, 'learning_rate': 4.792576433633044e-05, 'epoch': 0.12445413982017367, 'step': 691000}
INFO:transformers.trainer:{'loss': 3.3786516563892364, 'learning_rate': 4.79242634422178e-05, 'epoch': 0.12454419346693212, 'step': 691500}
INFO:transformers.trainer:{'loss': 3.3025036120414732, 'learning_rate': 4.792276254810516e-05, 'epoch': 0.12463424711369057, 'step': 692000}
INFO:transformers.trainer:{'loss': 3.3520835626125334, 'learning_rate': 4.792126165399252e-05, 'epoch': 0.12472430076044902, 'step': 692500}
INFO:transformers.trainer:{'loss': 3.344338243484497, 'learning_rate': 4.7919760759879876e-05, 'epoch': 0.12481435440720746, 'step': 693000}
INFO:transformers.trainer:{'loss': 3.403172783613205, 'learning_rate': 4.791825986576724e-05, 'epoch': 0.12490440805396591, 'step': 693500}
INFO:transformers.trainer:{'loss': 3.449055833339691, 'learning_rate': 4.7916758971654594e-05, 'epoch': 0.12499446170072435, 'step': 694000}
INFO:transformers.trainer:{'loss': 3.4039352266788483, 'learning_rate': 4.791525807754196e-05, 'epoch': 0.1250845153474828, 'step': 694500}
INFO:transformers.trainer:{'loss': 3.3446154475212095, 'learning_rate': 4.791375718342931e-05, 'epoch': 0.12517456899424126, 'step': 695000}
INFO:transformers.trainer:{'loss': 3.378064143657684, 'learning_rate': 4.791225628931668e-05, 'epoch': 0.1252646226409997, 'step': 695500}
INFO:transformers.trainer:{'loss': 3.4124471316337583, 'learning_rate': 4.791075539520403e-05, 'epoch': 0.12535467628775815, 'step': 696000}
INFO:transformers.trainer:{'loss': 3.3583596765995027, 'learning_rate': 4.7909254501091396e-05, 'epoch': 0.12544472993451658, 'step': 696500}
INFO:transformers.trainer:{'loss': 3.368843934774399, 'learning_rate': 4.790775360697875e-05, 'epoch': 0.12553478358127504, 'step': 697000}
INFO:transformers.trainer:{'loss': 3.3844846630096437, 'learning_rate': 4.7906252712866114e-05, 'epoch': 0.1256248372280335, 'step': 697500}
INFO:transformers.trainer:{'loss': 3.3002293095588686, 'learning_rate': 4.790475181875347e-05, 'epoch': 0.12571489087479193, 'step': 698000}
INFO:transformers.trainer:{'loss': 3.3386991666555406, 'learning_rate': 4.790325092464083e-05, 'epoch': 0.1258049445215504, 'step': 698500}
INFO:transformers.trainer:{'loss': 3.433003324985504, 'learning_rate': 4.7901750030528185e-05, 'epoch': 0.12589499816830882, 'step': 699000}
INFO:transformers.trainer:{'loss': 3.3719403750896455, 'learning_rate': 4.790024913641555e-05, 'epoch': 0.12598505181506728, 'step': 699500}
INFO:transformers.trainer:{'loss': 3.3364909148216246, 'learning_rate': 4.78987482423029e-05, 'epoch': 0.1260751054618257, 'step': 700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3921151707172394, 'learning_rate': 4.789724734819027e-05, 'epoch': 0.12616515910858417, 'step': 700500}
INFO:transformers.trainer:{'loss': 3.3089532907009125, 'learning_rate': 4.789574645407763e-05, 'epoch': 0.1262552127553426, 'step': 701000}
INFO:transformers.trainer:{'loss': 3.339248446941376, 'learning_rate': 4.789424555996499e-05, 'epoch': 0.12634526640210106, 'step': 701500}
INFO:transformers.trainer:{'loss': 3.3579566609859466, 'learning_rate': 4.7892744665852346e-05, 'epoch': 0.12643532004885952, 'step': 702000}
INFO:transformers.trainer:{'loss': 3.3426730966567995, 'learning_rate': 4.7891243771739705e-05, 'epoch': 0.12652537369561795, 'step': 702500}
INFO:transformers.trainer:{'loss': 3.4006307520866392, 'learning_rate': 4.7889742877627064e-05, 'epoch': 0.1266154273423764, 'step': 703000}
INFO:transformers.trainer:{'loss': 3.3416285536289214, 'learning_rate': 4.788824198351442e-05, 'epoch': 0.12670548098913484, 'step': 703500}
INFO:transformers.trainer:{'loss': 3.400873541355133, 'learning_rate': 4.788674108940178e-05, 'epoch': 0.1267955346358933, 'step': 704000}
INFO:transformers.trainer:{'loss': 3.3574024918079375, 'learning_rate': 4.788524019528914e-05, 'epoch': 0.12688558828265173, 'step': 704500}
INFO:transformers.trainer:{'loss': 3.39517084980011, 'learning_rate': 4.78837393011765e-05, 'epoch': 0.1269756419294102, 'step': 705000}
INFO:transformers.trainer:{'loss': 3.3451072976589202, 'learning_rate': 4.788223840706386e-05, 'epoch': 0.12706569557616865, 'step': 705500}
INFO:transformers.trainer:{'loss': 3.377594516992569, 'learning_rate': 4.788073751295122e-05, 'epoch': 0.12715574922292708, 'step': 706000}
INFO:transformers.trainer:{'loss': 3.3516660537719725, 'learning_rate': 4.787923661883858e-05, 'epoch': 0.12724580286968554, 'step': 706500}
INFO:transformers.trainer:{'loss': 3.328214218378067, 'learning_rate': 4.7877735724725936e-05, 'epoch': 0.12733585651644397, 'step': 707000}
INFO:transformers.trainer:{'loss': 3.3770398952960967, 'learning_rate': 4.7876234830613295e-05, 'epoch': 0.12742591016320243, 'step': 707500}
INFO:transformers.trainer:{'loss': 3.4202873163223266, 'learning_rate': 4.7874733936500654e-05, 'epoch': 0.12751596380996086, 'step': 708000}
INFO:transformers.trainer:{'loss': 3.2800527589321136, 'learning_rate': 4.7873233042388013e-05, 'epoch': 0.12760601745671932, 'step': 708500}
INFO:transformers.trainer:{'loss': 3.2865862312316896, 'learning_rate': 4.787173214827537e-05, 'epoch': 0.12769607110347778, 'step': 709000}
INFO:transformers.trainer:{'loss': 3.383570110797882, 'learning_rate': 4.787023125416273e-05, 'epoch': 0.1277861247502362, 'step': 709500}
INFO:transformers.trainer:{'loss': 3.3721351404190063, 'learning_rate': 4.786873036005009e-05, 'epoch': 0.12787617839699467, 'step': 710000}
INFO:transformers.trainer:{'loss': 3.3633418421745302, 'learning_rate': 4.786722946593745e-05, 'epoch': 0.1279662320437531, 'step': 710500}
INFO:transformers.trainer:{'loss': 3.408958443522453, 'learning_rate': 4.786572857182481e-05, 'epoch': 0.12805628569051156, 'step': 711000}
INFO:transformers.trainer:{'loss': 3.3674075725078585, 'learning_rate': 4.786422767771217e-05, 'epoch': 0.12814633933727, 'step': 711500}
INFO:transformers.trainer:{'loss': 3.3468008556365967, 'learning_rate': 4.786272678359953e-05, 'epoch': 0.12823639298402845, 'step': 712000}
INFO:transformers.trainer:{'loss': 3.369516670703888, 'learning_rate': 4.7861225889486886e-05, 'epoch': 0.1283264466307869, 'step': 712500}
INFO:transformers.trainer:{'loss': 3.319893723487854, 'learning_rate': 4.7859724995374245e-05, 'epoch': 0.12841650027754534, 'step': 713000}
INFO:transformers.trainer:{'loss': 3.291877334833145, 'learning_rate': 4.7858224101261604e-05, 'epoch': 0.1285065539243038, 'step': 713500}
INFO:transformers.trainer:{'loss': 3.3557670477628707, 'learning_rate': 4.785672320714896e-05, 'epoch': 0.12859660757106223, 'step': 714000}
INFO:transformers.trainer:{'loss': 3.3291507456302645, 'learning_rate': 4.785522231303632e-05, 'epoch': 0.12868666121782069, 'step': 714500}
INFO:transformers.trainer:{'loss': 3.312037129163742, 'learning_rate': 4.785372141892369e-05, 'epoch': 0.12877671486457912, 'step': 715000}
INFO:transformers.trainer:{'loss': 3.313181403398514, 'learning_rate': 4.785222052481104e-05, 'epoch': 0.12886676851133758, 'step': 715500}
INFO:transformers.trainer:{'loss': 3.3432399468421936, 'learning_rate': 4.7850719630698406e-05, 'epoch': 0.128956822158096, 'step': 716000}
INFO:transformers.trainer:{'loss': 3.414355620622635, 'learning_rate': 4.784921873658576e-05, 'epoch': 0.12904687580485447, 'step': 716500}
INFO:transformers.trainer:{'loss': 3.3973623530864714, 'learning_rate': 4.7847717842473124e-05, 'epoch': 0.12913692945161293, 'step': 717000}
INFO:transformers.trainer:{'loss': 3.3741303737163544, 'learning_rate': 4.7846216948360476e-05, 'epoch': 0.12922698309837136, 'step': 717500}
INFO:transformers.trainer:{'loss': 3.337208622455597, 'learning_rate': 4.784471605424784e-05, 'epoch': 0.12931703674512982, 'step': 718000}
INFO:transformers.trainer:{'loss': 3.4157657610177994, 'learning_rate': 4.7843215160135194e-05, 'epoch': 0.12940709039188825, 'step': 718500}
INFO:transformers.trainer:{'loss': 3.3263891837596895, 'learning_rate': 4.784171426602256e-05, 'epoch': 0.1294971440386467, 'step': 719000}
INFO:transformers.trainer:{'loss': 3.411909216403961, 'learning_rate': 4.784021337190991e-05, 'epoch': 0.12958719768540514, 'step': 719500}
INFO:transformers.trainer:{'loss': 3.3492848072052004, 'learning_rate': 4.783871247779728e-05, 'epoch': 0.1296772513321636, 'step': 720000}
INFO:transformers.trainer:{'loss': 3.35792751121521, 'learning_rate': 4.783721158368463e-05, 'epoch': 0.12976730497892205, 'step': 720500}
INFO:transformers.trainer:{'loss': 3.3643706851005555, 'learning_rate': 4.7835710689571996e-05, 'epoch': 0.12985735862568049, 'step': 721000}
INFO:transformers.trainer:{'loss': 3.3192061791419984, 'learning_rate': 4.7834209795459356e-05, 'epoch': 0.12994741227243894, 'step': 721500}
INFO:transformers.trainer:{'loss': 3.350925578594208, 'learning_rate': 4.7832708901346715e-05, 'epoch': 0.13003746591919738, 'step': 722000}
INFO:transformers.trainer:{'loss': 3.372689257144928, 'learning_rate': 4.7831208007234074e-05, 'epoch': 0.13012751956595583, 'step': 722500}
INFO:transformers.trainer:{'loss': 3.336982361197472, 'learning_rate': 4.782970711312143e-05, 'epoch': 0.13021757321271427, 'step': 723000}
INFO:transformers.trainer:{'loss': 3.3342139012813568, 'learning_rate': 4.782820621900879e-05, 'epoch': 0.13030762685947272, 'step': 723500}
INFO:transformers.trainer:{'loss': 3.3748671913146975, 'learning_rate': 4.782670532489615e-05, 'epoch': 0.13039768050623118, 'step': 724000}
INFO:transformers.trainer:{'loss': 3.352167144536972, 'learning_rate': 4.782520443078351e-05, 'epoch': 0.13048773415298962, 'step': 724500}
INFO:transformers.trainer:{'loss': 3.4235920147895813, 'learning_rate': 4.782370353667087e-05, 'epoch': 0.13057778779974807, 'step': 725000}
INFO:transformers.trainer:{'loss': 3.3467497491836546, 'learning_rate': 4.782220264255823e-05, 'epoch': 0.1306678414465065, 'step': 725500}
INFO:transformers.trainer:{'loss': 3.3448867399692537, 'learning_rate': 4.782070174844559e-05, 'epoch': 0.13075789509326496, 'step': 726000}
INFO:transformers.trainer:{'loss': 3.375864183664322, 'learning_rate': 4.7819200854332946e-05, 'epoch': 0.1308479487400234, 'step': 726500}
INFO:transformers.trainer:{'loss': 3.348131138086319, 'learning_rate': 4.7817699960220305e-05, 'epoch': 0.13093800238678185, 'step': 727000}
INFO:transformers.trainer:{'loss': 3.3552583458423615, 'learning_rate': 4.7816199066107664e-05, 'epoch': 0.1310280560335403, 'step': 727500}
INFO:transformers.trainer:{'loss': 3.3091583240032194, 'learning_rate': 4.781469817199502e-05, 'epoch': 0.13111810968029874, 'step': 728000}
INFO:transformers.trainer:{'loss': 3.4097412073612214, 'learning_rate': 4.781319727788238e-05, 'epoch': 0.1312081633270572, 'step': 728500}
INFO:transformers.trainer:{'loss': 3.3567363781929016, 'learning_rate': 4.781169638376974e-05, 'epoch': 0.13129821697381563, 'step': 729000}
INFO:transformers.trainer:{'loss': 3.344482260465622, 'learning_rate': 4.78101954896571e-05, 'epoch': 0.1313882706205741, 'step': 729500}
INFO:transformers.trainer:{'loss': 3.416091223716736, 'learning_rate': 4.780869459554446e-05, 'epoch': 0.13147832426733252, 'step': 730000}
INFO:transformers.trainer:{'loss': 3.337691091299057, 'learning_rate': 4.780719370143182e-05, 'epoch': 0.13156837791409098, 'step': 730500}
INFO:transformers.trainer:{'loss': 3.369392201900482, 'learning_rate': 4.780569280731918e-05, 'epoch': 0.13165843156084944, 'step': 731000}
INFO:transformers.trainer:{'loss': 3.3972559974193572, 'learning_rate': 4.7804191913206537e-05, 'epoch': 0.13174848520760787, 'step': 731500}
INFO:transformers.trainer:{'loss': 3.3762671300172804, 'learning_rate': 4.7802691019093896e-05, 'epoch': 0.13183853885436633, 'step': 732000}
INFO:transformers.trainer:{'loss': 3.362058089017868, 'learning_rate': 4.7801190124981255e-05, 'epoch': 0.13192859250112476, 'step': 732500}
INFO:transformers.trainer:{'loss': 3.345006068468094, 'learning_rate': 4.7799689230868614e-05, 'epoch': 0.13201864614788322, 'step': 733000}
INFO:transformers.trainer:{'loss': 3.2845176529884337, 'learning_rate': 4.779818833675597e-05, 'epoch': 0.13210869979464165, 'step': 733500}
INFO:transformers.trainer:{'loss': 3.378081092119217, 'learning_rate': 4.779668744264333e-05, 'epoch': 0.1321987534414001, 'step': 734000}
INFO:transformers.trainer:{'loss': 3.3885383751392366, 'learning_rate': 4.779518654853069e-05, 'epoch': 0.13228880708815854, 'step': 734500}
INFO:transformers.trainer:{'loss': 3.3790302374362944, 'learning_rate': 4.779368565441805e-05, 'epoch': 0.132378860734917, 'step': 735000}
INFO:transformers.trainer:{'loss': 3.375112452507019, 'learning_rate': 4.7792184760305416e-05, 'epoch': 0.13246891438167546, 'step': 735500}
INFO:transformers.trainer:{'loss': 3.3733969299793243, 'learning_rate': 4.779068386619277e-05, 'epoch': 0.1325589680284339, 'step': 736000}
INFO:transformers.trainer:{'loss': 3.356027511358261, 'learning_rate': 4.7789182972080134e-05, 'epoch': 0.13264902167519235, 'step': 736500}
INFO:transformers.trainer:{'loss': 3.3375921881198884, 'learning_rate': 4.7787682077967486e-05, 'epoch': 0.13273907532195078, 'step': 737000}
INFO:transformers.trainer:{'loss': 3.42636414372921, 'learning_rate': 4.778618118385485e-05, 'epoch': 0.13282912896870924, 'step': 737500}
INFO:transformers.trainer:{'loss': 3.3451498296260835, 'learning_rate': 4.7784680289742204e-05, 'epoch': 0.13291918261546767, 'step': 738000}
INFO:transformers.trainer:{'loss': 3.302088965892792, 'learning_rate': 4.778317939562957e-05, 'epoch': 0.13300923626222613, 'step': 738500}
INFO:transformers.trainer:{'loss': 3.3278290038108826, 'learning_rate': 4.778167850151692e-05, 'epoch': 0.1330992899089846, 'step': 739000}
INFO:transformers.trainer:{'loss': 3.3663659710884093, 'learning_rate': 4.778017760740429e-05, 'epoch': 0.13318934355574302, 'step': 739500}
INFO:transformers.trainer:{'loss': 3.369701072692871, 'learning_rate': 4.777867671329164e-05, 'epoch': 0.13327939720250148, 'step': 740000}
INFO:transformers.trainer:{'loss': 3.3014359703063967, 'learning_rate': 4.7777175819179006e-05, 'epoch': 0.1333694508492599, 'step': 740500}
INFO:transformers.trainer:{'loss': 3.305182754278183, 'learning_rate': 4.777567492506636e-05, 'epoch': 0.13345950449601837, 'step': 741000}
INFO:transformers.trainer:{'loss': 3.3813582575321197, 'learning_rate': 4.7774174030953724e-05, 'epoch': 0.1335495581427768, 'step': 741500}
INFO:transformers.trainer:{'loss': 3.3769077055454253, 'learning_rate': 4.777267313684108e-05, 'epoch': 0.13363961178953526, 'step': 742000}
INFO:transformers.trainer:{'loss': 3.3781732478141784, 'learning_rate': 4.777117224272844e-05, 'epoch': 0.13372966543629372, 'step': 742500}
INFO:transformers.trainer:{'loss': 3.38141859126091, 'learning_rate': 4.77696713486158e-05, 'epoch': 0.13381971908305215, 'step': 743000}
INFO:transformers.trainer:{'loss': 3.2774851211309435, 'learning_rate': 4.776817045450316e-05, 'epoch': 0.1339097727298106, 'step': 743500}
INFO:transformers.trainer:{'loss': 3.3782293610572816, 'learning_rate': 4.776666956039052e-05, 'epoch': 0.13399982637656904, 'step': 744000}
INFO:transformers.trainer:{'loss': 3.404492097854614, 'learning_rate': 4.776516866627788e-05, 'epoch': 0.1340898800233275, 'step': 744500}
INFO:transformers.trainer:{'loss': 3.377413695335388, 'learning_rate': 4.776366777216524e-05, 'epoch': 0.13417993367008593, 'step': 745000}
INFO:transformers.trainer:{'loss': 3.381650867342949, 'learning_rate': 4.77621668780526e-05, 'epoch': 0.1342699873168444, 'step': 745500}
INFO:transformers.trainer:{'loss': 3.300220449924469, 'learning_rate': 4.7760665983939956e-05, 'epoch': 0.13436004096360285, 'step': 746000}
INFO:transformers.trainer:{'loss': 3.400878611803055, 'learning_rate': 4.7759165089827315e-05, 'epoch': 0.13445009461036128, 'step': 746500}
INFO:transformers.trainer:{'loss': 3.3434378781318665, 'learning_rate': 4.7757664195714674e-05, 'epoch': 0.13454014825711974, 'step': 747000}
INFO:transformers.trainer:{'loss': 3.364597954183817, 'learning_rate': 4.775616330160203e-05, 'epoch': 0.13463020190387817, 'step': 747500}
INFO:transformers.trainer:{'loss': 3.3377062363624574, 'learning_rate': 4.775466240748939e-05, 'epoch': 0.13472025555063663, 'step': 748000}
INFO:transformers.trainer:{'loss': 3.3804448281526565, 'learning_rate': 4.775316151337675e-05, 'epoch': 0.13481030919739506, 'step': 748500}
INFO:transformers.trainer:{'loss': 3.3638278379440307, 'learning_rate': 4.775166061926411e-05, 'epoch': 0.13490036284415352, 'step': 749000}
INFO:transformers.trainer:{'loss': 3.380323754310608, 'learning_rate': 4.775015972515147e-05, 'epoch': 0.13499041649091198, 'step': 749500}
INFO:transformers.trainer:{'loss': 3.37015056848526, 'learning_rate': 4.774865883103883e-05, 'epoch': 0.1350804701376704, 'step': 750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.407335032939911, 'learning_rate': 4.774715793692619e-05, 'epoch': 0.13517052378442887, 'step': 750500}
INFO:transformers.trainer:{'loss': 3.322940842628479, 'learning_rate': 4.7745657042813546e-05, 'epoch': 0.1352605774311873, 'step': 751000}
INFO:transformers.trainer:{'loss': 3.4047886428833007, 'learning_rate': 4.7744156148700905e-05, 'epoch': 0.13535063107794576, 'step': 751500}
INFO:transformers.trainer:{'loss': 3.3335759341716766, 'learning_rate': 4.7742655254588264e-05, 'epoch': 0.1354406847247042, 'step': 752000}
INFO:transformers.trainer:{'loss': 3.3866521582603455, 'learning_rate': 4.7741154360475623e-05, 'epoch': 0.13553073837146265, 'step': 752500}
INFO:transformers.trainer:{'loss': 3.354815839767456, 'learning_rate': 4.773965346636298e-05, 'epoch': 0.13562079201822108, 'step': 753000}
INFO:transformers.trainer:{'loss': 3.404979273080826, 'learning_rate': 4.773815257225034e-05, 'epoch': 0.13571084566497954, 'step': 753500}
INFO:transformers.trainer:{'loss': 3.3624435863494875, 'learning_rate': 4.77366516781377e-05, 'epoch': 0.135800899311738, 'step': 754000}
INFO:transformers.trainer:{'loss': 3.335238624572754, 'learning_rate': 4.773515078402506e-05, 'epoch': 0.13589095295849643, 'step': 754500}
INFO:transformers.trainer:{'loss': 3.313209639787674, 'learning_rate': 4.773364988991242e-05, 'epoch': 0.1359810066052549, 'step': 755000}
INFO:transformers.trainer:{'loss': 3.4129472979307174, 'learning_rate': 4.773214899579978e-05, 'epoch': 0.13607106025201332, 'step': 755500}
INFO:transformers.trainer:{'loss': 3.3304751167297364, 'learning_rate': 4.7730648101687144e-05, 'epoch': 0.13616111389877178, 'step': 756000}
INFO:transformers.trainer:{'loss': 3.3720932931900025, 'learning_rate': 4.7729147207574496e-05, 'epoch': 0.1362511675455302, 'step': 756500}
INFO:transformers.trainer:{'loss': 3.369288775444031, 'learning_rate': 4.772764631346186e-05, 'epoch': 0.13634122119228867, 'step': 757000}
INFO:transformers.trainer:{'loss': 3.284535185098648, 'learning_rate': 4.7726145419349214e-05, 'epoch': 0.13643127483904713, 'step': 757500}
INFO:transformers.trainer:{'loss': 3.381022646188736, 'learning_rate': 4.772464452523658e-05, 'epoch': 0.13652132848580556, 'step': 758000}
INFO:transformers.trainer:{'loss': 3.392794013977051, 'learning_rate': 4.772314363112393e-05, 'epoch': 0.13661138213256402, 'step': 758500}
INFO:transformers.trainer:{'loss': 3.349748921632767, 'learning_rate': 4.77216427370113e-05, 'epoch': 0.13670143577932245, 'step': 759000}
INFO:transformers.trainer:{'loss': 3.3626016290187835, 'learning_rate': 4.772014184289865e-05, 'epoch': 0.1367914894260809, 'step': 759500}
INFO:transformers.trainer:{'loss': 3.3837209141254423, 'learning_rate': 4.7718640948786016e-05, 'epoch': 0.13688154307283934, 'step': 760000}
INFO:transformers.trainer:{'loss': 3.3901627609729768, 'learning_rate': 4.771714005467337e-05, 'epoch': 0.1369715967195978, 'step': 760500}
INFO:transformers.trainer:{'loss': 3.3583427901268004, 'learning_rate': 4.7715639160560734e-05, 'epoch': 0.13706165036635626, 'step': 761000}
INFO:transformers.trainer:{'loss': 3.32170690369606, 'learning_rate': 4.7714138266448086e-05, 'epoch': 0.1371517040131147, 'step': 761500}
INFO:transformers.trainer:{'loss': 3.3657849798202513, 'learning_rate': 4.771263737233545e-05, 'epoch': 0.13724175765987315, 'step': 762000}
INFO:transformers.trainer:{'loss': 3.369506534576416, 'learning_rate': 4.7711136478222804e-05, 'epoch': 0.13733181130663158, 'step': 762500}
INFO:transformers.trainer:{'loss': 3.3212516069412232, 'learning_rate': 4.770963558411017e-05, 'epoch': 0.13742186495339004, 'step': 763000}
INFO:transformers.trainer:{'loss': 3.331048941731453, 'learning_rate': 4.770813468999753e-05, 'epoch': 0.13751191860014847, 'step': 763500}
INFO:transformers.trainer:{'loss': 3.4131277225017547, 'learning_rate': 4.770663379588489e-05, 'epoch': 0.13760197224690693, 'step': 764000}
INFO:transformers.trainer:{'loss': 3.3787189121246337, 'learning_rate': 4.770513290177225e-05, 'epoch': 0.1376920258936654, 'step': 764500}
INFO:transformers.trainer:{'loss': 3.3465792062282564, 'learning_rate': 4.7703632007659606e-05, 'epoch': 0.13778207954042382, 'step': 765000}
INFO:transformers.trainer:{'loss': 3.3835107374191282, 'learning_rate': 4.7702131113546965e-05, 'epoch': 0.13787213318718228, 'step': 765500}
INFO:transformers.trainer:{'loss': 3.376488310575485, 'learning_rate': 4.7700630219434325e-05, 'epoch': 0.1379621868339407, 'step': 766000}
INFO:__main__:inputFile: ../../language-detector/fasttext/twitter_edin_50_en, outputDir: ../outputs/edin_tuned/bert_ft, model: 1
INFO:__main__:iniciando...
INFO:__main__:running ft bert
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140058369157104 on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock
INFO:filelock:Lock 140058369157104 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock
INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp1p1fiold
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "GET /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 231508
INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG:filelock:Attempting to release lock 140058369157104 on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock
INFO:filelock:Lock 140058369157104 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140058369158592 on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock
INFO:filelock:Lock 140058369158592 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock
INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpflki7y04
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "GET /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 433
INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
DEBUG:filelock:Attempting to release lock 140058369158592 on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock
INFO:filelock:Lock 140058369158592 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140058369158400 on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock
INFO:filelock:Lock 140058369158400 acquired on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock
INFO:transformers.file_utils:https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpkm0ss8m9
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "GET /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 440473133
INFO:transformers.trainer:{'loss': 3.3958372159004213, 'learning_rate': 4.7699129325321684e-05, 'epoch': 0.13805224048069917, 'step': 766500}
INFO:transformers.file_utils:storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
DEBUG:filelock:Attempting to release lock 140058369158400 on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock
INFO:filelock:Lock 140058369158400 released on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock
INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing BertModel.

INFO:transformers.modeling_utils:All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:transformers.modeling_utils:Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
INFO:transformers.data.datasets.language_modeling:Creating features from dataset file at ../../language-detector/fasttext/twitter_edin_50_en
INFO:transformers.trainer:{'loss': 3.3188325189352037, 'learning_rate': 4.769762843120904e-05, 'epoch': 0.1381422941274576, 'step': 767000}
INFO:transformers.trainer:{'loss': 3.3137657232284545, 'learning_rate': 4.76961275370964e-05, 'epoch': 0.13823234777421606, 'step': 767500}
INFO:transformers.trainer:{'loss': 3.343907304763794, 'learning_rate': 4.769462664298376e-05, 'epoch': 0.13832240142097452, 'step': 768000}
INFO:__main__:inputFile: ../../language-detector/fasttext/twitter_edin_50_en, outputDir: ../outputs/edin_tuned/bert_ft, model: 1
INFO:__main__:iniciando...
INFO:__main__:running ft bert
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing BertModel.

INFO:transformers.modeling_utils:All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1" 200 0
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-uncased-config.json HTTP/1.1" 200 0
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co:443
DEBUG:urllib3.connectionpool:https://cdn.huggingface.co:443 "HEAD /bert-base-uncased-pytorch_model.bin HTTP/1.1" 200 0
INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:transformers.modeling_utils:Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
INFO:transformers.data.datasets.language_modeling:Creating features from dataset file at ../../language-detector/fasttext/twitter_edin_50_en
INFO:transformers.trainer:{'loss': 3.299280073881149, 'learning_rate': 4.769312574887112e-05, 'epoch': 0.13841245506773295, 'step': 768500}
INFO:transformers.trainer:{'loss': 3.3448431357145307, 'learning_rate': 4.769162485475848e-05, 'epoch': 0.1385025087144914, 'step': 769000}
INFO:transformers.trainer:{'loss': 3.4020699007511137, 'learning_rate': 4.769012396064584e-05, 'epoch': 0.13859256236124984, 'step': 769500}
INFO:transformers.trainer:{'loss': 3.281877579450607, 'learning_rate': 4.76886230665332e-05, 'epoch': 0.1386826160080083, 'step': 770000}
INFO:transformers.trainer:{'loss': 3.3327787861824034, 'learning_rate': 4.7687122172420556e-05, 'epoch': 0.13877266965476673, 'step': 770500}
INFO:transformers.trainer:{'loss': 3.305930460214615, 'learning_rate': 4.7685621278307915e-05, 'epoch': 0.1388627233015252, 'step': 771000}
INFO:transformers.trainer:{'loss': 3.39001855301857, 'learning_rate': 4.7684120384195274e-05, 'epoch': 0.13895277694828362, 'step': 771500}
INFO:transformers.trainer:{'loss': 3.363163860082626, 'learning_rate': 4.768261949008263e-05, 'epoch': 0.13904283059504208, 'step': 772000}
INFO:transformers.trainer:{'loss': 3.3741512892246246, 'learning_rate': 4.768111859596999e-05, 'epoch': 0.13913288424180054, 'step': 772500}
INFO:transformers.trainer:{'loss': 3.3293022987842558, 'learning_rate': 4.767961770185735e-05, 'epoch': 0.13922293788855897, 'step': 773000}
INFO:transformers.trainer:{'loss': 3.2937036616802216, 'learning_rate': 4.767811680774471e-05, 'epoch': 0.13931299153531743, 'step': 773500}
INFO:transformers.trainer:{'loss': 3.3437172675132754, 'learning_rate': 4.767661591363207e-05, 'epoch': 0.13940304518207586, 'step': 774000}
INFO:transformers.trainer:{'loss': 3.3606644310951235, 'learning_rate': 4.767511501951943e-05, 'epoch': 0.13949309882883432, 'step': 774500}
INFO:transformers.trainer:{'loss': 3.35785050702095, 'learning_rate': 4.767361412540679e-05, 'epoch': 0.13958315247559275, 'step': 775000}
INFO:transformers.trainer:{'loss': 3.355322479009628, 'learning_rate': 4.7672113231294146e-05, 'epoch': 0.1396732061223512, 'step': 775500}
INFO:transformers.trainer:{'loss': 3.3887519984245302, 'learning_rate': 4.7670612337181506e-05, 'epoch': 0.13976325976910967, 'step': 776000}
INFO:transformers.trainer:{'loss': 3.330837630391121, 'learning_rate': 4.7669111443068865e-05, 'epoch': 0.1398533134158681, 'step': 776500}
INFO:transformers.trainer:{'loss': 3.3420000813007356, 'learning_rate': 4.7667610548956224e-05, 'epoch': 0.13994336706262656, 'step': 777000}
INFO:transformers.trainer:{'loss': 3.345139748096466, 'learning_rate': 4.766610965484359e-05, 'epoch': 0.140033420709385, 'step': 777500}
INFO:transformers.trainer:{'loss': 3.3268998985290525, 'learning_rate': 4.766460876073094e-05, 'epoch': 0.14012347435614345, 'step': 778000}
INFO:__main__:inputFile: ../../language-detector/fasttext/twitter_edin_50_en2, outputDir: ../outputs/edin_tuned/bert_ft, model: 1
INFO:__main__:iniciando...
INFO:__main__:running ft bert
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing BertModel.

INFO:transformers.modeling_utils:All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.
INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:transformers.modeling_utils:Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
INFO:transformers.data.datasets.language_modeling:Creating features from dataset file at ../../language-detector/fasttext/twitter_edin_50_en2
INFO:transformers.trainer:{'loss': 3.345231167793274, 'learning_rate': 4.766310786661831e-05, 'epoch': 0.14021352800290188, 'step': 778500}
INFO:transformers.trainer:{'loss': 3.351762323617935, 'learning_rate': 4.766160697250566e-05, 'epoch': 0.14030358164966034, 'step': 779000}
INFO:transformers.trainer:{'loss': 3.359998859643936, 'learning_rate': 4.7660106078393026e-05, 'epoch': 0.1403936352964188, 'step': 779500}
INFO:transformers.trainer:{'loss': 3.3952838225364683, 'learning_rate': 4.765860518428038e-05, 'epoch': 0.14048368894317723, 'step': 780000}
INFO:transformers.trainer:{'loss': 3.381878594636917, 'learning_rate': 4.7657104290167744e-05, 'epoch': 0.14057374258993569, 'step': 780500}
INFO:transformers.trainer:{'loss': 3.3315624923706055, 'learning_rate': 4.7655603396055096e-05, 'epoch': 0.14066379623669412, 'step': 781000}
INFO:transformers.trainer:{'loss': 3.342068888425827, 'learning_rate': 4.765410250194246e-05, 'epoch': 0.14075384988345258, 'step': 781500}
INFO:transformers.trainer:{'loss': 3.3097415974140167, 'learning_rate': 4.7652601607829814e-05, 'epoch': 0.140843903530211, 'step': 782000}
INFO:transformers.trainer:{'loss': 3.3542830266952515, 'learning_rate': 4.765110071371718e-05, 'epoch': 0.14093395717696947, 'step': 782500}
INFO:transformers.trainer:{'loss': 3.33836886882782, 'learning_rate': 4.764959981960453e-05, 'epoch': 0.14102401082372792, 'step': 783000}
INFO:transformers.trainer:{'loss': 3.4427278423309327, 'learning_rate': 4.76480989254919e-05, 'epoch': 0.14111406447048636, 'step': 783500}
INFO:transformers.trainer:{'loss': 3.344445229291916, 'learning_rate': 4.764659803137926e-05, 'epoch': 0.14120411811724481, 'step': 784000}
INFO:transformers.trainer:{'loss': 3.326789682149887, 'learning_rate': 4.7645097137266616e-05, 'epoch': 0.14129417176400325, 'step': 784500}
INFO:transformers.trainer:{'loss': 3.3586845922470094, 'learning_rate': 4.7643596243153975e-05, 'epoch': 0.1413842254107617, 'step': 785000}
INFO:transformers.trainer:{'loss': 3.322712849378586, 'learning_rate': 4.7642095349041334e-05, 'epoch': 0.14147427905752014, 'step': 785500}
INFO:transformers.trainer:{'loss': 3.3174518027305604, 'learning_rate': 4.764059445492869e-05, 'epoch': 0.1415643327042786, 'step': 786000}
INFO:transformers.trainer:{'loss': 3.3137855269908907, 'learning_rate': 4.763909356081605e-05, 'epoch': 0.14165438635103703, 'step': 786500}
INFO:transformers.trainer:{'loss': 3.3916452062129974, 'learning_rate': 4.763759266670341e-05, 'epoch': 0.14174443999779548, 'step': 787000}
INFO:transformers.trainer:{'loss': 3.3820027165412903, 'learning_rate': 4.763609177259077e-05, 'epoch': 0.14183449364455394, 'step': 787500}
INFO:transformers.trainer:{'loss': 3.3748075134754183, 'learning_rate': 4.763459087847813e-05, 'epoch': 0.14192454729131238, 'step': 788000}
INFO:transformers.trainer:{'loss': 3.3933766293525696, 'learning_rate': 4.763308998436549e-05, 'epoch': 0.14201460093807083, 'step': 788500}
INFO:transformers.trainer:{'loss': 3.326462495088577, 'learning_rate': 4.763158909025285e-05, 'epoch': 0.14210465458482927, 'step': 789000}
INFO:transformers.trainer:{'loss': 3.3692966560125353, 'learning_rate': 4.763008819614021e-05, 'epoch': 0.14219470823158772, 'step': 789500}
INFO:transformers.trainer:{'loss': 3.37467812538147, 'learning_rate': 4.7628587302027566e-05, 'epoch': 0.14228476187834616, 'step': 790000}
INFO:transformers.trainer:{'loss': 3.329055713891983, 'learning_rate': 4.7627086407914925e-05, 'epoch': 0.14237481552510461, 'step': 790500}
INFO:transformers.trainer:{'loss': 3.352149925708771, 'learning_rate': 4.7625585513802284e-05, 'epoch': 0.14246486917186307, 'step': 791000}
INFO:transformers.trainer:{'loss': 3.313536607980728, 'learning_rate': 4.762408461968964e-05, 'epoch': 0.1425549228186215, 'step': 791500}
INFO:transformers.trainer:{'loss': 3.326814061880112, 'learning_rate': 4.7622583725577e-05, 'epoch': 0.14264497646537996, 'step': 792000}
INFO:transformers.trainer:{'loss': 3.3401400628089903, 'learning_rate': 4.762108283146436e-05, 'epoch': 0.1427350301121384, 'step': 792500}
INFO:transformers.trainer:{'loss': 3.3233133351802824, 'learning_rate': 4.761958193735172e-05, 'epoch': 0.14282508375889685, 'step': 793000}
INFO:transformers.trainer:{'loss': 3.3668789269924164, 'learning_rate': 4.761808104323908e-05, 'epoch': 0.14291513740565528, 'step': 793500}
INFO:transformers.trainer:{'loss': 3.326780131816864, 'learning_rate': 4.761658014912644e-05, 'epoch': 0.14300519105241374, 'step': 794000}
INFO:transformers.trainer:{'loss': 3.4003876702785494, 'learning_rate': 4.76150792550138e-05, 'epoch': 0.1430952446991722, 'step': 794500}
INFO:transformers.trainer:{'loss': 3.3747259345054625, 'learning_rate': 4.7613578360901156e-05, 'epoch': 0.14318529834593063, 'step': 795000}
INFO:transformers.trainer:{'loss': 3.347690229177475, 'learning_rate': 4.7612077466788515e-05, 'epoch': 0.1432753519926891, 'step': 795500}
INFO:transformers.trainer:{'loss': 3.293746162891388, 'learning_rate': 4.7610576572675874e-05, 'epoch': 0.14336540563944752, 'step': 796000}
INFO:transformers.trainer:{'loss': 3.2878226370811463, 'learning_rate': 4.760907567856323e-05, 'epoch': 0.14345545928620598, 'step': 796500}
INFO:transformers.trainer:{'loss': 3.366328860282898, 'learning_rate': 4.760757478445059e-05, 'epoch': 0.14354551293296441, 'step': 797000}
INFO:transformers.trainer:{'loss': 3.3317199676036835, 'learning_rate': 4.760607389033795e-05, 'epoch': 0.14363556657972287, 'step': 797500}
INFO:transformers.trainer:{'loss': 3.367892947435379, 'learning_rate': 4.760457299622532e-05, 'epoch': 0.14372562022648133, 'step': 798000}
INFO:transformers.trainer:{'loss': 3.312868342399597, 'learning_rate': 4.760307210211267e-05, 'epoch': 0.14381567387323976, 'step': 798500}
INFO:transformers.trainer:{'loss': 3.355857038259506, 'learning_rate': 4.7601571208000035e-05, 'epoch': 0.14390572751999822, 'step': 799000}
INFO:transformers.trainer:{'loss': 3.3013293464183806, 'learning_rate': 4.760007031388739e-05, 'epoch': 0.14399578116675665, 'step': 799500}
INFO:transformers.trainer:{'loss': 3.376796000003815, 'learning_rate': 4.7598569419774754e-05, 'epoch': 0.1440858348135151, 'step': 800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3412477703094483, 'learning_rate': 4.7597068525662106e-05, 'epoch': 0.14417588846027354, 'step': 800500}
INFO:transformers.trainer:{'loss': 3.349590784788132, 'learning_rate': 4.759556763154947e-05, 'epoch': 0.144265942107032, 'step': 801000}
INFO:transformers.trainer:{'loss': 3.3931584808826445, 'learning_rate': 4.7594066737436824e-05, 'epoch': 0.14435599575379046, 'step': 801500}
INFO:transformers.trainer:{'loss': 3.3589578042030332, 'learning_rate': 4.759256584332419e-05, 'epoch': 0.1444460494005489, 'step': 802000}
INFO:transformers.trainer:{'loss': 3.3618235092163085, 'learning_rate': 4.759106494921154e-05, 'epoch': 0.14453610304730735, 'step': 802500}
INFO:transformers.trainer:{'loss': 3.3834904861450195, 'learning_rate': 4.758956405509891e-05, 'epoch': 0.14462615669406578, 'step': 803000}
INFO:transformers.trainer:{'loss': 3.3290308067798615, 'learning_rate': 4.758806316098626e-05, 'epoch': 0.14471621034082424, 'step': 803500}
INFO:transformers.trainer:{'loss': 3.3614015786647795, 'learning_rate': 4.7586562266873626e-05, 'epoch': 0.14480626398758267, 'step': 804000}
INFO:transformers.trainer:{'loss': 3.2986343009471892, 'learning_rate': 4.7585061372760985e-05, 'epoch': 0.14489631763434113, 'step': 804500}
INFO:transformers.trainer:{'loss': 3.359172561645508, 'learning_rate': 4.7583560478648344e-05, 'epoch': 0.14498637128109956, 'step': 805000}
INFO:transformers.trainer:{'loss': 3.3102342076301574, 'learning_rate': 4.75820595845357e-05, 'epoch': 0.14507642492785802, 'step': 805500}
INFO:transformers.trainer:{'loss': 3.3889905750751494, 'learning_rate': 4.758055869042306e-05, 'epoch': 0.14516647857461648, 'step': 806000}
INFO:transformers.trainer:{'loss': 3.3253158264160154, 'learning_rate': 4.757905779631042e-05, 'epoch': 0.1452565322213749, 'step': 806500}
INFO:transformers.trainer:{'loss': 3.3352289669513704, 'learning_rate': 4.757755690219778e-05, 'epoch': 0.14534658586813337, 'step': 807000}
INFO:transformers.trainer:{'loss': 3.3468505115509033, 'learning_rate': 4.757605600808514e-05, 'epoch': 0.1454366395148918, 'step': 807500}
INFO:transformers.trainer:{'loss': 3.3604682064056397, 'learning_rate': 4.75745551139725e-05, 'epoch': 0.14552669316165026, 'step': 808000}
INFO:transformers.trainer:{'loss': 3.3200173023939135, 'learning_rate': 4.757305421985986e-05, 'epoch': 0.1456167468084087, 'step': 808500}
INFO:transformers.trainer:{'loss': 3.3836193056106567, 'learning_rate': 4.7571553325747216e-05, 'epoch': 0.14570680045516715, 'step': 809000}
INFO:transformers.trainer:{'loss': 3.354240139245987, 'learning_rate': 4.7570052431634575e-05, 'epoch': 0.1457968541019256, 'step': 809500}
INFO:transformers.trainer:{'loss': 3.316699201822281, 'learning_rate': 4.7568551537521935e-05, 'epoch': 0.14588690774868404, 'step': 810000}
INFO:transformers.trainer:{'loss': 3.3445852925777437, 'learning_rate': 4.7567050643409294e-05, 'epoch': 0.1459769613954425, 'step': 810500}
INFO:transformers.trainer:{'loss': 3.336196201324463, 'learning_rate': 4.756554974929665e-05, 'epoch': 0.14606701504220093, 'step': 811000}
INFO:transformers.trainer:{'loss': 3.3413900570869446, 'learning_rate': 4.756404885518401e-05, 'epoch': 0.1461570686889594, 'step': 811500}
INFO:transformers.trainer:{'loss': 3.361474130153656, 'learning_rate': 4.756254796107138e-05, 'epoch': 0.14624712233571782, 'step': 812000}
INFO:transformers.trainer:{'loss': 3.340105523824692, 'learning_rate': 4.756104706695873e-05, 'epoch': 0.14633717598247628, 'step': 812500}
INFO:transformers.trainer:{'loss': 3.410342874765396, 'learning_rate': 4.7559546172846096e-05, 'epoch': 0.14642722962923474, 'step': 813000}
INFO:transformers.trainer:{'loss': 3.3336738283634184, 'learning_rate': 4.755804527873345e-05, 'epoch': 0.14651728327599317, 'step': 813500}
INFO:transformers.trainer:{'loss': 3.364669178724289, 'learning_rate': 4.7556544384620814e-05, 'epoch': 0.14660733692275163, 'step': 814000}
INFO:transformers.trainer:{'loss': 3.402891077518463, 'learning_rate': 4.7555043490508166e-05, 'epoch': 0.14669739056951006, 'step': 814500}
INFO:transformers.trainer:{'loss': 3.3645341567993166, 'learning_rate': 4.7553542596395525e-05, 'epoch': 0.14678744421626852, 'step': 815000}
INFO:transformers.trainer:{'loss': 3.3488831465244293, 'learning_rate': 4.7552041702282884e-05, 'epoch': 0.14687749786302695, 'step': 815500}
INFO:transformers.trainer:{'loss': 3.3051252379417417, 'learning_rate': 4.755054080817024e-05, 'epoch': 0.1469675515097854, 'step': 816000}
INFO:transformers.trainer:{'loss': 3.379724270820618, 'learning_rate': 4.75490399140576e-05, 'epoch': 0.14705760515654387, 'step': 816500}
INFO:transformers.trainer:{'loss': 3.3603404798507692, 'learning_rate': 4.754753901994496e-05, 'epoch': 0.1471476588033023, 'step': 817000}
INFO:transformers.trainer:{'loss': 3.358974883913994, 'learning_rate': 4.754603812583232e-05, 'epoch': 0.14723771245006076, 'step': 817500}
INFO:transformers.trainer:{'loss': 3.319920844078064, 'learning_rate': 4.754453723171968e-05, 'epoch': 0.1473277660968192, 'step': 818000}
INFO:transformers.trainer:{'loss': 3.34807921230793, 'learning_rate': 4.7543036337607045e-05, 'epoch': 0.14741781974357765, 'step': 818500}
INFO:transformers.trainer:{'loss': 3.374044529914856, 'learning_rate': 4.75415354434944e-05, 'epoch': 0.14750787339033608, 'step': 819000}
INFO:transformers.trainer:{'loss': 3.3559862141609194, 'learning_rate': 4.754003454938176e-05, 'epoch': 0.14759792703709454, 'step': 819500}
INFO:transformers.trainer:{'loss': 3.3603832457065583, 'learning_rate': 4.7538533655269116e-05, 'epoch': 0.147687980683853, 'step': 820000}
INFO:transformers.trainer:{'loss': 3.383098704099655, 'learning_rate': 4.753703276115648e-05, 'epoch': 0.14777803433061143, 'step': 820500}
INFO:transformers.trainer:{'loss': 3.3517019097805023, 'learning_rate': 4.7535531867043834e-05, 'epoch': 0.1478680879773699, 'step': 821000}
INFO:transformers.trainer:{'loss': 3.3557858805656435, 'learning_rate': 4.75340309729312e-05, 'epoch': 0.14795814162412832, 'step': 821500}
INFO:transformers.trainer:{'loss': 3.360066062450409, 'learning_rate': 4.753253007881855e-05, 'epoch': 0.14804819527088678, 'step': 822000}
INFO:transformers.trainer:{'loss': 3.3828908812999727, 'learning_rate': 4.753102918470592e-05, 'epoch': 0.1481382489176452, 'step': 822500}
INFO:transformers.trainer:{'loss': 3.361809166908264, 'learning_rate': 4.752952829059327e-05, 'epoch': 0.14822830256440367, 'step': 823000}
INFO:transformers.trainer:{'loss': 3.3639498209953307, 'learning_rate': 4.7528027396480636e-05, 'epoch': 0.1483183562111621, 'step': 823500}
INFO:transformers.trainer:{'loss': 3.3537048182487488, 'learning_rate': 4.752652650236799e-05, 'epoch': 0.14840840985792056, 'step': 824000}
INFO:transformers.trainer:{'loss': 3.3511257960796357, 'learning_rate': 4.7525025608255354e-05, 'epoch': 0.14849846350467902, 'step': 824500}
INFO:transformers.trainer:{'loss': 3.342294264793396, 'learning_rate': 4.7523524714142706e-05, 'epoch': 0.14858851715143745, 'step': 825000}
INFO:transformers.trainer:{'loss': 3.2851878442764284, 'learning_rate': 4.752202382003007e-05, 'epoch': 0.1486785707981959, 'step': 825500}
INFO:transformers.trainer:{'loss': 3.302111727952957, 'learning_rate': 4.752052292591743e-05, 'epoch': 0.14876862444495434, 'step': 826000}
INFO:transformers.trainer:{'loss': 3.3848685252666475, 'learning_rate': 4.751902203180479e-05, 'epoch': 0.1488586780917128, 'step': 826500}
INFO:transformers.trainer:{'loss': 3.332599057674408, 'learning_rate': 4.751752113769215e-05, 'epoch': 0.14894873173847123, 'step': 827000}
INFO:transformers.trainer:{'loss': 3.329917322397232, 'learning_rate': 4.751602024357951e-05, 'epoch': 0.1490387853852297, 'step': 827500}
INFO:transformers.trainer:{'loss': 3.3431705129146576, 'learning_rate': 4.751451934946687e-05, 'epoch': 0.14912883903198815, 'step': 828000}
INFO:transformers.trainer:{'loss': 3.3084967648983, 'learning_rate': 4.7513018455354226e-05, 'epoch': 0.14921889267874658, 'step': 828500}
INFO:transformers.trainer:{'loss': 3.360123199462891, 'learning_rate': 4.7511517561241585e-05, 'epoch': 0.14930894632550504, 'step': 829000}
INFO:transformers.trainer:{'loss': 3.2915044384002687, 'learning_rate': 4.7510016667128944e-05, 'epoch': 0.14939899997226347, 'step': 829500}
INFO:transformers.trainer:{'loss': 3.498505718946457, 'learning_rate': 4.75085157730163e-05, 'epoch': 0.14948905361902193, 'step': 830000}
INFO:transformers.trainer:{'loss': 3.3727706887722015, 'learning_rate': 4.750701487890366e-05, 'epoch': 0.14957910726578036, 'step': 830500}
INFO:transformers.trainer:{'loss': 3.3451898677349092, 'learning_rate': 4.750551398479102e-05, 'epoch': 0.14966916091253882, 'step': 831000}
INFO:transformers.trainer:{'loss': 3.3431376283168794, 'learning_rate': 4.750401309067838e-05, 'epoch': 0.14975921455929728, 'step': 831500}
INFO:transformers.trainer:{'loss': 3.381990607261658, 'learning_rate': 4.750251219656574e-05, 'epoch': 0.1498492682060557, 'step': 832000}
INFO:transformers.trainer:{'loss': 3.3611162700653074, 'learning_rate': 4.7501011302453105e-05, 'epoch': 0.14993932185281417, 'step': 832500}
INFO:transformers.trainer:{'loss': 3.4120014519691466, 'learning_rate': 4.749951040834046e-05, 'epoch': 0.1500293754995726, 'step': 833000}
INFO:transformers.trainer:{'loss': 3.4298687994480135, 'learning_rate': 4.7498009514227823e-05, 'epoch': 0.15011942914633106, 'step': 833500}
INFO:transformers.trainer:{'loss': 3.358808109164238, 'learning_rate': 4.7496508620115176e-05, 'epoch': 0.1502094827930895, 'step': 834000}
INFO:transformers.trainer:{'loss': 3.389713168978691, 'learning_rate': 4.749500772600254e-05, 'epoch': 0.15029953643984795, 'step': 834500}
INFO:transformers.trainer:{'loss': 3.3592712272405625, 'learning_rate': 4.7493506831889894e-05, 'epoch': 0.1503895900866064, 'step': 835000}
INFO:transformers.trainer:{'loss': 3.3779469188451765, 'learning_rate': 4.749200593777726e-05, 'epoch': 0.15047964373336484, 'step': 835500}
INFO:transformers.trainer:{'loss': 3.3357603645324705, 'learning_rate': 4.749050504366461e-05, 'epoch': 0.1505696973801233, 'step': 836000}
INFO:transformers.trainer:{'loss': 3.3674460909366606, 'learning_rate': 4.748900414955198e-05, 'epoch': 0.15065975102688173, 'step': 836500}
INFO:transformers.trainer:{'loss': 3.3232824234962464, 'learning_rate': 4.748750325543933e-05, 'epoch': 0.1507498046736402, 'step': 837000}
INFO:transformers.trainer:{'loss': 3.3041727764606477, 'learning_rate': 4.7486002361326696e-05, 'epoch': 0.15083985832039862, 'step': 837500}
INFO:transformers.trainer:{'loss': 3.3521170907020568, 'learning_rate': 4.748450146721405e-05, 'epoch': 0.15092991196715708, 'step': 838000}
INFO:transformers.trainer:{'loss': 3.338040588617325, 'learning_rate': 4.748300057310141e-05, 'epoch': 0.15101996561391554, 'step': 838500}
INFO:transformers.trainer:{'loss': 3.383207940816879, 'learning_rate': 4.7481499678988766e-05, 'epoch': 0.15111001926067397, 'step': 839000}
INFO:transformers.trainer:{'loss': 3.361077578306198, 'learning_rate': 4.7479998784876125e-05, 'epoch': 0.15120007290743243, 'step': 839500}
INFO:transformers.trainer:{'loss': 3.3168542313575746, 'learning_rate': 4.747849789076349e-05, 'epoch': 0.15129012655419086, 'step': 840000}
INFO:transformers.trainer:{'loss': 3.3349914581775666, 'learning_rate': 4.747699699665084e-05, 'epoch': 0.15138018020094932, 'step': 840500}
INFO:transformers.trainer:{'loss': 3.3551368823051453, 'learning_rate': 4.747549610253821e-05, 'epoch': 0.15147023384770775, 'step': 841000}
INFO:transformers.trainer:{'loss': 3.310194657564163, 'learning_rate': 4.747399520842556e-05, 'epoch': 0.1515602874944662, 'step': 841500}
INFO:transformers.trainer:{'loss': 3.3566104762554168, 'learning_rate': 4.747249431431293e-05, 'epoch': 0.15165034114122464, 'step': 842000}
INFO:transformers.trainer:{'loss': 3.3567899341583254, 'learning_rate': 4.747099342020028e-05, 'epoch': 0.1517403947879831, 'step': 842500}
INFO:transformers.trainer:{'loss': 3.3604371395111086, 'learning_rate': 4.7469492526087645e-05, 'epoch': 0.15183044843474156, 'step': 843000}
INFO:transformers.trainer:{'loss': 3.3733653151988983, 'learning_rate': 4.7467991631975e-05, 'epoch': 0.1519205020815, 'step': 843500}
INFO:transformers.trainer:{'loss': 3.3292411053180695, 'learning_rate': 4.7466490737862363e-05, 'epoch': 0.15201055572825845, 'step': 844000}
INFO:transformers.trainer:{'loss': 3.389927967786789, 'learning_rate': 4.7464989843749716e-05, 'epoch': 0.15210060937501688, 'step': 844500}
INFO:transformers.trainer:{'loss': 3.4132332317829133, 'learning_rate': 4.746348894963708e-05, 'epoch': 0.15219066302177534, 'step': 845000}
INFO:transformers.trainer:{'loss': 3.344173372030258, 'learning_rate': 4.7461988055524434e-05, 'epoch': 0.15228071666853377, 'step': 845500}
INFO:transformers.trainer:{'loss': 3.3923470120429995, 'learning_rate': 4.74604871614118e-05, 'epoch': 0.15237077031529223, 'step': 846000}
INFO:transformers.trainer:{'loss': 3.376118757724762, 'learning_rate': 4.745898626729916e-05, 'epoch': 0.15246082396205068, 'step': 846500}
INFO:transformers.trainer:{'loss': 3.342066050052643, 'learning_rate': 4.745748537318652e-05, 'epoch': 0.15255087760880912, 'step': 847000}
INFO:transformers.trainer:{'loss': 3.3142280131578445, 'learning_rate': 4.745598447907388e-05, 'epoch': 0.15264093125556757, 'step': 847500}
INFO:transformers.trainer:{'loss': 3.308935065507889, 'learning_rate': 4.7454483584961236e-05, 'epoch': 0.152730984902326, 'step': 848000}
INFO:transformers.trainer:{'loss': 3.321580055475235, 'learning_rate': 4.7452982690848595e-05, 'epoch': 0.15282103854908446, 'step': 848500}
INFO:transformers.trainer:{'loss': 3.3508098812103273, 'learning_rate': 4.7451481796735954e-05, 'epoch': 0.1529110921958429, 'step': 849000}
INFO:transformers.trainer:{'loss': 3.319675155878067, 'learning_rate': 4.744998090262331e-05, 'epoch': 0.15300114584260135, 'step': 849500}
INFO:transformers.trainer:{'loss': 3.3331166136264803, 'learning_rate': 4.744848000851067e-05, 'epoch': 0.1530911994893598, 'step': 850000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-850000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-850000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-850000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-750000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.312418027639389, 'learning_rate': 4.744697911439803e-05, 'epoch': 0.15318125313611825, 'step': 850500}
INFO:transformers.trainer:{'loss': 3.4232486317157744, 'learning_rate': 4.744547822028539e-05, 'epoch': 0.1532713067828767, 'step': 851000}
INFO:transformers.trainer:{'loss': 3.3473682564496996, 'learning_rate': 4.744397732617275e-05, 'epoch': 0.15336136042963514, 'step': 851500}
INFO:transformers.trainer:{'loss': 3.3231775271892547, 'learning_rate': 4.744247643206011e-05, 'epoch': 0.1534514140763936, 'step': 852000}
INFO:transformers.trainer:{'loss': 3.279061315536499, 'learning_rate': 4.744097553794747e-05, 'epoch': 0.15354146772315203, 'step': 852500}
INFO:transformers.trainer:{'loss': 3.4010460066795347, 'learning_rate': 4.743947464383483e-05, 'epoch': 0.15363152136991048, 'step': 853000}
INFO:transformers.trainer:{'loss': 3.292566318511963, 'learning_rate': 4.7437973749722185e-05, 'epoch': 0.15372157501666894, 'step': 853500}
INFO:transformers.trainer:{'loss': 3.3346002593040467, 'learning_rate': 4.743647285560955e-05, 'epoch': 0.15381162866342737, 'step': 854000}
INFO:transformers.trainer:{'loss': 3.3866575348377226, 'learning_rate': 4.7434971961496904e-05, 'epoch': 0.15390168231018583, 'step': 854500}
INFO:transformers.trainer:{'loss': 3.3307197806835176, 'learning_rate': 4.743347106738427e-05, 'epoch': 0.15399173595694426, 'step': 855000}
INFO:transformers.trainer:{'loss': 3.3809385209083556, 'learning_rate': 4.743197017327162e-05, 'epoch': 0.15408178960370272, 'step': 855500}
INFO:transformers.trainer:{'loss': 3.3552631051540374, 'learning_rate': 4.743046927915899e-05, 'epoch': 0.15417184325046115, 'step': 856000}
INFO:transformers.trainer:{'loss': 3.366319410085678, 'learning_rate': 4.742896838504634e-05, 'epoch': 0.1542618968972196, 'step': 856500}
INFO:transformers.trainer:{'loss': 3.333328364849091, 'learning_rate': 4.7427467490933706e-05, 'epoch': 0.15435195054397804, 'step': 857000}
INFO:transformers.trainer:{'loss': 3.340215141057968, 'learning_rate': 4.742596659682106e-05, 'epoch': 0.1544420041907365, 'step': 857500}
INFO:transformers.trainer:{'loss': 3.332718685865402, 'learning_rate': 4.7424465702708424e-05, 'epoch': 0.15453205783749496, 'step': 858000}
INFO:transformers.trainer:{'loss': 3.3062737951278685, 'learning_rate': 4.7422964808595776e-05, 'epoch': 0.1546221114842534, 'step': 858500}
INFO:transformers.trainer:{'loss': 3.354630532026291, 'learning_rate': 4.742146391448314e-05, 'epoch': 0.15471216513101185, 'step': 859000}
INFO:transformers.trainer:{'loss': 3.3394977264404297, 'learning_rate': 4.7419963020370494e-05, 'epoch': 0.15480221877777028, 'step': 859500}
INFO:transformers.trainer:{'loss': 3.356615722179413, 'learning_rate': 4.741846212625786e-05, 'epoch': 0.15489227242452874, 'step': 860000}
INFO:transformers.trainer:{'loss': 3.340015705347061, 'learning_rate': 4.741696123214522e-05, 'epoch': 0.15498232607128717, 'step': 860500}
INFO:transformers.trainer:{'loss': 3.356611865282059, 'learning_rate': 4.741546033803258e-05, 'epoch': 0.15507237971804563, 'step': 861000}
INFO:transformers.trainer:{'loss': 3.32469470000267, 'learning_rate': 4.741395944391994e-05, 'epoch': 0.1551624333648041, 'step': 861500}
INFO:transformers.trainer:{'loss': 3.356647003889084, 'learning_rate': 4.741245854980729e-05, 'epoch': 0.15525248701156252, 'step': 862000}
INFO:transformers.trainer:{'loss': 3.403853967189789, 'learning_rate': 4.7410957655694655e-05, 'epoch': 0.15534254065832098, 'step': 862500}
INFO:transformers.trainer:{'loss': 3.394993967294693, 'learning_rate': 4.740945676158201e-05, 'epoch': 0.1554325943050794, 'step': 863000}
INFO:transformers.trainer:{'loss': 3.3837976176738738, 'learning_rate': 4.740795586746937e-05, 'epoch': 0.15552264795183787, 'step': 863500}
INFO:transformers.trainer:{'loss': 3.3342579860687254, 'learning_rate': 4.7406454973356725e-05, 'epoch': 0.1556127015985963, 'step': 864000}
INFO:transformers.trainer:{'loss': 3.343713537454605, 'learning_rate': 4.740495407924409e-05, 'epoch': 0.15570275524535476, 'step': 864500}
INFO:transformers.trainer:{'loss': 3.33089097738266, 'learning_rate': 4.7403453185131444e-05, 'epoch': 0.15579280889211322, 'step': 865000}
INFO:transformers.trainer:{'loss': 3.361800193309784, 'learning_rate': 4.740195229101881e-05, 'epoch': 0.15588286253887165, 'step': 865500}
INFO:transformers.trainer:{'loss': 3.3443357791900636, 'learning_rate': 4.740045139690616e-05, 'epoch': 0.1559729161856301, 'step': 866000}
INFO:transformers.trainer:{'loss': 3.354067866563797, 'learning_rate': 4.739895050279353e-05, 'epoch': 0.15606296983238854, 'step': 866500}
INFO:transformers.trainer:{'loss': 3.3935333495140076, 'learning_rate': 4.7397449608680887e-05, 'epoch': 0.156153023479147, 'step': 867000}
INFO:transformers.trainer:{'loss': 3.2934688708782196, 'learning_rate': 4.7395948714568246e-05, 'epoch': 0.15624307712590543, 'step': 867500}
INFO:transformers.trainer:{'loss': 3.376386190414429, 'learning_rate': 4.7394447820455605e-05, 'epoch': 0.1563331307726639, 'step': 868000}
INFO:transformers.trainer:{'loss': 3.3093678107261657, 'learning_rate': 4.7392946926342964e-05, 'epoch': 0.15642318441942235, 'step': 868500}
INFO:transformers.trainer:{'loss': 3.3109668247699737, 'learning_rate': 4.739144603223032e-05, 'epoch': 0.15651323806618078, 'step': 869000}
INFO:transformers.trainer:{'loss': 3.322817101955414, 'learning_rate': 4.738994513811768e-05, 'epoch': 0.15660329171293924, 'step': 869500}
INFO:transformers.trainer:{'loss': 3.368170660734177, 'learning_rate': 4.738844424400504e-05, 'epoch': 0.15669334535969767, 'step': 870000}
INFO:transformers.trainer:{'loss': 3.321599618434906, 'learning_rate': 4.73869433498924e-05, 'epoch': 0.15678339900645613, 'step': 870500}
INFO:transformers.trainer:{'loss': 3.3480006206035613, 'learning_rate': 4.738544245577976e-05, 'epoch': 0.15687345265321456, 'step': 871000}
INFO:transformers.trainer:{'loss': 3.3226853621006014, 'learning_rate': 4.738394156166712e-05, 'epoch': 0.15696350629997302, 'step': 871500}
INFO:transformers.trainer:{'loss': 3.378940802574158, 'learning_rate': 4.738244066755448e-05, 'epoch': 0.15705355994673148, 'step': 872000}
INFO:transformers.trainer:{'loss': 3.4120882198810576, 'learning_rate': 4.7380939773441836e-05, 'epoch': 0.1571436135934899, 'step': 872500}
INFO:transformers.trainer:{'loss': 3.310168298125267, 'learning_rate': 4.7379438879329195e-05, 'epoch': 0.15723366724024837, 'step': 873000}
INFO:transformers.trainer:{'loss': 3.408598727464676, 'learning_rate': 4.7377937985216554e-05, 'epoch': 0.1573237208870068, 'step': 873500}
INFO:transformers.trainer:{'loss': 3.359360886096954, 'learning_rate': 4.737643709110391e-05, 'epoch': 0.15741377453376526, 'step': 874000}
INFO:transformers.trainer:{'loss': 3.3798204120397566, 'learning_rate': 4.737493619699128e-05, 'epoch': 0.1575038281805237, 'step': 874500}
INFO:transformers.trainer:{'loss': 3.3443316049575804, 'learning_rate': 4.737343530287863e-05, 'epoch': 0.15759388182728215, 'step': 875000}
INFO:transformers.trainer:{'loss': 3.3653879809379577, 'learning_rate': 4.7371934408766e-05, 'epoch': 0.15768393547404058, 'step': 875500}
INFO:transformers.trainer:{'loss': 3.345684572696686, 'learning_rate': 4.737043351465335e-05, 'epoch': 0.15777398912079904, 'step': 876000}
INFO:transformers.trainer:{'loss': 3.4024166915416716, 'learning_rate': 4.7368932620540715e-05, 'epoch': 0.1578640427675575, 'step': 876500}
INFO:transformers.trainer:{'loss': 3.4221165949106216, 'learning_rate': 4.736743172642807e-05, 'epoch': 0.15795409641431593, 'step': 877000}
INFO:transformers.trainer:{'loss': 3.4981038317680357, 'learning_rate': 4.736593083231543e-05, 'epoch': 0.1580441500610744, 'step': 877500}
INFO:transformers.trainer:{'loss': 3.439096236228943, 'learning_rate': 4.7364429938202786e-05, 'epoch': 0.15813420370783282, 'step': 878000}
INFO:transformers.trainer:{'loss': 3.2953454186916353, 'learning_rate': 4.736292904409015e-05, 'epoch': 0.15822425735459128, 'step': 878500}
INFO:transformers.trainer:{'loss': 3.354273126602173, 'learning_rate': 4.7361428149977504e-05, 'epoch': 0.1583143110013497, 'step': 879000}
INFO:transformers.trainer:{'loss': 3.386556014299393, 'learning_rate': 4.735992725586487e-05, 'epoch': 0.15840436464810817, 'step': 879500}
INFO:transformers.trainer:{'loss': 3.352476043701172, 'learning_rate': 4.735842636175222e-05, 'epoch': 0.15849441829486663, 'step': 880000}
INFO:transformers.trainer:{'loss': 3.3267741782665254, 'learning_rate': 4.735692546763959e-05, 'epoch': 0.15858447194162506, 'step': 880500}
INFO:transformers.trainer:{'loss': 3.40338028550148, 'learning_rate': 4.735542457352695e-05, 'epoch': 0.15867452558838352, 'step': 881000}
INFO:transformers.trainer:{'loss': 3.32844438290596, 'learning_rate': 4.7353923679414306e-05, 'epoch': 0.15876457923514195, 'step': 881500}
INFO:transformers.trainer:{'loss': 3.390977137088776, 'learning_rate': 4.7352422785301665e-05, 'epoch': 0.1588546328819004, 'step': 882000}
INFO:transformers.trainer:{'loss': 3.349072090744972, 'learning_rate': 4.7350921891189024e-05, 'epoch': 0.15894468652865884, 'step': 882500}
INFO:transformers.trainer:{'loss': 3.3227415173053743, 'learning_rate': 4.734942099707638e-05, 'epoch': 0.1590347401754173, 'step': 883000}
INFO:transformers.trainer:{'loss': 3.365209032535553, 'learning_rate': 4.734792010296374e-05, 'epoch': 0.15912479382217576, 'step': 883500}
INFO:transformers.trainer:{'loss': 3.348807632446289, 'learning_rate': 4.73464192088511e-05, 'epoch': 0.1592148474689342, 'step': 884000}
INFO:transformers.trainer:{'loss': 3.366896948337555, 'learning_rate': 4.734491831473846e-05, 'epoch': 0.15930490111569265, 'step': 884500}
INFO:transformers.trainer:{'loss': 3.3963724036216734, 'learning_rate': 4.734341742062582e-05, 'epoch': 0.15939495476245108, 'step': 885000}
INFO:transformers.trainer:{'loss': 3.3850360380411146, 'learning_rate': 4.734191652651317e-05, 'epoch': 0.15948500840920954, 'step': 885500}
INFO:transformers.trainer:{'loss': 3.358759243965149, 'learning_rate': 4.734041563240054e-05, 'epoch': 0.15957506205596797, 'step': 886000}
INFO:transformers.trainer:{'loss': 3.327049209356308, 'learning_rate': 4.733891473828789e-05, 'epoch': 0.15966511570272643, 'step': 886500}
INFO:transformers.trainer:{'loss': 3.342362356424332, 'learning_rate': 4.7337413844175255e-05, 'epoch': 0.1597551693494849, 'step': 887000}
INFO:transformers.trainer:{'loss': 3.364210578918457, 'learning_rate': 4.733591295006261e-05, 'epoch': 0.15984522299624332, 'step': 887500}
INFO:transformers.trainer:{'loss': 3.363636521100998, 'learning_rate': 4.7334412055949973e-05, 'epoch': 0.15993527664300178, 'step': 888000}
INFO:transformers.trainer:{'loss': 3.358310472249985, 'learning_rate': 4.733291116183733e-05, 'epoch': 0.1600253302897602, 'step': 888500}
INFO:transformers.trainer:{'loss': 3.4071830394268035, 'learning_rate': 4.733141026772469e-05, 'epoch': 0.16011538393651867, 'step': 889000}
INFO:transformers.trainer:{'loss': 3.3773872129917146, 'learning_rate': 4.732990937361205e-05, 'epoch': 0.1602054375832771, 'step': 889500}
INFO:transformers.trainer:{'loss': 3.305086319208145, 'learning_rate': 4.732840847949941e-05, 'epoch': 0.16029549123003556, 'step': 890000}
INFO:transformers.trainer:{'loss': 3.3876822695732116, 'learning_rate': 4.732690758538677e-05, 'epoch': 0.16038554487679402, 'step': 890500}
INFO:transformers.trainer:{'loss': 3.3014129192829134, 'learning_rate': 4.732540669127413e-05, 'epoch': 0.16047559852355245, 'step': 891000}
INFO:transformers.trainer:{'loss': 3.3711935908794404, 'learning_rate': 4.732390579716149e-05, 'epoch': 0.1605656521703109, 'step': 891500}
INFO:transformers.trainer:{'loss': 3.3072965676784514, 'learning_rate': 4.7322404903048846e-05, 'epoch': 0.16065570581706934, 'step': 892000}
INFO:transformers.trainer:{'loss': 3.335892399311066, 'learning_rate': 4.7320904008936205e-05, 'epoch': 0.1607457594638278, 'step': 892500}
INFO:transformers.trainer:{'loss': 3.328463457107544, 'learning_rate': 4.7319403114823564e-05, 'epoch': 0.16083581311058623, 'step': 893000}
INFO:transformers.trainer:{'loss': 3.405238351345062, 'learning_rate': 4.731790222071092e-05, 'epoch': 0.1609258667573447, 'step': 893500}
INFO:transformers.trainer:{'loss': 3.3486376147270205, 'learning_rate': 4.731640132659828e-05, 'epoch': 0.16101592040410312, 'step': 894000}
INFO:transformers.trainer:{'loss': 3.4078725156784055, 'learning_rate': 4.731490043248564e-05, 'epoch': 0.16110597405086158, 'step': 894500}
INFO:transformers.trainer:{'loss': 3.4532818682193755, 'learning_rate': 4.731339953837301e-05, 'epoch': 0.16119602769762004, 'step': 895000}
INFO:transformers.trainer:{'loss': 3.3750458465814592, 'learning_rate': 4.731189864426036e-05, 'epoch': 0.16128608134437847, 'step': 895500}
INFO:transformers.trainer:{'loss': 3.3657398414611817, 'learning_rate': 4.7310397750147725e-05, 'epoch': 0.16137613499113693, 'step': 896000}
INFO:transformers.trainer:{'loss': 3.331331787824631, 'learning_rate': 4.730889685603508e-05, 'epoch': 0.16146618863789536, 'step': 896500}
INFO:transformers.trainer:{'loss': 3.3694011702537536, 'learning_rate': 4.730739596192244e-05, 'epoch': 0.16155624228465382, 'step': 897000}
INFO:transformers.trainer:{'loss': 3.383473213434219, 'learning_rate': 4.7305895067809795e-05, 'epoch': 0.16164629593141225, 'step': 897500}
INFO:transformers.trainer:{'loss': 3.2833058829307555, 'learning_rate': 4.730439417369716e-05, 'epoch': 0.1617363495781707, 'step': 898000}
INFO:transformers.trainer:{'loss': 3.2670715079307557, 'learning_rate': 4.7302893279584513e-05, 'epoch': 0.16182640322492917, 'step': 898500}
INFO:transformers.trainer:{'loss': 3.332146551609039, 'learning_rate': 4.730139238547188e-05, 'epoch': 0.1619164568716876, 'step': 899000}
INFO:transformers.trainer:{'loss': 3.3288792774677276, 'learning_rate': 4.729989149135923e-05, 'epoch': 0.16200651051844606, 'step': 899500}
INFO:transformers.trainer:{'loss': 3.358276261806488, 'learning_rate': 4.72983905972466e-05, 'epoch': 0.1620965641652045, 'step': 900000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-900000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-900000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-900000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-800000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3333241270780563, 'learning_rate': 4.729688970313395e-05, 'epoch': 0.16218661781196295, 'step': 900500}
INFO:transformers.trainer:{'loss': 3.3489990022182465, 'learning_rate': 4.7295388809021315e-05, 'epoch': 0.16227667145872138, 'step': 901000}
INFO:transformers.trainer:{'loss': 3.3262118532657623, 'learning_rate': 4.7293887914908675e-05, 'epoch': 0.16236672510547984, 'step': 901500}
INFO:transformers.trainer:{'loss': 3.4211144759654997, 'learning_rate': 4.7292387020796034e-05, 'epoch': 0.1624567787522383, 'step': 902000}
INFO:transformers.trainer:{'loss': 3.3695423922538756, 'learning_rate': 4.729088612668339e-05, 'epoch': 0.16254683239899673, 'step': 902500}
INFO:transformers.trainer:{'loss': 3.33196204662323, 'learning_rate': 4.728938523257075e-05, 'epoch': 0.16263688604575519, 'step': 903000}
INFO:transformers.trainer:{'loss': 3.3363095467090607, 'learning_rate': 4.728788433845811e-05, 'epoch': 0.16272693969251362, 'step': 903500}
INFO:transformers.trainer:{'loss': 3.322539078474045, 'learning_rate': 4.728638344434547e-05, 'epoch': 0.16281699333927208, 'step': 904000}
INFO:transformers.trainer:{'loss': 3.3756590514183045, 'learning_rate': 4.728488255023283e-05, 'epoch': 0.1629070469860305, 'step': 904500}
INFO:transformers.trainer:{'loss': 3.416479393720627, 'learning_rate': 4.728338165612019e-05, 'epoch': 0.16299710063278897, 'step': 905000}
INFO:transformers.trainer:{'loss': 3.3392435891628267, 'learning_rate': 4.728188076200755e-05, 'epoch': 0.16308715427954742, 'step': 905500}
INFO:transformers.trainer:{'loss': 3.3247435796260834, 'learning_rate': 4.7280379867894906e-05, 'epoch': 0.16317720792630586, 'step': 906000}
INFO:transformers.trainer:{'loss': 3.3361441082954406, 'learning_rate': 4.7278878973782265e-05, 'epoch': 0.16326726157306432, 'step': 906500}
INFO:transformers.trainer:{'loss': 3.2880640511512755, 'learning_rate': 4.7277378079669624e-05, 'epoch': 0.16335731521982275, 'step': 907000}
INFO:transformers.trainer:{'loss': 3.343488317012787, 'learning_rate': 4.727587718555698e-05, 'epoch': 0.1634473688665812, 'step': 907500}
INFO:transformers.trainer:{'loss': 3.348934792757034, 'learning_rate': 4.727437629144434e-05, 'epoch': 0.16353742251333964, 'step': 908000}
INFO:transformers.trainer:{'loss': 3.3485182437896728, 'learning_rate': 4.72728753973317e-05, 'epoch': 0.1636274761600981, 'step': 908500}
INFO:transformers.trainer:{'loss': 3.3888032712936402, 'learning_rate': 4.727137450321906e-05, 'epoch': 0.16371752980685655, 'step': 909000}
INFO:transformers.trainer:{'loss': 3.400215307235718, 'learning_rate': 4.726987360910642e-05, 'epoch': 0.16380758345361499, 'step': 909500}
INFO:transformers.trainer:{'loss': 3.3037312152385714, 'learning_rate': 4.726837271499378e-05, 'epoch': 0.16389763710037344, 'step': 910000}
INFO:transformers.trainer:{'loss': 3.30016956114769, 'learning_rate': 4.726687182088114e-05, 'epoch': 0.16398769074713188, 'step': 910500}
INFO:transformers.trainer:{'loss': 3.4041137882471086, 'learning_rate': 4.7265370926768496e-05, 'epoch': 0.16407774439389033, 'step': 911000}
INFO:transformers.trainer:{'loss': 3.3674746738672257, 'learning_rate': 4.7263870032655856e-05, 'epoch': 0.16416779804064877, 'step': 911500}
INFO:transformers.trainer:{'loss': 3.3988458584547043, 'learning_rate': 4.7262369138543215e-05, 'epoch': 0.16425785168740722, 'step': 912000}
INFO:transformers.trainer:{'loss': 3.362601758480072, 'learning_rate': 4.7260868244430574e-05, 'epoch': 0.16434790533416566, 'step': 912500}
INFO:transformers.trainer:{'loss': 3.353757546186447, 'learning_rate': 4.725936735031793e-05, 'epoch': 0.16443795898092411, 'step': 913000}
INFO:transformers.trainer:{'loss': 3.321120572566986, 'learning_rate': 4.725786645620529e-05, 'epoch': 0.16452801262768257, 'step': 913500}
INFO:transformers.trainer:{'loss': 3.3474643857479096, 'learning_rate': 4.725636556209265e-05, 'epoch': 0.164618066274441, 'step': 914000}
INFO:transformers.trainer:{'loss': 3.3328604016304015, 'learning_rate': 4.725486466798001e-05, 'epoch': 0.16470811992119946, 'step': 914500}
INFO:transformers.trainer:{'loss': 3.3485716865062716, 'learning_rate': 4.725336377386737e-05, 'epoch': 0.1647981735679579, 'step': 915000}
INFO:transformers.trainer:{'loss': 3.3509449634552, 'learning_rate': 4.7251862879754735e-05, 'epoch': 0.16488822721471635, 'step': 915500}
INFO:transformers.trainer:{'loss': 3.3178590722084045, 'learning_rate': 4.725036198564209e-05, 'epoch': 0.16497828086147479, 'step': 916000}
INFO:transformers.trainer:{'loss': 3.3255255126953127, 'learning_rate': 4.724886109152945e-05, 'epoch': 0.16506833450823324, 'step': 916500}
INFO:transformers.trainer:{'loss': 3.3649365270137785, 'learning_rate': 4.7247360197416805e-05, 'epoch': 0.1651583881549917, 'step': 917000}
INFO:transformers.trainer:{'loss': 3.392517752170563, 'learning_rate': 4.724585930330417e-05, 'epoch': 0.16524844180175013, 'step': 917500}
INFO:transformers.trainer:{'loss': 3.3242290606498717, 'learning_rate': 4.724435840919152e-05, 'epoch': 0.1653384954485086, 'step': 918000}
INFO:transformers.trainer:{'loss': 3.350833200454712, 'learning_rate': 4.724285751507889e-05, 'epoch': 0.16542854909526702, 'step': 918500}
INFO:transformers.trainer:{'loss': 3.3663707258701323, 'learning_rate': 4.724135662096624e-05, 'epoch': 0.16551860274202548, 'step': 919000}
INFO:transformers.trainer:{'loss': 3.3910350995063783, 'learning_rate': 4.723985572685361e-05, 'epoch': 0.16560865638878391, 'step': 919500}
INFO:transformers.trainer:{'loss': 3.3791429007053377, 'learning_rate': 4.723835483274096e-05, 'epoch': 0.16569871003554237, 'step': 920000}
INFO:transformers.trainer:{'loss': 3.3585957295894624, 'learning_rate': 4.7236853938628325e-05, 'epoch': 0.16578876368230083, 'step': 920500}
INFO:transformers.trainer:{'loss': 3.3869462995529176, 'learning_rate': 4.723535304451568e-05, 'epoch': 0.16587881732905926, 'step': 921000}
INFO:transformers.trainer:{'loss': 3.3954374849796296, 'learning_rate': 4.723385215040304e-05, 'epoch': 0.16596887097581772, 'step': 921500}
INFO:transformers.trainer:{'loss': 3.3955510416030883, 'learning_rate': 4.7232351256290396e-05, 'epoch': 0.16605892462257615, 'step': 922000}
INFO:transformers.trainer:{'loss': 3.333657304763794, 'learning_rate': 4.723085036217776e-05, 'epoch': 0.1661489782693346, 'step': 922500}
INFO:transformers.trainer:{'loss': 3.3199008202552793, 'learning_rate': 4.722934946806512e-05, 'epoch': 0.16623903191609304, 'step': 923000}
INFO:transformers.trainer:{'loss': 3.2815273413658144, 'learning_rate': 4.722784857395248e-05, 'epoch': 0.1663290855628515, 'step': 923500}
INFO:transformers.trainer:{'loss': 3.317743203639984, 'learning_rate': 4.722634767983984e-05, 'epoch': 0.16641913920960996, 'step': 924000}
INFO:transformers.trainer:{'loss': 3.354771609067917, 'learning_rate': 4.72248467857272e-05, 'epoch': 0.1665091928563684, 'step': 924500}
INFO:transformers.trainer:{'loss': 3.326776709318161, 'learning_rate': 4.722334589161456e-05, 'epoch': 0.16659924650312685, 'step': 925000}
INFO:transformers.trainer:{'loss': 3.382520615339279, 'learning_rate': 4.7221844997501916e-05, 'epoch': 0.16668930014988528, 'step': 925500}
INFO:transformers.trainer:{'loss': 3.3187686678171158, 'learning_rate': 4.7220344103389275e-05, 'epoch': 0.16677935379664374, 'step': 926000}
INFO:transformers.trainer:{'loss': 3.384531723022461, 'learning_rate': 4.7218843209276634e-05, 'epoch': 0.16686940744340217, 'step': 926500}
INFO:transformers.trainer:{'loss': 3.333665592432022, 'learning_rate': 4.721734231516399e-05, 'epoch': 0.16695946109016063, 'step': 927000}
INFO:transformers.trainer:{'loss': 3.3190972917079926, 'learning_rate': 4.721584142105135e-05, 'epoch': 0.16704951473691906, 'step': 927500}
INFO:transformers.trainer:{'loss': 3.372608918428421, 'learning_rate': 4.721434052693871e-05, 'epoch': 0.16713956838367752, 'step': 928000}
INFO:transformers.trainer:{'loss': 3.289610199928284, 'learning_rate': 4.721283963282607e-05, 'epoch': 0.16722962203043598, 'step': 928500}
INFO:transformers.trainer:{'loss': 3.3592995760440827, 'learning_rate': 4.721133873871343e-05, 'epoch': 0.1673196756771944, 'step': 929000}
INFO:transformers.trainer:{'loss': 3.306405308485031, 'learning_rate': 4.720983784460079e-05, 'epoch': 0.16740972932395287, 'step': 929500}
INFO:transformers.trainer:{'loss': 3.319105661392212, 'learning_rate': 4.720833695048815e-05, 'epoch': 0.1674997829707113, 'step': 930000}
INFO:transformers.trainer:{'loss': 3.3997870619297026, 'learning_rate': 4.7206836056375506e-05, 'epoch': 0.16758983661746976, 'step': 930500}
INFO:transformers.trainer:{'loss': 3.336559899330139, 'learning_rate': 4.7205335162262865e-05, 'epoch': 0.1676798902642282, 'step': 931000}
INFO:transformers.trainer:{'loss': 3.3244974994659424, 'learning_rate': 4.7203834268150224e-05, 'epoch': 0.16776994391098665, 'step': 931500}
INFO:transformers.trainer:{'loss': 3.3571907062530517, 'learning_rate': 4.720233337403758e-05, 'epoch': 0.1678599975577451, 'step': 932000}
INFO:transformers.trainer:{'loss': 3.3287887332439423, 'learning_rate': 4.720083247992494e-05, 'epoch': 0.16795005120450354, 'step': 932500}
INFO:transformers.trainer:{'loss': 3.323292856454849, 'learning_rate': 4.71993315858123e-05, 'epoch': 0.168040104851262, 'step': 933000}
INFO:transformers.trainer:{'loss': 3.329671332359314, 'learning_rate': 4.719783069169966e-05, 'epoch': 0.16813015849802043, 'step': 933500}
INFO:transformers.trainer:{'loss': 3.331627514362335, 'learning_rate': 4.719632979758702e-05, 'epoch': 0.1682202121447789, 'step': 934000}
INFO:transformers.trainer:{'loss': 3.2905445539951326, 'learning_rate': 4.719482890347438e-05, 'epoch': 0.16831026579153732, 'step': 934500}
INFO:transformers.trainer:{'loss': 3.3048370336294175, 'learning_rate': 4.719332800936174e-05, 'epoch': 0.16840031943829578, 'step': 935000}
INFO:transformers.trainer:{'loss': 3.331066636323929, 'learning_rate': 4.71918271152491e-05, 'epoch': 0.16849037308505424, 'step': 935500}
INFO:transformers.trainer:{'loss': 3.339703638315201, 'learning_rate': 4.7190326221136456e-05, 'epoch': 0.16858042673181267, 'step': 936000}
INFO:transformers.trainer:{'loss': 3.3539963371753694, 'learning_rate': 4.7188825327023815e-05, 'epoch': 0.16867048037857113, 'step': 936500}
INFO:transformers.trainer:{'loss': 3.3839119963645934, 'learning_rate': 4.718732443291118e-05, 'epoch': 0.16876053402532956, 'step': 937000}
INFO:transformers.trainer:{'loss': 3.3976405630111692, 'learning_rate': 4.718582353879853e-05, 'epoch': 0.16885058767208802, 'step': 937500}
INFO:transformers.trainer:{'loss': 3.406085256814957, 'learning_rate': 4.71843226446859e-05, 'epoch': 0.16894064131884645, 'step': 938000}
INFO:transformers.trainer:{'loss': 3.320691364526749, 'learning_rate': 4.718282175057325e-05, 'epoch': 0.1690306949656049, 'step': 938500}
INFO:transformers.trainer:{'loss': 3.2895351831912993, 'learning_rate': 4.718132085646062e-05, 'epoch': 0.16912074861236337, 'step': 939000}
INFO:transformers.trainer:{'loss': 3.345032539129257, 'learning_rate': 4.717981996234797e-05, 'epoch': 0.1692108022591218, 'step': 939500}
INFO:transformers.trainer:{'loss': 3.381908448934555, 'learning_rate': 4.7178319068235335e-05, 'epoch': 0.16930085590588026, 'step': 940000}
INFO:transformers.trainer:{'loss': 3.321153525590897, 'learning_rate': 4.717681817412269e-05, 'epoch': 0.1693909095526387, 'step': 940500}
INFO:transformers.trainer:{'loss': 3.34919899559021, 'learning_rate': 4.717531728001005e-05, 'epoch': 0.16948096319939715, 'step': 941000}
INFO:transformers.trainer:{'loss': 3.3158078441619874, 'learning_rate': 4.7173816385897405e-05, 'epoch': 0.16957101684615558, 'step': 941500}
INFO:transformers.trainer:{'loss': 3.3255994997024536, 'learning_rate': 4.717231549178477e-05, 'epoch': 0.16966107049291404, 'step': 942000}
INFO:transformers.trainer:{'loss': 3.3597688121795652, 'learning_rate': 4.7170814597672123e-05, 'epoch': 0.1697511241396725, 'step': 942500}
INFO:transformers.trainer:{'loss': 3.3323499541282655, 'learning_rate': 4.716931370355949e-05, 'epoch': 0.16984117778643093, 'step': 943000}
INFO:transformers.trainer:{'loss': 3.302071986913681, 'learning_rate': 4.716781280944685e-05, 'epoch': 0.1699312314331894, 'step': 943500}
INFO:transformers.trainer:{'loss': 3.2710392925739287, 'learning_rate': 4.716631191533421e-05, 'epoch': 0.17002128507994782, 'step': 944000}
INFO:transformers.trainer:{'loss': 3.321100155353546, 'learning_rate': 4.7164811021221566e-05, 'epoch': 0.17011133872670628, 'step': 944500}
INFO:transformers.trainer:{'loss': 3.3493768986463546, 'learning_rate': 4.7163310127108925e-05, 'epoch': 0.1702013923734647, 'step': 945000}
INFO:transformers.trainer:{'loss': 3.3775491107702256, 'learning_rate': 4.7161809232996284e-05, 'epoch': 0.17029144602022317, 'step': 945500}
INFO:transformers.trainer:{'loss': 3.388003504753113, 'learning_rate': 4.7160308338883644e-05, 'epoch': 0.1703814996669816, 'step': 946000}
INFO:transformers.trainer:{'loss': 3.325142560720444, 'learning_rate': 4.7158807444771e-05, 'epoch': 0.17047155331374006, 'step': 946500}
INFO:transformers.trainer:{'loss': 3.3989111766815188, 'learning_rate': 4.715730655065836e-05, 'epoch': 0.17056160696049852, 'step': 947000}
INFO:transformers.trainer:{'loss': 3.3338894827365877, 'learning_rate': 4.715580565654572e-05, 'epoch': 0.17065166060725695, 'step': 947500}
INFO:transformers.trainer:{'loss': 3.3610141742229462, 'learning_rate': 4.715430476243308e-05, 'epoch': 0.1707417142540154, 'step': 948000}
INFO:transformers.trainer:{'loss': 3.3179151928424835, 'learning_rate': 4.715280386832044e-05, 'epoch': 0.17083176790077384, 'step': 948500}
INFO:transformers.trainer:{'loss': 3.3511521985530854, 'learning_rate': 4.71513029742078e-05, 'epoch': 0.1709218215475323, 'step': 949000}
INFO:transformers.trainer:{'loss': 3.3283378841876985, 'learning_rate': 4.714980208009516e-05, 'epoch': 0.17101187519429073, 'step': 949500}
INFO:transformers.trainer:{'loss': 3.291690064191818, 'learning_rate': 4.7148301185982516e-05, 'epoch': 0.1711019288410492, 'step': 950000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-950000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-950000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-950000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-850000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2806690270900725, 'learning_rate': 4.7146800291869875e-05, 'epoch': 0.17119198248780765, 'step': 950500}
INFO:transformers.trainer:{'loss': 3.298793890953064, 'learning_rate': 4.7145299397757234e-05, 'epoch': 0.17128203613456608, 'step': 951000}
INFO:transformers.trainer:{'loss': 3.3689205169677736, 'learning_rate': 4.714379850364459e-05, 'epoch': 0.17137208978132454, 'step': 951500}
INFO:transformers.trainer:{'loss': 3.3436288497447966, 'learning_rate': 4.714229760953195e-05, 'epoch': 0.17146214342808297, 'step': 952000}
INFO:transformers.trainer:{'loss': 3.337571207523346, 'learning_rate': 4.714079671541931e-05, 'epoch': 0.17155219707484143, 'step': 952500}
INFO:transformers.trainer:{'loss': 3.4156118746995925, 'learning_rate': 4.713929582130667e-05, 'epoch': 0.17164225072159986, 'step': 953000}
INFO:transformers.trainer:{'loss': 3.322089962720871, 'learning_rate': 4.713779492719403e-05, 'epoch': 0.17173230436835832, 'step': 953500}
INFO:transformers.trainer:{'loss': 3.315419345498085, 'learning_rate': 4.713629403308139e-05, 'epoch': 0.17182235801511678, 'step': 954000}
INFO:transformers.trainer:{'loss': 3.3753661217689515, 'learning_rate': 4.713479313896875e-05, 'epoch': 0.1719124116618752, 'step': 954500}
INFO:transformers.trainer:{'loss': 3.3163841874599456, 'learning_rate': 4.7133292244856106e-05, 'epoch': 0.17200246530863367, 'step': 955000}
INFO:transformers.trainer:{'loss': 3.3902531826496123, 'learning_rate': 4.7131791350743465e-05, 'epoch': 0.1720925189553921, 'step': 955500}
INFO:transformers.trainer:{'loss': 3.2998962154388427, 'learning_rate': 4.7130290456630825e-05, 'epoch': 0.17218257260215056, 'step': 956000}
INFO:transformers.trainer:{'loss': 3.3357573630809783, 'learning_rate': 4.7128789562518184e-05, 'epoch': 0.172272626248909, 'step': 956500}
INFO:transformers.trainer:{'loss': 3.335766420125961, 'learning_rate': 4.712728866840554e-05, 'epoch': 0.17236267989566745, 'step': 957000}
INFO:transformers.trainer:{'loss': 3.3562569298744203, 'learning_rate': 4.712578777429291e-05, 'epoch': 0.1724527335424259, 'step': 957500}
INFO:transformers.trainer:{'loss': 3.405655239343643, 'learning_rate': 4.712428688018026e-05, 'epoch': 0.17254278718918434, 'step': 958000}
INFO:transformers.trainer:{'loss': 3.3631347515583037, 'learning_rate': 4.7122785986067627e-05, 'epoch': 0.1726328408359428, 'step': 958500}
INFO:transformers.trainer:{'loss': 3.349778780460358, 'learning_rate': 4.712128509195498e-05, 'epoch': 0.17272289448270123, 'step': 959000}
INFO:transformers.trainer:{'loss': 3.2771623616218566, 'learning_rate': 4.7119784197842345e-05, 'epoch': 0.1728129481294597, 'step': 959500}
INFO:transformers.trainer:{'loss': 3.3133627318143843, 'learning_rate': 4.71182833037297e-05, 'epoch': 0.17290300177621812, 'step': 960000}
INFO:transformers.trainer:{'loss': 3.294800369977951, 'learning_rate': 4.711678240961706e-05, 'epoch': 0.17299305542297658, 'step': 960500}
INFO:transformers.trainer:{'loss': 3.2687885599136353, 'learning_rate': 4.7115281515504415e-05, 'epoch': 0.17308310906973504, 'step': 961000}
INFO:transformers.trainer:{'loss': 3.3582933695316313, 'learning_rate': 4.711378062139178e-05, 'epoch': 0.17317316271649347, 'step': 961500}
INFO:transformers.trainer:{'loss': 3.330159646987915, 'learning_rate': 4.711227972727913e-05, 'epoch': 0.17326321636325193, 'step': 962000}
INFO:transformers.trainer:{'loss': 3.284464841604233, 'learning_rate': 4.71107788331665e-05, 'epoch': 0.17335327001001036, 'step': 962500}
INFO:transformers.trainer:{'loss': 3.2960397436618805, 'learning_rate': 4.710927793905385e-05, 'epoch': 0.17344332365676882, 'step': 963000}
INFO:transformers.trainer:{'loss': 3.348140422344208, 'learning_rate': 4.710777704494122e-05, 'epoch': 0.17353337730352725, 'step': 963500}
INFO:transformers.trainer:{'loss': 3.3495365414619447, 'learning_rate': 4.7106276150828576e-05, 'epoch': 0.1736234309502857, 'step': 964000}
INFO:transformers.trainer:{'loss': 3.3442987751960755, 'learning_rate': 4.7104775256715935e-05, 'epoch': 0.17371348459704414, 'step': 964500}
INFO:transformers.trainer:{'loss': 3.3648677191734313, 'learning_rate': 4.7103274362603294e-05, 'epoch': 0.1738035382438026, 'step': 965000}
INFO:transformers.trainer:{'loss': 3.3170984961986543, 'learning_rate': 4.710177346849065e-05, 'epoch': 0.17389359189056106, 'step': 965500}
INFO:transformers.trainer:{'loss': 3.3551008709669112, 'learning_rate': 4.710027257437801e-05, 'epoch': 0.1739836455373195, 'step': 966000}
INFO:transformers.trainer:{'loss': 3.3374165444374086, 'learning_rate': 4.709877168026537e-05, 'epoch': 0.17407369918407795, 'step': 966500}
INFO:transformers.trainer:{'loss': 3.334514922142029, 'learning_rate': 4.709727078615273e-05, 'epoch': 0.17416375283083638, 'step': 967000}
INFO:transformers.trainer:{'loss': 3.3351738741397856, 'learning_rate': 4.709576989204009e-05, 'epoch': 0.17425380647759484, 'step': 967500}
INFO:transformers.trainer:{'loss': 3.3487898108959198, 'learning_rate': 4.709426899792745e-05, 'epoch': 0.17434386012435327, 'step': 968000}
INFO:transformers.trainer:{'loss': 3.344783069372177, 'learning_rate': 4.709276810381481e-05, 'epoch': 0.17443391377111173, 'step': 968500}
INFO:transformers.trainer:{'loss': 3.3068058965206144, 'learning_rate': 4.709126720970217e-05, 'epoch': 0.17452396741787018, 'step': 969000}
INFO:transformers.trainer:{'loss': 3.2851467254161837, 'learning_rate': 4.7089766315589526e-05, 'epoch': 0.17461402106462862, 'step': 969500}
INFO:transformers.trainer:{'loss': 3.3498054559230805, 'learning_rate': 4.7088265421476885e-05, 'epoch': 0.17470407471138708, 'step': 970000}
INFO:transformers.trainer:{'loss': 3.3583618574142458, 'learning_rate': 4.7086764527364244e-05, 'epoch': 0.1747941283581455, 'step': 970500}
INFO:transformers.trainer:{'loss': 3.3417577035427093, 'learning_rate': 4.70852636332516e-05, 'epoch': 0.17488418200490397, 'step': 971000}
INFO:transformers.trainer:{'loss': 3.3760014498233795, 'learning_rate': 4.708376273913896e-05, 'epoch': 0.1749742356516624, 'step': 971500}
INFO:transformers.trainer:{'loss': 3.33823494720459, 'learning_rate': 4.708226184502632e-05, 'epoch': 0.17506428929842086, 'step': 972000}
INFO:transformers.trainer:{'loss': 3.342000819444656, 'learning_rate': 4.708076095091368e-05, 'epoch': 0.17515434294517931, 'step': 972500}
INFO:transformers.trainer:{'loss': 3.3519360876083373, 'learning_rate': 4.707926005680104e-05, 'epoch': 0.17524439659193775, 'step': 973000}
INFO:transformers.trainer:{'loss': 3.41240988779068, 'learning_rate': 4.70777591626884e-05, 'epoch': 0.1753344502386962, 'step': 973500}
INFO:transformers.trainer:{'loss': 3.2923343183994294, 'learning_rate': 4.707625826857576e-05, 'epoch': 0.17542450388545464, 'step': 974000}
INFO:transformers.trainer:{'loss': 3.3595051922798156, 'learning_rate': 4.7074757374463116e-05, 'epoch': 0.1755145575322131, 'step': 974500}
INFO:transformers.trainer:{'loss': 3.317778618454933, 'learning_rate': 4.7073256480350475e-05, 'epoch': 0.17560461117897153, 'step': 975000}
INFO:transformers.trainer:{'loss': 3.312501182436943, 'learning_rate': 4.7071755586237834e-05, 'epoch': 0.17569466482572998, 'step': 975500}
INFO:transformers.trainer:{'loss': 3.3101476106643677, 'learning_rate': 4.707025469212519e-05, 'epoch': 0.17578471847248844, 'step': 976000}
INFO:transformers.trainer:{'loss': 3.3801914291381836, 'learning_rate': 4.706875379801255e-05, 'epoch': 0.17587477211924687, 'step': 976500}
INFO:transformers.trainer:{'loss': 3.34862651515007, 'learning_rate': 4.706725290389991e-05, 'epoch': 0.17596482576600533, 'step': 977000}
INFO:transformers.trainer:{'loss': 3.28084287238121, 'learning_rate': 4.706575200978727e-05, 'epoch': 0.17605487941276377, 'step': 977500}
INFO:transformers.trainer:{'loss': 3.359735733985901, 'learning_rate': 4.7064251115674636e-05, 'epoch': 0.17614493305952222, 'step': 978000}
INFO:transformers.trainer:{'loss': 3.302332716703415, 'learning_rate': 4.706275022156199e-05, 'epoch': 0.17623498670628066, 'step': 978500}
INFO:transformers.trainer:{'loss': 3.3105496072769167, 'learning_rate': 4.7061249327449354e-05, 'epoch': 0.17632504035303911, 'step': 979000}
INFO:transformers.trainer:{'loss': 3.301198536872864, 'learning_rate': 4.705974843333671e-05, 'epoch': 0.17641509399979757, 'step': 979500}
INFO:transformers.trainer:{'loss': 3.3246324474811555, 'learning_rate': 4.705824753922407e-05, 'epoch': 0.176505147646556, 'step': 980000}
INFO:transformers.trainer:{'loss': 3.3055415308475493, 'learning_rate': 4.7056746645111425e-05, 'epoch': 0.17659520129331446, 'step': 980500}
INFO:transformers.trainer:{'loss': 3.344353909254074, 'learning_rate': 4.705524575099879e-05, 'epoch': 0.1766852549400729, 'step': 981000}
INFO:transformers.trainer:{'loss': 3.338687888622284, 'learning_rate': 4.705374485688614e-05, 'epoch': 0.17677530858683135, 'step': 981500}
INFO:transformers.trainer:{'loss': 3.3191572523117063, 'learning_rate': 4.705224396277351e-05, 'epoch': 0.17686536223358978, 'step': 982000}
INFO:transformers.trainer:{'loss': 3.351296756744385, 'learning_rate': 4.705074306866086e-05, 'epoch': 0.17695541588034824, 'step': 982500}
INFO:transformers.trainer:{'loss': 3.3460599744319914, 'learning_rate': 4.704924217454823e-05, 'epoch': 0.17704546952710667, 'step': 983000}
INFO:transformers.trainer:{'loss': 3.389251181602478, 'learning_rate': 4.704774128043558e-05, 'epoch': 0.17713552317386513, 'step': 983500}
INFO:transformers.trainer:{'loss': 3.388167619943619, 'learning_rate': 4.7046240386322945e-05, 'epoch': 0.1772255768206236, 'step': 984000}
INFO:transformers.trainer:{'loss': 3.344982221841812, 'learning_rate': 4.70447394922103e-05, 'epoch': 0.17731563046738202, 'step': 984500}
INFO:transformers.trainer:{'loss': 3.343839993476868, 'learning_rate': 4.704323859809766e-05, 'epoch': 0.17740568411414048, 'step': 985000}
INFO:transformers.trainer:{'loss': 3.3072242522239685, 'learning_rate': 4.704173770398502e-05, 'epoch': 0.17749573776089891, 'step': 985500}
INFO:transformers.trainer:{'loss': 3.3617190639972687, 'learning_rate': 4.704023680987238e-05, 'epoch': 0.17758579140765737, 'step': 986000}
INFO:transformers.trainer:{'loss': 3.368574001312256, 'learning_rate': 4.703873591575974e-05, 'epoch': 0.1776758450544158, 'step': 986500}
INFO:transformers.trainer:{'loss': 3.325355686187744, 'learning_rate': 4.70372350216471e-05, 'epoch': 0.17776589870117426, 'step': 987000}
INFO:transformers.trainer:{'loss': 3.30766140294075, 'learning_rate': 4.703573412753446e-05, 'epoch': 0.17785595234793272, 'step': 987500}
INFO:transformers.trainer:{'loss': 3.4096554429531096, 'learning_rate': 4.703423323342182e-05, 'epoch': 0.17794600599469115, 'step': 988000}
INFO:transformers.trainer:{'loss': 3.3295579965114595, 'learning_rate': 4.7032732339309176e-05, 'epoch': 0.1780360596414496, 'step': 988500}
INFO:transformers.trainer:{'loss': 3.3895139544010164, 'learning_rate': 4.7031231445196535e-05, 'epoch': 0.17812611328820804, 'step': 989000}
INFO:transformers.trainer:{'loss': 3.345430984020233, 'learning_rate': 4.7029730551083894e-05, 'epoch': 0.1782161669349665, 'step': 989500}
INFO:transformers.trainer:{'loss': 3.3308541469573973, 'learning_rate': 4.7028229656971254e-05, 'epoch': 0.17830622058172493, 'step': 990000}
INFO:transformers.trainer:{'loss': 3.268688751220703, 'learning_rate': 4.702672876285861e-05, 'epoch': 0.1783962742284834, 'step': 990500}
INFO:transformers.trainer:{'loss': 3.3354099798202514, 'learning_rate': 4.702522786874597e-05, 'epoch': 0.17848632787524185, 'step': 991000}
INFO:transformers.trainer:{'loss': 3.330299852848053, 'learning_rate': 4.702372697463333e-05, 'epoch': 0.17857638152200028, 'step': 991500}
INFO:transformers.trainer:{'loss': 3.383555189371109, 'learning_rate': 4.702222608052069e-05, 'epoch': 0.17866643516875874, 'step': 992000}
INFO:transformers.trainer:{'loss': 3.330543523311615, 'learning_rate': 4.702072518640805e-05, 'epoch': 0.17875648881551717, 'step': 992500}
INFO:transformers.trainer:{'loss': 3.3411124827861785, 'learning_rate': 4.701922429229541e-05, 'epoch': 0.17884654246227563, 'step': 993000}
INFO:transformers.trainer:{'loss': 3.337519021987915, 'learning_rate': 4.701772339818277e-05, 'epoch': 0.17893659610903406, 'step': 993500}
INFO:transformers.trainer:{'loss': 3.322085176706314, 'learning_rate': 4.7016222504070126e-05, 'epoch': 0.17902664975579252, 'step': 994000}
INFO:transformers.trainer:{'loss': 3.299438470363617, 'learning_rate': 4.7014721609957485e-05, 'epoch': 0.17911670340255098, 'step': 994500}
INFO:transformers.trainer:{'loss': 3.31401429104805, 'learning_rate': 4.7013220715844844e-05, 'epoch': 0.1792067570493094, 'step': 995000}
INFO:transformers.trainer:{'loss': 3.282409646987915, 'learning_rate': 4.70117198217322e-05, 'epoch': 0.17929681069606787, 'step': 995500}
INFO:transformers.trainer:{'loss': 3.328443806171417, 'learning_rate': 4.701021892761956e-05, 'epoch': 0.1793868643428263, 'step': 996000}
INFO:transformers.trainer:{'loss': 3.3551839380264283, 'learning_rate': 4.700871803350692e-05, 'epoch': 0.17947691798958476, 'step': 996500}
INFO:transformers.trainer:{'loss': 3.3421818022727967, 'learning_rate': 4.700721713939428e-05, 'epoch': 0.1795669716363432, 'step': 997000}
INFO:transformers.trainer:{'loss': 3.3031122698783872, 'learning_rate': 4.700571624528164e-05, 'epoch': 0.17965702528310165, 'step': 997500}
INFO:transformers.trainer:{'loss': 3.3315315880775453, 'learning_rate': 4.7004215351169e-05, 'epoch': 0.17974707892986008, 'step': 998000}
INFO:transformers.trainer:{'loss': 3.3858429222106934, 'learning_rate': 4.700271445705636e-05, 'epoch': 0.17983713257661854, 'step': 998500}
INFO:transformers.trainer:{'loss': 3.302365567445755, 'learning_rate': 4.7001213562943716e-05, 'epoch': 0.179927186223377, 'step': 999000}
INFO:transformers.trainer:{'loss': 3.378087949037552, 'learning_rate': 4.699971266883108e-05, 'epoch': 0.18001723987013543, 'step': 999500}
INFO:transformers.trainer:{'loss': 3.3142255280017854, 'learning_rate': 4.6998211774718435e-05, 'epoch': 0.1801072935168939, 'step': 1000000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1000000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1000000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1000000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-900000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.266062905073166, 'learning_rate': 4.69967108806058e-05, 'epoch': 0.18019734716365232, 'step': 1000500}
INFO:transformers.trainer:{'loss': 3.329253355503082, 'learning_rate': 4.699520998649315e-05, 'epoch': 0.18028740081041078, 'step': 1001000}
INFO:transformers.trainer:{'loss': 3.323739614009857, 'learning_rate': 4.699370909238052e-05, 'epoch': 0.1803774544571692, 'step': 1001500}
INFO:transformers.trainer:{'loss': 3.3024729549884797, 'learning_rate': 4.699220819826787e-05, 'epoch': 0.18046750810392767, 'step': 1002000}
INFO:transformers.trainer:{'loss': 3.302510766029358, 'learning_rate': 4.6990707304155237e-05, 'epoch': 0.18055756175068613, 'step': 1002500}
INFO:transformers.trainer:{'loss': 3.3088574557304384, 'learning_rate': 4.698920641004259e-05, 'epoch': 0.18064761539744456, 'step': 1003000}
INFO:transformers.trainer:{'loss': 3.3698251025676726, 'learning_rate': 4.6987705515929955e-05, 'epoch': 0.18073766904420302, 'step': 1003500}
INFO:transformers.trainer:{'loss': 3.3770522377491, 'learning_rate': 4.698620462181731e-05, 'epoch': 0.18082772269096145, 'step': 1004000}
INFO:transformers.trainer:{'loss': 3.3646477596759796, 'learning_rate': 4.698470372770467e-05, 'epoch': 0.1809177763377199, 'step': 1004500}
INFO:transformers.trainer:{'loss': 3.314801000833511, 'learning_rate': 4.6983202833592025e-05, 'epoch': 0.18100782998447834, 'step': 1005000}
INFO:transformers.trainer:{'loss': 3.3661720171570777, 'learning_rate': 4.698170193947939e-05, 'epoch': 0.1810978836312368, 'step': 1005500}
INFO:transformers.trainer:{'loss': 3.328635887503624, 'learning_rate': 4.698020104536675e-05, 'epoch': 0.18118793727799526, 'step': 1006000}
INFO:transformers.trainer:{'loss': 3.282600112438202, 'learning_rate': 4.697870015125411e-05, 'epoch': 0.1812779909247537, 'step': 1006500}
INFO:transformers.trainer:{'loss': 3.3079861181974413, 'learning_rate': 4.697719925714147e-05, 'epoch': 0.18136804457151215, 'step': 1007000}
INFO:transformers.trainer:{'loss': 3.3222391246557237, 'learning_rate': 4.697569836302883e-05, 'epoch': 0.18145809821827058, 'step': 1007500}
INFO:transformers.trainer:{'loss': 3.361189243555069, 'learning_rate': 4.6974197468916186e-05, 'epoch': 0.18154815186502904, 'step': 1008000}
INFO:transformers.trainer:{'loss': 3.366945922613144, 'learning_rate': 4.6972696574803545e-05, 'epoch': 0.18163820551178747, 'step': 1008500}
INFO:transformers.trainer:{'loss': 3.3356643490791322, 'learning_rate': 4.6971195680690904e-05, 'epoch': 0.18172825915854593, 'step': 1009000}
INFO:transformers.trainer:{'loss': 3.3942525973320006, 'learning_rate': 4.696969478657826e-05, 'epoch': 0.1818183128053044, 'step': 1009500}
INFO:transformers.trainer:{'loss': 3.3328949632644655, 'learning_rate': 4.696819389246562e-05, 'epoch': 0.18190836645206282, 'step': 1010000}
INFO:transformers.trainer:{'loss': 3.3785425486564638, 'learning_rate': 4.696669299835298e-05, 'epoch': 0.18199842009882128, 'step': 1010500}
INFO:transformers.trainer:{'loss': 3.324122992992401, 'learning_rate': 4.696519210424034e-05, 'epoch': 0.1820884737455797, 'step': 1011000}
INFO:transformers.trainer:{'loss': 3.303469415426254, 'learning_rate': 4.69636912101277e-05, 'epoch': 0.18217852739233817, 'step': 1011500}
INFO:transformers.trainer:{'loss': 3.328781104564667, 'learning_rate': 4.696219031601506e-05, 'epoch': 0.1822685810390966, 'step': 1012000}
INFO:transformers.trainer:{'loss': 3.3057142658233643, 'learning_rate': 4.696068942190242e-05, 'epoch': 0.18235863468585506, 'step': 1012500}
INFO:transformers.trainer:{'loss': 3.3271191248893737, 'learning_rate': 4.6959188527789777e-05, 'epoch': 0.18244868833261352, 'step': 1013000}
INFO:transformers.trainer:{'loss': 3.3600474033355714, 'learning_rate': 4.6957687633677136e-05, 'epoch': 0.18253874197937195, 'step': 1013500}
INFO:transformers.trainer:{'loss': 3.2984545433521273, 'learning_rate': 4.6956186739564495e-05, 'epoch': 0.1826287956261304, 'step': 1014000}
INFO:transformers.trainer:{'loss': 3.3032452731132507, 'learning_rate': 4.6954685845451854e-05, 'epoch': 0.18271884927288884, 'step': 1014500}
INFO:transformers.trainer:{'loss': 3.3189926369190217, 'learning_rate': 4.695318495133921e-05, 'epoch': 0.1828089029196473, 'step': 1015000}
INFO:transformers.trainer:{'loss': 3.329163421034813, 'learning_rate': 4.695168405722657e-05, 'epoch': 0.18289895656640573, 'step': 1015500}
INFO:transformers.trainer:{'loss': 3.333664041757584, 'learning_rate': 4.695018316311393e-05, 'epoch': 0.1829890102131642, 'step': 1016000}
INFO:transformers.trainer:{'loss': 3.369089770078659, 'learning_rate': 4.694868226900129e-05, 'epoch': 0.18307906385992262, 'step': 1016500}
INFO:transformers.trainer:{'loss': 3.3864429404735565, 'learning_rate': 4.694718137488865e-05, 'epoch': 0.18316911750668108, 'step': 1017000}
INFO:transformers.trainer:{'loss': 3.3527781400680543, 'learning_rate': 4.694568048077601e-05, 'epoch': 0.18325917115343954, 'step': 1017500}
INFO:transformers.trainer:{'loss': 3.3022564115524293, 'learning_rate': 4.694417958666337e-05, 'epoch': 0.18334922480019797, 'step': 1018000}
INFO:transformers.trainer:{'loss': 3.3163048835992814, 'learning_rate': 4.6942678692550726e-05, 'epoch': 0.18343927844695643, 'step': 1018500}
INFO:transformers.trainer:{'loss': 3.331844573497772, 'learning_rate': 4.6941177798438085e-05, 'epoch': 0.18352933209371486, 'step': 1019000}
INFO:transformers.trainer:{'loss': 3.356115822315216, 'learning_rate': 4.6939676904325444e-05, 'epoch': 0.18361938574047332, 'step': 1019500}
INFO:transformers.trainer:{'loss': 3.2835484700202944, 'learning_rate': 4.693817601021281e-05, 'epoch': 0.18370943938723175, 'step': 1020000}
INFO:transformers.trainer:{'loss': 3.27387396979332, 'learning_rate': 4.693667511610016e-05, 'epoch': 0.1837994930339902, 'step': 1020500}
INFO:transformers.trainer:{'loss': 3.2615304630994797, 'learning_rate': 4.693517422198753e-05, 'epoch': 0.18388954668074867, 'step': 1021000}
INFO:transformers.trainer:{'loss': 3.3346282448768614, 'learning_rate': 4.693367332787488e-05, 'epoch': 0.1839796003275071, 'step': 1021500}
INFO:transformers.trainer:{'loss': 3.348643948316574, 'learning_rate': 4.6932172433762246e-05, 'epoch': 0.18406965397426556, 'step': 1022000}
INFO:transformers.trainer:{'loss': 3.3244008088111876, 'learning_rate': 4.69306715396496e-05, 'epoch': 0.184159707621024, 'step': 1022500}
INFO:transformers.trainer:{'loss': 3.3712205708026888, 'learning_rate': 4.6929170645536964e-05, 'epoch': 0.18424976126778245, 'step': 1023000}
INFO:transformers.trainer:{'loss': 3.3472144536972044, 'learning_rate': 4.692766975142432e-05, 'epoch': 0.18433981491454088, 'step': 1023500}
INFO:transformers.trainer:{'loss': 3.383986060619354, 'learning_rate': 4.692616885731168e-05, 'epoch': 0.18442986856129934, 'step': 1024000}
INFO:transformers.trainer:{'loss': 3.38264440369606, 'learning_rate': 4.6924667963199035e-05, 'epoch': 0.1845199222080578, 'step': 1024500}
INFO:transformers.trainer:{'loss': 3.312511713266373, 'learning_rate': 4.69231670690864e-05, 'epoch': 0.18460997585481623, 'step': 1025000}
INFO:transformers.trainer:{'loss': 3.357607578039169, 'learning_rate': 4.692166617497375e-05, 'epoch': 0.1847000295015747, 'step': 1025500}
INFO:transformers.trainer:{'loss': 3.2966295664310454, 'learning_rate': 4.692016528086112e-05, 'epoch': 0.18479008314833312, 'step': 1026000}
INFO:transformers.trainer:{'loss': 3.331869675397873, 'learning_rate': 4.691866438674848e-05, 'epoch': 0.18488013679509158, 'step': 1026500}
INFO:transformers.trainer:{'loss': 3.352779452562332, 'learning_rate': 4.691716349263584e-05, 'epoch': 0.18497019044185, 'step': 1027000}
INFO:transformers.trainer:{'loss': 3.332168662548065, 'learning_rate': 4.6915662598523196e-05, 'epoch': 0.18506024408860847, 'step': 1027500}
INFO:transformers.trainer:{'loss': 3.313013596534729, 'learning_rate': 4.6914161704410555e-05, 'epoch': 0.18515029773536693, 'step': 1028000}
INFO:transformers.trainer:{'loss': 3.361694805622101, 'learning_rate': 4.6912660810297914e-05, 'epoch': 0.18524035138212536, 'step': 1028500}
INFO:transformers.trainer:{'loss': 3.3315615856647494, 'learning_rate': 4.691115991618527e-05, 'epoch': 0.18533040502888382, 'step': 1029000}
INFO:transformers.trainer:{'loss': 3.3784361765384676, 'learning_rate': 4.690965902207263e-05, 'epoch': 0.18542045867564225, 'step': 1029500}
INFO:transformers.trainer:{'loss': 3.3695363092422483, 'learning_rate': 4.690815812795999e-05, 'epoch': 0.1855105123224007, 'step': 1030000}
INFO:transformers.trainer:{'loss': 3.3418760988712313, 'learning_rate': 4.690665723384735e-05, 'epoch': 0.18560056596915914, 'step': 1030500}
INFO:transformers.trainer:{'loss': 3.2969287662506104, 'learning_rate': 4.690515633973471e-05, 'epoch': 0.1856906196159176, 'step': 1031000}
INFO:transformers.trainer:{'loss': 3.368736627817154, 'learning_rate': 4.690365544562207e-05, 'epoch': 0.18578067326267605, 'step': 1031500}
INFO:transformers.trainer:{'loss': 3.2769930629730224, 'learning_rate': 4.690215455150943e-05, 'epoch': 0.18587072690943449, 'step': 1032000}
INFO:transformers.trainer:{'loss': 3.3661704392433167, 'learning_rate': 4.6900653657396786e-05, 'epoch': 0.18596078055619295, 'step': 1032500}
INFO:transformers.trainer:{'loss': 3.293559653520584, 'learning_rate': 4.6899152763284145e-05, 'epoch': 0.18605083420295138, 'step': 1033000}
INFO:transformers.trainer:{'loss': 3.2657252933979035, 'learning_rate': 4.6897651869171504e-05, 'epoch': 0.18614088784970984, 'step': 1033500}
INFO:transformers.trainer:{'loss': 3.2743596000671387, 'learning_rate': 4.6896150975058863e-05, 'epoch': 0.18623094149646827, 'step': 1034000}
INFO:transformers.trainer:{'loss': 3.322533308506012, 'learning_rate': 4.689465008094622e-05, 'epoch': 0.18632099514322673, 'step': 1034500}
INFO:transformers.trainer:{'loss': 3.309921581506729, 'learning_rate': 4.689314918683358e-05, 'epoch': 0.18641104878998516, 'step': 1035000}
INFO:transformers.trainer:{'loss': 3.3128624820709227, 'learning_rate': 4.689164829272094e-05, 'epoch': 0.18650110243674362, 'step': 1035500}
INFO:transformers.trainer:{'loss': 3.3721540274620057, 'learning_rate': 4.68901473986083e-05, 'epoch': 0.18659115608350207, 'step': 1036000}
INFO:transformers.trainer:{'loss': 3.4062113444805147, 'learning_rate': 4.688864650449566e-05, 'epoch': 0.1866812097302605, 'step': 1036500}
INFO:transformers.trainer:{'loss': 3.39236563873291, 'learning_rate': 4.688714561038302e-05, 'epoch': 0.18677126337701896, 'step': 1037000}
INFO:transformers.trainer:{'loss': 3.403811337709427, 'learning_rate': 4.688564471627038e-05, 'epoch': 0.1868613170237774, 'step': 1037500}
INFO:transformers.trainer:{'loss': 3.2765482649803164, 'learning_rate': 4.6884143822157736e-05, 'epoch': 0.18695137067053585, 'step': 1038000}
INFO:transformers.trainer:{'loss': 3.330271954536438, 'learning_rate': 4.6882642928045095e-05, 'epoch': 0.18704142431729429, 'step': 1038500}
INFO:transformers.trainer:{'loss': 3.30360812830925, 'learning_rate': 4.6881142033932454e-05, 'epoch': 0.18713147796405274, 'step': 1039000}
INFO:transformers.trainer:{'loss': 3.3719058504104615, 'learning_rate': 4.687964113981981e-05, 'epoch': 0.1872215316108112, 'step': 1039500}
INFO:transformers.trainer:{'loss': 3.338915778875351, 'learning_rate': 4.687814024570717e-05, 'epoch': 0.18731158525756963, 'step': 1040000}
INFO:transformers.trainer:{'loss': 3.348271842598915, 'learning_rate': 4.687663935159454e-05, 'epoch': 0.1874016389043281, 'step': 1040500}
INFO:transformers.trainer:{'loss': 3.3881886262893675, 'learning_rate': 4.687513845748189e-05, 'epoch': 0.18749169255108653, 'step': 1041000}
INFO:transformers.trainer:{'loss': 3.329112802505493, 'learning_rate': 4.6873637563369256e-05, 'epoch': 0.18758174619784498, 'step': 1041500}
INFO:transformers.trainer:{'loss': 3.3211058316230773, 'learning_rate': 4.687213666925661e-05, 'epoch': 0.18767179984460342, 'step': 1042000}
INFO:transformers.trainer:{'loss': 3.3849494552612303, 'learning_rate': 4.6870635775143974e-05, 'epoch': 0.18776185349136187, 'step': 1042500}
INFO:transformers.trainer:{'loss': 3.3443014767169954, 'learning_rate': 4.6869134881031326e-05, 'epoch': 0.18785190713812033, 'step': 1043000}
INFO:transformers.trainer:{'loss': 3.3399151298999787, 'learning_rate': 4.686763398691869e-05, 'epoch': 0.18794196078487876, 'step': 1043500}
INFO:transformers.trainer:{'loss': 3.403722637414932, 'learning_rate': 4.6866133092806044e-05, 'epoch': 0.18803201443163722, 'step': 1044000}
INFO:transformers.trainer:{'loss': 3.3704573967456817, 'learning_rate': 4.686463219869341e-05, 'epoch': 0.18812206807839565, 'step': 1044500}
INFO:transformers.trainer:{'loss': 3.31156916475296, 'learning_rate': 4.686313130458076e-05, 'epoch': 0.1882121217251541, 'step': 1045000}
INFO:transformers.trainer:{'loss': 3.3602581359148025, 'learning_rate': 4.686163041046813e-05, 'epoch': 0.18830217537191254, 'step': 1045500}
INFO:transformers.trainer:{'loss': 3.322446268796921, 'learning_rate': 4.686012951635548e-05, 'epoch': 0.188392229018671, 'step': 1046000}
INFO:transformers.trainer:{'loss': 3.3420999603271486, 'learning_rate': 4.6858628622242846e-05, 'epoch': 0.18848228266542946, 'step': 1046500}
INFO:transformers.trainer:{'loss': 3.2811696710586546, 'learning_rate': 4.68571277281302e-05, 'epoch': 0.1885723363121879, 'step': 1047000}
INFO:transformers.trainer:{'loss': 3.293358720541, 'learning_rate': 4.6855626834017565e-05, 'epoch': 0.18866238995894635, 'step': 1047500}
INFO:transformers.trainer:{'loss': 3.3265255768299102, 'learning_rate': 4.6854125939904924e-05, 'epoch': 0.18875244360570478, 'step': 1048000}
INFO:transformers.trainer:{'loss': 3.358935292959213, 'learning_rate': 4.685262504579228e-05, 'epoch': 0.18884249725246324, 'step': 1048500}
INFO:transformers.trainer:{'loss': 3.3016038444042204, 'learning_rate': 4.685112415167964e-05, 'epoch': 0.18893255089922167, 'step': 1049000}
INFO:transformers.trainer:{'loss': 3.328223253250122, 'learning_rate': 4.6849623257567e-05, 'epoch': 0.18902260454598013, 'step': 1049500}
INFO:transformers.trainer:{'loss': 3.313655544757843, 'learning_rate': 4.684812236345436e-05, 'epoch': 0.1891126581927386, 'step': 1050000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1050000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1050000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1050000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-950000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3285636467933655, 'learning_rate': 4.684662146934172e-05, 'epoch': 0.18920271183949702, 'step': 1050500}
INFO:transformers.trainer:{'loss': 3.3112649874687197, 'learning_rate': 4.684512057522908e-05, 'epoch': 0.18929276548625548, 'step': 1051000}
INFO:transformers.trainer:{'loss': 3.3591311552524568, 'learning_rate': 4.684361968111644e-05, 'epoch': 0.1893828191330139, 'step': 1051500}
INFO:transformers.trainer:{'loss': 3.3176309208869936, 'learning_rate': 4.6842118787003796e-05, 'epoch': 0.18947287277977237, 'step': 1052000}
INFO:transformers.trainer:{'loss': 3.2963244907855986, 'learning_rate': 4.6840617892891155e-05, 'epoch': 0.1895629264265308, 'step': 1052500}
INFO:transformers.trainer:{'loss': 3.3517673518657682, 'learning_rate': 4.6839116998778514e-05, 'epoch': 0.18965298007328926, 'step': 1053000}
INFO:transformers.trainer:{'loss': 3.307773669242859, 'learning_rate': 4.683761610466587e-05, 'epoch': 0.1897430337200477, 'step': 1053500}
INFO:transformers.trainer:{'loss': 3.3186123217344283, 'learning_rate': 4.683611521055323e-05, 'epoch': 0.18983308736680615, 'step': 1054000}
INFO:transformers.trainer:{'loss': 3.265200328588486, 'learning_rate': 4.68346143164406e-05, 'epoch': 0.1899231410135646, 'step': 1054500}
INFO:transformers.trainer:{'loss': 3.3561640655994416, 'learning_rate': 4.683311342232795e-05, 'epoch': 0.19001319466032304, 'step': 1055000}
INFO:transformers.trainer:{'loss': 3.314439159989357, 'learning_rate': 4.6831612528215316e-05, 'epoch': 0.1901032483070815, 'step': 1055500}
INFO:transformers.trainer:{'loss': 3.354705251932144, 'learning_rate': 4.683011163410267e-05, 'epoch': 0.19019330195383993, 'step': 1056000}
INFO:transformers.trainer:{'loss': 3.2929331736564635, 'learning_rate': 4.6828610739990034e-05, 'epoch': 0.1902833556005984, 'step': 1056500}
INFO:transformers.trainer:{'loss': 3.3083444657325747, 'learning_rate': 4.6827109845877387e-05, 'epoch': 0.19037340924735682, 'step': 1057000}
INFO:transformers.trainer:{'loss': 3.2693371329307555, 'learning_rate': 4.6825608951764746e-05, 'epoch': 0.19046346289411528, 'step': 1057500}
INFO:transformers.trainer:{'loss': 3.355127145767212, 'learning_rate': 4.6824108057652105e-05, 'epoch': 0.19055351654087374, 'step': 1058000}
INFO:transformers.trainer:{'loss': 3.3730494141578675, 'learning_rate': 4.6822607163539464e-05, 'epoch': 0.19064357018763217, 'step': 1058500}
INFO:transformers.trainer:{'loss': 3.3060266621112824, 'learning_rate': 4.682110626942682e-05, 'epoch': 0.19073362383439063, 'step': 1059000}
INFO:transformers.trainer:{'loss': 3.3310653017759324, 'learning_rate': 4.681960537531418e-05, 'epoch': 0.19082367748114906, 'step': 1059500}
INFO:transformers.trainer:{'loss': 3.3480100059509277, 'learning_rate': 4.681810448120154e-05, 'epoch': 0.19091373112790752, 'step': 1060000}
INFO:transformers.trainer:{'loss': 3.383087378025055, 'learning_rate': 4.68166035870889e-05, 'epoch': 0.19100378477466595, 'step': 1060500}
INFO:transformers.trainer:{'loss': 3.3223223140239715, 'learning_rate': 4.6815102692976266e-05, 'epoch': 0.1910938384214244, 'step': 1061000}
INFO:transformers.trainer:{'loss': 3.3121602783203126, 'learning_rate': 4.681360179886362e-05, 'epoch': 0.19118389206818287, 'step': 1061500}
INFO:transformers.trainer:{'loss': 3.2887633949518205, 'learning_rate': 4.6812100904750984e-05, 'epoch': 0.1912739457149413, 'step': 1062000}
INFO:transformers.trainer:{'loss': 3.3451970839500427, 'learning_rate': 4.6810600010638336e-05, 'epoch': 0.19136399936169976, 'step': 1062500}
INFO:transformers.trainer:{'loss': 3.366469234228134, 'learning_rate': 4.68090991165257e-05, 'epoch': 0.1914540530084582, 'step': 1063000}
INFO:transformers.trainer:{'loss': 3.2536683349609374, 'learning_rate': 4.6807598222413054e-05, 'epoch': 0.19154410665521665, 'step': 1063500}
INFO:transformers.trainer:{'loss': 3.327541998386383, 'learning_rate': 4.680609732830042e-05, 'epoch': 0.19163416030197508, 'step': 1064000}
INFO:transformers.trainer:{'loss': 3.399516056537628, 'learning_rate': 4.680459643418777e-05, 'epoch': 0.19172421394873354, 'step': 1064500}
INFO:transformers.trainer:{'loss': 3.3019068928956985, 'learning_rate': 4.680309554007514e-05, 'epoch': 0.191814267595492, 'step': 1065000}
INFO:transformers.trainer:{'loss': 3.29096362221241, 'learning_rate': 4.680159464596249e-05, 'epoch': 0.19190432124225043, 'step': 1065500}
INFO:transformers.trainer:{'loss': 3.30101750767231, 'learning_rate': 4.6800093751849856e-05, 'epoch': 0.1919943748890089, 'step': 1066000}
INFO:transformers.trainer:{'loss': 3.376335396647453, 'learning_rate': 4.679859285773721e-05, 'epoch': 0.19208442853576732, 'step': 1066500}
INFO:transformers.trainer:{'loss': 3.345823815345764, 'learning_rate': 4.6797091963624574e-05, 'epoch': 0.19217448218252578, 'step': 1067000}
INFO:transformers.trainer:{'loss': 3.330908007144928, 'learning_rate': 4.6795591069511927e-05, 'epoch': 0.1922645358292842, 'step': 1067500}
INFO:transformers.trainer:{'loss': 3.2902831261157988, 'learning_rate': 4.679409017539929e-05, 'epoch': 0.19235458947604267, 'step': 1068000}
INFO:transformers.trainer:{'loss': 3.3454429261684417, 'learning_rate': 4.679258928128665e-05, 'epoch': 0.19244464312280113, 'step': 1068500}
INFO:transformers.trainer:{'loss': 3.284157437801361, 'learning_rate': 4.679108838717401e-05, 'epoch': 0.19253469676955956, 'step': 1069000}
INFO:transformers.trainer:{'loss': 3.2970095579624177, 'learning_rate': 4.678958749306137e-05, 'epoch': 0.19262475041631802, 'step': 1069500}
INFO:transformers.trainer:{'loss': 3.3493196268081666, 'learning_rate': 4.678808659894873e-05, 'epoch': 0.19271480406307645, 'step': 1070000}
INFO:transformers.trainer:{'loss': 3.3234411351680757, 'learning_rate': 4.678658570483609e-05, 'epoch': 0.1928048577098349, 'step': 1070500}
INFO:transformers.trainer:{'loss': 3.411181960105896, 'learning_rate': 4.678508481072345e-05, 'epoch': 0.19289491135659334, 'step': 1071000}
INFO:transformers.trainer:{'loss': 3.3749637122154237, 'learning_rate': 4.6783583916610806e-05, 'epoch': 0.1929849650033518, 'step': 1071500}
INFO:transformers.trainer:{'loss': 3.322053599357605, 'learning_rate': 4.6782083022498165e-05, 'epoch': 0.19307501865011023, 'step': 1072000}
INFO:transformers.trainer:{'loss': 3.3539559922218323, 'learning_rate': 4.6780582128385524e-05, 'epoch': 0.1931650722968687, 'step': 1072500}
INFO:transformers.trainer:{'loss': 3.3180136919021606, 'learning_rate': 4.677908123427288e-05, 'epoch': 0.19325512594362715, 'step': 1073000}
INFO:transformers.trainer:{'loss': 3.2740126719474794, 'learning_rate': 4.677758034016024e-05, 'epoch': 0.19334517959038558, 'step': 1073500}
INFO:transformers.trainer:{'loss': 3.3181794288158417, 'learning_rate': 4.67760794460476e-05, 'epoch': 0.19343523323714404, 'step': 1074000}
INFO:transformers.trainer:{'loss': 3.3419661173820496, 'learning_rate': 4.677457855193496e-05, 'epoch': 0.19352528688390247, 'step': 1074500}
INFO:transformers.trainer:{'loss': 3.3346768379211427, 'learning_rate': 4.6773077657822326e-05, 'epoch': 0.19361534053066093, 'step': 1075000}
INFO:transformers.trainer:{'loss': 3.3024352114200592, 'learning_rate': 4.677157676370968e-05, 'epoch': 0.19370539417741936, 'step': 1075500}
INFO:transformers.trainer:{'loss': 3.316999616384506, 'learning_rate': 4.6770075869597044e-05, 'epoch': 0.19379544782417782, 'step': 1076000}
INFO:transformers.trainer:{'loss': 3.361460571527481, 'learning_rate': 4.6768574975484396e-05, 'epoch': 0.19388550147093628, 'step': 1076500}
INFO:transformers.trainer:{'loss': 3.2951137998104096, 'learning_rate': 4.676707408137176e-05, 'epoch': 0.1939755551176947, 'step': 1077000}
INFO:transformers.trainer:{'loss': 3.2830923051834104, 'learning_rate': 4.6765573187259114e-05, 'epoch': 0.19406560876445317, 'step': 1077500}
INFO:transformers.trainer:{'loss': 3.242264742612839, 'learning_rate': 4.676407229314648e-05, 'epoch': 0.1941556624112116, 'step': 1078000}
INFO:transformers.trainer:{'loss': 3.3410278042554857, 'learning_rate': 4.676257139903383e-05, 'epoch': 0.19424571605797006, 'step': 1078500}
INFO:transformers.trainer:{'loss': 3.273290395975113, 'learning_rate': 4.67610705049212e-05, 'epoch': 0.1943357697047285, 'step': 1079000}
INFO:transformers.trainer:{'loss': 3.283175830125809, 'learning_rate': 4.675956961080855e-05, 'epoch': 0.19442582335148695, 'step': 1079500}
INFO:transformers.trainer:{'loss': 3.3144295885562896, 'learning_rate': 4.6758068716695916e-05, 'epoch': 0.1945158769982454, 'step': 1080000}
INFO:transformers.trainer:{'loss': 3.3386844985485076, 'learning_rate': 4.675656782258327e-05, 'epoch': 0.19460593064500384, 'step': 1080500}
INFO:transformers.trainer:{'loss': 3.3330261163711548, 'learning_rate': 4.675506692847063e-05, 'epoch': 0.1946959842917623, 'step': 1081000}
INFO:transformers.trainer:{'loss': 3.372457599401474, 'learning_rate': 4.675356603435799e-05, 'epoch': 0.19478603793852073, 'step': 1081500}
INFO:transformers.trainer:{'loss': 3.3055800144672394, 'learning_rate': 4.6752065140245346e-05, 'epoch': 0.1948760915852792, 'step': 1082000}
INFO:transformers.trainer:{'loss': 3.320354743003845, 'learning_rate': 4.675056424613271e-05, 'epoch': 0.19496614523203762, 'step': 1082500}
INFO:transformers.trainer:{'loss': 3.3394660351276397, 'learning_rate': 4.6749063352020064e-05, 'epoch': 0.19505619887879608, 'step': 1083000}
INFO:transformers.trainer:{'loss': 3.282429173707962, 'learning_rate': 4.674756245790743e-05, 'epoch': 0.19514625252555454, 'step': 1083500}
INFO:transformers.trainer:{'loss': 3.3391476216316223, 'learning_rate': 4.674606156379478e-05, 'epoch': 0.19523630617231297, 'step': 1084000}
INFO:transformers.trainer:{'loss': 3.2955175573825835, 'learning_rate': 4.674456066968215e-05, 'epoch': 0.19532635981907143, 'step': 1084500}
INFO:transformers.trainer:{'loss': 3.2899971323013304, 'learning_rate': 4.67430597755695e-05, 'epoch': 0.19541641346582986, 'step': 1085000}
INFO:transformers.trainer:{'loss': 3.2750160621404647, 'learning_rate': 4.6741558881456866e-05, 'epoch': 0.19550646711258832, 'step': 1085500}
INFO:transformers.trainer:{'loss': 3.289836682200432, 'learning_rate': 4.674005798734422e-05, 'epoch': 0.19559652075934675, 'step': 1086000}
INFO:transformers.trainer:{'loss': 3.3587573657035827, 'learning_rate': 4.6738557093231584e-05, 'epoch': 0.1956865744061052, 'step': 1086500}
INFO:transformers.trainer:{'loss': 3.3243042719364166, 'learning_rate': 4.6737056199118936e-05, 'epoch': 0.19577662805286364, 'step': 1087000}
INFO:transformers.trainer:{'loss': 3.3509900369644163, 'learning_rate': 4.67355553050063e-05, 'epoch': 0.1958666816996221, 'step': 1087500}
INFO:transformers.trainer:{'loss': 3.36106973361969, 'learning_rate': 4.6734054410893654e-05, 'epoch': 0.19595673534638056, 'step': 1088000}
INFO:transformers.trainer:{'loss': 3.335376641392708, 'learning_rate': 4.673255351678102e-05, 'epoch': 0.196046788993139, 'step': 1088500}
INFO:transformers.trainer:{'loss': 3.350829892873764, 'learning_rate': 4.673105262266838e-05, 'epoch': 0.19613684263989745, 'step': 1089000}
INFO:transformers.trainer:{'loss': 3.328415043592453, 'learning_rate': 4.672955172855574e-05, 'epoch': 0.19622689628665588, 'step': 1089500}
INFO:transformers.trainer:{'loss': 3.3482096059322357, 'learning_rate': 4.67280508344431e-05, 'epoch': 0.19631694993341434, 'step': 1090000}
INFO:transformers.trainer:{'loss': 3.28292010474205, 'learning_rate': 4.6726549940330456e-05, 'epoch': 0.19640700358017277, 'step': 1090500}
INFO:transformers.trainer:{'loss': 3.3633430109024047, 'learning_rate': 4.6725049046217815e-05, 'epoch': 0.19649705722693123, 'step': 1091000}
INFO:transformers.trainer:{'loss': 3.3555654532909394, 'learning_rate': 4.6723548152105175e-05, 'epoch': 0.19658711087368969, 'step': 1091500}
INFO:transformers.trainer:{'loss': 3.396449818134308, 'learning_rate': 4.6722047257992534e-05, 'epoch': 0.19667716452044812, 'step': 1092000}
INFO:transformers.trainer:{'loss': 3.328624478816986, 'learning_rate': 4.672054636387989e-05, 'epoch': 0.19676721816720658, 'step': 1092500}
INFO:transformers.trainer:{'loss': 3.2391404227018357, 'learning_rate': 4.671904546976725e-05, 'epoch': 0.196857271813965, 'step': 1093000}
INFO:transformers.trainer:{'loss': 3.343881152391434, 'learning_rate': 4.671754457565461e-05, 'epoch': 0.19694732546072347, 'step': 1093500}
INFO:transformers.trainer:{'loss': 3.356205441713333, 'learning_rate': 4.671604368154197e-05, 'epoch': 0.1970373791074819, 'step': 1094000}
INFO:transformers.trainer:{'loss': 3.3876569652557373, 'learning_rate': 4.671454278742933e-05, 'epoch': 0.19712743275424036, 'step': 1094500}
INFO:transformers.trainer:{'loss': 3.3214493873119353, 'learning_rate': 4.671304189331669e-05, 'epoch': 0.19721748640099881, 'step': 1095000}
INFO:transformers.trainer:{'loss': 3.341744808673859, 'learning_rate': 4.671154099920405e-05, 'epoch': 0.19730754004775725, 'step': 1095500}
INFO:transformers.trainer:{'loss': 3.324233701944351, 'learning_rate': 4.6710040105091406e-05, 'epoch': 0.1973975936945157, 'step': 1096000}
INFO:transformers.trainer:{'loss': 3.3644205706119537, 'learning_rate': 4.670853921097877e-05, 'epoch': 0.19748764734127414, 'step': 1096500}
INFO:transformers.trainer:{'loss': 3.352001718044281, 'learning_rate': 4.6707038316866124e-05, 'epoch': 0.1975777009880326, 'step': 1097000}
INFO:transformers.trainer:{'loss': 3.3129236161708833, 'learning_rate': 4.670553742275349e-05, 'epoch': 0.19766775463479103, 'step': 1097500}
INFO:transformers.trainer:{'loss': 3.321243593454361, 'learning_rate': 4.670403652864084e-05, 'epoch': 0.19775780828154949, 'step': 1098000}
INFO:transformers.trainer:{'loss': 3.320133482694626, 'learning_rate': 4.670253563452821e-05, 'epoch': 0.19784786192830794, 'step': 1098500}
INFO:transformers.trainer:{'loss': 3.3533126428127287, 'learning_rate': 4.670103474041556e-05, 'epoch': 0.19793791557506638, 'step': 1099000}
INFO:transformers.trainer:{'loss': 3.359772490501404, 'learning_rate': 4.6699533846302926e-05, 'epoch': 0.19802796922182483, 'step': 1099500}
INFO:transformers.trainer:{'loss': 3.3364614889621733, 'learning_rate': 4.669803295219028e-05, 'epoch': 0.19811802286858327, 'step': 1100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1100000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1000000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.325115830421448, 'learning_rate': 4.6696532058077644e-05, 'epoch': 0.19820807651534172, 'step': 1100500}
INFO:transformers.trainer:{'loss': 3.326214819192886, 'learning_rate': 4.6695031163964996e-05, 'epoch': 0.19829813016210016, 'step': 1101000}
INFO:transformers.trainer:{'loss': 3.3124371559619905, 'learning_rate': 4.669353026985236e-05, 'epoch': 0.19838818380885861, 'step': 1101500}
INFO:transformers.trainer:{'loss': 3.315923784971237, 'learning_rate': 4.6692029375739715e-05, 'epoch': 0.19847823745561707, 'step': 1102000}
INFO:transformers.trainer:{'loss': 3.330711282253265, 'learning_rate': 4.669052848162708e-05, 'epoch': 0.1985682911023755, 'step': 1102500}
INFO:transformers.trainer:{'loss': 3.3375621116161347, 'learning_rate': 4.668902758751444e-05, 'epoch': 0.19865834474913396, 'step': 1103000}
INFO:transformers.trainer:{'loss': 3.3471003321409225, 'learning_rate': 4.66875266934018e-05, 'epoch': 0.1987483983958924, 'step': 1103500}
INFO:transformers.trainer:{'loss': 3.3371677438020706, 'learning_rate': 4.668602579928916e-05, 'epoch': 0.19883845204265085, 'step': 1104000}
INFO:transformers.trainer:{'loss': 3.3136858196258543, 'learning_rate': 4.668452490517651e-05, 'epoch': 0.19892850568940929, 'step': 1104500}
INFO:transformers.trainer:{'loss': 3.350633308172226, 'learning_rate': 4.6683024011063876e-05, 'epoch': 0.19901855933616774, 'step': 1105000}
INFO:transformers.trainer:{'loss': 3.303521972179413, 'learning_rate': 4.668152311695123e-05, 'epoch': 0.19910861298292618, 'step': 1105500}
INFO:transformers.trainer:{'loss': 3.2655809030532836, 'learning_rate': 4.6680022222838594e-05, 'epoch': 0.19919866662968463, 'step': 1106000}
INFO:transformers.trainer:{'loss': 3.373284648656845, 'learning_rate': 4.6678521328725946e-05, 'epoch': 0.1992887202764431, 'step': 1106500}
INFO:transformers.trainer:{'loss': 3.329124131679535, 'learning_rate': 4.667702043461331e-05, 'epoch': 0.19937877392320152, 'step': 1107000}
INFO:transformers.trainer:{'loss': 3.320958080291748, 'learning_rate': 4.6675519540500664e-05, 'epoch': 0.19946882756995998, 'step': 1107500}
INFO:transformers.trainer:{'loss': 3.378608960866928, 'learning_rate': 4.667401864638803e-05, 'epoch': 0.19955888121671841, 'step': 1108000}
INFO:transformers.trainer:{'loss': 3.3204784214496614, 'learning_rate': 4.667251775227538e-05, 'epoch': 0.19964893486347687, 'step': 1108500}
INFO:transformers.trainer:{'loss': 3.3409775614738466, 'learning_rate': 4.667101685816275e-05, 'epoch': 0.1997389885102353, 'step': 1109000}
INFO:transformers.trainer:{'loss': 3.2853355565071105, 'learning_rate': 4.66695159640501e-05, 'epoch': 0.19982904215699376, 'step': 1109500}
INFO:transformers.trainer:{'loss': 3.306888542890549, 'learning_rate': 4.6668015069937466e-05, 'epoch': 0.19991909580375222, 'step': 1110000}
INFO:transformers.trainer:{'loss': 3.3422191150188447, 'learning_rate': 4.6666514175824825e-05, 'epoch': 0.20000914945051065, 'step': 1110500}
INFO:transformers.trainer:{'loss': 3.2995045604705813, 'learning_rate': 4.6665013281712184e-05, 'epoch': 0.2000992030972691, 'step': 1111000}
INFO:transformers.trainer:{'loss': 3.337789491176605, 'learning_rate': 4.666351238759954e-05, 'epoch': 0.20018925674402754, 'step': 1111500}
INFO:transformers.trainer:{'loss': 3.299717097520828, 'learning_rate': 4.66620114934869e-05, 'epoch': 0.200279310390786, 'step': 1112000}
INFO:transformers.trainer:{'loss': 3.4109598038196562, 'learning_rate': 4.666051059937426e-05, 'epoch': 0.20036936403754443, 'step': 1112500}
INFO:transformers.trainer:{'loss': 3.2958534877300263, 'learning_rate': 4.665900970526162e-05, 'epoch': 0.2004594176843029, 'step': 1113000}
INFO:transformers.trainer:{'loss': 3.2954412781000135, 'learning_rate': 4.665750881114898e-05, 'epoch': 0.20054947133106135, 'step': 1113500}
INFO:transformers.trainer:{'loss': 3.3511574835777282, 'learning_rate': 4.665600791703634e-05, 'epoch': 0.20063952497781978, 'step': 1114000}
INFO:transformers.trainer:{'loss': 3.3210669021606445, 'learning_rate': 4.66545070229237e-05, 'epoch': 0.20072957862457824, 'step': 1114500}
INFO:transformers.trainer:{'loss': 3.2947957241535186, 'learning_rate': 4.665300612881106e-05, 'epoch': 0.20081963227133667, 'step': 1115000}
INFO:transformers.trainer:{'loss': 3.392740032672882, 'learning_rate': 4.6651505234698416e-05, 'epoch': 0.20090968591809513, 'step': 1115500}
INFO:transformers.trainer:{'loss': 3.323693420410156, 'learning_rate': 4.6650004340585775e-05, 'epoch': 0.20099973956485356, 'step': 1116000}
INFO:transformers.trainer:{'loss': 3.2814005388617518, 'learning_rate': 4.6648503446473134e-05, 'epoch': 0.20108979321161202, 'step': 1116500}
INFO:transformers.trainer:{'loss': 3.3244912967681883, 'learning_rate': 4.66470025523605e-05, 'epoch': 0.20117984685837048, 'step': 1117000}
INFO:transformers.trainer:{'loss': 3.2996966679096222, 'learning_rate': 4.664550165824785e-05, 'epoch': 0.2012699005051289, 'step': 1117500}
INFO:transformers.trainer:{'loss': 3.3345526456832886, 'learning_rate': 4.664400076413522e-05, 'epoch': 0.20135995415188737, 'step': 1118000}
INFO:transformers.trainer:{'loss': 3.3507596862316134, 'learning_rate': 4.664249987002257e-05, 'epoch': 0.2014500077986458, 'step': 1118500}
INFO:transformers.trainer:{'loss': 3.3574886667728423, 'learning_rate': 4.6640998975909936e-05, 'epoch': 0.20154006144540426, 'step': 1119000}
INFO:transformers.trainer:{'loss': 3.361686756372452, 'learning_rate': 4.663949808179729e-05, 'epoch': 0.2016301150921627, 'step': 1119500}
INFO:transformers.trainer:{'loss': 3.309129052877426, 'learning_rate': 4.6637997187684654e-05, 'epoch': 0.20172016873892115, 'step': 1120000}
INFO:transformers.trainer:{'loss': 3.352080511808395, 'learning_rate': 4.6636496293572006e-05, 'epoch': 0.2018102223856796, 'step': 1120500}
INFO:transformers.trainer:{'loss': 3.311875690460205, 'learning_rate': 4.663499539945937e-05, 'epoch': 0.20190027603243804, 'step': 1121000}
INFO:transformers.trainer:{'loss': 3.3645323629379273, 'learning_rate': 4.6633494505346724e-05, 'epoch': 0.2019903296791965, 'step': 1121500}
INFO:transformers.trainer:{'loss': 3.3428567361831667, 'learning_rate': 4.663199361123409e-05, 'epoch': 0.20208038332595493, 'step': 1122000}
INFO:transformers.trainer:{'loss': 3.3469540593624116, 'learning_rate': 4.663049271712144e-05, 'epoch': 0.2021704369727134, 'step': 1122500}
INFO:transformers.trainer:{'loss': 3.383153856754303, 'learning_rate': 4.662899182300881e-05, 'epoch': 0.20226049061947182, 'step': 1123000}
INFO:transformers.trainer:{'loss': 3.346005550146103, 'learning_rate': 4.662749092889617e-05, 'epoch': 0.20235054426623028, 'step': 1123500}
INFO:transformers.trainer:{'loss': 3.3444168734550477, 'learning_rate': 4.6625990034783526e-05, 'epoch': 0.2024405979129887, 'step': 1124000}
INFO:transformers.trainer:{'loss': 3.3209562051296233, 'learning_rate': 4.6624489140670885e-05, 'epoch': 0.20253065155974717, 'step': 1124500}
INFO:transformers.trainer:{'loss': 3.3560897171497346, 'learning_rate': 4.6622988246558244e-05, 'epoch': 0.20262070520650563, 'step': 1125000}
INFO:transformers.trainer:{'loss': 3.3455153827667234, 'learning_rate': 4.6621487352445603e-05, 'epoch': 0.20271075885326406, 'step': 1125500}
INFO:transformers.trainer:{'loss': 3.346366267681122, 'learning_rate': 4.661998645833296e-05, 'epoch': 0.20280081250002252, 'step': 1126000}
INFO:transformers.trainer:{'loss': 3.320030784368515, 'learning_rate': 4.661848556422032e-05, 'epoch': 0.20289086614678095, 'step': 1126500}
INFO:transformers.trainer:{'loss': 3.2464346504211425, 'learning_rate': 4.661698467010768e-05, 'epoch': 0.2029809197935394, 'step': 1127000}
INFO:transformers.trainer:{'loss': 3.344500044345856, 'learning_rate': 4.661548377599504e-05, 'epoch': 0.20307097344029784, 'step': 1127500}
INFO:transformers.trainer:{'loss': 3.3567860012054442, 'learning_rate': 4.66139828818824e-05, 'epoch': 0.2031610270870563, 'step': 1128000}
INFO:transformers.trainer:{'loss': 3.3401156458854677, 'learning_rate': 4.661248198776976e-05, 'epoch': 0.20325108073381476, 'step': 1128500}
INFO:transformers.trainer:{'loss': 3.320269846200943, 'learning_rate': 4.661098109365711e-05, 'epoch': 0.2033411343805732, 'step': 1129000}
INFO:transformers.trainer:{'loss': 3.3569601809978487, 'learning_rate': 4.6609480199544476e-05, 'epoch': 0.20343118802733165, 'step': 1129500}
INFO:transformers.trainer:{'loss': 3.2940135152339933, 'learning_rate': 4.660797930543183e-05, 'epoch': 0.20352124167409008, 'step': 1130000}
INFO:transformers.trainer:{'loss': 3.3364021434783937, 'learning_rate': 4.6606478411319194e-05, 'epoch': 0.20361129532084854, 'step': 1130500}
INFO:transformers.trainer:{'loss': 3.316111314892769, 'learning_rate': 4.660497751720655e-05, 'epoch': 0.20370134896760697, 'step': 1131000}
INFO:transformers.trainer:{'loss': 3.351247020959854, 'learning_rate': 4.660347662309391e-05, 'epoch': 0.20379140261436543, 'step': 1131500}
INFO:transformers.trainer:{'loss': 3.334749127149582, 'learning_rate': 4.660197572898127e-05, 'epoch': 0.2038814562611239, 'step': 1132000}
INFO:transformers.trainer:{'loss': 3.2796703095436097, 'learning_rate': 4.660047483486863e-05, 'epoch': 0.20397150990788232, 'step': 1132500}
INFO:transformers.trainer:{'loss': 3.30607976603508, 'learning_rate': 4.659897394075599e-05, 'epoch': 0.20406156355464078, 'step': 1133000}
INFO:transformers.trainer:{'loss': 3.3629529592990877, 'learning_rate': 4.659747304664335e-05, 'epoch': 0.2041516172013992, 'step': 1133500}
INFO:transformers.trainer:{'loss': 3.3522236196994784, 'learning_rate': 4.659597215253071e-05, 'epoch': 0.20424167084815767, 'step': 1134000}
INFO:transformers.trainer:{'loss': 3.2774095647335053, 'learning_rate': 4.6594471258418066e-05, 'epoch': 0.2043317244949161, 'step': 1134500}
INFO:transformers.trainer:{'loss': 3.3767004845142363, 'learning_rate': 4.6592970364305425e-05, 'epoch': 0.20442177814167456, 'step': 1135000}
INFO:transformers.trainer:{'loss': 3.310718197107315, 'learning_rate': 4.6591469470192784e-05, 'epoch': 0.20451183178843302, 'step': 1135500}
INFO:transformers.trainer:{'loss': 3.3559532277584077, 'learning_rate': 4.6589968576080144e-05, 'epoch': 0.20460188543519145, 'step': 1136000}
INFO:transformers.trainer:{'loss': 3.3732314703464508, 'learning_rate': 4.65884676819675e-05, 'epoch': 0.2046919390819499, 'step': 1136500}
INFO:transformers.trainer:{'loss': 3.3170995502471925, 'learning_rate': 4.658696678785486e-05, 'epoch': 0.20478199272870834, 'step': 1137000}
INFO:transformers.trainer:{'loss': 3.3072245960235596, 'learning_rate': 4.658546589374223e-05, 'epoch': 0.2048720463754668, 'step': 1137500}
INFO:transformers.trainer:{'loss': 3.32706653046608, 'learning_rate': 4.658396499962958e-05, 'epoch': 0.20496210002222523, 'step': 1138000}
INFO:transformers.trainer:{'loss': 3.313135540485382, 'learning_rate': 4.6582464105516946e-05, 'epoch': 0.2050521536689837, 'step': 1138500}
INFO:transformers.trainer:{'loss': 3.2923516116142273, 'learning_rate': 4.65809632114043e-05, 'epoch': 0.20514220731574215, 'step': 1139000}
INFO:transformers.trainer:{'loss': 3.2902053322792053, 'learning_rate': 4.6579462317291664e-05, 'epoch': 0.20523226096250058, 'step': 1139500}
INFO:transformers.trainer:{'loss': 3.310555095434189, 'learning_rate': 4.6577961423179016e-05, 'epoch': 0.20532231460925904, 'step': 1140000}
INFO:transformers.trainer:{'loss': 3.2755465557575225, 'learning_rate': 4.657646052906638e-05, 'epoch': 0.20541236825601747, 'step': 1140500}
INFO:transformers.trainer:{'loss': 3.3156891198158265, 'learning_rate': 4.6574959634953734e-05, 'epoch': 0.20550242190277593, 'step': 1141000}
INFO:transformers.trainer:{'loss': 3.3809345350265505, 'learning_rate': 4.65734587408411e-05, 'epoch': 0.20559247554953436, 'step': 1141500}
INFO:transformers.trainer:{'loss': 3.35138471865654, 'learning_rate': 4.657195784672845e-05, 'epoch': 0.20568252919629282, 'step': 1142000}
INFO:transformers.trainer:{'loss': 3.3220209715366362, 'learning_rate': 4.657045695261582e-05, 'epoch': 0.20577258284305125, 'step': 1142500}
INFO:transformers.trainer:{'loss': 3.317763111591339, 'learning_rate': 4.656895605850317e-05, 'epoch': 0.2058626364898097, 'step': 1143000}
INFO:transformers.trainer:{'loss': 3.345960968494415, 'learning_rate': 4.6567455164390536e-05, 'epoch': 0.20595269013656817, 'step': 1143500}
INFO:transformers.trainer:{'loss': 3.318154528141022, 'learning_rate': 4.656595427027789e-05, 'epoch': 0.2060427437833266, 'step': 1144000}
INFO:transformers.trainer:{'loss': 3.3708063797950745, 'learning_rate': 4.6564453376165254e-05, 'epoch': 0.20613279743008506, 'step': 1144500}
INFO:transformers.trainer:{'loss': 3.3721944164037705, 'learning_rate': 4.656295248205261e-05, 'epoch': 0.2062228510768435, 'step': 1145000}
INFO:transformers.trainer:{'loss': 3.3688242532014847, 'learning_rate': 4.656145158793997e-05, 'epoch': 0.20631290472360195, 'step': 1145500}
INFO:transformers.trainer:{'loss': 3.364157514333725, 'learning_rate': 4.655995069382733e-05, 'epoch': 0.20640295837036038, 'step': 1146000}
INFO:transformers.trainer:{'loss': 3.2908192846775055, 'learning_rate': 4.655844979971469e-05, 'epoch': 0.20649301201711884, 'step': 1146500}
INFO:transformers.trainer:{'loss': 3.3090688259601593, 'learning_rate': 4.655694890560205e-05, 'epoch': 0.2065830656638773, 'step': 1147000}
INFO:transformers.trainer:{'loss': 3.3633896722793577, 'learning_rate': 4.655544801148941e-05, 'epoch': 0.20667311931063573, 'step': 1147500}
INFO:transformers.trainer:{'loss': 3.2891055772304534, 'learning_rate': 4.655394711737677e-05, 'epoch': 0.2067631729573942, 'step': 1148000}
INFO:transformers.trainer:{'loss': 3.32018453335762, 'learning_rate': 4.6552446223264127e-05, 'epoch': 0.20685322660415262, 'step': 1148500}
INFO:transformers.trainer:{'loss': 3.325082124710083, 'learning_rate': 4.6550945329151486e-05, 'epoch': 0.20694328025091108, 'step': 1149000}
INFO:transformers.trainer:{'loss': 3.2734538962841033, 'learning_rate': 4.6549444435038845e-05, 'epoch': 0.2070333338976695, 'step': 1149500}
INFO:transformers.trainer:{'loss': 3.3130106567144395, 'learning_rate': 4.6547943540926204e-05, 'epoch': 0.20712338754442797, 'step': 1150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1050000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.312548450946808, 'learning_rate': 4.654644264681356e-05, 'epoch': 0.20721344119118643, 'step': 1150500}
INFO:transformers.trainer:{'loss': 3.3705254361629486, 'learning_rate': 4.654494175270092e-05, 'epoch': 0.20730349483794486, 'step': 1151000}
INFO:transformers.trainer:{'loss': 3.2632242701053618, 'learning_rate': 4.654344085858828e-05, 'epoch': 0.20739354848470332, 'step': 1151500}
INFO:transformers.trainer:{'loss': 3.324400093793869, 'learning_rate': 4.654193996447564e-05, 'epoch': 0.20748360213146175, 'step': 1152000}
INFO:transformers.trainer:{'loss': 3.3522371637821196, 'learning_rate': 4.6540439070363e-05, 'epoch': 0.2075736557782202, 'step': 1152500}
INFO:transformers.trainer:{'loss': 3.252590029001236, 'learning_rate': 4.653893817625036e-05, 'epoch': 0.20766370942497864, 'step': 1153000}
INFO:transformers.trainer:{'loss': 3.2999391255378723, 'learning_rate': 4.653743728213772e-05, 'epoch': 0.2077537630717371, 'step': 1153500}
INFO:transformers.trainer:{'loss': 3.3085574839115144, 'learning_rate': 4.6535936388025076e-05, 'epoch': 0.20784381671849556, 'step': 1154000}
INFO:transformers.trainer:{'loss': 3.3063174834251403, 'learning_rate': 4.6534435493912435e-05, 'epoch': 0.207933870365254, 'step': 1154500}
INFO:transformers.trainer:{'loss': 3.339355000972748, 'learning_rate': 4.6532934599799794e-05, 'epoch': 0.20802392401201245, 'step': 1155000}
INFO:transformers.trainer:{'loss': 3.3234222674369813, 'learning_rate': 4.653143370568715e-05, 'epoch': 0.20811397765877088, 'step': 1155500}
INFO:transformers.trainer:{'loss': 3.370741360902786, 'learning_rate': 4.652993281157451e-05, 'epoch': 0.20820403130552934, 'step': 1156000}
INFO:transformers.trainer:{'loss': 3.262339673280716, 'learning_rate': 4.652843191746187e-05, 'epoch': 0.20829408495228777, 'step': 1156500}
INFO:transformers.trainer:{'loss': 3.297717072725296, 'learning_rate': 4.652693102334923e-05, 'epoch': 0.20838413859904623, 'step': 1157000}
INFO:transformers.trainer:{'loss': 3.3336166567802428, 'learning_rate': 4.652543012923659e-05, 'epoch': 0.20847419224580466, 'step': 1157500}
INFO:transformers.trainer:{'loss': 3.3289756996631623, 'learning_rate': 4.652392923512395e-05, 'epoch': 0.20856424589256312, 'step': 1158000}
INFO:transformers.trainer:{'loss': 3.3709039549827575, 'learning_rate': 4.652242834101131e-05, 'epoch': 0.20865429953932157, 'step': 1158500}
INFO:transformers.trainer:{'loss': 3.2923002078533172, 'learning_rate': 4.6520927446898673e-05, 'epoch': 0.20874435318608, 'step': 1159000}
INFO:transformers.trainer:{'loss': 3.283572370290756, 'learning_rate': 4.6519426552786026e-05, 'epoch': 0.20883440683283847, 'step': 1159500}
INFO:transformers.trainer:{'loss': 3.352948909521103, 'learning_rate': 4.651792565867339e-05, 'epoch': 0.2089244604795969, 'step': 1160000}
INFO:transformers.trainer:{'loss': 3.307474054813385, 'learning_rate': 4.6516424764560744e-05, 'epoch': 0.20901451412635536, 'step': 1160500}
INFO:transformers.trainer:{'loss': 3.306199951887131, 'learning_rate': 4.651492387044811e-05, 'epoch': 0.2091045677731138, 'step': 1161000}
INFO:transformers.trainer:{'loss': 3.3127473073005675, 'learning_rate': 4.651342297633546e-05, 'epoch': 0.20919462141987225, 'step': 1161500}
INFO:transformers.trainer:{'loss': 3.2798903493881224, 'learning_rate': 4.651192208222283e-05, 'epoch': 0.2092846750666307, 'step': 1162000}
INFO:transformers.trainer:{'loss': 3.3345965433120726, 'learning_rate': 4.651042118811018e-05, 'epoch': 0.20937472871338914, 'step': 1162500}
INFO:transformers.trainer:{'loss': 3.3074536724090575, 'learning_rate': 4.6508920293997546e-05, 'epoch': 0.2094647823601476, 'step': 1163000}
INFO:transformers.trainer:{'loss': 3.3346863942146303, 'learning_rate': 4.65074193998849e-05, 'epoch': 0.20955483600690603, 'step': 1163500}
INFO:transformers.trainer:{'loss': 3.2583179228305816, 'learning_rate': 4.6505918505772264e-05, 'epoch': 0.20964488965366448, 'step': 1164000}
INFO:transformers.trainer:{'loss': 3.27139776468277, 'learning_rate': 4.6504417611659616e-05, 'epoch': 0.20973494330042292, 'step': 1164500}
INFO:transformers.trainer:{'loss': 3.3172849538326266, 'learning_rate': 4.650291671754698e-05, 'epoch': 0.20982499694718137, 'step': 1165000}
INFO:transformers.trainer:{'loss': 3.3428663041591644, 'learning_rate': 4.650141582343434e-05, 'epoch': 0.20991505059393983, 'step': 1165500}
INFO:transformers.trainer:{'loss': 3.335327451944351, 'learning_rate': 4.64999149293217e-05, 'epoch': 0.21000510424069826, 'step': 1166000}
INFO:transformers.trainer:{'loss': 3.32263367664814, 'learning_rate': 4.649841403520906e-05, 'epoch': 0.21009515788745672, 'step': 1166500}
INFO:transformers.trainer:{'loss': 3.3261689229011537, 'learning_rate': 4.649691314109642e-05, 'epoch': 0.21018521153421516, 'step': 1167000}
INFO:transformers.trainer:{'loss': 3.297486951589584, 'learning_rate': 4.649541224698378e-05, 'epoch': 0.21027526518097361, 'step': 1167500}
INFO:transformers.trainer:{'loss': 3.369596012353897, 'learning_rate': 4.6493911352871136e-05, 'epoch': 0.21036531882773205, 'step': 1168000}
INFO:transformers.trainer:{'loss': 3.4031402728557585, 'learning_rate': 4.6492410458758495e-05, 'epoch': 0.2104553724744905, 'step': 1168500}
INFO:transformers.trainer:{'loss': 3.3455171236991883, 'learning_rate': 4.6490909564645854e-05, 'epoch': 0.21054542612124896, 'step': 1169000}
INFO:transformers.trainer:{'loss': 3.2814460307359696, 'learning_rate': 4.6489408670533213e-05, 'epoch': 0.2106354797680074, 'step': 1169500}
INFO:transformers.trainer:{'loss': 3.3257399365901947, 'learning_rate': 4.648790777642057e-05, 'epoch': 0.21072553341476585, 'step': 1170000}
INFO:transformers.trainer:{'loss': 3.309666801214218, 'learning_rate': 4.648640688230793e-05, 'epoch': 0.21081558706152428, 'step': 1170500}
INFO:transformers.trainer:{'loss': 3.3198243683576583, 'learning_rate': 4.648490598819529e-05, 'epoch': 0.21090564070828274, 'step': 1171000}
INFO:transformers.trainer:{'loss': 3.2970563025474546, 'learning_rate': 4.648340509408265e-05, 'epoch': 0.21099569435504117, 'step': 1171500}
INFO:transformers.trainer:{'loss': 3.324925096988678, 'learning_rate': 4.648190419997001e-05, 'epoch': 0.21108574800179963, 'step': 1172000}
INFO:transformers.trainer:{'loss': 3.356828151226044, 'learning_rate': 4.648040330585737e-05, 'epoch': 0.2111758016485581, 'step': 1172500}
INFO:transformers.trainer:{'loss': 3.3312962079048156, 'learning_rate': 4.647890241174473e-05, 'epoch': 0.21126585529531652, 'step': 1173000}
INFO:transformers.trainer:{'loss': 3.2982382831573487, 'learning_rate': 4.6477401517632086e-05, 'epoch': 0.21135590894207498, 'step': 1173500}
INFO:transformers.trainer:{'loss': 3.333989510059357, 'learning_rate': 4.6475900623519445e-05, 'epoch': 0.2114459625888334, 'step': 1174000}
INFO:transformers.trainer:{'loss': 3.3500074973106386, 'learning_rate': 4.6474399729406804e-05, 'epoch': 0.21153601623559187, 'step': 1174500}
INFO:transformers.trainer:{'loss': 3.337070767879486, 'learning_rate': 4.647289883529416e-05, 'epoch': 0.2116260698823503, 'step': 1175000}
INFO:transformers.trainer:{'loss': 3.3219566323757173, 'learning_rate': 4.647139794118152e-05, 'epoch': 0.21171612352910876, 'step': 1175500}
INFO:transformers.trainer:{'loss': 3.3710373876094817, 'learning_rate': 4.646989704706888e-05, 'epoch': 0.2118061771758672, 'step': 1176000}
INFO:transformers.trainer:{'loss': 3.294334641456604, 'learning_rate': 4.646839615295624e-05, 'epoch': 0.21189623082262565, 'step': 1176500}
INFO:transformers.trainer:{'loss': 3.2864905021190642, 'learning_rate': 4.64668952588436e-05, 'epoch': 0.2119862844693841, 'step': 1177000}
INFO:transformers.trainer:{'loss': 3.331342427492142, 'learning_rate': 4.646539436473096e-05, 'epoch': 0.21207633811614254, 'step': 1177500}
INFO:transformers.trainer:{'loss': 3.2933625555038453, 'learning_rate': 4.646389347061832e-05, 'epoch': 0.212166391762901, 'step': 1178000}
INFO:transformers.trainer:{'loss': 3.3358707530498504, 'learning_rate': 4.6462392576505676e-05, 'epoch': 0.21225644540965943, 'step': 1178500}
INFO:transformers.trainer:{'loss': 3.261964726924896, 'learning_rate': 4.6460891682393035e-05, 'epoch': 0.2123464990564179, 'step': 1179000}
INFO:transformers.trainer:{'loss': 3.335349188685417, 'learning_rate': 4.64593907882804e-05, 'epoch': 0.21243655270317632, 'step': 1179500}
INFO:transformers.trainer:{'loss': 3.309515419244766, 'learning_rate': 4.6457889894167754e-05, 'epoch': 0.21252660634993478, 'step': 1180000}
INFO:transformers.trainer:{'loss': 3.398798293828964, 'learning_rate': 4.645638900005512e-05, 'epoch': 0.21261665999669324, 'step': 1180500}
INFO:transformers.trainer:{'loss': 3.3131181082725525, 'learning_rate': 4.645488810594247e-05, 'epoch': 0.21270671364345167, 'step': 1181000}
INFO:transformers.trainer:{'loss': 3.3683106219768524, 'learning_rate': 4.645338721182984e-05, 'epoch': 0.21279676729021013, 'step': 1181500}
INFO:transformers.trainer:{'loss': 3.3289164407253264, 'learning_rate': 4.645188631771719e-05, 'epoch': 0.21288682093696856, 'step': 1182000}
INFO:transformers.trainer:{'loss': 3.3481176989078523, 'learning_rate': 4.6450385423604556e-05, 'epoch': 0.21297687458372702, 'step': 1182500}
INFO:transformers.trainer:{'loss': 3.355282599210739, 'learning_rate': 4.644888452949191e-05, 'epoch': 0.21306692823048545, 'step': 1183000}
INFO:transformers.trainer:{'loss': 3.2819190537929535, 'learning_rate': 4.6447383635379274e-05, 'epoch': 0.2131569818772439, 'step': 1183500}
INFO:transformers.trainer:{'loss': 3.2961768667697906, 'learning_rate': 4.6445882741266626e-05, 'epoch': 0.21324703552400237, 'step': 1184000}
INFO:transformers.trainer:{'loss': 3.328951051235199, 'learning_rate': 4.644438184715399e-05, 'epoch': 0.2133370891707608, 'step': 1184500}
INFO:transformers.trainer:{'loss': 3.399719170808792, 'learning_rate': 4.6442880953041344e-05, 'epoch': 0.21342714281751926, 'step': 1185000}
INFO:transformers.trainer:{'loss': 3.321675750732422, 'learning_rate': 4.644138005892871e-05, 'epoch': 0.2135171964642777, 'step': 1185500}
INFO:transformers.trainer:{'loss': 3.2796999769210817, 'learning_rate': 4.643987916481607e-05, 'epoch': 0.21360725011103615, 'step': 1186000}
INFO:transformers.trainer:{'loss': 3.3637614966630935, 'learning_rate': 4.643837827070343e-05, 'epoch': 0.21369730375779458, 'step': 1186500}
INFO:transformers.trainer:{'loss': 3.3268700870275496, 'learning_rate': 4.643687737659079e-05, 'epoch': 0.21378735740455304, 'step': 1187000}
INFO:transformers.trainer:{'loss': 3.2843538994789125, 'learning_rate': 4.6435376482478146e-05, 'epoch': 0.2138774110513115, 'step': 1187500}
INFO:transformers.trainer:{'loss': 3.3462932698726653, 'learning_rate': 4.6433875588365505e-05, 'epoch': 0.21396746469806993, 'step': 1188000}
INFO:transformers.trainer:{'loss': 3.3255339663028716, 'learning_rate': 4.6432374694252864e-05, 'epoch': 0.2140575183448284, 'step': 1188500}
INFO:transformers.trainer:{'loss': 3.304239761352539, 'learning_rate': 4.643087380014022e-05, 'epoch': 0.21414757199158682, 'step': 1189000}
INFO:transformers.trainer:{'loss': 3.374900335788727, 'learning_rate': 4.642937290602758e-05, 'epoch': 0.21423762563834528, 'step': 1189500}
INFO:transformers.trainer:{'loss': 3.2824856060743333, 'learning_rate': 4.642787201191494e-05, 'epoch': 0.2143276792851037, 'step': 1190000}
INFO:transformers.trainer:{'loss': 3.3162952456474306, 'learning_rate': 4.64263711178023e-05, 'epoch': 0.21441773293186217, 'step': 1190500}
INFO:transformers.trainer:{'loss': 3.286135575056076, 'learning_rate': 4.642487022368966e-05, 'epoch': 0.21450778657862063, 'step': 1191000}
INFO:transformers.trainer:{'loss': 3.3612027752399443, 'learning_rate': 4.642336932957702e-05, 'epoch': 0.21459784022537906, 'step': 1191500}
INFO:transformers.trainer:{'loss': 3.3613729947805404, 'learning_rate': 4.642186843546438e-05, 'epoch': 0.21468789387213752, 'step': 1192000}
INFO:transformers.trainer:{'loss': 3.766202915906906, 'learning_rate': 4.6420367541351737e-05, 'epoch': 0.21477794751889595, 'step': 1192500}
INFO:transformers.trainer:{'loss': 3.4911794776916505, 'learning_rate': 4.6418866647239096e-05, 'epoch': 0.2148680011656544, 'step': 1193000}
INFO:transformers.trainer:{'loss': 3.330579125881195, 'learning_rate': 4.6417365753126455e-05, 'epoch': 0.21495805481241284, 'step': 1193500}
INFO:transformers.trainer:{'loss': 3.3301951622962953, 'learning_rate': 4.6415864859013814e-05, 'epoch': 0.2150481084591713, 'step': 1194000}
INFO:transformers.trainer:{'loss': 3.2921074612140657, 'learning_rate': 4.641436396490117e-05, 'epoch': 0.21513816210592973, 'step': 1194500}
INFO:transformers.trainer:{'loss': 3.3139351887702944, 'learning_rate': 4.641286307078853e-05, 'epoch': 0.2152282157526882, 'step': 1195000}
INFO:transformers.trainer:{'loss': 3.3004114856719973, 'learning_rate': 4.641136217667589e-05, 'epoch': 0.21531826939944665, 'step': 1195500}
INFO:transformers.trainer:{'loss': 3.3575916469097136, 'learning_rate': 4.640986128256325e-05, 'epoch': 0.21540832304620508, 'step': 1196000}
INFO:transformers.trainer:{'loss': 3.2963717029094695, 'learning_rate': 4.640836038845061e-05, 'epoch': 0.21549837669296354, 'step': 1196500}
INFO:transformers.trainer:{'loss': 3.4167558951377868, 'learning_rate': 4.640685949433797e-05, 'epoch': 0.21558843033972197, 'step': 1197000}
INFO:transformers.trainer:{'loss': 3.2989002442359925, 'learning_rate': 4.640535860022533e-05, 'epoch': 0.21567848398648043, 'step': 1197500}
INFO:transformers.trainer:{'loss': 3.342690174102783, 'learning_rate': 4.6403857706112686e-05, 'epoch': 0.21576853763323886, 'step': 1198000}
INFO:transformers.trainer:{'loss': 3.3332835409641266, 'learning_rate': 4.6402356812000045e-05, 'epoch': 0.21585859127999732, 'step': 1198500}
INFO:transformers.trainer:{'loss': 3.3791870305538176, 'learning_rate': 4.6400855917887404e-05, 'epoch': 0.21594864492675578, 'step': 1199000}
INFO:transformers.trainer:{'loss': 3.3389618904590606, 'learning_rate': 4.639935502377476e-05, 'epoch': 0.2160386985735142, 'step': 1199500}
INFO:transformers.trainer:{'loss': 3.335102274656296, 'learning_rate': 4.639785412966213e-05, 'epoch': 0.21612875222027267, 'step': 1200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.340360534906387, 'learning_rate': 4.639635323554948e-05, 'epoch': 0.2162188058670311, 'step': 1200500}
INFO:transformers.trainer:{'loss': 3.362924823760986, 'learning_rate': 4.639485234143685e-05, 'epoch': 0.21630885951378956, 'step': 1201000}
INFO:transformers.trainer:{'loss': 3.3041196404099464, 'learning_rate': 4.63933514473242e-05, 'epoch': 0.216398913160548, 'step': 1201500}
INFO:transformers.trainer:{'loss': 3.3966588249206544, 'learning_rate': 4.6391850553211565e-05, 'epoch': 0.21648896680730645, 'step': 1202000}
INFO:transformers.trainer:{'loss': 3.3803488714694976, 'learning_rate': 4.639034965909892e-05, 'epoch': 0.2165790204540649, 'step': 1202500}
INFO:transformers.trainer:{'loss': 3.3706398471593855, 'learning_rate': 4.638884876498628e-05, 'epoch': 0.21666907410082334, 'step': 1203000}
INFO:transformers.trainer:{'loss': 3.3797313969135283, 'learning_rate': 4.6387347870873636e-05, 'epoch': 0.2167591277475818, 'step': 1203500}
INFO:transformers.trainer:{'loss': 3.3391815330982206, 'learning_rate': 4.6385846976761e-05, 'epoch': 0.21684918139434023, 'step': 1204000}
INFO:transformers.trainer:{'loss': 3.315762749671936, 'learning_rate': 4.6384346082648354e-05, 'epoch': 0.2169392350410987, 'step': 1204500}
INFO:transformers.trainer:{'loss': 3.3339023036956785, 'learning_rate': 4.638284518853572e-05, 'epoch': 0.21702928868785712, 'step': 1205000}
INFO:transformers.trainer:{'loss': 3.386225141763687, 'learning_rate': 4.638134429442307e-05, 'epoch': 0.21711934233461558, 'step': 1205500}
INFO:transformers.trainer:{'loss': 3.456950142621994, 'learning_rate': 4.637984340031044e-05, 'epoch': 0.21720939598137404, 'step': 1206000}
INFO:transformers.trainer:{'loss': 3.319558053970337, 'learning_rate': 4.637834250619779e-05, 'epoch': 0.21729944962813247, 'step': 1206500}
INFO:transformers.trainer:{'loss': 3.341804736614227, 'learning_rate': 4.6376841612085156e-05, 'epoch': 0.21738950327489093, 'step': 1207000}
INFO:transformers.trainer:{'loss': 3.3863075740337374, 'learning_rate': 4.6375340717972515e-05, 'epoch': 0.21747955692164936, 'step': 1207500}
INFO:transformers.trainer:{'loss': 3.251929806470871, 'learning_rate': 4.6373839823859874e-05, 'epoch': 0.21756961056840782, 'step': 1208000}
INFO:transformers.trainer:{'loss': 3.3279615213871003, 'learning_rate': 4.637233892974723e-05, 'epoch': 0.21765966421516625, 'step': 1208500}
INFO:transformers.trainer:{'loss': 3.3326661961078643, 'learning_rate': 4.637083803563459e-05, 'epoch': 0.2177497178619247, 'step': 1209000}
INFO:transformers.trainer:{'loss': 3.287648765563965, 'learning_rate': 4.636933714152195e-05, 'epoch': 0.21783977150868317, 'step': 1209500}
INFO:transformers.trainer:{'loss': 3.359012987375259, 'learning_rate': 4.636783624740931e-05, 'epoch': 0.2179298251554416, 'step': 1210000}
INFO:transformers.trainer:{'loss': 3.308031835794449, 'learning_rate': 4.636633535329667e-05, 'epoch': 0.21801987880220006, 'step': 1210500}
INFO:transformers.trainer:{'loss': 3.3067855665683745, 'learning_rate': 4.636483445918403e-05, 'epoch': 0.2181099324489585, 'step': 1211000}
INFO:transformers.trainer:{'loss': 3.2766167612075807, 'learning_rate': 4.636333356507139e-05, 'epoch': 0.21819998609571695, 'step': 1211500}
INFO:transformers.trainer:{'loss': 3.3564638090133667, 'learning_rate': 4.6361832670958746e-05, 'epoch': 0.21829003974247538, 'step': 1212000}
INFO:transformers.trainer:{'loss': 3.301528472185135, 'learning_rate': 4.6360331776846105e-05, 'epoch': 0.21838009338923384, 'step': 1212500}
INFO:transformers.trainer:{'loss': 3.2632007374763488, 'learning_rate': 4.6358830882733464e-05, 'epoch': 0.21847014703599227, 'step': 1213000}
INFO:transformers.trainer:{'loss': 3.337247471809387, 'learning_rate': 4.6357329988620823e-05, 'epoch': 0.21856020068275073, 'step': 1213500}
INFO:transformers.trainer:{'loss': 3.3048912041187286, 'learning_rate': 4.635582909450818e-05, 'epoch': 0.21865025432950919, 'step': 1214000}
INFO:transformers.trainer:{'loss': 3.262132021069527, 'learning_rate': 4.635432820039554e-05, 'epoch': 0.21874030797626762, 'step': 1214500}
INFO:transformers.trainer:{'loss': 3.306588553905487, 'learning_rate': 4.63528273062829e-05, 'epoch': 0.21883036162302608, 'step': 1215000}
INFO:transformers.trainer:{'loss': 3.343841386556625, 'learning_rate': 4.635132641217026e-05, 'epoch': 0.2189204152697845, 'step': 1215500}
INFO:transformers.trainer:{'loss': 3.329254514813423, 'learning_rate': 4.634982551805762e-05, 'epoch': 0.21901046891654297, 'step': 1216000}
INFO:transformers.trainer:{'loss': 3.3212726657390594, 'learning_rate': 4.634832462394498e-05, 'epoch': 0.2191005225633014, 'step': 1216500}
INFO:transformers.trainer:{'loss': 3.3276247866153716, 'learning_rate': 4.634682372983234e-05, 'epoch': 0.21919057621005986, 'step': 1217000}
INFO:transformers.trainer:{'loss': 3.3541052005290983, 'learning_rate': 4.6345322835719696e-05, 'epoch': 0.21928062985681832, 'step': 1217500}
INFO:transformers.trainer:{'loss': 3.3148086535930634, 'learning_rate': 4.6343821941607055e-05, 'epoch': 0.21937068350357675, 'step': 1218000}
INFO:transformers.trainer:{'loss': 3.301957545042038, 'learning_rate': 4.6342321047494414e-05, 'epoch': 0.2194607371503352, 'step': 1218500}
INFO:transformers.trainer:{'loss': 3.305969617128372, 'learning_rate': 4.634082015338177e-05, 'epoch': 0.21955079079709364, 'step': 1219000}
INFO:transformers.trainer:{'loss': 3.3249859476089476, 'learning_rate': 4.633931925926913e-05, 'epoch': 0.2196408444438521, 'step': 1219500}
INFO:transformers.trainer:{'loss': 3.379128778934479, 'learning_rate': 4.633781836515649e-05, 'epoch': 0.21973089809061053, 'step': 1220000}
INFO:transformers.trainer:{'loss': 3.3394126167297364, 'learning_rate': 4.633631747104386e-05, 'epoch': 0.21982095173736899, 'step': 1220500}
INFO:transformers.trainer:{'loss': 3.320263300657272, 'learning_rate': 4.633481657693121e-05, 'epoch': 0.21991100538412744, 'step': 1221000}
INFO:transformers.trainer:{'loss': 3.383997931957245, 'learning_rate': 4.6333315682818575e-05, 'epoch': 0.22000105903088588, 'step': 1221500}
INFO:transformers.trainer:{'loss': 3.354806849718094, 'learning_rate': 4.633181478870593e-05, 'epoch': 0.22009111267764433, 'step': 1222000}
INFO:transformers.trainer:{'loss': 3.3313685688972474, 'learning_rate': 4.633031389459329e-05, 'epoch': 0.22018116632440277, 'step': 1222500}
INFO:transformers.trainer:{'loss': 3.3359481229782104, 'learning_rate': 4.6328813000480645e-05, 'epoch': 0.22027121997116123, 'step': 1223000}
INFO:transformers.trainer:{'loss': 3.3083158226013185, 'learning_rate': 4.632731210636801e-05, 'epoch': 0.22036127361791966, 'step': 1223500}
INFO:transformers.trainer:{'loss': 3.2686970603466032, 'learning_rate': 4.6325811212255363e-05, 'epoch': 0.22045132726467812, 'step': 1224000}
INFO:transformers.trainer:{'loss': 3.3561419615745542, 'learning_rate': 4.632431031814273e-05, 'epoch': 0.22054138091143657, 'step': 1224500}
INFO:transformers.trainer:{'loss': 3.3144307782649993, 'learning_rate': 4.632280942403008e-05, 'epoch': 0.220631434558195, 'step': 1225000}
INFO:transformers.trainer:{'loss': 3.335752956390381, 'learning_rate': 4.632130852991745e-05, 'epoch': 0.22072148820495346, 'step': 1225500}
INFO:transformers.trainer:{'loss': 3.3713947455883027, 'learning_rate': 4.63198076358048e-05, 'epoch': 0.2208115418517119, 'step': 1226000}
INFO:transformers.trainer:{'loss': 3.3292374794483184, 'learning_rate': 4.6318306741692165e-05, 'epoch': 0.22090159549847035, 'step': 1226500}
INFO:transformers.trainer:{'loss': 3.3217995352745056, 'learning_rate': 4.631680584757952e-05, 'epoch': 0.22099164914522879, 'step': 1227000}
INFO:transformers.trainer:{'loss': 3.3605684940814973, 'learning_rate': 4.6315304953466884e-05, 'epoch': 0.22108170279198724, 'step': 1227500}
INFO:transformers.trainer:{'loss': 3.3376810863018034, 'learning_rate': 4.631380405935424e-05, 'epoch': 0.22117175643874568, 'step': 1228000}
INFO:transformers.trainer:{'loss': 3.2890171954631806, 'learning_rate': 4.63123031652416e-05, 'epoch': 0.22126181008550413, 'step': 1228500}
INFO:transformers.trainer:{'loss': 3.3675197253227234, 'learning_rate': 4.631080227112896e-05, 'epoch': 0.2213518637322626, 'step': 1229000}
INFO:transformers.trainer:{'loss': 3.33147070145607, 'learning_rate': 4.630930137701632e-05, 'epoch': 0.22144191737902102, 'step': 1229500}
INFO:transformers.trainer:{'loss': 3.327505987405777, 'learning_rate': 4.630780048290368e-05, 'epoch': 0.22153197102577948, 'step': 1230000}
INFO:transformers.trainer:{'loss': 3.3147201116085054, 'learning_rate': 4.630629958879104e-05, 'epoch': 0.22162202467253792, 'step': 1230500}
INFO:transformers.trainer:{'loss': 3.3605178027153015, 'learning_rate': 4.63047986946784e-05, 'epoch': 0.22171207831929637, 'step': 1231000}
INFO:transformers.trainer:{'loss': 3.431554407119751, 'learning_rate': 4.6303297800565756e-05, 'epoch': 0.2218021319660548, 'step': 1231500}
INFO:transformers.trainer:{'loss': 3.344746157646179, 'learning_rate': 4.6301796906453115e-05, 'epoch': 0.22189218561281326, 'step': 1232000}
INFO:transformers.trainer:{'loss': 3.3478558695316316, 'learning_rate': 4.6300296012340474e-05, 'epoch': 0.22198223925957172, 'step': 1232500}
INFO:transformers.trainer:{'loss': 3.28113769698143, 'learning_rate': 4.629879511822783e-05, 'epoch': 0.22207229290633015, 'step': 1233000}
INFO:transformers.trainer:{'loss': 3.3231258878707886, 'learning_rate': 4.629729422411519e-05, 'epoch': 0.2221623465530886, 'step': 1233500}
INFO:transformers.trainer:{'loss': 3.3456506185531616, 'learning_rate': 4.629579333000255e-05, 'epoch': 0.22225240019984704, 'step': 1234000}
INFO:transformers.trainer:{'loss': 3.3733075655698777, 'learning_rate': 4.629429243588991e-05, 'epoch': 0.2223424538466055, 'step': 1234500}
INFO:transformers.trainer:{'loss': 3.2587409284114837, 'learning_rate': 4.629279154177727e-05, 'epoch': 0.22243250749336393, 'step': 1235000}
INFO:transformers.trainer:{'loss': 3.318300577878952, 'learning_rate': 4.629129064766463e-05, 'epoch': 0.2225225611401224, 'step': 1235500}
INFO:transformers.trainer:{'loss': 3.383336619377136, 'learning_rate': 4.628978975355199e-05, 'epoch': 0.22261261478688085, 'step': 1236000}
INFO:transformers.trainer:{'loss': 3.3199127079248427, 'learning_rate': 4.6288288859439346e-05, 'epoch': 0.22270266843363928, 'step': 1236500}
INFO:transformers.trainer:{'loss': 3.4110085039138793, 'learning_rate': 4.6286787965326706e-05, 'epoch': 0.22279272208039774, 'step': 1237000}
INFO:transformers.trainer:{'loss': 3.3531429550647736, 'learning_rate': 4.6285287071214065e-05, 'epoch': 0.22288277572715617, 'step': 1237500}
INFO:transformers.trainer:{'loss': 3.3059615783691405, 'learning_rate': 4.6283786177101424e-05, 'epoch': 0.22297282937391463, 'step': 1238000}
INFO:transformers.trainer:{'loss': 3.3597909677028657, 'learning_rate': 4.628228528298878e-05, 'epoch': 0.22306288302067306, 'step': 1238500}
INFO:transformers.trainer:{'loss': 3.2731629931926727, 'learning_rate': 4.628078438887614e-05, 'epoch': 0.22315293666743152, 'step': 1239000}
INFO:transformers.trainer:{'loss': 3.318570878982544, 'learning_rate': 4.62792834947635e-05, 'epoch': 0.22324299031418998, 'step': 1239500}
INFO:transformers.trainer:{'loss': 3.2844171903133392, 'learning_rate': 4.627778260065086e-05, 'epoch': 0.2233330439609484, 'step': 1240000}
INFO:transformers.trainer:{'loss': 3.3403620071411133, 'learning_rate': 4.627628170653822e-05, 'epoch': 0.22342309760770687, 'step': 1240500}
INFO:transformers.trainer:{'loss': 3.332471286058426, 'learning_rate': 4.627478081242558e-05, 'epoch': 0.2235131512544653, 'step': 1241000}
INFO:transformers.trainer:{'loss': 3.337811388731003, 'learning_rate': 4.627327991831294e-05, 'epoch': 0.22360320490122376, 'step': 1241500}
INFO:transformers.trainer:{'loss': 3.278019832134247, 'learning_rate': 4.62717790242003e-05, 'epoch': 0.2236932585479822, 'step': 1242000}
INFO:transformers.trainer:{'loss': 3.3407955162525176, 'learning_rate': 4.6270278130087655e-05, 'epoch': 0.22378331219474065, 'step': 1242500}
INFO:transformers.trainer:{'loss': 3.385479476213455, 'learning_rate': 4.626877723597502e-05, 'epoch': 0.2238733658414991, 'step': 1243000}
INFO:transformers.trainer:{'loss': 3.274465436935425, 'learning_rate': 4.626727634186237e-05, 'epoch': 0.22396341948825754, 'step': 1243500}
INFO:transformers.trainer:{'loss': 3.398041792869568, 'learning_rate': 4.626577544774974e-05, 'epoch': 0.224053473135016, 'step': 1244000}
INFO:transformers.trainer:{'loss': 3.333163540840149, 'learning_rate': 4.626427455363709e-05, 'epoch': 0.22414352678177443, 'step': 1244500}
INFO:transformers.trainer:{'loss': 3.279908776283264, 'learning_rate': 4.626277365952446e-05, 'epoch': 0.2242335804285329, 'step': 1245000}
INFO:transformers.trainer:{'loss': 3.315390980243683, 'learning_rate': 4.626127276541181e-05, 'epoch': 0.22432363407529132, 'step': 1245500}
INFO:transformers.trainer:{'loss': 3.3676479260921477, 'learning_rate': 4.6259771871299175e-05, 'epoch': 0.22441368772204978, 'step': 1246000}
INFO:transformers.trainer:{'loss': 3.3343630372285844, 'learning_rate': 4.625827097718653e-05, 'epoch': 0.2245037413688082, 'step': 1246500}
INFO:transformers.trainer:{'loss': 3.2799890222549437, 'learning_rate': 4.625677008307389e-05, 'epoch': 0.22459379501556667, 'step': 1247000}
INFO:transformers.trainer:{'loss': 3.331907266139984, 'learning_rate': 4.6255269188961246e-05, 'epoch': 0.22468384866232513, 'step': 1247500}
INFO:transformers.trainer:{'loss': 3.336763848781586, 'learning_rate': 4.625376829484861e-05, 'epoch': 0.22477390230908356, 'step': 1248000}
INFO:transformers.trainer:{'loss': 3.3546972341537478, 'learning_rate': 4.625226740073597e-05, 'epoch': 0.22486395595584202, 'step': 1248500}
INFO:transformers.trainer:{'loss': 3.257865446567535, 'learning_rate': 4.625076650662333e-05, 'epoch': 0.22495400960260045, 'step': 1249000}
INFO:transformers.trainer:{'loss': 3.347458339691162, 'learning_rate': 4.624926561251069e-05, 'epoch': 0.2250440632493589, 'step': 1249500}
INFO:transformers.trainer:{'loss': 3.3512019567489624, 'learning_rate': 4.624776471839805e-05, 'epoch': 0.22513411689611734, 'step': 1250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.363645086288452, 'learning_rate': 4.624626382428541e-05, 'epoch': 0.2252241705428758, 'step': 1250500}
INFO:transformers.trainer:{'loss': 3.361865737438202, 'learning_rate': 4.6244762930172766e-05, 'epoch': 0.22531422418963426, 'step': 1251000}
INFO:transformers.trainer:{'loss': 3.3601890358924864, 'learning_rate': 4.6243262036060125e-05, 'epoch': 0.2254042778363927, 'step': 1251500}
INFO:transformers.trainer:{'loss': 3.291286059141159, 'learning_rate': 4.6241761141947484e-05, 'epoch': 0.22549433148315115, 'step': 1252000}
INFO:transformers.trainer:{'loss': 3.39195157623291, 'learning_rate': 4.624026024783484e-05, 'epoch': 0.22558438512990958, 'step': 1252500}
INFO:transformers.trainer:{'loss': 3.3302814846038817, 'learning_rate': 4.62387593537222e-05, 'epoch': 0.22567443877666804, 'step': 1253000}
INFO:transformers.trainer:{'loss': 3.2934473366737365, 'learning_rate': 4.623725845960956e-05, 'epoch': 0.22576449242342647, 'step': 1253500}
INFO:transformers.trainer:{'loss': 3.3157096853256225, 'learning_rate': 4.623575756549692e-05, 'epoch': 0.22585454607018493, 'step': 1254000}
INFO:transformers.trainer:{'loss': 3.305759609937668, 'learning_rate': 4.623425667138428e-05, 'epoch': 0.2259445997169434, 'step': 1254500}
INFO:transformers.trainer:{'loss': 3.3594026148319243, 'learning_rate': 4.623275577727164e-05, 'epoch': 0.22603465336370182, 'step': 1255000}
INFO:transformers.trainer:{'loss': 3.3481432955265045, 'learning_rate': 4.6231254883159e-05, 'epoch': 0.22612470701046028, 'step': 1255500}
INFO:transformers.trainer:{'loss': 3.2948007638454437, 'learning_rate': 4.6229753989046356e-05, 'epoch': 0.2262147606572187, 'step': 1256000}
INFO:transformers.trainer:{'loss': 3.340627193927765, 'learning_rate': 4.6228253094933715e-05, 'epoch': 0.22630481430397717, 'step': 1256500}
INFO:transformers.trainer:{'loss': 3.286531414747238, 'learning_rate': 4.6226752200821074e-05, 'epoch': 0.2263948679507356, 'step': 1257000}
INFO:transformers.trainer:{'loss': 3.3496992847919462, 'learning_rate': 4.622525130670843e-05, 'epoch': 0.22648492159749406, 'step': 1257500}
INFO:transformers.trainer:{'loss': 3.33937451004982, 'learning_rate': 4.622375041259579e-05, 'epoch': 0.22657497524425252, 'step': 1258000}
INFO:transformers.trainer:{'loss': 3.283162134647369, 'learning_rate': 4.622224951848315e-05, 'epoch': 0.22666502889101095, 'step': 1258500}
INFO:transformers.trainer:{'loss': 3.3295830734968184, 'learning_rate': 4.622074862437051e-05, 'epoch': 0.2267550825377694, 'step': 1259000}
INFO:transformers.trainer:{'loss': 3.3014709105491638, 'learning_rate': 4.621924773025787e-05, 'epoch': 0.22684513618452784, 'step': 1259500}
INFO:transformers.trainer:{'loss': 3.367208395242691, 'learning_rate': 4.621774683614523e-05, 'epoch': 0.2269351898312863, 'step': 1260000}
INFO:transformers.trainer:{'loss': 3.32675897192955, 'learning_rate': 4.621624594203259e-05, 'epoch': 0.22702524347804473, 'step': 1260500}
INFO:transformers.trainer:{'loss': 3.372564884185791, 'learning_rate': 4.621474504791995e-05, 'epoch': 0.2271152971248032, 'step': 1261000}
INFO:transformers.trainer:{'loss': 3.304949011683464, 'learning_rate': 4.6213244153807306e-05, 'epoch': 0.22720535077156165, 'step': 1261500}
INFO:transformers.trainer:{'loss': 3.332514836549759, 'learning_rate': 4.6211743259694665e-05, 'epoch': 0.22729540441832008, 'step': 1262000}
INFO:transformers.trainer:{'loss': 3.3654742377996443, 'learning_rate': 4.621024236558203e-05, 'epoch': 0.22738545806507854, 'step': 1262500}
INFO:transformers.trainer:{'loss': 3.298148741722107, 'learning_rate': 4.620874147146938e-05, 'epoch': 0.22747551171183697, 'step': 1263000}
INFO:transformers.trainer:{'loss': 3.31935453248024, 'learning_rate': 4.620724057735675e-05, 'epoch': 0.22756556535859543, 'step': 1263500}
INFO:transformers.trainer:{'loss': 3.3521706845760346, 'learning_rate': 4.62057396832441e-05, 'epoch': 0.22765561900535386, 'step': 1264000}
INFO:transformers.trainer:{'loss': 3.2915990443229677, 'learning_rate': 4.620423878913147e-05, 'epoch': 0.22774567265211232, 'step': 1264500}
INFO:transformers.trainer:{'loss': 3.3090522425174713, 'learning_rate': 4.620273789501882e-05, 'epoch': 0.22783572629887075, 'step': 1265000}
INFO:transformers.trainer:{'loss': 3.316734570264816, 'learning_rate': 4.6201237000906185e-05, 'epoch': 0.2279257799456292, 'step': 1265500}
INFO:transformers.trainer:{'loss': 3.287560425937176, 'learning_rate': 4.619973610679354e-05, 'epoch': 0.22801583359238767, 'step': 1266000}
INFO:transformers.trainer:{'loss': 3.2928440766334535, 'learning_rate': 4.61982352126809e-05, 'epoch': 0.2281058872391461, 'step': 1266500}
INFO:transformers.trainer:{'loss': 3.362002097129822, 'learning_rate': 4.6196734318568255e-05, 'epoch': 0.22819594088590456, 'step': 1267000}
INFO:transformers.trainer:{'loss': 3.289762104511261, 'learning_rate': 4.619523342445562e-05, 'epoch': 0.228285994532663, 'step': 1267500}
INFO:transformers.trainer:{'loss': 3.386981724500656, 'learning_rate': 4.6193732530342973e-05, 'epoch': 0.22837604817942145, 'step': 1268000}
INFO:transformers.trainer:{'loss': 3.276281062602997, 'learning_rate': 4.619223163623034e-05, 'epoch': 0.22846610182617988, 'step': 1268500}
INFO:transformers.trainer:{'loss': 3.3659050970077513, 'learning_rate': 4.619073074211769e-05, 'epoch': 0.22855615547293834, 'step': 1269000}
INFO:transformers.trainer:{'loss': 3.324090006351471, 'learning_rate': 4.618922984800506e-05, 'epoch': 0.2286462091196968, 'step': 1269500}
INFO:transformers.trainer:{'loss': 3.3647791402339937, 'learning_rate': 4.6187728953892416e-05, 'epoch': 0.22873626276645523, 'step': 1270000}
INFO:transformers.trainer:{'loss': 3.336555522441864, 'learning_rate': 4.6186228059779775e-05, 'epoch': 0.2288263164132137, 'step': 1270500}
INFO:transformers.trainer:{'loss': 3.2886746743917463, 'learning_rate': 4.6184727165667134e-05, 'epoch': 0.22891637005997212, 'step': 1271000}
INFO:transformers.trainer:{'loss': 3.3804947361946107, 'learning_rate': 4.6183226271554494e-05, 'epoch': 0.22900642370673058, 'step': 1271500}
INFO:transformers.trainer:{'loss': 3.359413213610649, 'learning_rate': 4.618172537744185e-05, 'epoch': 0.229096477353489, 'step': 1272000}
INFO:transformers.trainer:{'loss': 3.396025491833687, 'learning_rate': 4.618022448332921e-05, 'epoch': 0.22918653100024747, 'step': 1272500}
INFO:transformers.trainer:{'loss': 3.3692483505010604, 'learning_rate': 4.617872358921657e-05, 'epoch': 0.22927658464700593, 'step': 1273000}
INFO:transformers.trainer:{'loss': 3.263583689689636, 'learning_rate': 4.617722269510393e-05, 'epoch': 0.22936663829376436, 'step': 1273500}
INFO:transformers.trainer:{'loss': 3.296927461862564, 'learning_rate': 4.617572180099129e-05, 'epoch': 0.22945669194052282, 'step': 1274000}
INFO:transformers.trainer:{'loss': 3.24967025578022, 'learning_rate': 4.617422090687865e-05, 'epoch': 0.22954674558728125, 'step': 1274500}
INFO:transformers.trainer:{'loss': 3.3208766148090363, 'learning_rate': 4.617272001276601e-05, 'epoch': 0.2296367992340397, 'step': 1275000}
INFO:transformers.trainer:{'loss': 3.3370524356365205, 'learning_rate': 4.6171219118653366e-05, 'epoch': 0.22972685288079814, 'step': 1275500}
INFO:transformers.trainer:{'loss': 3.3337228178977965, 'learning_rate': 4.6169718224540725e-05, 'epoch': 0.2298169065275566, 'step': 1276000}
INFO:transformers.trainer:{'loss': 3.2924608569145204, 'learning_rate': 4.6168217330428084e-05, 'epoch': 0.22990696017431506, 'step': 1276500}
INFO:transformers.trainer:{'loss': 3.25904408288002, 'learning_rate': 4.616671643631544e-05, 'epoch': 0.2299970138210735, 'step': 1277000}
INFO:transformers.trainer:{'loss': 3.3398131489753724, 'learning_rate': 4.61652155422028e-05, 'epoch': 0.23008706746783195, 'step': 1277500}
INFO:transformers.trainer:{'loss': 3.3169758551120756, 'learning_rate': 4.616371464809016e-05, 'epoch': 0.23017712111459038, 'step': 1278000}
INFO:transformers.trainer:{'loss': 3.2479275689125062, 'learning_rate': 4.616221375397752e-05, 'epoch': 0.23026717476134884, 'step': 1278500}
INFO:transformers.trainer:{'loss': 3.371007473707199, 'learning_rate': 4.616071285986488e-05, 'epoch': 0.23035722840810727, 'step': 1279000}
INFO:transformers.trainer:{'loss': 3.3132962086200712, 'learning_rate': 4.615921196575224e-05, 'epoch': 0.23044728205486573, 'step': 1279500}
INFO:transformers.trainer:{'loss': 3.3204847786426543, 'learning_rate': 4.61577110716396e-05, 'epoch': 0.23053733570162419, 'step': 1280000}
INFO:transformers.trainer:{'loss': 3.343651422023773, 'learning_rate': 4.6156210177526956e-05, 'epoch': 0.23062738934838262, 'step': 1280500}
INFO:transformers.trainer:{'loss': 3.3513101811409, 'learning_rate': 4.6154709283414315e-05, 'epoch': 0.23071744299514108, 'step': 1281000}
INFO:transformers.trainer:{'loss': 3.3619143233299256, 'learning_rate': 4.6153208389301675e-05, 'epoch': 0.2308074966418995, 'step': 1281500}
INFO:transformers.trainer:{'loss': 3.3099739956855774, 'learning_rate': 4.6151707495189034e-05, 'epoch': 0.23089755028865797, 'step': 1282000}
INFO:transformers.trainer:{'loss': 3.319012137174606, 'learning_rate': 4.615020660107639e-05, 'epoch': 0.2309876039354164, 'step': 1282500}
INFO:transformers.trainer:{'loss': 3.2719700412750243, 'learning_rate': 4.614870570696376e-05, 'epoch': 0.23107765758217486, 'step': 1283000}
INFO:transformers.trainer:{'loss': 3.355256109714508, 'learning_rate': 4.614720481285111e-05, 'epoch': 0.2311677112289333, 'step': 1283500}
INFO:transformers.trainer:{'loss': 3.295430807352066, 'learning_rate': 4.6145703918738477e-05, 'epoch': 0.23125776487569175, 'step': 1284000}
INFO:transformers.trainer:{'loss': 3.3170125410556794, 'learning_rate': 4.614420302462583e-05, 'epoch': 0.2313478185224502, 'step': 1284500}
INFO:transformers.trainer:{'loss': 3.2729160656929017, 'learning_rate': 4.6142702130513195e-05, 'epoch': 0.23143787216920864, 'step': 1285000}
INFO:transformers.trainer:{'loss': 3.3066453409194945, 'learning_rate': 4.614120123640055e-05, 'epoch': 0.2315279258159671, 'step': 1285500}
INFO:transformers.trainer:{'loss': 3.2854352061748506, 'learning_rate': 4.613970034228791e-05, 'epoch': 0.23161797946272553, 'step': 1286000}
INFO:transformers.trainer:{'loss': 3.3649797921180724, 'learning_rate': 4.6138199448175265e-05, 'epoch': 0.23170803310948399, 'step': 1286500}
INFO:transformers.trainer:{'loss': 3.3241220488548278, 'learning_rate': 4.613669855406263e-05, 'epoch': 0.23179808675624242, 'step': 1287000}
INFO:transformers.trainer:{'loss': 3.3457098259925844, 'learning_rate': 4.613519765994998e-05, 'epoch': 0.23188814040300088, 'step': 1287500}
INFO:transformers.trainer:{'loss': 3.276584101676941, 'learning_rate': 4.613369676583735e-05, 'epoch': 0.23197819404975933, 'step': 1288000}
INFO:transformers.trainer:{'loss': 3.347473120927811, 'learning_rate': 4.61321958717247e-05, 'epoch': 0.23206824769651777, 'step': 1288500}
INFO:transformers.trainer:{'loss': 3.316915915250778, 'learning_rate': 4.613069497761207e-05, 'epoch': 0.23215830134327622, 'step': 1289000}
INFO:transformers.trainer:{'loss': 3.2601230449676515, 'learning_rate': 4.612919408349942e-05, 'epoch': 0.23224835499003466, 'step': 1289500}
INFO:transformers.trainer:{'loss': 3.2727840455770494, 'learning_rate': 4.6127693189386785e-05, 'epoch': 0.23233840863679311, 'step': 1290000}
INFO:transformers.trainer:{'loss': 3.320375880241394, 'learning_rate': 4.6126192295274144e-05, 'epoch': 0.23242846228355155, 'step': 1290500}
INFO:transformers.trainer:{'loss': 3.36510777425766, 'learning_rate': 4.61246914011615e-05, 'epoch': 0.23251851593031, 'step': 1291000}
INFO:transformers.trainer:{'loss': 3.285962879896164, 'learning_rate': 4.612319050704886e-05, 'epoch': 0.23260856957706846, 'step': 1291500}
INFO:transformers.trainer:{'loss': 3.3160954077243803, 'learning_rate': 4.612168961293622e-05, 'epoch': 0.2326986232238269, 'step': 1292000}
INFO:transformers.trainer:{'loss': 3.2787813704013824, 'learning_rate': 4.612018871882358e-05, 'epoch': 0.23278867687058535, 'step': 1292500}
INFO:transformers.trainer:{'loss': 3.2762193748950956, 'learning_rate': 4.611868782471094e-05, 'epoch': 0.23287873051734378, 'step': 1293000}
INFO:transformers.trainer:{'loss': 3.281477519989014, 'learning_rate': 4.61171869305983e-05, 'epoch': 0.23296878416410224, 'step': 1293500}
INFO:transformers.trainer:{'loss': 3.2940115461349486, 'learning_rate': 4.611568603648566e-05, 'epoch': 0.23305883781086068, 'step': 1294000}
INFO:transformers.trainer:{'loss': 3.3532083678245543, 'learning_rate': 4.611418514237302e-05, 'epoch': 0.23314889145761913, 'step': 1294500}
INFO:transformers.trainer:{'loss': 3.3789956765174867, 'learning_rate': 4.6112684248260376e-05, 'epoch': 0.2332389451043776, 'step': 1295000}
INFO:transformers.trainer:{'loss': 3.2969591945409773, 'learning_rate': 4.6111183354147735e-05, 'epoch': 0.23332899875113602, 'step': 1295500}
INFO:transformers.trainer:{'loss': 3.311364921808243, 'learning_rate': 4.6109682460035094e-05, 'epoch': 0.23341905239789448, 'step': 1296000}
INFO:transformers.trainer:{'loss': 3.3469028487205503, 'learning_rate': 4.610818156592245e-05, 'epoch': 0.23350910604465291, 'step': 1296500}
INFO:transformers.trainer:{'loss': 3.27169655919075, 'learning_rate': 4.610668067180982e-05, 'epoch': 0.23359915969141137, 'step': 1297000}
INFO:transformers.trainer:{'loss': 3.304621351957321, 'learning_rate': 4.610517977769717e-05, 'epoch': 0.2336892133381698, 'step': 1297500}
INFO:transformers.trainer:{'loss': 3.3413237369060518, 'learning_rate': 4.610367888358454e-05, 'epoch': 0.23377926698492826, 'step': 1298000}
INFO:transformers.trainer:{'loss': 3.309513522148132, 'learning_rate': 4.610217798947189e-05, 'epoch': 0.2338693206316867, 'step': 1298500}
INFO:transformers.trainer:{'loss': 3.2698326301574707, 'learning_rate': 4.6100677095359255e-05, 'epoch': 0.23395937427844515, 'step': 1299000}
INFO:transformers.trainer:{'loss': 3.385945416688919, 'learning_rate': 4.609917620124661e-05, 'epoch': 0.2340494279252036, 'step': 1299500}
INFO:transformers.trainer:{'loss': 3.279481231689453, 'learning_rate': 4.6097675307133966e-05, 'epoch': 0.23413948157196204, 'step': 1300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2932776107788087, 'learning_rate': 4.6096174413021325e-05, 'epoch': 0.2342295352187205, 'step': 1300500}
INFO:transformers.trainer:{'loss': 3.3290167121887206, 'learning_rate': 4.6094673518908684e-05, 'epoch': 0.23431958886547893, 'step': 1301000}
INFO:transformers.trainer:{'loss': 3.317190966963768, 'learning_rate': 4.609317262479604e-05, 'epoch': 0.2344096425122374, 'step': 1301500}
INFO:transformers.trainer:{'loss': 3.2484015283584595, 'learning_rate': 4.60916717306834e-05, 'epoch': 0.23449969615899582, 'step': 1302000}
INFO:transformers.trainer:{'loss': 3.3458354201316833, 'learning_rate': 4.609017083657076e-05, 'epoch': 0.23458974980575428, 'step': 1302500}
INFO:transformers.trainer:{'loss': 3.293189559817314, 'learning_rate': 4.608866994245812e-05, 'epoch': 0.23467980345251274, 'step': 1303000}
INFO:transformers.trainer:{'loss': 3.2521319749355317, 'learning_rate': 4.608716904834548e-05, 'epoch': 0.23476985709927117, 'step': 1303500}
INFO:transformers.trainer:{'loss': 3.303852813243866, 'learning_rate': 4.608566815423284e-05, 'epoch': 0.23485991074602963, 'step': 1304000}
INFO:transformers.trainer:{'loss': 3.373224477291107, 'learning_rate': 4.6084167260120204e-05, 'epoch': 0.23494996439278806, 'step': 1304500}
INFO:transformers.trainer:{'loss': 3.3526764726638794, 'learning_rate': 4.608266636600756e-05, 'epoch': 0.23504001803954652, 'step': 1305000}
INFO:transformers.trainer:{'loss': 3.2587692530155183, 'learning_rate': 4.608116547189492e-05, 'epoch': 0.23513007168630495, 'step': 1305500}
INFO:transformers.trainer:{'loss': 3.2992295989990232, 'learning_rate': 4.6079664577782275e-05, 'epoch': 0.2352201253330634, 'step': 1306000}
INFO:transformers.trainer:{'loss': 3.3658379011154174, 'learning_rate': 4.607816368366964e-05, 'epoch': 0.23531017897982187, 'step': 1306500}
INFO:transformers.trainer:{'loss': 3.3246750742197038, 'learning_rate': 4.607666278955699e-05, 'epoch': 0.2354002326265803, 'step': 1307000}
INFO:transformers.trainer:{'loss': 3.368447469472885, 'learning_rate': 4.607516189544436e-05, 'epoch': 0.23549028627333876, 'step': 1307500}
INFO:transformers.trainer:{'loss': 3.3569126329422, 'learning_rate': 4.607366100133171e-05, 'epoch': 0.2355803399200972, 'step': 1308000}
INFO:transformers.trainer:{'loss': 3.2822917070388793, 'learning_rate': 4.607216010721908e-05, 'epoch': 0.23567039356685565, 'step': 1308500}
INFO:transformers.trainer:{'loss': 3.322555066823959, 'learning_rate': 4.607065921310643e-05, 'epoch': 0.23576044721361408, 'step': 1309000}
INFO:transformers.trainer:{'loss': 3.354737269163132, 'learning_rate': 4.6069158318993795e-05, 'epoch': 0.23585050086037254, 'step': 1309500}
INFO:transformers.trainer:{'loss': 3.291305094718933, 'learning_rate': 4.606765742488115e-05, 'epoch': 0.235940554507131, 'step': 1310000}
INFO:transformers.trainer:{'loss': 3.3405322173833847, 'learning_rate': 4.606615653076851e-05, 'epoch': 0.23603060815388943, 'step': 1310500}
INFO:transformers.trainer:{'loss': 3.329349184036255, 'learning_rate': 4.606465563665587e-05, 'epoch': 0.2361206618006479, 'step': 1311000}
INFO:transformers.trainer:{'loss': 3.3805591096878054, 'learning_rate': 4.606315474254323e-05, 'epoch': 0.23621071544740632, 'step': 1311500}
INFO:transformers.trainer:{'loss': 3.3015847375392915, 'learning_rate': 4.606165384843059e-05, 'epoch': 0.23630076909416478, 'step': 1312000}
INFO:transformers.trainer:{'loss': 3.3444613523483278, 'learning_rate': 4.606015295431795e-05, 'epoch': 0.2363908227409232, 'step': 1312500}
INFO:transformers.trainer:{'loss': 3.3095736532211304, 'learning_rate': 4.605865206020531e-05, 'epoch': 0.23648087638768167, 'step': 1313000}
INFO:transformers.trainer:{'loss': 3.317486555814743, 'learning_rate': 4.605715116609267e-05, 'epoch': 0.23657093003444013, 'step': 1313500}
INFO:transformers.trainer:{'loss': 3.30033731508255, 'learning_rate': 4.6055650271980026e-05, 'epoch': 0.23666098368119856, 'step': 1314000}
INFO:transformers.trainer:{'loss': 3.3319682650566103, 'learning_rate': 4.6054149377867385e-05, 'epoch': 0.23675103732795702, 'step': 1314500}
INFO:transformers.trainer:{'loss': 3.308070810317993, 'learning_rate': 4.6052648483754744e-05, 'epoch': 0.23684109097471545, 'step': 1315000}
INFO:transformers.trainer:{'loss': 3.2921130378246306, 'learning_rate': 4.6051147589642103e-05, 'epoch': 0.2369311446214739, 'step': 1315500}
INFO:transformers.trainer:{'loss': 3.348088152885437, 'learning_rate': 4.604964669552946e-05, 'epoch': 0.23702119826823234, 'step': 1316000}
INFO:transformers.trainer:{'loss': 3.355288943529129, 'learning_rate': 4.604814580141682e-05, 'epoch': 0.2371112519149908, 'step': 1316500}
INFO:transformers.trainer:{'loss': 3.3407912757396696, 'learning_rate': 4.604664490730418e-05, 'epoch': 0.23720130556174923, 'step': 1317000}
INFO:transformers.trainer:{'loss': 3.3302474517822267, 'learning_rate': 4.604514401319154e-05, 'epoch': 0.2372913592085077, 'step': 1317500}
INFO:transformers.trainer:{'loss': 3.3388694853782654, 'learning_rate': 4.60436431190789e-05, 'epoch': 0.23738141285526615, 'step': 1318000}
INFO:transformers.trainer:{'loss': 3.3310300002098083, 'learning_rate': 4.6042142224966265e-05, 'epoch': 0.23747146650202458, 'step': 1318500}
INFO:transformers.trainer:{'loss': 3.329467824935913, 'learning_rate': 4.604064133085362e-05, 'epoch': 0.23756152014878304, 'step': 1319000}
INFO:transformers.trainer:{'loss': 3.3449343588352205, 'learning_rate': 4.603914043674098e-05, 'epoch': 0.23765157379554147, 'step': 1319500}
INFO:transformers.trainer:{'loss': 3.3457700843811033, 'learning_rate': 4.6037639542628335e-05, 'epoch': 0.23774162744229993, 'step': 1320000}
INFO:transformers.trainer:{'loss': 3.2842219185829165, 'learning_rate': 4.60361386485157e-05, 'epoch': 0.23783168108905836, 'step': 1320500}
INFO:transformers.trainer:{'loss': 3.286095133066177, 'learning_rate': 4.603463775440305e-05, 'epoch': 0.23792173473581682, 'step': 1321000}
INFO:transformers.trainer:{'loss': 3.34373339676857, 'learning_rate': 4.603313686029042e-05, 'epoch': 0.23801178838257528, 'step': 1321500}
INFO:transformers.trainer:{'loss': 3.3127512834072115, 'learning_rate': 4.603163596617777e-05, 'epoch': 0.2381018420293337, 'step': 1322000}
INFO:transformers.trainer:{'loss': 3.2894407715797422, 'learning_rate': 4.603013507206514e-05, 'epoch': 0.23819189567609217, 'step': 1322500}
INFO:transformers.trainer:{'loss': 3.3636024396419524, 'learning_rate': 4.602863417795249e-05, 'epoch': 0.2382819493228506, 'step': 1323000}
INFO:transformers.trainer:{'loss': 3.312293278217316, 'learning_rate': 4.602713328383985e-05, 'epoch': 0.23837200296960906, 'step': 1323500}
INFO:transformers.trainer:{'loss': 3.3457417616844176, 'learning_rate': 4.602563238972721e-05, 'epoch': 0.2384620566163675, 'step': 1324000}
INFO:transformers.trainer:{'loss': 3.323884615659714, 'learning_rate': 4.6024131495614566e-05, 'epoch': 0.23855211026312595, 'step': 1324500}
INFO:transformers.trainer:{'loss': 3.330858474969864, 'learning_rate': 4.602263060150193e-05, 'epoch': 0.2386421639098844, 'step': 1325000}
INFO:transformers.trainer:{'loss': 3.3137752120494843, 'learning_rate': 4.6021129707389284e-05, 'epoch': 0.23873221755664284, 'step': 1325500}
INFO:transformers.trainer:{'loss': 3.308285706281662, 'learning_rate': 4.601962881327665e-05, 'epoch': 0.2388222712034013, 'step': 1326000}
INFO:transformers.trainer:{'loss': 3.315031188249588, 'learning_rate': 4.6018127919164e-05, 'epoch': 0.23891232485015973, 'step': 1326500}
INFO:transformers.trainer:{'loss': 3.3386871507167815, 'learning_rate': 4.601662702505137e-05, 'epoch': 0.2390023784969182, 'step': 1327000}
INFO:transformers.trainer:{'loss': 3.251065146446228, 'learning_rate': 4.601512613093872e-05, 'epoch': 0.23909243214367662, 'step': 1327500}
INFO:transformers.trainer:{'loss': 3.345593513250351, 'learning_rate': 4.6013625236826087e-05, 'epoch': 0.23918248579043508, 'step': 1328000}
INFO:transformers.trainer:{'loss': 3.3514972133636474, 'learning_rate': 4.601212434271344e-05, 'epoch': 0.23927253943719354, 'step': 1328500}
INFO:transformers.trainer:{'loss': 3.3612740936279297, 'learning_rate': 4.6010623448600805e-05, 'epoch': 0.23936259308395197, 'step': 1329000}
INFO:transformers.trainer:{'loss': 3.329521378040314, 'learning_rate': 4.600912255448816e-05, 'epoch': 0.23945264673071043, 'step': 1329500}
INFO:transformers.trainer:{'loss': 3.3075701406002045, 'learning_rate': 4.600762166037552e-05, 'epoch': 0.23954270037746886, 'step': 1330000}
INFO:transformers.trainer:{'loss': 3.336048760890961, 'learning_rate': 4.6006120766262875e-05, 'epoch': 0.23963275402422732, 'step': 1330500}
INFO:transformers.trainer:{'loss': 3.3325318887233735, 'learning_rate': 4.600461987215024e-05, 'epoch': 0.23972280767098575, 'step': 1331000}
INFO:transformers.trainer:{'loss': 3.3305715572834016, 'learning_rate': 4.60031189780376e-05, 'epoch': 0.2398128613177442, 'step': 1331500}
INFO:transformers.trainer:{'loss': 3.3679096541404725, 'learning_rate': 4.600161808392496e-05, 'epoch': 0.23990291496450267, 'step': 1332000}
INFO:transformers.trainer:{'loss': 3.3262749602794646, 'learning_rate': 4.600011718981232e-05, 'epoch': 0.2399929686112611, 'step': 1332500}
INFO:transformers.trainer:{'loss': 3.3208155727386472, 'learning_rate': 4.599861629569968e-05, 'epoch': 0.24008302225801956, 'step': 1333000}
INFO:transformers.trainer:{'loss': 3.356757075548172, 'learning_rate': 4.5997115401587036e-05, 'epoch': 0.240173075904778, 'step': 1333500}
INFO:transformers.trainer:{'loss': 3.269628354549408, 'learning_rate': 4.5995614507474395e-05, 'epoch': 0.24026312955153645, 'step': 1334000}
INFO:transformers.trainer:{'loss': 3.404918912053108, 'learning_rate': 4.5994113613361754e-05, 'epoch': 0.24035318319829488, 'step': 1334500}
INFO:transformers.trainer:{'loss': 3.304611161470413, 'learning_rate': 4.599261271924911e-05, 'epoch': 0.24044323684505334, 'step': 1335000}
INFO:transformers.trainer:{'loss': 3.2947962086200713, 'learning_rate': 4.599111182513647e-05, 'epoch': 0.24053329049181177, 'step': 1335500}
INFO:transformers.trainer:{'loss': 3.3236792125701906, 'learning_rate': 4.598961093102383e-05, 'epoch': 0.24062334413857023, 'step': 1336000}
INFO:transformers.trainer:{'loss': 3.3162339413166046, 'learning_rate': 4.598811003691119e-05, 'epoch': 0.2407133977853287, 'step': 1336500}
INFO:transformers.trainer:{'loss': 3.3230590369701387, 'learning_rate': 4.598660914279855e-05, 'epoch': 0.24080345143208712, 'step': 1337000}
INFO:transformers.trainer:{'loss': 3.2786280574798585, 'learning_rate': 4.598510824868591e-05, 'epoch': 0.24089350507884558, 'step': 1337500}
INFO:transformers.trainer:{'loss': 3.2995856173038485, 'learning_rate': 4.598360735457327e-05, 'epoch': 0.240983558725604, 'step': 1338000}
INFO:transformers.trainer:{'loss': 3.283147488594055, 'learning_rate': 4.5982106460460627e-05, 'epoch': 0.24107361237236247, 'step': 1338500}
INFO:transformers.trainer:{'loss': 3.381605302810669, 'learning_rate': 4.598060556634799e-05, 'epoch': 0.2411636660191209, 'step': 1339000}
INFO:transformers.trainer:{'loss': 3.291359499454498, 'learning_rate': 4.5979104672235345e-05, 'epoch': 0.24125371966587936, 'step': 1339500}
INFO:transformers.trainer:{'loss': 3.2841595672369004, 'learning_rate': 4.597760377812271e-05, 'epoch': 0.24134377331263782, 'step': 1340000}
INFO:transformers.trainer:{'loss': 3.3316107741594316, 'learning_rate': 4.597610288401006e-05, 'epoch': 0.24143382695939625, 'step': 1340500}
INFO:transformers.trainer:{'loss': 3.32670454120636, 'learning_rate': 4.597460198989743e-05, 'epoch': 0.2415238806061547, 'step': 1341000}
INFO:transformers.trainer:{'loss': 3.2776665481328964, 'learning_rate': 4.597310109578478e-05, 'epoch': 0.24161393425291314, 'step': 1341500}
INFO:transformers.trainer:{'loss': 3.2422148690223693, 'learning_rate': 4.597160020167215e-05, 'epoch': 0.2417039878996716, 'step': 1342000}
INFO:transformers.trainer:{'loss': 3.3179895927906036, 'learning_rate': 4.59700993075595e-05, 'epoch': 0.24179404154643003, 'step': 1342500}
INFO:transformers.trainer:{'loss': 3.3076440014839172, 'learning_rate': 4.5968598413446865e-05, 'epoch': 0.2418840951931885, 'step': 1343000}
INFO:transformers.trainer:{'loss': 3.2978598735332487, 'learning_rate': 4.596709751933422e-05, 'epoch': 0.24197414883994695, 'step': 1343500}
INFO:transformers.trainer:{'loss': 3.41994002699852, 'learning_rate': 4.596559662522158e-05, 'epoch': 0.24206420248670538, 'step': 1344000}
INFO:transformers.trainer:{'loss': 3.317282872915268, 'learning_rate': 4.5964095731108935e-05, 'epoch': 0.24215425613346384, 'step': 1344500}
INFO:transformers.trainer:{'loss': 3.356643116354942, 'learning_rate': 4.59625948369963e-05, 'epoch': 0.24224430978022227, 'step': 1345000}
INFO:transformers.trainer:{'loss': 3.2986856322288514, 'learning_rate': 4.596109394288366e-05, 'epoch': 0.24233436342698073, 'step': 1345500}
INFO:transformers.trainer:{'loss': 3.3010603940486907, 'learning_rate': 4.595959304877102e-05, 'epoch': 0.24242441707373916, 'step': 1346000}
INFO:transformers.trainer:{'loss': 3.3431648325920107, 'learning_rate': 4.595809215465838e-05, 'epoch': 0.24251447072049762, 'step': 1346500}
INFO:transformers.trainer:{'loss': 3.382153312921524, 'learning_rate': 4.595659126054574e-05, 'epoch': 0.24260452436725607, 'step': 1347000}
INFO:transformers.trainer:{'loss': 3.3526412136554717, 'learning_rate': 4.5955090366433096e-05, 'epoch': 0.2426945780140145, 'step': 1347500}
INFO:transformers.trainer:{'loss': 3.288653044939041, 'learning_rate': 4.595358947232045e-05, 'epoch': 0.24278463166077296, 'step': 1348000}
INFO:transformers.trainer:{'loss': 3.281947027683258, 'learning_rate': 4.5952088578207814e-05, 'epoch': 0.2428746853075314, 'step': 1348500}
INFO:transformers.trainer:{'loss': 3.2994704763889313, 'learning_rate': 4.595058768409517e-05, 'epoch': 0.24296473895428986, 'step': 1349000}
INFO:transformers.trainer:{'loss': 3.249605533361435, 'learning_rate': 4.594908678998253e-05, 'epoch': 0.2430547926010483, 'step': 1349500}
INFO:transformers.trainer:{'loss': 3.3564629917144777, 'learning_rate': 4.5947585895869885e-05, 'epoch': 0.24314484624780675, 'step': 1350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.32201908993721, 'learning_rate': 4.594608500175725e-05, 'epoch': 0.2432348998945652, 'step': 1350500}
INFO:transformers.trainer:{'loss': 3.315065207719803, 'learning_rate': 4.59445841076446e-05, 'epoch': 0.24332495354132364, 'step': 1351000}
INFO:transformers.trainer:{'loss': 3.3032766749858857, 'learning_rate': 4.594308321353197e-05, 'epoch': 0.2434150071880821, 'step': 1351500}
INFO:transformers.trainer:{'loss': 3.380763097643852, 'learning_rate': 4.594158231941932e-05, 'epoch': 0.24350506083484053, 'step': 1352000}
INFO:transformers.trainer:{'loss': 3.3632355115413666, 'learning_rate': 4.594008142530669e-05, 'epoch': 0.24359511448159898, 'step': 1352500}
INFO:transformers.trainer:{'loss': 3.335366702079773, 'learning_rate': 4.5938580531194046e-05, 'epoch': 0.24368516812835742, 'step': 1353000}
INFO:transformers.trainer:{'loss': 3.3383047664165497, 'learning_rate': 4.5937079637081405e-05, 'epoch': 0.24377522177511587, 'step': 1353500}
INFO:transformers.trainer:{'loss': 3.2964820263385772, 'learning_rate': 4.5935578742968764e-05, 'epoch': 0.2438652754218743, 'step': 1354000}
INFO:transformers.trainer:{'loss': 3.2988672835826875, 'learning_rate': 4.593407784885612e-05, 'epoch': 0.24395532906863276, 'step': 1354500}
INFO:transformers.trainer:{'loss': 3.324827518939972, 'learning_rate': 4.593257695474348e-05, 'epoch': 0.24404538271539122, 'step': 1355000}
INFO:transformers.trainer:{'loss': 3.397415937423706, 'learning_rate': 4.593107606063084e-05, 'epoch': 0.24413543636214965, 'step': 1355500}
INFO:transformers.trainer:{'loss': 3.3310880688428877, 'learning_rate': 4.59295751665182e-05, 'epoch': 0.2442254900089081, 'step': 1356000}
INFO:transformers.trainer:{'loss': 3.37481067943573, 'learning_rate': 4.592807427240556e-05, 'epoch': 0.24431554365566654, 'step': 1356500}
INFO:transformers.trainer:{'loss': 3.252755547761917, 'learning_rate': 4.592657337829292e-05, 'epoch': 0.244405597302425, 'step': 1357000}
INFO:transformers.trainer:{'loss': 3.2530827775001527, 'learning_rate': 4.592507248418028e-05, 'epoch': 0.24449565094918344, 'step': 1357500}
INFO:transformers.trainer:{'loss': 3.298131396532059, 'learning_rate': 4.5923571590067636e-05, 'epoch': 0.2445857045959419, 'step': 1358000}
INFO:transformers.trainer:{'loss': 3.2827385494709014, 'learning_rate': 4.5922070695954995e-05, 'epoch': 0.24467575824270035, 'step': 1358500}
INFO:transformers.trainer:{'loss': 3.240247862815857, 'learning_rate': 4.5920569801842354e-05, 'epoch': 0.24476581188945878, 'step': 1359000}
INFO:transformers.trainer:{'loss': 3.282568508386612, 'learning_rate': 4.591906890772972e-05, 'epoch': 0.24485586553621724, 'step': 1359500}
INFO:transformers.trainer:{'loss': 3.2910366213321685, 'learning_rate': 4.591756801361707e-05, 'epoch': 0.24494591918297567, 'step': 1360000}
INFO:transformers.trainer:{'loss': 3.309810973405838, 'learning_rate': 4.591606711950444e-05, 'epoch': 0.24503597282973413, 'step': 1360500}
INFO:transformers.trainer:{'loss': 3.28418420791626, 'learning_rate': 4.591456622539179e-05, 'epoch': 0.24512602647649256, 'step': 1361000}
INFO:transformers.trainer:{'loss': 3.3252854063510893, 'learning_rate': 4.5913065331279156e-05, 'epoch': 0.24521608012325102, 'step': 1361500}
INFO:transformers.trainer:{'loss': 3.269928002357483, 'learning_rate': 4.591156443716651e-05, 'epoch': 0.24530613377000948, 'step': 1362000}
INFO:transformers.trainer:{'loss': 3.3825859253406523, 'learning_rate': 4.5910063543053875e-05, 'epoch': 0.2453961874167679, 'step': 1362500}
INFO:transformers.trainer:{'loss': 3.283205127954483, 'learning_rate': 4.590856264894123e-05, 'epoch': 0.24548624106352637, 'step': 1363000}
INFO:transformers.trainer:{'loss': 3.376142405748367, 'learning_rate': 4.590706175482859e-05, 'epoch': 0.2455762947102848, 'step': 1363500}
INFO:transformers.trainer:{'loss': 3.234588335156441, 'learning_rate': 4.5905560860715945e-05, 'epoch': 0.24566634835704326, 'step': 1364000}
INFO:transformers.trainer:{'loss': 3.2804302113056183, 'learning_rate': 4.590405996660331e-05, 'epoch': 0.2457564020038017, 'step': 1364500}
INFO:transformers.trainer:{'loss': 3.3432850630283357, 'learning_rate': 4.590255907249066e-05, 'epoch': 0.24584645565056015, 'step': 1365000}
INFO:transformers.trainer:{'loss': 3.3616996297836303, 'learning_rate': 4.590105817837803e-05, 'epoch': 0.2459365092973186, 'step': 1365500}
INFO:transformers.trainer:{'loss': 3.2858165769577026, 'learning_rate': 4.589955728426538e-05, 'epoch': 0.24602656294407704, 'step': 1366000}
INFO:transformers.trainer:{'loss': 3.267081533193588, 'learning_rate': 4.589805639015275e-05, 'epoch': 0.2461166165908355, 'step': 1366500}
INFO:transformers.trainer:{'loss': 3.3151196205615996, 'learning_rate': 4.5896555496040106e-05, 'epoch': 0.24620667023759393, 'step': 1367000}
INFO:transformers.trainer:{'loss': 3.286751032829285, 'learning_rate': 4.5895054601927465e-05, 'epoch': 0.2462967238843524, 'step': 1367500}
INFO:transformers.trainer:{'loss': 3.297355829000473, 'learning_rate': 4.5893553707814824e-05, 'epoch': 0.24638677753111082, 'step': 1368000}
INFO:transformers.trainer:{'loss': 3.294729940414429, 'learning_rate': 4.589205281370218e-05, 'epoch': 0.24647683117786928, 'step': 1368500}
INFO:transformers.trainer:{'loss': 3.3581527869701384, 'learning_rate': 4.589055191958954e-05, 'epoch': 0.2465668848246277, 'step': 1369000}
INFO:transformers.trainer:{'loss': 3.318474826335907, 'learning_rate': 4.58890510254769e-05, 'epoch': 0.24665693847138617, 'step': 1369500}
INFO:transformers.trainer:{'loss': 3.342175228834152, 'learning_rate': 4.588755013136426e-05, 'epoch': 0.24674699211814463, 'step': 1370000}
INFO:transformers.trainer:{'loss': 3.335550616979599, 'learning_rate': 4.588604923725162e-05, 'epoch': 0.24683704576490306, 'step': 1370500}
INFO:transformers.trainer:{'loss': 3.2922865906953813, 'learning_rate': 4.588454834313898e-05, 'epoch': 0.24692709941166152, 'step': 1371000}
INFO:transformers.trainer:{'loss': 3.3334748311042786, 'learning_rate': 4.588304744902633e-05, 'epoch': 0.24701715305841995, 'step': 1371500}
INFO:transformers.trainer:{'loss': 3.318361735701561, 'learning_rate': 4.5881546554913696e-05, 'epoch': 0.2471072067051784, 'step': 1372000}
INFO:transformers.trainer:{'loss': 3.409880669116974, 'learning_rate': 4.588004566080105e-05, 'epoch': 0.24719726035193684, 'step': 1372500}
INFO:transformers.trainer:{'loss': 3.3198688123226168, 'learning_rate': 4.5878544766688415e-05, 'epoch': 0.2472873139986953, 'step': 1373000}
INFO:transformers.trainer:{'loss': 3.2994256184101105, 'learning_rate': 4.5877043872575774e-05, 'epoch': 0.24737736764545376, 'step': 1373500}
INFO:transformers.trainer:{'loss': 3.3464637315273285, 'learning_rate': 4.587554297846313e-05, 'epoch': 0.2474674212922122, 'step': 1374000}
INFO:transformers.trainer:{'loss': 3.335534168243408, 'learning_rate': 4.587404208435049e-05, 'epoch': 0.24755747493897065, 'step': 1374500}
INFO:transformers.trainer:{'loss': 3.285062828540802, 'learning_rate': 4.587254119023785e-05, 'epoch': 0.24764752858572908, 'step': 1375000}
INFO:transformers.trainer:{'loss': 3.37206547665596, 'learning_rate': 4.587104029612521e-05, 'epoch': 0.24773758223248754, 'step': 1375500}
INFO:transformers.trainer:{'loss': 3.2945649342536925, 'learning_rate': 4.586953940201257e-05, 'epoch': 0.24782763587924597, 'step': 1376000}
INFO:transformers.trainer:{'loss': 3.291204721212387, 'learning_rate': 4.586803850789993e-05, 'epoch': 0.24791768952600443, 'step': 1376500}
INFO:transformers.trainer:{'loss': 3.329762013673782, 'learning_rate': 4.586653761378729e-05, 'epoch': 0.2480077431727629, 'step': 1377000}
INFO:transformers.trainer:{'loss': 3.262585772037506, 'learning_rate': 4.5865036719674646e-05, 'epoch': 0.24809779681952132, 'step': 1377500}
INFO:transformers.trainer:{'loss': 3.3312758214473726, 'learning_rate': 4.5863535825562005e-05, 'epoch': 0.24818785046627978, 'step': 1378000}
INFO:transformers.trainer:{'loss': 3.3426798654794694, 'learning_rate': 4.5862034931449364e-05, 'epoch': 0.2482779041130382, 'step': 1378500}
INFO:transformers.trainer:{'loss': 3.3470584802627563, 'learning_rate': 4.586053403733672e-05, 'epoch': 0.24836795775979667, 'step': 1379000}
INFO:transformers.trainer:{'loss': 3.341583840608597, 'learning_rate': 4.585903314322408e-05, 'epoch': 0.2484580114065551, 'step': 1379500}
INFO:transformers.trainer:{'loss': 3.3256337502002715, 'learning_rate': 4.585753224911145e-05, 'epoch': 0.24854806505331356, 'step': 1380000}
INFO:transformers.trainer:{'loss': 3.2784903120994566, 'learning_rate': 4.58560313549988e-05, 'epoch': 0.24863811870007202, 'step': 1380500}
INFO:transformers.trainer:{'loss': 3.397522550582886, 'learning_rate': 4.5854530460886166e-05, 'epoch': 0.24872817234683045, 'step': 1381000}
INFO:transformers.trainer:{'loss': 3.323765338897705, 'learning_rate': 4.585302956677352e-05, 'epoch': 0.2488182259935889, 'step': 1381500}
INFO:transformers.trainer:{'loss': 3.3789701833724974, 'learning_rate': 4.5851528672660884e-05, 'epoch': 0.24890827964034734, 'step': 1382000}
INFO:transformers.trainer:{'loss': 3.3711811072826388, 'learning_rate': 4.5850027778548237e-05, 'epoch': 0.2489983332871058, 'step': 1382500}
INFO:transformers.trainer:{'loss': 3.2898331038951873, 'learning_rate': 4.58485268844356e-05, 'epoch': 0.24908838693386423, 'step': 1383000}
INFO:transformers.trainer:{'loss': 3.268074684858322, 'learning_rate': 4.5847025990322955e-05, 'epoch': 0.2491784405806227, 'step': 1383500}
INFO:transformers.trainer:{'loss': 3.2244893177747724, 'learning_rate': 4.584552509621032e-05, 'epoch': 0.24926849422738115, 'step': 1384000}
INFO:transformers.trainer:{'loss': 3.3499543218612673, 'learning_rate': 4.584402420209767e-05, 'epoch': 0.24935854787413958, 'step': 1384500}
INFO:transformers.trainer:{'loss': 3.3686834037303925, 'learning_rate': 4.584252330798504e-05, 'epoch': 0.24944860152089804, 'step': 1385000}
INFO:transformers.trainer:{'loss': 3.3010865948200228, 'learning_rate': 4.584102241387239e-05, 'epoch': 0.24953865516765647, 'step': 1385500}
INFO:transformers.trainer:{'loss': 3.3191057641506196, 'learning_rate': 4.583952151975976e-05, 'epoch': 0.24962870881441493, 'step': 1386000}
INFO:transformers.trainer:{'loss': 3.3080951771736147, 'learning_rate': 4.583802062564711e-05, 'epoch': 0.24971876246117336, 'step': 1386500}
INFO:transformers.trainer:{'loss': 3.33540095615387, 'learning_rate': 4.5836519731534475e-05, 'epoch': 0.24980881610793182, 'step': 1387000}
INFO:transformers.trainer:{'loss': 3.3464787192344665, 'learning_rate': 4.5835018837421834e-05, 'epoch': 0.24989886975469025, 'step': 1387500}
INFO:transformers.trainer:{'loss': 3.3061953270435334, 'learning_rate': 4.583351794330919e-05, 'epoch': 0.2499889234014487, 'step': 1388000}
INFO:transformers.trainer:{'loss': 3.310243797540665, 'learning_rate': 4.583201704919655e-05, 'epoch': 0.25007897704820714, 'step': 1388500}
INFO:transformers.trainer:{'loss': 3.294243178129196, 'learning_rate': 4.583051615508391e-05, 'epoch': 0.2501690306949656, 'step': 1389000}
INFO:transformers.trainer:{'loss': 3.354373514890671, 'learning_rate': 4.582901526097127e-05, 'epoch': 0.25025908434172406, 'step': 1389500}
INFO:transformers.trainer:{'loss': 3.2942217638492584, 'learning_rate': 4.582751436685863e-05, 'epoch': 0.2503491379884825, 'step': 1390000}
INFO:transformers.trainer:{'loss': 3.3459424431324005, 'learning_rate': 4.582601347274599e-05, 'epoch': 0.2504391916352409, 'step': 1390500}
INFO:transformers.trainer:{'loss': 3.331954985141754, 'learning_rate': 4.582451257863335e-05, 'epoch': 0.2505292452819994, 'step': 1391000}
INFO:transformers.trainer:{'loss': 3.262567541360855, 'learning_rate': 4.5823011684520706e-05, 'epoch': 0.25061929892875784, 'step': 1391500}
INFO:transformers.trainer:{'loss': 3.343287124872208, 'learning_rate': 4.5821510790408065e-05, 'epoch': 0.2507093525755163, 'step': 1392000}
INFO:transformers.trainer:{'loss': 3.3115746052265167, 'learning_rate': 4.5820009896295424e-05, 'epoch': 0.25079940622227476, 'step': 1392500}
INFO:transformers.trainer:{'loss': 3.3215610086917877, 'learning_rate': 4.581850900218278e-05, 'epoch': 0.25088945986903316, 'step': 1393000}
INFO:transformers.trainer:{'loss': 3.303691740036011, 'learning_rate': 4.581700810807014e-05, 'epoch': 0.2509795135157916, 'step': 1393500}
INFO:transformers.trainer:{'loss': 3.3332642288208008, 'learning_rate': 4.58155072139575e-05, 'epoch': 0.2510695671625501, 'step': 1394000}
INFO:transformers.trainer:{'loss': 3.238358145952225, 'learning_rate': 4.581400631984486e-05, 'epoch': 0.25115962080930854, 'step': 1394500}
INFO:transformers.trainer:{'loss': 3.292688009262085, 'learning_rate': 4.581250542573222e-05, 'epoch': 0.251249674456067, 'step': 1395000}
INFO:transformers.trainer:{'loss': 3.354487186431885, 'learning_rate': 4.581100453161958e-05, 'epoch': 0.2513397281028254, 'step': 1395500}
INFO:transformers.trainer:{'loss': 3.276560053110123, 'learning_rate': 4.580950363750694e-05, 'epoch': 0.25142978174958386, 'step': 1396000}
INFO:transformers.trainer:{'loss': 3.3651967389583586, 'learning_rate': 4.58080027433943e-05, 'epoch': 0.2515198353963423, 'step': 1396500}
INFO:transformers.trainer:{'loss': 3.3314359080791474, 'learning_rate': 4.5806501849281656e-05, 'epoch': 0.2516098890431008, 'step': 1397000}
INFO:transformers.trainer:{'loss': 3.3650182654857637, 'learning_rate': 4.5805000955169015e-05, 'epoch': 0.2516999426898592, 'step': 1397500}
INFO:transformers.trainer:{'loss': 3.3103985788822174, 'learning_rate': 4.5803500061056374e-05, 'epoch': 0.25178999633661764, 'step': 1398000}
INFO:transformers.trainer:{'loss': 3.316177349805832, 'learning_rate': 4.580199916694373e-05, 'epoch': 0.2518800499833761, 'step': 1398500}
INFO:transformers.trainer:{'loss': 3.2917655251026154, 'learning_rate': 4.580049827283109e-05, 'epoch': 0.25197010363013456, 'step': 1399000}
INFO:transformers.trainer:{'loss': 3.292363603591919, 'learning_rate': 4.579899737871845e-05, 'epoch': 0.252060157276893, 'step': 1399500}
INFO:transformers.trainer:{'loss': 3.265600290119648, 'learning_rate': 4.579749648460581e-05, 'epoch': 0.2521502109236514, 'step': 1400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.328991450548172, 'learning_rate': 4.579599559049317e-05, 'epoch': 0.2522402645704099, 'step': 1400500}
INFO:transformers.trainer:{'loss': 3.3560957498550414, 'learning_rate': 4.579449469638053e-05, 'epoch': 0.25233031821716834, 'step': 1401000}
INFO:transformers.trainer:{'loss': 3.302550272464752, 'learning_rate': 4.5792993802267894e-05, 'epoch': 0.2524203718639268, 'step': 1401500}
INFO:transformers.trainer:{'loss': 3.281766154527664, 'learning_rate': 4.5791492908155246e-05, 'epoch': 0.2525104255106852, 'step': 1402000}
INFO:transformers.trainer:{'loss': 3.285851898908615, 'learning_rate': 4.578999201404261e-05, 'epoch': 0.25260047915744366, 'step': 1402500}
INFO:transformers.trainer:{'loss': 3.3597509601116182, 'learning_rate': 4.5788491119929964e-05, 'epoch': 0.2526905328042021, 'step': 1403000}
INFO:transformers.trainer:{'loss': 3.406146612405777, 'learning_rate': 4.578699022581733e-05, 'epoch': 0.2527805864509606, 'step': 1403500}
INFO:transformers.trainer:{'loss': 3.297644029855728, 'learning_rate': 4.578548933170468e-05, 'epoch': 0.25287064009771903, 'step': 1404000}
INFO:transformers.trainer:{'loss': 3.2763950810432436, 'learning_rate': 4.578398843759205e-05, 'epoch': 0.25296069374447744, 'step': 1404500}
INFO:transformers.trainer:{'loss': 3.325892877340317, 'learning_rate': 4.57824875434794e-05, 'epoch': 0.2530507473912359, 'step': 1405000}
INFO:transformers.trainer:{'loss': 3.2904728043079374, 'learning_rate': 4.5780986649366766e-05, 'epoch': 0.25314080103799436, 'step': 1405500}
INFO:transformers.trainer:{'loss': 3.3197598571777345, 'learning_rate': 4.577948575525412e-05, 'epoch': 0.2532308546847528, 'step': 1406000}
INFO:transformers.trainer:{'loss': 3.2663298894166948, 'learning_rate': 4.5777984861141484e-05, 'epoch': 0.2533209083315113, 'step': 1406500}
INFO:transformers.trainer:{'loss': 3.321923001050949, 'learning_rate': 4.577648396702884e-05, 'epoch': 0.2534109619782697, 'step': 1407000}
INFO:transformers.trainer:{'loss': 3.2898968534469604, 'learning_rate': 4.57749830729162e-05, 'epoch': 0.25350101562502814, 'step': 1407500}
INFO:transformers.trainer:{'loss': 3.3082078886032105, 'learning_rate': 4.577348217880356e-05, 'epoch': 0.2535910692717866, 'step': 1408000}
INFO:transformers.trainer:{'loss': 3.3276129047870637, 'learning_rate': 4.577198128469092e-05, 'epoch': 0.25368112291854505, 'step': 1408500}
INFO:transformers.trainer:{'loss': 3.3560786385536194, 'learning_rate': 4.577048039057828e-05, 'epoch': 0.25377117656530346, 'step': 1409000}
INFO:transformers.trainer:{'loss': 3.2579514338970186, 'learning_rate': 4.576897949646564e-05, 'epoch': 0.2538612302120619, 'step': 1409500}
INFO:transformers.trainer:{'loss': 3.2588350265026094, 'learning_rate': 4.5767478602353e-05, 'epoch': 0.2539512838588204, 'step': 1410000}
INFO:transformers.trainer:{'loss': 3.3149109230041502, 'learning_rate': 4.576597770824036e-05, 'epoch': 0.25404133750557883, 'step': 1410500}
INFO:transformers.trainer:{'loss': 3.305912589073181, 'learning_rate': 4.5764476814127716e-05, 'epoch': 0.2541313911523373, 'step': 1411000}
INFO:transformers.trainer:{'loss': 3.368671560525894, 'learning_rate': 4.5762975920015075e-05, 'epoch': 0.2542214447990957, 'step': 1411500}
INFO:transformers.trainer:{'loss': 3.2878969311714172, 'learning_rate': 4.5761475025902434e-05, 'epoch': 0.25431149844585416, 'step': 1412000}
INFO:transformers.trainer:{'loss': 3.3282210800647736, 'learning_rate': 4.575997413178979e-05, 'epoch': 0.2544015520926126, 'step': 1412500}
INFO:transformers.trainer:{'loss': 3.3292608873844145, 'learning_rate': 4.575847323767715e-05, 'epoch': 0.2544916057393711, 'step': 1413000}
INFO:transformers.trainer:{'loss': 3.332912085771561, 'learning_rate': 4.575697234356451e-05, 'epoch': 0.2545816593861295, 'step': 1413500}
INFO:transformers.trainer:{'loss': 3.2723584051132204, 'learning_rate': 4.575547144945187e-05, 'epoch': 0.25467171303288794, 'step': 1414000}
INFO:transformers.trainer:{'loss': 3.314433729171753, 'learning_rate': 4.575397055533923e-05, 'epoch': 0.2547617666796464, 'step': 1414500}
INFO:transformers.trainer:{'loss': 3.3041143198013305, 'learning_rate': 4.575246966122659e-05, 'epoch': 0.25485182032640485, 'step': 1415000}
INFO:transformers.trainer:{'loss': 3.345343287229538, 'learning_rate': 4.575096876711395e-05, 'epoch': 0.2549418739731633, 'step': 1415500}
INFO:transformers.trainer:{'loss': 3.255321429014206, 'learning_rate': 4.5749467873001306e-05, 'epoch': 0.2550319276199217, 'step': 1416000}
INFO:transformers.trainer:{'loss': 3.334614055633545, 'learning_rate': 4.5747966978888665e-05, 'epoch': 0.2551219812666802, 'step': 1416500}
INFO:transformers.trainer:{'loss': 3.3017859907150267, 'learning_rate': 4.5746466084776025e-05, 'epoch': 0.25521203491343863, 'step': 1417000}
INFO:transformers.trainer:{'loss': 3.2866740221977233, 'learning_rate': 4.5744965190663384e-05, 'epoch': 0.2553020885601971, 'step': 1417500}
INFO:transformers.trainer:{'loss': 3.3495980932712555, 'learning_rate': 4.574346429655074e-05, 'epoch': 0.25539214220695555, 'step': 1418000}
INFO:transformers.trainer:{'loss': 3.250470735311508, 'learning_rate': 4.57419634024381e-05, 'epoch': 0.25548219585371396, 'step': 1418500}
INFO:transformers.trainer:{'loss': 3.2842494761943817, 'learning_rate': 4.574046250832546e-05, 'epoch': 0.2555722495004724, 'step': 1419000}
INFO:transformers.trainer:{'loss': 3.3558207199573515, 'learning_rate': 4.573896161421282e-05, 'epoch': 0.2556623031472309, 'step': 1419500}
INFO:transformers.trainer:{'loss': 3.277906056642532, 'learning_rate': 4.573746072010018e-05, 'epoch': 0.25575235679398933, 'step': 1420000}
INFO:transformers.trainer:{'loss': 3.2914106736183166, 'learning_rate': 4.573595982598754e-05, 'epoch': 0.25584241044074774, 'step': 1420500}
INFO:transformers.trainer:{'loss': 3.3448057863712313, 'learning_rate': 4.57344589318749e-05, 'epoch': 0.2559324640875062, 'step': 1421000}
INFO:transformers.trainer:{'loss': 3.2566214733123777, 'learning_rate': 4.5732958037762256e-05, 'epoch': 0.25602251773426465, 'step': 1421500}
INFO:transformers.trainer:{'loss': 3.3215435898303984, 'learning_rate': 4.573145714364962e-05, 'epoch': 0.2561125713810231, 'step': 1422000}
INFO:transformers.trainer:{'loss': 3.296373427271843, 'learning_rate': 4.5729956249536974e-05, 'epoch': 0.25620262502778157, 'step': 1422500}
INFO:transformers.trainer:{'loss': 3.353893965482712, 'learning_rate': 4.572845535542434e-05, 'epoch': 0.25629267867454, 'step': 1423000}
INFO:transformers.trainer:{'loss': 3.308356535077095, 'learning_rate': 4.572695446131169e-05, 'epoch': 0.25638273232129843, 'step': 1423500}
INFO:transformers.trainer:{'loss': 3.268160793542862, 'learning_rate': 4.572545356719906e-05, 'epoch': 0.2564727859680569, 'step': 1424000}
INFO:transformers.trainer:{'loss': 3.3416709420681, 'learning_rate': 4.572395267308641e-05, 'epoch': 0.25656283961481535, 'step': 1424500}
INFO:transformers.trainer:{'loss': 3.3099365121126176, 'learning_rate': 4.5722451778973776e-05, 'epoch': 0.2566528932615738, 'step': 1425000}
INFO:transformers.trainer:{'loss': 3.281411182165146, 'learning_rate': 4.572095088486113e-05, 'epoch': 0.2567429469083322, 'step': 1425500}
INFO:transformers.trainer:{'loss': 3.285097548961639, 'learning_rate': 4.5719449990748494e-05, 'epoch': 0.2568330005550907, 'step': 1426000}
INFO:transformers.trainer:{'loss': 3.311397592306137, 'learning_rate': 4.5717949096635846e-05, 'epoch': 0.25692305420184913, 'step': 1426500}
INFO:transformers.trainer:{'loss': 3.325778119802475, 'learning_rate': 4.571644820252321e-05, 'epoch': 0.2570131078486076, 'step': 1427000}
INFO:transformers.trainer:{'loss': 3.3347682433128356, 'learning_rate': 4.5714947308410565e-05, 'epoch': 0.257103161495366, 'step': 1427500}
INFO:transformers.trainer:{'loss': 3.314923819065094, 'learning_rate': 4.571344641429793e-05, 'epoch': 0.25719321514212445, 'step': 1428000}
INFO:transformers.trainer:{'loss': 3.288644011735916, 'learning_rate': 4.571194552018528e-05, 'epoch': 0.2572832687888829, 'step': 1428500}
INFO:transformers.trainer:{'loss': 3.3350335981845856, 'learning_rate': 4.571044462607265e-05, 'epoch': 0.25737332243564137, 'step': 1429000}
INFO:transformers.trainer:{'loss': 3.3086248171329498, 'learning_rate': 4.570894373196001e-05, 'epoch': 0.25746337608239983, 'step': 1429500}
INFO:transformers.trainer:{'loss': 3.262172290802002, 'learning_rate': 4.5707442837847367e-05, 'epoch': 0.25755342972915823, 'step': 1430000}
INFO:transformers.trainer:{'loss': 3.2837320687770846, 'learning_rate': 4.5705941943734726e-05, 'epoch': 0.2576434833759167, 'step': 1430500}
INFO:transformers.trainer:{'loss': 3.3166566894054412, 'learning_rate': 4.5704441049622085e-05, 'epoch': 0.25773353702267515, 'step': 1431000}
INFO:transformers.trainer:{'loss': 3.3099108612537385, 'learning_rate': 4.5702940155509444e-05, 'epoch': 0.2578235906694336, 'step': 1431500}
INFO:transformers.trainer:{'loss': 3.413050147294998, 'learning_rate': 4.57014392613968e-05, 'epoch': 0.257913644316192, 'step': 1432000}
INFO:transformers.trainer:{'loss': 3.2990753009319307, 'learning_rate': 4.569993836728416e-05, 'epoch': 0.2580036979629505, 'step': 1432500}
INFO:transformers.trainer:{'loss': 3.3176818215847015, 'learning_rate': 4.569843747317152e-05, 'epoch': 0.25809375160970893, 'step': 1433000}
INFO:transformers.trainer:{'loss': 3.3068290506601334, 'learning_rate': 4.569693657905888e-05, 'epoch': 0.2581838052564674, 'step': 1433500}
INFO:transformers.trainer:{'loss': 3.315454158782959, 'learning_rate': 4.569543568494624e-05, 'epoch': 0.25827385890322585, 'step': 1434000}
INFO:transformers.trainer:{'loss': 3.2786746764183046, 'learning_rate': 4.56939347908336e-05, 'epoch': 0.25836391254998425, 'step': 1434500}
INFO:transformers.trainer:{'loss': 3.2632899515628813, 'learning_rate': 4.569243389672096e-05, 'epoch': 0.2584539661967427, 'step': 1435000}
INFO:transformers.trainer:{'loss': 3.313739294052124, 'learning_rate': 4.5690933002608316e-05, 'epoch': 0.25854401984350117, 'step': 1435500}
INFO:transformers.trainer:{'loss': 3.3144754147529603, 'learning_rate': 4.5689432108495675e-05, 'epoch': 0.25863407349025963, 'step': 1436000}
INFO:transformers.trainer:{'loss': 3.3086192232370375, 'learning_rate': 4.5687931214383034e-05, 'epoch': 0.2587241271370181, 'step': 1436500}
INFO:transformers.trainer:{'loss': 3.3233411564826967, 'learning_rate': 4.568643032027039e-05, 'epoch': 0.2588141807837765, 'step': 1437000}
INFO:transformers.trainer:{'loss': 3.2510381789207456, 'learning_rate': 4.568492942615775e-05, 'epoch': 0.25890423443053495, 'step': 1437500}
INFO:transformers.trainer:{'loss': 3.2760637538433075, 'learning_rate': 4.568342853204511e-05, 'epoch': 0.2589942880772934, 'step': 1438000}
INFO:transformers.trainer:{'loss': 3.3007223258018494, 'learning_rate': 4.568192763793247e-05, 'epoch': 0.25908434172405187, 'step': 1438500}
INFO:transformers.trainer:{'loss': 3.3495196523666384, 'learning_rate': 4.568042674381983e-05, 'epoch': 0.2591743953708103, 'step': 1439000}
INFO:transformers.trainer:{'loss': 3.3156660684347155, 'learning_rate': 4.567892584970719e-05, 'epoch': 0.25926444901756873, 'step': 1439500}
INFO:transformers.trainer:{'loss': 3.3246695261001586, 'learning_rate': 4.567742495559455e-05, 'epoch': 0.2593545026643272, 'step': 1440000}
INFO:transformers.trainer:{'loss': 3.2971852140426634, 'learning_rate': 4.567592406148191e-05, 'epoch': 0.25944455631108565, 'step': 1440500}
INFO:transformers.trainer:{'loss': 3.3122562017440798, 'learning_rate': 4.5674423167369266e-05, 'epoch': 0.2595346099578441, 'step': 1441000}
INFO:transformers.trainer:{'loss': 3.3198282380104063, 'learning_rate': 4.5672922273256625e-05, 'epoch': 0.2596246636046025, 'step': 1441500}
INFO:transformers.trainer:{'loss': 3.282483113706112, 'learning_rate': 4.5671421379143984e-05, 'epoch': 0.25971471725136097, 'step': 1442000}
INFO:transformers.trainer:{'loss': 3.3071146092414856, 'learning_rate': 4.566992048503135e-05, 'epoch': 0.25980477089811943, 'step': 1442500}
INFO:transformers.trainer:{'loss': 3.3092859752178194, 'learning_rate': 4.56684195909187e-05, 'epoch': 0.2598948245448779, 'step': 1443000}
INFO:transformers.trainer:{'loss': 3.3536656346321108, 'learning_rate': 4.566691869680607e-05, 'epoch': 0.25998487819163635, 'step': 1443500}
INFO:transformers.trainer:{'loss': 3.317932381629944, 'learning_rate': 4.566541780269342e-05, 'epoch': 0.26007493183839475, 'step': 1444000}
INFO:transformers.trainer:{'loss': 3.252379704236984, 'learning_rate': 4.5663916908580786e-05, 'epoch': 0.2601649854851532, 'step': 1444500}
INFO:transformers.trainer:{'loss': 3.2410224530696867, 'learning_rate': 4.566241601446814e-05, 'epoch': 0.26025503913191167, 'step': 1445000}
INFO:transformers.trainer:{'loss': 3.2872999486923216, 'learning_rate': 4.5660915120355504e-05, 'epoch': 0.26034509277867013, 'step': 1445500}
INFO:transformers.trainer:{'loss': 3.3101940739154814, 'learning_rate': 4.5659414226242856e-05, 'epoch': 0.26043514642542853, 'step': 1446000}
INFO:transformers.trainer:{'loss': 3.2885352053642274, 'learning_rate': 4.565791333213022e-05, 'epoch': 0.260525200072187, 'step': 1446500}
INFO:transformers.trainer:{'loss': 3.237478572130203, 'learning_rate': 4.5656412438017574e-05, 'epoch': 0.26061525371894545, 'step': 1447000}
INFO:transformers.trainer:{'loss': 3.3189946496486664, 'learning_rate': 4.565491154390494e-05, 'epoch': 0.2607053073657039, 'step': 1447500}
INFO:transformers.trainer:{'loss': 3.3226031432151792, 'learning_rate': 4.565341064979229e-05, 'epoch': 0.26079536101246237, 'step': 1448000}
INFO:transformers.trainer:{'loss': 3.3101247684955597, 'learning_rate': 4.565190975567966e-05, 'epoch': 0.26088541465922077, 'step': 1448500}
INFO:transformers.trainer:{'loss': 3.326188786268234, 'learning_rate': 4.565040886156701e-05, 'epoch': 0.26097546830597923, 'step': 1449000}
INFO:transformers.trainer:{'loss': 3.321635848760605, 'learning_rate': 4.5648907967454376e-05, 'epoch': 0.2610655219527377, 'step': 1449500}
INFO:transformers.trainer:{'loss': 3.2700180201530458, 'learning_rate': 4.5647407073341735e-05, 'epoch': 0.26115557559949615, 'step': 1450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2872055559158326, 'learning_rate': 4.5645906179229094e-05, 'epoch': 0.26124562924625455, 'step': 1450500}
INFO:transformers.trainer:{'loss': 3.361004296064377, 'learning_rate': 4.5644405285116453e-05, 'epoch': 0.261335682893013, 'step': 1451000}
INFO:transformers.trainer:{'loss': 3.3081359243392945, 'learning_rate': 4.564290439100381e-05, 'epoch': 0.26142573653977147, 'step': 1451500}
INFO:transformers.trainer:{'loss': 3.3029102916717528, 'learning_rate': 4.564140349689117e-05, 'epoch': 0.26151579018652993, 'step': 1452000}
INFO:transformers.trainer:{'loss': 3.3105589364767076, 'learning_rate': 4.563990260277853e-05, 'epoch': 0.2616058438332884, 'step': 1452500}
INFO:transformers.trainer:{'loss': 3.25008207988739, 'learning_rate': 4.563840170866589e-05, 'epoch': 0.2616958974800468, 'step': 1453000}
INFO:transformers.trainer:{'loss': 3.275103365302086, 'learning_rate': 4.563690081455325e-05, 'epoch': 0.26178595112680525, 'step': 1453500}
INFO:transformers.trainer:{'loss': 3.306035432100296, 'learning_rate': 4.563539992044061e-05, 'epoch': 0.2618760047735637, 'step': 1454000}
INFO:transformers.trainer:{'loss': 3.2720844695568085, 'learning_rate': 4.563389902632797e-05, 'epoch': 0.26196605842032217, 'step': 1454500}
INFO:transformers.trainer:{'loss': 3.3172370345592497, 'learning_rate': 4.5632398132215326e-05, 'epoch': 0.2620561120670806, 'step': 1455000}
INFO:transformers.trainer:{'loss': 3.3357972145080566, 'learning_rate': 4.5630897238102685e-05, 'epoch': 0.26214616571383903, 'step': 1455500}
INFO:transformers.trainer:{'loss': 3.3079554295539855, 'learning_rate': 4.5629396343990044e-05, 'epoch': 0.2622362193605975, 'step': 1456000}
INFO:transformers.trainer:{'loss': 3.3022921862602233, 'learning_rate': 4.56278954498774e-05, 'epoch': 0.26232627300735595, 'step': 1456500}
INFO:transformers.trainer:{'loss': 3.3376091663837433, 'learning_rate': 4.562639455576476e-05, 'epoch': 0.2624163266541144, 'step': 1457000}
INFO:transformers.trainer:{'loss': 3.3021643748283385, 'learning_rate': 4.562489366165212e-05, 'epoch': 0.2625063803008728, 'step': 1457500}
INFO:transformers.trainer:{'loss': 3.319485170125961, 'learning_rate': 4.562339276753948e-05, 'epoch': 0.26259643394763127, 'step': 1458000}
INFO:transformers.trainer:{'loss': 3.280120436191559, 'learning_rate': 4.562189187342684e-05, 'epoch': 0.26268648759438973, 'step': 1458500}
INFO:transformers.trainer:{'loss': 3.308201607465744, 'learning_rate': 4.56203909793142e-05, 'epoch': 0.2627765412411482, 'step': 1459000}
INFO:transformers.trainer:{'loss': 3.3505614182949066, 'learning_rate': 4.561889008520156e-05, 'epoch': 0.26286659488790665, 'step': 1459500}
INFO:transformers.trainer:{'loss': 3.3363550659418104, 'learning_rate': 4.5617389191088916e-05, 'epoch': 0.26295664853466505, 'step': 1460000}
INFO:transformers.trainer:{'loss': 3.302291067123413, 'learning_rate': 4.5615888296976275e-05, 'epoch': 0.2630467021814235, 'step': 1460500}
INFO:transformers.trainer:{'loss': 3.3345536274909975, 'learning_rate': 4.5614387402863634e-05, 'epoch': 0.26313675582818197, 'step': 1461000}
INFO:transformers.trainer:{'loss': 3.2913071131706237, 'learning_rate': 4.5612886508750994e-05, 'epoch': 0.2632268094749404, 'step': 1461500}
INFO:transformers.trainer:{'loss': 3.2961176104545595, 'learning_rate': 4.561138561463835e-05, 'epoch': 0.2633168631216989, 'step': 1462000}
INFO:transformers.trainer:{'loss': 3.2697239751815794, 'learning_rate': 4.560988472052571e-05, 'epoch': 0.2634069167684573, 'step': 1462500}
INFO:transformers.trainer:{'loss': 3.335739487171173, 'learning_rate': 4.560838382641307e-05, 'epoch': 0.26349697041521575, 'step': 1463000}
INFO:transformers.trainer:{'loss': 3.334746597528458, 'learning_rate': 4.560688293230043e-05, 'epoch': 0.2635870240619742, 'step': 1463500}
INFO:transformers.trainer:{'loss': 3.2536615788936616, 'learning_rate': 4.5605382038187796e-05, 'epoch': 0.26367707770873267, 'step': 1464000}
INFO:transformers.trainer:{'loss': 3.272014466524124, 'learning_rate': 4.560388114407515e-05, 'epoch': 0.26376713135549107, 'step': 1464500}
INFO:transformers.trainer:{'loss': 3.298185715675354, 'learning_rate': 4.5602380249962514e-05, 'epoch': 0.26385718500224953, 'step': 1465000}
INFO:transformers.trainer:{'loss': 3.2563646402359008, 'learning_rate': 4.5600879355849866e-05, 'epoch': 0.263947238649008, 'step': 1465500}
INFO:transformers.trainer:{'loss': 3.2999816813468934, 'learning_rate': 4.559937846173723e-05, 'epoch': 0.26403729229576645, 'step': 1466000}
INFO:transformers.trainer:{'loss': 3.3156711513996124, 'learning_rate': 4.5597877567624584e-05, 'epoch': 0.2641273459425249, 'step': 1466500}
INFO:transformers.trainer:{'loss': 3.3082078814506533, 'learning_rate': 4.559637667351195e-05, 'epoch': 0.2642173995892833, 'step': 1467000}
INFO:transformers.trainer:{'loss': 3.318910948038101, 'learning_rate': 4.55948757793993e-05, 'epoch': 0.26430745323604177, 'step': 1467500}
INFO:transformers.trainer:{'loss': 3.2510541830062865, 'learning_rate': 4.559337488528667e-05, 'epoch': 0.2643975068828002, 'step': 1468000}
INFO:transformers.trainer:{'loss': 3.3826884505748747, 'learning_rate': 4.559187399117402e-05, 'epoch': 0.2644875605295587, 'step': 1468500}
INFO:transformers.trainer:{'loss': 3.288560387969017, 'learning_rate': 4.5590373097061386e-05, 'epoch': 0.2645776141763171, 'step': 1469000}
INFO:transformers.trainer:{'loss': 3.3489959676265717, 'learning_rate': 4.558887220294874e-05, 'epoch': 0.26466766782307555, 'step': 1469500}
INFO:transformers.trainer:{'loss': 3.3027852017879487, 'learning_rate': 4.5587371308836104e-05, 'epoch': 0.264757721469834, 'step': 1470000}
INFO:transformers.trainer:{'loss': 3.3192775590419767, 'learning_rate': 4.558587041472346e-05, 'epoch': 0.26484777511659247, 'step': 1470500}
INFO:transformers.trainer:{'loss': 3.311463237285614, 'learning_rate': 4.558436952061082e-05, 'epoch': 0.2649378287633509, 'step': 1471000}
INFO:transformers.trainer:{'loss': 3.29492367041111, 'learning_rate': 4.558286862649818e-05, 'epoch': 0.26502788241010933, 'step': 1471500}
INFO:transformers.trainer:{'loss': 3.362543610095978, 'learning_rate': 4.558136773238554e-05, 'epoch': 0.2651179360568678, 'step': 1472000}
INFO:transformers.trainer:{'loss': 3.33884050154686, 'learning_rate': 4.55798668382729e-05, 'epoch': 0.26520798970362625, 'step': 1472500}
INFO:transformers.trainer:{'loss': 3.2241899465322494, 'learning_rate': 4.557836594416026e-05, 'epoch': 0.2652980433503847, 'step': 1473000}
INFO:transformers.trainer:{'loss': 3.2850966843366622, 'learning_rate': 4.557686505004762e-05, 'epoch': 0.26538809699714316, 'step': 1473500}
INFO:transformers.trainer:{'loss': 3.2650536301136017, 'learning_rate': 4.5575364155934977e-05, 'epoch': 0.26547815064390157, 'step': 1474000}
INFO:transformers.trainer:{'loss': 3.285587289571762, 'learning_rate': 4.5573863261822336e-05, 'epoch': 0.26556820429066, 'step': 1474500}
INFO:transformers.trainer:{'loss': 3.2523169929981233, 'learning_rate': 4.5572362367709695e-05, 'epoch': 0.2656582579374185, 'step': 1475000}
INFO:transformers.trainer:{'loss': 3.269030406713486, 'learning_rate': 4.5570861473597054e-05, 'epoch': 0.26574831158417694, 'step': 1475500}
INFO:transformers.trainer:{'loss': 3.3400445688962934, 'learning_rate': 4.556936057948441e-05, 'epoch': 0.26583836523093535, 'step': 1476000}
INFO:transformers.trainer:{'loss': 3.345209775686264, 'learning_rate': 4.556785968537177e-05, 'epoch': 0.2659284188776938, 'step': 1476500}
INFO:transformers.trainer:{'loss': 3.3002714051008226, 'learning_rate': 4.556635879125913e-05, 'epoch': 0.26601847252445227, 'step': 1477000}
INFO:transformers.trainer:{'loss': 3.3357380990982057, 'learning_rate': 4.556485789714649e-05, 'epoch': 0.2661085261712107, 'step': 1477500}
INFO:transformers.trainer:{'loss': 3.2480719943046568, 'learning_rate': 4.556335700303385e-05, 'epoch': 0.2661985798179692, 'step': 1478000}
INFO:transformers.trainer:{'loss': 3.3606143090724947, 'learning_rate': 4.556185610892121e-05, 'epoch': 0.2662886334647276, 'step': 1478500}
INFO:transformers.trainer:{'loss': 3.2619374668598176, 'learning_rate': 4.556035521480857e-05, 'epoch': 0.26637868711148605, 'step': 1479000}
INFO:transformers.trainer:{'loss': 3.280535255908966, 'learning_rate': 4.5558854320695926e-05, 'epoch': 0.2664687407582445, 'step': 1479500}
INFO:transformers.trainer:{'loss': 4.127514663934708, 'learning_rate': 4.5557353426583285e-05, 'epoch': 0.26655879440500296, 'step': 1480000}
INFO:transformers.trainer:{'loss': 3.2839628541469574, 'learning_rate': 4.5555852532470644e-05, 'epoch': 0.2666488480517614, 'step': 1480500}
INFO:transformers.trainer:{'loss': 3.239840271472931, 'learning_rate': 4.5554351638358e-05, 'epoch': 0.2667389016985198, 'step': 1481000}
INFO:transformers.trainer:{'loss': 3.331515130519867, 'learning_rate': 4.555285074424536e-05, 'epoch': 0.2668289553452783, 'step': 1481500}
INFO:transformers.trainer:{'loss': 3.298398492574692, 'learning_rate': 4.555134985013272e-05, 'epoch': 0.26691900899203674, 'step': 1482000}
INFO:transformers.trainer:{'loss': 3.3021661565303804, 'learning_rate': 4.554984895602008e-05, 'epoch': 0.2670090626387952, 'step': 1482500}
INFO:transformers.trainer:{'loss': 3.3232096693515776, 'learning_rate': 4.554834806190744e-05, 'epoch': 0.2670991162855536, 'step': 1483000}
INFO:transformers.trainer:{'loss': 3.3187057247161866, 'learning_rate': 4.55468471677948e-05, 'epoch': 0.26718916993231207, 'step': 1483500}
INFO:transformers.trainer:{'loss': 3.267654677271843, 'learning_rate': 4.554534627368216e-05, 'epoch': 0.2672792235790705, 'step': 1484000}
INFO:transformers.trainer:{'loss': 3.257451909184456, 'learning_rate': 4.5543845379569523e-05, 'epoch': 0.267369277225829, 'step': 1484500}
INFO:transformers.trainer:{'loss': 3.32802342915535, 'learning_rate': 4.5542344485456876e-05, 'epoch': 0.26745933087258744, 'step': 1485000}
INFO:transformers.trainer:{'loss': 3.3009134626388548, 'learning_rate': 4.554084359134424e-05, 'epoch': 0.26754938451934585, 'step': 1485500}
INFO:transformers.trainer:{'loss': 3.355078667640686, 'learning_rate': 4.5539342697231594e-05, 'epoch': 0.2676394381661043, 'step': 1486000}
INFO:transformers.trainer:{'loss': 3.3167888269424437, 'learning_rate': 4.553784180311896e-05, 'epoch': 0.26772949181286276, 'step': 1486500}
INFO:transformers.trainer:{'loss': 3.232308733344078, 'learning_rate': 4.553634090900631e-05, 'epoch': 0.2678195454596212, 'step': 1487000}
INFO:transformers.trainer:{'loss': 3.274762587070465, 'learning_rate': 4.553484001489368e-05, 'epoch': 0.2679095991063796, 'step': 1487500}
INFO:transformers.trainer:{'loss': 3.369725902080536, 'learning_rate': 4.553333912078103e-05, 'epoch': 0.2679996527531381, 'step': 1488000}
INFO:transformers.trainer:{'loss': 3.3666962378025054, 'learning_rate': 4.5531838226668396e-05, 'epoch': 0.26808970639989654, 'step': 1488500}
INFO:transformers.trainer:{'loss': 3.3562425258159636, 'learning_rate': 4.553033733255575e-05, 'epoch': 0.268179760046655, 'step': 1489000}
INFO:transformers.trainer:{'loss': 3.284482714653015, 'learning_rate': 4.5528836438443114e-05, 'epoch': 0.26826981369341346, 'step': 1489500}
INFO:transformers.trainer:{'loss': 3.33606991481781, 'learning_rate': 4.5527335544330466e-05, 'epoch': 0.26835986734017186, 'step': 1490000}
INFO:transformers.trainer:{'loss': 3.378396348953247, 'learning_rate': 4.552583465021783e-05, 'epoch': 0.2684499209869303, 'step': 1490500}
INFO:transformers.trainer:{'loss': 3.313384073972702, 'learning_rate': 4.552433375610519e-05, 'epoch': 0.2685399746336888, 'step': 1491000}
INFO:transformers.trainer:{'loss': 3.3431612978577614, 'learning_rate': 4.552283286199255e-05, 'epoch': 0.26863002828044724, 'step': 1491500}
INFO:transformers.trainer:{'loss': 3.240457387447357, 'learning_rate': 4.552133196787991e-05, 'epoch': 0.2687200819272057, 'step': 1492000}
INFO:transformers.trainer:{'loss': 3.3435642709732054, 'learning_rate': 4.551983107376727e-05, 'epoch': 0.2688101355739641, 'step': 1492500}
INFO:transformers.trainer:{'loss': 3.2524459557533265, 'learning_rate': 4.551833017965463e-05, 'epoch': 0.26890018922072256, 'step': 1493000}
INFO:transformers.trainer:{'loss': 3.328333293914795, 'learning_rate': 4.5516829285541986e-05, 'epoch': 0.268990242867481, 'step': 1493500}
INFO:transformers.trainer:{'loss': 3.2889365265369417, 'learning_rate': 4.5515328391429345e-05, 'epoch': 0.2690802965142395, 'step': 1494000}
INFO:transformers.trainer:{'loss': 3.2699405407905577, 'learning_rate': 4.5513827497316704e-05, 'epoch': 0.2691703501609979, 'step': 1494500}
INFO:transformers.trainer:{'loss': 3.334790608048439, 'learning_rate': 4.5512326603204063e-05, 'epoch': 0.26926040380775634, 'step': 1495000}
INFO:transformers.trainer:{'loss': 3.325299418926239, 'learning_rate': 4.551082570909142e-05, 'epoch': 0.2693504574545148, 'step': 1495500}
INFO:transformers.trainer:{'loss': 3.3095893154144287, 'learning_rate': 4.550932481497878e-05, 'epoch': 0.26944051110127326, 'step': 1496000}
INFO:transformers.trainer:{'loss': 3.282056730031967, 'learning_rate': 4.550782392086614e-05, 'epoch': 0.2695305647480317, 'step': 1496500}
INFO:transformers.trainer:{'loss': 3.307779614329338, 'learning_rate': 4.55063230267535e-05, 'epoch': 0.2696206183947901, 'step': 1497000}
INFO:transformers.trainer:{'loss': 3.2991924159526826, 'learning_rate': 4.550482213264086e-05, 'epoch': 0.2697106720415486, 'step': 1497500}
INFO:transformers.trainer:{'loss': 3.2899623359441756, 'learning_rate': 4.550332123852822e-05, 'epoch': 0.26980072568830704, 'step': 1498000}
INFO:transformers.trainer:{'loss': 3.30542471408844, 'learning_rate': 4.550182034441558e-05, 'epoch': 0.2698907793350655, 'step': 1498500}
INFO:transformers.trainer:{'loss': 3.2882549043893814, 'learning_rate': 4.5500319450302936e-05, 'epoch': 0.26998083298182396, 'step': 1499000}
INFO:transformers.trainer:{'loss': 3.3146992992162705, 'learning_rate': 4.5498818556190295e-05, 'epoch': 0.27007088662858236, 'step': 1499500}
INFO:transformers.trainer:{'loss': 3.3201220539808274, 'learning_rate': 4.5497317662077654e-05, 'epoch': 0.2701609402753408, 'step': 1500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.3113143153190614, 'learning_rate': 4.549581676796501e-05, 'epoch': 0.2702509939220993, 'step': 1500500}
INFO:transformers.trainer:{'loss': 3.2719979159832002, 'learning_rate': 4.549431587385237e-05, 'epoch': 0.27034104756885774, 'step': 1501000}
INFO:transformers.trainer:{'loss': 3.3049458694458007, 'learning_rate': 4.549281497973973e-05, 'epoch': 0.27043110121561614, 'step': 1501500}
INFO:transformers.trainer:{'loss': 3.266012269973755, 'learning_rate': 4.549131408562709e-05, 'epoch': 0.2705211548623746, 'step': 1502000}
INFO:transformers.trainer:{'loss': 3.247072730302811, 'learning_rate': 4.548981319151445e-05, 'epoch': 0.27061120850913306, 'step': 1502500}
INFO:transformers.trainer:{'loss': 3.2690992810726165, 'learning_rate': 4.548831229740181e-05, 'epoch': 0.2707012621558915, 'step': 1503000}
INFO:transformers.trainer:{'loss': 3.3835804476737974, 'learning_rate': 4.548681140328917e-05, 'epoch': 0.27079131580265, 'step': 1503500}
INFO:transformers.trainer:{'loss': 3.2491560990810395, 'learning_rate': 4.5485310509176526e-05, 'epoch': 0.2708813694494084, 'step': 1504000}
INFO:transformers.trainer:{'loss': 3.331077957391739, 'learning_rate': 4.5483809615063885e-05, 'epoch': 0.27097142309616684, 'step': 1504500}
INFO:transformers.trainer:{'loss': 3.2946328797340394, 'learning_rate': 4.548230872095125e-05, 'epoch': 0.2710614767429253, 'step': 1505000}
INFO:transformers.trainer:{'loss': 3.2495063834190367, 'learning_rate': 4.5480807826838603e-05, 'epoch': 0.27115153038968376, 'step': 1505500}
INFO:transformers.trainer:{'loss': 3.300868362426758, 'learning_rate': 4.547930693272597e-05, 'epoch': 0.27124158403644216, 'step': 1506000}
INFO:transformers.trainer:{'loss': 3.3294282274246214, 'learning_rate': 4.547780603861332e-05, 'epoch': 0.2713316376832006, 'step': 1506500}
INFO:transformers.trainer:{'loss': 3.248211178779602, 'learning_rate': 4.547630514450069e-05, 'epoch': 0.2714216913299591, 'step': 1507000}
INFO:transformers.trainer:{'loss': 3.3375845987796784, 'learning_rate': 4.547480425038804e-05, 'epoch': 0.27151174497671754, 'step': 1507500}
INFO:transformers.trainer:{'loss': 3.26162370377779, 'learning_rate': 4.5473303356275406e-05, 'epoch': 0.271601798623476, 'step': 1508000}
INFO:transformers.trainer:{'loss': 3.309732747554779, 'learning_rate': 4.547180246216276e-05, 'epoch': 0.2716918522702344, 'step': 1508500}
INFO:transformers.trainer:{'loss': 3.312306708097458, 'learning_rate': 4.5470301568050124e-05, 'epoch': 0.27178190591699286, 'step': 1509000}
INFO:transformers.trainer:{'loss': 3.3021938760280607, 'learning_rate': 4.5468800673937476e-05, 'epoch': 0.2718719595637513, 'step': 1509500}
INFO:transformers.trainer:{'loss': 3.3110063552856444, 'learning_rate': 4.546729977982484e-05, 'epoch': 0.2719620132105098, 'step': 1510000}
INFO:transformers.trainer:{'loss': 3.330818993806839, 'learning_rate': 4.5465798885712194e-05, 'epoch': 0.27205206685726824, 'step': 1510500}
INFO:transformers.trainer:{'loss': 3.3471491060256957, 'learning_rate': 4.546429799159956e-05, 'epoch': 0.27214212050402664, 'step': 1511000}
INFO:transformers.trainer:{'loss': 3.368802353143692, 'learning_rate': 4.546279709748691e-05, 'epoch': 0.2722321741507851, 'step': 1511500}
INFO:transformers.trainer:{'loss': 3.279811514854431, 'learning_rate': 4.546129620337428e-05, 'epoch': 0.27232222779754356, 'step': 1512000}
INFO:transformers.trainer:{'loss': 3.2680578260421753, 'learning_rate': 4.545979530926164e-05, 'epoch': 0.272412281444302, 'step': 1512500}
INFO:transformers.trainer:{'loss': 3.2970601675510407, 'learning_rate': 4.5458294415148996e-05, 'epoch': 0.2725023350910604, 'step': 1513000}
INFO:transformers.trainer:{'loss': 3.272028134584427, 'learning_rate': 4.5456793521036355e-05, 'epoch': 0.2725923887378189, 'step': 1513500}
INFO:transformers.trainer:{'loss': 3.2604434356689453, 'learning_rate': 4.5455292626923714e-05, 'epoch': 0.27268244238457734, 'step': 1514000}
INFO:transformers.trainer:{'loss': 3.3754291212558747, 'learning_rate': 4.545379173281107e-05, 'epoch': 0.2727724960313358, 'step': 1514500}
INFO:transformers.trainer:{'loss': 3.2908441729545594, 'learning_rate': 4.545229083869843e-05, 'epoch': 0.27286254967809426, 'step': 1515000}
INFO:transformers.trainer:{'loss': 3.2903336505889893, 'learning_rate': 4.545078994458579e-05, 'epoch': 0.27295260332485266, 'step': 1515500}
INFO:transformers.trainer:{'loss': 3.266751030445099, 'learning_rate': 4.544928905047315e-05, 'epoch': 0.2730426569716111, 'step': 1516000}
INFO:transformers.trainer:{'loss': 3.2773575744628904, 'learning_rate': 4.544778815636051e-05, 'epoch': 0.2731327106183696, 'step': 1516500}
INFO:transformers.trainer:{'loss': 3.326078441619873, 'learning_rate': 4.544628726224787e-05, 'epoch': 0.27322276426512804, 'step': 1517000}
INFO:transformers.trainer:{'loss': 3.327532403469086, 'learning_rate': 4.544478636813523e-05, 'epoch': 0.2733128179118865, 'step': 1517500}
INFO:transformers.trainer:{'loss': 3.308666087388992, 'learning_rate': 4.5443285474022587e-05, 'epoch': 0.2734028715586449, 'step': 1518000}
INFO:transformers.trainer:{'loss': 3.2679476141929626, 'learning_rate': 4.5441784579909946e-05, 'epoch': 0.27349292520540336, 'step': 1518500}
INFO:transformers.trainer:{'loss': 3.2941770956516265, 'learning_rate': 4.5440283685797305e-05, 'epoch': 0.2735829788521618, 'step': 1519000}
INFO:transformers.trainer:{'loss': 3.2986949105262755, 'learning_rate': 4.5438782791684664e-05, 'epoch': 0.2736730324989203, 'step': 1519500}
INFO:transformers.trainer:{'loss': 3.287248603820801, 'learning_rate': 4.543728189757202e-05, 'epoch': 0.2737630861456787, 'step': 1520000}
INFO:transformers.trainer:{'loss': 3.2910241811275482, 'learning_rate': 4.543578100345938e-05, 'epoch': 0.27385313979243714, 'step': 1520500}
INFO:transformers.trainer:{'loss': 3.2239842817783355, 'learning_rate': 4.543428010934674e-05, 'epoch': 0.2739431934391956, 'step': 1521000}
INFO:transformers.trainer:{'loss': 3.292317945957184, 'learning_rate': 4.54327792152341e-05, 'epoch': 0.27403324708595406, 'step': 1521500}
INFO:transformers.trainer:{'loss': 3.3023632979393005, 'learning_rate': 4.543127832112146e-05, 'epoch': 0.2741233007327125, 'step': 1522000}
INFO:transformers.trainer:{'loss': 3.29366121840477, 'learning_rate': 4.542977742700882e-05, 'epoch': 0.2742133543794709, 'step': 1522500}
INFO:transformers.trainer:{'loss': 3.2862356028556823, 'learning_rate': 4.542827653289618e-05, 'epoch': 0.2743034080262294, 'step': 1523000}
INFO:transformers.trainer:{'loss': 3.2592157983779906, 'learning_rate': 4.5426775638783536e-05, 'epoch': 0.27439346167298784, 'step': 1523500}
INFO:transformers.trainer:{'loss': 3.2768705434799195, 'learning_rate': 4.5425274744670895e-05, 'epoch': 0.2744835153197463, 'step': 1524000}
INFO:transformers.trainer:{'loss': 3.3412080087661744, 'learning_rate': 4.5423773850558254e-05, 'epoch': 0.2745735689665047, 'step': 1524500}
INFO:transformers.trainer:{'loss': 3.2661502578258514, 'learning_rate': 4.542227295644561e-05, 'epoch': 0.27466362261326316, 'step': 1525000}
INFO:transformers.trainer:{'loss': 3.2583229892253875, 'learning_rate': 4.542077206233297e-05, 'epoch': 0.2747536762600216, 'step': 1525500}
INFO:transformers.trainer:{'loss': 3.2695235698223115, 'learning_rate': 4.541927116822033e-05, 'epoch': 0.2748437299067801, 'step': 1526000}
INFO:transformers.trainer:{'loss': 3.2966149582862854, 'learning_rate': 4.54177702741077e-05, 'epoch': 0.27493378355353854, 'step': 1526500}
INFO:transformers.trainer:{'loss': 3.29305029630661, 'learning_rate': 4.541626937999505e-05, 'epoch': 0.27502383720029694, 'step': 1527000}
INFO:transformers.trainer:{'loss': 3.3285291500091554, 'learning_rate': 4.5414768485882415e-05, 'epoch': 0.2751138908470554, 'step': 1527500}
INFO:transformers.trainer:{'loss': 3.4282897181510927, 'learning_rate': 4.541326759176977e-05, 'epoch': 0.27520394449381386, 'step': 1528000}
INFO:transformers.trainer:{'loss': 3.2419102499485017, 'learning_rate': 4.541176669765713e-05, 'epoch': 0.2752939981405723, 'step': 1528500}
INFO:transformers.trainer:{'loss': 3.358622443199158, 'learning_rate': 4.5410265803544486e-05, 'epoch': 0.2753840517873308, 'step': 1529000}
INFO:transformers.trainer:{'loss': 3.269329826593399, 'learning_rate': 4.540876490943185e-05, 'epoch': 0.2754741054340892, 'step': 1529500}
INFO:transformers.trainer:{'loss': 3.2145772984027863, 'learning_rate': 4.5407264015319204e-05, 'epoch': 0.27556415908084764, 'step': 1530000}
INFO:transformers.trainer:{'loss': 3.2697440040111543, 'learning_rate': 4.540576312120657e-05, 'epoch': 0.2756542127276061, 'step': 1530500}
INFO:transformers.trainer:{'loss': 3.321083175897598, 'learning_rate': 4.540426222709392e-05, 'epoch': 0.27574426637436456, 'step': 1531000}
INFO:transformers.trainer:{'loss': 3.2702770357131956, 'learning_rate': 4.540276133298129e-05, 'epoch': 0.27583432002112296, 'step': 1531500}
INFO:transformers.trainer:{'loss': 3.2680525584220885, 'learning_rate': 4.540126043886864e-05, 'epoch': 0.2759243736678814, 'step': 1532000}
INFO:transformers.trainer:{'loss': 3.2714036736488343, 'learning_rate': 4.5399759544756006e-05, 'epoch': 0.2760144273146399, 'step': 1532500}
INFO:transformers.trainer:{'loss': 3.2506658380031586, 'learning_rate': 4.5398258650643365e-05, 'epoch': 0.27610448096139834, 'step': 1533000}
INFO:transformers.trainer:{'loss': 3.262878539800644, 'learning_rate': 4.5396757756530724e-05, 'epoch': 0.2761945346081568, 'step': 1533500}
INFO:transformers.trainer:{'loss': 3.26661651968956, 'learning_rate': 4.539525686241808e-05, 'epoch': 0.2762845882549152, 'step': 1534000}
INFO:transformers.trainer:{'loss': 3.3234255188703536, 'learning_rate': 4.539375596830544e-05, 'epoch': 0.27637464190167366, 'step': 1534500}
INFO:transformers.trainer:{'loss': 3.306998873949051, 'learning_rate': 4.53922550741928e-05, 'epoch': 0.2764646955484321, 'step': 1535000}
INFO:transformers.trainer:{'loss': 3.293255973815918, 'learning_rate': 4.539075418008016e-05, 'epoch': 0.2765547491951906, 'step': 1535500}
INFO:transformers.trainer:{'loss': 3.327714991569519, 'learning_rate': 4.538925328596752e-05, 'epoch': 0.27664480284194903, 'step': 1536000}
INFO:transformers.trainer:{'loss': 3.3201889674663545, 'learning_rate': 4.538775239185488e-05, 'epoch': 0.27673485648870744, 'step': 1536500}
INFO:transformers.trainer:{'loss': 3.2755865852832793, 'learning_rate': 4.538625149774224e-05, 'epoch': 0.2768249101354659, 'step': 1537000}
INFO:transformers.trainer:{'loss': 3.324479844331741, 'learning_rate': 4.5384750603629596e-05, 'epoch': 0.27691496378222435, 'step': 1537500}
INFO:transformers.trainer:{'loss': 3.3216414663791656, 'learning_rate': 4.5383249709516955e-05, 'epoch': 0.2770050174289828, 'step': 1538000}
INFO:transformers.trainer:{'loss': 3.398491621017456, 'learning_rate': 4.5381748815404314e-05, 'epoch': 0.2770950710757412, 'step': 1538500}
INFO:transformers.trainer:{'loss': 3.378429707288742, 'learning_rate': 4.5380247921291673e-05, 'epoch': 0.2771851247224997, 'step': 1539000}
INFO:transformers.trainer:{'loss': 3.3485796477794647, 'learning_rate': 4.537874702717904e-05, 'epoch': 0.27727517836925814, 'step': 1539500}
INFO:transformers.trainer:{'loss': 3.349132784128189, 'learning_rate': 4.537724613306639e-05, 'epoch': 0.2773652320160166, 'step': 1540000}
INFO:transformers.trainer:{'loss': 3.311514115333557, 'learning_rate': 4.537574523895376e-05, 'epoch': 0.27745528566277505, 'step': 1540500}
INFO:transformers.trainer:{'loss': 3.3318283200263976, 'learning_rate': 4.537424434484111e-05, 'epoch': 0.27754533930953346, 'step': 1541000}
INFO:transformers.trainer:{'loss': 3.3056024477481842, 'learning_rate': 4.5372743450728475e-05, 'epoch': 0.2776353929562919, 'step': 1541500}
INFO:transformers.trainer:{'loss': 3.287006507396698, 'learning_rate': 4.537124255661583e-05, 'epoch': 0.2777254466030504, 'step': 1542000}
INFO:transformers.trainer:{'loss': 3.33506391787529, 'learning_rate': 4.5369741662503194e-05, 'epoch': 0.27781550024980883, 'step': 1542500}
INFO:transformers.trainer:{'loss': 3.2954855082035066, 'learning_rate': 4.5368240768390546e-05, 'epoch': 0.27790555389656724, 'step': 1543000}
INFO:transformers.trainer:{'loss': 3.224650566101074, 'learning_rate': 4.5366739874277905e-05, 'epoch': 0.2779956075433257, 'step': 1543500}
INFO:transformers.trainer:{'loss': 3.3026691176891325, 'learning_rate': 4.5365238980165264e-05, 'epoch': 0.27808566119008415, 'step': 1544000}
INFO:transformers.trainer:{'loss': 3.3002127809524535, 'learning_rate': 4.536373808605262e-05, 'epoch': 0.2781757148368426, 'step': 1544500}
INFO:transformers.trainer:{'loss': 3.318423502445221, 'learning_rate': 4.536223719193998e-05, 'epoch': 0.2782657684836011, 'step': 1545000}
INFO:transformers.trainer:{'loss': 3.317383360385895, 'learning_rate': 4.536073629782734e-05, 'epoch': 0.2783558221303595, 'step': 1545500}
INFO:transformers.trainer:{'loss': 3.3139214923381806, 'learning_rate': 4.53592354037147e-05, 'epoch': 0.27844587577711793, 'step': 1546000}
INFO:transformers.trainer:{'loss': 3.2770421764850615, 'learning_rate': 4.535773450960206e-05, 'epoch': 0.2785359294238764, 'step': 1546500}
INFO:transformers.trainer:{'loss': 3.299015581846237, 'learning_rate': 4.5356233615489425e-05, 'epoch': 0.27862598307063485, 'step': 1547000}
INFO:transformers.trainer:{'loss': 3.3332276797294615, 'learning_rate': 4.535473272137678e-05, 'epoch': 0.2787160367173933, 'step': 1547500}
INFO:transformers.trainer:{'loss': 3.25157125043869, 'learning_rate': 4.535323182726414e-05, 'epoch': 0.2788060903641517, 'step': 1548000}
INFO:transformers.trainer:{'loss': 3.249212171554565, 'learning_rate': 4.5351730933151495e-05, 'epoch': 0.2788961440109102, 'step': 1548500}
INFO:transformers.trainer:{'loss': 3.2834513533115386, 'learning_rate': 4.535023003903886e-05, 'epoch': 0.27898619765766863, 'step': 1549000}
INFO:transformers.trainer:{'loss': 3.3123493406772613, 'learning_rate': 4.5348729144926213e-05, 'epoch': 0.2790762513044271, 'step': 1549500}
INFO:transformers.trainer:{'loss': 3.272990938901901, 'learning_rate': 4.534722825081358e-05, 'epoch': 0.2791663049511855, 'step': 1550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.351844263553619, 'learning_rate': 4.534572735670093e-05, 'epoch': 0.27925635859794395, 'step': 1550500}
INFO:transformers.trainer:{'loss': 3.321399145126343, 'learning_rate': 4.53442264625883e-05, 'epoch': 0.2793464122447024, 'step': 1551000}
INFO:transformers.trainer:{'loss': 3.2853296484947205, 'learning_rate': 4.534272556847565e-05, 'epoch': 0.2794364658914609, 'step': 1551500}
INFO:transformers.trainer:{'loss': 3.3131079416275027, 'learning_rate': 4.5341224674363015e-05, 'epoch': 0.27952651953821933, 'step': 1552000}
INFO:transformers.trainer:{'loss': 3.247668710947037, 'learning_rate': 4.533972378025037e-05, 'epoch': 0.27961657318497773, 'step': 1552500}
INFO:transformers.trainer:{'loss': 3.29050637114048, 'learning_rate': 4.5338222886137734e-05, 'epoch': 0.2797066268317362, 'step': 1553000}
INFO:transformers.trainer:{'loss': 3.286237676858902, 'learning_rate': 4.533672199202509e-05, 'epoch': 0.27979668047849465, 'step': 1553500}
INFO:transformers.trainer:{'loss': 3.3085961656570433, 'learning_rate': 4.533522109791245e-05, 'epoch': 0.2798867341252531, 'step': 1554000}
INFO:transformers.trainer:{'loss': 3.2570453224182128, 'learning_rate': 4.533372020379981e-05, 'epoch': 0.2799767877720115, 'step': 1554500}
INFO:transformers.trainer:{'loss': 3.2809894375801085, 'learning_rate': 4.533221930968717e-05, 'epoch': 0.28006684141877, 'step': 1555000}
INFO:transformers.trainer:{'loss': 3.304277729034424, 'learning_rate': 4.533071841557453e-05, 'epoch': 0.28015689506552843, 'step': 1555500}
INFO:transformers.trainer:{'loss': 3.2729308973550797, 'learning_rate': 4.532921752146189e-05, 'epoch': 0.2802469487122869, 'step': 1556000}
INFO:transformers.trainer:{'loss': 3.319977543592453, 'learning_rate': 4.532771662734925e-05, 'epoch': 0.28033700235904535, 'step': 1556500}
INFO:transformers.trainer:{'loss': 3.3215133430957793, 'learning_rate': 4.5326215733236606e-05, 'epoch': 0.28042705600580375, 'step': 1557000}
INFO:transformers.trainer:{'loss': 3.276665097475052, 'learning_rate': 4.5324714839123965e-05, 'epoch': 0.2805171096525622, 'step': 1557500}
INFO:transformers.trainer:{'loss': 3.2808084700107574, 'learning_rate': 4.5323213945011324e-05, 'epoch': 0.28060716329932067, 'step': 1558000}
INFO:transformers.trainer:{'loss': 3.2806157841682433, 'learning_rate': 4.532171305089868e-05, 'epoch': 0.28069721694607913, 'step': 1558500}
INFO:transformers.trainer:{'loss': 3.3148445241451263, 'learning_rate': 4.532021215678604e-05, 'epoch': 0.2807872705928376, 'step': 1559000}
INFO:transformers.trainer:{'loss': 3.2446342067718508, 'learning_rate': 4.53187112626734e-05, 'epoch': 0.280877324239596, 'step': 1559500}
INFO:transformers.trainer:{'loss': 3.277432096481323, 'learning_rate': 4.531721036856076e-05, 'epoch': 0.28096737788635445, 'step': 1560000}
INFO:transformers.trainer:{'loss': 3.2817961052656175, 'learning_rate': 4.531570947444812e-05, 'epoch': 0.2810574315331129, 'step': 1560500}
INFO:transformers.trainer:{'loss': 3.259519665360451, 'learning_rate': 4.5314208580335485e-05, 'epoch': 0.28114748517987137, 'step': 1561000}
INFO:transformers.trainer:{'loss': 3.2663686304092407, 'learning_rate': 4.531270768622284e-05, 'epoch': 0.2812375388266298, 'step': 1561500}
INFO:transformers.trainer:{'loss': 3.256046100974083, 'learning_rate': 4.53112067921102e-05, 'epoch': 0.28132759247338823, 'step': 1562000}
INFO:transformers.trainer:{'loss': 3.329498600959778, 'learning_rate': 4.5309705897997556e-05, 'epoch': 0.2814176461201467, 'step': 1562500}
INFO:transformers.trainer:{'loss': 3.3109800029993055, 'learning_rate': 4.530820500388492e-05, 'epoch': 0.28150769976690515, 'step': 1563000}
INFO:transformers.trainer:{'loss': 3.304116405010223, 'learning_rate': 4.5306704109772274e-05, 'epoch': 0.2815977534136636, 'step': 1563500}
INFO:transformers.trainer:{'loss': 3.302878494501114, 'learning_rate': 4.530520321565964e-05, 'epoch': 0.281687807060422, 'step': 1564000}
INFO:transformers.trainer:{'loss': 3.276342511177063, 'learning_rate': 4.530370232154699e-05, 'epoch': 0.28177786070718047, 'step': 1564500}
INFO:transformers.trainer:{'loss': 3.260649795293808, 'learning_rate': 4.530220142743436e-05, 'epoch': 0.28186791435393893, 'step': 1565000}
INFO:transformers.trainer:{'loss': 3.3062349107265474, 'learning_rate': 4.530070053332171e-05, 'epoch': 0.2819579680006974, 'step': 1565500}
INFO:transformers.trainer:{'loss': 3.2593966921567916, 'learning_rate': 4.5299199639209076e-05, 'epoch': 0.28204802164745585, 'step': 1566000}
INFO:transformers.trainer:{'loss': 3.2994602665901183, 'learning_rate': 4.529769874509643e-05, 'epoch': 0.28213807529421425, 'step': 1566500}
INFO:transformers.trainer:{'loss': 3.2898996965885163, 'learning_rate': 4.529619785098379e-05, 'epoch': 0.2822281289409727, 'step': 1567000}
INFO:transformers.trainer:{'loss': 3.290376244068146, 'learning_rate': 4.529469695687115e-05, 'epoch': 0.28231818258773117, 'step': 1567500}
INFO:transformers.trainer:{'loss': 3.2445991597175596, 'learning_rate': 4.5293196062758505e-05, 'epoch': 0.28240823623448963, 'step': 1568000}
INFO:transformers.trainer:{'loss': 3.283381879091263, 'learning_rate': 4.529169516864587e-05, 'epoch': 0.28249828988124803, 'step': 1568500}
INFO:transformers.trainer:{'loss': 3.349902240395546, 'learning_rate': 4.529019427453322e-05, 'epoch': 0.2825883435280065, 'step': 1569000}
INFO:transformers.trainer:{'loss': 3.319164128303528, 'learning_rate': 4.528869338042059e-05, 'epoch': 0.28267839717476495, 'step': 1569500}
INFO:transformers.trainer:{'loss': 3.260924442052841, 'learning_rate': 4.528719248630794e-05, 'epoch': 0.2827684508215234, 'step': 1570000}
INFO:transformers.trainer:{'loss': 3.3215722514390946, 'learning_rate': 4.528569159219531e-05, 'epoch': 0.28285850446828187, 'step': 1570500}
INFO:transformers.trainer:{'loss': 3.240515214443207, 'learning_rate': 4.528419069808266e-05, 'epoch': 0.28294855811504027, 'step': 1571000}
INFO:transformers.trainer:{'loss': 3.3130102734565736, 'learning_rate': 4.5282689803970025e-05, 'epoch': 0.28303861176179873, 'step': 1571500}
INFO:transformers.trainer:{'loss': 3.313695837020874, 'learning_rate': 4.528118890985738e-05, 'epoch': 0.2831286654085572, 'step': 1572000}
INFO:transformers.trainer:{'loss': 3.311026660680771, 'learning_rate': 4.527968801574474e-05, 'epoch': 0.28321871905531565, 'step': 1572500}
INFO:transformers.trainer:{'loss': 3.2631187336444856, 'learning_rate': 4.5278187121632096e-05, 'epoch': 0.28330877270207405, 'step': 1573000}
INFO:transformers.trainer:{'loss': 3.29150719332695, 'learning_rate': 4.527668622751946e-05, 'epoch': 0.2833988263488325, 'step': 1573500}
INFO:transformers.trainer:{'loss': 3.2644492881298066, 'learning_rate': 4.5275185333406814e-05, 'epoch': 0.28348887999559097, 'step': 1574000}
INFO:transformers.trainer:{'loss': 3.2992675632238386, 'learning_rate': 4.527368443929418e-05, 'epoch': 0.28357893364234943, 'step': 1574500}
INFO:transformers.trainer:{'loss': 3.2719537279605864, 'learning_rate': 4.527218354518154e-05, 'epoch': 0.2836689872891079, 'step': 1575000}
INFO:transformers.trainer:{'loss': 3.266609096765518, 'learning_rate': 4.52706826510689e-05, 'epoch': 0.2837590409358663, 'step': 1575500}
INFO:transformers.trainer:{'loss': 3.2810476195812224, 'learning_rate': 4.526918175695626e-05, 'epoch': 0.28384909458262475, 'step': 1576000}
INFO:transformers.trainer:{'loss': 3.26280694437027, 'learning_rate': 4.5267680862843616e-05, 'epoch': 0.2839391482293832, 'step': 1576500}
INFO:transformers.trainer:{'loss': 3.2770316488742828, 'learning_rate': 4.5266179968730975e-05, 'epoch': 0.28402920187614167, 'step': 1577000}
INFO:transformers.trainer:{'loss': 3.2571832435131074, 'learning_rate': 4.5264679074618334e-05, 'epoch': 0.2841192555229001, 'step': 1577500}
INFO:transformers.trainer:{'loss': 3.2952037471532822, 'learning_rate': 4.526317818050569e-05, 'epoch': 0.28420930916965853, 'step': 1578000}
INFO:transformers.trainer:{'loss': 3.2970091457366943, 'learning_rate': 4.526167728639305e-05, 'epoch': 0.284299362816417, 'step': 1578500}
INFO:transformers.trainer:{'loss': 3.2923668847084047, 'learning_rate': 4.526017639228041e-05, 'epoch': 0.28438941646317545, 'step': 1579000}
INFO:transformers.trainer:{'loss': 3.2821093442440032, 'learning_rate': 4.525867549816777e-05, 'epoch': 0.2844794701099339, 'step': 1579500}
INFO:transformers.trainer:{'loss': 3.2904193423986436, 'learning_rate': 4.525717460405513e-05, 'epoch': 0.2845695237566923, 'step': 1580000}
INFO:transformers.trainer:{'loss': 3.276907331466675, 'learning_rate': 4.525567370994249e-05, 'epoch': 0.28465957740345077, 'step': 1580500}
INFO:transformers.trainer:{'loss': 3.207162078142166, 'learning_rate': 4.525417281582985e-05, 'epoch': 0.28474963105020923, 'step': 1581000}
INFO:transformers.trainer:{'loss': 3.3170403932332992, 'learning_rate': 4.525267192171721e-05, 'epoch': 0.2848396846969677, 'step': 1581500}
INFO:transformers.trainer:{'loss': 3.2669064338207243, 'learning_rate': 4.5251171027604565e-05, 'epoch': 0.28492973834372615, 'step': 1582000}
INFO:transformers.trainer:{'loss': 3.2798989434242247, 'learning_rate': 4.524967013349193e-05, 'epoch': 0.28501979199048455, 'step': 1582500}
INFO:transformers.trainer:{'loss': 3.2362484776973726, 'learning_rate': 4.524816923937928e-05, 'epoch': 0.285109845637243, 'step': 1583000}
INFO:transformers.trainer:{'loss': 3.2764028685092925, 'learning_rate': 4.524666834526665e-05, 'epoch': 0.28519989928400147, 'step': 1583500}
INFO:transformers.trainer:{'loss': 3.283854405403137, 'learning_rate': 4.5245167451154e-05, 'epoch': 0.2852899529307599, 'step': 1584000}
INFO:transformers.trainer:{'loss': 3.3070471098423004, 'learning_rate': 4.524366655704137e-05, 'epoch': 0.2853800065775184, 'step': 1584500}
INFO:transformers.trainer:{'loss': 3.264494429349899, 'learning_rate': 4.524216566292872e-05, 'epoch': 0.2854700602242768, 'step': 1585000}
INFO:transformers.trainer:{'loss': 3.3260358266830443, 'learning_rate': 4.5240664768816085e-05, 'epoch': 0.28556011387103525, 'step': 1585500}
INFO:transformers.trainer:{'loss': 3.2660319638252258, 'learning_rate': 4.523916387470344e-05, 'epoch': 0.2856501675177937, 'step': 1586000}
INFO:transformers.trainer:{'loss': 3.2665445621013642, 'learning_rate': 4.5237662980590803e-05, 'epoch': 0.28574022116455217, 'step': 1586500}
INFO:transformers.trainer:{'loss': 3.270337304353714, 'learning_rate': 4.5236162086478156e-05, 'epoch': 0.28583027481131057, 'step': 1587000}
INFO:transformers.trainer:{'loss': 3.307144304275513, 'learning_rate': 4.523466119236552e-05, 'epoch': 0.28592032845806903, 'step': 1587500}
INFO:transformers.trainer:{'loss': 3.349775136232376, 'learning_rate': 4.5233160298252874e-05, 'epoch': 0.2860103821048275, 'step': 1588000}
INFO:transformers.trainer:{'loss': 3.3145635101795197, 'learning_rate': 4.523165940414024e-05, 'epoch': 0.28610043575158595, 'step': 1588500}
INFO:transformers.trainer:{'loss': 3.36212620139122, 'learning_rate': 4.52301585100276e-05, 'epoch': 0.2861904893983444, 'step': 1589000}
INFO:transformers.trainer:{'loss': 3.2769606206417086, 'learning_rate': 4.522865761591496e-05, 'epoch': 0.2862805430451028, 'step': 1589500}
INFO:transformers.trainer:{'loss': 3.3009639618396758, 'learning_rate': 4.522715672180232e-05, 'epoch': 0.28637059669186127, 'step': 1590000}
INFO:transformers.trainer:{'loss': 3.3219628059864044, 'learning_rate': 4.522565582768967e-05, 'epoch': 0.2864606503386197, 'step': 1590500}
INFO:transformers.trainer:{'loss': 3.267348225593567, 'learning_rate': 4.5224154933577035e-05, 'epoch': 0.2865507039853782, 'step': 1591000}
INFO:transformers.trainer:{'loss': 3.3092990114688874, 'learning_rate': 4.522265403946439e-05, 'epoch': 0.2866407576321366, 'step': 1591500}
INFO:transformers.trainer:{'loss': 3.2426042478084565, 'learning_rate': 4.522115314535175e-05, 'epoch': 0.28673081127889505, 'step': 1592000}
INFO:transformers.trainer:{'loss': 3.281178221464157, 'learning_rate': 4.5219652251239105e-05, 'epoch': 0.2868208649256535, 'step': 1592500}
INFO:transformers.trainer:{'loss': 3.2552245852947235, 'learning_rate': 4.521815135712647e-05, 'epoch': 0.28691091857241197, 'step': 1593000}
INFO:transformers.trainer:{'loss': 3.278673531651497, 'learning_rate': 4.5216650463013823e-05, 'epoch': 0.2870009722191704, 'step': 1593500}
INFO:transformers.trainer:{'loss': 3.3189176445007322, 'learning_rate': 4.521514956890119e-05, 'epoch': 0.28709102586592883, 'step': 1594000}
INFO:transformers.trainer:{'loss': 3.3090004737377168, 'learning_rate': 4.521364867478854e-05, 'epoch': 0.2871810795126873, 'step': 1594500}
INFO:transformers.trainer:{'loss': 3.280269376754761, 'learning_rate': 4.521214778067591e-05, 'epoch': 0.28727113315944575, 'step': 1595000}
INFO:transformers.trainer:{'loss': 3.2513636989593504, 'learning_rate': 4.5210646886563266e-05, 'epoch': 0.2873611868062042, 'step': 1595500}
INFO:transformers.trainer:{'loss': 3.261133707165718, 'learning_rate': 4.5209145992450625e-05, 'epoch': 0.28745124045296266, 'step': 1596000}
INFO:transformers.trainer:{'loss': 3.22998664355278, 'learning_rate': 4.5207645098337984e-05, 'epoch': 0.28754129409972107, 'step': 1596500}
INFO:transformers.trainer:{'loss': 3.2574784262180327, 'learning_rate': 4.5206144204225344e-05, 'epoch': 0.2876313477464795, 'step': 1597000}
INFO:transformers.trainer:{'loss': 3.2836889547109602, 'learning_rate': 4.52046433101127e-05, 'epoch': 0.287721401393238, 'step': 1597500}
INFO:transformers.trainer:{'loss': 3.233706470012665, 'learning_rate': 4.520314241600006e-05, 'epoch': 0.28781145503999644, 'step': 1598000}
INFO:transformers.trainer:{'loss': 3.177256031036377, 'learning_rate': 4.520164152188742e-05, 'epoch': 0.28790150868675485, 'step': 1598500}
INFO:transformers.trainer:{'loss': 3.2988386490345003, 'learning_rate': 4.520014062777478e-05, 'epoch': 0.2879915623335133, 'step': 1599000}
INFO:transformers.trainer:{'loss': 3.2106146425008775, 'learning_rate': 4.519863973366214e-05, 'epoch': 0.28808161598027177, 'step': 1599500}
INFO:transformers.trainer:{'loss': 3.234638032436371, 'learning_rate': 4.51971388395495e-05, 'epoch': 0.2881716696270302, 'step': 1600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.285650658369064, 'learning_rate': 4.519563794543686e-05, 'epoch': 0.2882617232737887, 'step': 1600500}
INFO:transformers.trainer:{'loss': 3.289851378917694, 'learning_rate': 4.5194137051324216e-05, 'epoch': 0.2883517769205471, 'step': 1601000}
INFO:transformers.trainer:{'loss': 3.2747598524093626, 'learning_rate': 4.5192636157211575e-05, 'epoch': 0.28844183056730555, 'step': 1601500}
INFO:transformers.trainer:{'loss': 3.3170972480773924, 'learning_rate': 4.519113526309894e-05, 'epoch': 0.288531884214064, 'step': 1602000}
INFO:transformers.trainer:{'loss': 3.301235114812851, 'learning_rate': 4.518963436898629e-05, 'epoch': 0.28862193786082246, 'step': 1602500}
INFO:transformers.trainer:{'loss': 3.2622257428169252, 'learning_rate': 4.518813347487366e-05, 'epoch': 0.2887119915075809, 'step': 1603000}
INFO:transformers.trainer:{'loss': 3.2863972063064577, 'learning_rate': 4.518663258076101e-05, 'epoch': 0.2888020451543393, 'step': 1603500}
INFO:transformers.trainer:{'loss': 3.293032219409943, 'learning_rate': 4.518513168664838e-05, 'epoch': 0.2888920988010978, 'step': 1604000}
INFO:transformers.trainer:{'loss': 3.2905148208141326, 'learning_rate': 4.518363079253573e-05, 'epoch': 0.28898215244785624, 'step': 1604500}
INFO:transformers.trainer:{'loss': 3.2593735654354097, 'learning_rate': 4.5182129898423095e-05, 'epoch': 0.2890722060946147, 'step': 1605000}
INFO:transformers.trainer:{'loss': 3.230985872030258, 'learning_rate': 4.518062900431045e-05, 'epoch': 0.2891622597413731, 'step': 1605500}
INFO:transformers.trainer:{'loss': 3.3112215509414673, 'learning_rate': 4.517912811019781e-05, 'epoch': 0.28925231338813157, 'step': 1606000}
INFO:transformers.trainer:{'loss': 3.3446914863586428, 'learning_rate': 4.5177627216085165e-05, 'epoch': 0.28934236703489, 'step': 1606500}
INFO:transformers.trainer:{'loss': 3.258961531162262, 'learning_rate': 4.517612632197253e-05, 'epoch': 0.2894324206816485, 'step': 1607000}
INFO:transformers.trainer:{'loss': 3.324056537389755, 'learning_rate': 4.5174625427859884e-05, 'epoch': 0.28952247432840694, 'step': 1607500}
INFO:transformers.trainer:{'loss': 3.319967337369919, 'learning_rate': 4.517312453374725e-05, 'epoch': 0.28961252797516535, 'step': 1608000}
INFO:transformers.trainer:{'loss': 3.265542691230774, 'learning_rate': 4.51716236396346e-05, 'epoch': 0.2897025816219238, 'step': 1608500}
INFO:transformers.trainer:{'loss': 3.3260766677856446, 'learning_rate': 4.517012274552197e-05, 'epoch': 0.28979263526868226, 'step': 1609000}
INFO:transformers.trainer:{'loss': 3.31101731801033, 'learning_rate': 4.5168621851409327e-05, 'epoch': 0.2898826889154407, 'step': 1609500}
INFO:transformers.trainer:{'loss': 3.256083340406418, 'learning_rate': 4.5167120957296686e-05, 'epoch': 0.2899727425621991, 'step': 1610000}
INFO:transformers.trainer:{'loss': 3.2730152475833894, 'learning_rate': 4.5165620063184045e-05, 'epoch': 0.2900627962089576, 'step': 1610500}
INFO:transformers.trainer:{'loss': 3.31787286400795, 'learning_rate': 4.5164119169071404e-05, 'epoch': 0.29015284985571604, 'step': 1611000}
INFO:transformers.trainer:{'loss': 3.306883401155472, 'learning_rate': 4.516261827495876e-05, 'epoch': 0.2902429035024745, 'step': 1611500}
INFO:transformers.trainer:{'loss': 3.342832462310791, 'learning_rate': 4.516111738084612e-05, 'epoch': 0.29033295714923296, 'step': 1612000}
INFO:transformers.trainer:{'loss': 3.2416239295005798, 'learning_rate': 4.515961648673348e-05, 'epoch': 0.29042301079599137, 'step': 1612500}
INFO:transformers.trainer:{'loss': 3.298260780572891, 'learning_rate': 4.515811559262084e-05, 'epoch': 0.2905130644427498, 'step': 1613000}
INFO:transformers.trainer:{'loss': 3.3029773645401, 'learning_rate': 4.51566146985082e-05, 'epoch': 0.2906031180895083, 'step': 1613500}
INFO:transformers.trainer:{'loss': 3.28785689330101, 'learning_rate': 4.515511380439555e-05, 'epoch': 0.29069317173626674, 'step': 1614000}
INFO:transformers.trainer:{'loss': 3.3289870052337647, 'learning_rate': 4.515361291028292e-05, 'epoch': 0.2907832253830252, 'step': 1614500}
INFO:transformers.trainer:{'loss': 3.264383864879608, 'learning_rate': 4.515211201617027e-05, 'epoch': 0.2908732790297836, 'step': 1615000}
INFO:transformers.trainer:{'loss': 3.2602105486392974, 'learning_rate': 4.5150611122057635e-05, 'epoch': 0.29096333267654206, 'step': 1615500}
INFO:transformers.trainer:{'loss': 3.2788589193820954, 'learning_rate': 4.5149110227944994e-05, 'epoch': 0.2910533863233005, 'step': 1616000}
INFO:transformers.trainer:{'loss': 3.2678691679239273, 'learning_rate': 4.514760933383235e-05, 'epoch': 0.291143439970059, 'step': 1616500}
INFO:transformers.trainer:{'loss': 3.3399879009723663, 'learning_rate': 4.514610843971971e-05, 'epoch': 0.2912334936168174, 'step': 1617000}
INFO:transformers.trainer:{'loss': 3.2897693293094634, 'learning_rate': 4.514460754560707e-05, 'epoch': 0.29132354726357584, 'step': 1617500}
INFO:transformers.trainer:{'loss': 3.281365125656128, 'learning_rate': 4.514310665149443e-05, 'epoch': 0.2914136009103343, 'step': 1618000}
INFO:transformers.trainer:{'loss': 3.315155707359314, 'learning_rate': 4.514160575738179e-05, 'epoch': 0.29150365455709276, 'step': 1618500}
INFO:transformers.trainer:{'loss': 3.3665476422309877, 'learning_rate': 4.514010486326915e-05, 'epoch': 0.2915937082038512, 'step': 1619000}
INFO:transformers.trainer:{'loss': 3.318173680305481, 'learning_rate': 4.513860396915651e-05, 'epoch': 0.2916837618506096, 'step': 1619500}
INFO:transformers.trainer:{'loss': 3.2796928582191467, 'learning_rate': 4.5137103075043867e-05, 'epoch': 0.2917738154973681, 'step': 1620000}
INFO:transformers.trainer:{'loss': 3.263717073917389, 'learning_rate': 4.5135602180931226e-05, 'epoch': 0.29186386914412654, 'step': 1620500}
INFO:transformers.trainer:{'loss': 3.2749415563941002, 'learning_rate': 4.5134101286818585e-05, 'epoch': 0.291953922790885, 'step': 1621000}
INFO:transformers.trainer:{'loss': 3.334546130657196, 'learning_rate': 4.5132600392705944e-05, 'epoch': 0.29204397643764346, 'step': 1621500}
INFO:transformers.trainer:{'loss': 3.2684817039966583, 'learning_rate': 4.51310994985933e-05, 'epoch': 0.29213403008440186, 'step': 1622000}
INFO:transformers.trainer:{'loss': 3.366544413805008, 'learning_rate': 4.512959860448066e-05, 'epoch': 0.2922240837311603, 'step': 1622500}
INFO:transformers.trainer:{'loss': 3.3356484396457673, 'learning_rate': 4.512809771036802e-05, 'epoch': 0.2923141373779188, 'step': 1623000}
INFO:transformers.trainer:{'loss': 3.3228250172138214, 'learning_rate': 4.512659681625539e-05, 'epoch': 0.29240419102467724, 'step': 1623500}
INFO:transformers.trainer:{'loss': 3.2994921696186066, 'learning_rate': 4.512509592214274e-05, 'epoch': 0.29249424467143564, 'step': 1624000}
INFO:transformers.trainer:{'loss': 3.2916093168258667, 'learning_rate': 4.5123595028030105e-05, 'epoch': 0.2925842983181941, 'step': 1624500}
INFO:transformers.trainer:{'loss': 3.3202187967300416, 'learning_rate': 4.512209413391746e-05, 'epoch': 0.29267435196495256, 'step': 1625000}
INFO:transformers.trainer:{'loss': 3.2527798578739167, 'learning_rate': 4.512059323980482e-05, 'epoch': 0.292764405611711, 'step': 1625500}
INFO:transformers.trainer:{'loss': 3.3324162714481353, 'learning_rate': 4.5119092345692175e-05, 'epoch': 0.2928544592584695, 'step': 1626000}
INFO:transformers.trainer:{'loss': 3.314541034460068, 'learning_rate': 4.511759145157954e-05, 'epoch': 0.2929445129052279, 'step': 1626500}
INFO:transformers.trainer:{'loss': 3.3322499732971194, 'learning_rate': 4.511609055746689e-05, 'epoch': 0.29303456655198634, 'step': 1627000}
INFO:transformers.trainer:{'loss': 3.334059179544449, 'learning_rate': 4.511458966335426e-05, 'epoch': 0.2931246201987448, 'step': 1627500}
INFO:transformers.trainer:{'loss': 3.31172456073761, 'learning_rate': 4.511308876924161e-05, 'epoch': 0.29321467384550326, 'step': 1628000}
INFO:transformers.trainer:{'loss': 3.2927546482086183, 'learning_rate': 4.511158787512898e-05, 'epoch': 0.29330472749226166, 'step': 1628500}
INFO:transformers.trainer:{'loss': 3.2489249901771546, 'learning_rate': 4.511008698101633e-05, 'epoch': 0.2933947811390201, 'step': 1629000}
INFO:transformers.trainer:{'loss': 3.2586273012161255, 'learning_rate': 4.5108586086903695e-05, 'epoch': 0.2934848347857786, 'step': 1629500}
INFO:transformers.trainer:{'loss': 3.275005956411362, 'learning_rate': 4.5107085192791054e-05, 'epoch': 0.29357488843253704, 'step': 1630000}
INFO:transformers.trainer:{'loss': 3.352635223865509, 'learning_rate': 4.5105584298678413e-05, 'epoch': 0.2936649420792955, 'step': 1630500}
INFO:transformers.trainer:{'loss': 3.281635214328766, 'learning_rate': 4.510408340456577e-05, 'epoch': 0.2937549957260539, 'step': 1631000}
INFO:transformers.trainer:{'loss': 3.3328772809505463, 'learning_rate': 4.510258251045313e-05, 'epoch': 0.29384504937281236, 'step': 1631500}
INFO:transformers.trainer:{'loss': 3.2945630373954775, 'learning_rate': 4.510108161634049e-05, 'epoch': 0.2939351030195708, 'step': 1632000}
INFO:transformers.trainer:{'loss': 3.2867521088123324, 'learning_rate': 4.509958072222785e-05, 'epoch': 0.2940251566663293, 'step': 1632500}
INFO:transformers.trainer:{'loss': 3.2983637726306916, 'learning_rate': 4.509807982811521e-05, 'epoch': 0.29411521031308774, 'step': 1633000}
INFO:transformers.trainer:{'loss': 3.3001244757175447, 'learning_rate': 4.509657893400257e-05, 'epoch': 0.29420526395984614, 'step': 1633500}
INFO:transformers.trainer:{'loss': 3.21929138314724, 'learning_rate': 4.509507803988993e-05, 'epoch': 0.2942953176066046, 'step': 1634000}
INFO:transformers.trainer:{'loss': 3.2817609167099, 'learning_rate': 4.5093577145777286e-05, 'epoch': 0.29438537125336306, 'step': 1634500}
INFO:transformers.trainer:{'loss': 3.303236923456192, 'learning_rate': 4.5092076251664645e-05, 'epoch': 0.2944754249001215, 'step': 1635000}
INFO:transformers.trainer:{'loss': 3.326410083293915, 'learning_rate': 4.5090575357552004e-05, 'epoch': 0.2945654785468799, 'step': 1635500}
INFO:transformers.trainer:{'loss': 3.318975999593735, 'learning_rate': 4.508907446343936e-05, 'epoch': 0.2946555321936384, 'step': 1636000}
INFO:transformers.trainer:{'loss': 3.4699465069770814, 'learning_rate': 4.508757356932672e-05, 'epoch': 0.29474558584039684, 'step': 1636500}
INFO:transformers.trainer:{'loss': 3.3200793116092684, 'learning_rate': 4.508607267521408e-05, 'epoch': 0.2948356394871553, 'step': 1637000}
INFO:transformers.trainer:{'loss': 3.34645326089859, 'learning_rate': 4.508457178110144e-05, 'epoch': 0.29492569313391376, 'step': 1637500}
INFO:transformers.trainer:{'loss': 3.417507685661316, 'learning_rate': 4.50830708869888e-05, 'epoch': 0.29501574678067216, 'step': 1638000}
INFO:transformers.trainer:{'loss': 3.2492793090343475, 'learning_rate': 4.508156999287616e-05, 'epoch': 0.2951058004274306, 'step': 1638500}
INFO:transformers.trainer:{'loss': 3.329036299943924, 'learning_rate': 4.508006909876352e-05, 'epoch': 0.2951958540741891, 'step': 1639000}
INFO:transformers.trainer:{'loss': 3.3563375606536865, 'learning_rate': 4.5078568204650876e-05, 'epoch': 0.29528590772094754, 'step': 1639500}
INFO:transformers.trainer:{'loss': 3.294203323841095, 'learning_rate': 4.5077067310538235e-05, 'epoch': 0.295375961367706, 'step': 1640000}
INFO:transformers.trainer:{'loss': 3.2401499803066254, 'learning_rate': 4.5075566416425594e-05, 'epoch': 0.2954660150144644, 'step': 1640500}
INFO:transformers.trainer:{'loss': 3.252851501107216, 'learning_rate': 4.5074065522312953e-05, 'epoch': 0.29555606866122286, 'step': 1641000}
INFO:transformers.trainer:{'loss': 3.3764982430934904, 'learning_rate': 4.507256462820031e-05, 'epoch': 0.2956461223079813, 'step': 1641500}
INFO:transformers.trainer:{'loss': 3.2720010535717012, 'learning_rate': 4.507106373408767e-05, 'epoch': 0.2957361759547398, 'step': 1642000}
INFO:transformers.trainer:{'loss': 3.194381492137909, 'learning_rate': 4.506956283997503e-05, 'epoch': 0.2958262296014982, 'step': 1642500}
INFO:transformers.trainer:{'loss': 3.304451212644577, 'learning_rate': 4.506806194586239e-05, 'epoch': 0.29591628324825664, 'step': 1643000}
INFO:transformers.trainer:{'loss': 3.313305224657059, 'learning_rate': 4.506656105174975e-05, 'epoch': 0.2960063368950151, 'step': 1643500}
INFO:transformers.trainer:{'loss': 3.2443303582668306, 'learning_rate': 4.5065060157637115e-05, 'epoch': 0.29609639054177356, 'step': 1644000}
INFO:transformers.trainer:{'loss': 3.3403215408325195, 'learning_rate': 4.506355926352447e-05, 'epoch': 0.296186444188532, 'step': 1644500}
INFO:transformers.trainer:{'loss': 3.287625933647156, 'learning_rate': 4.506205836941183e-05, 'epoch': 0.2962764978352904, 'step': 1645000}
INFO:transformers.trainer:{'loss': 3.233460667848587, 'learning_rate': 4.5060557475299185e-05, 'epoch': 0.2963665514820489, 'step': 1645500}
INFO:transformers.trainer:{'loss': 3.286115246295929, 'learning_rate': 4.505905658118655e-05, 'epoch': 0.29645660512880734, 'step': 1646000}
INFO:transformers.trainer:{'loss': 3.2528706500530244, 'learning_rate': 4.50575556870739e-05, 'epoch': 0.2965466587755658, 'step': 1646500}
INFO:transformers.trainer:{'loss': 3.292834939956665, 'learning_rate': 4.505605479296127e-05, 'epoch': 0.2966367124223242, 'step': 1647000}
INFO:transformers.trainer:{'loss': 3.286531285405159, 'learning_rate': 4.505455389884862e-05, 'epoch': 0.29672676606908266, 'step': 1647500}
INFO:transformers.trainer:{'loss': 3.321111151456833, 'learning_rate': 4.505305300473599e-05, 'epoch': 0.2968168197158411, 'step': 1648000}
INFO:transformers.trainer:{'loss': 3.243772013425827, 'learning_rate': 4.505155211062334e-05, 'epoch': 0.2969068733625996, 'step': 1648500}
INFO:transformers.trainer:{'loss': 3.349207339525223, 'learning_rate': 4.5050051216510705e-05, 'epoch': 0.29699692700935804, 'step': 1649000}
INFO:transformers.trainer:{'loss': 3.2381427249908445, 'learning_rate': 4.504855032239806e-05, 'epoch': 0.29708698065611644, 'step': 1649500}
INFO:transformers.trainer:{'loss': 3.28910018324852, 'learning_rate': 4.504704942828542e-05, 'epoch': 0.2971770343028749, 'step': 1650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.341546191215515, 'learning_rate': 4.504554853417278e-05, 'epoch': 0.29726708794963336, 'step': 1650500}
INFO:transformers.trainer:{'loss': 3.2917819006443025, 'learning_rate': 4.504404764006014e-05, 'epoch': 0.2973571415963918, 'step': 1651000}
INFO:transformers.trainer:{'loss': 3.294901044726372, 'learning_rate': 4.50425467459475e-05, 'epoch': 0.2974471952431503, 'step': 1651500}
INFO:transformers.trainer:{'loss': 3.3364251358509063, 'learning_rate': 4.504104585183486e-05, 'epoch': 0.2975372488899087, 'step': 1652000}
INFO:transformers.trainer:{'loss': 3.3015951998233795, 'learning_rate': 4.503954495772222e-05, 'epoch': 0.29762730253666714, 'step': 1652500}
INFO:transformers.trainer:{'loss': 3.2999801313877106, 'learning_rate': 4.503804406360958e-05, 'epoch': 0.2977173561834256, 'step': 1653000}
INFO:transformers.trainer:{'loss': 3.3535999999046324, 'learning_rate': 4.5036543169496937e-05, 'epoch': 0.29780740983018406, 'step': 1653500}
INFO:transformers.trainer:{'loss': 3.2698986027240755, 'learning_rate': 4.5035042275384296e-05, 'epoch': 0.29789746347694246, 'step': 1654000}
INFO:transformers.trainer:{'loss': 3.2801780145168307, 'learning_rate': 4.5033541381271655e-05, 'epoch': 0.2979875171237009, 'step': 1654500}
INFO:transformers.trainer:{'loss': 3.308908402323723, 'learning_rate': 4.5032040487159014e-05, 'epoch': 0.2980775707704594, 'step': 1655000}
INFO:transformers.trainer:{'loss': 3.3195222496986387, 'learning_rate': 4.503053959304637e-05, 'epoch': 0.29816762441721784, 'step': 1655500}
INFO:transformers.trainer:{'loss': 3.3002617933750154, 'learning_rate': 4.502903869893373e-05, 'epoch': 0.2982576780639763, 'step': 1656000}
INFO:transformers.trainer:{'loss': 3.2968900611400604, 'learning_rate': 4.502753780482109e-05, 'epoch': 0.2983477317107347, 'step': 1656500}
INFO:transformers.trainer:{'loss': 3.329586229085922, 'learning_rate': 4.502603691070845e-05, 'epoch': 0.29843778535749316, 'step': 1657000}
INFO:transformers.trainer:{'loss': 3.244235724568367, 'learning_rate': 4.502453601659581e-05, 'epoch': 0.2985278390042516, 'step': 1657500}
INFO:transformers.trainer:{'loss': 3.3466522121429443, 'learning_rate': 4.502303512248317e-05, 'epoch': 0.2986178926510101, 'step': 1658000}
INFO:transformers.trainer:{'loss': 3.213014002561569, 'learning_rate': 4.502153422837053e-05, 'epoch': 0.29870794629776853, 'step': 1658500}
INFO:transformers.trainer:{'loss': 3.2224821286201477, 'learning_rate': 4.5020033334257886e-05, 'epoch': 0.29879799994452694, 'step': 1659000}
INFO:transformers.trainer:{'loss': 3.281515735387802, 'learning_rate': 4.5018532440145245e-05, 'epoch': 0.2988880535912854, 'step': 1659500}
INFO:transformers.trainer:{'loss': 3.2681188814640043, 'learning_rate': 4.5017031546032604e-05, 'epoch': 0.29897810723804386, 'step': 1660000}
INFO:transformers.trainer:{'loss': 3.2741894967556, 'learning_rate': 4.501553065191996e-05, 'epoch': 0.2990681608848023, 'step': 1660500}
INFO:transformers.trainer:{'loss': 3.2862398474216463, 'learning_rate': 4.501402975780732e-05, 'epoch': 0.2991582145315607, 'step': 1661000}
INFO:transformers.trainer:{'loss': 3.3394638953208924, 'learning_rate': 4.501252886369468e-05, 'epoch': 0.2992482681783192, 'step': 1661500}
INFO:transformers.trainer:{'loss': 3.3052014622688293, 'learning_rate': 4.501102796958204e-05, 'epoch': 0.29933832182507764, 'step': 1662000}
INFO:transformers.trainer:{'loss': 3.2865647807121277, 'learning_rate': 4.50095270754694e-05, 'epoch': 0.2994283754718361, 'step': 1662500}
INFO:transformers.trainer:{'loss': 3.278697840690613, 'learning_rate': 4.500802618135676e-05, 'epoch': 0.29951842911859455, 'step': 1663000}
INFO:transformers.trainer:{'loss': 3.3018279678821565, 'learning_rate': 4.500652528724412e-05, 'epoch': 0.29960848276535296, 'step': 1663500}
INFO:transformers.trainer:{'loss': 3.312101410627365, 'learning_rate': 4.5005024393131477e-05, 'epoch': 0.2996985364121114, 'step': 1664000}
INFO:transformers.trainer:{'loss': 3.2827027468681336, 'learning_rate': 4.500352349901884e-05, 'epoch': 0.2997885900588699, 'step': 1664500}
INFO:transformers.trainer:{'loss': 3.2819874260425568, 'learning_rate': 4.5002022604906195e-05, 'epoch': 0.29987864370562833, 'step': 1665000}
INFO:transformers.trainer:{'loss': 3.261957546710968, 'learning_rate': 4.500052171079356e-05, 'epoch': 0.29996869735238674, 'step': 1665500}
INFO:transformers.trainer:{'loss': 3.2688121180534364, 'learning_rate': 4.499902081668091e-05, 'epoch': 0.3000587509991452, 'step': 1666000}
INFO:transformers.trainer:{'loss': 3.214190194129944, 'learning_rate': 4.499751992256828e-05, 'epoch': 0.30014880464590366, 'step': 1666500}
INFO:transformers.trainer:{'loss': 3.2947381591796874, 'learning_rate': 4.499601902845563e-05, 'epoch': 0.3002388582926621, 'step': 1667000}
INFO:transformers.trainer:{'loss': 3.3161921463012694, 'learning_rate': 4.4994518134343e-05, 'epoch': 0.3003289119394206, 'step': 1667500}
INFO:transformers.trainer:{'loss': 3.2556962295770644, 'learning_rate': 4.499301724023035e-05, 'epoch': 0.300418965586179, 'step': 1668000}
INFO:transformers.trainer:{'loss': 3.2312594611644743, 'learning_rate': 4.4991516346117715e-05, 'epoch': 0.30050901923293744, 'step': 1668500}
INFO:transformers.trainer:{'loss': 3.2803131222724913, 'learning_rate': 4.499001545200507e-05, 'epoch': 0.3005990728796959, 'step': 1669000}
INFO:transformers.trainer:{'loss': 3.283844392299652, 'learning_rate': 4.498851455789243e-05, 'epoch': 0.30068912652645435, 'step': 1669500}
INFO:transformers.trainer:{'loss': 3.235679507136345, 'learning_rate': 4.4987013663779785e-05, 'epoch': 0.3007791801732128, 'step': 1670000}
INFO:transformers.trainer:{'loss': 3.299200767278671, 'learning_rate': 4.498551276966715e-05, 'epoch': 0.3008692338199712, 'step': 1670500}
INFO:transformers.trainer:{'loss': 3.3057776055335997, 'learning_rate': 4.49840118755545e-05, 'epoch': 0.3009592874667297, 'step': 1671000}
INFO:transformers.trainer:{'loss': 3.2645958437919615, 'learning_rate': 4.498251098144187e-05, 'epoch': 0.30104934111348813, 'step': 1671500}
INFO:transformers.trainer:{'loss': 3.2744718265533446, 'learning_rate': 4.498101008732923e-05, 'epoch': 0.3011393947602466, 'step': 1672000}
INFO:transformers.trainer:{'loss': 3.326690183401108, 'learning_rate': 4.497950919321659e-05, 'epoch': 0.301229448407005, 'step': 1672500}
INFO:transformers.trainer:{'loss': 3.2536084933280947, 'learning_rate': 4.4978008299103946e-05, 'epoch': 0.30131950205376345, 'step': 1673000}
INFO:transformers.trainer:{'loss': 3.283628214597702, 'learning_rate': 4.4976507404991305e-05, 'epoch': 0.3014095557005219, 'step': 1673500}
INFO:transformers.trainer:{'loss': 3.2646536905765533, 'learning_rate': 4.4975006510878664e-05, 'epoch': 0.3014996093472804, 'step': 1674000}
INFO:transformers.trainer:{'loss': 3.3108423523902895, 'learning_rate': 4.4973505616766023e-05, 'epoch': 0.30158966299403883, 'step': 1674500}
INFO:transformers.trainer:{'loss': 3.3328239040374754, 'learning_rate': 4.497200472265338e-05, 'epoch': 0.30167971664079724, 'step': 1675000}
INFO:transformers.trainer:{'loss': 3.260526748418808, 'learning_rate': 4.497050382854074e-05, 'epoch': 0.3017697702875557, 'step': 1675500}
INFO:transformers.trainer:{'loss': 3.3015339868068696, 'learning_rate': 4.49690029344281e-05, 'epoch': 0.30185982393431415, 'step': 1676000}
INFO:transformers.trainer:{'loss': 3.260045251369476, 'learning_rate': 4.496750204031546e-05, 'epoch': 0.3019498775810726, 'step': 1676500}
INFO:transformers.trainer:{'loss': 3.2485749673843385, 'learning_rate': 4.496600114620282e-05, 'epoch': 0.30203993122783107, 'step': 1677000}
INFO:transformers.trainer:{'loss': 3.271439703464508, 'learning_rate': 4.496450025209018e-05, 'epoch': 0.3021299848745895, 'step': 1677500}
INFO:transformers.trainer:{'loss': 3.2663428206443785, 'learning_rate': 4.496299935797754e-05, 'epoch': 0.30222003852134793, 'step': 1678000}
INFO:transformers.trainer:{'loss': 3.2645122299194336, 'learning_rate': 4.4961498463864896e-05, 'epoch': 0.3023100921681064, 'step': 1678500}
INFO:transformers.trainer:{'loss': 3.2556052474975585, 'learning_rate': 4.4959997569752255e-05, 'epoch': 0.30240014581486485, 'step': 1679000}
INFO:transformers.trainer:{'loss': 3.2811071527004243, 'learning_rate': 4.4958496675639614e-05, 'epoch': 0.30249019946162325, 'step': 1679500}
INFO:transformers.trainer:{'loss': 3.290722987294197, 'learning_rate': 4.495699578152697e-05, 'epoch': 0.3025802531083817, 'step': 1680000}
INFO:transformers.trainer:{'loss': 3.2503365268707274, 'learning_rate': 4.495549488741433e-05, 'epoch': 0.3026703067551402, 'step': 1680500}
INFO:transformers.trainer:{'loss': 3.269168746471405, 'learning_rate': 4.495399399330169e-05, 'epoch': 0.30276036040189863, 'step': 1681000}
INFO:transformers.trainer:{'loss': 3.3272812197208403, 'learning_rate': 4.495249309918905e-05, 'epoch': 0.3028504140486571, 'step': 1681500}
INFO:transformers.trainer:{'loss': 3.2800558404922486, 'learning_rate': 4.495099220507641e-05, 'epoch': 0.3029404676954155, 'step': 1682000}
INFO:transformers.trainer:{'loss': 3.2899491411447523, 'learning_rate': 4.494949131096377e-05, 'epoch': 0.30303052134217395, 'step': 1682500}
INFO:transformers.trainer:{'loss': 3.31861923122406, 'learning_rate': 4.494799041685113e-05, 'epoch': 0.3031205749889324, 'step': 1683000}
INFO:transformers.trainer:{'loss': 3.3081107044219973, 'learning_rate': 4.4946489522738486e-05, 'epoch': 0.30321062863569087, 'step': 1683500}
INFO:transformers.trainer:{'loss': 3.2730987322330476, 'learning_rate': 4.4944988628625845e-05, 'epoch': 0.3033006822824493, 'step': 1684000}
INFO:transformers.trainer:{'loss': 3.2581761193275454, 'learning_rate': 4.4943487734513204e-05, 'epoch': 0.30339073592920773, 'step': 1684500}
INFO:transformers.trainer:{'loss': 3.2760668959617614, 'learning_rate': 4.4941986840400563e-05, 'epoch': 0.3034807895759662, 'step': 1685000}
INFO:transformers.trainer:{'loss': 3.30487273979187, 'learning_rate': 4.494048594628792e-05, 'epoch': 0.30357084322272465, 'step': 1685500}
INFO:transformers.trainer:{'loss': 3.34011589217186, 'learning_rate': 4.493898505217529e-05, 'epoch': 0.3036608968694831, 'step': 1686000}
INFO:transformers.trainer:{'loss': 3.3319872381687166, 'learning_rate': 4.493748415806264e-05, 'epoch': 0.3037509505162415, 'step': 1686500}
INFO:transformers.trainer:{'loss': 3.2572829144001005, 'learning_rate': 4.4935983263950006e-05, 'epoch': 0.303841004163, 'step': 1687000}
INFO:transformers.trainer:{'loss': 3.287691321849823, 'learning_rate': 4.493448236983736e-05, 'epoch': 0.30393105780975843, 'step': 1687500}
INFO:transformers.trainer:{'loss': 3.211377124786377, 'learning_rate': 4.4932981475724725e-05, 'epoch': 0.3040211114565169, 'step': 1688000}
INFO:transformers.trainer:{'loss': 3.3011693069934847, 'learning_rate': 4.493148058161208e-05, 'epoch': 0.30411116510327535, 'step': 1688500}
INFO:transformers.trainer:{'loss': 3.252988308906555, 'learning_rate': 4.492997968749944e-05, 'epoch': 0.30420121875003375, 'step': 1689000}
INFO:transformers.trainer:{'loss': 3.257327955126762, 'learning_rate': 4.4928478793386795e-05, 'epoch': 0.3042912723967922, 'step': 1689500}
INFO:transformers.trainer:{'loss': 3.296393178701401, 'learning_rate': 4.492697789927416e-05, 'epoch': 0.30438132604355067, 'step': 1690000}
INFO:transformers.trainer:{'loss': 3.3004382877349854, 'learning_rate': 4.492547700516151e-05, 'epoch': 0.30447137969030913, 'step': 1690500}
INFO:transformers.trainer:{'loss': 3.325054754495621, 'learning_rate': 4.492397611104888e-05, 'epoch': 0.30456143333706753, 'step': 1691000}
INFO:transformers.trainer:{'loss': 3.3082347357273103, 'learning_rate': 4.492247521693623e-05, 'epoch': 0.304651486983826, 'step': 1691500}
INFO:transformers.trainer:{'loss': 3.2365052609443663, 'learning_rate': 4.49209743228236e-05, 'epoch': 0.30474154063058445, 'step': 1692000}
INFO:transformers.trainer:{'loss': 3.3001058070659637, 'learning_rate': 4.4919473428710956e-05, 'epoch': 0.3048315942773429, 'step': 1692500}
INFO:transformers.trainer:{'loss': 3.3100675048828125, 'learning_rate': 4.4917972534598315e-05, 'epoch': 0.30492164792410137, 'step': 1693000}
INFO:transformers.trainer:{'loss': 3.300774113893509, 'learning_rate': 4.4916471640485674e-05, 'epoch': 0.3050117015708598, 'step': 1693500}
INFO:transformers.trainer:{'loss': 3.294629632472992, 'learning_rate': 4.491497074637303e-05, 'epoch': 0.30510175521761823, 'step': 1694000}
INFO:transformers.trainer:{'loss': 3.307250953912735, 'learning_rate': 4.491346985226039e-05, 'epoch': 0.3051918088643767, 'step': 1694500}
INFO:transformers.trainer:{'loss': 3.3157952020168304, 'learning_rate': 4.491196895814775e-05, 'epoch': 0.30528186251113515, 'step': 1695000}
INFO:transformers.trainer:{'loss': 3.2928572597503663, 'learning_rate': 4.491046806403511e-05, 'epoch': 0.3053719161578936, 'step': 1695500}
INFO:transformers.trainer:{'loss': 3.2776913123130798, 'learning_rate': 4.490896716992247e-05, 'epoch': 0.305461969804652, 'step': 1696000}
INFO:transformers.trainer:{'loss': 3.2406317899227144, 'learning_rate': 4.490746627580983e-05, 'epoch': 0.30555202345141047, 'step': 1696500}
INFO:transformers.trainer:{'loss': 3.2363861380815506, 'learning_rate': 4.490596538169719e-05, 'epoch': 0.30564207709816893, 'step': 1697000}
INFO:transformers.trainer:{'loss': 3.2831851456165313, 'learning_rate': 4.4904464487584546e-05, 'epoch': 0.3057321307449274, 'step': 1697500}
INFO:transformers.trainer:{'loss': 3.2668453840017317, 'learning_rate': 4.4902963593471906e-05, 'epoch': 0.3058221843916858, 'step': 1698000}
INFO:transformers.trainer:{'loss': 3.316088258743286, 'learning_rate': 4.4901462699359265e-05, 'epoch': 0.30591223803844425, 'step': 1698500}
INFO:transformers.trainer:{'loss': 3.2624664788246154, 'learning_rate': 4.4899961805246624e-05, 'epoch': 0.3060022916852027, 'step': 1699000}
INFO:transformers.trainer:{'loss': 3.2940067942142486, 'learning_rate': 4.489846091113398e-05, 'epoch': 0.30609234533196117, 'step': 1699500}
INFO:transformers.trainer:{'loss': 3.3152567043304444, 'learning_rate': 4.489696001702134e-05, 'epoch': 0.3061823989787196, 'step': 1700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2830151603221895, 'learning_rate': 4.48954591229087e-05, 'epoch': 0.30627245262547803, 'step': 1700500}
INFO:transformers.trainer:{'loss': 3.2710341303348542, 'learning_rate': 4.489395822879606e-05, 'epoch': 0.3063625062722365, 'step': 1701000}
INFO:transformers.trainer:{'loss': 3.310610483407974, 'learning_rate': 4.489245733468342e-05, 'epoch': 0.30645255991899495, 'step': 1701500}
INFO:transformers.trainer:{'loss': 3.31954843044281, 'learning_rate': 4.489095644057078e-05, 'epoch': 0.3065426135657534, 'step': 1702000}
INFO:transformers.trainer:{'loss': 3.301286975622177, 'learning_rate': 4.488945554645814e-05, 'epoch': 0.3066326672125118, 'step': 1702500}
INFO:transformers.trainer:{'loss': 3.2870433297157287, 'learning_rate': 4.4887954652345496e-05, 'epoch': 0.30672272085927027, 'step': 1703000}
INFO:transformers.trainer:{'loss': 3.210798205137253, 'learning_rate': 4.4886453758232855e-05, 'epoch': 0.30681277450602873, 'step': 1703500}
INFO:transformers.trainer:{'loss': 3.251598241329193, 'learning_rate': 4.4884952864120214e-05, 'epoch': 0.3069028281527872, 'step': 1704000}
INFO:transformers.trainer:{'loss': 3.2818170824050905, 'learning_rate': 4.488345197000757e-05, 'epoch': 0.30699288179954565, 'step': 1704500}
INFO:transformers.trainer:{'loss': 3.2667156558036803, 'learning_rate': 4.488195107589493e-05, 'epoch': 0.30708293544630405, 'step': 1705000}
INFO:transformers.trainer:{'loss': 3.258161953687668, 'learning_rate': 4.488045018178229e-05, 'epoch': 0.3071729890930625, 'step': 1705500}
INFO:transformers.trainer:{'loss': 3.268170111179352, 'learning_rate': 4.487894928766965e-05, 'epoch': 0.30726304273982097, 'step': 1706000}
INFO:transformers.trainer:{'loss': 3.3021116864681246, 'learning_rate': 4.4877448393557016e-05, 'epoch': 0.3073530963865794, 'step': 1706500}
INFO:transformers.trainer:{'loss': 3.3128392684459684, 'learning_rate': 4.487594749944437e-05, 'epoch': 0.3074431500333379, 'step': 1707000}
INFO:transformers.trainer:{'loss': 3.3601889116764068, 'learning_rate': 4.4874446605331734e-05, 'epoch': 0.3075332036800963, 'step': 1707500}
INFO:transformers.trainer:{'loss': 3.290496613502502, 'learning_rate': 4.4872945711219087e-05, 'epoch': 0.30762325732685475, 'step': 1708000}
INFO:transformers.trainer:{'loss': 3.2752479150295257, 'learning_rate': 4.487144481710645e-05, 'epoch': 0.3077133109736132, 'step': 1708500}
INFO:transformers.trainer:{'loss': 3.2849355676174166, 'learning_rate': 4.4869943922993805e-05, 'epoch': 0.30780336462037167, 'step': 1709000}
INFO:transformers.trainer:{'loss': 3.220433175086975, 'learning_rate': 4.486844302888117e-05, 'epoch': 0.30789341826713007, 'step': 1709500}
INFO:transformers.trainer:{'loss': 3.282951871395111, 'learning_rate': 4.486694213476852e-05, 'epoch': 0.30798347191388853, 'step': 1710000}
INFO:transformers.trainer:{'loss': 3.2602421798706054, 'learning_rate': 4.486544124065589e-05, 'epoch': 0.308073525560647, 'step': 1710500}
INFO:transformers.trainer:{'loss': 3.3270826206207276, 'learning_rate': 4.486394034654324e-05, 'epoch': 0.30816357920740545, 'step': 1711000}
INFO:transformers.trainer:{'loss': 3.268211953163147, 'learning_rate': 4.486243945243061e-05, 'epoch': 0.3082536328541639, 'step': 1711500}
INFO:transformers.trainer:{'loss': 3.293690192699432, 'learning_rate': 4.486093855831796e-05, 'epoch': 0.3083436865009223, 'step': 1712000}
INFO:transformers.trainer:{'loss': 3.2678707842826844, 'learning_rate': 4.4859437664205325e-05, 'epoch': 0.30843374014768077, 'step': 1712500}
INFO:transformers.trainer:{'loss': 3.3202457978725435, 'learning_rate': 4.4857936770092684e-05, 'epoch': 0.3085237937944392, 'step': 1713000}
INFO:transformers.trainer:{'loss': 3.2657233889102937, 'learning_rate': 4.485643587598004e-05, 'epoch': 0.3086138474411977, 'step': 1713500}
INFO:transformers.trainer:{'loss': 3.315359564781189, 'learning_rate': 4.48549349818674e-05, 'epoch': 0.3087039010879561, 'step': 1714000}
INFO:transformers.trainer:{'loss': 3.2503265669345858, 'learning_rate': 4.485343408775476e-05, 'epoch': 0.30879395473471455, 'step': 1714500}
INFO:transformers.trainer:{'loss': 3.226418032884598, 'learning_rate': 4.485193319364212e-05, 'epoch': 0.308884008381473, 'step': 1715000}
INFO:transformers.trainer:{'loss': 3.2709266302585602, 'learning_rate': 4.485043229952948e-05, 'epoch': 0.30897406202823147, 'step': 1715500}
INFO:transformers.trainer:{'loss': 3.2710645825862885, 'learning_rate': 4.484893140541684e-05, 'epoch': 0.3090641156749899, 'step': 1716000}
INFO:transformers.trainer:{'loss': 3.3302743854522707, 'learning_rate': 4.48474305113042e-05, 'epoch': 0.30915416932174833, 'step': 1716500}
INFO:transformers.trainer:{'loss': 3.276541225552559, 'learning_rate': 4.4845929617191556e-05, 'epoch': 0.3092442229685068, 'step': 1717000}
INFO:transformers.trainer:{'loss': 3.29412105846405, 'learning_rate': 4.4844428723078915e-05, 'epoch': 0.30933427661526525, 'step': 1717500}
INFO:transformers.trainer:{'loss': 3.266811488866806, 'learning_rate': 4.4842927828966274e-05, 'epoch': 0.3094243302620237, 'step': 1718000}
INFO:transformers.trainer:{'loss': 3.2739801197052003, 'learning_rate': 4.484142693485363e-05, 'epoch': 0.30951438390878216, 'step': 1718500}
INFO:transformers.trainer:{'loss': 3.2657373542785644, 'learning_rate': 4.483992604074099e-05, 'epoch': 0.30960443755554057, 'step': 1719000}
INFO:transformers.trainer:{'loss': 3.2671635221242905, 'learning_rate': 4.483842514662835e-05, 'epoch': 0.309694491202299, 'step': 1719500}
INFO:transformers.trainer:{'loss': 3.2443019720315935, 'learning_rate': 4.483692425251571e-05, 'epoch': 0.3097845448490575, 'step': 1720000}
INFO:transformers.trainer:{'loss': 3.277297706604004, 'learning_rate': 4.483542335840307e-05, 'epoch': 0.30987459849581594, 'step': 1720500}
INFO:transformers.trainer:{'loss': 3.2678319444656374, 'learning_rate': 4.483392246429043e-05, 'epoch': 0.30996465214257435, 'step': 1721000}
INFO:transformers.trainer:{'loss': 3.311305416345596, 'learning_rate': 4.483242157017779e-05, 'epoch': 0.3100547057893328, 'step': 1721500}
INFO:transformers.trainer:{'loss': 3.289403116464615, 'learning_rate': 4.483092067606515e-05, 'epoch': 0.31014475943609127, 'step': 1722000}
INFO:transformers.trainer:{'loss': 3.2398872222900392, 'learning_rate': 4.4829419781952506e-05, 'epoch': 0.3102348130828497, 'step': 1722500}
INFO:transformers.trainer:{'loss': 3.255626589536667, 'learning_rate': 4.4827918887839865e-05, 'epoch': 0.3103248667296082, 'step': 1723000}
INFO:transformers.trainer:{'loss': 3.2448677361011504, 'learning_rate': 4.4826417993727224e-05, 'epoch': 0.3104149203763666, 'step': 1723500}
INFO:transformers.trainer:{'loss': 3.2107641708850863, 'learning_rate': 4.482491709961458e-05, 'epoch': 0.31050497402312505, 'step': 1724000}
INFO:transformers.trainer:{'loss': 3.288182286977768, 'learning_rate': 4.482341620550194e-05, 'epoch': 0.3105950276698835, 'step': 1724500}
INFO:transformers.trainer:{'loss': 3.2787683482170107, 'learning_rate': 4.48219153113893e-05, 'epoch': 0.31068508131664196, 'step': 1725000}
INFO:transformers.trainer:{'loss': 3.262562979102135, 'learning_rate': 4.482041441727666e-05, 'epoch': 0.3107751349634004, 'step': 1725500}
INFO:transformers.trainer:{'loss': 3.299470247745514, 'learning_rate': 4.481891352316402e-05, 'epoch': 0.3108651886101588, 'step': 1726000}
INFO:transformers.trainer:{'loss': 3.2596675440073013, 'learning_rate': 4.481741262905138e-05, 'epoch': 0.3109552422569173, 'step': 1726500}
INFO:transformers.trainer:{'loss': 3.2115861444473266, 'learning_rate': 4.4815911734938744e-05, 'epoch': 0.31104529590367574, 'step': 1727000}
INFO:transformers.trainer:{'loss': 3.2921199190616606, 'learning_rate': 4.4814410840826096e-05, 'epoch': 0.3111353495504342, 'step': 1727500}
INFO:transformers.trainer:{'loss': 3.2870244629383087, 'learning_rate': 4.481290994671346e-05, 'epoch': 0.3112254031971926, 'step': 1728000}
INFO:transformers.trainer:{'loss': 3.338192405939102, 'learning_rate': 4.4811409052600814e-05, 'epoch': 0.31131545684395107, 'step': 1728500}
INFO:transformers.trainer:{'loss': 3.3258688168525694, 'learning_rate': 4.480990815848818e-05, 'epoch': 0.3114055104907095, 'step': 1729000}
INFO:transformers.trainer:{'loss': 3.232305407464504, 'learning_rate': 4.480840726437553e-05, 'epoch': 0.311495564137468, 'step': 1729500}
INFO:transformers.trainer:{'loss': 3.2388695240020753, 'learning_rate': 4.48069063702629e-05, 'epoch': 0.31158561778422644, 'step': 1730000}
INFO:transformers.trainer:{'loss': 3.2338253581523895, 'learning_rate': 4.480540547615025e-05, 'epoch': 0.31167567143098485, 'step': 1730500}
INFO:transformers.trainer:{'loss': 3.2411894071102143, 'learning_rate': 4.4803904582037616e-05, 'epoch': 0.3117657250777433, 'step': 1731000}
INFO:transformers.trainer:{'loss': 3.2487004425525665, 'learning_rate': 4.480240368792497e-05, 'epoch': 0.31185577872450176, 'step': 1731500}
INFO:transformers.trainer:{'loss': 3.338049140572548, 'learning_rate': 4.4800902793812334e-05, 'epoch': 0.3119458323712602, 'step': 1732000}
INFO:transformers.trainer:{'loss': 3.2623372102975847, 'learning_rate': 4.479940189969969e-05, 'epoch': 0.3120358860180186, 'step': 1732500}
INFO:transformers.trainer:{'loss': 3.310416349887848, 'learning_rate': 4.479790100558705e-05, 'epoch': 0.3121259396647771, 'step': 1733000}
INFO:transformers.trainer:{'loss': 3.2136054569482804, 'learning_rate': 4.4796400111474405e-05, 'epoch': 0.31221599331153554, 'step': 1733500}
INFO:transformers.trainer:{'loss': 3.253985768556595, 'learning_rate': 4.479489921736177e-05, 'epoch': 0.312306046958294, 'step': 1734000}
INFO:transformers.trainer:{'loss': 3.2821982820034026, 'learning_rate': 4.479339832324913e-05, 'epoch': 0.31239610060505246, 'step': 1734500}
INFO:transformers.trainer:{'loss': 3.268608325123787, 'learning_rate': 4.479189742913649e-05, 'epoch': 0.31248615425181087, 'step': 1735000}
INFO:transformers.trainer:{'loss': 3.2142276903390883, 'learning_rate': 4.479039653502385e-05, 'epoch': 0.3125762078985693, 'step': 1735500}
INFO:transformers.trainer:{'loss': 3.293127780199051, 'learning_rate': 4.478889564091121e-05, 'epoch': 0.3126662615453278, 'step': 1736000}
INFO:transformers.trainer:{'loss': 3.2503845915794374, 'learning_rate': 4.4787394746798566e-05, 'epoch': 0.31275631519208624, 'step': 1736500}
INFO:transformers.trainer:{'loss': 3.2937509129047395, 'learning_rate': 4.4785893852685925e-05, 'epoch': 0.3128463688388447, 'step': 1737000}
INFO:transformers.trainer:{'loss': 3.2701259288787843, 'learning_rate': 4.4784392958573284e-05, 'epoch': 0.3129364224856031, 'step': 1737500}
INFO:transformers.trainer:{'loss': 3.2721366647481918, 'learning_rate': 4.478289206446064e-05, 'epoch': 0.31302647613236156, 'step': 1738000}
INFO:transformers.trainer:{'loss': 3.2613187458515167, 'learning_rate': 4.4781391170348e-05, 'epoch': 0.31311652977912, 'step': 1738500}
INFO:transformers.trainer:{'loss': 3.2698345133066176, 'learning_rate': 4.477989027623536e-05, 'epoch': 0.3132065834258785, 'step': 1739000}
INFO:transformers.trainer:{'loss': 3.2831293454170227, 'learning_rate': 4.477838938212272e-05, 'epoch': 0.3132966370726369, 'step': 1739500}
INFO:transformers.trainer:{'loss': 3.1713250427246096, 'learning_rate': 4.477688848801008e-05, 'epoch': 0.31338669071939534, 'step': 1740000}
INFO:transformers.trainer:{'loss': 3.239736492037773, 'learning_rate': 4.477538759389744e-05, 'epoch': 0.3134767443661538, 'step': 1740500}
INFO:transformers.trainer:{'loss': 3.280744922876358, 'learning_rate': 4.47738866997848e-05, 'epoch': 0.31356679801291226, 'step': 1741000}
INFO:transformers.trainer:{'loss': 3.2390876804590225, 'learning_rate': 4.4772385805672156e-05, 'epoch': 0.3136568516596707, 'step': 1741500}
INFO:transformers.trainer:{'loss': 3.2274047435522077, 'learning_rate': 4.4770884911559515e-05, 'epoch': 0.3137469053064291, 'step': 1742000}
INFO:transformers.trainer:{'loss': 3.318460857629776, 'learning_rate': 4.4769384017446875e-05, 'epoch': 0.3138369589531876, 'step': 1742500}
INFO:transformers.trainer:{'loss': 3.2982325036525726, 'learning_rate': 4.4767883123334234e-05, 'epoch': 0.31392701259994604, 'step': 1743000}
INFO:transformers.trainer:{'loss': 3.2912873616218565, 'learning_rate': 4.476638222922159e-05, 'epoch': 0.3140170662467045, 'step': 1743500}
INFO:transformers.trainer:{'loss': 3.2439562985897066, 'learning_rate': 4.476488133510895e-05, 'epoch': 0.31410711989346296, 'step': 1744000}
INFO:transformers.trainer:{'loss': 3.3380611152648925, 'learning_rate': 4.476338044099631e-05, 'epoch': 0.31419717354022136, 'step': 1744500}
INFO:transformers.trainer:{'loss': 3.2426364583969116, 'learning_rate': 4.476187954688367e-05, 'epoch': 0.3142872271869798, 'step': 1745000}
INFO:transformers.trainer:{'loss': 3.2531315228939057, 'learning_rate': 4.476037865277103e-05, 'epoch': 0.3143772808337383, 'step': 1745500}
INFO:transformers.trainer:{'loss': 3.2672052810192107, 'learning_rate': 4.475887775865839e-05, 'epoch': 0.31446733448049674, 'step': 1746000}
INFO:transformers.trainer:{'loss': 3.2753060541152954, 'learning_rate': 4.475737686454575e-05, 'epoch': 0.31455738812725514, 'step': 1746500}
INFO:transformers.trainer:{'loss': 3.2966855931282044, 'learning_rate': 4.4755875970433106e-05, 'epoch': 0.3146474417740136, 'step': 1747000}
INFO:transformers.trainer:{'loss': 3.301865767598152, 'learning_rate': 4.4754375076320465e-05, 'epoch': 0.31473749542077206, 'step': 1747500}
INFO:transformers.trainer:{'loss': 3.2914999366998674, 'learning_rate': 4.4752874182207824e-05, 'epoch': 0.3148275490675305, 'step': 1748000}
INFO:transformers.trainer:{'loss': 3.2684367284774782, 'learning_rate': 4.475137328809519e-05, 'epoch': 0.314917602714289, 'step': 1748500}
INFO:transformers.trainer:{'loss': 3.244906097650528, 'learning_rate': 4.474987239398254e-05, 'epoch': 0.3150076563610474, 'step': 1749000}
INFO:transformers.trainer:{'loss': 3.259199624300003, 'learning_rate': 4.474837149986991e-05, 'epoch': 0.31509771000780584, 'step': 1749500}
INFO:transformers.trainer:{'loss': 3.357739722251892, 'learning_rate': 4.474687060575726e-05, 'epoch': 0.3151877636545643, 'step': 1750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.258197754383087, 'learning_rate': 4.4745369711644626e-05, 'epoch': 0.31527781730132276, 'step': 1750500}
INFO:transformers.trainer:{'loss': 3.2512294855117796, 'learning_rate': 4.474386881753198e-05, 'epoch': 0.31536787094808116, 'step': 1751000}
INFO:transformers.trainer:{'loss': 3.297430885076523, 'learning_rate': 4.4742367923419344e-05, 'epoch': 0.3154579245948396, 'step': 1751500}
INFO:transformers.trainer:{'loss': 3.205256898880005, 'learning_rate': 4.4740867029306696e-05, 'epoch': 0.3155479782415981, 'step': 1752000}
INFO:transformers.trainer:{'loss': 3.2811263407468796, 'learning_rate': 4.473936613519406e-05, 'epoch': 0.31563803188835654, 'step': 1752500}
INFO:transformers.trainer:{'loss': 3.2916058976650238, 'learning_rate': 4.4737865241081415e-05, 'epoch': 0.315728085535115, 'step': 1753000}
INFO:transformers.trainer:{'loss': 3.2946144323349, 'learning_rate': 4.473636434696878e-05, 'epoch': 0.3158181391818734, 'step': 1753500}
INFO:transformers.trainer:{'loss': 3.272856734275818, 'learning_rate': 4.473486345285613e-05, 'epoch': 0.31590819282863186, 'step': 1754000}
INFO:transformers.trainer:{'loss': 3.2544815909862517, 'learning_rate': 4.47333625587435e-05, 'epoch': 0.3159982464753903, 'step': 1754500}
INFO:transformers.trainer:{'loss': 3.192229509949684, 'learning_rate': 4.473186166463086e-05, 'epoch': 0.3160883001221488, 'step': 1755000}
INFO:transformers.trainer:{'loss': 3.2758249173164367, 'learning_rate': 4.4730360770518217e-05, 'epoch': 0.31617835376890724, 'step': 1755500}
INFO:transformers.trainer:{'loss': 3.2295739624500275, 'learning_rate': 4.4728859876405576e-05, 'epoch': 0.31626840741566564, 'step': 1756000}
INFO:transformers.trainer:{'loss': 3.2088661394119264, 'learning_rate': 4.4727358982292935e-05, 'epoch': 0.3163584610624241, 'step': 1756500}
INFO:transformers.trainer:{'loss': 3.269644247531891, 'learning_rate': 4.4725858088180294e-05, 'epoch': 0.31644851470918256, 'step': 1757000}
INFO:transformers.trainer:{'loss': 3.284299094438553, 'learning_rate': 4.472435719406765e-05, 'epoch': 0.316538568355941, 'step': 1757500}
INFO:transformers.trainer:{'loss': 3.2508853294849396, 'learning_rate': 4.472285629995501e-05, 'epoch': 0.3166286220026994, 'step': 1758000}
INFO:transformers.trainer:{'loss': 3.2334563674926757, 'learning_rate': 4.472135540584237e-05, 'epoch': 0.3167186756494579, 'step': 1758500}
INFO:transformers.trainer:{'loss': 3.239780102014542, 'learning_rate': 4.471985451172973e-05, 'epoch': 0.31680872929621634, 'step': 1759000}
INFO:transformers.trainer:{'loss': 3.326691343307495, 'learning_rate': 4.471835361761709e-05, 'epoch': 0.3168987829429748, 'step': 1759500}
INFO:transformers.trainer:{'loss': 3.2454164538383483, 'learning_rate': 4.471685272350445e-05, 'epoch': 0.31698883658973326, 'step': 1760000}
INFO:transformers.trainer:{'loss': 3.231128403186798, 'learning_rate': 4.471535182939181e-05, 'epoch': 0.31707889023649166, 'step': 1760500}
INFO:transformers.trainer:{'loss': 3.211090919494629, 'learning_rate': 4.4713850935279166e-05, 'epoch': 0.3171689438832501, 'step': 1761000}
INFO:transformers.trainer:{'loss': 3.2558436884880066, 'learning_rate': 4.471235004116653e-05, 'epoch': 0.3172589975300086, 'step': 1761500}
INFO:transformers.trainer:{'loss': 3.287912235021591, 'learning_rate': 4.4710849147053884e-05, 'epoch': 0.31734905117676704, 'step': 1762000}
INFO:transformers.trainer:{'loss': 3.3015863540172576, 'learning_rate': 4.470934825294124e-05, 'epoch': 0.3174391048235255, 'step': 1762500}
INFO:transformers.trainer:{'loss': 3.2810646889209747, 'learning_rate': 4.47078473588286e-05, 'epoch': 0.3175291584702839, 'step': 1763000}
INFO:transformers.trainer:{'loss': 3.2515516693592073, 'learning_rate': 4.470634646471596e-05, 'epoch': 0.31761921211704236, 'step': 1763500}
INFO:transformers.trainer:{'loss': 3.316616827726364, 'learning_rate': 4.470484557060332e-05, 'epoch': 0.3177092657638008, 'step': 1764000}
INFO:transformers.trainer:{'loss': 3.235078956127167, 'learning_rate': 4.470334467649068e-05, 'epoch': 0.3177993194105593, 'step': 1764500}
INFO:transformers.trainer:{'loss': 3.228536282300949, 'learning_rate': 4.470184378237804e-05, 'epoch': 0.3178893730573177, 'step': 1765000}
INFO:transformers.trainer:{'loss': 3.243034484386444, 'learning_rate': 4.47003428882654e-05, 'epoch': 0.31797942670407614, 'step': 1765500}
INFO:transformers.trainer:{'loss': 3.2554603654146193, 'learning_rate': 4.469884199415276e-05, 'epoch': 0.3180694803508346, 'step': 1766000}
INFO:transformers.trainer:{'loss': 3.3416538307666777, 'learning_rate': 4.4697341100040116e-05, 'epoch': 0.31815953399759306, 'step': 1766500}
INFO:transformers.trainer:{'loss': 3.2722923753261566, 'learning_rate': 4.4695840205927475e-05, 'epoch': 0.3182495876443515, 'step': 1767000}
INFO:transformers.trainer:{'loss': 3.3137431955337524, 'learning_rate': 4.4694339311814834e-05, 'epoch': 0.3183396412911099, 'step': 1767500}
INFO:transformers.trainer:{'loss': 3.2934026312828064, 'learning_rate': 4.469283841770219e-05, 'epoch': 0.3184296949378684, 'step': 1768000}
INFO:transformers.trainer:{'loss': 3.2628079016208646, 'learning_rate': 4.469133752358955e-05, 'epoch': 0.31851974858462684, 'step': 1768500}
INFO:transformers.trainer:{'loss': 3.2612032868862153, 'learning_rate': 4.468983662947692e-05, 'epoch': 0.3186098022313853, 'step': 1769000}
INFO:transformers.trainer:{'loss': 3.261320613384247, 'learning_rate': 4.468833573536427e-05, 'epoch': 0.3186998558781437, 'step': 1769500}
INFO:transformers.trainer:{'loss': 3.2526194460392, 'learning_rate': 4.4686834841251636e-05, 'epoch': 0.31878990952490216, 'step': 1770000}
INFO:transformers.trainer:{'loss': 3.2803926963806154, 'learning_rate': 4.468533394713899e-05, 'epoch': 0.3188799631716606, 'step': 1770500}
INFO:transformers.trainer:{'loss': 3.2481848773956297, 'learning_rate': 4.4683833053026354e-05, 'epoch': 0.3189700168184191, 'step': 1771000}
INFO:transformers.trainer:{'loss': 3.2228715586662293, 'learning_rate': 4.4682332158913706e-05, 'epoch': 0.31906007046517754, 'step': 1771500}
INFO:transformers.trainer:{'loss': 3.1917582862377167, 'learning_rate': 4.468083126480107e-05, 'epoch': 0.31915012411193594, 'step': 1772000}
INFO:transformers.trainer:{'loss': 3.254882964849472, 'learning_rate': 4.4679330370688424e-05, 'epoch': 0.3192401777586944, 'step': 1772500}
INFO:transformers.trainer:{'loss': 3.274362922668457, 'learning_rate': 4.467782947657579e-05, 'epoch': 0.31933023140545286, 'step': 1773000}
INFO:transformers.trainer:{'loss': 3.3066830723285676, 'learning_rate': 4.467632858246314e-05, 'epoch': 0.3194202850522113, 'step': 1773500}
INFO:transformers.trainer:{'loss': 3.178857864618301, 'learning_rate': 4.467482768835051e-05, 'epoch': 0.3195103386989698, 'step': 1774000}
INFO:transformers.trainer:{'loss': 3.2566979687213897, 'learning_rate': 4.467332679423786e-05, 'epoch': 0.3196003923457282, 'step': 1774500}
INFO:transformers.trainer:{'loss': 3.238272447824478, 'learning_rate': 4.4671825900125226e-05, 'epoch': 0.31969044599248664, 'step': 1775000}
INFO:transformers.trainer:{'loss': 3.2539063906669616, 'learning_rate': 4.4670325006012585e-05, 'epoch': 0.3197804996392451, 'step': 1775500}
INFO:transformers.trainer:{'loss': 3.2973873872756956, 'learning_rate': 4.4668824111899944e-05, 'epoch': 0.31987055328600356, 'step': 1776000}
INFO:transformers.trainer:{'loss': 3.2474838798046113, 'learning_rate': 4.4667323217787303e-05, 'epoch': 0.31996060693276196, 'step': 1776500}
INFO:transformers.trainer:{'loss': 3.3393846051692964, 'learning_rate': 4.466582232367466e-05, 'epoch': 0.3200506605795204, 'step': 1777000}
INFO:transformers.trainer:{'loss': 3.3068432903289793, 'learning_rate': 4.466432142956202e-05, 'epoch': 0.3201407142262789, 'step': 1777500}
INFO:transformers.trainer:{'loss': 3.246677350401878, 'learning_rate': 4.466282053544938e-05, 'epoch': 0.32023076787303734, 'step': 1778000}
INFO:transformers.trainer:{'loss': 3.258588971853256, 'learning_rate': 4.466131964133674e-05, 'epoch': 0.3203208215197958, 'step': 1778500}
INFO:transformers.trainer:{'loss': 3.270650834798813, 'learning_rate': 4.46598187472241e-05, 'epoch': 0.3204108751665542, 'step': 1779000}
INFO:transformers.trainer:{'loss': 3.2931904349327086, 'learning_rate': 4.465831785311146e-05, 'epoch': 0.32050092881331266, 'step': 1779500}
INFO:transformers.trainer:{'loss': 3.265115070581436, 'learning_rate': 4.465681695899882e-05, 'epoch': 0.3205909824600711, 'step': 1780000}
INFO:transformers.trainer:{'loss': 3.246201642513275, 'learning_rate': 4.4655316064886176e-05, 'epoch': 0.3206810361068296, 'step': 1780500}
INFO:transformers.trainer:{'loss': 3.2483774950504305, 'learning_rate': 4.4653815170773535e-05, 'epoch': 0.32077108975358803, 'step': 1781000}
INFO:transformers.trainer:{'loss': 3.2906166532039642, 'learning_rate': 4.4652314276660894e-05, 'epoch': 0.32086114340034644, 'step': 1781500}
INFO:transformers.trainer:{'loss': 3.2283620046377184, 'learning_rate': 4.465081338254825e-05, 'epoch': 0.3209511970471049, 'step': 1782000}
INFO:transformers.trainer:{'loss': 3.2204604785442354, 'learning_rate': 4.464931248843561e-05, 'epoch': 0.32104125069386336, 'step': 1782500}
INFO:transformers.trainer:{'loss': 3.3098549411296845, 'learning_rate': 4.464781159432298e-05, 'epoch': 0.3211313043406218, 'step': 1783000}
INFO:transformers.trainer:{'loss': 3.3149207537174226, 'learning_rate': 4.464631070021033e-05, 'epoch': 0.3212213579873802, 'step': 1783500}
INFO:transformers.trainer:{'loss': 3.237923504114151, 'learning_rate': 4.4644809806097696e-05, 'epoch': 0.3213114116341387, 'step': 1784000}
INFO:transformers.trainer:{'loss': 3.2661274354457857, 'learning_rate': 4.464330891198505e-05, 'epoch': 0.32140146528089714, 'step': 1784500}
INFO:transformers.trainer:{'loss': 3.3352372483015063, 'learning_rate': 4.4641808017872414e-05, 'epoch': 0.3214915189276556, 'step': 1785000}
INFO:transformers.trainer:{'loss': 3.263694487094879, 'learning_rate': 4.4640307123759766e-05, 'epoch': 0.32158157257441405, 'step': 1785500}
INFO:transformers.trainer:{'loss': 3.3361091306209563, 'learning_rate': 4.4638806229647125e-05, 'epoch': 0.32167162622117246, 'step': 1786000}
INFO:transformers.trainer:{'loss': 3.2834058578014376, 'learning_rate': 4.4637305335534484e-05, 'epoch': 0.3217616798679309, 'step': 1786500}
INFO:transformers.trainer:{'loss': 3.321788059473038, 'learning_rate': 4.4635804441421844e-05, 'epoch': 0.3218517335146894, 'step': 1787000}
INFO:transformers.trainer:{'loss': 3.358993547916412, 'learning_rate': 4.46343035473092e-05, 'epoch': 0.32194178716144783, 'step': 1787500}
INFO:transformers.trainer:{'loss': 3.362747484922409, 'learning_rate': 4.463280265319656e-05, 'epoch': 0.32203184080820624, 'step': 1788000}
INFO:transformers.trainer:{'loss': 3.2807653238773344, 'learning_rate': 4.463130175908392e-05, 'epoch': 0.3221218944549647, 'step': 1788500}
INFO:transformers.trainer:{'loss': 3.354075345993042, 'learning_rate': 4.462980086497128e-05, 'epoch': 0.32221194810172316, 'step': 1789000}
INFO:transformers.trainer:{'loss': 3.316195941448212, 'learning_rate': 4.4628299970858646e-05, 'epoch': 0.3223020017484816, 'step': 1789500}
INFO:transformers.trainer:{'loss': 3.3298549852371218, 'learning_rate': 4.4626799076746e-05, 'epoch': 0.3223920553952401, 'step': 1790000}
INFO:transformers.trainer:{'loss': 3.2770236268043518, 'learning_rate': 4.4625298182633364e-05, 'epoch': 0.3224821090419985, 'step': 1790500}
INFO:transformers.trainer:{'loss': 3.281434305667877, 'learning_rate': 4.4623797288520716e-05, 'epoch': 0.32257216268875694, 'step': 1791000}
INFO:transformers.trainer:{'loss': 3.2983023924827575, 'learning_rate': 4.462229639440808e-05, 'epoch': 0.3226622163355154, 'step': 1791500}
INFO:transformers.trainer:{'loss': 3.244500865697861, 'learning_rate': 4.4620795500295434e-05, 'epoch': 0.32275226998227385, 'step': 1792000}
INFO:transformers.trainer:{'loss': 3.231168151140213, 'learning_rate': 4.46192946061828e-05, 'epoch': 0.3228423236290323, 'step': 1792500}
INFO:transformers.trainer:{'loss': 3.2527286911010744, 'learning_rate': 4.461779371207015e-05, 'epoch': 0.3229323772757907, 'step': 1793000}
INFO:transformers.trainer:{'loss': 3.2530911753177643, 'learning_rate': 4.461629281795752e-05, 'epoch': 0.3230224309225492, 'step': 1793500}
INFO:transformers.trainer:{'loss': 3.2384851100444796, 'learning_rate': 4.461479192384487e-05, 'epoch': 0.32311248456930763, 'step': 1794000}
INFO:transformers.trainer:{'loss': 3.212400036096573, 'learning_rate': 4.4613291029732236e-05, 'epoch': 0.3232025382160661, 'step': 1794500}
INFO:transformers.trainer:{'loss': 3.2750105550289152, 'learning_rate': 4.461179013561959e-05, 'epoch': 0.3232925918628245, 'step': 1795000}
INFO:transformers.trainer:{'loss': 3.288798424243927, 'learning_rate': 4.4610289241506954e-05, 'epoch': 0.32338264550958296, 'step': 1795500}
INFO:transformers.trainer:{'loss': 3.314080581665039, 'learning_rate': 4.4608788347394306e-05, 'epoch': 0.3234726991563414, 'step': 1796000}
INFO:transformers.trainer:{'loss': 3.2719121853113173, 'learning_rate': 4.460728745328167e-05, 'epoch': 0.3235627528030999, 'step': 1796500}
INFO:transformers.trainer:{'loss': 3.2813980116844177, 'learning_rate': 4.460578655916903e-05, 'epoch': 0.32365280644985833, 'step': 1797000}
INFO:transformers.trainer:{'loss': 3.201974401473999, 'learning_rate': 4.460428566505639e-05, 'epoch': 0.32374286009661674, 'step': 1797500}
INFO:transformers.trainer:{'loss': 3.301914237141609, 'learning_rate': 4.460278477094375e-05, 'epoch': 0.3238329137433752, 'step': 1798000}
INFO:transformers.trainer:{'loss': 3.2729137939214707, 'learning_rate': 4.460128387683111e-05, 'epoch': 0.32392296739013365, 'step': 1798500}
INFO:transformers.trainer:{'loss': 3.2340886595249176, 'learning_rate': 4.459978298271847e-05, 'epoch': 0.3240130210368921, 'step': 1799000}
INFO:transformers.trainer:{'loss': 3.309107563495636, 'learning_rate': 4.4598282088605827e-05, 'epoch': 0.32410307468365057, 'step': 1799500}
INFO:transformers.trainer:{'loss': 3.247436790704727, 'learning_rate': 4.4596781194493186e-05, 'epoch': 0.324193128330409, 'step': 1800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2986090128421783, 'learning_rate': 4.4595280300380545e-05, 'epoch': 0.32428318197716743, 'step': 1800500}
INFO:transformers.trainer:{'loss': 3.255128345489502, 'learning_rate': 4.4593779406267904e-05, 'epoch': 0.3243732356239259, 'step': 1801000}
INFO:transformers.trainer:{'loss': 3.2575093200206755, 'learning_rate': 4.459227851215526e-05, 'epoch': 0.32446328927068435, 'step': 1801500}
INFO:transformers.trainer:{'loss': 3.256675377011299, 'learning_rate': 4.459077761804262e-05, 'epoch': 0.32455334291744276, 'step': 1802000}
INFO:transformers.trainer:{'loss': 3.2678532609939577, 'learning_rate': 4.458927672392998e-05, 'epoch': 0.3246433965642012, 'step': 1802500}
INFO:transformers.trainer:{'loss': 3.3152606763839723, 'learning_rate': 4.458777582981734e-05, 'epoch': 0.3247334502109597, 'step': 1803000}
INFO:transformers.trainer:{'loss': 3.2888796293735503, 'learning_rate': 4.4586274935704706e-05, 'epoch': 0.32482350385771813, 'step': 1803500}
INFO:transformers.trainer:{'loss': 3.227215576648712, 'learning_rate': 4.458477404159206e-05, 'epoch': 0.3249135575044766, 'step': 1804000}
INFO:transformers.trainer:{'loss': 3.2594781205654146, 'learning_rate': 4.4583273147479424e-05, 'epoch': 0.325003611151235, 'step': 1804500}
INFO:transformers.trainer:{'loss': 3.2408408360481262, 'learning_rate': 4.4581772253366776e-05, 'epoch': 0.32509366479799345, 'step': 1805000}
INFO:transformers.trainer:{'loss': 3.258722976922989, 'learning_rate': 4.458027135925414e-05, 'epoch': 0.3251837184447519, 'step': 1805500}
INFO:transformers.trainer:{'loss': 3.2749337463378905, 'learning_rate': 4.4578770465141494e-05, 'epoch': 0.32527377209151037, 'step': 1806000}
INFO:transformers.trainer:{'loss': 3.2766316726207734, 'learning_rate': 4.457726957102886e-05, 'epoch': 0.3253638257382688, 'step': 1806500}
INFO:transformers.trainer:{'loss': 3.266706992149353, 'learning_rate': 4.457576867691621e-05, 'epoch': 0.32545387938502723, 'step': 1807000}
INFO:transformers.trainer:{'loss': 3.2155281583070754, 'learning_rate': 4.457426778280358e-05, 'epoch': 0.3255439330317857, 'step': 1807500}
INFO:transformers.trainer:{'loss': 3.3025333800315857, 'learning_rate': 4.457276688869093e-05, 'epoch': 0.32563398667854415, 'step': 1808000}
INFO:transformers.trainer:{'loss': 3.2359215297698976, 'learning_rate': 4.4571265994578296e-05, 'epoch': 0.3257240403253026, 'step': 1808500}
INFO:transformers.trainer:{'loss': 3.27231023478508, 'learning_rate': 4.456976510046565e-05, 'epoch': 0.325814093972061, 'step': 1809000}
INFO:transformers.trainer:{'loss': 3.2412946254014967, 'learning_rate': 4.456826420635301e-05, 'epoch': 0.3259041476188195, 'step': 1809500}
INFO:transformers.trainer:{'loss': 3.2663616774082183, 'learning_rate': 4.456676331224037e-05, 'epoch': 0.32599420126557793, 'step': 1810000}
INFO:transformers.trainer:{'loss': 3.2595570964813234, 'learning_rate': 4.4565262418127726e-05, 'epoch': 0.3260842549123364, 'step': 1810500}
INFO:transformers.trainer:{'loss': 3.321438579082489, 'learning_rate': 4.456376152401509e-05, 'epoch': 0.32617430855909485, 'step': 1811000}
INFO:transformers.trainer:{'loss': 3.300103852272034, 'learning_rate': 4.4562260629902444e-05, 'epoch': 0.32626436220585325, 'step': 1811500}
INFO:transformers.trainer:{'loss': 3.2834819638729096, 'learning_rate': 4.456075973578981e-05, 'epoch': 0.3263544158526117, 'step': 1812000}
INFO:transformers.trainer:{'loss': 3.3124330973625185, 'learning_rate': 4.455925884167716e-05, 'epoch': 0.32644446949937017, 'step': 1812500}
INFO:transformers.trainer:{'loss': 3.2429295382499697, 'learning_rate': 4.455775794756453e-05, 'epoch': 0.32653452314612863, 'step': 1813000}
INFO:transformers.trainer:{'loss': 3.255863251209259, 'learning_rate': 4.455625705345188e-05, 'epoch': 0.32662457679288703, 'step': 1813500}
INFO:transformers.trainer:{'loss': 3.2618113050460815, 'learning_rate': 4.4554756159339246e-05, 'epoch': 0.3267146304396455, 'step': 1814000}
INFO:transformers.trainer:{'loss': 3.2681815543174744, 'learning_rate': 4.45532552652266e-05, 'epoch': 0.32680468408640395, 'step': 1814500}
INFO:transformers.trainer:{'loss': 3.3059748177528383, 'learning_rate': 4.4551754371113964e-05, 'epoch': 0.3268947377331624, 'step': 1815000}
INFO:transformers.trainer:{'loss': 3.2705899491310118, 'learning_rate': 4.4550253477001316e-05, 'epoch': 0.32698479137992087, 'step': 1815500}
INFO:transformers.trainer:{'loss': 3.1710412423610688, 'learning_rate': 4.454875258288868e-05, 'epoch': 0.3270748450266793, 'step': 1816000}
INFO:transformers.trainer:{'loss': 3.236026491641998, 'learning_rate': 4.4547251688776034e-05, 'epoch': 0.32716489867343773, 'step': 1816500}
INFO:transformers.trainer:{'loss': 3.2590813137292862, 'learning_rate': 4.45457507946634e-05, 'epoch': 0.3272549523201962, 'step': 1817000}
INFO:transformers.trainer:{'loss': 3.2498129801750184, 'learning_rate': 4.454424990055076e-05, 'epoch': 0.32734500596695465, 'step': 1817500}
INFO:transformers.trainer:{'loss': 3.300311489343643, 'learning_rate': 4.454274900643812e-05, 'epoch': 0.3274350596137131, 'step': 1818000}
INFO:transformers.trainer:{'loss': 3.2706298990249634, 'learning_rate': 4.454124811232548e-05, 'epoch': 0.3275251132604715, 'step': 1818500}
INFO:transformers.trainer:{'loss': 3.2381546099185945, 'learning_rate': 4.4539747218212836e-05, 'epoch': 0.32761516690722997, 'step': 1819000}
INFO:transformers.trainer:{'loss': 3.261616456627846, 'learning_rate': 4.4538246324100195e-05, 'epoch': 0.32770522055398843, 'step': 1819500}
INFO:transformers.trainer:{'loss': 3.2676836001873015, 'learning_rate': 4.4536745429987554e-05, 'epoch': 0.3277952742007469, 'step': 1820000}
INFO:transformers.trainer:{'loss': 3.2943073296546936, 'learning_rate': 4.4535244535874913e-05, 'epoch': 0.3278853278475053, 'step': 1820500}
INFO:transformers.trainer:{'loss': 3.2259183840751646, 'learning_rate': 4.453374364176227e-05, 'epoch': 0.32797538149426375, 'step': 1821000}
INFO:transformers.trainer:{'loss': 3.214512326478958, 'learning_rate': 4.453224274764963e-05, 'epoch': 0.3280654351410222, 'step': 1821500}
INFO:transformers.trainer:{'loss': 3.204803735375404, 'learning_rate': 4.453074185353699e-05, 'epoch': 0.32815548878778067, 'step': 1822000}
INFO:transformers.trainer:{'loss': 3.2090449850559235, 'learning_rate': 4.452924095942435e-05, 'epoch': 0.32824554243453913, 'step': 1822500}
INFO:transformers.trainer:{'loss': 3.266594398021698, 'learning_rate': 4.452774006531171e-05, 'epoch': 0.32833559608129753, 'step': 1823000}
INFO:transformers.trainer:{'loss': 3.18661421084404, 'learning_rate': 4.452623917119907e-05, 'epoch': 0.328425649728056, 'step': 1823500}
INFO:transformers.trainer:{'loss': 3.2685529820919035, 'learning_rate': 4.4524738277086434e-05, 'epoch': 0.32851570337481445, 'step': 1824000}
INFO:transformers.trainer:{'loss': 3.2709671113491057, 'learning_rate': 4.4523237382973786e-05, 'epoch': 0.3286057570215729, 'step': 1824500}
INFO:transformers.trainer:{'loss': 3.238644182920456, 'learning_rate': 4.452173648886115e-05, 'epoch': 0.3286958106683313, 'step': 1825000}
INFO:transformers.trainer:{'loss': 3.2286638276576998, 'learning_rate': 4.4520235594748504e-05, 'epoch': 0.32878586431508977, 'step': 1825500}
INFO:transformers.trainer:{'loss': 3.311643897652626, 'learning_rate': 4.451873470063587e-05, 'epoch': 0.32887591796184823, 'step': 1826000}
INFO:transformers.trainer:{'loss': 3.2848729133605956, 'learning_rate': 4.451723380652322e-05, 'epoch': 0.3289659716086067, 'step': 1826500}
INFO:transformers.trainer:{'loss': 3.2737082854509354, 'learning_rate': 4.451573291241059e-05, 'epoch': 0.32905602525536515, 'step': 1827000}
INFO:transformers.trainer:{'loss': 3.2355010423660278, 'learning_rate': 4.451423201829794e-05, 'epoch': 0.32914607890212355, 'step': 1827500}
INFO:transformers.trainer:{'loss': 3.22788414645195, 'learning_rate': 4.4512731124185306e-05, 'epoch': 0.329236132548882, 'step': 1828000}
INFO:transformers.trainer:{'loss': 3.297741300821304, 'learning_rate': 4.451123023007266e-05, 'epoch': 0.32932618619564047, 'step': 1828500}
INFO:transformers.trainer:{'loss': 3.179774074316025, 'learning_rate': 4.4509729335960024e-05, 'epoch': 0.32941623984239893, 'step': 1829000}
INFO:transformers.trainer:{'loss': 3.293672464609146, 'learning_rate': 4.4508228441847376e-05, 'epoch': 0.3295062934891574, 'step': 1829500}
INFO:transformers.trainer:{'loss': 3.3024386200904847, 'learning_rate': 4.450672754773474e-05, 'epoch': 0.3295963471359158, 'step': 1830000}
INFO:transformers.trainer:{'loss': 3.313572112083435, 'learning_rate': 4.4505226653622094e-05, 'epoch': 0.32968640078267425, 'step': 1830500}
INFO:transformers.trainer:{'loss': 3.300245745897293, 'learning_rate': 4.450372575950946e-05, 'epoch': 0.3297764544294327, 'step': 1831000}
INFO:transformers.trainer:{'loss': 3.230496022462845, 'learning_rate': 4.450222486539682e-05, 'epoch': 0.32986650807619117, 'step': 1831500}
INFO:transformers.trainer:{'loss': 3.232147171676159, 'learning_rate': 4.450072397128418e-05, 'epoch': 0.32995656172294957, 'step': 1832000}
INFO:transformers.trainer:{'loss': 3.2505144073963166, 'learning_rate': 4.449922307717154e-05, 'epoch': 0.33004661536970803, 'step': 1832500}
INFO:transformers.trainer:{'loss': 3.2393935387134554, 'learning_rate': 4.449772218305889e-05, 'epoch': 0.3301366690164665, 'step': 1833000}
INFO:transformers.trainer:{'loss': 3.3217623958587645, 'learning_rate': 4.4496221288946256e-05, 'epoch': 0.33022672266322495, 'step': 1833500}
INFO:transformers.trainer:{'loss': 3.25578119635582, 'learning_rate': 4.449472039483361e-05, 'epoch': 0.3303167763099834, 'step': 1834000}
INFO:transformers.trainer:{'loss': 3.309263135433197, 'learning_rate': 4.4493219500720974e-05, 'epoch': 0.3304068299567418, 'step': 1834500}
INFO:transformers.trainer:{'loss': 3.2358859037160874, 'learning_rate': 4.4491718606608326e-05, 'epoch': 0.33049688360350027, 'step': 1835000}
INFO:transformers.trainer:{'loss': 3.266637068986893, 'learning_rate': 4.449021771249569e-05, 'epoch': 0.33058693725025873, 'step': 1835500}
INFO:transformers.trainer:{'loss': 3.271693951487541, 'learning_rate': 4.4488716818383044e-05, 'epoch': 0.3306769908970172, 'step': 1836000}
INFO:transformers.trainer:{'loss': 3.270356546521187, 'learning_rate': 4.448721592427041e-05, 'epoch': 0.33076704454377565, 'step': 1836500}
INFO:transformers.trainer:{'loss': 3.2991861035823824, 'learning_rate': 4.448571503015776e-05, 'epoch': 0.33085709819053405, 'step': 1837000}
INFO:transformers.trainer:{'loss': 3.2957654178142546, 'learning_rate': 4.448421413604513e-05, 'epoch': 0.3309471518372925, 'step': 1837500}
INFO:transformers.trainer:{'loss': 3.3498050129413603, 'learning_rate': 4.448271324193249e-05, 'epoch': 0.33103720548405097, 'step': 1838000}
INFO:transformers.trainer:{'loss': 3.2470422360897064, 'learning_rate': 4.4481212347819846e-05, 'epoch': 0.3311272591308094, 'step': 1838500}
INFO:transformers.trainer:{'loss': 3.2726950533390045, 'learning_rate': 4.4479711453707205e-05, 'epoch': 0.33121731277756783, 'step': 1839000}
INFO:transformers.trainer:{'loss': 3.239891036987305, 'learning_rate': 4.4478210559594564e-05, 'epoch': 0.3313073664243263, 'step': 1839500}
INFO:transformers.trainer:{'loss': 3.2743071546554567, 'learning_rate': 4.447670966548192e-05, 'epoch': 0.33139742007108475, 'step': 1840000}
INFO:transformers.trainer:{'loss': 3.2301470563411714, 'learning_rate': 4.447520877136928e-05, 'epoch': 0.3314874737178432, 'step': 1840500}
INFO:transformers.trainer:{'loss': 3.231276324033737, 'learning_rate': 4.447370787725664e-05, 'epoch': 0.33157752736460167, 'step': 1841000}
INFO:transformers.trainer:{'loss': 3.3272914221286776, 'learning_rate': 4.4472206983144e-05, 'epoch': 0.33166758101136007, 'step': 1841500}
INFO:transformers.trainer:{'loss': 3.275401580095291, 'learning_rate': 4.447070608903136e-05, 'epoch': 0.3317576346581185, 'step': 1842000}
INFO:transformers.trainer:{'loss': 3.2163336637020112, 'learning_rate': 4.446920519491872e-05, 'epoch': 0.331847688304877, 'step': 1842500}
INFO:transformers.trainer:{'loss': 3.2157950055599214, 'learning_rate': 4.446770430080608e-05, 'epoch': 0.33193774195163545, 'step': 1843000}
INFO:transformers.trainer:{'loss': 3.2610964032411576, 'learning_rate': 4.4466203406693437e-05, 'epoch': 0.33202779559839385, 'step': 1843500}
INFO:transformers.trainer:{'loss': 3.30912571811676, 'learning_rate': 4.4464702512580796e-05, 'epoch': 0.3321178492451523, 'step': 1844000}
INFO:transformers.trainer:{'loss': 3.222264074921608, 'learning_rate': 4.4463201618468155e-05, 'epoch': 0.33220790289191077, 'step': 1844500}
INFO:transformers.trainer:{'loss': 3.1929810165166854, 'learning_rate': 4.4461700724355514e-05, 'epoch': 0.3322979565386692, 'step': 1845000}
INFO:transformers.trainer:{'loss': 3.2874051377773283, 'learning_rate': 4.446019983024288e-05, 'epoch': 0.3323880101854277, 'step': 1845500}
INFO:transformers.trainer:{'loss': 3.2798229119777678, 'learning_rate': 4.445869893613023e-05, 'epoch': 0.3324780638321861, 'step': 1846000}
INFO:transformers.trainer:{'loss': 3.245215118646622, 'learning_rate': 4.44571980420176e-05, 'epoch': 0.33256811747894455, 'step': 1846500}
INFO:transformers.trainer:{'loss': 3.1942835586071014, 'learning_rate': 4.445569714790495e-05, 'epoch': 0.332658171125703, 'step': 1847000}
INFO:transformers.trainer:{'loss': 3.192890533924103, 'learning_rate': 4.4454196253792316e-05, 'epoch': 0.33274822477246147, 'step': 1847500}
INFO:transformers.trainer:{'loss': 3.323663161993027, 'learning_rate': 4.445269535967967e-05, 'epoch': 0.3328382784192199, 'step': 1848000}
INFO:transformers.trainer:{'loss': 3.2996158158779143, 'learning_rate': 4.4451194465567034e-05, 'epoch': 0.3329283320659783, 'step': 1848500}
INFO:transformers.trainer:{'loss': 3.2194938840866087, 'learning_rate': 4.4449693571454386e-05, 'epoch': 0.3330183857127368, 'step': 1849000}
INFO:transformers.trainer:{'loss': 3.255746078014374, 'learning_rate': 4.444819267734175e-05, 'epoch': 0.33310843935949525, 'step': 1849500}
INFO:transformers.trainer:{'loss': 3.2650221631526946, 'learning_rate': 4.4446691783229104e-05, 'epoch': 0.3331984930062537, 'step': 1850000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1850000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1850000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1850000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1750000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.245269223332405, 'learning_rate': 4.444519088911647e-05, 'epoch': 0.3332885466530121, 'step': 1850500}
INFO:transformers.trainer:{'loss': 3.2746558644771575, 'learning_rate': 4.444368999500382e-05, 'epoch': 0.33337860029977057, 'step': 1851000}
INFO:transformers.trainer:{'loss': 3.2679918963909147, 'learning_rate': 4.444218910089119e-05, 'epoch': 0.333468653946529, 'step': 1851500}
INFO:transformers.trainer:{'loss': 3.255549778342247, 'learning_rate': 4.444068820677855e-05, 'epoch': 0.3335587075932875, 'step': 1852000}
INFO:transformers.trainer:{'loss': 3.3002106211185454, 'learning_rate': 4.4439187312665906e-05, 'epoch': 0.33364876124004594, 'step': 1852500}
INFO:transformers.trainer:{'loss': 3.271313652276993, 'learning_rate': 4.4437686418553265e-05, 'epoch': 0.33373881488680435, 'step': 1853000}
INFO:transformers.trainer:{'loss': 3.2599469792842863, 'learning_rate': 4.4436185524440624e-05, 'epoch': 0.3338288685335628, 'step': 1853500}
INFO:transformers.trainer:{'loss': 3.266136847496033, 'learning_rate': 4.443468463032798e-05, 'epoch': 0.33391892218032126, 'step': 1854000}
INFO:transformers.trainer:{'loss': 3.176138971209526, 'learning_rate': 4.443318373621534e-05, 'epoch': 0.3340089758270797, 'step': 1854500}
INFO:transformers.trainer:{'loss': 3.271041411399841, 'learning_rate': 4.44316828421027e-05, 'epoch': 0.3340990294738381, 'step': 1855000}
INFO:transformers.trainer:{'loss': 3.2546699147224425, 'learning_rate': 4.443018194799006e-05, 'epoch': 0.3341890831205966, 'step': 1855500}
INFO:transformers.trainer:{'loss': 3.243792615890503, 'learning_rate': 4.442868105387742e-05, 'epoch': 0.33427913676735505, 'step': 1856000}
INFO:transformers.trainer:{'loss': 3.2808194632530214, 'learning_rate': 4.442718015976478e-05, 'epoch': 0.3343691904141135, 'step': 1856500}
INFO:transformers.trainer:{'loss': 3.2544886429309843, 'learning_rate': 4.442567926565214e-05, 'epoch': 0.33445924406087196, 'step': 1857000}
INFO:transformers.trainer:{'loss': 3.260079745054245, 'learning_rate': 4.442417837153949e-05, 'epoch': 0.33454929770763037, 'step': 1857500}
INFO:transformers.trainer:{'loss': 3.1735087852478028, 'learning_rate': 4.4422677477426856e-05, 'epoch': 0.3346393513543888, 'step': 1858000}
INFO:transformers.trainer:{'loss': 3.1983512437343595, 'learning_rate': 4.4421176583314215e-05, 'epoch': 0.3347294050011473, 'step': 1858500}
INFO:transformers.trainer:{'loss': 3.3114597499370575, 'learning_rate': 4.4419675689201574e-05, 'epoch': 0.33481945864790574, 'step': 1859000}
INFO:transformers.trainer:{'loss': 3.2768511805534364, 'learning_rate': 4.441817479508893e-05, 'epoch': 0.3349095122946642, 'step': 1859500}
INFO:transformers.trainer:{'loss': 3.243463927030563, 'learning_rate': 4.441667390097629e-05, 'epoch': 0.3349995659414226, 'step': 1860000}
INFO:transformers.trainer:{'loss': 3.2188040506839752, 'learning_rate': 4.441517300686365e-05, 'epoch': 0.33508961958818106, 'step': 1860500}
INFO:transformers.trainer:{'loss': 3.239220458984375, 'learning_rate': 4.441367211275101e-05, 'epoch': 0.3351796732349395, 'step': 1861000}
INFO:transformers.trainer:{'loss': 3.2218248898983, 'learning_rate': 4.441217121863837e-05, 'epoch': 0.335269726881698, 'step': 1861500}
INFO:transformers.trainer:{'loss': 3.238581924676895, 'learning_rate': 4.441067032452573e-05, 'epoch': 0.3353597805284564, 'step': 1862000}
INFO:transformers.trainer:{'loss': 3.2912956174612047, 'learning_rate': 4.440916943041309e-05, 'epoch': 0.33544983417521484, 'step': 1862500}
INFO:transformers.trainer:{'loss': 3.1982384142875673, 'learning_rate': 4.4407668536300446e-05, 'epoch': 0.3355398878219733, 'step': 1863000}
INFO:transformers.trainer:{'loss': 3.2079932756423952, 'learning_rate': 4.4406167642187805e-05, 'epoch': 0.33562994146873176, 'step': 1863500}
INFO:transformers.trainer:{'loss': 3.2303628716468813, 'learning_rate': 4.4404666748075164e-05, 'epoch': 0.3357199951154902, 'step': 1864000}
INFO:transformers.trainer:{'loss': 3.2848292553424834, 'learning_rate': 4.4403165853962523e-05, 'epoch': 0.3358100487622486, 'step': 1864500}
INFO:transformers.trainer:{'loss': 3.2304206953048706, 'learning_rate': 4.440166495984988e-05, 'epoch': 0.3359001024090071, 'step': 1865000}
INFO:transformers.trainer:{'loss': 3.256232519388199, 'learning_rate': 4.440016406573724e-05, 'epoch': 0.33599015605576554, 'step': 1865500}
INFO:transformers.trainer:{'loss': 3.260937870979309, 'learning_rate': 4.439866317162461e-05, 'epoch': 0.336080209702524, 'step': 1866000}
INFO:transformers.trainer:{'loss': 3.2701974890232086, 'learning_rate': 4.439716227751196e-05, 'epoch': 0.33617026334928246, 'step': 1866500}
INFO:transformers.trainer:{'loss': 3.242065418958664, 'learning_rate': 4.4395661383399325e-05, 'epoch': 0.33626031699604086, 'step': 1867000}
INFO:transformers.trainer:{'loss': 3.2090549502372743, 'learning_rate': 4.439416048928668e-05, 'epoch': 0.3363503706427993, 'step': 1867500}
INFO:transformers.trainer:{'loss': 3.2337993848323823, 'learning_rate': 4.4392659595174044e-05, 'epoch': 0.3364404242895578, 'step': 1868000}
INFO:transformers.trainer:{'loss': 3.291962602376938, 'learning_rate': 4.4391158701061396e-05, 'epoch': 0.33653047793631624, 'step': 1868500}
INFO:transformers.trainer:{'loss': 3.250086017847061, 'learning_rate': 4.438965780694876e-05, 'epoch': 0.33662053158307464, 'step': 1869000}
INFO:transformers.trainer:{'loss': 3.2793556028604507, 'learning_rate': 4.4388156912836114e-05, 'epoch': 0.3367105852298331, 'step': 1869500}
INFO:transformers.trainer:{'loss': 3.249285775184631, 'learning_rate': 4.438665601872348e-05, 'epoch': 0.33680063887659156, 'step': 1870000}
INFO:transformers.trainer:{'loss': 3.2177762820720672, 'learning_rate': 4.438515512461083e-05, 'epoch': 0.33689069252335, 'step': 1870500}
INFO:transformers.trainer:{'loss': 3.257037369966507, 'learning_rate': 4.43836542304982e-05, 'epoch': 0.3369807461701085, 'step': 1871000}
INFO:transformers.trainer:{'loss': 3.258401575088501, 'learning_rate': 4.438215333638555e-05, 'epoch': 0.3370707998168669, 'step': 1871500}
INFO:transformers.trainer:{'loss': 3.205768314242363, 'learning_rate': 4.4380652442272916e-05, 'epoch': 0.33716085346362534, 'step': 1872000}
INFO:transformers.trainer:{'loss': 3.265835902452469, 'learning_rate': 4.4379151548160275e-05, 'epoch': 0.3372509071103838, 'step': 1872500}
INFO:transformers.trainer:{'loss': 3.268263084411621, 'learning_rate': 4.4377650654047634e-05, 'epoch': 0.33734096075714226, 'step': 1873000}
INFO:transformers.trainer:{'loss': 3.3044547860622404, 'learning_rate': 4.437614975993499e-05, 'epoch': 0.33743101440390066, 'step': 1873500}
INFO:transformers.trainer:{'loss': 3.2259499213695526, 'learning_rate': 4.437464886582235e-05, 'epoch': 0.3375210680506591, 'step': 1874000}
INFO:transformers.trainer:{'loss': 3.1865135657787325, 'learning_rate': 4.437314797170971e-05, 'epoch': 0.3376111216974176, 'step': 1874500}
INFO:transformers.trainer:{'loss': 3.2871088967323305, 'learning_rate': 4.437164707759707e-05, 'epoch': 0.33770117534417604, 'step': 1875000}
INFO:transformers.trainer:{'loss': 3.2146612842082978, 'learning_rate': 4.437014618348443e-05, 'epoch': 0.3377912289909345, 'step': 1875500}
INFO:transformers.trainer:{'loss': 3.2799922971725466, 'learning_rate': 4.436864528937179e-05, 'epoch': 0.3378812826376929, 'step': 1876000}
INFO:transformers.trainer:{'loss': 3.248189740896225, 'learning_rate': 4.436714439525915e-05, 'epoch': 0.33797133628445136, 'step': 1876500}
INFO:transformers.trainer:{'loss': 3.243944958925247, 'learning_rate': 4.4365643501146506e-05, 'epoch': 0.3380613899312098, 'step': 1877000}
INFO:transformers.trainer:{'loss': 3.2266319556236267, 'learning_rate': 4.4364142607033865e-05, 'epoch': 0.3381514435779683, 'step': 1877500}
INFO:transformers.trainer:{'loss': 3.2463163845539094, 'learning_rate': 4.4362641712921225e-05, 'epoch': 0.33824149722472674, 'step': 1878000}
INFO:transformers.trainer:{'loss': 3.2430418119430544, 'learning_rate': 4.4361140818808584e-05, 'epoch': 0.33833155087148514, 'step': 1878500}
INFO:transformers.trainer:{'loss': 3.2940552150011064, 'learning_rate': 4.435963992469594e-05, 'epoch': 0.3384216045182436, 'step': 1879000}
INFO:transformers.trainer:{'loss': 3.2702170033454894, 'learning_rate': 4.43581390305833e-05, 'epoch': 0.33851165816500206, 'step': 1879500}
INFO:transformers.trainer:{'loss': 3.210216952562332, 'learning_rate': 4.435663813647066e-05, 'epoch': 0.3386017118117605, 'step': 1880000}
INFO:transformers.trainer:{'loss': 3.2257576439380644, 'learning_rate': 4.435513724235802e-05, 'epoch': 0.3386917654585189, 'step': 1880500}
INFO:transformers.trainer:{'loss': 3.2462472178936004, 'learning_rate': 4.435363634824538e-05, 'epoch': 0.3387818191052774, 'step': 1881000}
INFO:transformers.trainer:{'loss': 3.302731538057327, 'learning_rate': 4.435213545413274e-05, 'epoch': 0.33887187275203584, 'step': 1881500}
INFO:transformers.trainer:{'loss': 3.2004188723564146, 'learning_rate': 4.43506345600201e-05, 'epoch': 0.3389619263987943, 'step': 1882000}
INFO:transformers.trainer:{'loss': 3.2479573566913604, 'learning_rate': 4.4349133665907456e-05, 'epoch': 0.33905198004555276, 'step': 1882500}
INFO:transformers.trainer:{'loss': 3.2760091230869293, 'learning_rate': 4.4347632771794815e-05, 'epoch': 0.33914203369231116, 'step': 1883000}
INFO:transformers.trainer:{'loss': 3.2251047599315643, 'learning_rate': 4.4346131877682174e-05, 'epoch': 0.3392320873390696, 'step': 1883500}
INFO:transformers.trainer:{'loss': 3.2398597099781035, 'learning_rate': 4.434463098356953e-05, 'epoch': 0.3393221409858281, 'step': 1884000}
INFO:transformers.trainer:{'loss': 3.3133503963947297, 'learning_rate': 4.434313008945689e-05, 'epoch': 0.33941219463258654, 'step': 1884500}
INFO:transformers.trainer:{'loss': 3.257048178434372, 'learning_rate': 4.434162919534425e-05, 'epoch': 0.339502248279345, 'step': 1885000}
INFO:transformers.trainer:{'loss': 3.270059700012207, 'learning_rate': 4.434012830123161e-05, 'epoch': 0.3395923019261034, 'step': 1885500}
INFO:transformers.trainer:{'loss': 3.290413241863251, 'learning_rate': 4.433862740711897e-05, 'epoch': 0.33968235557286186, 'step': 1886000}
INFO:transformers.trainer:{'loss': 3.259630263566971, 'learning_rate': 4.4337126513006335e-05, 'epoch': 0.3397724092196203, 'step': 1886500}
INFO:transformers.trainer:{'loss': 3.248525308609009, 'learning_rate': 4.433562561889369e-05, 'epoch': 0.3398624628663788, 'step': 1887000}
INFO:transformers.trainer:{'loss': 3.268534583091736, 'learning_rate': 4.433412472478105e-05, 'epoch': 0.3399525165131372, 'step': 1887500}
INFO:transformers.trainer:{'loss': 3.2994250507354734, 'learning_rate': 4.4332623830668406e-05, 'epoch': 0.34004257015989564, 'step': 1888000}
INFO:transformers.trainer:{'loss': 3.2473984355926513, 'learning_rate': 4.433112293655577e-05, 'epoch': 0.3401326238066541, 'step': 1888500}
INFO:transformers.trainer:{'loss': 3.2150731208324435, 'learning_rate': 4.4329622042443124e-05, 'epoch': 0.34022267745341256, 'step': 1889000}
INFO:transformers.trainer:{'loss': 3.2341019530296324, 'learning_rate': 4.432812114833049e-05, 'epoch': 0.340312731100171, 'step': 1889500}
INFO:transformers.trainer:{'loss': 3.2711944613456727, 'learning_rate': 4.432662025421784e-05, 'epoch': 0.3404027847469294, 'step': 1890000}
INFO:transformers.trainer:{'loss': 3.26928449177742, 'learning_rate': 4.432511936010521e-05, 'epoch': 0.3404928383936879, 'step': 1890500}
INFO:transformers.trainer:{'loss': 3.2283842175006865, 'learning_rate': 4.432361846599256e-05, 'epoch': 0.34058289204044634, 'step': 1891000}
INFO:transformers.trainer:{'loss': 3.2358796083927155, 'learning_rate': 4.4322117571879926e-05, 'epoch': 0.3406729456872048, 'step': 1891500}
INFO:transformers.trainer:{'loss': 3.198886439323425, 'learning_rate': 4.432061667776728e-05, 'epoch': 0.3407629993339632, 'step': 1892000}
INFO:transformers.trainer:{'loss': 3.3286141349077223, 'learning_rate': 4.4319115783654644e-05, 'epoch': 0.34085305298072166, 'step': 1892500}
INFO:transformers.trainer:{'loss': 3.2269440257549284, 'learning_rate': 4.4317614889541996e-05, 'epoch': 0.3409431066274801, 'step': 1893000}
INFO:transformers.trainer:{'loss': 3.2551487040519715, 'learning_rate': 4.431611399542936e-05, 'epoch': 0.3410331602742386, 'step': 1893500}
INFO:transformers.trainer:{'loss': 3.2494978947639463, 'learning_rate': 4.431461310131672e-05, 'epoch': 0.34112321392099704, 'step': 1894000}
INFO:transformers.trainer:{'loss': 3.2859308750629426, 'learning_rate': 4.431311220720408e-05, 'epoch': 0.34121326756775544, 'step': 1894500}
INFO:transformers.trainer:{'loss': 3.223454313993454, 'learning_rate': 4.431161131309144e-05, 'epoch': 0.3413033212145139, 'step': 1895000}
INFO:transformers.trainer:{'loss': 3.206908437728882, 'learning_rate': 4.43101104189788e-05, 'epoch': 0.34139337486127236, 'step': 1895500}
INFO:transformers.trainer:{'loss': 3.3388299251794815, 'learning_rate': 4.430860952486616e-05, 'epoch': 0.3414834285080308, 'step': 1896000}
INFO:transformers.trainer:{'loss': 3.271585119962692, 'learning_rate': 4.4307108630753516e-05, 'epoch': 0.3415734821547893, 'step': 1896500}
INFO:transformers.trainer:{'loss': 3.2362152508497237, 'learning_rate': 4.4305607736640875e-05, 'epoch': 0.3416635358015477, 'step': 1897000}
INFO:transformers.trainer:{'loss': 3.223094089984894, 'learning_rate': 4.4304106842528234e-05, 'epoch': 0.34175358944830614, 'step': 1897500}
INFO:transformers.trainer:{'loss': 3.269028557538986, 'learning_rate': 4.430260594841559e-05, 'epoch': 0.3418436430950646, 'step': 1898000}
INFO:transformers.trainer:{'loss': 3.2827835955619813, 'learning_rate': 4.430110505430295e-05, 'epoch': 0.34193369674182306, 'step': 1898500}
INFO:transformers.trainer:{'loss': 3.2490847685337068, 'learning_rate': 4.429960416019031e-05, 'epoch': 0.34202375038858146, 'step': 1899000}
INFO:transformers.trainer:{'loss': 3.258298640012741, 'learning_rate': 4.429810326607767e-05, 'epoch': 0.3421138040353399, 'step': 1899500}
INFO:transformers.trainer:{'loss': 3.2594916970729826, 'learning_rate': 4.429660237196503e-05, 'epoch': 0.3422038576820984, 'step': 1900000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1900000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1900000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1900000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1800000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2645643582344057, 'learning_rate': 4.429510147785239e-05, 'epoch': 0.34229391132885684, 'step': 1900500}
INFO:transformers.trainer:{'loss': 3.2380516102313996, 'learning_rate': 4.429360058373975e-05, 'epoch': 0.3423839649756153, 'step': 1901000}
INFO:transformers.trainer:{'loss': 3.280477121591568, 'learning_rate': 4.429209968962711e-05, 'epoch': 0.3424740186223737, 'step': 1901500}
INFO:transformers.trainer:{'loss': 3.1886404838562012, 'learning_rate': 4.4290598795514466e-05, 'epoch': 0.34256407226913216, 'step': 1902000}
INFO:transformers.trainer:{'loss': 3.259681128144264, 'learning_rate': 4.4289097901401825e-05, 'epoch': 0.3426541259158906, 'step': 1902500}
INFO:transformers.trainer:{'loss': 3.214010093688965, 'learning_rate': 4.4287597007289184e-05, 'epoch': 0.3427441795626491, 'step': 1903000}
INFO:transformers.trainer:{'loss': 3.2674433448314666, 'learning_rate': 4.428609611317654e-05, 'epoch': 0.34283423320940754, 'step': 1903500}
INFO:transformers.trainer:{'loss': 3.284943216562271, 'learning_rate': 4.42845952190639e-05, 'epoch': 0.34292428685616594, 'step': 1904000}
INFO:transformers.trainer:{'loss': 3.29132785987854, 'learning_rate': 4.428309432495126e-05, 'epoch': 0.3430143405029244, 'step': 1904500}
INFO:transformers.trainer:{'loss': 3.25917774605751, 'learning_rate': 4.428159343083862e-05, 'epoch': 0.34310439414968286, 'step': 1905000}
INFO:transformers.trainer:{'loss': 3.2121003217697144, 'learning_rate': 4.428009253672598e-05, 'epoch': 0.3431944477964413, 'step': 1905500}
INFO:transformers.trainer:{'loss': 3.2496849505901335, 'learning_rate': 4.427859164261334e-05, 'epoch': 0.3432845014431997, 'step': 1906000}
INFO:transformers.trainer:{'loss': 3.2489274019002914, 'learning_rate': 4.42770907485007e-05, 'epoch': 0.3433745550899582, 'step': 1906500}
INFO:transformers.trainer:{'loss': 3.2514488739967344, 'learning_rate': 4.4275589854388056e-05, 'epoch': 0.34346460873671664, 'step': 1907000}
INFO:transformers.trainer:{'loss': 3.23343510389328, 'learning_rate': 4.4274088960275415e-05, 'epoch': 0.3435546623834751, 'step': 1907500}
INFO:transformers.trainer:{'loss': 3.249751340150833, 'learning_rate': 4.427258806616278e-05, 'epoch': 0.34364471603023355, 'step': 1908000}
INFO:transformers.trainer:{'loss': 3.263367885351181, 'learning_rate': 4.427108717205013e-05, 'epoch': 0.34373476967699196, 'step': 1908500}
INFO:transformers.trainer:{'loss': 3.2497757503986358, 'learning_rate': 4.42695862779375e-05, 'epoch': 0.3438248233237504, 'step': 1909000}
INFO:transformers.trainer:{'loss': 3.2562026648521423, 'learning_rate': 4.426808538382485e-05, 'epoch': 0.3439148769705089, 'step': 1909500}
INFO:transformers.trainer:{'loss': 3.225788510322571, 'learning_rate': 4.426658448971222e-05, 'epoch': 0.34400493061726733, 'step': 1910000}
INFO:transformers.trainer:{'loss': 3.2836417989730835, 'learning_rate': 4.426508359559957e-05, 'epoch': 0.34409498426402574, 'step': 1910500}
INFO:transformers.trainer:{'loss': 3.224613131523132, 'learning_rate': 4.4263582701486935e-05, 'epoch': 0.3441850379107842, 'step': 1911000}
INFO:transformers.trainer:{'loss': 3.2710382764339445, 'learning_rate': 4.426208180737429e-05, 'epoch': 0.34427509155754266, 'step': 1911500}
INFO:transformers.trainer:{'loss': 3.2513666377067567, 'learning_rate': 4.4260580913261653e-05, 'epoch': 0.3443651452043011, 'step': 1912000}
INFO:transformers.trainer:{'loss': 3.2198510130643845, 'learning_rate': 4.4259080019149006e-05, 'epoch': 0.3444551988510596, 'step': 1912500}
INFO:transformers.trainer:{'loss': 3.2495674465894697, 'learning_rate': 4.425757912503637e-05, 'epoch': 0.344545252497818, 'step': 1913000}
INFO:transformers.trainer:{'loss': 3.2750899101495743, 'learning_rate': 4.4256078230923724e-05, 'epoch': 0.34463530614457644, 'step': 1913500}
INFO:transformers.trainer:{'loss': 3.2906441998481752, 'learning_rate': 4.425457733681109e-05, 'epoch': 0.3447253597913349, 'step': 1914000}
INFO:transformers.trainer:{'loss': 3.2855138647556306, 'learning_rate': 4.425307644269845e-05, 'epoch': 0.34481541343809335, 'step': 1914500}
INFO:transformers.trainer:{'loss': 3.2151572504043577, 'learning_rate': 4.425157554858581e-05, 'epoch': 0.3449054670848518, 'step': 1915000}
INFO:transformers.trainer:{'loss': 3.260448613166809, 'learning_rate': 4.425007465447317e-05, 'epoch': 0.3449955207316102, 'step': 1915500}
INFO:transformers.trainer:{'loss': 3.205619759559631, 'learning_rate': 4.4248573760360526e-05, 'epoch': 0.3450855743783687, 'step': 1916000}
INFO:transformers.trainer:{'loss': 3.270906394958496, 'learning_rate': 4.4247072866247885e-05, 'epoch': 0.34517562802512713, 'step': 1916500}
INFO:transformers.trainer:{'loss': 3.253099808692932, 'learning_rate': 4.4245571972135244e-05, 'epoch': 0.3452656816718856, 'step': 1917000}
INFO:transformers.trainer:{'loss': 3.26198167181015, 'learning_rate': 4.42440710780226e-05, 'epoch': 0.345355735318644, 'step': 1917500}
INFO:transformers.trainer:{'loss': 3.262777057170868, 'learning_rate': 4.424257018390996e-05, 'epoch': 0.34544578896540246, 'step': 1918000}
INFO:transformers.trainer:{'loss': 3.2335369185209273, 'learning_rate': 4.424106928979732e-05, 'epoch': 0.3455358426121609, 'step': 1918500}
INFO:transformers.trainer:{'loss': 3.2644046382904053, 'learning_rate': 4.423956839568468e-05, 'epoch': 0.3456258962589194, 'step': 1919000}
INFO:transformers.trainer:{'loss': 3.2468252067565917, 'learning_rate': 4.423806750157204e-05, 'epoch': 0.34571594990567783, 'step': 1919500}
INFO:transformers.trainer:{'loss': 3.2190726698637007, 'learning_rate': 4.42365666074594e-05, 'epoch': 0.34580600355243624, 'step': 1920000}
INFO:transformers.trainer:{'loss': 3.2568393089771273, 'learning_rate': 4.423506571334676e-05, 'epoch': 0.3458960571991947, 'step': 1920500}
INFO:transformers.trainer:{'loss': 3.302791161060333, 'learning_rate': 4.4233564819234116e-05, 'epoch': 0.34598611084595315, 'step': 1921000}
INFO:transformers.trainer:{'loss': 3.2153899627923965, 'learning_rate': 4.4232063925121475e-05, 'epoch': 0.3460761644927116, 'step': 1921500}
INFO:transformers.trainer:{'loss': 3.2833606061935425, 'learning_rate': 4.4230563031008834e-05, 'epoch': 0.34616621813947007, 'step': 1922000}
INFO:transformers.trainer:{'loss': 3.282005876302719, 'learning_rate': 4.4229062136896194e-05, 'epoch': 0.3462562717862285, 'step': 1922500}
INFO:transformers.trainer:{'loss': 3.3123690197467806, 'learning_rate': 4.422756124278355e-05, 'epoch': 0.34634632543298693, 'step': 1923000}
INFO:transformers.trainer:{'loss': 3.2410137823820113, 'learning_rate': 4.422606034867091e-05, 'epoch': 0.3464363790797454, 'step': 1923500}
INFO:transformers.trainer:{'loss': 3.2093473954200746, 'learning_rate': 4.422455945455827e-05, 'epoch': 0.34652643272650385, 'step': 1924000}
INFO:transformers.trainer:{'loss': 3.243679568052292, 'learning_rate': 4.422305856044563e-05, 'epoch': 0.34661648637326226, 'step': 1924500}
INFO:transformers.trainer:{'loss': 3.2183255581855774, 'learning_rate': 4.422155766633299e-05, 'epoch': 0.3467065400200207, 'step': 1925000}
INFO:transformers.trainer:{'loss': 3.3239449722766876, 'learning_rate': 4.422005677222035e-05, 'epoch': 0.3467965936667792, 'step': 1925500}
INFO:transformers.trainer:{'loss': 3.30862335395813, 'learning_rate': 4.421855587810771e-05, 'epoch': 0.34688664731353763, 'step': 1926000}
INFO:transformers.trainer:{'loss': 3.295000501036644, 'learning_rate': 4.4217054983995066e-05, 'epoch': 0.3469767009602961, 'step': 1926500}
INFO:transformers.trainer:{'loss': 3.23241122341156, 'learning_rate': 4.4215554089882425e-05, 'epoch': 0.3470667546070545, 'step': 1927000}
INFO:transformers.trainer:{'loss': 3.2561734936237334, 'learning_rate': 4.4214053195769784e-05, 'epoch': 0.34715680825381295, 'step': 1927500}
INFO:transformers.trainer:{'loss': 3.2196609407365324, 'learning_rate': 4.421255230165714e-05, 'epoch': 0.3472468619005714, 'step': 1928000}
INFO:transformers.trainer:{'loss': 3.2692468881607057, 'learning_rate': 4.421105140754451e-05, 'epoch': 0.34733691554732987, 'step': 1928500}
INFO:transformers.trainer:{'loss': 3.2768036046028137, 'learning_rate': 4.420955051343186e-05, 'epoch': 0.3474269691940883, 'step': 1929000}
INFO:transformers.trainer:{'loss': 3.2144851018190383, 'learning_rate': 4.420804961931923e-05, 'epoch': 0.34751702284084673, 'step': 1929500}
INFO:transformers.trainer:{'loss': 3.252962479829788, 'learning_rate': 4.420654872520658e-05, 'epoch': 0.3476070764876052, 'step': 1930000}
INFO:transformers.trainer:{'loss': 3.2708976917266845, 'learning_rate': 4.4205047831093945e-05, 'epoch': 0.34769713013436365, 'step': 1930500}
INFO:transformers.trainer:{'loss': 3.270549899458885, 'learning_rate': 4.42035469369813e-05, 'epoch': 0.3477871837811221, 'step': 1931000}
INFO:transformers.trainer:{'loss': 3.284226147413254, 'learning_rate': 4.420204604286866e-05, 'epoch': 0.3478772374278805, 'step': 1931500}
INFO:transformers.trainer:{'loss': 3.203652299404144, 'learning_rate': 4.4200545148756015e-05, 'epoch': 0.347967291074639, 'step': 1932000}
INFO:transformers.trainer:{'loss': 3.27383882856369, 'learning_rate': 4.419904425464338e-05, 'epoch': 0.34805734472139743, 'step': 1932500}
INFO:transformers.trainer:{'loss': 3.300087438583374, 'learning_rate': 4.4197543360530734e-05, 'epoch': 0.3481473983681559, 'step': 1933000}
INFO:transformers.trainer:{'loss': 3.1905444774627685, 'learning_rate': 4.41960424664181e-05, 'epoch': 0.34823745201491435, 'step': 1933500}
INFO:transformers.trainer:{'loss': 3.277310975790024, 'learning_rate': 4.419454157230545e-05, 'epoch': 0.34832750566167275, 'step': 1934000}
INFO:transformers.trainer:{'loss': 3.2524768068790437, 'learning_rate': 4.419304067819282e-05, 'epoch': 0.3484175593084312, 'step': 1934500}
INFO:transformers.trainer:{'loss': 3.215692671060562, 'learning_rate': 4.4191539784080177e-05, 'epoch': 0.34850761295518967, 'step': 1935000}
INFO:transformers.trainer:{'loss': 3.207954066514969, 'learning_rate': 4.4190038889967536e-05, 'epoch': 0.34859766660194813, 'step': 1935500}
INFO:transformers.trainer:{'loss': 3.221944658398628, 'learning_rate': 4.4188537995854895e-05, 'epoch': 0.34868772024870653, 'step': 1936000}
INFO:transformers.trainer:{'loss': 3.253582004070282, 'learning_rate': 4.4187037101742254e-05, 'epoch': 0.348777773895465, 'step': 1936500}
INFO:transformers.trainer:{'loss': 3.230706431865692, 'learning_rate': 4.418553620762961e-05, 'epoch': 0.34886782754222345, 'step': 1937000}
INFO:transformers.trainer:{'loss': 3.2284032135009766, 'learning_rate': 4.418403531351697e-05, 'epoch': 0.3489578811889819, 'step': 1937500}
INFO:transformers.trainer:{'loss': 3.234013360977173, 'learning_rate': 4.418253441940433e-05, 'epoch': 0.34904793483574037, 'step': 1938000}
INFO:transformers.trainer:{'loss': 3.207070454120636, 'learning_rate': 4.418103352529169e-05, 'epoch': 0.3491379884824988, 'step': 1938500}
INFO:transformers.trainer:{'loss': 3.224909461736679, 'learning_rate': 4.417953263117905e-05, 'epoch': 0.34922804212925723, 'step': 1939000}
INFO:transformers.trainer:{'loss': 3.2939274725914003, 'learning_rate': 4.417803173706641e-05, 'epoch': 0.3493180957760157, 'step': 1939500}
INFO:transformers.trainer:{'loss': 3.2094151029586793, 'learning_rate': 4.417653084295377e-05, 'epoch': 0.34940814942277415, 'step': 1940000}
INFO:transformers.trainer:{'loss': 3.2070226726531983, 'learning_rate': 4.4175029948841126e-05, 'epoch': 0.3494982030695326, 'step': 1940500}
INFO:transformers.trainer:{'loss': 3.241122932076454, 'learning_rate': 4.4173529054728485e-05, 'epoch': 0.349588256716291, 'step': 1941000}
INFO:transformers.trainer:{'loss': 3.2585110249519347, 'learning_rate': 4.4172028160615844e-05, 'epoch': 0.34967831036304947, 'step': 1941500}
INFO:transformers.trainer:{'loss': 3.227958435535431, 'learning_rate': 4.41705272665032e-05, 'epoch': 0.34976836400980793, 'step': 1942000}
INFO:transformers.trainer:{'loss': 3.2250488409996034, 'learning_rate': 4.416902637239056e-05, 'epoch': 0.3498584176565664, 'step': 1942500}
INFO:transformers.trainer:{'loss': 3.2538009526729583, 'learning_rate': 4.416752547827792e-05, 'epoch': 0.3499484713033248, 'step': 1943000}
INFO:transformers.trainer:{'loss': 3.2260394092798235, 'learning_rate': 4.416602458416528e-05, 'epoch': 0.35003852495008325, 'step': 1943500}
INFO:transformers.trainer:{'loss': 3.2123149132728575, 'learning_rate': 4.416452369005264e-05, 'epoch': 0.3501285785968417, 'step': 1944000}
INFO:transformers.trainer:{'loss': 3.1723570137023924, 'learning_rate': 4.416302279594e-05, 'epoch': 0.35021863224360017, 'step': 1944500}
INFO:transformers.trainer:{'loss': 3.2385392315387724, 'learning_rate': 4.416152190182736e-05, 'epoch': 0.35030868589035863, 'step': 1945000}
INFO:transformers.trainer:{'loss': 3.233083700656891, 'learning_rate': 4.4160021007714717e-05, 'epoch': 0.35039873953711703, 'step': 1945500}
INFO:transformers.trainer:{'loss': 3.338879942059517, 'learning_rate': 4.4158520113602076e-05, 'epoch': 0.3504887931838755, 'step': 1946000}
INFO:transformers.trainer:{'loss': 3.265286524415016, 'learning_rate': 4.4157019219489435e-05, 'epoch': 0.35057884683063395, 'step': 1946500}
INFO:transformers.trainer:{'loss': 3.3107023713588712, 'learning_rate': 4.4155518325376794e-05, 'epoch': 0.3506689004773924, 'step': 1947000}
INFO:transformers.trainer:{'loss': 3.243413045167923, 'learning_rate': 4.415401743126415e-05, 'epoch': 0.3507589541241508, 'step': 1947500}
INFO:transformers.trainer:{'loss': 3.1870081380605697, 'learning_rate': 4.415251653715151e-05, 'epoch': 0.35084900777090927, 'step': 1948000}
INFO:transformers.trainer:{'loss': 3.2408033998012544, 'learning_rate': 4.415101564303887e-05, 'epoch': 0.35093906141766773, 'step': 1948500}
INFO:transformers.trainer:{'loss': 3.2902821125984194, 'learning_rate': 4.414951474892624e-05, 'epoch': 0.3510291150644262, 'step': 1949000}
INFO:transformers.trainer:{'loss': 3.270543053150177, 'learning_rate': 4.414801385481359e-05, 'epoch': 0.35111916871118465, 'step': 1949500}
INFO:transformers.trainer:{'loss': 3.206253247499466, 'learning_rate': 4.4146512960700955e-05, 'epoch': 0.35120922235794305, 'step': 1950000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-1950000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1950000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-1950000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1850000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.249521112322807, 'learning_rate': 4.414501206658831e-05, 'epoch': 0.3512992760047015, 'step': 1950500}
INFO:transformers.trainer:{'loss': 3.2042458128929137, 'learning_rate': 4.414351117247567e-05, 'epoch': 0.35138932965145997, 'step': 1951000}
INFO:transformers.trainer:{'loss': 3.258616949558258, 'learning_rate': 4.4142010278363025e-05, 'epoch': 0.35147938329821843, 'step': 1951500}
INFO:transformers.trainer:{'loss': 3.221224554657936, 'learning_rate': 4.414050938425039e-05, 'epoch': 0.3515694369449769, 'step': 1952000}
INFO:transformers.trainer:{'loss': 3.2029710342884066, 'learning_rate': 4.413900849013774e-05, 'epoch': 0.3516594905917353, 'step': 1952500}
INFO:transformers.trainer:{'loss': 3.2700131607055662, 'learning_rate': 4.413750759602511e-05, 'epoch': 0.35174954423849375, 'step': 1953000}
INFO:transformers.trainer:{'loss': 3.211148602724075, 'learning_rate': 4.413600670191246e-05, 'epoch': 0.3518395978852522, 'step': 1953500}
INFO:transformers.trainer:{'loss': 3.2021510877609254, 'learning_rate': 4.413450580779983e-05, 'epoch': 0.35192965153201067, 'step': 1954000}
INFO:transformers.trainer:{'loss': 3.216774782896042, 'learning_rate': 4.413300491368718e-05, 'epoch': 0.35201970517876907, 'step': 1954500}
INFO:transformers.trainer:{'loss': 3.2302191298007967, 'learning_rate': 4.4131504019574545e-05, 'epoch': 0.35210975882552753, 'step': 1955000}
INFO:transformers.trainer:{'loss': 3.2102325873374937, 'learning_rate': 4.41300031254619e-05, 'epoch': 0.352199812472286, 'step': 1955500}
INFO:transformers.trainer:{'loss': 3.172202648639679, 'learning_rate': 4.4128502231349263e-05, 'epoch': 0.35228986611904445, 'step': 1956000}
INFO:transformers.trainer:{'loss': 3.3232592704296113, 'learning_rate': 4.412700133723662e-05, 'epoch': 0.3523799197658029, 'step': 1956500}
INFO:transformers.trainer:{'loss': 3.255438250899315, 'learning_rate': 4.412550044312398e-05, 'epoch': 0.3524699734125613, 'step': 1957000}
INFO:transformers.trainer:{'loss': 3.307786012649536, 'learning_rate': 4.412399954901134e-05, 'epoch': 0.35256002705931977, 'step': 1957500}
INFO:transformers.trainer:{'loss': 3.1870411117076873, 'learning_rate': 4.41224986548987e-05, 'epoch': 0.35265008070607823, 'step': 1958000}
INFO:transformers.trainer:{'loss': 3.2288503742218015, 'learning_rate': 4.412099776078606e-05, 'epoch': 0.3527401343528367, 'step': 1958500}
INFO:transformers.trainer:{'loss': 3.2571308026313783, 'learning_rate': 4.411949686667342e-05, 'epoch': 0.35283018799959515, 'step': 1959000}
INFO:transformers.trainer:{'loss': 3.2158438489437104, 'learning_rate': 4.411799597256078e-05, 'epoch': 0.35292024164635355, 'step': 1959500}
INFO:transformers.trainer:{'loss': 3.2096579275131227, 'learning_rate': 4.4116495078448136e-05, 'epoch': 0.353010295293112, 'step': 1960000}
INFO:transformers.trainer:{'loss': 3.2287846236228943, 'learning_rate': 4.4114994184335495e-05, 'epoch': 0.35310034893987047, 'step': 1960500}
INFO:transformers.trainer:{'loss': 3.186473674535751, 'learning_rate': 4.4113493290222854e-05, 'epoch': 0.3531904025866289, 'step': 1961000}
INFO:transformers.trainer:{'loss': 3.2483404853343965, 'learning_rate': 4.411199239611021e-05, 'epoch': 0.35328045623338733, 'step': 1961500}
INFO:transformers.trainer:{'loss': 3.2822412719726564, 'learning_rate': 4.411049150199757e-05, 'epoch': 0.3533705098801458, 'step': 1962000}
INFO:transformers.trainer:{'loss': 3.224140042066574, 'learning_rate': 4.410899060788493e-05, 'epoch': 0.35346056352690425, 'step': 1962500}
INFO:transformers.trainer:{'loss': 3.2092892413139342, 'learning_rate': 4.410748971377229e-05, 'epoch': 0.3535506171736627, 'step': 1963000}
INFO:transformers.trainer:{'loss': 3.168745330810547, 'learning_rate': 4.410598881965965e-05, 'epoch': 0.35364067082042117, 'step': 1963500}
INFO:transformers.trainer:{'loss': 3.19224555182457, 'learning_rate': 4.410448792554701e-05, 'epoch': 0.35373072446717957, 'step': 1964000}
INFO:transformers.trainer:{'loss': 3.246845961689949, 'learning_rate': 4.410298703143437e-05, 'epoch': 0.35382077811393803, 'step': 1964500}
INFO:transformers.trainer:{'loss': 3.2633721759319307, 'learning_rate': 4.4101486137321726e-05, 'epoch': 0.3539108317606965, 'step': 1965000}
INFO:transformers.trainer:{'loss': 3.272990820169449, 'learning_rate': 4.4099985243209085e-05, 'epoch': 0.35400088540745495, 'step': 1965500}
INFO:transformers.trainer:{'loss': 3.2844034348726274, 'learning_rate': 4.4098484349096444e-05, 'epoch': 0.35409093905421335, 'step': 1966000}
INFO:transformers.trainer:{'loss': 3.2812566266059875, 'learning_rate': 4.4096983454983803e-05, 'epoch': 0.3541809927009718, 'step': 1966500}
INFO:transformers.trainer:{'loss': 3.3032352793216706, 'learning_rate': 4.409548256087116e-05, 'epoch': 0.35427104634773027, 'step': 1967000}
INFO:transformers.trainer:{'loss': 3.3027258133888244, 'learning_rate': 4.409398166675852e-05, 'epoch': 0.3543610999944887, 'step': 1967500}
INFO:transformers.trainer:{'loss': 3.3088616243600844, 'learning_rate': 4.409248077264588e-05, 'epoch': 0.3544511536412472, 'step': 1968000}
INFO:transformers.trainer:{'loss': 3.2327517473697664, 'learning_rate': 4.409097987853324e-05, 'epoch': 0.3545412072880056, 'step': 1968500}
INFO:transformers.trainer:{'loss': 3.238171200633049, 'learning_rate': 4.40894789844206e-05, 'epoch': 0.35463126093476405, 'step': 1969000}
INFO:transformers.trainer:{'loss': 3.2549993191957474, 'learning_rate': 4.4087978090307965e-05, 'epoch': 0.3547213145815225, 'step': 1969500}
INFO:transformers.trainer:{'loss': 3.2849677171707152, 'learning_rate': 4.408647719619532e-05, 'epoch': 0.35481136822828097, 'step': 1970000}
INFO:transformers.trainer:{'loss': 3.2761854128837586, 'learning_rate': 4.408497630208268e-05, 'epoch': 0.3549014218750394, 'step': 1970500}
INFO:transformers.trainer:{'loss': 3.2596953336000443, 'learning_rate': 4.4083475407970035e-05, 'epoch': 0.35499147552179783, 'step': 1971000}
INFO:transformers.trainer:{'loss': 3.2790707362890243, 'learning_rate': 4.40819745138574e-05, 'epoch': 0.3550815291685563, 'step': 1971500}
INFO:transformers.trainer:{'loss': 3.2637092332839965, 'learning_rate': 4.408047361974475e-05, 'epoch': 0.35517158281531475, 'step': 1972000}
INFO:transformers.trainer:{'loss': 3.282522466659546, 'learning_rate': 4.407897272563212e-05, 'epoch': 0.3552616364620732, 'step': 1972500}
INFO:transformers.trainer:{'loss': 3.301625602245331, 'learning_rate': 4.407747183151947e-05, 'epoch': 0.3553516901088316, 'step': 1973000}
INFO:transformers.trainer:{'loss': 3.2256474571228027, 'learning_rate': 4.407597093740684e-05, 'epoch': 0.35544174375559007, 'step': 1973500}
INFO:transformers.trainer:{'loss': 3.2596893599033354, 'learning_rate': 4.407447004329419e-05, 'epoch': 0.3555317974023485, 'step': 1974000}
INFO:transformers.trainer:{'loss': 3.211669784784317, 'learning_rate': 4.4072969149181555e-05, 'epoch': 0.355621851049107, 'step': 1974500}
INFO:transformers.trainer:{'loss': 3.2801193277835847, 'learning_rate': 4.407146825506891e-05, 'epoch': 0.35571190469586544, 'step': 1975000}
INFO:transformers.trainer:{'loss': 3.324999196052551, 'learning_rate': 4.406996736095627e-05, 'epoch': 0.35580195834262385, 'step': 1975500}
INFO:transformers.trainer:{'loss': 3.3083235152959825, 'learning_rate': 4.4068466466843625e-05, 'epoch': 0.3558920119893823, 'step': 1976000}
INFO:transformers.trainer:{'loss': 3.195449825882912, 'learning_rate': 4.406696557273099e-05, 'epoch': 0.35598206563614077, 'step': 1976500}
INFO:transformers.trainer:{'loss': 3.23021639251709, 'learning_rate': 4.406546467861835e-05, 'epoch': 0.3560721192828992, 'step': 1977000}
INFO:transformers.trainer:{'loss': 3.2433219256401062, 'learning_rate': 4.406396378450571e-05, 'epoch': 0.3561621729296577, 'step': 1977500}
INFO:transformers.trainer:{'loss': 3.3334321718215945, 'learning_rate': 4.406246289039307e-05, 'epoch': 0.3562522265764161, 'step': 1978000}
INFO:transformers.trainer:{'loss': 3.2930343174934387, 'learning_rate': 4.406096199628043e-05, 'epoch': 0.35634228022317455, 'step': 1978500}
INFO:transformers.trainer:{'loss': 3.2991277184486387, 'learning_rate': 4.4059461102167787e-05, 'epoch': 0.356432333869933, 'step': 1979000}
INFO:transformers.trainer:{'loss': 3.2521745257377623, 'learning_rate': 4.4057960208055146e-05, 'epoch': 0.35652238751669146, 'step': 1979500}
INFO:transformers.trainer:{'loss': 3.2538494675159453, 'learning_rate': 4.4056459313942505e-05, 'epoch': 0.35661244116344987, 'step': 1980000}
INFO:transformers.trainer:{'loss': 3.225746886253357, 'learning_rate': 4.4054958419829864e-05, 'epoch': 0.3567024948102083, 'step': 1980500}
INFO:transformers.trainer:{'loss': 3.2554204981327057, 'learning_rate': 4.405345752571722e-05, 'epoch': 0.3567925484569668, 'step': 1981000}
INFO:transformers.trainer:{'loss': 3.2656264111995696, 'learning_rate': 4.405195663160458e-05, 'epoch': 0.35688260210372524, 'step': 1981500}
INFO:transformers.trainer:{'loss': 3.255689163684845, 'learning_rate': 4.405045573749194e-05, 'epoch': 0.3569726557504837, 'step': 1982000}
INFO:transformers.trainer:{'loss': 3.218649659872055, 'learning_rate': 4.40489548433793e-05, 'epoch': 0.3570627093972421, 'step': 1982500}
INFO:transformers.trainer:{'loss': 3.2344638612270353, 'learning_rate': 4.404745394926666e-05, 'epoch': 0.35715276304400057, 'step': 1983000}
INFO:transformers.trainer:{'loss': 3.272593724966049, 'learning_rate': 4.404595305515402e-05, 'epoch': 0.357242816690759, 'step': 1983500}
INFO:transformers.trainer:{'loss': 3.316371330022812, 'learning_rate': 4.404445216104138e-05, 'epoch': 0.3573328703375175, 'step': 1984000}
INFO:transformers.trainer:{'loss': 3.3424024555683136, 'learning_rate': 4.4042951266928736e-05, 'epoch': 0.3574229239842759, 'step': 1984500}
INFO:transformers.trainer:{'loss': 3.3315364761352537, 'learning_rate': 4.4041450372816095e-05, 'epoch': 0.35751297763103435, 'step': 1985000}
INFO:transformers.trainer:{'loss': 3.2273596024513242, 'learning_rate': 4.4039949478703454e-05, 'epoch': 0.3576030312777928, 'step': 1985500}
INFO:transformers.trainer:{'loss': 3.2588062262535096, 'learning_rate': 4.403844858459081e-05, 'epoch': 0.35769308492455126, 'step': 1986000}
INFO:transformers.trainer:{'loss': 3.2145442311763763, 'learning_rate': 4.403694769047817e-05, 'epoch': 0.3577831385713097, 'step': 1986500}
INFO:transformers.trainer:{'loss': 3.201970772743225, 'learning_rate': 4.403544679636553e-05, 'epoch': 0.3578731922180681, 'step': 1987000}
INFO:transformers.trainer:{'loss': 3.2835162901878356, 'learning_rate': 4.403394590225289e-05, 'epoch': 0.3579632458648266, 'step': 1987500}
INFO:transformers.trainer:{'loss': 3.3180382902622223, 'learning_rate': 4.403244500814025e-05, 'epoch': 0.35805329951158504, 'step': 1988000}
INFO:transformers.trainer:{'loss': 3.2513640804290773, 'learning_rate': 4.403094411402761e-05, 'epoch': 0.3581433531583435, 'step': 1988500}
INFO:transformers.trainer:{'loss': 3.6124543879032136, 'learning_rate': 4.402944321991497e-05, 'epoch': 0.35823340680510196, 'step': 1989000}
INFO:transformers.trainer:{'loss': 3.559647099018097, 'learning_rate': 4.4027942325802327e-05, 'epoch': 0.35832346045186036, 'step': 1989500}
INFO:transformers.trainer:{'loss': 3.7749747366905213, 'learning_rate': 4.4026441431689686e-05, 'epoch': 0.3584135140986188, 'step': 1990000}
INFO:transformers.trainer:{'loss': 4.056908637046814, 'learning_rate': 4.4024940537577045e-05, 'epoch': 0.3585035677453773, 'step': 1990500}
INFO:transformers.trainer:{'loss': 3.533947068452835, 'learning_rate': 4.402343964346441e-05, 'epoch': 0.35859362139213574, 'step': 1991000}
INFO:transformers.trainer:{'loss': 3.395379820585251, 'learning_rate': 4.402193874935176e-05, 'epoch': 0.35868367503889415, 'step': 1991500}
INFO:transformers.trainer:{'loss': 3.4276717591285704, 'learning_rate': 4.402043785523913e-05, 'epoch': 0.3587737286856526, 'step': 1992000}
INFO:transformers.trainer:{'loss': 3.3345596162080766, 'learning_rate': 4.401893696112648e-05, 'epoch': 0.35886378233241106, 'step': 1992500}
INFO:transformers.trainer:{'loss': 3.2348077045679093, 'learning_rate': 4.401743606701385e-05, 'epoch': 0.3589538359791695, 'step': 1993000}
INFO:transformers.trainer:{'loss': 3.2571570661067963, 'learning_rate': 4.40159351729012e-05, 'epoch': 0.359043889625928, 'step': 1993500}
INFO:transformers.trainer:{'loss': 3.2245413253307342, 'learning_rate': 4.4014434278788565e-05, 'epoch': 0.3591339432726864, 'step': 1994000}
INFO:transformers.trainer:{'loss': 3.2303591653108596, 'learning_rate': 4.401293338467592e-05, 'epoch': 0.35922399691944484, 'step': 1994500}
INFO:transformers.trainer:{'loss': 3.247551662325859, 'learning_rate': 4.401143249056328e-05, 'epoch': 0.3593140505662033, 'step': 1995000}
INFO:transformers.trainer:{'loss': 3.251482078790665, 'learning_rate': 4.4009931596450635e-05, 'epoch': 0.35940410421296176, 'step': 1995500}
INFO:transformers.trainer:{'loss': 3.229743176460266, 'learning_rate': 4.4008430702338e-05, 'epoch': 0.35949415785972016, 'step': 1996000}
INFO:transformers.trainer:{'loss': 3.2183230464458465, 'learning_rate': 4.400692980822535e-05, 'epoch': 0.3595842115064786, 'step': 1996500}
INFO:transformers.trainer:{'loss': 3.275545734643936, 'learning_rate': 4.400542891411272e-05, 'epoch': 0.3596742651532371, 'step': 1997000}
INFO:transformers.trainer:{'loss': 3.260062289476395, 'learning_rate': 4.400392802000008e-05, 'epoch': 0.35976431879999554, 'step': 1997500}
INFO:transformers.trainer:{'loss': 3.1803927843570707, 'learning_rate': 4.400242712588744e-05, 'epoch': 0.359854372446754, 'step': 1998000}
INFO:transformers.trainer:{'loss': 3.2797215766906738, 'learning_rate': 4.4000926231774796e-05, 'epoch': 0.3599444260935124, 'step': 1998500}
INFO:transformers.trainer:{'loss': 3.286150009870529, 'learning_rate': 4.3999425337662155e-05, 'epoch': 0.36003447974027086, 'step': 1999000}
INFO:transformers.trainer:{'loss': 3.2967494688034056, 'learning_rate': 4.3997924443549514e-05, 'epoch': 0.3601245333870293, 'step': 1999500}
INFO:transformers.trainer:{'loss': 3.220610426425934, 'learning_rate': 4.399642354943687e-05, 'epoch': 0.3602145870337878, 'step': 2000000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2000000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2000000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2000000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1900000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.181349378824234, 'learning_rate': 4.399492265532423e-05, 'epoch': 0.36030464068054624, 'step': 2000500}
INFO:transformers.trainer:{'loss': 3.2538272895812987, 'learning_rate': 4.399342176121159e-05, 'epoch': 0.36039469432730464, 'step': 2001000}
INFO:transformers.trainer:{'loss': 3.2412491080760955, 'learning_rate': 4.399192086709895e-05, 'epoch': 0.3604847479740631, 'step': 2001500}
INFO:transformers.trainer:{'loss': 3.2585253493785857, 'learning_rate': 4.399041997298631e-05, 'epoch': 0.36057480162082156, 'step': 2002000}
INFO:transformers.trainer:{'loss': 3.290441774845123, 'learning_rate': 4.398891907887367e-05, 'epoch': 0.36066485526758, 'step': 2002500}
INFO:transformers.trainer:{'loss': 3.2542510356903076, 'learning_rate': 4.398741818476103e-05, 'epoch': 0.3607549089143384, 'step': 2003000}
INFO:transformers.trainer:{'loss': 3.3300680866241454, 'learning_rate': 4.398591729064839e-05, 'epoch': 0.3608449625610969, 'step': 2003500}
INFO:transformers.trainer:{'loss': 3.2551488239765165, 'learning_rate': 4.3984416396535746e-05, 'epoch': 0.36093501620785534, 'step': 2004000}
INFO:transformers.trainer:{'loss': 3.250084804177284, 'learning_rate': 4.3982915502423105e-05, 'epoch': 0.3610250698546138, 'step': 2004500}
INFO:transformers.trainer:{'loss': 3.2942770409584043, 'learning_rate': 4.3981414608310464e-05, 'epoch': 0.36111512350137226, 'step': 2005000}
INFO:transformers.trainer:{'loss': 3.2118401972055435, 'learning_rate': 4.397991371419782e-05, 'epoch': 0.36120517714813066, 'step': 2005500}
INFO:transformers.trainer:{'loss': 3.265705677509308, 'learning_rate': 4.397841282008518e-05, 'epoch': 0.3612952307948891, 'step': 2006000}
INFO:transformers.trainer:{'loss': 3.3043593828678133, 'learning_rate': 4.397691192597254e-05, 'epoch': 0.3613852844416476, 'step': 2006500}
INFO:transformers.trainer:{'loss': 3.299973613977432, 'learning_rate': 4.39754110318599e-05, 'epoch': 0.36147533808840604, 'step': 2007000}
INFO:transformers.trainer:{'loss': 3.265460015773773, 'learning_rate': 4.397391013774726e-05, 'epoch': 0.3615653917351645, 'step': 2007500}
INFO:transformers.trainer:{'loss': 3.267240217208862, 'learning_rate': 4.397240924363462e-05, 'epoch': 0.3616554453819229, 'step': 2008000}
INFO:transformers.trainer:{'loss': 3.2356634364128114, 'learning_rate': 4.397090834952198e-05, 'epoch': 0.36174549902868136, 'step': 2008500}
INFO:transformers.trainer:{'loss': 3.2363688896894454, 'learning_rate': 4.3969407455409336e-05, 'epoch': 0.3618355526754398, 'step': 2009000}
INFO:transformers.trainer:{'loss': 3.2318127722740173, 'learning_rate': 4.3967906561296695e-05, 'epoch': 0.3619256063221983, 'step': 2009500}
INFO:transformers.trainer:{'loss': 3.2672931295633316, 'learning_rate': 4.3966405667184054e-05, 'epoch': 0.3620156599689567, 'step': 2010000}
INFO:transformers.trainer:{'loss': 3.2965491588115694, 'learning_rate': 4.3964904773071413e-05, 'epoch': 0.36210571361571514, 'step': 2010500}
INFO:transformers.trainer:{'loss': 3.251068877220154, 'learning_rate': 4.396340387895877e-05, 'epoch': 0.3621957672624736, 'step': 2011000}
INFO:transformers.trainer:{'loss': 3.243168010234833, 'learning_rate': 4.396190298484614e-05, 'epoch': 0.36228582090923206, 'step': 2011500}
INFO:transformers.trainer:{'loss': 3.2487845747470856, 'learning_rate': 4.396040209073349e-05, 'epoch': 0.3623758745559905, 'step': 2012000}
INFO:transformers.trainer:{'loss': 3.2920663504600527, 'learning_rate': 4.3958901196620856e-05, 'epoch': 0.3624659282027489, 'step': 2012500}
INFO:transformers.trainer:{'loss': 3.223375243186951, 'learning_rate': 4.395740030250821e-05, 'epoch': 0.3625559818495074, 'step': 2013000}
INFO:transformers.trainer:{'loss': 3.262137337446213, 'learning_rate': 4.3955899408395575e-05, 'epoch': 0.36264603549626584, 'step': 2013500}
INFO:transformers.trainer:{'loss': 3.2310909311771394, 'learning_rate': 4.395439851428293e-05, 'epoch': 0.3627360891430243, 'step': 2014000}
INFO:transformers.trainer:{'loss': 3.331535763144493, 'learning_rate': 4.395289762017029e-05, 'epoch': 0.3628261427897827, 'step': 2014500}
INFO:transformers.trainer:{'loss': 3.284312523841858, 'learning_rate': 4.3951396726057645e-05, 'epoch': 0.36291619643654116, 'step': 2015000}
INFO:transformers.trainer:{'loss': 3.276442449808121, 'learning_rate': 4.394989583194501e-05, 'epoch': 0.3630062500832996, 'step': 2015500}
INFO:transformers.trainer:{'loss': 3.248945427894592, 'learning_rate': 4.394839493783236e-05, 'epoch': 0.3630963037300581, 'step': 2016000}
INFO:transformers.trainer:{'loss': 3.238483090877533, 'learning_rate': 4.394689404371973e-05, 'epoch': 0.36318635737681654, 'step': 2016500}
INFO:transformers.trainer:{'loss': 3.2422721705436706, 'learning_rate': 4.394539314960708e-05, 'epoch': 0.36327641102357494, 'step': 2017000}
INFO:transformers.trainer:{'loss': 3.24082018995285, 'learning_rate': 4.394389225549445e-05, 'epoch': 0.3633664646703334, 'step': 2017500}
INFO:transformers.trainer:{'loss': 3.291440920114517, 'learning_rate': 4.3942391361381806e-05, 'epoch': 0.36345651831709186, 'step': 2018000}
INFO:transformers.trainer:{'loss': 3.236970535516739, 'learning_rate': 4.3940890467269165e-05, 'epoch': 0.3635465719638503, 'step': 2018500}
INFO:transformers.trainer:{'loss': 3.2383222036361694, 'learning_rate': 4.3939389573156524e-05, 'epoch': 0.3636366256106088, 'step': 2019000}
INFO:transformers.trainer:{'loss': 3.233531845331192, 'learning_rate': 4.393788867904388e-05, 'epoch': 0.3637266792573672, 'step': 2019500}
INFO:transformers.trainer:{'loss': 3.30213667845726, 'learning_rate': 4.393638778493124e-05, 'epoch': 0.36381673290412564, 'step': 2020000}
INFO:transformers.trainer:{'loss': 3.310351546525955, 'learning_rate': 4.39348868908186e-05, 'epoch': 0.3639067865508841, 'step': 2020500}
INFO:transformers.trainer:{'loss': 3.281463335990906, 'learning_rate': 4.393338599670596e-05, 'epoch': 0.36399684019764256, 'step': 2021000}
INFO:transformers.trainer:{'loss': 3.248282727241516, 'learning_rate': 4.393188510259332e-05, 'epoch': 0.36408689384440096, 'step': 2021500}
INFO:transformers.trainer:{'loss': 3.227475247859955, 'learning_rate': 4.393038420848068e-05, 'epoch': 0.3641769474911594, 'step': 2022000}
INFO:transformers.trainer:{'loss': 3.253910276889801, 'learning_rate': 4.392888331436804e-05, 'epoch': 0.3642670011379179, 'step': 2022500}
INFO:transformers.trainer:{'loss': 3.2612325801849367, 'learning_rate': 4.3927382420255396e-05, 'epoch': 0.36435705478467634, 'step': 2023000}
INFO:transformers.trainer:{'loss': 3.2651023786067963, 'learning_rate': 4.3925881526142756e-05, 'epoch': 0.3644471084314348, 'step': 2023500}
INFO:transformers.trainer:{'loss': 3.272540090084076, 'learning_rate': 4.3924380632030115e-05, 'epoch': 0.3645371620781932, 'step': 2024000}
INFO:transformers.trainer:{'loss': 3.2843393111228942, 'learning_rate': 4.3922879737917474e-05, 'epoch': 0.36462721572495166, 'step': 2024500}
INFO:transformers.trainer:{'loss': 3.2765487372875213, 'learning_rate': 4.392137884380483e-05, 'epoch': 0.3647172693717101, 'step': 2025000}
INFO:transformers.trainer:{'loss': 3.215983962059021, 'learning_rate': 4.39198779496922e-05, 'epoch': 0.3648073230184686, 'step': 2025500}
INFO:transformers.trainer:{'loss': 3.286792079925537, 'learning_rate': 4.391837705557955e-05, 'epoch': 0.36489737666522704, 'step': 2026000}
INFO:transformers.trainer:{'loss': 3.319795576810837, 'learning_rate': 4.3916876161466917e-05, 'epoch': 0.36498743031198544, 'step': 2026500}
INFO:transformers.trainer:{'loss': 3.2751503977775576, 'learning_rate': 4.391537526735427e-05, 'epoch': 0.3650774839587439, 'step': 2027000}
INFO:transformers.trainer:{'loss': 3.222655503511429, 'learning_rate': 4.3913874373241635e-05, 'epoch': 0.36516753760550236, 'step': 2027500}
INFO:transformers.trainer:{'loss': 3.2580456094741823, 'learning_rate': 4.391237347912899e-05, 'epoch': 0.3652575912522608, 'step': 2028000}
INFO:transformers.trainer:{'loss': 3.228545101881027, 'learning_rate': 4.3910872585016346e-05, 'epoch': 0.3653476448990192, 'step': 2028500}
INFO:transformers.trainer:{'loss': 3.2384727466106416, 'learning_rate': 4.3909371690903705e-05, 'epoch': 0.3654376985457777, 'step': 2029000}
INFO:transformers.trainer:{'loss': 3.254436058998108, 'learning_rate': 4.3907870796791064e-05, 'epoch': 0.36552775219253614, 'step': 2029500}
INFO:transformers.trainer:{'loss': 3.240903389453888, 'learning_rate': 4.390636990267842e-05, 'epoch': 0.3656178058392946, 'step': 2030000}
INFO:transformers.trainer:{'loss': 3.2578053147792816, 'learning_rate': 4.390486900856578e-05, 'epoch': 0.36570785948605306, 'step': 2030500}
INFO:transformers.trainer:{'loss': 3.249845504760742, 'learning_rate': 4.390336811445314e-05, 'epoch': 0.36579791313281146, 'step': 2031000}
INFO:transformers.trainer:{'loss': 3.25593003988266, 'learning_rate': 4.39018672203405e-05, 'epoch': 0.3658879667795699, 'step': 2031500}
INFO:transformers.trainer:{'loss': 3.22808030462265, 'learning_rate': 4.3900366326227866e-05, 'epoch': 0.3659780204263284, 'step': 2032000}
INFO:transformers.trainer:{'loss': 3.245059527158737, 'learning_rate': 4.389886543211522e-05, 'epoch': 0.36606807407308684, 'step': 2032500}
INFO:transformers.trainer:{'loss': 3.213531253576279, 'learning_rate': 4.3897364538002584e-05, 'epoch': 0.36615812771984524, 'step': 2033000}
INFO:transformers.trainer:{'loss': 3.1909452338218687, 'learning_rate': 4.3895863643889937e-05, 'epoch': 0.3662481813666037, 'step': 2033500}
INFO:transformers.trainer:{'loss': 3.265681833744049, 'learning_rate': 4.38943627497773e-05, 'epoch': 0.36633823501336216, 'step': 2034000}
INFO:transformers.trainer:{'loss': 3.2351306862831115, 'learning_rate': 4.3892861855664655e-05, 'epoch': 0.3664282886601206, 'step': 2034500}
INFO:transformers.trainer:{'loss': 3.2278601095676422, 'learning_rate': 4.389136096155202e-05, 'epoch': 0.3665183423068791, 'step': 2035000}
INFO:transformers.trainer:{'loss': 3.207871922492981, 'learning_rate': 4.388986006743937e-05, 'epoch': 0.3666083959536375, 'step': 2035500}
INFO:transformers.trainer:{'loss': 3.3181243562698364, 'learning_rate': 4.388835917332674e-05, 'epoch': 0.36669844960039594, 'step': 2036000}
INFO:transformers.trainer:{'loss': 3.2558610649108886, 'learning_rate': 4.388685827921409e-05, 'epoch': 0.3667885032471544, 'step': 2036500}
INFO:transformers.trainer:{'loss': 3.2878430688381197, 'learning_rate': 4.388535738510146e-05, 'epoch': 0.36687855689391285, 'step': 2037000}
INFO:transformers.trainer:{'loss': 3.1696750161647795, 'learning_rate': 4.388385649098881e-05, 'epoch': 0.3669686105406713, 'step': 2037500}
INFO:transformers.trainer:{'loss': 3.2245293884277344, 'learning_rate': 4.3882355596876175e-05, 'epoch': 0.3670586641874297, 'step': 2038000}
INFO:transformers.trainer:{'loss': 3.213970567703247, 'learning_rate': 4.388085470276353e-05, 'epoch': 0.3671487178341882, 'step': 2038500}
INFO:transformers.trainer:{'loss': 3.2818909413814543, 'learning_rate': 4.387935380865089e-05, 'epoch': 0.36723877148094664, 'step': 2039000}
INFO:transformers.trainer:{'loss': 3.2326408289670945, 'learning_rate': 4.387785291453825e-05, 'epoch': 0.3673288251277051, 'step': 2039500}
INFO:transformers.trainer:{'loss': 3.2302394552230833, 'learning_rate': 4.387635202042561e-05, 'epoch': 0.3674188787744635, 'step': 2040000}
INFO:transformers.trainer:{'loss': 3.2066818056106565, 'learning_rate': 4.387485112631297e-05, 'epoch': 0.36750893242122196, 'step': 2040500}
INFO:transformers.trainer:{'loss': 3.194712342739105, 'learning_rate': 4.387335023220033e-05, 'epoch': 0.3675989860679804, 'step': 2041000}
INFO:transformers.trainer:{'loss': 3.293874983549118, 'learning_rate': 4.387184933808769e-05, 'epoch': 0.3676890397147389, 'step': 2041500}
INFO:transformers.trainer:{'loss': 3.217397745847702, 'learning_rate': 4.387034844397505e-05, 'epoch': 0.36777909336149733, 'step': 2042000}
INFO:transformers.trainer:{'loss': 3.264903590917587, 'learning_rate': 4.3868847549862406e-05, 'epoch': 0.36786914700825574, 'step': 2042500}
INFO:transformers.trainer:{'loss': 3.2798533771038056, 'learning_rate': 4.3867346655749765e-05, 'epoch': 0.3679592006550142, 'step': 2043000}
INFO:transformers.trainer:{'loss': 3.240280770778656, 'learning_rate': 4.3865845761637124e-05, 'epoch': 0.36804925430177265, 'step': 2043500}
INFO:transformers.trainer:{'loss': 3.238359538078308, 'learning_rate': 4.386434486752448e-05, 'epoch': 0.3681393079485311, 'step': 2044000}
INFO:transformers.trainer:{'loss': 3.310931156873703, 'learning_rate': 4.386284397341184e-05, 'epoch': 0.3682293615952896, 'step': 2044500}
INFO:transformers.trainer:{'loss': 3.24085766685009, 'learning_rate': 4.38613430792992e-05, 'epoch': 0.368319415242048, 'step': 2045000}
INFO:transformers.trainer:{'loss': 3.225228776216507, 'learning_rate': 4.385984218518656e-05, 'epoch': 0.36840946888880644, 'step': 2045500}
INFO:transformers.trainer:{'loss': 3.242581319332123, 'learning_rate': 4.3858341291073926e-05, 'epoch': 0.3684995225355649, 'step': 2046000}
INFO:transformers.trainer:{'loss': 3.23657113468647, 'learning_rate': 4.385684039696128e-05, 'epoch': 0.36858957618232335, 'step': 2046500}
INFO:transformers.trainer:{'loss': 3.219051868200302, 'learning_rate': 4.3855339502848644e-05, 'epoch': 0.36867962982908176, 'step': 2047000}
INFO:transformers.trainer:{'loss': 3.306746447086334, 'learning_rate': 4.3853838608736e-05, 'epoch': 0.3687696834758402, 'step': 2047500}
INFO:transformers.trainer:{'loss': 3.298447431087494, 'learning_rate': 4.385233771462336e-05, 'epoch': 0.3688597371225987, 'step': 2048000}
INFO:transformers.trainer:{'loss': 3.247457363128662, 'learning_rate': 4.3850836820510715e-05, 'epoch': 0.36894979076935713, 'step': 2048500}
INFO:transformers.trainer:{'loss': 3.1633294456005094, 'learning_rate': 4.384933592639808e-05, 'epoch': 0.3690398444161156, 'step': 2049000}
INFO:transformers.trainer:{'loss': 3.2923274924755095, 'learning_rate': 4.384783503228543e-05, 'epoch': 0.369129898062874, 'step': 2049500}
INFO:transformers.trainer:{'loss': 3.2425596477985383, 'learning_rate': 4.38463341381728e-05, 'epoch': 0.36921995170963245, 'step': 2050000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2050000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2050000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2050000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-1950000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.177444475412369, 'learning_rate': 4.384483324406015e-05, 'epoch': 0.3693100053563909, 'step': 2050500}
INFO:transformers.trainer:{'loss': 3.167160901069641, 'learning_rate': 4.384333234994752e-05, 'epoch': 0.3694000590031494, 'step': 2051000}
INFO:transformers.trainer:{'loss': 3.222394552230835, 'learning_rate': 4.384183145583487e-05, 'epoch': 0.3694901126499078, 'step': 2051500}
INFO:transformers.trainer:{'loss': 3.2202689912319182, 'learning_rate': 4.384033056172223e-05, 'epoch': 0.36958016629666623, 'step': 2052000}
INFO:transformers.trainer:{'loss': 3.2646453902721406, 'learning_rate': 4.383882966760959e-05, 'epoch': 0.3696702199434247, 'step': 2052500}
INFO:transformers.trainer:{'loss': 3.2969589970111848, 'learning_rate': 4.3837328773496946e-05, 'epoch': 0.36976027359018315, 'step': 2053000}
INFO:transformers.trainer:{'loss': 3.2108842833042144, 'learning_rate': 4.383582787938431e-05, 'epoch': 0.3698503272369416, 'step': 2053500}
INFO:transformers.trainer:{'loss': 3.2853858647346494, 'learning_rate': 4.3834326985271664e-05, 'epoch': 0.3699403808837, 'step': 2054000}
INFO:transformers.trainer:{'loss': 3.18188170838356, 'learning_rate': 4.383282609115903e-05, 'epoch': 0.3700304345304585, 'step': 2054500}
INFO:transformers.trainer:{'loss': 3.246349364757538, 'learning_rate': 4.383132519704638e-05, 'epoch': 0.37012048817721693, 'step': 2055000}
INFO:transformers.trainer:{'loss': 3.264841539144516, 'learning_rate': 4.382982430293375e-05, 'epoch': 0.3702105418239754, 'step': 2055500}
INFO:transformers.trainer:{'loss': 3.26598686504364, 'learning_rate': 4.38283234088211e-05, 'epoch': 0.37030059547073385, 'step': 2056000}
INFO:transformers.trainer:{'loss': 3.2483091299533844, 'learning_rate': 4.3826822514708466e-05, 'epoch': 0.37039064911749225, 'step': 2056500}
INFO:transformers.trainer:{'loss': 3.2503705191612244, 'learning_rate': 4.382532162059582e-05, 'epoch': 0.3704807027642507, 'step': 2057000}
INFO:transformers.trainer:{'loss': 3.232545855522156, 'learning_rate': 4.3823820726483184e-05, 'epoch': 0.3705707564110092, 'step': 2057500}
INFO:transformers.trainer:{'loss': 3.194686817884445, 'learning_rate': 4.382231983237054e-05, 'epoch': 0.37066081005776763, 'step': 2058000}
INFO:transformers.trainer:{'loss': 3.2726900177001954, 'learning_rate': 4.38208189382579e-05, 'epoch': 0.37075086370452603, 'step': 2058500}
INFO:transformers.trainer:{'loss': 3.3135890283584595, 'learning_rate': 4.3819318044145255e-05, 'epoch': 0.3708409173512845, 'step': 2059000}
INFO:transformers.trainer:{'loss': 3.342979444026947, 'learning_rate': 4.381781715003262e-05, 'epoch': 0.37093097099804295, 'step': 2059500}
INFO:transformers.trainer:{'loss': 3.3095764467716218, 'learning_rate': 4.381631625591998e-05, 'epoch': 0.3710210246448014, 'step': 2060000}
INFO:transformers.trainer:{'loss': 3.252374594926834, 'learning_rate': 4.381481536180734e-05, 'epoch': 0.37111107829155987, 'step': 2060500}
INFO:transformers.trainer:{'loss': 3.2152095704078674, 'learning_rate': 4.38133144676947e-05, 'epoch': 0.3712011319383183, 'step': 2061000}
INFO:transformers.trainer:{'loss': 3.2365845160484312, 'learning_rate': 4.381181357358206e-05, 'epoch': 0.37129118558507673, 'step': 2061500}
INFO:transformers.trainer:{'loss': 3.221929494380951, 'learning_rate': 4.3810312679469416e-05, 'epoch': 0.3713812392318352, 'step': 2062000}
INFO:transformers.trainer:{'loss': 3.2728663258552553, 'learning_rate': 4.3808811785356775e-05, 'epoch': 0.37147129287859365, 'step': 2062500}
INFO:transformers.trainer:{'loss': 3.2545427186489104, 'learning_rate': 4.3807310891244134e-05, 'epoch': 0.3715613465253521, 'step': 2063000}
INFO:transformers.trainer:{'loss': 3.2322391159534454, 'learning_rate': 4.380580999713149e-05, 'epoch': 0.3716514001721105, 'step': 2063500}
INFO:transformers.trainer:{'loss': 3.3009857478141784, 'learning_rate': 4.380430910301885e-05, 'epoch': 0.37174145381886897, 'step': 2064000}
INFO:transformers.trainer:{'loss': 3.2387057104110717, 'learning_rate': 4.380280820890621e-05, 'epoch': 0.37183150746562743, 'step': 2064500}
INFO:transformers.trainer:{'loss': 3.1618832273483277, 'learning_rate': 4.380130731479357e-05, 'epoch': 0.3719215611123859, 'step': 2065000}
INFO:transformers.trainer:{'loss': 3.203535463452339, 'learning_rate': 4.379980642068093e-05, 'epoch': 0.3720116147591443, 'step': 2065500}
INFO:transformers.trainer:{'loss': 3.2926157667636873, 'learning_rate': 4.379830552656829e-05, 'epoch': 0.37210166840590275, 'step': 2066000}
INFO:transformers.trainer:{'loss': 3.2899612612724303, 'learning_rate': 4.3796804632455654e-05, 'epoch': 0.3721917220526612, 'step': 2066500}
INFO:transformers.trainer:{'loss': 3.288458549976349, 'learning_rate': 4.3795303738343006e-05, 'epoch': 0.37228177569941967, 'step': 2067000}
INFO:transformers.trainer:{'loss': 3.2496614062786104, 'learning_rate': 4.379380284423037e-05, 'epoch': 0.37237182934617813, 'step': 2067500}
INFO:transformers.trainer:{'loss': 3.1853217849731443, 'learning_rate': 4.3792301950117725e-05, 'epoch': 0.37246188299293653, 'step': 2068000}
INFO:transformers.trainer:{'loss': 3.2333722238540648, 'learning_rate': 4.379080105600509e-05, 'epoch': 0.372551936639695, 'step': 2068500}
INFO:transformers.trainer:{'loss': 3.2420836238861086, 'learning_rate': 4.378930016189244e-05, 'epoch': 0.37264199028645345, 'step': 2069000}
INFO:transformers.trainer:{'loss': 3.2860344262123107, 'learning_rate': 4.378779926777981e-05, 'epoch': 0.3727320439332119, 'step': 2069500}
INFO:transformers.trainer:{'loss': 3.2640867302417753, 'learning_rate': 4.378629837366716e-05, 'epoch': 0.3728220975799703, 'step': 2070000}
INFO:transformers.trainer:{'loss': 3.267010807156563, 'learning_rate': 4.3784797479554527e-05, 'epoch': 0.37291215122672877, 'step': 2070500}
INFO:transformers.trainer:{'loss': 3.2280373485088347, 'learning_rate': 4.378329658544188e-05, 'epoch': 0.37300220487348723, 'step': 2071000}
INFO:transformers.trainer:{'loss': 3.249511742591858, 'learning_rate': 4.3781795691329245e-05, 'epoch': 0.3730922585202457, 'step': 2071500}
INFO:transformers.trainer:{'loss': 3.2618346939086913, 'learning_rate': 4.37802947972166e-05, 'epoch': 0.37318231216700415, 'step': 2072000}
INFO:transformers.trainer:{'loss': 3.2436554057598115, 'learning_rate': 4.377879390310396e-05, 'epoch': 0.37327236581376255, 'step': 2072500}
INFO:transformers.trainer:{'loss': 3.2635512742996218, 'learning_rate': 4.3777293008991315e-05, 'epoch': 0.373362419460521, 'step': 2073000}
INFO:transformers.trainer:{'loss': 3.228143190741539, 'learning_rate': 4.377579211487868e-05, 'epoch': 0.37345247310727947, 'step': 2073500}
INFO:transformers.trainer:{'loss': 3.2846443194150923, 'learning_rate': 4.377429122076604e-05, 'epoch': 0.37354252675403793, 'step': 2074000}
INFO:transformers.trainer:{'loss': 3.2848926610946654, 'learning_rate': 4.37727903266534e-05, 'epoch': 0.3736325804007964, 'step': 2074500}
INFO:transformers.trainer:{'loss': 3.2015672116279603, 'learning_rate': 4.377128943254076e-05, 'epoch': 0.3737226340475548, 'step': 2075000}
INFO:transformers.trainer:{'loss': 3.2671155338287354, 'learning_rate': 4.376978853842812e-05, 'epoch': 0.37381268769431325, 'step': 2075500}
INFO:transformers.trainer:{'loss': 3.245327240228653, 'learning_rate': 4.3768287644315476e-05, 'epoch': 0.3739027413410717, 'step': 2076000}
INFO:transformers.trainer:{'loss': 3.215786052823067, 'learning_rate': 4.376678675020283e-05, 'epoch': 0.37399279498783017, 'step': 2076500}
INFO:transformers.trainer:{'loss': 3.251148993253708, 'learning_rate': 4.3765285856090194e-05, 'epoch': 0.37408284863458857, 'step': 2077000}
INFO:transformers.trainer:{'loss': 3.2215497846603394, 'learning_rate': 4.3763784961977546e-05, 'epoch': 0.37417290228134703, 'step': 2077500}
INFO:transformers.trainer:{'loss': 3.2580283052921297, 'learning_rate': 4.376228406786491e-05, 'epoch': 0.3742629559281055, 'step': 2078000}
INFO:transformers.trainer:{'loss': 3.2812005560398103, 'learning_rate': 4.3760783173752265e-05, 'epoch': 0.37435300957486395, 'step': 2078500}
INFO:transformers.trainer:{'loss': 3.2851782945394516, 'learning_rate': 4.375928227963963e-05, 'epoch': 0.3744430632216224, 'step': 2079000}
INFO:transformers.trainer:{'loss': 3.2292267096042635, 'learning_rate': 4.375778138552698e-05, 'epoch': 0.3745331168683808, 'step': 2079500}
INFO:transformers.trainer:{'loss': 3.187587776303291, 'learning_rate': 4.375628049141435e-05, 'epoch': 0.37462317051513927, 'step': 2080000}
INFO:transformers.trainer:{'loss': 3.2440938379764557, 'learning_rate': 4.375477959730171e-05, 'epoch': 0.37471322416189773, 'step': 2080500}
INFO:transformers.trainer:{'loss': 3.23004306101799, 'learning_rate': 4.3753278703189067e-05, 'epoch': 0.3748032778086562, 'step': 2081000}
INFO:transformers.trainer:{'loss': 3.1802857897281647, 'learning_rate': 4.3751777809076426e-05, 'epoch': 0.37489333145541465, 'step': 2081500}
INFO:transformers.trainer:{'loss': 3.1983285390138625, 'learning_rate': 4.3750276914963785e-05, 'epoch': 0.37498338510217305, 'step': 2082000}
INFO:transformers.trainer:{'loss': 3.236614441394806, 'learning_rate': 4.3748776020851144e-05, 'epoch': 0.3750734387489315, 'step': 2082500}
INFO:transformers.trainer:{'loss': 3.2946946017742156, 'learning_rate': 4.37472751267385e-05, 'epoch': 0.37516349239568997, 'step': 2083000}
INFO:transformers.trainer:{'loss': 3.2718999156951902, 'learning_rate': 4.374577423262586e-05, 'epoch': 0.3752535460424484, 'step': 2083500}
INFO:transformers.trainer:{'loss': 3.3108918046951294, 'learning_rate': 4.374427333851322e-05, 'epoch': 0.37534359968920683, 'step': 2084000}
INFO:transformers.trainer:{'loss': 3.199738651752472, 'learning_rate': 4.374277244440058e-05, 'epoch': 0.3754336533359653, 'step': 2084500}
INFO:transformers.trainer:{'loss': 3.274704831600189, 'learning_rate': 4.374127155028794e-05, 'epoch': 0.37552370698272375, 'step': 2085000}
INFO:transformers.trainer:{'loss': 3.2602464337348938, 'learning_rate': 4.37397706561753e-05, 'epoch': 0.3756137606294822, 'step': 2085500}
INFO:transformers.trainer:{'loss': 3.2212632504701615, 'learning_rate': 4.373826976206266e-05, 'epoch': 0.37570381427624067, 'step': 2086000}
INFO:transformers.trainer:{'loss': 3.212742938756943, 'learning_rate': 4.3736768867950016e-05, 'epoch': 0.37579386792299907, 'step': 2086500}
INFO:transformers.trainer:{'loss': 3.2228768446445466, 'learning_rate': 4.3735267973837375e-05, 'epoch': 0.37588392156975753, 'step': 2087000}
INFO:transformers.trainer:{'loss': 3.2294302382469176, 'learning_rate': 4.3733767079724734e-05, 'epoch': 0.375973975216516, 'step': 2087500}
INFO:transformers.trainer:{'loss': 3.2335698080062865, 'learning_rate': 4.37322661856121e-05, 'epoch': 0.37606402886327445, 'step': 2088000}
INFO:transformers.trainer:{'loss': 3.2210633203983305, 'learning_rate': 4.373076529149945e-05, 'epoch': 0.37615408251003285, 'step': 2088500}
INFO:transformers.trainer:{'loss': 3.3114006180763242, 'learning_rate': 4.372926439738682e-05, 'epoch': 0.3762441361567913, 'step': 2089000}
INFO:transformers.trainer:{'loss': 3.2446679561138154, 'learning_rate': 4.372776350327417e-05, 'epoch': 0.37633418980354977, 'step': 2089500}
INFO:transformers.trainer:{'loss': 3.19841681265831, 'learning_rate': 4.3726262609161536e-05, 'epoch': 0.3764242434503082, 'step': 2090000}
INFO:transformers.trainer:{'loss': 3.2394323205947875, 'learning_rate': 4.372476171504889e-05, 'epoch': 0.3765142970970667, 'step': 2090500}
INFO:transformers.trainer:{'loss': 3.282700672388077, 'learning_rate': 4.3723260820936254e-05, 'epoch': 0.3766043507438251, 'step': 2091000}
INFO:transformers.trainer:{'loss': 3.2178503108024596, 'learning_rate': 4.372175992682361e-05, 'epoch': 0.37669440439058355, 'step': 2091500}
INFO:transformers.trainer:{'loss': 3.2442018811702726, 'learning_rate': 4.372025903271097e-05, 'epoch': 0.376784458037342, 'step': 2092000}
INFO:transformers.trainer:{'loss': 3.2460894906520843, 'learning_rate': 4.3718758138598325e-05, 'epoch': 0.37687451168410047, 'step': 2092500}
INFO:transformers.trainer:{'loss': 3.3176698179244997, 'learning_rate': 4.371725724448569e-05, 'epoch': 0.3769645653308589, 'step': 2093000}
INFO:transformers.trainer:{'loss': 3.2489125447273253, 'learning_rate': 4.371575635037304e-05, 'epoch': 0.37705461897761733, 'step': 2093500}
INFO:transformers.trainer:{'loss': 3.1777767615318298, 'learning_rate': 4.371425545626041e-05, 'epoch': 0.3771446726243758, 'step': 2094000}
INFO:transformers.trainer:{'loss': 3.271559817790985, 'learning_rate': 4.371275456214777e-05, 'epoch': 0.37723472627113425, 'step': 2094500}
INFO:transformers.trainer:{'loss': 3.1705639054775236, 'learning_rate': 4.371125366803513e-05, 'epoch': 0.3773247799178927, 'step': 2095000}
INFO:transformers.trainer:{'loss': 3.2386961764097215, 'learning_rate': 4.3709752773922486e-05, 'epoch': 0.3774148335646511, 'step': 2095500}
INFO:transformers.trainer:{'loss': 3.2376480374336243, 'learning_rate': 4.3708251879809845e-05, 'epoch': 0.37750488721140957, 'step': 2096000}
INFO:transformers.trainer:{'loss': 3.212351661682129, 'learning_rate': 4.3706750985697204e-05, 'epoch': 0.377594940858168, 'step': 2096500}
INFO:transformers.trainer:{'loss': 3.2155860662460327, 'learning_rate': 4.370525009158456e-05, 'epoch': 0.3776849945049265, 'step': 2097000}
INFO:transformers.trainer:{'loss': 3.2266505057811736, 'learning_rate': 4.370374919747192e-05, 'epoch': 0.37777504815168494, 'step': 2097500}
INFO:transformers.trainer:{'loss': 3.219116148710251, 'learning_rate': 4.370224830335928e-05, 'epoch': 0.37786510179844335, 'step': 2098000}
INFO:transformers.trainer:{'loss': 3.2398433401584623, 'learning_rate': 4.370074740924664e-05, 'epoch': 0.3779551554452018, 'step': 2098500}
INFO:transformers.trainer:{'loss': 3.23209561753273, 'learning_rate': 4.3699246515134e-05, 'epoch': 0.37804520909196027, 'step': 2099000}
INFO:transformers.trainer:{'loss': 3.232401569366455, 'learning_rate': 4.369774562102136e-05, 'epoch': 0.3781352627387187, 'step': 2099500}
INFO:transformers.trainer:{'loss': 3.2820475329756738, 'learning_rate': 4.369624472690871e-05, 'epoch': 0.3782253163854772, 'step': 2100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2100000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2000000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1885721509456633, 'learning_rate': 4.3694743832796076e-05, 'epoch': 0.3783153700322356, 'step': 2100500}
INFO:transformers.trainer:{'loss': 3.2159766634702684, 'learning_rate': 4.369324293868343e-05, 'epoch': 0.37840542367899405, 'step': 2101000}
INFO:transformers.trainer:{'loss': 3.2110082182884216, 'learning_rate': 4.3691742044570794e-05, 'epoch': 0.3784954773257525, 'step': 2101500}
INFO:transformers.trainer:{'loss': 3.2569482136964796, 'learning_rate': 4.3690241150458153e-05, 'epoch': 0.37858553097251096, 'step': 2102000}
INFO:transformers.trainer:{'loss': 3.2583225791454313, 'learning_rate': 4.368874025634551e-05, 'epoch': 0.37867558461926937, 'step': 2102500}
INFO:transformers.trainer:{'loss': 3.262675971031189, 'learning_rate': 4.368723936223287e-05, 'epoch': 0.3787656382660278, 'step': 2103000}
INFO:transformers.trainer:{'loss': 3.1973381831645966, 'learning_rate': 4.368573846812023e-05, 'epoch': 0.3788556919127863, 'step': 2103500}
INFO:transformers.trainer:{'loss': 3.2254313941001893, 'learning_rate': 4.368423757400759e-05, 'epoch': 0.37894574555954474, 'step': 2104000}
INFO:transformers.trainer:{'loss': 3.197685634613037, 'learning_rate': 4.368273667989495e-05, 'epoch': 0.3790357992063032, 'step': 2104500}
INFO:transformers.trainer:{'loss': 3.2395656049251556, 'learning_rate': 4.368123578578231e-05, 'epoch': 0.3791258528530616, 'step': 2105000}
INFO:transformers.trainer:{'loss': 3.2657884616851804, 'learning_rate': 4.367973489166967e-05, 'epoch': 0.37921590649982007, 'step': 2105500}
INFO:transformers.trainer:{'loss': 3.2147368121147157, 'learning_rate': 4.3678233997557026e-05, 'epoch': 0.3793059601465785, 'step': 2106000}
INFO:transformers.trainer:{'loss': 3.2361076996326448, 'learning_rate': 4.3676733103444385e-05, 'epoch': 0.379396013793337, 'step': 2106500}
INFO:transformers.trainer:{'loss': 3.302428528547287, 'learning_rate': 4.3675232209331744e-05, 'epoch': 0.3794860674400954, 'step': 2107000}
INFO:transformers.trainer:{'loss': 3.1523566868305206, 'learning_rate': 4.36737313152191e-05, 'epoch': 0.37957612108685385, 'step': 2107500}
INFO:transformers.trainer:{'loss': 3.203236106157303, 'learning_rate': 4.367223042110646e-05, 'epoch': 0.3796661747336123, 'step': 2108000}
INFO:transformers.trainer:{'loss': 3.258508133172989, 'learning_rate': 4.367072952699383e-05, 'epoch': 0.37975622838037076, 'step': 2108500}
INFO:transformers.trainer:{'loss': 3.2026095261573793, 'learning_rate': 4.366922863288118e-05, 'epoch': 0.3798462820271292, 'step': 2109000}
INFO:transformers.trainer:{'loss': 3.2427746078968047, 'learning_rate': 4.3667727738768546e-05, 'epoch': 0.3799363356738876, 'step': 2109500}
INFO:transformers.trainer:{'loss': 3.1938032191991805, 'learning_rate': 4.36662268446559e-05, 'epoch': 0.3800263893206461, 'step': 2110000}
INFO:transformers.trainer:{'loss': 3.240262768268585, 'learning_rate': 4.3664725950543264e-05, 'epoch': 0.38011644296740454, 'step': 2110500}
INFO:transformers.trainer:{'loss': 3.271879057407379, 'learning_rate': 4.3663225056430616e-05, 'epoch': 0.380206496614163, 'step': 2111000}
INFO:transformers.trainer:{'loss': 3.2891775534152985, 'learning_rate': 4.366172416231798e-05, 'epoch': 0.38029655026092146, 'step': 2111500}
INFO:transformers.trainer:{'loss': 3.1584784188270567, 'learning_rate': 4.3660223268205334e-05, 'epoch': 0.38038660390767987, 'step': 2112000}
INFO:transformers.trainer:{'loss': 3.2404023160934448, 'learning_rate': 4.36587223740927e-05, 'epoch': 0.3804766575544383, 'step': 2112500}
INFO:transformers.trainer:{'loss': 3.235067009449005, 'learning_rate': 4.365722147998005e-05, 'epoch': 0.3805667112011968, 'step': 2113000}
INFO:transformers.trainer:{'loss': 3.3198848925828934, 'learning_rate': 4.365572058586742e-05, 'epoch': 0.38065676484795524, 'step': 2113500}
INFO:transformers.trainer:{'loss': 3.2391061561107635, 'learning_rate': 4.365421969175477e-05, 'epoch': 0.38074681849471365, 'step': 2114000}
INFO:transformers.trainer:{'loss': 3.2530037218332293, 'learning_rate': 4.3652718797642136e-05, 'epoch': 0.3808368721414721, 'step': 2114500}
INFO:transformers.trainer:{'loss': 3.324244078874588, 'learning_rate': 4.365121790352949e-05, 'epoch': 0.38092692578823056, 'step': 2115000}
INFO:transformers.trainer:{'loss': 3.2620155096054075, 'learning_rate': 4.3649717009416855e-05, 'epoch': 0.381016979434989, 'step': 2115500}
INFO:transformers.trainer:{'loss': 3.2291799244880677, 'learning_rate': 4.3648216115304214e-05, 'epoch': 0.3811070330817475, 'step': 2116000}
INFO:transformers.trainer:{'loss': 3.204328210234642, 'learning_rate': 4.364671522119157e-05, 'epoch': 0.3811970867285059, 'step': 2116500}
INFO:transformers.trainer:{'loss': 3.2178025796413423, 'learning_rate': 4.364521432707893e-05, 'epoch': 0.38128714037526434, 'step': 2117000}
INFO:transformers.trainer:{'loss': 3.241910305023193, 'learning_rate': 4.364371343296629e-05, 'epoch': 0.3813771940220228, 'step': 2117500}
INFO:transformers.trainer:{'loss': 3.2270384380817414, 'learning_rate': 4.364221253885365e-05, 'epoch': 0.38146724766878126, 'step': 2118000}
INFO:transformers.trainer:{'loss': 3.214972209453583, 'learning_rate': 4.364071164474101e-05, 'epoch': 0.3815573013155397, 'step': 2118500}
INFO:transformers.trainer:{'loss': 3.269580836772919, 'learning_rate': 4.363921075062837e-05, 'epoch': 0.3816473549622981, 'step': 2119000}
INFO:transformers.trainer:{'loss': 3.3099449691772462, 'learning_rate': 4.363770985651573e-05, 'epoch': 0.3817374086090566, 'step': 2119500}
INFO:transformers.trainer:{'loss': 3.2227067766189577, 'learning_rate': 4.3636208962403086e-05, 'epoch': 0.38182746225581504, 'step': 2120000}
INFO:transformers.trainer:{'loss': 3.3209019050598143, 'learning_rate': 4.3634708068290445e-05, 'epoch': 0.3819175159025735, 'step': 2120500}
INFO:transformers.trainer:{'loss': 3.243857581138611, 'learning_rate': 4.3633207174177804e-05, 'epoch': 0.3820075695493319, 'step': 2121000}
INFO:transformers.trainer:{'loss': 3.2574238684177397, 'learning_rate': 4.363170628006516e-05, 'epoch': 0.38209762319609036, 'step': 2121500}
INFO:transformers.trainer:{'loss': 3.270325507879257, 'learning_rate': 4.363020538595252e-05, 'epoch': 0.3821876768428488, 'step': 2122000}
INFO:transformers.trainer:{'loss': 3.2236965119838716, 'learning_rate': 4.362870449183988e-05, 'epoch': 0.3822777304896073, 'step': 2122500}
INFO:transformers.trainer:{'loss': 3.2284476962089537, 'learning_rate': 4.362720359772724e-05, 'epoch': 0.38236778413636574, 'step': 2123000}
INFO:transformers.trainer:{'loss': 3.242700350046158, 'learning_rate': 4.36257027036146e-05, 'epoch': 0.38245783778312414, 'step': 2123500}
INFO:transformers.trainer:{'loss': 3.2467678966522215, 'learning_rate': 4.362420180950196e-05, 'epoch': 0.3825478914298826, 'step': 2124000}
INFO:transformers.trainer:{'loss': 3.217811675786972, 'learning_rate': 4.362270091538932e-05, 'epoch': 0.38263794507664106, 'step': 2124500}
INFO:transformers.trainer:{'loss': 3.2333999087810517, 'learning_rate': 4.3621200021276677e-05, 'epoch': 0.3827279987233995, 'step': 2125000}
INFO:transformers.trainer:{'loss': 3.209591989994049, 'learning_rate': 4.3619699127164036e-05, 'epoch': 0.3828180523701579, 'step': 2125500}
INFO:transformers.trainer:{'loss': 3.274962276697159, 'learning_rate': 4.3618198233051395e-05, 'epoch': 0.3829081060169164, 'step': 2126000}
INFO:transformers.trainer:{'loss': 3.289470504999161, 'learning_rate': 4.3616697338938754e-05, 'epoch': 0.38299815966367484, 'step': 2126500}
INFO:transformers.trainer:{'loss': 3.246870889425278, 'learning_rate': 4.361519644482611e-05, 'epoch': 0.3830882133104333, 'step': 2127000}
INFO:transformers.trainer:{'loss': 3.232948759794235, 'learning_rate': 4.361369555071347e-05, 'epoch': 0.38317826695719176, 'step': 2127500}
INFO:transformers.trainer:{'loss': 3.1995649788379668, 'learning_rate': 4.361219465660083e-05, 'epoch': 0.38326832060395016, 'step': 2128000}
INFO:transformers.trainer:{'loss': 3.2652769916057585, 'learning_rate': 4.361069376248819e-05, 'epoch': 0.3833583742507086, 'step': 2128500}
INFO:transformers.trainer:{'loss': 3.2903628673553467, 'learning_rate': 4.3609192868375556e-05, 'epoch': 0.3834484278974671, 'step': 2129000}
INFO:transformers.trainer:{'loss': 3.1892517799139024, 'learning_rate': 4.360769197426291e-05, 'epoch': 0.38353848154422554, 'step': 2129500}
INFO:transformers.trainer:{'loss': 3.2051335372924803, 'learning_rate': 4.3606191080150274e-05, 'epoch': 0.383628535190984, 'step': 2130000}
INFO:transformers.trainer:{'loss': 3.258826183319092, 'learning_rate': 4.3604690186037626e-05, 'epoch': 0.3837185888377424, 'step': 2130500}
INFO:transformers.trainer:{'loss': 3.277030678987503, 'learning_rate': 4.360318929192499e-05, 'epoch': 0.38380864248450086, 'step': 2131000}
INFO:transformers.trainer:{'loss': 3.1738817602396012, 'learning_rate': 4.3601688397812344e-05, 'epoch': 0.3838986961312593, 'step': 2131500}
INFO:transformers.trainer:{'loss': 3.21726059114933, 'learning_rate': 4.360018750369971e-05, 'epoch': 0.3839887497780178, 'step': 2132000}
INFO:transformers.trainer:{'loss': 3.211402714729309, 'learning_rate': 4.359868660958706e-05, 'epoch': 0.3840788034247762, 'step': 2132500}
INFO:transformers.trainer:{'loss': 3.2355951738357542, 'learning_rate': 4.359718571547443e-05, 'epoch': 0.38416885707153464, 'step': 2133000}
INFO:transformers.trainer:{'loss': 3.23310976934433, 'learning_rate': 4.359568482136178e-05, 'epoch': 0.3842589107182931, 'step': 2133500}
INFO:transformers.trainer:{'loss': 3.21231183886528, 'learning_rate': 4.3594183927249146e-05, 'epoch': 0.38434896436505156, 'step': 2134000}
INFO:transformers.trainer:{'loss': 3.2136000862121583, 'learning_rate': 4.35926830331365e-05, 'epoch': 0.38443901801181, 'step': 2134500}
INFO:transformers.trainer:{'loss': 3.25908444583416, 'learning_rate': 4.3591182139023864e-05, 'epoch': 0.3845290716585684, 'step': 2135000}
INFO:transformers.trainer:{'loss': 3.2310162484645844, 'learning_rate': 4.3589681244911217e-05, 'epoch': 0.3846191253053269, 'step': 2135500}
INFO:transformers.trainer:{'loss': 3.263295265197754, 'learning_rate': 4.358818035079858e-05, 'epoch': 0.38470917895208534, 'step': 2136000}
INFO:transformers.trainer:{'loss': 3.2946808791160582, 'learning_rate': 4.358667945668594e-05, 'epoch': 0.3847992325988438, 'step': 2136500}
INFO:transformers.trainer:{'loss': 3.2065480213165283, 'learning_rate': 4.35851785625733e-05, 'epoch': 0.38488928624560226, 'step': 2137000}
INFO:transformers.trainer:{'loss': 3.2689222660064696, 'learning_rate': 4.358367766846066e-05, 'epoch': 0.38497933989236066, 'step': 2137500}
INFO:transformers.trainer:{'loss': 3.2742647559642792, 'learning_rate': 4.358217677434802e-05, 'epoch': 0.3850693935391191, 'step': 2138000}
INFO:transformers.trainer:{'loss': 3.2884481308460236, 'learning_rate': 4.358067588023538e-05, 'epoch': 0.3851594471858776, 'step': 2138500}
INFO:transformers.trainer:{'loss': 3.27059154009819, 'learning_rate': 4.357917498612274e-05, 'epoch': 0.38524950083263604, 'step': 2139000}
INFO:transformers.trainer:{'loss': 3.2109479675292967, 'learning_rate': 4.3577674092010096e-05, 'epoch': 0.38533955447939444, 'step': 2139500}
INFO:transformers.trainer:{'loss': 3.248010622262955, 'learning_rate': 4.3576173197897455e-05, 'epoch': 0.3854296081261529, 'step': 2140000}
INFO:transformers.trainer:{'loss': 3.2472391724586487, 'learning_rate': 4.3574672303784814e-05, 'epoch': 0.38551966177291136, 'step': 2140500}
INFO:transformers.trainer:{'loss': 3.2600117976665497, 'learning_rate': 4.357317140967217e-05, 'epoch': 0.3856097154196698, 'step': 2141000}
INFO:transformers.trainer:{'loss': 3.223992998838425, 'learning_rate': 4.357167051555953e-05, 'epoch': 0.3856997690664283, 'step': 2141500}
INFO:transformers.trainer:{'loss': 3.2012159090042114, 'learning_rate': 4.357016962144689e-05, 'epoch': 0.3857898227131867, 'step': 2142000}
INFO:transformers.trainer:{'loss': 3.186894674539566, 'learning_rate': 4.356866872733425e-05, 'epoch': 0.38587987635994514, 'step': 2142500}
INFO:transformers.trainer:{'loss': 3.227030905365944, 'learning_rate': 4.356716783322161e-05, 'epoch': 0.3859699300067036, 'step': 2143000}
INFO:transformers.trainer:{'loss': 3.2567126708030703, 'learning_rate': 4.356566693910897e-05, 'epoch': 0.38605998365346206, 'step': 2143500}
INFO:transformers.trainer:{'loss': 3.234965794801712, 'learning_rate': 4.356416604499633e-05, 'epoch': 0.38615003730022046, 'step': 2144000}
INFO:transformers.trainer:{'loss': 3.23559165596962, 'learning_rate': 4.3562665150883686e-05, 'epoch': 0.3862400909469789, 'step': 2144500}
INFO:transformers.trainer:{'loss': 3.200108204126358, 'learning_rate': 4.3561164256771045e-05, 'epoch': 0.3863301445937374, 'step': 2145000}
INFO:transformers.trainer:{'loss': 3.286110251903534, 'learning_rate': 4.3559663362658404e-05, 'epoch': 0.38642019824049584, 'step': 2145500}
INFO:transformers.trainer:{'loss': 3.1963633875846864, 'learning_rate': 4.3558162468545763e-05, 'epoch': 0.3865102518872543, 'step': 2146000}
INFO:transformers.trainer:{'loss': 3.246275307893753, 'learning_rate': 4.355666157443312e-05, 'epoch': 0.3866003055340127, 'step': 2146500}
INFO:transformers.trainer:{'loss': 3.192621374130249, 'learning_rate': 4.355516068032048e-05, 'epoch': 0.38669035918077116, 'step': 2147000}
INFO:transformers.trainer:{'loss': 3.228166699886322, 'learning_rate': 4.355365978620784e-05, 'epoch': 0.3867804128275296, 'step': 2147500}
INFO:transformers.trainer:{'loss': 3.2346126960515975, 'learning_rate': 4.35521588920952e-05, 'epoch': 0.3868704664742881, 'step': 2148000}
INFO:transformers.trainer:{'loss': 3.1748102407455443, 'learning_rate': 4.355065799798256e-05, 'epoch': 0.38696052012104654, 'step': 2148500}
INFO:transformers.trainer:{'loss': 3.222712066888809, 'learning_rate': 4.354915710386992e-05, 'epoch': 0.38705057376780494, 'step': 2149000}
INFO:transformers.trainer:{'loss': 3.1942826490402223, 'learning_rate': 4.354765620975728e-05, 'epoch': 0.3871406274145634, 'step': 2149500}
INFO:transformers.trainer:{'loss': 3.232248996257782, 'learning_rate': 4.3546155315644636e-05, 'epoch': 0.38723068106132186, 'step': 2150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2050000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2592712471485137, 'learning_rate': 4.3544654421532e-05, 'epoch': 0.3873207347080803, 'step': 2150500}
INFO:transformers.trainer:{'loss': 3.1942112901210784, 'learning_rate': 4.3543153527419354e-05, 'epoch': 0.3874107883548387, 'step': 2151000}
INFO:transformers.trainer:{'loss': 3.222030504703522, 'learning_rate': 4.354165263330672e-05, 'epoch': 0.3875008420015972, 'step': 2151500}
INFO:transformers.trainer:{'loss': 3.220473016023636, 'learning_rate': 4.354015173919407e-05, 'epoch': 0.38759089564835564, 'step': 2152000}
INFO:transformers.trainer:{'loss': 3.2573262536525727, 'learning_rate': 4.353865084508144e-05, 'epoch': 0.3876809492951141, 'step': 2152500}
INFO:transformers.trainer:{'loss': 3.2395780227184297, 'learning_rate': 4.353714995096879e-05, 'epoch': 0.38777100294187256, 'step': 2153000}
INFO:transformers.trainer:{'loss': 3.2543637411594393, 'learning_rate': 4.3535649056856156e-05, 'epoch': 0.38786105658863096, 'step': 2153500}
INFO:transformers.trainer:{'loss': 3.2871373655796052, 'learning_rate': 4.353414816274351e-05, 'epoch': 0.3879511102353894, 'step': 2154000}
INFO:transformers.trainer:{'loss': 3.2371712951660156, 'learning_rate': 4.3532647268630874e-05, 'epoch': 0.3880411638821479, 'step': 2154500}
INFO:transformers.trainer:{'loss': 3.215914176940918, 'learning_rate': 4.3531146374518226e-05, 'epoch': 0.38813121752890634, 'step': 2155000}
INFO:transformers.trainer:{'loss': 3.2363427851200104, 'learning_rate': 4.352964548040559e-05, 'epoch': 0.38822127117566474, 'step': 2155500}
INFO:transformers.trainer:{'loss': 3.257707223653793, 'learning_rate': 4.3528144586292944e-05, 'epoch': 0.3883113248224232, 'step': 2156000}
INFO:transformers.trainer:{'loss': 3.2403208203315734, 'learning_rate': 4.352664369218031e-05, 'epoch': 0.38840137846918166, 'step': 2156500}
INFO:transformers.trainer:{'loss': 3.176329114675522, 'learning_rate': 4.352514279806767e-05, 'epoch': 0.3884914321159401, 'step': 2157000}
INFO:transformers.trainer:{'loss': 3.2533721261024473, 'learning_rate': 4.352364190395503e-05, 'epoch': 0.3885814857626986, 'step': 2157500}
INFO:transformers.trainer:{'loss': 3.2152780652046205, 'learning_rate': 4.352214100984239e-05, 'epoch': 0.388671539409457, 'step': 2158000}
INFO:transformers.trainer:{'loss': 3.2728046875, 'learning_rate': 4.3520640115729746e-05, 'epoch': 0.38876159305621544, 'step': 2158500}
INFO:transformers.trainer:{'loss': 3.248600220680237, 'learning_rate': 4.3519139221617106e-05, 'epoch': 0.3888516467029739, 'step': 2159000}
INFO:transformers.trainer:{'loss': 3.263780603647232, 'learning_rate': 4.3517638327504465e-05, 'epoch': 0.38894170034973236, 'step': 2159500}
INFO:transformers.trainer:{'loss': 3.205312739491463, 'learning_rate': 4.3516137433391824e-05, 'epoch': 0.3890317539964908, 'step': 2160000}
INFO:transformers.trainer:{'loss': 3.2413206136226655, 'learning_rate': 4.351463653927918e-05, 'epoch': 0.3891218076432492, 'step': 2160500}
INFO:transformers.trainer:{'loss': 3.2685759513378145, 'learning_rate': 4.351313564516654e-05, 'epoch': 0.3892118612900077, 'step': 2161000}
INFO:transformers.trainer:{'loss': 3.1883176515102387, 'learning_rate': 4.35116347510539e-05, 'epoch': 0.38930191493676614, 'step': 2161500}
INFO:transformers.trainer:{'loss': 3.2742759877443315, 'learning_rate': 4.351013385694126e-05, 'epoch': 0.3893919685835246, 'step': 2162000}
INFO:transformers.trainer:{'loss': 3.1918444647789, 'learning_rate': 4.350863296282862e-05, 'epoch': 0.389482022230283, 'step': 2162500}
INFO:transformers.trainer:{'loss': 3.141410558462143, 'learning_rate': 4.350713206871598e-05, 'epoch': 0.38957207587704146, 'step': 2163000}
INFO:transformers.trainer:{'loss': 3.2804208855628967, 'learning_rate': 4.350563117460334e-05, 'epoch': 0.3896621295237999, 'step': 2163500}
INFO:transformers.trainer:{'loss': 3.209328287601471, 'learning_rate': 4.3504130280490696e-05, 'epoch': 0.3897521831705584, 'step': 2164000}
INFO:transformers.trainer:{'loss': 3.2206810755729673, 'learning_rate': 4.3502629386378055e-05, 'epoch': 0.38984223681731683, 'step': 2164500}
INFO:transformers.trainer:{'loss': 3.2861670269966123, 'learning_rate': 4.3501128492265414e-05, 'epoch': 0.38993229046407524, 'step': 2165000}
INFO:transformers.trainer:{'loss': 3.2189650480747223, 'learning_rate': 4.349962759815277e-05, 'epoch': 0.3900223441108337, 'step': 2165500}
INFO:transformers.trainer:{'loss': 3.2313899240493775, 'learning_rate': 4.349812670404013e-05, 'epoch': 0.39011239775759216, 'step': 2166000}
INFO:transformers.trainer:{'loss': 3.2896478562355043, 'learning_rate': 4.349662580992749e-05, 'epoch': 0.3902024514043506, 'step': 2166500}
INFO:transformers.trainer:{'loss': 3.214060824394226, 'learning_rate': 4.349512491581485e-05, 'epoch': 0.3902925050511091, 'step': 2167000}
INFO:transformers.trainer:{'loss': 3.2537143113613127, 'learning_rate': 4.349362402170221e-05, 'epoch': 0.3903825586978675, 'step': 2167500}
INFO:transformers.trainer:{'loss': 3.2409783833026884, 'learning_rate': 4.349212312758957e-05, 'epoch': 0.39047261234462594, 'step': 2168000}
INFO:transformers.trainer:{'loss': 3.2445413076877596, 'learning_rate': 4.349062223347693e-05, 'epoch': 0.3905626659913844, 'step': 2168500}
INFO:transformers.trainer:{'loss': 3.2472755472660064, 'learning_rate': 4.3489121339364287e-05, 'epoch': 0.39065271963814285, 'step': 2169000}
INFO:transformers.trainer:{'loss': 3.256975031614304, 'learning_rate': 4.3487620445251646e-05, 'epoch': 0.39074277328490126, 'step': 2169500}
INFO:transformers.trainer:{'loss': 3.2225449159145354, 'learning_rate': 4.3486119551139005e-05, 'epoch': 0.3908328269316597, 'step': 2170000}
INFO:transformers.trainer:{'loss': 3.2357323577404022, 'learning_rate': 4.3484618657026364e-05, 'epoch': 0.3909228805784182, 'step': 2170500}
INFO:transformers.trainer:{'loss': 3.259715096592903, 'learning_rate': 4.348311776291373e-05, 'epoch': 0.39101293422517663, 'step': 2171000}
INFO:transformers.trainer:{'loss': 3.204636454105377, 'learning_rate': 4.348161686880108e-05, 'epoch': 0.3911029878719351, 'step': 2171500}
INFO:transformers.trainer:{'loss': 3.1944392323493958, 'learning_rate': 4.348011597468845e-05, 'epoch': 0.3911930415186935, 'step': 2172000}
INFO:transformers.trainer:{'loss': 3.2252914888858797, 'learning_rate': 4.34786150805758e-05, 'epoch': 0.39128309516545196, 'step': 2172500}
INFO:transformers.trainer:{'loss': 3.243438606977463, 'learning_rate': 4.3477114186463166e-05, 'epoch': 0.3913731488122104, 'step': 2173000}
INFO:transformers.trainer:{'loss': 3.322463243961334, 'learning_rate': 4.347561329235052e-05, 'epoch': 0.3914632024589689, 'step': 2173500}
INFO:transformers.trainer:{'loss': 3.242867904186249, 'learning_rate': 4.3474112398237884e-05, 'epoch': 0.3915532561057273, 'step': 2174000}
INFO:transformers.trainer:{'loss': 3.2345027890205382, 'learning_rate': 4.3472611504125236e-05, 'epoch': 0.39164330975248574, 'step': 2174500}
INFO:transformers.trainer:{'loss': 3.286600450992584, 'learning_rate': 4.34711106100126e-05, 'epoch': 0.3917333633992442, 'step': 2175000}
INFO:transformers.trainer:{'loss': 3.250052699327469, 'learning_rate': 4.3469609715899954e-05, 'epoch': 0.39182341704600265, 'step': 2175500}
INFO:transformers.trainer:{'loss': 3.2004793653488157, 'learning_rate': 4.346810882178732e-05, 'epoch': 0.3919134706927611, 'step': 2176000}
INFO:transformers.trainer:{'loss': 3.233552751302719, 'learning_rate': 4.346660792767467e-05, 'epoch': 0.3920035243395195, 'step': 2176500}
INFO:transformers.trainer:{'loss': 3.2514819991588593, 'learning_rate': 4.346510703356204e-05, 'epoch': 0.392093577986278, 'step': 2177000}
INFO:transformers.trainer:{'loss': 3.22307177734375, 'learning_rate': 4.34636061394494e-05, 'epoch': 0.39218363163303643, 'step': 2177500}
INFO:transformers.trainer:{'loss': 3.217881104707718, 'learning_rate': 4.3462105245336756e-05, 'epoch': 0.3922736852797949, 'step': 2178000}
INFO:transformers.trainer:{'loss': 3.2556883499622344, 'learning_rate': 4.3460604351224115e-05, 'epoch': 0.39236373892655335, 'step': 2178500}
INFO:transformers.trainer:{'loss': 3.204691758155823, 'learning_rate': 4.3459103457111474e-05, 'epoch': 0.39245379257331175, 'step': 2179000}
INFO:transformers.trainer:{'loss': 3.204208423733711, 'learning_rate': 4.345760256299883e-05, 'epoch': 0.3925438462200702, 'step': 2179500}
INFO:transformers.trainer:{'loss': 3.218305401802063, 'learning_rate': 4.345610166888619e-05, 'epoch': 0.3926338998668287, 'step': 2180000}
INFO:transformers.trainer:{'loss': 3.24575561773777, 'learning_rate': 4.345460077477355e-05, 'epoch': 0.39272395351358713, 'step': 2180500}
INFO:transformers.trainer:{'loss': 3.2356953802108763, 'learning_rate': 4.345309988066091e-05, 'epoch': 0.39281400716034554, 'step': 2181000}
INFO:transformers.trainer:{'loss': 3.215876525402069, 'learning_rate': 4.345159898654827e-05, 'epoch': 0.392904060807104, 'step': 2181500}
INFO:transformers.trainer:{'loss': 3.2123802423477175, 'learning_rate': 4.345009809243563e-05, 'epoch': 0.39299411445386245, 'step': 2182000}
INFO:transformers.trainer:{'loss': 3.2078433921337126, 'learning_rate': 4.344859719832299e-05, 'epoch': 0.3930841681006209, 'step': 2182500}
INFO:transformers.trainer:{'loss': 3.242737801074982, 'learning_rate': 4.344709630421035e-05, 'epoch': 0.39317422174737937, 'step': 2183000}
INFO:transformers.trainer:{'loss': 3.238976029753685, 'learning_rate': 4.3445595410097706e-05, 'epoch': 0.3932642753941378, 'step': 2183500}
INFO:transformers.trainer:{'loss': 3.1961241154670716, 'learning_rate': 4.3444094515985065e-05, 'epoch': 0.39335432904089623, 'step': 2184000}
INFO:transformers.trainer:{'loss': 3.1950774545669556, 'learning_rate': 4.3442593621872424e-05, 'epoch': 0.3934443826876547, 'step': 2184500}
INFO:transformers.trainer:{'loss': 3.255426458120346, 'learning_rate': 4.344109272775978e-05, 'epoch': 0.39353443633441315, 'step': 2185000}
INFO:transformers.trainer:{'loss': 3.1610114438533783, 'learning_rate': 4.343959183364714e-05, 'epoch': 0.3936244899811716, 'step': 2185500}
INFO:transformers.trainer:{'loss': 3.2311862154006956, 'learning_rate': 4.34380909395345e-05, 'epoch': 0.39371454362793, 'step': 2186000}
INFO:transformers.trainer:{'loss': 3.208941086769104, 'learning_rate': 4.343659004542186e-05, 'epoch': 0.3938045972746885, 'step': 2186500}
INFO:transformers.trainer:{'loss': 3.263454211235046, 'learning_rate': 4.343508915130922e-05, 'epoch': 0.39389465092144693, 'step': 2187000}
INFO:transformers.trainer:{'loss': 3.217566919803619, 'learning_rate': 4.343358825719658e-05, 'epoch': 0.3939847045682054, 'step': 2187500}
INFO:transformers.trainer:{'loss': 3.2724329648017885, 'learning_rate': 4.343208736308394e-05, 'epoch': 0.3940747582149638, 'step': 2188000}
INFO:transformers.trainer:{'loss': 3.184649328947067, 'learning_rate': 4.3430586468971296e-05, 'epoch': 0.39416481186172225, 'step': 2188500}
INFO:transformers.trainer:{'loss': 3.236526398897171, 'learning_rate': 4.3429085574858655e-05, 'epoch': 0.3942548655084807, 'step': 2189000}
INFO:transformers.trainer:{'loss': 3.234199404478073, 'learning_rate': 4.3427584680746014e-05, 'epoch': 0.39434491915523917, 'step': 2189500}
INFO:transformers.trainer:{'loss': 3.2322294495105743, 'learning_rate': 4.342608378663337e-05, 'epoch': 0.39443497280199763, 'step': 2190000}
INFO:transformers.trainer:{'loss': 3.226343300819397, 'learning_rate': 4.342458289252073e-05, 'epoch': 0.39452502644875603, 'step': 2190500}
INFO:transformers.trainer:{'loss': 3.2565933971405028, 'learning_rate': 4.342308199840809e-05, 'epoch': 0.3946150800955145, 'step': 2191000}
INFO:transformers.trainer:{'loss': 3.1525111976861955, 'learning_rate': 4.342158110429546e-05, 'epoch': 0.39470513374227295, 'step': 2191500}
INFO:transformers.trainer:{'loss': 3.2260065457820892, 'learning_rate': 4.342008021018281e-05, 'epoch': 0.3947951873890314, 'step': 2192000}
INFO:transformers.trainer:{'loss': 3.218012906551361, 'learning_rate': 4.3418579316070175e-05, 'epoch': 0.3948852410357898, 'step': 2192500}
INFO:transformers.trainer:{'loss': 3.2622234816551208, 'learning_rate': 4.341707842195753e-05, 'epoch': 0.3949752946825483, 'step': 2193000}
INFO:transformers.trainer:{'loss': 3.257795111656189, 'learning_rate': 4.3415577527844894e-05, 'epoch': 0.39506534832930673, 'step': 2193500}
INFO:transformers.trainer:{'loss': 3.2531302394866946, 'learning_rate': 4.3414076633732246e-05, 'epoch': 0.3951554019760652, 'step': 2194000}
INFO:transformers.trainer:{'loss': 3.2285756614208223, 'learning_rate': 4.341257573961961e-05, 'epoch': 0.39524545562282365, 'step': 2194500}
INFO:transformers.trainer:{'loss': 3.2222281143665312, 'learning_rate': 4.3411074845506964e-05, 'epoch': 0.39533550926958205, 'step': 2195000}
INFO:transformers.trainer:{'loss': 3.2172177048921586, 'learning_rate': 4.340957395139433e-05, 'epoch': 0.3954255629163405, 'step': 2195500}
INFO:transformers.trainer:{'loss': 3.1974177392721175, 'learning_rate': 4.340807305728168e-05, 'epoch': 0.39551561656309897, 'step': 2196000}
INFO:transformers.trainer:{'loss': 3.159558274269104, 'learning_rate': 4.340657216316905e-05, 'epoch': 0.39560567020985743, 'step': 2196500}
INFO:transformers.trainer:{'loss': 3.254784874677658, 'learning_rate': 4.34050712690564e-05, 'epoch': 0.3956957238566159, 'step': 2197000}
INFO:transformers.trainer:{'loss': 3.288527500987053, 'learning_rate': 4.3403570374943766e-05, 'epoch': 0.3957857775033743, 'step': 2197500}
INFO:transformers.trainer:{'loss': 3.2120221445560455, 'learning_rate': 4.340206948083112e-05, 'epoch': 0.39587583115013275, 'step': 2198000}
INFO:transformers.trainer:{'loss': 3.233773092985153, 'learning_rate': 4.3400568586718484e-05, 'epoch': 0.3959658847968912, 'step': 2198500}
INFO:transformers.trainer:{'loss': 3.2995432255268096, 'learning_rate': 4.339906769260584e-05, 'epoch': 0.39605593844364967, 'step': 2199000}
INFO:transformers.trainer:{'loss': 3.203817718267441, 'learning_rate': 4.33975667984932e-05, 'epoch': 0.3961459920904081, 'step': 2199500}
INFO:transformers.trainer:{'loss': 3.2392240552902223, 'learning_rate': 4.339606590438056e-05, 'epoch': 0.39623604573716653, 'step': 2200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1874264612197876, 'learning_rate': 4.339456501026792e-05, 'epoch': 0.396326099383925, 'step': 2200500}
INFO:transformers.trainer:{'loss': 3.2231359510421753, 'learning_rate': 4.339306411615528e-05, 'epoch': 0.39641615303068345, 'step': 2201000}
INFO:transformers.trainer:{'loss': 3.2602902073860167, 'learning_rate': 4.339156322204264e-05, 'epoch': 0.3965062066774419, 'step': 2201500}
INFO:transformers.trainer:{'loss': 3.207778045654297, 'learning_rate': 4.339006232793e-05, 'epoch': 0.3965962603242003, 'step': 2202000}
INFO:transformers.trainer:{'loss': 3.189767416477203, 'learning_rate': 4.3388561433817356e-05, 'epoch': 0.39668631397095877, 'step': 2202500}
INFO:transformers.trainer:{'loss': 3.269591833114624, 'learning_rate': 4.3387060539704715e-05, 'epoch': 0.39677636761771723, 'step': 2203000}
INFO:transformers.trainer:{'loss': 3.261062518119812, 'learning_rate': 4.3385559645592075e-05, 'epoch': 0.3968664212644757, 'step': 2203500}
INFO:transformers.trainer:{'loss': 3.19330770277977, 'learning_rate': 4.3384058751479434e-05, 'epoch': 0.39695647491123415, 'step': 2204000}
INFO:transformers.trainer:{'loss': 3.205479394197464, 'learning_rate': 4.338255785736679e-05, 'epoch': 0.39704652855799255, 'step': 2204500}
INFO:transformers.trainer:{'loss': 3.1879190015792847, 'learning_rate': 4.338105696325415e-05, 'epoch': 0.397136582204751, 'step': 2205000}
INFO:transformers.trainer:{'loss': 3.2297598395347595, 'learning_rate': 4.337955606914151e-05, 'epoch': 0.39722663585150947, 'step': 2205500}
INFO:transformers.trainer:{'loss': 3.2258003273010254, 'learning_rate': 4.337805517502887e-05, 'epoch': 0.3973166894982679, 'step': 2206000}
INFO:transformers.trainer:{'loss': 3.204251933813095, 'learning_rate': 4.337655428091623e-05, 'epoch': 0.39740674314502633, 'step': 2206500}
INFO:transformers.trainer:{'loss': 3.1784278185367585, 'learning_rate': 4.337505338680359e-05, 'epoch': 0.3974967967917848, 'step': 2207000}
INFO:transformers.trainer:{'loss': 3.252869562506676, 'learning_rate': 4.337355249269095e-05, 'epoch': 0.39758685043854325, 'step': 2207500}
INFO:transformers.trainer:{'loss': 3.254869875192642, 'learning_rate': 4.3372051598578306e-05, 'epoch': 0.3976769040853017, 'step': 2208000}
INFO:transformers.trainer:{'loss': 3.196625718355179, 'learning_rate': 4.3370550704465665e-05, 'epoch': 0.39776695773206017, 'step': 2208500}
INFO:transformers.trainer:{'loss': 3.208042238473892, 'learning_rate': 4.3369049810353024e-05, 'epoch': 0.39785701137881857, 'step': 2209000}
INFO:transformers.trainer:{'loss': 3.246797476172447, 'learning_rate': 4.336754891624038e-05, 'epoch': 0.39794706502557703, 'step': 2209500}
INFO:transformers.trainer:{'loss': 3.251102376461029, 'learning_rate': 4.336604802212774e-05, 'epoch': 0.3980371186723355, 'step': 2210000}
INFO:transformers.trainer:{'loss': 3.2100329699516297, 'learning_rate': 4.33645471280151e-05, 'epoch': 0.39812717231909395, 'step': 2210500}
INFO:transformers.trainer:{'loss': 3.1740898740291597, 'learning_rate': 4.336304623390246e-05, 'epoch': 0.39821722596585235, 'step': 2211000}
INFO:transformers.trainer:{'loss': 3.2347011499404905, 'learning_rate': 4.336154533978982e-05, 'epoch': 0.3983072796126108, 'step': 2211500}
INFO:transformers.trainer:{'loss': 3.250190493106842, 'learning_rate': 4.336004444567718e-05, 'epoch': 0.39839733325936927, 'step': 2212000}
INFO:transformers.trainer:{'loss': 3.2477268466949463, 'learning_rate': 4.335854355156454e-05, 'epoch': 0.3984873869061277, 'step': 2212500}
INFO:transformers.trainer:{'loss': 3.2110375964641573, 'learning_rate': 4.33570426574519e-05, 'epoch': 0.3985774405528862, 'step': 2213000}
INFO:transformers.trainer:{'loss': 3.209690631747246, 'learning_rate': 4.3355541763339256e-05, 'epoch': 0.3986674941996446, 'step': 2213500}
INFO:transformers.trainer:{'loss': 3.223040118455887, 'learning_rate': 4.335404086922662e-05, 'epoch': 0.39875754784640305, 'step': 2214000}
INFO:transformers.trainer:{'loss': 3.2414015469551085, 'learning_rate': 4.3352539975113974e-05, 'epoch': 0.3988476014931615, 'step': 2214500}
INFO:transformers.trainer:{'loss': 3.253489127397537, 'learning_rate': 4.335103908100134e-05, 'epoch': 0.39893765513991997, 'step': 2215000}
INFO:transformers.trainer:{'loss': 3.2559044321775437, 'learning_rate': 4.334953818688869e-05, 'epoch': 0.3990277087866784, 'step': 2215500}
INFO:transformers.trainer:{'loss': 3.2416189815998075, 'learning_rate': 4.334803729277606e-05, 'epoch': 0.39911776243343683, 'step': 2216000}
INFO:transformers.trainer:{'loss': 3.2170406683683397, 'learning_rate': 4.334653639866341e-05, 'epoch': 0.3992078160801953, 'step': 2216500}
INFO:transformers.trainer:{'loss': 3.200902055978775, 'learning_rate': 4.3345035504550776e-05, 'epoch': 0.39929786972695375, 'step': 2217000}
INFO:transformers.trainer:{'loss': 3.204905130505562, 'learning_rate': 4.334353461043813e-05, 'epoch': 0.3993879233737122, 'step': 2217500}
INFO:transformers.trainer:{'loss': 3.250083303451538, 'learning_rate': 4.3342033716325494e-05, 'epoch': 0.3994779770204706, 'step': 2218000}
INFO:transformers.trainer:{'loss': 3.259673636198044, 'learning_rate': 4.3340532822212846e-05, 'epoch': 0.39956803066722907, 'step': 2218500}
INFO:transformers.trainer:{'loss': 3.241862904071808, 'learning_rate': 4.333903192810021e-05, 'epoch': 0.3996580843139875, 'step': 2219000}
INFO:transformers.trainer:{'loss': 3.2363299078941345, 'learning_rate': 4.333753103398757e-05, 'epoch': 0.399748137960746, 'step': 2219500}
INFO:transformers.trainer:{'loss': 3.2335560829639434, 'learning_rate': 4.333603013987493e-05, 'epoch': 0.39983819160750445, 'step': 2220000}
INFO:transformers.trainer:{'loss': 3.2081015870571137, 'learning_rate': 4.333452924576229e-05, 'epoch': 0.39992824525426285, 'step': 2220500}
INFO:transformers.trainer:{'loss': 3.220189456939697, 'learning_rate': 4.333302835164965e-05, 'epoch': 0.4000182989010213, 'step': 2221000}
INFO:transformers.trainer:{'loss': 3.278313740849495, 'learning_rate': 4.333152745753701e-05, 'epoch': 0.40010835254777977, 'step': 2221500}
INFO:transformers.trainer:{'loss': 3.1782632001638413, 'learning_rate': 4.3330026563424366e-05, 'epoch': 0.4001984061945382, 'step': 2222000}
INFO:transformers.trainer:{'loss': 3.2453258697986604, 'learning_rate': 4.3328525669311725e-05, 'epoch': 0.4002884598412967, 'step': 2222500}
INFO:transformers.trainer:{'loss': 3.1938068883419035, 'learning_rate': 4.3327024775199084e-05, 'epoch': 0.4003785134880551, 'step': 2223000}
INFO:transformers.trainer:{'loss': 3.2473923406600953, 'learning_rate': 4.332552388108644e-05, 'epoch': 0.40046856713481355, 'step': 2223500}
INFO:transformers.trainer:{'loss': 3.1700390808582304, 'learning_rate': 4.33240229869738e-05, 'epoch': 0.400558620781572, 'step': 2224000}
INFO:transformers.trainer:{'loss': 3.2410516750812532, 'learning_rate': 4.332252209286116e-05, 'epoch': 0.40064867442833046, 'step': 2224500}
INFO:transformers.trainer:{'loss': 3.218124557733536, 'learning_rate': 4.332102119874852e-05, 'epoch': 0.40073872807508887, 'step': 2225000}
INFO:transformers.trainer:{'loss': 3.2685572454929352, 'learning_rate': 4.331952030463588e-05, 'epoch': 0.4008287817218473, 'step': 2225500}
INFO:transformers.trainer:{'loss': 3.2181150455474854, 'learning_rate': 4.331801941052324e-05, 'epoch': 0.4009188353686058, 'step': 2226000}
INFO:transformers.trainer:{'loss': 3.1916212828159334, 'learning_rate': 4.33165185164106e-05, 'epoch': 0.40100888901536424, 'step': 2226500}
INFO:transformers.trainer:{'loss': 3.261629456281662, 'learning_rate': 4.331501762229796e-05, 'epoch': 0.4010989426621227, 'step': 2227000}
INFO:transformers.trainer:{'loss': 3.2405999660491944, 'learning_rate': 4.3313516728185316e-05, 'epoch': 0.4011889963088811, 'step': 2227500}
INFO:transformers.trainer:{'loss': 3.1920336165428163, 'learning_rate': 4.3312015834072675e-05, 'epoch': 0.40127904995563957, 'step': 2228000}
INFO:transformers.trainer:{'loss': 3.253195370435715, 'learning_rate': 4.3310514939960034e-05, 'epoch': 0.401369103602398, 'step': 2228500}
INFO:transformers.trainer:{'loss': 3.2556193447113038, 'learning_rate': 4.330901404584739e-05, 'epoch': 0.4014591572491565, 'step': 2229000}
INFO:transformers.trainer:{'loss': 3.1792228109836578, 'learning_rate': 4.330751315173475e-05, 'epoch': 0.4015492108959149, 'step': 2229500}
INFO:transformers.trainer:{'loss': 3.2101202988624573, 'learning_rate': 4.330601225762211e-05, 'epoch': 0.40163926454267335, 'step': 2230000}
INFO:transformers.trainer:{'loss': 3.1912507727146147, 'learning_rate': 4.330451136350947e-05, 'epoch': 0.4017293181894318, 'step': 2230500}
INFO:transformers.trainer:{'loss': 3.2117020978927613, 'learning_rate': 4.330301046939683e-05, 'epoch': 0.40181937183619026, 'step': 2231000}
INFO:transformers.trainer:{'loss': 3.19092546916008, 'learning_rate': 4.330150957528419e-05, 'epoch': 0.4019094254829487, 'step': 2231500}
INFO:transformers.trainer:{'loss': 3.177246549844742, 'learning_rate': 4.330000868117155e-05, 'epoch': 0.4019994791297071, 'step': 2232000}
INFO:transformers.trainer:{'loss': 3.2534810370206833, 'learning_rate': 4.3298507787058906e-05, 'epoch': 0.4020895327764656, 'step': 2232500}
INFO:transformers.trainer:{'loss': 3.185887106895447, 'learning_rate': 4.3297006892946265e-05, 'epoch': 0.40217958642322404, 'step': 2233000}
INFO:transformers.trainer:{'loss': 3.246507720708847, 'learning_rate': 4.329550599883363e-05, 'epoch': 0.4022696400699825, 'step': 2233500}
INFO:transformers.trainer:{'loss': 3.2349229793548586, 'learning_rate': 4.329400510472098e-05, 'epoch': 0.40235969371674096, 'step': 2234000}
INFO:transformers.trainer:{'loss': 3.184878706932068, 'learning_rate': 4.329250421060835e-05, 'epoch': 0.40244974736349937, 'step': 2234500}
INFO:transformers.trainer:{'loss': 3.3173656673431395, 'learning_rate': 4.32910033164957e-05, 'epoch': 0.4025398010102578, 'step': 2235000}
INFO:transformers.trainer:{'loss': 3.1914183151721955, 'learning_rate': 4.328950242238307e-05, 'epoch': 0.4026298546570163, 'step': 2235500}
INFO:transformers.trainer:{'loss': 3.219613027572632, 'learning_rate': 4.328800152827042e-05, 'epoch': 0.40271990830377474, 'step': 2236000}
INFO:transformers.trainer:{'loss': 3.2360665054321287, 'learning_rate': 4.3286500634157785e-05, 'epoch': 0.40280996195053315, 'step': 2236500}
INFO:transformers.trainer:{'loss': 3.197166066646576, 'learning_rate': 4.328499974004514e-05, 'epoch': 0.4029000155972916, 'step': 2237000}
INFO:transformers.trainer:{'loss': 3.1527007709741595, 'learning_rate': 4.3283498845932503e-05, 'epoch': 0.40299006924405006, 'step': 2237500}
INFO:transformers.trainer:{'loss': 3.2634523210525512, 'learning_rate': 4.3281997951819856e-05, 'epoch': 0.4030801228908085, 'step': 2238000}
INFO:transformers.trainer:{'loss': 3.2361931414604186, 'learning_rate': 4.328049705770722e-05, 'epoch': 0.403170176537567, 'step': 2238500}
INFO:transformers.trainer:{'loss': 3.2686822168827057, 'learning_rate': 4.3278996163594574e-05, 'epoch': 0.4032602301843254, 'step': 2239000}
INFO:transformers.trainer:{'loss': 3.227704784631729, 'learning_rate': 4.327749526948194e-05, 'epoch': 0.40335028383108384, 'step': 2239500}
INFO:transformers.trainer:{'loss': 3.2276990060806274, 'learning_rate': 4.32759943753693e-05, 'epoch': 0.4034403374778423, 'step': 2240000}
INFO:transformers.trainer:{'loss': 3.215835716485977, 'learning_rate': 4.327449348125666e-05, 'epoch': 0.40353039112460076, 'step': 2240500}
INFO:transformers.trainer:{'loss': 3.244806706786156, 'learning_rate': 4.327299258714402e-05, 'epoch': 0.4036204447713592, 'step': 2241000}
INFO:transformers.trainer:{'loss': 3.2529855403900148, 'learning_rate': 4.3271491693031376e-05, 'epoch': 0.4037104984181176, 'step': 2241500}
INFO:transformers.trainer:{'loss': 3.1874821318387987, 'learning_rate': 4.3269990798918735e-05, 'epoch': 0.4038005520648761, 'step': 2242000}
INFO:transformers.trainer:{'loss': 3.2400849702358245, 'learning_rate': 4.3268489904806094e-05, 'epoch': 0.40389060571163454, 'step': 2242500}
INFO:transformers.trainer:{'loss': 3.231127577662468, 'learning_rate': 4.326698901069345e-05, 'epoch': 0.403980659358393, 'step': 2243000}
INFO:transformers.trainer:{'loss': 3.273632031440735, 'learning_rate': 4.326548811658081e-05, 'epoch': 0.4040707130051514, 'step': 2243500}
INFO:transformers.trainer:{'loss': 3.1953873586654664, 'learning_rate': 4.326398722246817e-05, 'epoch': 0.40416076665190986, 'step': 2244000}
INFO:transformers.trainer:{'loss': 3.267620672225952, 'learning_rate': 4.326248632835553e-05, 'epoch': 0.4042508202986683, 'step': 2244500}
INFO:transformers.trainer:{'loss': 3.24402459192276, 'learning_rate': 4.326098543424289e-05, 'epoch': 0.4043408739454268, 'step': 2245000}
INFO:transformers.trainer:{'loss': 3.228918733358383, 'learning_rate': 4.325948454013025e-05, 'epoch': 0.40443092759218524, 'step': 2245500}
INFO:transformers.trainer:{'loss': 3.19620388007164, 'learning_rate': 4.325798364601761e-05, 'epoch': 0.40452098123894364, 'step': 2246000}
INFO:transformers.trainer:{'loss': 3.2022969920635225, 'learning_rate': 4.3256482751904966e-05, 'epoch': 0.4046110348857021, 'step': 2246500}
INFO:transformers.trainer:{'loss': 3.176871682882309, 'learning_rate': 4.3254981857792325e-05, 'epoch': 0.40470108853246056, 'step': 2247000}
INFO:transformers.trainer:{'loss': 3.2244722011089326, 'learning_rate': 4.3253480963679684e-05, 'epoch': 0.404791142179219, 'step': 2247500}
INFO:transformers.trainer:{'loss': 3.274239504814148, 'learning_rate': 4.3251980069567044e-05, 'epoch': 0.4048811958259774, 'step': 2248000}
INFO:transformers.trainer:{'loss': 3.1935997629761697, 'learning_rate': 4.32504791754544e-05, 'epoch': 0.4049712494727359, 'step': 2248500}
INFO:transformers.trainer:{'loss': 3.2033483333587647, 'learning_rate': 4.324897828134176e-05, 'epoch': 0.40506130311949434, 'step': 2249000}
INFO:transformers.trainer:{'loss': 3.2493966386318207, 'learning_rate': 4.324747738722912e-05, 'epoch': 0.4051513567662528, 'step': 2249500}
INFO:transformers.trainer:{'loss': 3.204447752952576, 'learning_rate': 4.324597649311648e-05, 'epoch': 0.40524141041301126, 'step': 2250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2029875972270965, 'learning_rate': 4.324447559900384e-05, 'epoch': 0.40533146405976966, 'step': 2250500}
INFO:transformers.trainer:{'loss': 3.217156395435333, 'learning_rate': 4.32429747048912e-05, 'epoch': 0.4054215177065281, 'step': 2251000}
INFO:transformers.trainer:{'loss': 3.2350238871574404, 'learning_rate': 4.324147381077856e-05, 'epoch': 0.4055115713532866, 'step': 2251500}
INFO:transformers.trainer:{'loss': 3.2182224912643433, 'learning_rate': 4.3239972916665916e-05, 'epoch': 0.40560162500004504, 'step': 2252000}
INFO:transformers.trainer:{'loss': 3.20658933198452, 'learning_rate': 4.3238472022553275e-05, 'epoch': 0.4056916786468035, 'step': 2252500}
INFO:transformers.trainer:{'loss': 3.2640218632221223, 'learning_rate': 4.3236971128440634e-05, 'epoch': 0.4057817322935619, 'step': 2253000}
INFO:transformers.trainer:{'loss': 3.271456066608429, 'learning_rate': 4.323547023432799e-05, 'epoch': 0.40587178594032036, 'step': 2253500}
INFO:transformers.trainer:{'loss': 3.229083103179932, 'learning_rate': 4.323396934021536e-05, 'epoch': 0.4059618395870788, 'step': 2254000}
INFO:transformers.trainer:{'loss': 3.2027217179536818, 'learning_rate': 4.323246844610271e-05, 'epoch': 0.4060518932338373, 'step': 2254500}
INFO:transformers.trainer:{'loss': 3.2966458189487455, 'learning_rate': 4.323096755199008e-05, 'epoch': 0.4061419468805957, 'step': 2255000}
INFO:transformers.trainer:{'loss': 3.2536033339500428, 'learning_rate': 4.322946665787743e-05, 'epoch': 0.40623200052735414, 'step': 2255500}
INFO:transformers.trainer:{'loss': 3.2521275894641875, 'learning_rate': 4.3227965763764795e-05, 'epoch': 0.4063220541741126, 'step': 2256000}
INFO:transformers.trainer:{'loss': 3.24459752368927, 'learning_rate': 4.322646486965215e-05, 'epoch': 0.40641210782087106, 'step': 2256500}
INFO:transformers.trainer:{'loss': 3.1741639246940614, 'learning_rate': 4.322496397553951e-05, 'epoch': 0.4065021614676295, 'step': 2257000}
INFO:transformers.trainer:{'loss': 3.219873052597046, 'learning_rate': 4.3223463081426865e-05, 'epoch': 0.4065922151143879, 'step': 2257500}
INFO:transformers.trainer:{'loss': 3.2591325061321257, 'learning_rate': 4.322196218731423e-05, 'epoch': 0.4066822687611464, 'step': 2258000}
INFO:transformers.trainer:{'loss': 3.1205819675922393, 'learning_rate': 4.3220461293201584e-05, 'epoch': 0.40677232240790484, 'step': 2258500}
INFO:transformers.trainer:{'loss': 3.1972812798023225, 'learning_rate': 4.321896039908895e-05, 'epoch': 0.4068623760546633, 'step': 2259000}
INFO:transformers.trainer:{'loss': 3.2109436066150665, 'learning_rate': 4.32174595049763e-05, 'epoch': 0.40695242970142176, 'step': 2259500}
INFO:transformers.trainer:{'loss': 3.145654129385948, 'learning_rate': 4.321595861086367e-05, 'epoch': 0.40704248334818016, 'step': 2260000}
INFO:transformers.trainer:{'loss': 3.1980404177904127, 'learning_rate': 4.321445771675102e-05, 'epoch': 0.4071325369949386, 'step': 2260500}
INFO:transformers.trainer:{'loss': 3.2648256998062135, 'learning_rate': 4.3212956822638386e-05, 'epoch': 0.4072225906416971, 'step': 2261000}
INFO:transformers.trainer:{'loss': 3.219487962245941, 'learning_rate': 4.3211455928525745e-05, 'epoch': 0.40731264428845554, 'step': 2261500}
INFO:transformers.trainer:{'loss': 3.220061372756958, 'learning_rate': 4.3209955034413104e-05, 'epoch': 0.40740269793521394, 'step': 2262000}
INFO:transformers.trainer:{'loss': 3.273772641181946, 'learning_rate': 4.320845414030046e-05, 'epoch': 0.4074927515819724, 'step': 2262500}
INFO:transformers.trainer:{'loss': 3.270966933965683, 'learning_rate': 4.320695324618782e-05, 'epoch': 0.40758280522873086, 'step': 2263000}
INFO:transformers.trainer:{'loss': 3.1964511222839356, 'learning_rate': 4.320545235207518e-05, 'epoch': 0.4076728588754893, 'step': 2263500}
INFO:transformers.trainer:{'loss': 3.1793907244205473, 'learning_rate': 4.320395145796254e-05, 'epoch': 0.4077629125222478, 'step': 2264000}
INFO:transformers.trainer:{'loss': 3.205859380364418, 'learning_rate': 4.32024505638499e-05, 'epoch': 0.4078529661690062, 'step': 2264500}
INFO:transformers.trainer:{'loss': 3.187630737543106, 'learning_rate': 4.320094966973726e-05, 'epoch': 0.40794301981576464, 'step': 2265000}
INFO:transformers.trainer:{'loss': 3.216797288894653, 'learning_rate': 4.319944877562462e-05, 'epoch': 0.4080330734625231, 'step': 2265500}
INFO:transformers.trainer:{'loss': 3.222744012117386, 'learning_rate': 4.3197947881511976e-05, 'epoch': 0.40812312710928156, 'step': 2266000}
INFO:transformers.trainer:{'loss': 3.2005011289119722, 'learning_rate': 4.3196446987399335e-05, 'epoch': 0.40821318075603996, 'step': 2266500}
INFO:transformers.trainer:{'loss': 3.256833478927612, 'learning_rate': 4.3194946093286694e-05, 'epoch': 0.4083032344027984, 'step': 2267000}
INFO:transformers.trainer:{'loss': 3.2097787878513335, 'learning_rate': 4.319344519917405e-05, 'epoch': 0.4083932880495569, 'step': 2267500}
INFO:transformers.trainer:{'loss': 3.1850865032672884, 'learning_rate': 4.319194430506142e-05, 'epoch': 0.40848334169631534, 'step': 2268000}
INFO:transformers.trainer:{'loss': 3.2075702290534975, 'learning_rate': 4.319044341094877e-05, 'epoch': 0.4085733953430738, 'step': 2268500}
INFO:transformers.trainer:{'loss': 3.2816118440628053, 'learning_rate': 4.318894251683614e-05, 'epoch': 0.4086634489898322, 'step': 2269000}
INFO:transformers.trainer:{'loss': 3.221754979848862, 'learning_rate': 4.318744162272349e-05, 'epoch': 0.40875350263659066, 'step': 2269500}
INFO:transformers.trainer:{'loss': 3.2325719823837282, 'learning_rate': 4.3185940728610855e-05, 'epoch': 0.4088435562833491, 'step': 2270000}
INFO:transformers.trainer:{'loss': 3.29919908952713, 'learning_rate': 4.318443983449821e-05, 'epoch': 0.4089336099301076, 'step': 2270500}
INFO:transformers.trainer:{'loss': 3.268607897043228, 'learning_rate': 4.3182938940385567e-05, 'epoch': 0.40902366357686604, 'step': 2271000}
INFO:transformers.trainer:{'loss': 3.271035522699356, 'learning_rate': 4.3181438046272926e-05, 'epoch': 0.40911371722362444, 'step': 2271500}
INFO:transformers.trainer:{'loss': 3.2006383481025695, 'learning_rate': 4.3179937152160285e-05, 'epoch': 0.4092037708703829, 'step': 2272000}
INFO:transformers.trainer:{'loss': 3.241416534900665, 'learning_rate': 4.3178436258047644e-05, 'epoch': 0.40929382451714136, 'step': 2272500}
INFO:transformers.trainer:{'loss': 3.2263039734363557, 'learning_rate': 4.3176935363935e-05, 'epoch': 0.4093838781638998, 'step': 2273000}
INFO:transformers.trainer:{'loss': 3.224893652677536, 'learning_rate': 4.317543446982236e-05, 'epoch': 0.4094739318106582, 'step': 2273500}
INFO:transformers.trainer:{'loss': 3.1761223051548004, 'learning_rate': 4.317393357570972e-05, 'epoch': 0.4095639854574167, 'step': 2274000}
INFO:transformers.trainer:{'loss': 3.222042017996311, 'learning_rate': 4.317243268159708e-05, 'epoch': 0.40965403910417514, 'step': 2274500}
INFO:transformers.trainer:{'loss': 3.1737628682851793, 'learning_rate': 4.317093178748444e-05, 'epoch': 0.4097440927509336, 'step': 2275000}
INFO:transformers.trainer:{'loss': 3.2191861114501954, 'learning_rate': 4.3169430893371805e-05, 'epoch': 0.40983414639769206, 'step': 2275500}
INFO:transformers.trainer:{'loss': 3.236797344684601, 'learning_rate': 4.316792999925916e-05, 'epoch': 0.40992420004445046, 'step': 2276000}
INFO:transformers.trainer:{'loss': 3.1860703070163727, 'learning_rate': 4.316642910514652e-05, 'epoch': 0.4100142536912089, 'step': 2276500}
INFO:transformers.trainer:{'loss': 3.13169861805439, 'learning_rate': 4.3164928211033875e-05, 'epoch': 0.4101043073379674, 'step': 2277000}
INFO:transformers.trainer:{'loss': 3.2312188239097597, 'learning_rate': 4.316342731692124e-05, 'epoch': 0.41019436098472584, 'step': 2277500}
INFO:transformers.trainer:{'loss': 3.232179060459137, 'learning_rate': 4.316192642280859e-05, 'epoch': 0.4102844146314843, 'step': 2278000}
INFO:transformers.trainer:{'loss': 3.2509705325365066, 'learning_rate': 4.316042552869596e-05, 'epoch': 0.4103744682782427, 'step': 2278500}
INFO:transformers.trainer:{'loss': 3.2571628241539003, 'learning_rate': 4.315892463458331e-05, 'epoch': 0.41046452192500116, 'step': 2279000}
INFO:transformers.trainer:{'loss': 3.2327453639507295, 'learning_rate': 4.315742374047068e-05, 'epoch': 0.4105545755717596, 'step': 2279500}
INFO:transformers.trainer:{'loss': 3.2708152318000794, 'learning_rate': 4.315592284635803e-05, 'epoch': 0.4106446292185181, 'step': 2280000}
INFO:transformers.trainer:{'loss': 3.1757344572544097, 'learning_rate': 4.3154421952245395e-05, 'epoch': 0.4107346828652765, 'step': 2280500}
INFO:transformers.trainer:{'loss': 3.2593307237625124, 'learning_rate': 4.315292105813275e-05, 'epoch': 0.41082473651203494, 'step': 2281000}
INFO:transformers.trainer:{'loss': 3.2505390285253526, 'learning_rate': 4.3151420164020113e-05, 'epoch': 0.4109147901587934, 'step': 2281500}
INFO:transformers.trainer:{'loss': 3.1592813551425936, 'learning_rate': 4.314991926990747e-05, 'epoch': 0.41100484380555186, 'step': 2282000}
INFO:transformers.trainer:{'loss': 3.271607489824295, 'learning_rate': 4.314841837579483e-05, 'epoch': 0.4110948974523103, 'step': 2282500}
INFO:transformers.trainer:{'loss': 3.198071724891663, 'learning_rate': 4.314691748168219e-05, 'epoch': 0.4111849510990687, 'step': 2283000}
INFO:transformers.trainer:{'loss': 3.2344206845760346, 'learning_rate': 4.314541658756955e-05, 'epoch': 0.4112750047458272, 'step': 2283500}
INFO:transformers.trainer:{'loss': 3.2674811038970946, 'learning_rate': 4.314391569345691e-05, 'epoch': 0.41136505839258564, 'step': 2284000}
INFO:transformers.trainer:{'loss': 3.207544688940048, 'learning_rate': 4.314241479934427e-05, 'epoch': 0.4114551120393441, 'step': 2284500}
INFO:transformers.trainer:{'loss': 3.2460459517240525, 'learning_rate': 4.314091390523163e-05, 'epoch': 0.4115451656861025, 'step': 2285000}
INFO:transformers.trainer:{'loss': 3.1797641468048097, 'learning_rate': 4.3139413011118986e-05, 'epoch': 0.41163521933286096, 'step': 2285500}
INFO:transformers.trainer:{'loss': 3.190702452659607, 'learning_rate': 4.3137912117006345e-05, 'epoch': 0.4117252729796194, 'step': 2286000}
INFO:transformers.trainer:{'loss': 3.243331223487854, 'learning_rate': 4.3136411222893704e-05, 'epoch': 0.4118153266263779, 'step': 2286500}
INFO:transformers.trainer:{'loss': 3.1916226670742036, 'learning_rate': 4.313491032878106e-05, 'epoch': 0.41190538027313633, 'step': 2287000}
INFO:transformers.trainer:{'loss': 3.2590488921403886, 'learning_rate': 4.313340943466842e-05, 'epoch': 0.41199543391989474, 'step': 2287500}
INFO:transformers.trainer:{'loss': 3.236840478658676, 'learning_rate': 4.313190854055578e-05, 'epoch': 0.4120854875666532, 'step': 2288000}
INFO:transformers.trainer:{'loss': 3.2290716519355773, 'learning_rate': 4.313040764644315e-05, 'epoch': 0.41217554121341166, 'step': 2288500}
INFO:transformers.trainer:{'loss': 3.2708209762573244, 'learning_rate': 4.31289067523305e-05, 'epoch': 0.4122655948601701, 'step': 2289000}
INFO:transformers.trainer:{'loss': 3.2391164951324463, 'learning_rate': 4.3127405858217865e-05, 'epoch': 0.4123556485069286, 'step': 2289500}
INFO:transformers.trainer:{'loss': 3.190606157541275, 'learning_rate': 4.312590496410522e-05, 'epoch': 0.412445702153687, 'step': 2290000}
INFO:transformers.trainer:{'loss': 3.2492414004802703, 'learning_rate': 4.312440406999258e-05, 'epoch': 0.41253575580044544, 'step': 2290500}
INFO:transformers.trainer:{'loss': 3.2160342552661896, 'learning_rate': 4.3122903175879935e-05, 'epoch': 0.4126258094472039, 'step': 2291000}
INFO:transformers.trainer:{'loss': 3.2193917167186736, 'learning_rate': 4.31214022817673e-05, 'epoch': 0.41271586309396235, 'step': 2291500}
INFO:transformers.trainer:{'loss': 3.2634206436872484, 'learning_rate': 4.3119901387654653e-05, 'epoch': 0.41280591674072076, 'step': 2292000}
INFO:transformers.trainer:{'loss': 3.2178817727565767, 'learning_rate': 4.311840049354202e-05, 'epoch': 0.4128959703874792, 'step': 2292500}
INFO:transformers.trainer:{'loss': 3.1990197269916534, 'learning_rate': 4.311689959942937e-05, 'epoch': 0.4129860240342377, 'step': 2293000}
INFO:transformers.trainer:{'loss': 3.222541717529297, 'learning_rate': 4.311539870531674e-05, 'epoch': 0.41307607768099613, 'step': 2293500}
INFO:transformers.trainer:{'loss': 3.235315006017685, 'learning_rate': 4.311389781120409e-05, 'epoch': 0.4131661313277546, 'step': 2294000}
INFO:transformers.trainer:{'loss': 3.1907636294364927, 'learning_rate': 4.3112396917091455e-05, 'epoch': 0.413256184974513, 'step': 2294500}
INFO:transformers.trainer:{'loss': 3.208056519269943, 'learning_rate': 4.311089602297881e-05, 'epoch': 0.41334623862127146, 'step': 2295000}
INFO:transformers.trainer:{'loss': 3.2161849803924563, 'learning_rate': 4.310939512886617e-05, 'epoch': 0.4134362922680299, 'step': 2295500}
INFO:transformers.trainer:{'loss': 3.1858148362636567, 'learning_rate': 4.310789423475353e-05, 'epoch': 0.4135263459147884, 'step': 2296000}
INFO:transformers.trainer:{'loss': 3.179092296600342, 'learning_rate': 4.3106393340640885e-05, 'epoch': 0.4136163995615468, 'step': 2296500}
INFO:transformers.trainer:{'loss': 3.14726083612442, 'learning_rate': 4.310489244652825e-05, 'epoch': 0.41370645320830524, 'step': 2297000}
INFO:transformers.trainer:{'loss': 3.1809742114543913, 'learning_rate': 4.31033915524156e-05, 'epoch': 0.4137965068550637, 'step': 2297500}
INFO:transformers.trainer:{'loss': 3.20080926156044, 'learning_rate': 4.310189065830297e-05, 'epoch': 0.41388656050182215, 'step': 2298000}
INFO:transformers.trainer:{'loss': 3.2415270779132843, 'learning_rate': 4.310038976419032e-05, 'epoch': 0.4139766141485806, 'step': 2298500}
INFO:transformers.trainer:{'loss': 3.1974399375915525, 'learning_rate': 4.309888887007769e-05, 'epoch': 0.414066667795339, 'step': 2299000}
INFO:transformers.trainer:{'loss': 3.2257176673412324, 'learning_rate': 4.309738797596504e-05, 'epoch': 0.4141567214420975, 'step': 2299500}
INFO:transformers.trainer:{'loss': 3.233382106781006, 'learning_rate': 4.3095887081852405e-05, 'epoch': 0.41424677508885593, 'step': 2300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.204263944387436, 'learning_rate': 4.309438618773976e-05, 'epoch': 0.4143368287356144, 'step': 2300500}
INFO:transformers.trainer:{'loss': 3.2435311391353605, 'learning_rate': 4.309288529362712e-05, 'epoch': 0.41442688238237285, 'step': 2301000}
INFO:transformers.trainer:{'loss': 3.277882541894913, 'learning_rate': 4.3091384399514475e-05, 'epoch': 0.41451693602913126, 'step': 2301500}
INFO:transformers.trainer:{'loss': 3.174211442708969, 'learning_rate': 4.308988350540184e-05, 'epoch': 0.4146069896758897, 'step': 2302000}
INFO:transformers.trainer:{'loss': 3.23564497423172, 'learning_rate': 4.30883826112892e-05, 'epoch': 0.4146970433226482, 'step': 2302500}
INFO:transformers.trainer:{'loss': 3.1601703526973726, 'learning_rate': 4.308688171717656e-05, 'epoch': 0.41478709696940663, 'step': 2303000}
INFO:transformers.trainer:{'loss': 3.2507881109714507, 'learning_rate': 4.308538082306392e-05, 'epoch': 0.41487715061616504, 'step': 2303500}
INFO:transformers.trainer:{'loss': 3.2346216807365415, 'learning_rate': 4.308387992895128e-05, 'epoch': 0.4149672042629235, 'step': 2304000}
INFO:transformers.trainer:{'loss': 3.2755189201831816, 'learning_rate': 4.3082379034838636e-05, 'epoch': 0.41505725790968195, 'step': 2304500}
INFO:transformers.trainer:{'loss': 3.224154145717621, 'learning_rate': 4.3080878140725996e-05, 'epoch': 0.4151473115564404, 'step': 2305000}
INFO:transformers.trainer:{'loss': 3.2470142064094545, 'learning_rate': 4.3079377246613355e-05, 'epoch': 0.41523736520319887, 'step': 2305500}
INFO:transformers.trainer:{'loss': 3.225197104930878, 'learning_rate': 4.3077876352500714e-05, 'epoch': 0.4153274188499573, 'step': 2306000}
INFO:transformers.trainer:{'loss': 3.217086621284485, 'learning_rate': 4.307637545838807e-05, 'epoch': 0.41541747249671573, 'step': 2306500}
INFO:transformers.trainer:{'loss': 3.2576678478717804, 'learning_rate': 4.307487456427543e-05, 'epoch': 0.4155075261434742, 'step': 2307000}
INFO:transformers.trainer:{'loss': 3.1987656490802765, 'learning_rate': 4.307337367016279e-05, 'epoch': 0.41559757979023265, 'step': 2307500}
INFO:transformers.trainer:{'loss': 3.210433843612671, 'learning_rate': 4.307187277605015e-05, 'epoch': 0.4156876334369911, 'step': 2308000}
INFO:transformers.trainer:{'loss': 3.2457921793460844, 'learning_rate': 4.307037188193751e-05, 'epoch': 0.4157776870837495, 'step': 2308500}
INFO:transformers.trainer:{'loss': 3.2105806485414505, 'learning_rate': 4.306887098782487e-05, 'epoch': 0.415867740730508, 'step': 2309000}
INFO:transformers.trainer:{'loss': 3.1907189950942993, 'learning_rate': 4.306737009371223e-05, 'epoch': 0.41595779437726643, 'step': 2309500}
INFO:transformers.trainer:{'loss': 3.1625876194238662, 'learning_rate': 4.306586919959959e-05, 'epoch': 0.4160478480240249, 'step': 2310000}
INFO:transformers.trainer:{'loss': 3.2408184292316435, 'learning_rate': 4.3064368305486945e-05, 'epoch': 0.4161379016707833, 'step': 2310500}
INFO:transformers.trainer:{'loss': 3.2507327835559847, 'learning_rate': 4.306286741137431e-05, 'epoch': 0.41622795531754175, 'step': 2311000}
INFO:transformers.trainer:{'loss': 3.215962598800659, 'learning_rate': 4.306136651726166e-05, 'epoch': 0.4163180089643002, 'step': 2311500}
INFO:transformers.trainer:{'loss': 3.221058382511139, 'learning_rate': 4.305986562314903e-05, 'epoch': 0.41640806261105867, 'step': 2312000}
INFO:transformers.trainer:{'loss': 3.201262016415596, 'learning_rate': 4.305836472903638e-05, 'epoch': 0.41649811625781713, 'step': 2312500}
INFO:transformers.trainer:{'loss': 3.2579028506278993, 'learning_rate': 4.305686383492375e-05, 'epoch': 0.41658816990457553, 'step': 2313000}
INFO:transformers.trainer:{'loss': 3.248019164085388, 'learning_rate': 4.30553629408111e-05, 'epoch': 0.416678223551334, 'step': 2313500}
INFO:transformers.trainer:{'loss': 3.243370581150055, 'learning_rate': 4.3053862046698465e-05, 'epoch': 0.41676827719809245, 'step': 2314000}
INFO:transformers.trainer:{'loss': 3.1883080513477324, 'learning_rate': 4.305236115258582e-05, 'epoch': 0.4168583308448509, 'step': 2314500}
INFO:transformers.trainer:{'loss': 3.2189284498691557, 'learning_rate': 4.305086025847318e-05, 'epoch': 0.4169483844916093, 'step': 2315000}
INFO:transformers.trainer:{'loss': 3.2187129628658293, 'learning_rate': 4.3049359364360536e-05, 'epoch': 0.4170384381383678, 'step': 2315500}
INFO:transformers.trainer:{'loss': 3.2679852385520936, 'learning_rate': 4.30478584702479e-05, 'epoch': 0.41712849178512623, 'step': 2316000}
INFO:transformers.trainer:{'loss': 3.1911252351999284, 'learning_rate': 4.304635757613526e-05, 'epoch': 0.4172185454318847, 'step': 2316500}
INFO:transformers.trainer:{'loss': 3.2427796241044997, 'learning_rate': 4.304485668202262e-05, 'epoch': 0.41730859907864315, 'step': 2317000}
INFO:transformers.trainer:{'loss': 3.2057165278196336, 'learning_rate': 4.304335578790998e-05, 'epoch': 0.41739865272540155, 'step': 2317500}
INFO:transformers.trainer:{'loss': 3.171800653219223, 'learning_rate': 4.304185489379734e-05, 'epoch': 0.41748870637216, 'step': 2318000}
INFO:transformers.trainer:{'loss': 3.2348745210170744, 'learning_rate': 4.30403539996847e-05, 'epoch': 0.41757876001891847, 'step': 2318500}
INFO:transformers.trainer:{'loss': 3.1896999108791353, 'learning_rate': 4.303885310557205e-05, 'epoch': 0.41766881366567693, 'step': 2319000}
INFO:transformers.trainer:{'loss': 3.1813472216129304, 'learning_rate': 4.3037352211459415e-05, 'epoch': 0.4177588673124354, 'step': 2319500}
INFO:transformers.trainer:{'loss': 3.2635260388851166, 'learning_rate': 4.303585131734677e-05, 'epoch': 0.4178489209591938, 'step': 2320000}
INFO:transformers.trainer:{'loss': 3.2005902717113495, 'learning_rate': 4.303435042323413e-05, 'epoch': 0.41793897460595225, 'step': 2320500}
INFO:transformers.trainer:{'loss': 3.2435696792602537, 'learning_rate': 4.3032849529121485e-05, 'epoch': 0.4180290282527107, 'step': 2321000}
INFO:transformers.trainer:{'loss': 3.183227070569992, 'learning_rate': 4.303134863500885e-05, 'epoch': 0.41811908189946917, 'step': 2321500}
INFO:transformers.trainer:{'loss': 3.2405842185020446, 'learning_rate': 4.30298477408962e-05, 'epoch': 0.4182091355462276, 'step': 2322000}
INFO:transformers.trainer:{'loss': 3.196555315732956, 'learning_rate': 4.302834684678357e-05, 'epoch': 0.41829918919298603, 'step': 2322500}
INFO:transformers.trainer:{'loss': 3.1743453431129454, 'learning_rate': 4.302684595267092e-05, 'epoch': 0.4183892428397445, 'step': 2323000}
INFO:transformers.trainer:{'loss': 3.2146555973291395, 'learning_rate': 4.302534505855829e-05, 'epoch': 0.41847929648650295, 'step': 2323500}
INFO:transformers.trainer:{'loss': 3.181641738653183, 'learning_rate': 4.3023844164445646e-05, 'epoch': 0.4185693501332614, 'step': 2324000}
INFO:transformers.trainer:{'loss': 3.217902370929718, 'learning_rate': 4.3022343270333005e-05, 'epoch': 0.4186594037800198, 'step': 2324500}
INFO:transformers.trainer:{'loss': 3.255367083787918, 'learning_rate': 4.3020842376220364e-05, 'epoch': 0.41874945742677827, 'step': 2325000}
INFO:transformers.trainer:{'loss': 3.1541420837640763, 'learning_rate': 4.301934148210772e-05, 'epoch': 0.41883951107353673, 'step': 2325500}
INFO:transformers.trainer:{'loss': 3.2076401410102844, 'learning_rate': 4.301784058799508e-05, 'epoch': 0.4189295647202952, 'step': 2326000}
INFO:transformers.trainer:{'loss': 3.2501250302791593, 'learning_rate': 4.301633969388244e-05, 'epoch': 0.41901961836705365, 'step': 2326500}
INFO:transformers.trainer:{'loss': 3.250363413333893, 'learning_rate': 4.30148387997698e-05, 'epoch': 0.41910967201381205, 'step': 2327000}
INFO:transformers.trainer:{'loss': 3.171521147489548, 'learning_rate': 4.301333790565716e-05, 'epoch': 0.4191997256605705, 'step': 2327500}
INFO:transformers.trainer:{'loss': 3.1935021915435793, 'learning_rate': 4.301183701154452e-05, 'epoch': 0.41928977930732897, 'step': 2328000}
INFO:transformers.trainer:{'loss': 3.244122590780258, 'learning_rate': 4.301033611743188e-05, 'epoch': 0.41937983295408743, 'step': 2328500}
INFO:transformers.trainer:{'loss': 3.132562193036079, 'learning_rate': 4.300883522331924e-05, 'epoch': 0.41946988660084583, 'step': 2329000}
INFO:transformers.trainer:{'loss': 3.195233525633812, 'learning_rate': 4.3007334329206596e-05, 'epoch': 0.4195599402476043, 'step': 2329500}
INFO:transformers.trainer:{'loss': 3.232735140800476, 'learning_rate': 4.3005833435093955e-05, 'epoch': 0.41964999389436275, 'step': 2330000}
INFO:transformers.trainer:{'loss': 3.229117438316345, 'learning_rate': 4.300433254098132e-05, 'epoch': 0.4197400475411212, 'step': 2330500}
INFO:transformers.trainer:{'loss': 3.2046614695787428, 'learning_rate': 4.300283164686867e-05, 'epoch': 0.41983010118787967, 'step': 2331000}
INFO:transformers.trainer:{'loss': 3.228576630830765, 'learning_rate': 4.300133075275604e-05, 'epoch': 0.41992015483463807, 'step': 2331500}
INFO:transformers.trainer:{'loss': 3.189706261873245, 'learning_rate': 4.299982985864339e-05, 'epoch': 0.42001020848139653, 'step': 2332000}
INFO:transformers.trainer:{'loss': 3.1588856415748596, 'learning_rate': 4.299832896453076e-05, 'epoch': 0.420100262128155, 'step': 2332500}
INFO:transformers.trainer:{'loss': 3.240360577583313, 'learning_rate': 4.299682807041811e-05, 'epoch': 0.42019031577491345, 'step': 2333000}
INFO:transformers.trainer:{'loss': 3.207692909002304, 'learning_rate': 4.2995327176305475e-05, 'epoch': 0.42028036942167185, 'step': 2333500}
INFO:transformers.trainer:{'loss': 3.187584617614746, 'learning_rate': 4.299382628219283e-05, 'epoch': 0.4203704230684303, 'step': 2334000}
INFO:transformers.trainer:{'loss': 3.2214623577594756, 'learning_rate': 4.299232538808019e-05, 'epoch': 0.42046047671518877, 'step': 2334500}
INFO:transformers.trainer:{'loss': 3.158192818880081, 'learning_rate': 4.2990824493967545e-05, 'epoch': 0.42055053036194723, 'step': 2335000}
INFO:transformers.trainer:{'loss': 3.255108535051346, 'learning_rate': 4.298932359985491e-05, 'epoch': 0.4206405840087057, 'step': 2335500}
INFO:transformers.trainer:{'loss': 3.2038039860725402, 'learning_rate': 4.2987822705742263e-05, 'epoch': 0.4207306376554641, 'step': 2336000}
INFO:transformers.trainer:{'loss': 3.220218286514282, 'learning_rate': 4.298632181162963e-05, 'epoch': 0.42082069130222255, 'step': 2336500}
INFO:transformers.trainer:{'loss': 3.1864185041189192, 'learning_rate': 4.298482091751699e-05, 'epoch': 0.420910744948981, 'step': 2337000}
INFO:transformers.trainer:{'loss': 3.222002233505249, 'learning_rate': 4.298332002340435e-05, 'epoch': 0.42100079859573947, 'step': 2337500}
INFO:transformers.trainer:{'loss': 3.1184371925592425, 'learning_rate': 4.2981819129291706e-05, 'epoch': 0.4210908522424979, 'step': 2338000}
INFO:transformers.trainer:{'loss': 3.2734459409713743, 'learning_rate': 4.2980318235179065e-05, 'epoch': 0.42118090588925633, 'step': 2338500}
INFO:transformers.trainer:{'loss': 3.196298271894455, 'learning_rate': 4.2978817341066425e-05, 'epoch': 0.4212709595360148, 'step': 2339000}
INFO:transformers.trainer:{'loss': 3.2253582344055176, 'learning_rate': 4.2977316446953784e-05, 'epoch': 0.42136101318277325, 'step': 2339500}
INFO:transformers.trainer:{'loss': 3.2475564744472503, 'learning_rate': 4.297581555284114e-05, 'epoch': 0.4214510668295317, 'step': 2340000}
INFO:transformers.trainer:{'loss': 3.22810083091259, 'learning_rate': 4.29743146587285e-05, 'epoch': 0.4215411204762901, 'step': 2340500}
INFO:transformers.trainer:{'loss': 3.137900940656662, 'learning_rate': 4.297281376461586e-05, 'epoch': 0.42163117412304857, 'step': 2341000}
INFO:transformers.trainer:{'loss': 3.1353781490325927, 'learning_rate': 4.297131287050322e-05, 'epoch': 0.421721227769807, 'step': 2341500}
INFO:transformers.trainer:{'loss': 3.1880247547626497, 'learning_rate': 4.296981197639058e-05, 'epoch': 0.4218112814165655, 'step': 2342000}
INFO:transformers.trainer:{'loss': 3.3123132407665254, 'learning_rate': 4.296831108227793e-05, 'epoch': 0.42190133506332395, 'step': 2342500}
INFO:transformers.trainer:{'loss': 3.1917965347766875, 'learning_rate': 4.29668101881653e-05, 'epoch': 0.42199138871008235, 'step': 2343000}
INFO:transformers.trainer:{'loss': 3.211318187952042, 'learning_rate': 4.296530929405265e-05, 'epoch': 0.4220814423568408, 'step': 2343500}
INFO:transformers.trainer:{'loss': 3.2665368916988373, 'learning_rate': 4.2963808399940015e-05, 'epoch': 0.42217149600359927, 'step': 2344000}
INFO:transformers.trainer:{'loss': 3.1984148243665693, 'learning_rate': 4.2962307505827374e-05, 'epoch': 0.4222615496503577, 'step': 2344500}
INFO:transformers.trainer:{'loss': 3.184630763053894, 'learning_rate': 4.296080661171473e-05, 'epoch': 0.4223516032971162, 'step': 2345000}
INFO:transformers.trainer:{'loss': 3.2605142934322355, 'learning_rate': 4.295930571760209e-05, 'epoch': 0.4224416569438746, 'step': 2345500}
INFO:transformers.trainer:{'loss': 3.229275983333588, 'learning_rate': 4.295780482348945e-05, 'epoch': 0.42253171059063305, 'step': 2346000}
INFO:transformers.trainer:{'loss': 3.15735510802269, 'learning_rate': 4.295630392937681e-05, 'epoch': 0.4226217642373915, 'step': 2346500}
INFO:transformers.trainer:{'loss': 3.1865100791454317, 'learning_rate': 4.295480303526417e-05, 'epoch': 0.42271181788414997, 'step': 2347000}
INFO:transformers.trainer:{'loss': 3.219207843899727, 'learning_rate': 4.295330214115153e-05, 'epoch': 0.42280187153090837, 'step': 2347500}
INFO:transformers.trainer:{'loss': 3.2783307332992555, 'learning_rate': 4.295180124703889e-05, 'epoch': 0.4228919251776668, 'step': 2348000}
INFO:transformers.trainer:{'loss': 3.202215348958969, 'learning_rate': 4.2950300352926246e-05, 'epoch': 0.4229819788244253, 'step': 2348500}
INFO:transformers.trainer:{'loss': 3.19627863907814, 'learning_rate': 4.2948799458813606e-05, 'epoch': 0.42307203247118375, 'step': 2349000}
INFO:transformers.trainer:{'loss': 3.226105856180191, 'learning_rate': 4.2947298564700965e-05, 'epoch': 0.4231620861179422, 'step': 2349500}
INFO:transformers.trainer:{'loss': 3.184519952058792, 'learning_rate': 4.2945797670588324e-05, 'epoch': 0.4232521397647006, 'step': 2350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2321738015413284, 'learning_rate': 4.294429677647568e-05, 'epoch': 0.42334219341145907, 'step': 2350500}
INFO:transformers.trainer:{'loss': 3.1835001616477965, 'learning_rate': 4.294279588236305e-05, 'epoch': 0.4234322470582175, 'step': 2351000}
INFO:transformers.trainer:{'loss': 3.1770843148231505, 'learning_rate': 4.29412949882504e-05, 'epoch': 0.423522300704976, 'step': 2351500}
INFO:transformers.trainer:{'loss': 3.200806320309639, 'learning_rate': 4.2939794094137767e-05, 'epoch': 0.4236123543517344, 'step': 2352000}
INFO:transformers.trainer:{'loss': 3.1777068240642548, 'learning_rate': 4.293829320002512e-05, 'epoch': 0.42370240799849285, 'step': 2352500}
INFO:transformers.trainer:{'loss': 3.2333162187337874, 'learning_rate': 4.2936792305912485e-05, 'epoch': 0.4237924616452513, 'step': 2353000}
INFO:transformers.trainer:{'loss': 3.131115256071091, 'learning_rate': 4.293529141179984e-05, 'epoch': 0.42388251529200976, 'step': 2353500}
INFO:transformers.trainer:{'loss': 3.223810563087463, 'learning_rate': 4.29337905176872e-05, 'epoch': 0.4239725689387682, 'step': 2354000}
INFO:transformers.trainer:{'loss': 3.223302484989166, 'learning_rate': 4.2932289623574555e-05, 'epoch': 0.4240626225855266, 'step': 2354500}
INFO:transformers.trainer:{'loss': 3.198128028869629, 'learning_rate': 4.293078872946192e-05, 'epoch': 0.4241526762322851, 'step': 2355000}
INFO:transformers.trainer:{'loss': 3.210201518535614, 'learning_rate': 4.292928783534927e-05, 'epoch': 0.42424272987904355, 'step': 2355500}
INFO:transformers.trainer:{'loss': 3.1798859087228775, 'learning_rate': 4.292778694123664e-05, 'epoch': 0.424332783525802, 'step': 2356000}
INFO:transformers.trainer:{'loss': 3.1908387598991395, 'learning_rate': 4.292628604712399e-05, 'epoch': 0.42442283717256046, 'step': 2356500}
INFO:transformers.trainer:{'loss': 3.248756725549698, 'learning_rate': 4.292478515301136e-05, 'epoch': 0.42451289081931887, 'step': 2357000}
INFO:transformers.trainer:{'loss': 3.2500184442996978, 'learning_rate': 4.292328425889871e-05, 'epoch': 0.4246029444660773, 'step': 2357500}
INFO:transformers.trainer:{'loss': 3.2616983139514923, 'learning_rate': 4.2921783364786075e-05, 'epoch': 0.4246929981128358, 'step': 2358000}
INFO:transformers.trainer:{'loss': 3.226266247034073, 'learning_rate': 4.2920282470673434e-05, 'epoch': 0.42478305175959424, 'step': 2358500}
INFO:transformers.trainer:{'loss': 3.205358707666397, 'learning_rate': 4.291878157656079e-05, 'epoch': 0.42487310540635265, 'step': 2359000}
INFO:transformers.trainer:{'loss': 3.181472528219223, 'learning_rate': 4.291728068244815e-05, 'epoch': 0.4249631590531111, 'step': 2359500}
INFO:transformers.trainer:{'loss': 3.2032396020889284, 'learning_rate': 4.291577978833551e-05, 'epoch': 0.42505321269986956, 'step': 2360000}
INFO:transformers.trainer:{'loss': 3.252746954202652, 'learning_rate': 4.291427889422287e-05, 'epoch': 0.425143266346628, 'step': 2360500}
INFO:transformers.trainer:{'loss': 3.263932055950165, 'learning_rate': 4.291277800011023e-05, 'epoch': 0.4252333199933865, 'step': 2361000}
INFO:transformers.trainer:{'loss': 3.2482220256328582, 'learning_rate': 4.291127710599759e-05, 'epoch': 0.4253233736401449, 'step': 2361500}
INFO:transformers.trainer:{'loss': 3.1807139666080473, 'learning_rate': 4.290977621188495e-05, 'epoch': 0.42541342728690335, 'step': 2362000}
INFO:transformers.trainer:{'loss': 3.210218726634979, 'learning_rate': 4.290827531777231e-05, 'epoch': 0.4255034809336618, 'step': 2362500}
INFO:transformers.trainer:{'loss': 3.271316018819809, 'learning_rate': 4.2906774423659666e-05, 'epoch': 0.42559353458042026, 'step': 2363000}
INFO:transformers.trainer:{'loss': 3.1804780588150026, 'learning_rate': 4.2905273529547025e-05, 'epoch': 0.4256835882271787, 'step': 2363500}
INFO:transformers.trainer:{'loss': 3.1930658679008483, 'learning_rate': 4.2903772635434384e-05, 'epoch': 0.4257736418739371, 'step': 2364000}
INFO:transformers.trainer:{'loss': 3.2039743077754976, 'learning_rate': 4.290227174132174e-05, 'epoch': 0.4258636955206956, 'step': 2364500}
INFO:transformers.trainer:{'loss': 3.2161422505378723, 'learning_rate': 4.29007708472091e-05, 'epoch': 0.42595374916745404, 'step': 2365000}
INFO:transformers.trainer:{'loss': 3.2490200552940367, 'learning_rate': 4.289926995309646e-05, 'epoch': 0.4260438028142125, 'step': 2365500}
INFO:transformers.trainer:{'loss': 3.214772870540619, 'learning_rate': 4.289776905898382e-05, 'epoch': 0.4261338564609709, 'step': 2366000}
INFO:transformers.trainer:{'loss': 3.2230974212884904, 'learning_rate': 4.289626816487118e-05, 'epoch': 0.42622391010772936, 'step': 2366500}
INFO:transformers.trainer:{'loss': 3.176438247203827, 'learning_rate': 4.289476727075854e-05, 'epoch': 0.4263139637544878, 'step': 2367000}
INFO:transformers.trainer:{'loss': 3.158019272327423, 'learning_rate': 4.28932663766459e-05, 'epoch': 0.4264040174012463, 'step': 2367500}
INFO:transformers.trainer:{'loss': 3.1115729012489317, 'learning_rate': 4.2891765482533256e-05, 'epoch': 0.42649407104800474, 'step': 2368000}
INFO:transformers.trainer:{'loss': 3.2439082496166227, 'learning_rate': 4.2890264588420615e-05, 'epoch': 0.42658412469476314, 'step': 2368500}
INFO:transformers.trainer:{'loss': 3.1930309948921205, 'learning_rate': 4.2888763694307974e-05, 'epoch': 0.4266741783415216, 'step': 2369000}
INFO:transformers.trainer:{'loss': 3.2253445439338684, 'learning_rate': 4.288726280019533e-05, 'epoch': 0.42676423198828006, 'step': 2369500}
INFO:transformers.trainer:{'loss': 3.200626303076744, 'learning_rate': 4.288576190608269e-05, 'epoch': 0.4268542856350385, 'step': 2370000}
INFO:transformers.trainer:{'loss': 3.214228125691414, 'learning_rate': 4.288426101197005e-05, 'epoch': 0.4269443392817969, 'step': 2370500}
INFO:transformers.trainer:{'loss': 3.2157305450439453, 'learning_rate': 4.288276011785741e-05, 'epoch': 0.4270343929285554, 'step': 2371000}
INFO:transformers.trainer:{'loss': 3.2359856312274933, 'learning_rate': 4.288125922374477e-05, 'epoch': 0.42712444657531384, 'step': 2371500}
INFO:transformers.trainer:{'loss': 3.1888509393930433, 'learning_rate': 4.287975832963213e-05, 'epoch': 0.4272145002220723, 'step': 2372000}
INFO:transformers.trainer:{'loss': 3.189732045888901, 'learning_rate': 4.2878257435519494e-05, 'epoch': 0.42730455386883076, 'step': 2372500}
INFO:transformers.trainer:{'loss': 3.259504897356033, 'learning_rate': 4.287675654140685e-05, 'epoch': 0.42739460751558916, 'step': 2373000}
INFO:transformers.trainer:{'loss': 3.1376679968833923, 'learning_rate': 4.287525564729421e-05, 'epoch': 0.4274846611623476, 'step': 2373500}
INFO:transformers.trainer:{'loss': 3.2173048059940337, 'learning_rate': 4.2873754753181565e-05, 'epoch': 0.4275747148091061, 'step': 2374000}
INFO:transformers.trainer:{'loss': 3.2642993803024294, 'learning_rate': 4.287225385906893e-05, 'epoch': 0.42766476845586454, 'step': 2374500}
INFO:transformers.trainer:{'loss': 3.19319362950325, 'learning_rate': 4.287075296495628e-05, 'epoch': 0.427754822102623, 'step': 2375000}
INFO:transformers.trainer:{'loss': 3.208499137401581, 'learning_rate': 4.286925207084365e-05, 'epoch': 0.4278448757493814, 'step': 2375500}
INFO:transformers.trainer:{'loss': 3.2105670623779297, 'learning_rate': 4.2867751176731e-05, 'epoch': 0.42793492939613986, 'step': 2376000}
INFO:transformers.trainer:{'loss': 3.211962586522102, 'learning_rate': 4.286625028261837e-05, 'epoch': 0.4280249830428983, 'step': 2376500}
INFO:transformers.trainer:{'loss': 3.2733671205043793, 'learning_rate': 4.286474938850572e-05, 'epoch': 0.4281150366896568, 'step': 2377000}
INFO:transformers.trainer:{'loss': 3.2527851724624632, 'learning_rate': 4.2863248494393085e-05, 'epoch': 0.4282050903364152, 'step': 2377500}
INFO:transformers.trainer:{'loss': 3.238607486486435, 'learning_rate': 4.286174760028044e-05, 'epoch': 0.42829514398317364, 'step': 2378000}
INFO:transformers.trainer:{'loss': 3.2359187042713167, 'learning_rate': 4.28602467061678e-05, 'epoch': 0.4283851976299321, 'step': 2378500}
INFO:transformers.trainer:{'loss': 3.252724948167801, 'learning_rate': 4.285874581205516e-05, 'epoch': 0.42847525127669056, 'step': 2379000}
INFO:transformers.trainer:{'loss': 3.1823422117233275, 'learning_rate': 4.285724491794252e-05, 'epoch': 0.428565304923449, 'step': 2379500}
INFO:transformers.trainer:{'loss': 3.192180485963821, 'learning_rate': 4.285574402382988e-05, 'epoch': 0.4286553585702074, 'step': 2380000}
INFO:transformers.trainer:{'loss': 3.224482530474663, 'learning_rate': 4.285424312971724e-05, 'epoch': 0.4287454122169659, 'step': 2380500}
INFO:transformers.trainer:{'loss': 3.2189865720272066, 'learning_rate': 4.28527422356046e-05, 'epoch': 0.42883546586372434, 'step': 2381000}
INFO:transformers.trainer:{'loss': 3.190300451040268, 'learning_rate': 4.285124134149196e-05, 'epoch': 0.4289255195104828, 'step': 2381500}
INFO:transformers.trainer:{'loss': 3.2356582968235017, 'learning_rate': 4.2849740447379316e-05, 'epoch': 0.42901557315724126, 'step': 2382000}
INFO:transformers.trainer:{'loss': 3.2252972016334533, 'learning_rate': 4.2848239553266675e-05, 'epoch': 0.42910562680399966, 'step': 2382500}
INFO:transformers.trainer:{'loss': 3.2174777143001556, 'learning_rate': 4.2846738659154034e-05, 'epoch': 0.4291956804507581, 'step': 2383000}
INFO:transformers.trainer:{'loss': 3.2601823880672454, 'learning_rate': 4.2845237765041394e-05, 'epoch': 0.4292857340975166, 'step': 2383500}
INFO:transformers.trainer:{'loss': 3.1700703246593473, 'learning_rate': 4.284373687092875e-05, 'epoch': 0.42937578774427504, 'step': 2384000}
INFO:transformers.trainer:{'loss': 3.246473807811737, 'learning_rate': 4.284223597681611e-05, 'epoch': 0.42946584139103344, 'step': 2384500}
INFO:transformers.trainer:{'loss': 3.273029000759125, 'learning_rate': 4.284073508270347e-05, 'epoch': 0.4295558950377919, 'step': 2385000}
INFO:transformers.trainer:{'loss': 3.2332191045284273, 'learning_rate': 4.283923418859083e-05, 'epoch': 0.42964594868455036, 'step': 2385500}
INFO:transformers.trainer:{'loss': 3.1756324911117555, 'learning_rate': 4.283773329447819e-05, 'epoch': 0.4297360023313088, 'step': 2386000}
INFO:transformers.trainer:{'loss': 3.200717677116394, 'learning_rate': 4.283623240036555e-05, 'epoch': 0.4298260559780673, 'step': 2386500}
INFO:transformers.trainer:{'loss': 3.2422961645126342, 'learning_rate': 4.283473150625291e-05, 'epoch': 0.4299161096248257, 'step': 2387000}
INFO:transformers.trainer:{'loss': 3.1897467517852784, 'learning_rate': 4.2833230612140266e-05, 'epoch': 0.43000616327158414, 'step': 2387500}
INFO:transformers.trainer:{'loss': 3.2590991600751877, 'learning_rate': 4.2831729718027625e-05, 'epoch': 0.4300962169183426, 'step': 2388000}
INFO:transformers.trainer:{'loss': 3.2460795526504516, 'learning_rate': 4.2830228823914984e-05, 'epoch': 0.43018627056510106, 'step': 2388500}
INFO:transformers.trainer:{'loss': 3.2185926830768583, 'learning_rate': 4.282872792980234e-05, 'epoch': 0.43027632421185946, 'step': 2389000}
INFO:transformers.trainer:{'loss': 3.1873473348617556, 'learning_rate': 4.28272270356897e-05, 'epoch': 0.4303663778586179, 'step': 2389500}
INFO:transformers.trainer:{'loss': 3.2219171822071075, 'learning_rate': 4.282572614157706e-05, 'epoch': 0.4304564315053764, 'step': 2390000}
INFO:transformers.trainer:{'loss': 3.265879531621933, 'learning_rate': 4.282422524746442e-05, 'epoch': 0.43054648515213484, 'step': 2390500}
INFO:transformers.trainer:{'loss': 3.2201601996421814, 'learning_rate': 4.282272435335178e-05, 'epoch': 0.4306365387988933, 'step': 2391000}
INFO:transformers.trainer:{'loss': 3.185348419904709, 'learning_rate': 4.282122345923914e-05, 'epoch': 0.4307265924456517, 'step': 2391500}
INFO:transformers.trainer:{'loss': 3.191447305083275, 'learning_rate': 4.28197225651265e-05, 'epoch': 0.43081664609241016, 'step': 2392000}
INFO:transformers.trainer:{'loss': 3.2191189908981324, 'learning_rate': 4.2818221671013856e-05, 'epoch': 0.4309066997391686, 'step': 2392500}
INFO:transformers.trainer:{'loss': 3.1967759490013123, 'learning_rate': 4.281672077690122e-05, 'epoch': 0.4309967533859271, 'step': 2393000}
INFO:transformers.trainer:{'loss': 3.1826697583198547, 'learning_rate': 4.2815219882788575e-05, 'epoch': 0.43108680703268554, 'step': 2393500}
INFO:transformers.trainer:{'loss': 3.191916093587875, 'learning_rate': 4.281371898867594e-05, 'epoch': 0.43117686067944394, 'step': 2394000}
INFO:transformers.trainer:{'loss': 3.1561774172782897, 'learning_rate': 4.281221809456329e-05, 'epoch': 0.4312669143262024, 'step': 2394500}
INFO:transformers.trainer:{'loss': 3.185868988275528, 'learning_rate': 4.281071720045066e-05, 'epoch': 0.43135696797296086, 'step': 2395000}
INFO:transformers.trainer:{'loss': 3.2104251022338866, 'learning_rate': 4.280921630633801e-05, 'epoch': 0.4314470216197193, 'step': 2395500}
INFO:transformers.trainer:{'loss': 3.2066432061195376, 'learning_rate': 4.2807715412225377e-05, 'epoch': 0.4315370752664777, 'step': 2396000}
INFO:transformers.trainer:{'loss': 3.250113685131073, 'learning_rate': 4.280621451811273e-05, 'epoch': 0.4316271289132362, 'step': 2396500}
INFO:transformers.trainer:{'loss': 3.2137861508131027, 'learning_rate': 4.2804713624000095e-05, 'epoch': 0.43171718255999464, 'step': 2397000}
INFO:transformers.trainer:{'loss': 3.1669594864845276, 'learning_rate': 4.280321272988745e-05, 'epoch': 0.4318072362067531, 'step': 2397500}
INFO:transformers.trainer:{'loss': 3.210188782453537, 'learning_rate': 4.280171183577481e-05, 'epoch': 0.43189728985351156, 'step': 2398000}
INFO:transformers.trainer:{'loss': 3.270417102575302, 'learning_rate': 4.2800210941662165e-05, 'epoch': 0.43198734350026996, 'step': 2398500}
INFO:transformers.trainer:{'loss': 3.2398712327480315, 'learning_rate': 4.279871004754953e-05, 'epoch': 0.4320773971470284, 'step': 2399000}
INFO:transformers.trainer:{'loss': 3.2315187125205993, 'learning_rate': 4.279720915343689e-05, 'epoch': 0.4321674507937869, 'step': 2399500}
INFO:transformers.trainer:{'loss': 3.1373827803134917, 'learning_rate': 4.279570825932425e-05, 'epoch': 0.43225750444054534, 'step': 2400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.240086155653, 'learning_rate': 4.279420736521161e-05, 'epoch': 0.4323475580873038, 'step': 2400500}
INFO:transformers.trainer:{'loss': 3.221714111804962, 'learning_rate': 4.279270647109897e-05, 'epoch': 0.4324376117340622, 'step': 2401000}
INFO:transformers.trainer:{'loss': 3.18017631149292, 'learning_rate': 4.2791205576986326e-05, 'epoch': 0.43252766538082066, 'step': 2401500}
INFO:transformers.trainer:{'loss': 3.2702016117572783, 'learning_rate': 4.2789704682873685e-05, 'epoch': 0.4326177190275791, 'step': 2402000}
INFO:transformers.trainer:{'loss': 3.229150359392166, 'learning_rate': 4.2788203788761044e-05, 'epoch': 0.4327077726743376, 'step': 2402500}
INFO:transformers.trainer:{'loss': 3.1559599088430406, 'learning_rate': 4.27867028946484e-05, 'epoch': 0.432797826321096, 'step': 2403000}
INFO:transformers.trainer:{'loss': 3.2201275177001953, 'learning_rate': 4.278520200053576e-05, 'epoch': 0.43288787996785444, 'step': 2403500}
INFO:transformers.trainer:{'loss': 3.2207936667203905, 'learning_rate': 4.278370110642312e-05, 'epoch': 0.4329779336146129, 'step': 2404000}
INFO:transformers.trainer:{'loss': 3.236269139766693, 'learning_rate': 4.278220021231048e-05, 'epoch': 0.43306798726137136, 'step': 2404500}
INFO:transformers.trainer:{'loss': 3.192154361963272, 'learning_rate': 4.278069931819784e-05, 'epoch': 0.4331580409081298, 'step': 2405000}
INFO:transformers.trainer:{'loss': 3.2202468800544737, 'learning_rate': 4.27791984240852e-05, 'epoch': 0.4332480945548882, 'step': 2405500}
INFO:transformers.trainer:{'loss': 3.2554138927459717, 'learning_rate': 4.277769752997256e-05, 'epoch': 0.4333381482016467, 'step': 2406000}
INFO:transformers.trainer:{'loss': 3.19017587685585, 'learning_rate': 4.2776196635859917e-05, 'epoch': 0.43342820184840514, 'step': 2406500}
INFO:transformers.trainer:{'loss': 3.2200083022117614, 'learning_rate': 4.2774695741747276e-05, 'epoch': 0.4335182554951636, 'step': 2407000}
INFO:transformers.trainer:{'loss': 3.185857492685318, 'learning_rate': 4.2773194847634635e-05, 'epoch': 0.433608309141922, 'step': 2407500}
INFO:transformers.trainer:{'loss': 3.200611666202545, 'learning_rate': 4.2771693953521994e-05, 'epoch': 0.43369836278868046, 'step': 2408000}
INFO:transformers.trainer:{'loss': 3.266182192325592, 'learning_rate': 4.277019305940935e-05, 'epoch': 0.4337884164354389, 'step': 2408500}
INFO:transformers.trainer:{'loss': 3.1993150300979614, 'learning_rate': 4.276869216529671e-05, 'epoch': 0.4338784700821974, 'step': 2409000}
INFO:transformers.trainer:{'loss': 3.166514220714569, 'learning_rate': 4.276719127118407e-05, 'epoch': 0.43396852372895584, 'step': 2409500}
INFO:transformers.trainer:{'loss': 3.2289900834560394, 'learning_rate': 4.276569037707143e-05, 'epoch': 0.43405857737571424, 'step': 2410000}
INFO:transformers.trainer:{'loss': 3.2404323348999022, 'learning_rate': 4.276418948295879e-05, 'epoch': 0.4341486310224727, 'step': 2410500}
INFO:transformers.trainer:{'loss': 3.187455876111984, 'learning_rate': 4.276268858884615e-05, 'epoch': 0.43423868466923116, 'step': 2411000}
INFO:transformers.trainer:{'loss': 3.1441003739833833, 'learning_rate': 4.276118769473351e-05, 'epoch': 0.4343287383159896, 'step': 2411500}
INFO:transformers.trainer:{'loss': 3.2307811748981474, 'learning_rate': 4.2759686800620866e-05, 'epoch': 0.4344187919627481, 'step': 2412000}
INFO:transformers.trainer:{'loss': 3.2519214136600496, 'learning_rate': 4.2758185906508225e-05, 'epoch': 0.4345088456095065, 'step': 2412500}
INFO:transformers.trainer:{'loss': 3.2436396626234054, 'learning_rate': 4.2756685012395584e-05, 'epoch': 0.43459889925626494, 'step': 2413000}
INFO:transformers.trainer:{'loss': 3.1900045897960663, 'learning_rate': 4.275518411828295e-05, 'epoch': 0.4346889529030234, 'step': 2413500}
INFO:transformers.trainer:{'loss': 3.1456342681646348, 'learning_rate': 4.27536832241703e-05, 'epoch': 0.43477900654978185, 'step': 2414000}
INFO:transformers.trainer:{'loss': 3.1603743953704835, 'learning_rate': 4.275218233005767e-05, 'epoch': 0.43486906019654026, 'step': 2414500}
INFO:transformers.trainer:{'loss': 3.214449551820755, 'learning_rate': 4.275068143594502e-05, 'epoch': 0.4349591138432987, 'step': 2415000}
INFO:transformers.trainer:{'loss': 3.222064607620239, 'learning_rate': 4.2749180541832386e-05, 'epoch': 0.4350491674900572, 'step': 2415500}
INFO:transformers.trainer:{'loss': 3.1542074501514437, 'learning_rate': 4.274767964771974e-05, 'epoch': 0.43513922113681563, 'step': 2416000}
INFO:transformers.trainer:{'loss': 3.181725495815277, 'learning_rate': 4.2746178753607104e-05, 'epoch': 0.4352292747835741, 'step': 2416500}
INFO:transformers.trainer:{'loss': 3.205509835958481, 'learning_rate': 4.274467785949446e-05, 'epoch': 0.4353193284303325, 'step': 2417000}
INFO:transformers.trainer:{'loss': 3.2336788766384124, 'learning_rate': 4.274317696538182e-05, 'epoch': 0.43540938207709096, 'step': 2417500}
INFO:transformers.trainer:{'loss': 3.242757204771042, 'learning_rate': 4.2741676071269175e-05, 'epoch': 0.4354994357238494, 'step': 2418000}
INFO:transformers.trainer:{'loss': 3.2138986144065855, 'learning_rate': 4.274017517715654e-05, 'epoch': 0.4355894893706079, 'step': 2418500}
INFO:transformers.trainer:{'loss': 3.246679655075073, 'learning_rate': 4.273867428304389e-05, 'epoch': 0.43567954301736633, 'step': 2419000}
INFO:transformers.trainer:{'loss': 3.2339430723190308, 'learning_rate': 4.273717338893126e-05, 'epoch': 0.43576959666412474, 'step': 2419500}
INFO:transformers.trainer:{'loss': 3.183123907089233, 'learning_rate': 4.273567249481861e-05, 'epoch': 0.4358596503108832, 'step': 2420000}
INFO:transformers.trainer:{'loss': 3.2034072704315184, 'learning_rate': 4.273417160070598e-05, 'epoch': 0.43594970395764165, 'step': 2420500}
INFO:transformers.trainer:{'loss': 3.2836304500102997, 'learning_rate': 4.2732670706593336e-05, 'epoch': 0.4360397576044001, 'step': 2421000}
INFO:transformers.trainer:{'loss': 3.170415984630585, 'learning_rate': 4.2731169812480695e-05, 'epoch': 0.4361298112511585, 'step': 2421500}
INFO:transformers.trainer:{'loss': 3.2152902505397796, 'learning_rate': 4.2729668918368054e-05, 'epoch': 0.436219864897917, 'step': 2422000}
INFO:transformers.trainer:{'loss': 3.174263806581497, 'learning_rate': 4.272816802425541e-05, 'epoch': 0.43630991854467543, 'step': 2422500}
INFO:transformers.trainer:{'loss': 3.211033771753311, 'learning_rate': 4.272666713014277e-05, 'epoch': 0.4363999721914339, 'step': 2423000}
INFO:transformers.trainer:{'loss': 3.2881095604896546, 'learning_rate': 4.272516623603013e-05, 'epoch': 0.43649002583819235, 'step': 2423500}
INFO:transformers.trainer:{'loss': 3.2239824891090394, 'learning_rate': 4.272366534191749e-05, 'epoch': 0.43658007948495076, 'step': 2424000}
INFO:transformers.trainer:{'loss': 3.237426859378815, 'learning_rate': 4.272216444780485e-05, 'epoch': 0.4366701331317092, 'step': 2424500}
INFO:transformers.trainer:{'loss': 3.2244189338684084, 'learning_rate': 4.272066355369221e-05, 'epoch': 0.4367601867784677, 'step': 2425000}
INFO:transformers.trainer:{'loss': 3.193934379577637, 'learning_rate': 4.271916265957957e-05, 'epoch': 0.43685024042522613, 'step': 2425500}
INFO:transformers.trainer:{'loss': 3.258525620698929, 'learning_rate': 4.2717661765466926e-05, 'epoch': 0.43694029407198454, 'step': 2426000}
INFO:transformers.trainer:{'loss': 3.23056578540802, 'learning_rate': 4.2716160871354285e-05, 'epoch': 0.437030347718743, 'step': 2426500}
INFO:transformers.trainer:{'loss': 3.1923130366802215, 'learning_rate': 4.2714659977241644e-05, 'epoch': 0.43712040136550145, 'step': 2427000}
INFO:transformers.trainer:{'loss': 3.2329006447792055, 'learning_rate': 4.2713159083129003e-05, 'epoch': 0.4372104550122599, 'step': 2427500}
INFO:transformers.trainer:{'loss': 3.1123293635845184, 'learning_rate': 4.271165818901636e-05, 'epoch': 0.43730050865901837, 'step': 2428000}
INFO:transformers.trainer:{'loss': 3.2495530264377592, 'learning_rate': 4.271015729490372e-05, 'epoch': 0.4373905623057768, 'step': 2428500}
INFO:transformers.trainer:{'loss': 3.249808023929596, 'learning_rate': 4.270865640079108e-05, 'epoch': 0.43748061595253523, 'step': 2429000}
INFO:transformers.trainer:{'loss': 3.2047602407932283, 'learning_rate': 4.270715550667844e-05, 'epoch': 0.4375706695992937, 'step': 2429500}
INFO:transformers.trainer:{'loss': 3.199267126560211, 'learning_rate': 4.27056546125658e-05, 'epoch': 0.43766072324605215, 'step': 2430000}
INFO:transformers.trainer:{'loss': 3.2464321874380113, 'learning_rate': 4.270415371845316e-05, 'epoch': 0.4377507768928106, 'step': 2430500}
INFO:transformers.trainer:{'loss': 3.2841452655792236, 'learning_rate': 4.270265282434052e-05, 'epoch': 0.437840830539569, 'step': 2431000}
INFO:transformers.trainer:{'loss': 3.199682026863098, 'learning_rate': 4.2701151930227876e-05, 'epoch': 0.4379308841863275, 'step': 2431500}
INFO:transformers.trainer:{'loss': 3.2065183742046357, 'learning_rate': 4.2699651036115235e-05, 'epoch': 0.43802093783308593, 'step': 2432000}
INFO:transformers.trainer:{'loss': 3.2283212168216706, 'learning_rate': 4.2698150142002594e-05, 'epoch': 0.4381109914798444, 'step': 2432500}
INFO:transformers.trainer:{'loss': 3.1869467952251433, 'learning_rate': 4.269664924788995e-05, 'epoch': 0.4382010451266028, 'step': 2433000}
INFO:transformers.trainer:{'loss': 3.195757454633713, 'learning_rate': 4.269514835377731e-05, 'epoch': 0.43829109877336125, 'step': 2433500}
INFO:transformers.trainer:{'loss': 3.2082720861434937, 'learning_rate': 4.269364745966467e-05, 'epoch': 0.4383811524201197, 'step': 2434000}
INFO:transformers.trainer:{'loss': 3.1857929067611694, 'learning_rate': 4.269214656555203e-05, 'epoch': 0.43847120606687817, 'step': 2434500}
INFO:transformers.trainer:{'loss': 3.1696971896886827, 'learning_rate': 4.2690645671439396e-05, 'epoch': 0.43856125971363663, 'step': 2435000}
INFO:transformers.trainer:{'loss': 3.155436253786087, 'learning_rate': 4.268914477732675e-05, 'epoch': 0.43865131336039503, 'step': 2435500}
INFO:transformers.trainer:{'loss': 3.2472796384096148, 'learning_rate': 4.2687643883214114e-05, 'epoch': 0.4387413670071535, 'step': 2436000}
INFO:transformers.trainer:{'loss': 3.209623172998428, 'learning_rate': 4.2686142989101466e-05, 'epoch': 0.43883142065391195, 'step': 2436500}
INFO:transformers.trainer:{'loss': 3.1630938687324526, 'learning_rate': 4.268464209498883e-05, 'epoch': 0.4389214743006704, 'step': 2437000}
INFO:transformers.trainer:{'loss': 3.2324326524734497, 'learning_rate': 4.2683141200876184e-05, 'epoch': 0.4390115279474288, 'step': 2437500}
INFO:transformers.trainer:{'loss': 3.1895222795009612, 'learning_rate': 4.268164030676355e-05, 'epoch': 0.4391015815941873, 'step': 2438000}
INFO:transformers.trainer:{'loss': 3.1244618985652926, 'learning_rate': 4.26801394126509e-05, 'epoch': 0.43919163524094573, 'step': 2438500}
INFO:transformers.trainer:{'loss': 3.286982814192772, 'learning_rate': 4.267863851853827e-05, 'epoch': 0.4392816888877042, 'step': 2439000}
INFO:transformers.trainer:{'loss': 3.217954139471054, 'learning_rate': 4.267713762442562e-05, 'epoch': 0.43937174253446265, 'step': 2439500}
INFO:transformers.trainer:{'loss': 3.1855348999500275, 'learning_rate': 4.2675636730312986e-05, 'epoch': 0.43946179618122105, 'step': 2440000}
INFO:transformers.trainer:{'loss': 3.213522582769394, 'learning_rate': 4.267413583620034e-05, 'epoch': 0.4395518498279795, 'step': 2440500}
INFO:transformers.trainer:{'loss': 3.193387164592743, 'learning_rate': 4.2672634942087705e-05, 'epoch': 0.43964190347473797, 'step': 2441000}
INFO:transformers.trainer:{'loss': 3.2272195613384245, 'learning_rate': 4.2671134047975064e-05, 'epoch': 0.43973195712149643, 'step': 2441500}
INFO:transformers.trainer:{'loss': 3.2370750148296357, 'learning_rate': 4.266963315386242e-05, 'epoch': 0.4398220107682549, 'step': 2442000}
INFO:transformers.trainer:{'loss': 3.1523113503456117, 'learning_rate': 4.266813225974978e-05, 'epoch': 0.4399120644150133, 'step': 2442500}
INFO:transformers.trainer:{'loss': 3.2330748581886293, 'learning_rate': 4.266663136563714e-05, 'epoch': 0.44000211806177175, 'step': 2443000}
INFO:transformers.trainer:{'loss': 3.2104858322143555, 'learning_rate': 4.26651304715245e-05, 'epoch': 0.4400921717085302, 'step': 2443500}
INFO:transformers.trainer:{'loss': 3.2227700481414794, 'learning_rate': 4.266362957741186e-05, 'epoch': 0.44018222535528867, 'step': 2444000}
INFO:transformers.trainer:{'loss': 3.2645214517116545, 'learning_rate': 4.266212868329922e-05, 'epoch': 0.4402722790020471, 'step': 2444500}
INFO:transformers.trainer:{'loss': 3.2441070404052734, 'learning_rate': 4.266062778918658e-05, 'epoch': 0.44036233264880553, 'step': 2445000}
INFO:transformers.trainer:{'loss': 3.203010626554489, 'learning_rate': 4.2659126895073936e-05, 'epoch': 0.440452386295564, 'step': 2445500}
INFO:transformers.trainer:{'loss': 3.15554389166832, 'learning_rate': 4.2657626000961295e-05, 'epoch': 0.44054243994232245, 'step': 2446000}
INFO:transformers.trainer:{'loss': 3.238160066366196, 'learning_rate': 4.2656125106848654e-05, 'epoch': 0.4406324935890809, 'step': 2446500}
INFO:transformers.trainer:{'loss': 3.2173529918193817, 'learning_rate': 4.265462421273601e-05, 'epoch': 0.4407225472358393, 'step': 2447000}
INFO:transformers.trainer:{'loss': 3.22077604675293, 'learning_rate': 4.265312331862337e-05, 'epoch': 0.44081260088259777, 'step': 2447500}
INFO:transformers.trainer:{'loss': 3.1746855959892275, 'learning_rate': 4.265162242451073e-05, 'epoch': 0.44090265452935623, 'step': 2448000}
INFO:transformers.trainer:{'loss': 3.246422989487648, 'learning_rate': 4.265012153039809e-05, 'epoch': 0.4409927081761147, 'step': 2448500}
INFO:transformers.trainer:{'loss': 3.2710176916122435, 'learning_rate': 4.264862063628545e-05, 'epoch': 0.44108276182287315, 'step': 2449000}
INFO:transformers.trainer:{'loss': 3.1891745598316192, 'learning_rate': 4.264711974217281e-05, 'epoch': 0.44117281546963155, 'step': 2449500}
INFO:transformers.trainer:{'loss': 3.2234472215175627, 'learning_rate': 4.264561884806017e-05, 'epoch': 0.44126286911639, 'step': 2450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2126767973899844, 'learning_rate': 4.2644117953947527e-05, 'epoch': 0.44135292276314847, 'step': 2450500}
INFO:transformers.trainer:{'loss': 3.23205499958992, 'learning_rate': 4.2642617059834886e-05, 'epoch': 0.44144297640990693, 'step': 2451000}
INFO:transformers.trainer:{'loss': 3.161560022354126, 'learning_rate': 4.2641116165722245e-05, 'epoch': 0.44153303005666533, 'step': 2451500}
INFO:transformers.trainer:{'loss': 3.2312156314849854, 'learning_rate': 4.2639615271609604e-05, 'epoch': 0.4416230837034238, 'step': 2452000}
INFO:transformers.trainer:{'loss': 3.172006690263748, 'learning_rate': 4.263811437749696e-05, 'epoch': 0.44171313735018225, 'step': 2452500}
INFO:transformers.trainer:{'loss': 3.1850406720638276, 'learning_rate': 4.263661348338432e-05, 'epoch': 0.4418031909969407, 'step': 2453000}
INFO:transformers.trainer:{'loss': 3.1387520170211793, 'learning_rate': 4.263511258927168e-05, 'epoch': 0.44189324464369917, 'step': 2453500}
INFO:transformers.trainer:{'loss': 3.210871176958084, 'learning_rate': 4.263361169515904e-05, 'epoch': 0.44198329829045757, 'step': 2454000}
INFO:transformers.trainer:{'loss': 3.2066916995048524, 'learning_rate': 4.26321108010464e-05, 'epoch': 0.44207335193721603, 'step': 2454500}
INFO:transformers.trainer:{'loss': 3.1983412160873415, 'learning_rate': 4.263060990693376e-05, 'epoch': 0.4421634055839745, 'step': 2455000}
INFO:transformers.trainer:{'loss': 3.209157788872719, 'learning_rate': 4.2629109012821124e-05, 'epoch': 0.44225345923073295, 'step': 2455500}
INFO:transformers.trainer:{'loss': 3.2179898962974547, 'learning_rate': 4.2627608118708476e-05, 'epoch': 0.44234351287749135, 'step': 2456000}
INFO:transformers.trainer:{'loss': 3.1258029153347016, 'learning_rate': 4.262610722459584e-05, 'epoch': 0.4424335665242498, 'step': 2456500}
INFO:transformers.trainer:{'loss': 3.2612373645305635, 'learning_rate': 4.2624606330483194e-05, 'epoch': 0.44252362017100827, 'step': 2457000}
INFO:transformers.trainer:{'loss': 3.1802604968547823, 'learning_rate': 4.262310543637056e-05, 'epoch': 0.44261367381776673, 'step': 2457500}
INFO:transformers.trainer:{'loss': 3.147553097486496, 'learning_rate': 4.262160454225791e-05, 'epoch': 0.4427037274645252, 'step': 2458000}
INFO:transformers.trainer:{'loss': 3.197640857100487, 'learning_rate': 4.262010364814528e-05, 'epoch': 0.4427937811112836, 'step': 2458500}
INFO:transformers.trainer:{'loss': 3.179711830377579, 'learning_rate': 4.261860275403263e-05, 'epoch': 0.44288383475804205, 'step': 2459000}
INFO:transformers.trainer:{'loss': 3.1880066578388213, 'learning_rate': 4.2617101859919996e-05, 'epoch': 0.4429738884048005, 'step': 2459500}
INFO:transformers.trainer:{'loss': 3.1947247817516327, 'learning_rate': 4.261560096580735e-05, 'epoch': 0.44306394205155897, 'step': 2460000}
INFO:transformers.trainer:{'loss': 3.1950282678604127, 'learning_rate': 4.2614100071694714e-05, 'epoch': 0.4431539956983174, 'step': 2460500}
INFO:transformers.trainer:{'loss': 3.212350038290024, 'learning_rate': 4.2612599177582067e-05, 'epoch': 0.44324404934507583, 'step': 2461000}
INFO:transformers.trainer:{'loss': 3.2076658456325533, 'learning_rate': 4.261109828346943e-05, 'epoch': 0.4433341029918343, 'step': 2461500}
INFO:transformers.trainer:{'loss': 3.211478771686554, 'learning_rate': 4.260959738935679e-05, 'epoch': 0.44342415663859275, 'step': 2462000}
INFO:transformers.trainer:{'loss': 3.1764214742183685, 'learning_rate': 4.260809649524415e-05, 'epoch': 0.4435142102853512, 'step': 2462500}
INFO:transformers.trainer:{'loss': 3.229607761144638, 'learning_rate': 4.260659560113151e-05, 'epoch': 0.4436042639321096, 'step': 2463000}
INFO:transformers.trainer:{'loss': 3.1926549022197723, 'learning_rate': 4.260509470701887e-05, 'epoch': 0.44369431757886807, 'step': 2463500}
INFO:transformers.trainer:{'loss': 3.1724067146778108, 'learning_rate': 4.260359381290623e-05, 'epoch': 0.44378437122562653, 'step': 2464000}
INFO:transformers.trainer:{'loss': 3.175887571454048, 'learning_rate': 4.260209291879359e-05, 'epoch': 0.443874424872385, 'step': 2464500}
INFO:transformers.trainer:{'loss': 3.2479976880550385, 'learning_rate': 4.2600592024680946e-05, 'epoch': 0.44396447851914345, 'step': 2465000}
INFO:transformers.trainer:{'loss': 3.2632176647186277, 'learning_rate': 4.2599091130568305e-05, 'epoch': 0.44405453216590185, 'step': 2465500}
INFO:transformers.trainer:{'loss': 3.1943741085529327, 'learning_rate': 4.2597590236455664e-05, 'epoch': 0.4441445858126603, 'step': 2466000}
INFO:transformers.trainer:{'loss': 3.2505498374700545, 'learning_rate': 4.259608934234302e-05, 'epoch': 0.44423463945941877, 'step': 2466500}
INFO:transformers.trainer:{'loss': 3.1282749276161192, 'learning_rate': 4.259458844823038e-05, 'epoch': 0.4443246931061772, 'step': 2467000}
INFO:transformers.trainer:{'loss': 3.1539469105005264, 'learning_rate': 4.259308755411774e-05, 'epoch': 0.4444147467529357, 'step': 2467500}
INFO:transformers.trainer:{'loss': 3.198029976606369, 'learning_rate': 4.25915866600051e-05, 'epoch': 0.4445048003996941, 'step': 2468000}
INFO:transformers.trainer:{'loss': 3.2266715009212494, 'learning_rate': 4.259008576589246e-05, 'epoch': 0.44459485404645255, 'step': 2468500}
INFO:transformers.trainer:{'loss': 3.187348544359207, 'learning_rate': 4.258858487177982e-05, 'epoch': 0.444684907693211, 'step': 2469000}
INFO:transformers.trainer:{'loss': 3.2140752363204954, 'learning_rate': 4.258708397766718e-05, 'epoch': 0.44477496133996947, 'step': 2469500}
INFO:transformers.trainer:{'loss': 3.2326275007724763, 'learning_rate': 4.2585583083554536e-05, 'epoch': 0.44486501498672787, 'step': 2470000}
INFO:transformers.trainer:{'loss': 3.2093656191825866, 'learning_rate': 4.2584082189441895e-05, 'epoch': 0.44495506863348633, 'step': 2470500}
INFO:transformers.trainer:{'loss': 3.1690308356285097, 'learning_rate': 4.2582581295329254e-05, 'epoch': 0.4450451222802448, 'step': 2471000}
INFO:transformers.trainer:{'loss': 3.246653242111206, 'learning_rate': 4.2581080401216613e-05, 'epoch': 0.44513517592700325, 'step': 2471500}
INFO:transformers.trainer:{'loss': 3.1915553003549575, 'learning_rate': 4.257957950710397e-05, 'epoch': 0.4452252295737617, 'step': 2472000}
INFO:transformers.trainer:{'loss': 3.198531973361969, 'learning_rate': 4.257807861299133e-05, 'epoch': 0.4453152832205201, 'step': 2472500}
INFO:transformers.trainer:{'loss': 3.2143732274770738, 'learning_rate': 4.257657771887869e-05, 'epoch': 0.44540533686727857, 'step': 2473000}
INFO:transformers.trainer:{'loss': 3.150584423303604, 'learning_rate': 4.257507682476605e-05, 'epoch': 0.445495390514037, 'step': 2473500}
INFO:transformers.trainer:{'loss': 3.2175694633722305, 'learning_rate': 4.257357593065341e-05, 'epoch': 0.4455854441607955, 'step': 2474000}
INFO:transformers.trainer:{'loss': 3.2763774921894075, 'learning_rate': 4.257207503654077e-05, 'epoch': 0.4456754978075539, 'step': 2474500}
INFO:transformers.trainer:{'loss': 3.2542058262825013, 'learning_rate': 4.257057414242813e-05, 'epoch': 0.44576555145431235, 'step': 2475000}
INFO:transformers.trainer:{'loss': 3.1568513486385346, 'learning_rate': 4.2569073248315486e-05, 'epoch': 0.4458556051010708, 'step': 2475500}
INFO:transformers.trainer:{'loss': 3.26590554189682, 'learning_rate': 4.256757235420285e-05, 'epoch': 0.44594565874782927, 'step': 2476000}
INFO:transformers.trainer:{'loss': 3.2509052381515504, 'learning_rate': 4.2566071460090204e-05, 'epoch': 0.4460357123945877, 'step': 2476500}
INFO:transformers.trainer:{'loss': 3.2096333701610567, 'learning_rate': 4.256457056597757e-05, 'epoch': 0.44612576604134613, 'step': 2477000}
INFO:transformers.trainer:{'loss': 3.1879741017818453, 'learning_rate': 4.256306967186492e-05, 'epoch': 0.4462158196881046, 'step': 2477500}
INFO:transformers.trainer:{'loss': 3.1922033240795136, 'learning_rate': 4.256156877775229e-05, 'epoch': 0.44630587333486305, 'step': 2478000}
INFO:transformers.trainer:{'loss': 3.166852152824402, 'learning_rate': 4.256006788363964e-05, 'epoch': 0.4463959269816215, 'step': 2478500}
INFO:transformers.trainer:{'loss': 3.1660864996910094, 'learning_rate': 4.2558566989527006e-05, 'epoch': 0.44648598062837996, 'step': 2479000}
INFO:transformers.trainer:{'loss': 3.2162933316230773, 'learning_rate': 4.255706609541436e-05, 'epoch': 0.44657603427513837, 'step': 2479500}
INFO:transformers.trainer:{'loss': 3.248082650184631, 'learning_rate': 4.2555565201301724e-05, 'epoch': 0.4466660879218968, 'step': 2480000}
INFO:transformers.trainer:{'loss': 3.2164835486412047, 'learning_rate': 4.2554064307189076e-05, 'epoch': 0.4467561415686553, 'step': 2480500}
INFO:transformers.trainer:{'loss': 3.226171805858612, 'learning_rate': 4.255256341307644e-05, 'epoch': 0.44684619521541374, 'step': 2481000}
INFO:transformers.trainer:{'loss': 3.2565312390327454, 'learning_rate': 4.2551062518963794e-05, 'epoch': 0.44693624886217215, 'step': 2481500}
INFO:transformers.trainer:{'loss': 3.2153318645954134, 'learning_rate': 4.254956162485116e-05, 'epoch': 0.4470263025089306, 'step': 2482000}
INFO:transformers.trainer:{'loss': 3.182145350933075, 'learning_rate': 4.254806073073851e-05, 'epoch': 0.44711635615568907, 'step': 2482500}
INFO:transformers.trainer:{'loss': 3.2144537353515625, 'learning_rate': 4.254655983662588e-05, 'epoch': 0.4472064098024475, 'step': 2483000}
INFO:transformers.trainer:{'loss': 3.2050716569423674, 'learning_rate': 4.254505894251324e-05, 'epoch': 0.447296463449206, 'step': 2483500}
INFO:transformers.trainer:{'loss': 3.2293696942329406, 'learning_rate': 4.2543558048400596e-05, 'epoch': 0.4473865170959644, 'step': 2484000}
INFO:transformers.trainer:{'loss': 3.205310337662697, 'learning_rate': 4.2542057154287955e-05, 'epoch': 0.44747657074272285, 'step': 2484500}
INFO:transformers.trainer:{'loss': 3.227569730520248, 'learning_rate': 4.2540556260175315e-05, 'epoch': 0.4475666243894813, 'step': 2485000}
INFO:transformers.trainer:{'loss': 3.195573001384735, 'learning_rate': 4.2539055366062674e-05, 'epoch': 0.44765667803623976, 'step': 2485500}
INFO:transformers.trainer:{'loss': 3.161822414159775, 'learning_rate': 4.253755447195003e-05, 'epoch': 0.4477467316829982, 'step': 2486000}
INFO:transformers.trainer:{'loss': 3.2247059786319734, 'learning_rate': 4.253605357783739e-05, 'epoch': 0.4478367853297566, 'step': 2486500}
INFO:transformers.trainer:{'loss': 3.2502267112731933, 'learning_rate': 4.253455268372475e-05, 'epoch': 0.4479268389765151, 'step': 2487000}
INFO:transformers.trainer:{'loss': 3.194097130537033, 'learning_rate': 4.253305178961211e-05, 'epoch': 0.44801689262327354, 'step': 2487500}
INFO:transformers.trainer:{'loss': 3.2859642119407653, 'learning_rate': 4.253155089549947e-05, 'epoch': 0.448106946270032, 'step': 2488000}
INFO:transformers.trainer:{'loss': 3.1625954250097275, 'learning_rate': 4.253005000138683e-05, 'epoch': 0.4481969999167904, 'step': 2488500}
INFO:transformers.trainer:{'loss': 3.149178839802742, 'learning_rate': 4.252854910727419e-05, 'epoch': 0.44828705356354887, 'step': 2489000}
INFO:transformers.trainer:{'loss': 3.2225816926956177, 'learning_rate': 4.2527048213161546e-05, 'epoch': 0.4483771072103073, 'step': 2489500}
INFO:transformers.trainer:{'loss': 3.1833865506649017, 'learning_rate': 4.2525547319048905e-05, 'epoch': 0.4484671608570658, 'step': 2490000}
INFO:transformers.trainer:{'loss': 3.189621828556061, 'learning_rate': 4.2524046424936264e-05, 'epoch': 0.44855721450382424, 'step': 2490500}
INFO:transformers.trainer:{'loss': 3.213429552078247, 'learning_rate': 4.252254553082362e-05, 'epoch': 0.44864726815058265, 'step': 2491000}
INFO:transformers.trainer:{'loss': 3.181662456870079, 'learning_rate': 4.252104463671098e-05, 'epoch': 0.4487373217973411, 'step': 2491500}
INFO:transformers.trainer:{'loss': 3.170080117940903, 'learning_rate': 4.251954374259834e-05, 'epoch': 0.44882737544409956, 'step': 2492000}
INFO:transformers.trainer:{'loss': 3.2684894144535064, 'learning_rate': 4.25180428484857e-05, 'epoch': 0.448917429090858, 'step': 2492500}
INFO:transformers.trainer:{'loss': 3.233390429019928, 'learning_rate': 4.251654195437306e-05, 'epoch': 0.4490074827376164, 'step': 2493000}
INFO:transformers.trainer:{'loss': 3.2344263768196106, 'learning_rate': 4.251504106026042e-05, 'epoch': 0.4490975363843749, 'step': 2493500}
INFO:transformers.trainer:{'loss': 3.193170542240143, 'learning_rate': 4.251354016614778e-05, 'epoch': 0.44918759003113334, 'step': 2494000}
INFO:transformers.trainer:{'loss': 3.1743283574581147, 'learning_rate': 4.2512039272035136e-05, 'epoch': 0.4492776436778918, 'step': 2494500}
INFO:transformers.trainer:{'loss': 3.2511433069705964, 'learning_rate': 4.2510538377922496e-05, 'epoch': 0.44936769732465026, 'step': 2495000}
INFO:transformers.trainer:{'loss': 3.245900063753128, 'learning_rate': 4.2509037483809855e-05, 'epoch': 0.44945775097140866, 'step': 2495500}
INFO:transformers.trainer:{'loss': 3.2001551337242127, 'learning_rate': 4.2507536589697214e-05, 'epoch': 0.4495478046181671, 'step': 2496000}
INFO:transformers.trainer:{'loss': 3.198061477661133, 'learning_rate': 4.250603569558458e-05, 'epoch': 0.4496378582649256, 'step': 2496500}
INFO:transformers.trainer:{'loss': 3.2242946012020113, 'learning_rate': 4.250453480147193e-05, 'epoch': 0.44972791191168404, 'step': 2497000}
INFO:transformers.trainer:{'loss': 3.195661878824234, 'learning_rate': 4.25030339073593e-05, 'epoch': 0.4498179655584425, 'step': 2497500}
INFO:transformers.trainer:{'loss': 3.2296364035606384, 'learning_rate': 4.250153301324665e-05, 'epoch': 0.4499080192052009, 'step': 2498000}
INFO:transformers.trainer:{'loss': 3.213136534690857, 'learning_rate': 4.2500032119134016e-05, 'epoch': 0.44999807285195936, 'step': 2498500}
INFO:transformers.trainer:{'loss': 3.2272630343437196, 'learning_rate': 4.249853122502137e-05, 'epoch': 0.4500881264987178, 'step': 2499000}
INFO:transformers.trainer:{'loss': 3.2787392938137057, 'learning_rate': 4.2497030330908734e-05, 'epoch': 0.4501781801454763, 'step': 2499500}
INFO:transformers.trainer:{'loss': 3.1773750864267347, 'learning_rate': 4.2495529436796086e-05, 'epoch': 0.4502682337922347, 'step': 2500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1678658806085584, 'learning_rate': 4.249402854268345e-05, 'epoch': 0.45035828743899314, 'step': 2500500}
INFO:transformers.trainer:{'loss': 3.196973169207573, 'learning_rate': 4.2492527648570804e-05, 'epoch': 0.4504483410857516, 'step': 2501000}
INFO:transformers.trainer:{'loss': 3.147408786058426, 'learning_rate': 4.249102675445817e-05, 'epoch': 0.45053839473251006, 'step': 2501500}
INFO:transformers.trainer:{'loss': 3.216481034517288, 'learning_rate': 4.248952586034552e-05, 'epoch': 0.4506284483792685, 'step': 2502000}
INFO:transformers.trainer:{'loss': 3.1769281294345855, 'learning_rate': 4.248802496623289e-05, 'epoch': 0.4507185020260269, 'step': 2502500}
INFO:transformers.trainer:{'loss': 3.257396519780159, 'learning_rate': 4.248652407212024e-05, 'epoch': 0.4508085556727854, 'step': 2503000}
INFO:transformers.trainer:{'loss': 3.176107339859009, 'learning_rate': 4.2485023178007606e-05, 'epoch': 0.45089860931954384, 'step': 2503500}
INFO:transformers.trainer:{'loss': 3.2594838593006132, 'learning_rate': 4.2483522283894965e-05, 'epoch': 0.4509886629663023, 'step': 2504000}
INFO:transformers.trainer:{'loss': 3.2174124486446383, 'learning_rate': 4.2482021389782324e-05, 'epoch': 0.45107871661306076, 'step': 2504500}
INFO:transformers.trainer:{'loss': 3.1378481855392457, 'learning_rate': 4.248052049566968e-05, 'epoch': 0.45116877025981916, 'step': 2505000}
INFO:transformers.trainer:{'loss': 3.1826229150295258, 'learning_rate': 4.247901960155704e-05, 'epoch': 0.4512588239065776, 'step': 2505500}
INFO:transformers.trainer:{'loss': 3.2099199755191803, 'learning_rate': 4.24775187074444e-05, 'epoch': 0.4513488775533361, 'step': 2506000}
INFO:transformers.trainer:{'loss': 3.2120796835422514, 'learning_rate': 4.247601781333176e-05, 'epoch': 0.45143893120009454, 'step': 2506500}
INFO:transformers.trainer:{'loss': 3.186944396853447, 'learning_rate': 4.247451691921912e-05, 'epoch': 0.45152898484685294, 'step': 2507000}
INFO:transformers.trainer:{'loss': 3.2493437848091125, 'learning_rate': 4.247301602510648e-05, 'epoch': 0.4516190384936114, 'step': 2507500}
INFO:transformers.trainer:{'loss': 3.186270573735237, 'learning_rate': 4.247151513099384e-05, 'epoch': 0.45170909214036986, 'step': 2508000}
INFO:transformers.trainer:{'loss': 3.239937580823898, 'learning_rate': 4.24700142368812e-05, 'epoch': 0.4517991457871283, 'step': 2508500}
INFO:transformers.trainer:{'loss': 3.23118204665184, 'learning_rate': 4.2468513342768556e-05, 'epoch': 0.4518891994338868, 'step': 2509000}
INFO:transformers.trainer:{'loss': 3.2080475535392763, 'learning_rate': 4.2467012448655915e-05, 'epoch': 0.4519792530806452, 'step': 2509500}
INFO:transformers.trainer:{'loss': 3.183291423201561, 'learning_rate': 4.2465511554543274e-05, 'epoch': 0.45206930672740364, 'step': 2510000}
INFO:transformers.trainer:{'loss': 3.208742294549942, 'learning_rate': 4.246401066043064e-05, 'epoch': 0.4521593603741621, 'step': 2510500}
INFO:transformers.trainer:{'loss': 3.2431309962272645, 'learning_rate': 4.246250976631799e-05, 'epoch': 0.45224941402092056, 'step': 2511000}
INFO:transformers.trainer:{'loss': 3.1938476903438566, 'learning_rate': 4.246100887220536e-05, 'epoch': 0.45233946766767896, 'step': 2511500}
INFO:transformers.trainer:{'loss': 3.185597022533417, 'learning_rate': 4.245950797809271e-05, 'epoch': 0.4524295213144374, 'step': 2512000}
INFO:transformers.trainer:{'loss': 3.1681284248828887, 'learning_rate': 4.2458007083980076e-05, 'epoch': 0.4525195749611959, 'step': 2512500}
INFO:transformers.trainer:{'loss': 3.2041467752456665, 'learning_rate': 4.245650618986743e-05, 'epoch': 0.45260962860795434, 'step': 2513000}
INFO:transformers.trainer:{'loss': 3.1983721470832824, 'learning_rate': 4.2455005295754794e-05, 'epoch': 0.4526996822547128, 'step': 2513500}
INFO:transformers.trainer:{'loss': 3.2092134482860564, 'learning_rate': 4.2453504401642146e-05, 'epoch': 0.4527897359014712, 'step': 2514000}
INFO:transformers.trainer:{'loss': 3.2250002303123475, 'learning_rate': 4.2452003507529505e-05, 'epoch': 0.45287978954822966, 'step': 2514500}
INFO:transformers.trainer:{'loss': 3.2235187318325043, 'learning_rate': 4.2450502613416864e-05, 'epoch': 0.4529698431949881, 'step': 2515000}
INFO:transformers.trainer:{'loss': 3.18826527261734, 'learning_rate': 4.244900171930422e-05, 'epoch': 0.4530598968417466, 'step': 2515500}
INFO:transformers.trainer:{'loss': 3.183986447811127, 'learning_rate': 4.244750082519158e-05, 'epoch': 0.45314995048850504, 'step': 2516000}
INFO:transformers.trainer:{'loss': 3.169784158706665, 'learning_rate': 4.244599993107894e-05, 'epoch': 0.45324000413526344, 'step': 2516500}
INFO:transformers.trainer:{'loss': 3.184895387649536, 'learning_rate': 4.24444990369663e-05, 'epoch': 0.4533300577820219, 'step': 2517000}
INFO:transformers.trainer:{'loss': 3.1562119369506836, 'learning_rate': 4.244299814285366e-05, 'epoch': 0.45342011142878036, 'step': 2517500}
INFO:transformers.trainer:{'loss': 3.2164862172603605, 'learning_rate': 4.2441497248741025e-05, 'epoch': 0.4535101650755388, 'step': 2518000}
INFO:transformers.trainer:{'loss': 3.211786647319794, 'learning_rate': 4.243999635462838e-05, 'epoch': 0.4536002187222972, 'step': 2518500}
INFO:transformers.trainer:{'loss': 3.2172786135673523, 'learning_rate': 4.2438495460515744e-05, 'epoch': 0.4536902723690557, 'step': 2519000}
INFO:transformers.trainer:{'loss': 3.232345126628876, 'learning_rate': 4.2436994566403096e-05, 'epoch': 0.45378032601581414, 'step': 2519500}
INFO:transformers.trainer:{'loss': 3.2547721335887907, 'learning_rate': 4.243549367229046e-05, 'epoch': 0.4538703796625726, 'step': 2520000}
INFO:transformers.trainer:{'loss': 3.2063343591690066, 'learning_rate': 4.2433992778177814e-05, 'epoch': 0.45396043330933106, 'step': 2520500}
INFO:transformers.trainer:{'loss': 3.2027217602729796, 'learning_rate': 4.243249188406518e-05, 'epoch': 0.45405048695608946, 'step': 2521000}
INFO:transformers.trainer:{'loss': 3.243746194243431, 'learning_rate': 4.243099098995253e-05, 'epoch': 0.4541405406028479, 'step': 2521500}
INFO:transformers.trainer:{'loss': 3.210475976347923, 'learning_rate': 4.24294900958399e-05, 'epoch': 0.4542305942496064, 'step': 2522000}
INFO:transformers.trainer:{'loss': 3.2107441239356995, 'learning_rate': 4.242798920172725e-05, 'epoch': 0.45432064789636484, 'step': 2522500}
INFO:transformers.trainer:{'loss': 3.167489589691162, 'learning_rate': 4.2426488307614616e-05, 'epoch': 0.4544107015431233, 'step': 2523000}
INFO:transformers.trainer:{'loss': 3.227541919231415, 'learning_rate': 4.242498741350197e-05, 'epoch': 0.4545007551898817, 'step': 2523500}
INFO:transformers.trainer:{'loss': 3.187335650920868, 'learning_rate': 4.2423486519389334e-05, 'epoch': 0.45459080883664016, 'step': 2524000}
INFO:transformers.trainer:{'loss': 3.2007136462926864, 'learning_rate': 4.242198562527669e-05, 'epoch': 0.4546808624833986, 'step': 2524500}
INFO:transformers.trainer:{'loss': 3.2120894693136215, 'learning_rate': 4.242048473116405e-05, 'epoch': 0.4547709161301571, 'step': 2525000}
INFO:transformers.trainer:{'loss': 3.255707389831543, 'learning_rate': 4.241898383705141e-05, 'epoch': 0.4548609697769155, 'step': 2525500}
INFO:transformers.trainer:{'loss': 3.1950957815647127, 'learning_rate': 4.241748294293877e-05, 'epoch': 0.45495102342367394, 'step': 2526000}
INFO:transformers.trainer:{'loss': 3.177782326936722, 'learning_rate': 4.241598204882613e-05, 'epoch': 0.4550410770704324, 'step': 2526500}
INFO:transformers.trainer:{'loss': 3.1335239264965056, 'learning_rate': 4.241448115471349e-05, 'epoch': 0.45513113071719086, 'step': 2527000}
INFO:transformers.trainer:{'loss': 3.2108295109272005, 'learning_rate': 4.241298026060085e-05, 'epoch': 0.4552211843639493, 'step': 2527500}
INFO:transformers.trainer:{'loss': 3.232432600736618, 'learning_rate': 4.2411479366488206e-05, 'epoch': 0.4553112380107077, 'step': 2528000}
INFO:transformers.trainer:{'loss': 3.1632933809757233, 'learning_rate': 4.2409978472375565e-05, 'epoch': 0.4554012916574662, 'step': 2528500}
INFO:transformers.trainer:{'loss': 3.175942668437958, 'learning_rate': 4.2408477578262925e-05, 'epoch': 0.45549134530422464, 'step': 2529000}
INFO:transformers.trainer:{'loss': 3.1664398740530015, 'learning_rate': 4.2406976684150284e-05, 'epoch': 0.4555813989509831, 'step': 2529500}
INFO:transformers.trainer:{'loss': 3.2299764288663866, 'learning_rate': 4.240547579003764e-05, 'epoch': 0.4556714525977415, 'step': 2530000}
INFO:transformers.trainer:{'loss': 3.236894289255142, 'learning_rate': 4.2403974895925e-05, 'epoch': 0.45576150624449996, 'step': 2530500}
INFO:transformers.trainer:{'loss': 3.146437606573105, 'learning_rate': 4.240247400181236e-05, 'epoch': 0.4558515598912584, 'step': 2531000}
INFO:transformers.trainer:{'loss': 3.173056284189224, 'learning_rate': 4.240097310769972e-05, 'epoch': 0.4559416135380169, 'step': 2531500}
INFO:transformers.trainer:{'loss': 3.159007514715195, 'learning_rate': 4.2399472213587086e-05, 'epoch': 0.45603166718477534, 'step': 2532000}
INFO:transformers.trainer:{'loss': 3.201933875799179, 'learning_rate': 4.239797131947444e-05, 'epoch': 0.45612172083153374, 'step': 2532500}
INFO:transformers.trainer:{'loss': 3.199021759748459, 'learning_rate': 4.2396470425361804e-05, 'epoch': 0.4562117744782922, 'step': 2533000}
INFO:transformers.trainer:{'loss': 3.1951390092372893, 'learning_rate': 4.2394969531249156e-05, 'epoch': 0.45630182812505066, 'step': 2533500}
INFO:transformers.trainer:{'loss': 3.190026456594467, 'learning_rate': 4.239346863713652e-05, 'epoch': 0.4563918817718091, 'step': 2534000}
INFO:transformers.trainer:{'loss': 3.182915145635605, 'learning_rate': 4.2391967743023874e-05, 'epoch': 0.4564819354185676, 'step': 2534500}
INFO:transformers.trainer:{'loss': 3.1720519664287568, 'learning_rate': 4.239046684891124e-05, 'epoch': 0.456571989065326, 'step': 2535000}
INFO:transformers.trainer:{'loss': 3.240812816143036, 'learning_rate': 4.238896595479859e-05, 'epoch': 0.45666204271208444, 'step': 2535500}
INFO:transformers.trainer:{'loss': 3.1972451230287553, 'learning_rate': 4.238746506068596e-05, 'epoch': 0.4567520963588429, 'step': 2536000}
INFO:transformers.trainer:{'loss': 3.1052090430259707, 'learning_rate': 4.238596416657331e-05, 'epoch': 0.45684215000560136, 'step': 2536500}
INFO:transformers.trainer:{'loss': 3.196849902391434, 'learning_rate': 4.2384463272460676e-05, 'epoch': 0.45693220365235976, 'step': 2537000}
INFO:transformers.trainer:{'loss': 3.2316435952186584, 'learning_rate': 4.238296237834803e-05, 'epoch': 0.4570222572991182, 'step': 2537500}
INFO:transformers.trainer:{'loss': 3.1760567607879637, 'learning_rate': 4.238146148423539e-05, 'epoch': 0.4571123109458767, 'step': 2538000}
INFO:transformers.trainer:{'loss': 3.217658648967743, 'learning_rate': 4.237996059012275e-05, 'epoch': 0.45720236459263514, 'step': 2538500}
INFO:transformers.trainer:{'loss': 3.192169929265976, 'learning_rate': 4.2378459696010106e-05, 'epoch': 0.4572924182393936, 'step': 2539000}
INFO:transformers.trainer:{'loss': 3.1770269236564634, 'learning_rate': 4.237695880189747e-05, 'epoch': 0.457382471886152, 'step': 2539500}
INFO:transformers.trainer:{'loss': 3.198306270837784, 'learning_rate': 4.2375457907784824e-05, 'epoch': 0.45747252553291046, 'step': 2540000}
INFO:transformers.trainer:{'loss': 3.180068219423294, 'learning_rate': 4.237395701367219e-05, 'epoch': 0.4575625791796689, 'step': 2540500}
INFO:transformers.trainer:{'loss': 3.199365528225899, 'learning_rate': 4.237245611955954e-05, 'epoch': 0.4576526328264274, 'step': 2541000}
INFO:transformers.trainer:{'loss': 3.1954007930755615, 'learning_rate': 4.237095522544691e-05, 'epoch': 0.45774268647318583, 'step': 2541500}
INFO:transformers.trainer:{'loss': 3.2171369317770004, 'learning_rate': 4.236945433133426e-05, 'epoch': 0.45783274011994424, 'step': 2542000}
INFO:transformers.trainer:{'loss': 3.1771020052433014, 'learning_rate': 4.2367953437221626e-05, 'epoch': 0.4579227937667027, 'step': 2542500}
INFO:transformers.trainer:{'loss': 3.2469085397720336, 'learning_rate': 4.236645254310898e-05, 'epoch': 0.45801284741346115, 'step': 2543000}
INFO:transformers.trainer:{'loss': 3.190498866558075, 'learning_rate': 4.2364951648996344e-05, 'epoch': 0.4581029010602196, 'step': 2543500}
INFO:transformers.trainer:{'loss': 3.182945155382156, 'learning_rate': 4.2363450754883696e-05, 'epoch': 0.458192954706978, 'step': 2544000}
INFO:transformers.trainer:{'loss': 3.2054257955551146, 'learning_rate': 4.236194986077106e-05, 'epoch': 0.4582830083537365, 'step': 2544500}
INFO:transformers.trainer:{'loss': 3.2024716930389405, 'learning_rate': 4.236044896665842e-05, 'epoch': 0.45837306200049494, 'step': 2545000}
INFO:transformers.trainer:{'loss': 3.206590455055237, 'learning_rate': 4.235894807254578e-05, 'epoch': 0.4584631156472534, 'step': 2545500}
INFO:transformers.trainer:{'loss': 3.2178291654586793, 'learning_rate': 4.235744717843314e-05, 'epoch': 0.45855316929401185, 'step': 2546000}
INFO:transformers.trainer:{'loss': 3.1454608442783356, 'learning_rate': 4.23559462843205e-05, 'epoch': 0.45864322294077026, 'step': 2546500}
INFO:transformers.trainer:{'loss': 3.1513985307216643, 'learning_rate': 4.235444539020786e-05, 'epoch': 0.4587332765875287, 'step': 2547000}
INFO:transformers.trainer:{'loss': 3.217502109527588, 'learning_rate': 4.2352944496095216e-05, 'epoch': 0.4588233302342872, 'step': 2547500}
INFO:transformers.trainer:{'loss': 3.1428230559825896, 'learning_rate': 4.2351443601982575e-05, 'epoch': 0.45891338388104563, 'step': 2548000}
INFO:transformers.trainer:{'loss': 3.1968437633514406, 'learning_rate': 4.2349942707869934e-05, 'epoch': 0.45900343752780404, 'step': 2548500}
INFO:transformers.trainer:{'loss': 3.237103879928589, 'learning_rate': 4.234844181375729e-05, 'epoch': 0.4590934911745625, 'step': 2549000}
INFO:transformers.trainer:{'loss': 3.1543217623233795, 'learning_rate': 4.234694091964465e-05, 'epoch': 0.45918354482132095, 'step': 2549500}
INFO:transformers.trainer:{'loss': 3.232692545413971, 'learning_rate': 4.234544002553201e-05, 'epoch': 0.4592735984680794, 'step': 2550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1869827105998993, 'learning_rate': 4.234393913141937e-05, 'epoch': 0.4593636521148379, 'step': 2550500}
INFO:transformers.trainer:{'loss': 3.179891332626343, 'learning_rate': 4.234243823730673e-05, 'epoch': 0.4594537057615963, 'step': 2551000}
INFO:transformers.trainer:{'loss': 3.174003221273422, 'learning_rate': 4.234093734319409e-05, 'epoch': 0.45954375940835474, 'step': 2551500}
INFO:transformers.trainer:{'loss': 3.255633301734924, 'learning_rate': 4.233943644908145e-05, 'epoch': 0.4596338130551132, 'step': 2552000}
INFO:transformers.trainer:{'loss': 3.2089390041828154, 'learning_rate': 4.2337935554968813e-05, 'epoch': 0.45972386670187165, 'step': 2552500}
INFO:transformers.trainer:{'loss': 3.175492476463318, 'learning_rate': 4.2336434660856166e-05, 'epoch': 0.4598139203486301, 'step': 2553000}
INFO:transformers.trainer:{'loss': 3.1980594518184664, 'learning_rate': 4.233493376674353e-05, 'epoch': 0.4599039739953885, 'step': 2553500}
INFO:transformers.trainer:{'loss': 3.192409373283386, 'learning_rate': 4.2333432872630884e-05, 'epoch': 0.459994027642147, 'step': 2554000}
INFO:transformers.trainer:{'loss': 3.1461298060417175, 'learning_rate': 4.233193197851825e-05, 'epoch': 0.46008408128890543, 'step': 2554500}
INFO:transformers.trainer:{'loss': 3.1655683126449583, 'learning_rate': 4.23304310844056e-05, 'epoch': 0.4601741349356639, 'step': 2555000}
INFO:transformers.trainer:{'loss': 3.226041370868683, 'learning_rate': 4.232893019029297e-05, 'epoch': 0.4602641885824223, 'step': 2555500}
INFO:transformers.trainer:{'loss': 3.188382084608078, 'learning_rate': 4.232742929618032e-05, 'epoch': 0.46035424222918075, 'step': 2556000}
INFO:transformers.trainer:{'loss': 3.2343642590045927, 'learning_rate': 4.2325928402067686e-05, 'epoch': 0.4604442958759392, 'step': 2556500}
INFO:transformers.trainer:{'loss': 3.2097695524692536, 'learning_rate': 4.232442750795504e-05, 'epoch': 0.4605343495226977, 'step': 2557000}
INFO:transformers.trainer:{'loss': 3.2288838901519776, 'learning_rate': 4.2322926613842404e-05, 'epoch': 0.46062440316945613, 'step': 2557500}
INFO:transformers.trainer:{'loss': 3.268359350681305, 'learning_rate': 4.2321425719729756e-05, 'epoch': 0.46071445681621453, 'step': 2558000}
INFO:transformers.trainer:{'loss': 3.2138503343462945, 'learning_rate': 4.231992482561712e-05, 'epoch': 0.460804510462973, 'step': 2558500}
INFO:transformers.trainer:{'loss': 3.192131205558777, 'learning_rate': 4.231842393150448e-05, 'epoch': 0.46089456410973145, 'step': 2559000}
INFO:transformers.trainer:{'loss': 3.2052849135398866, 'learning_rate': 4.231692303739184e-05, 'epoch': 0.4609846177564899, 'step': 2559500}
INFO:transformers.trainer:{'loss': 3.136339984178543, 'learning_rate': 4.23154221432792e-05, 'epoch': 0.46107467140324837, 'step': 2560000}
INFO:transformers.trainer:{'loss': 3.223663946866989, 'learning_rate': 4.231392124916656e-05, 'epoch': 0.4611647250500068, 'step': 2560500}
INFO:transformers.trainer:{'loss': 3.1715317964553833, 'learning_rate': 4.231242035505392e-05, 'epoch': 0.46125477869676523, 'step': 2561000}
INFO:transformers.trainer:{'loss': 3.1981013069152833, 'learning_rate': 4.231091946094127e-05, 'epoch': 0.4613448323435237, 'step': 2561500}
INFO:transformers.trainer:{'loss': 3.1867590749263766, 'learning_rate': 4.2309418566828635e-05, 'epoch': 0.46143488599028215, 'step': 2562000}
INFO:transformers.trainer:{'loss': 3.205481338739395, 'learning_rate': 4.230791767271599e-05, 'epoch': 0.46152493963704055, 'step': 2562500}
INFO:transformers.trainer:{'loss': 3.1917848596572878, 'learning_rate': 4.2306416778603353e-05, 'epoch': 0.461614993283799, 'step': 2563000}
INFO:transformers.trainer:{'loss': 3.2048840148448945, 'learning_rate': 4.2304915884490706e-05, 'epoch': 0.4617050469305575, 'step': 2563500}
INFO:transformers.trainer:{'loss': 3.187850984811783, 'learning_rate': 4.230341499037807e-05, 'epoch': 0.46179510057731593, 'step': 2564000}
INFO:transformers.trainer:{'loss': 3.2077371068000793, 'learning_rate': 4.2301914096265424e-05, 'epoch': 0.4618851542240744, 'step': 2564500}
INFO:transformers.trainer:{'loss': 3.18400217962265, 'learning_rate': 4.230041320215279e-05, 'epoch': 0.4619752078708328, 'step': 2565000}
INFO:transformers.trainer:{'loss': 3.197557416677475, 'learning_rate': 4.229891230804014e-05, 'epoch': 0.46206526151759125, 'step': 2565500}
INFO:transformers.trainer:{'loss': 3.1508966782093046, 'learning_rate': 4.229741141392751e-05, 'epoch': 0.4621553151643497, 'step': 2566000}
INFO:transformers.trainer:{'loss': 3.1594878015518186, 'learning_rate': 4.229591051981487e-05, 'epoch': 0.46224536881110817, 'step': 2566500}
INFO:transformers.trainer:{'loss': 3.20787408387661, 'learning_rate': 4.2294409625702226e-05, 'epoch': 0.4623354224578666, 'step': 2567000}
INFO:transformers.trainer:{'loss': 3.2672352018356325, 'learning_rate': 4.2292908731589585e-05, 'epoch': 0.46242547610462503, 'step': 2567500}
INFO:transformers.trainer:{'loss': 3.2512089849710466, 'learning_rate': 4.2291407837476944e-05, 'epoch': 0.4625155297513835, 'step': 2568000}
INFO:transformers.trainer:{'loss': 3.18309637594223, 'learning_rate': 4.22899069433643e-05, 'epoch': 0.46260558339814195, 'step': 2568500}
INFO:transformers.trainer:{'loss': 3.0988968102931977, 'learning_rate': 4.228840604925166e-05, 'epoch': 0.4626956370449004, 'step': 2569000}
INFO:transformers.trainer:{'loss': 3.1850574805736542, 'learning_rate': 4.228690515513902e-05, 'epoch': 0.4627856906916588, 'step': 2569500}
INFO:transformers.trainer:{'loss': 3.227182491540909, 'learning_rate': 4.228540426102638e-05, 'epoch': 0.46287574433841727, 'step': 2570000}
INFO:transformers.trainer:{'loss': 3.1984633560180664, 'learning_rate': 4.228390336691374e-05, 'epoch': 0.46296579798517573, 'step': 2570500}
INFO:transformers.trainer:{'loss': 3.182273335814476, 'learning_rate': 4.22824024728011e-05, 'epoch': 0.4630558516319342, 'step': 2571000}
INFO:transformers.trainer:{'loss': 3.166235863685608, 'learning_rate': 4.228090157868846e-05, 'epoch': 0.46314590527869265, 'step': 2571500}
INFO:transformers.trainer:{'loss': 3.163558989048004, 'learning_rate': 4.2279400684575816e-05, 'epoch': 0.46323595892545105, 'step': 2572000}
INFO:transformers.trainer:{'loss': 3.182946733236313, 'learning_rate': 4.2277899790463175e-05, 'epoch': 0.4633260125722095, 'step': 2572500}
INFO:transformers.trainer:{'loss': 3.185973725795746, 'learning_rate': 4.227639889635054e-05, 'epoch': 0.46341606621896797, 'step': 2573000}
INFO:transformers.trainer:{'loss': 3.190759973168373, 'learning_rate': 4.2274898002237894e-05, 'epoch': 0.46350611986572643, 'step': 2573500}
INFO:transformers.trainer:{'loss': 3.2636675786972047, 'learning_rate': 4.227339710812526e-05, 'epoch': 0.46359617351248483, 'step': 2574000}
INFO:transformers.trainer:{'loss': 3.2066130640506745, 'learning_rate': 4.227189621401261e-05, 'epoch': 0.4636862271592433, 'step': 2574500}
INFO:transformers.trainer:{'loss': 3.205224254369736, 'learning_rate': 4.227039531989998e-05, 'epoch': 0.46377628080600175, 'step': 2575000}
INFO:transformers.trainer:{'loss': 3.1679832273721695, 'learning_rate': 4.226889442578733e-05, 'epoch': 0.4638663344527602, 'step': 2575500}
INFO:transformers.trainer:{'loss': 3.173709522485733, 'learning_rate': 4.2267393531674696e-05, 'epoch': 0.46395638809951867, 'step': 2576000}
INFO:transformers.trainer:{'loss': 3.1769826858043673, 'learning_rate': 4.226589263756205e-05, 'epoch': 0.46404644174627707, 'step': 2576500}
INFO:transformers.trainer:{'loss': 3.1925190372467043, 'learning_rate': 4.2264391743449414e-05, 'epoch': 0.46413649539303553, 'step': 2577000}
INFO:transformers.trainer:{'loss': 3.207450057864189, 'learning_rate': 4.2262890849336766e-05, 'epoch': 0.464226549039794, 'step': 2577500}
INFO:transformers.trainer:{'loss': 3.170104736804962, 'learning_rate': 4.226138995522413e-05, 'epoch': 0.46431660268655245, 'step': 2578000}
INFO:transformers.trainer:{'loss': 3.196346194267273, 'learning_rate': 4.2259889061111484e-05, 'epoch': 0.4644066563333109, 'step': 2578500}
INFO:transformers.trainer:{'loss': 3.251833585739136, 'learning_rate': 4.225838816699885e-05, 'epoch': 0.4644967099800693, 'step': 2579000}
INFO:transformers.trainer:{'loss': 3.226319681406021, 'learning_rate': 4.22568872728862e-05, 'epoch': 0.46458676362682777, 'step': 2579500}
INFO:transformers.trainer:{'loss': 3.226071620941162, 'learning_rate': 4.225538637877357e-05, 'epoch': 0.46467681727358623, 'step': 2580000}
INFO:transformers.trainer:{'loss': 3.225454986333847, 'learning_rate': 4.225388548466093e-05, 'epoch': 0.4647668709203447, 'step': 2580500}
INFO:transformers.trainer:{'loss': 3.204067638874054, 'learning_rate': 4.2252384590548286e-05, 'epoch': 0.4648569245671031, 'step': 2581000}
INFO:transformers.trainer:{'loss': 3.1587437739372253, 'learning_rate': 4.2250883696435645e-05, 'epoch': 0.46494697821386155, 'step': 2581500}
INFO:transformers.trainer:{'loss': 3.198527426958084, 'learning_rate': 4.2249382802323004e-05, 'epoch': 0.46503703186062, 'step': 2582000}
INFO:transformers.trainer:{'loss': 3.264470063686371, 'learning_rate': 4.224788190821036e-05, 'epoch': 0.46512708550737847, 'step': 2582500}
INFO:transformers.trainer:{'loss': 3.1705041778087617, 'learning_rate': 4.224638101409772e-05, 'epoch': 0.4652171391541369, 'step': 2583000}
INFO:transformers.trainer:{'loss': 3.2144866923093796, 'learning_rate': 4.224488011998508e-05, 'epoch': 0.46530719280089533, 'step': 2583500}
INFO:transformers.trainer:{'loss': 3.2002992272377013, 'learning_rate': 4.224337922587244e-05, 'epoch': 0.4653972464476538, 'step': 2584000}
INFO:transformers.trainer:{'loss': 3.2362553247213364, 'learning_rate': 4.22418783317598e-05, 'epoch': 0.46548730009441225, 'step': 2584500}
INFO:transformers.trainer:{'loss': 3.1718912944793702, 'learning_rate': 4.224037743764716e-05, 'epoch': 0.4655773537411707, 'step': 2585000}
INFO:transformers.trainer:{'loss': 3.1883316402435304, 'learning_rate': 4.223887654353452e-05, 'epoch': 0.4656674073879291, 'step': 2585500}
INFO:transformers.trainer:{'loss': 3.199788992166519, 'learning_rate': 4.223737564942187e-05, 'epoch': 0.46575746103468757, 'step': 2586000}
INFO:transformers.trainer:{'loss': 3.172615555047989, 'learning_rate': 4.2235874755309236e-05, 'epoch': 0.46584751468144603, 'step': 2586500}
INFO:transformers.trainer:{'loss': 3.222611846923828, 'learning_rate': 4.2234373861196595e-05, 'epoch': 0.4659375683282045, 'step': 2587000}
INFO:transformers.trainer:{'loss': 3.1413182617425917, 'learning_rate': 4.2232872967083954e-05, 'epoch': 0.46602762197496295, 'step': 2587500}
INFO:transformers.trainer:{'loss': 3.1747191667556764, 'learning_rate': 4.223137207297131e-05, 'epoch': 0.46611767562172135, 'step': 2588000}
INFO:transformers.trainer:{'loss': 3.2239408605098725, 'learning_rate': 4.222987117885867e-05, 'epoch': 0.4662077292684798, 'step': 2588500}
INFO:transformers.trainer:{'loss': 3.1484187729358672, 'learning_rate': 4.222837028474603e-05, 'epoch': 0.46629778291523827, 'step': 2589000}
INFO:transformers.trainer:{'loss': 3.156366736650467, 'learning_rate': 4.222686939063339e-05, 'epoch': 0.4663878365619967, 'step': 2589500}
INFO:transformers.trainer:{'loss': 3.2351067733764647, 'learning_rate': 4.222536849652075e-05, 'epoch': 0.4664778902087552, 'step': 2590000}
INFO:transformers.trainer:{'loss': 3.246776649594307, 'learning_rate': 4.222386760240811e-05, 'epoch': 0.4665679438555136, 'step': 2590500}
INFO:transformers.trainer:{'loss': 3.2291877752542497, 'learning_rate': 4.222236670829547e-05, 'epoch': 0.46665799750227205, 'step': 2591000}
INFO:transformers.trainer:{'loss': 3.1805762506723405, 'learning_rate': 4.2220865814182826e-05, 'epoch': 0.4667480511490305, 'step': 2591500}
INFO:transformers.trainer:{'loss': 3.207024641036987, 'learning_rate': 4.2219364920070185e-05, 'epoch': 0.46683810479578897, 'step': 2592000}
INFO:transformers.trainer:{'loss': 3.2039881361722946, 'learning_rate': 4.2217864025957544e-05, 'epoch': 0.46692815844254737, 'step': 2592500}
INFO:transformers.trainer:{'loss': 3.203452019453049, 'learning_rate': 4.22163631318449e-05, 'epoch': 0.46701821208930583, 'step': 2593000}
INFO:transformers.trainer:{'loss': 3.1894061262607574, 'learning_rate': 4.221486223773226e-05, 'epoch': 0.4671082657360643, 'step': 2593500}
INFO:transformers.trainer:{'loss': 3.1413643279075623, 'learning_rate': 4.221336134361962e-05, 'epoch': 0.46719831938282275, 'step': 2594000}
INFO:transformers.trainer:{'loss': 3.155131655454636, 'learning_rate': 4.221186044950699e-05, 'epoch': 0.4672883730295812, 'step': 2594500}
INFO:transformers.trainer:{'loss': 3.1281203536987303, 'learning_rate': 4.221035955539434e-05, 'epoch': 0.4673784266763396, 'step': 2595000}
INFO:transformers.trainer:{'loss': 3.16902672624588, 'learning_rate': 4.2208858661281705e-05, 'epoch': 0.46746848032309807, 'step': 2595500}
INFO:transformers.trainer:{'loss': 3.2040387325286863, 'learning_rate': 4.220735776716906e-05, 'epoch': 0.4675585339698565, 'step': 2596000}
INFO:transformers.trainer:{'loss': 3.1487369812726973, 'learning_rate': 4.220585687305642e-05, 'epoch': 0.467648587616615, 'step': 2596500}
INFO:transformers.trainer:{'loss': 3.202773946523666, 'learning_rate': 4.2204355978943776e-05, 'epoch': 0.4677386412633734, 'step': 2597000}
INFO:transformers.trainer:{'loss': 3.200536671757698, 'learning_rate': 4.220285508483114e-05, 'epoch': 0.46782869491013185, 'step': 2597500}
INFO:transformers.trainer:{'loss': 3.1457106865644455, 'learning_rate': 4.2201354190718494e-05, 'epoch': 0.4679187485568903, 'step': 2598000}
INFO:transformers.trainer:{'loss': 3.1555772542953493, 'learning_rate': 4.219985329660586e-05, 'epoch': 0.46800880220364877, 'step': 2598500}
INFO:transformers.trainer:{'loss': 3.2097437493801118, 'learning_rate': 4.219835240249321e-05, 'epoch': 0.4680988558504072, 'step': 2599000}
INFO:transformers.trainer:{'loss': 3.1290252702236176, 'learning_rate': 4.219685150838058e-05, 'epoch': 0.46818890949716563, 'step': 2599500}
INFO:transformers.trainer:{'loss': 3.205246414899826, 'learning_rate': 4.219535061426793e-05, 'epoch': 0.4682789631439241, 'step': 2600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.185902792215347, 'learning_rate': 4.2193849720155296e-05, 'epoch': 0.46836901679068255, 'step': 2600500}
INFO:transformers.trainer:{'loss': 3.183954764962196, 'learning_rate': 4.2192348826042655e-05, 'epoch': 0.468459070437441, 'step': 2601000}
INFO:transformers.trainer:{'loss': 3.2049685389995575, 'learning_rate': 4.2190847931930014e-05, 'epoch': 0.46854912408419946, 'step': 2601500}
INFO:transformers.trainer:{'loss': 3.158607024669647, 'learning_rate': 4.218934703781737e-05, 'epoch': 0.46863917773095787, 'step': 2602000}
INFO:transformers.trainer:{'loss': 3.1436185169219972, 'learning_rate': 4.218784614370473e-05, 'epoch': 0.4687292313777163, 'step': 2602500}
INFO:transformers.trainer:{'loss': 3.178534529924393, 'learning_rate': 4.218634524959209e-05, 'epoch': 0.4688192850244748, 'step': 2603000}
INFO:transformers.trainer:{'loss': 3.1025212440490724, 'learning_rate': 4.218484435547945e-05, 'epoch': 0.46890933867123324, 'step': 2603500}
INFO:transformers.trainer:{'loss': 3.213906632900238, 'learning_rate': 4.218334346136681e-05, 'epoch': 0.46899939231799165, 'step': 2604000}
INFO:transformers.trainer:{'loss': 3.1374900362491607, 'learning_rate': 4.218184256725417e-05, 'epoch': 0.4690894459647501, 'step': 2604500}
INFO:transformers.trainer:{'loss': 3.230387256860733, 'learning_rate': 4.218034167314153e-05, 'epoch': 0.46917949961150857, 'step': 2605000}
INFO:transformers.trainer:{'loss': 3.144097215652466, 'learning_rate': 4.2178840779028886e-05, 'epoch': 0.469269553258267, 'step': 2605500}
INFO:transformers.trainer:{'loss': 3.14086239528656, 'learning_rate': 4.2177339884916245e-05, 'epoch': 0.4693596069050255, 'step': 2606000}
INFO:transformers.trainer:{'loss': 3.152302531003952, 'learning_rate': 4.2175838990803604e-05, 'epoch': 0.4694496605517839, 'step': 2606500}
INFO:transformers.trainer:{'loss': 3.1883971523046495, 'learning_rate': 4.2174338096690963e-05, 'epoch': 0.46953971419854235, 'step': 2607000}
INFO:transformers.trainer:{'loss': 3.2121073188781737, 'learning_rate': 4.217283720257832e-05, 'epoch': 0.4696297678453008, 'step': 2607500}
INFO:transformers.trainer:{'loss': 3.192180356502533, 'learning_rate': 4.217133630846568e-05, 'epoch': 0.46971982149205926, 'step': 2608000}
INFO:transformers.trainer:{'loss': 3.187003367185593, 'learning_rate': 4.216983541435304e-05, 'epoch': 0.4698098751388177, 'step': 2608500}
INFO:transformers.trainer:{'loss': 3.2268942186832428, 'learning_rate': 4.21683345202404e-05, 'epoch': 0.4698999287855761, 'step': 2609000}
INFO:transformers.trainer:{'loss': 3.1758334658145904, 'learning_rate': 4.216683362612776e-05, 'epoch': 0.4699899824323346, 'step': 2609500}
INFO:transformers.trainer:{'loss': 3.2315224096775057, 'learning_rate': 4.216533273201512e-05, 'epoch': 0.47008003607909304, 'step': 2610000}
INFO:transformers.trainer:{'loss': 3.1718671910762786, 'learning_rate': 4.216383183790248e-05, 'epoch': 0.4701700897258515, 'step': 2610500}
INFO:transformers.trainer:{'loss': 3.1544062497615815, 'learning_rate': 4.2162330943789836e-05, 'epoch': 0.4702601433726099, 'step': 2611000}
INFO:transformers.trainer:{'loss': 3.1676419084072114, 'learning_rate': 4.2160830049677195e-05, 'epoch': 0.47035019701936837, 'step': 2611500}
INFO:transformers.trainer:{'loss': 3.1790119075775145, 'learning_rate': 4.2159329155564554e-05, 'epoch': 0.4704402506661268, 'step': 2612000}
INFO:transformers.trainer:{'loss': 3.128198357462883, 'learning_rate': 4.215782826145191e-05, 'epoch': 0.4705303043128853, 'step': 2612500}
INFO:transformers.trainer:{'loss': 3.1823676970005037, 'learning_rate': 4.215632736733927e-05, 'epoch': 0.47062035795964374, 'step': 2613000}
INFO:transformers.trainer:{'loss': 3.1283287398815154, 'learning_rate': 4.215482647322663e-05, 'epoch': 0.47071041160640215, 'step': 2613500}
INFO:transformers.trainer:{'loss': 3.1374726107120514, 'learning_rate': 4.215332557911399e-05, 'epoch': 0.4708004652531606, 'step': 2614000}
INFO:transformers.trainer:{'loss': 3.1992469052076338, 'learning_rate': 4.215182468500135e-05, 'epoch': 0.47089051889991906, 'step': 2614500}
INFO:transformers.trainer:{'loss': 3.181513101577759, 'learning_rate': 4.2150323790888715e-05, 'epoch': 0.4709805725466775, 'step': 2615000}
INFO:transformers.trainer:{'loss': 3.190437134385109, 'learning_rate': 4.214882289677607e-05, 'epoch': 0.4710706261934359, 'step': 2615500}
INFO:transformers.trainer:{'loss': 3.1995591707229614, 'learning_rate': 4.214732200266343e-05, 'epoch': 0.4711606798401944, 'step': 2616000}
INFO:transformers.trainer:{'loss': 3.187809130549431, 'learning_rate': 4.2145821108550785e-05, 'epoch': 0.47125073348695284, 'step': 2616500}
INFO:transformers.trainer:{'loss': 3.2283528733253477, 'learning_rate': 4.214432021443815e-05, 'epoch': 0.4713407871337113, 'step': 2617000}
INFO:transformers.trainer:{'loss': 3.1868237257003784, 'learning_rate': 4.2142819320325503e-05, 'epoch': 0.47143084078046976, 'step': 2617500}
INFO:transformers.trainer:{'loss': 3.1531362075805665, 'learning_rate': 4.214131842621287e-05, 'epoch': 0.47152089442722817, 'step': 2618000}
INFO:transformers.trainer:{'loss': 3.159997234582901, 'learning_rate': 4.213981753210022e-05, 'epoch': 0.4716109480739866, 'step': 2618500}
INFO:transformers.trainer:{'loss': 3.2379796907901763, 'learning_rate': 4.213831663798759e-05, 'epoch': 0.4717010017207451, 'step': 2619000}
INFO:transformers.trainer:{'loss': 3.2067081334590912, 'learning_rate': 4.213681574387494e-05, 'epoch': 0.47179105536750354, 'step': 2619500}
INFO:transformers.trainer:{'loss': 3.2014708876609803, 'learning_rate': 4.2135314849762305e-05, 'epoch': 0.471881109014262, 'step': 2620000}
INFO:transformers.trainer:{'loss': 3.1632076394557953, 'learning_rate': 4.213381395564966e-05, 'epoch': 0.4719711626610204, 'step': 2620500}
INFO:transformers.trainer:{'loss': 3.2774277329444885, 'learning_rate': 4.2132313061537024e-05, 'epoch': 0.47206121630777886, 'step': 2621000}
INFO:transformers.trainer:{'loss': 3.203242725610733, 'learning_rate': 4.213081216742438e-05, 'epoch': 0.4721512699545373, 'step': 2621500}
INFO:transformers.trainer:{'loss': 3.1938345602750777, 'learning_rate': 4.212931127331174e-05, 'epoch': 0.4722413236012958, 'step': 2622000}
INFO:transformers.trainer:{'loss': 3.1602265832424163, 'learning_rate': 4.21278103791991e-05, 'epoch': 0.4723313772480542, 'step': 2622500}
INFO:transformers.trainer:{'loss': 3.2016549270153045, 'learning_rate': 4.212630948508646e-05, 'epoch': 0.47242143089481264, 'step': 2623000}
INFO:transformers.trainer:{'loss': 3.1855238666534422, 'learning_rate': 4.212480859097382e-05, 'epoch': 0.4725114845415711, 'step': 2623500}
INFO:transformers.trainer:{'loss': 3.147681527853012, 'learning_rate': 4.212330769686118e-05, 'epoch': 0.47260153818832956, 'step': 2624000}
INFO:transformers.trainer:{'loss': 3.207670934677124, 'learning_rate': 4.212180680274854e-05, 'epoch': 0.472691591835088, 'step': 2624500}
INFO:transformers.trainer:{'loss': 3.19359458398819, 'learning_rate': 4.2120305908635896e-05, 'epoch': 0.4727816454818464, 'step': 2625000}
INFO:transformers.trainer:{'loss': 3.191514441251755, 'learning_rate': 4.2118805014523255e-05, 'epoch': 0.4728716991286049, 'step': 2625500}
INFO:transformers.trainer:{'loss': 3.2190537374019623, 'learning_rate': 4.2117304120410614e-05, 'epoch': 0.47296175277536334, 'step': 2626000}
INFO:transformers.trainer:{'loss': 3.2258670746088027, 'learning_rate': 4.211580322629797e-05, 'epoch': 0.4730518064221218, 'step': 2626500}
INFO:transformers.trainer:{'loss': 3.1391022291183472, 'learning_rate': 4.211430233218533e-05, 'epoch': 0.47314186006888026, 'step': 2627000}
INFO:transformers.trainer:{'loss': 3.1750440399646758, 'learning_rate': 4.211280143807269e-05, 'epoch': 0.47323191371563866, 'step': 2627500}
INFO:transformers.trainer:{'loss': 3.2087732629776, 'learning_rate': 4.211130054396005e-05, 'epoch': 0.4733219673623971, 'step': 2628000}
INFO:transformers.trainer:{'loss': 3.1814951716661453, 'learning_rate': 4.210979964984741e-05, 'epoch': 0.4734120210091556, 'step': 2628500}
INFO:transformers.trainer:{'loss': 3.2274143068790435, 'learning_rate': 4.210829875573477e-05, 'epoch': 0.47350207465591404, 'step': 2629000}
INFO:transformers.trainer:{'loss': 3.156211674451828, 'learning_rate': 4.210679786162213e-05, 'epoch': 0.47359212830267244, 'step': 2629500}
INFO:transformers.trainer:{'loss': 3.2036756167411804, 'learning_rate': 4.2105296967509486e-05, 'epoch': 0.4736821819494309, 'step': 2630000}
INFO:transformers.trainer:{'loss': 3.178799899101257, 'learning_rate': 4.2103796073396846e-05, 'epoch': 0.47377223559618936, 'step': 2630500}
INFO:transformers.trainer:{'loss': 3.156476736545563, 'learning_rate': 4.2102295179284205e-05, 'epoch': 0.4738622892429478, 'step': 2631000}
INFO:transformers.trainer:{'loss': 3.1219950890541077, 'learning_rate': 4.2100794285171564e-05, 'epoch': 0.4739523428897063, 'step': 2631500}
INFO:transformers.trainer:{'loss': 3.2309410161972045, 'learning_rate': 4.209929339105892e-05, 'epoch': 0.4740423965364647, 'step': 2632000}
INFO:transformers.trainer:{'loss': 3.2397276105880737, 'learning_rate': 4.209779249694628e-05, 'epoch': 0.47413245018322314, 'step': 2632500}
INFO:transformers.trainer:{'loss': 3.1825543842315676, 'learning_rate': 4.209629160283364e-05, 'epoch': 0.4742225038299816, 'step': 2633000}
INFO:transformers.trainer:{'loss': 3.2043195688724517, 'learning_rate': 4.2094790708721e-05, 'epoch': 0.47431255747674006, 'step': 2633500}
INFO:transformers.trainer:{'loss': 3.171990286588669, 'learning_rate': 4.209328981460836e-05, 'epoch': 0.47440261112349846, 'step': 2634000}
INFO:transformers.trainer:{'loss': 3.1634933576583864, 'learning_rate': 4.209178892049572e-05, 'epoch': 0.4744926647702569, 'step': 2634500}
INFO:transformers.trainer:{'loss': 3.1511459159851074, 'learning_rate': 4.209028802638308e-05, 'epoch': 0.4745827184170154, 'step': 2635000}
INFO:transformers.trainer:{'loss': 3.1980308690071104, 'learning_rate': 4.208878713227044e-05, 'epoch': 0.47467277206377384, 'step': 2635500}
INFO:transformers.trainer:{'loss': 3.14958462035656, 'learning_rate': 4.2087286238157795e-05, 'epoch': 0.4747628257105323, 'step': 2636000}
INFO:transformers.trainer:{'loss': 3.138436973333359, 'learning_rate': 4.208578534404516e-05, 'epoch': 0.4748528793572907, 'step': 2636500}
INFO:transformers.trainer:{'loss': 3.213518949508667, 'learning_rate': 4.208428444993251e-05, 'epoch': 0.47494293300404916, 'step': 2637000}
INFO:transformers.trainer:{'loss': 3.197499272584915, 'learning_rate': 4.208278355581988e-05, 'epoch': 0.4750329866508076, 'step': 2637500}
INFO:transformers.trainer:{'loss': 3.190158447742462, 'learning_rate': 4.208128266170723e-05, 'epoch': 0.4751230402975661, 'step': 2638000}
INFO:transformers.trainer:{'loss': 3.186624446153641, 'learning_rate': 4.20797817675946e-05, 'epoch': 0.47521309394432454, 'step': 2638500}
INFO:transformers.trainer:{'loss': 3.165946848154068, 'learning_rate': 4.207828087348195e-05, 'epoch': 0.47530314759108294, 'step': 2639000}
INFO:transformers.trainer:{'loss': 3.1896557453870775, 'learning_rate': 4.2076779979369315e-05, 'epoch': 0.4753932012378414, 'step': 2639500}
INFO:transformers.trainer:{'loss': 3.1920851867198943, 'learning_rate': 4.207527908525667e-05, 'epoch': 0.47548325488459986, 'step': 2640000}
INFO:transformers.trainer:{'loss': 3.174272105693817, 'learning_rate': 4.207377819114403e-05, 'epoch': 0.4755733085313583, 'step': 2640500}
INFO:transformers.trainer:{'loss': 3.2267632106542585, 'learning_rate': 4.2072277297031386e-05, 'epoch': 0.4756633621781167, 'step': 2641000}
INFO:transformers.trainer:{'loss': 3.171988332748413, 'learning_rate': 4.207077640291875e-05, 'epoch': 0.4757534158248752, 'step': 2641500}
INFO:transformers.trainer:{'loss': 3.165758302092552, 'learning_rate': 4.2069275508806104e-05, 'epoch': 0.47584346947163364, 'step': 2642000}
INFO:transformers.trainer:{'loss': 3.209630228757858, 'learning_rate': 4.206777461469347e-05, 'epoch': 0.4759335231183921, 'step': 2642500}
INFO:transformers.trainer:{'loss': 3.241453971862793, 'learning_rate': 4.206627372058083e-05, 'epoch': 0.47602357676515056, 'step': 2643000}
INFO:transformers.trainer:{'loss': 3.17566019153595, 'learning_rate': 4.206477282646819e-05, 'epoch': 0.47611363041190896, 'step': 2643500}
INFO:transformers.trainer:{'loss': 3.2164035964012148, 'learning_rate': 4.206327193235555e-05, 'epoch': 0.4762036840586674, 'step': 2644000}
INFO:transformers.trainer:{'loss': 3.1764303804636, 'learning_rate': 4.2061771038242906e-05, 'epoch': 0.4762937377054259, 'step': 2644500}
INFO:transformers.trainer:{'loss': 3.2141029574871065, 'learning_rate': 4.2060270144130265e-05, 'epoch': 0.47638379135218434, 'step': 2645000}
INFO:transformers.trainer:{'loss': 3.2211457839012145, 'learning_rate': 4.2058769250017624e-05, 'epoch': 0.4764738449989428, 'step': 2645500}
INFO:transformers.trainer:{'loss': 3.1511003918647766, 'learning_rate': 4.205726835590498e-05, 'epoch': 0.4765638986457012, 'step': 2646000}
INFO:transformers.trainer:{'loss': 3.242518728733063, 'learning_rate': 4.205576746179234e-05, 'epoch': 0.47665395229245966, 'step': 2646500}
INFO:transformers.trainer:{'loss': 3.1707128894329073, 'learning_rate': 4.20542665676797e-05, 'epoch': 0.4767440059392181, 'step': 2647000}
INFO:transformers.trainer:{'loss': 3.1995420844554903, 'learning_rate': 4.205276567356706e-05, 'epoch': 0.4768340595859766, 'step': 2647500}
INFO:transformers.trainer:{'loss': 3.170328417420387, 'learning_rate': 4.205126477945442e-05, 'epoch': 0.476924113232735, 'step': 2648000}
INFO:transformers.trainer:{'loss': 3.209218456029892, 'learning_rate': 4.204976388534178e-05, 'epoch': 0.47701416687949344, 'step': 2648500}
INFO:transformers.trainer:{'loss': 3.144888590335846, 'learning_rate': 4.204826299122914e-05, 'epoch': 0.4771042205262519, 'step': 2649000}
INFO:transformers.trainer:{'loss': 3.2138117067813874, 'learning_rate': 4.2046762097116496e-05, 'epoch': 0.47719427417301036, 'step': 2649500}
INFO:transformers.trainer:{'loss': 3.1324172706604005, 'learning_rate': 4.2045261203003855e-05, 'epoch': 0.4772843278197688, 'step': 2650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2150626435279848, 'learning_rate': 4.2043760308891214e-05, 'epoch': 0.4773743814665272, 'step': 2650500}
INFO:transformers.trainer:{'loss': 3.188227621793747, 'learning_rate': 4.204225941477857e-05, 'epoch': 0.4774644351132857, 'step': 2651000}
INFO:transformers.trainer:{'loss': 3.1158836498260496, 'learning_rate': 4.204075852066593e-05, 'epoch': 0.47755448876004414, 'step': 2651500}
INFO:transformers.trainer:{'loss': 3.221396814107895, 'learning_rate': 4.203925762655329e-05, 'epoch': 0.4776445424068026, 'step': 2652000}
INFO:transformers.trainer:{'loss': 3.1661229407787324, 'learning_rate': 4.203775673244065e-05, 'epoch': 0.477734596053561, 'step': 2652500}
INFO:transformers.trainer:{'loss': 3.187283910870552, 'learning_rate': 4.203625583832801e-05, 'epoch': 0.47782464970031946, 'step': 2653000}
INFO:transformers.trainer:{'loss': 3.187847937822342, 'learning_rate': 4.203475494421537e-05, 'epoch': 0.4779147033470779, 'step': 2653500}
INFO:transformers.trainer:{'loss': 3.1824566662311553, 'learning_rate': 4.203325405010273e-05, 'epoch': 0.4780047569938364, 'step': 2654000}
INFO:transformers.trainer:{'loss': 3.226613657593727, 'learning_rate': 4.203175315599009e-05, 'epoch': 0.47809481064059484, 'step': 2654500}
INFO:transformers.trainer:{'loss': 3.1811644282341005, 'learning_rate': 4.2030252261877446e-05, 'epoch': 0.47818486428735324, 'step': 2655000}
INFO:transformers.trainer:{'loss': 3.176667377948761, 'learning_rate': 4.2028751367764805e-05, 'epoch': 0.4782749179341117, 'step': 2655500}
INFO:transformers.trainer:{'loss': 3.183240178346634, 'learning_rate': 4.202725047365217e-05, 'epoch': 0.47836497158087016, 'step': 2656000}
INFO:transformers.trainer:{'loss': 3.2070058586597443, 'learning_rate': 4.202574957953952e-05, 'epoch': 0.4784550252276286, 'step': 2656500}
INFO:transformers.trainer:{'loss': 3.2730604183673857, 'learning_rate': 4.202424868542689e-05, 'epoch': 0.4785450788743871, 'step': 2657000}
INFO:transformers.trainer:{'loss': 3.210148682355881, 'learning_rate': 4.202274779131424e-05, 'epoch': 0.4786351325211455, 'step': 2657500}
INFO:transformers.trainer:{'loss': 3.247789548635483, 'learning_rate': 4.202124689720161e-05, 'epoch': 0.47872518616790394, 'step': 2658000}
INFO:transformers.trainer:{'loss': 3.2257866843938827, 'learning_rate': 4.201974600308896e-05, 'epoch': 0.4788152398146624, 'step': 2658500}
INFO:transformers.trainer:{'loss': 3.2268898861408233, 'learning_rate': 4.2018245108976325e-05, 'epoch': 0.47890529346142086, 'step': 2659000}
INFO:transformers.trainer:{'loss': 3.2032563269138334, 'learning_rate': 4.201674421486368e-05, 'epoch': 0.47899534710817926, 'step': 2659500}
INFO:transformers.trainer:{'loss': 3.2680199180841445, 'learning_rate': 4.201524332075104e-05, 'epoch': 0.4790854007549377, 'step': 2660000}
INFO:transformers.trainer:{'loss': 3.227303016424179, 'learning_rate': 4.2013742426638395e-05, 'epoch': 0.4791754544016962, 'step': 2660500}
INFO:transformers.trainer:{'loss': 3.217343404054642, 'learning_rate': 4.201224153252576e-05, 'epoch': 0.47926550804845464, 'step': 2661000}
INFO:transformers.trainer:{'loss': 3.211813904285431, 'learning_rate': 4.2010740638413113e-05, 'epoch': 0.4793555616952131, 'step': 2661500}
INFO:transformers.trainer:{'loss': 3.2521389560699463, 'learning_rate': 4.200923974430048e-05, 'epoch': 0.4794456153419715, 'step': 2662000}
INFO:transformers.trainer:{'loss': 3.1860398368835448, 'learning_rate': 4.200773885018783e-05, 'epoch': 0.47953566898872996, 'step': 2662500}
INFO:transformers.trainer:{'loss': 3.1683313553333283, 'learning_rate': 4.20062379560752e-05, 'epoch': 0.4796257226354884, 'step': 2663000}
INFO:transformers.trainer:{'loss': 3.225210562944412, 'learning_rate': 4.2004737061962556e-05, 'epoch': 0.4797157762822469, 'step': 2663500}
INFO:transformers.trainer:{'loss': 3.201892324447632, 'learning_rate': 4.2003236167849915e-05, 'epoch': 0.47980582992900533, 'step': 2664000}
INFO:transformers.trainer:{'loss': 3.2738669979572297, 'learning_rate': 4.2001735273737274e-05, 'epoch': 0.47989588357576374, 'step': 2664500}
INFO:transformers.trainer:{'loss': 3.253839180231094, 'learning_rate': 4.2000234379624634e-05, 'epoch': 0.4799859372225222, 'step': 2665000}
INFO:transformers.trainer:{'loss': 3.2164904839992525, 'learning_rate': 4.199873348551199e-05, 'epoch': 0.48007599086928066, 'step': 2665500}
INFO:transformers.trainer:{'loss': 3.1561764734983444, 'learning_rate': 4.199723259139935e-05, 'epoch': 0.4801660445160391, 'step': 2666000}
INFO:transformers.trainer:{'loss': 3.184988156557083, 'learning_rate': 4.199573169728671e-05, 'epoch': 0.4802560981627975, 'step': 2666500}
INFO:transformers.trainer:{'loss': 3.1934234582185743, 'learning_rate': 4.199423080317407e-05, 'epoch': 0.480346151809556, 'step': 2667000}
INFO:transformers.trainer:{'loss': 3.25306201004982, 'learning_rate': 4.199272990906143e-05, 'epoch': 0.48043620545631444, 'step': 2667500}
INFO:transformers.trainer:{'loss': 3.2007853734493255, 'learning_rate': 4.199122901494879e-05, 'epoch': 0.4805262591030729, 'step': 2668000}
INFO:transformers.trainer:{'loss': 3.2059287402629852, 'learning_rate': 4.198972812083615e-05, 'epoch': 0.48061631274983135, 'step': 2668500}
INFO:transformers.trainer:{'loss': 3.2143836559057237, 'learning_rate': 4.1988227226723506e-05, 'epoch': 0.48070636639658976, 'step': 2669000}
INFO:transformers.trainer:{'loss': 3.1879562108516692, 'learning_rate': 4.1986726332610865e-05, 'epoch': 0.4807964200433482, 'step': 2669500}
INFO:transformers.trainer:{'loss': 3.2031344027519224, 'learning_rate': 4.1985225438498224e-05, 'epoch': 0.4808864736901067, 'step': 2670000}
INFO:transformers.trainer:{'loss': 3.176619705438614, 'learning_rate': 4.198372454438558e-05, 'epoch': 0.48097652733686513, 'step': 2670500}
INFO:transformers.trainer:{'loss': 3.2783068132400515, 'learning_rate': 4.198222365027294e-05, 'epoch': 0.48106658098362354, 'step': 2671000}
INFO:transformers.trainer:{'loss': 3.183771013021469, 'learning_rate': 4.19807227561603e-05, 'epoch': 0.481156634630382, 'step': 2671500}
INFO:transformers.trainer:{'loss': 3.198413102388382, 'learning_rate': 4.197922186204766e-05, 'epoch': 0.48124668827714046, 'step': 2672000}
INFO:transformers.trainer:{'loss': 3.1789485491514204, 'learning_rate': 4.197772096793502e-05, 'epoch': 0.4813367419238989, 'step': 2672500}
INFO:transformers.trainer:{'loss': 3.185527149677277, 'learning_rate': 4.197622007382238e-05, 'epoch': 0.4814267955706574, 'step': 2673000}
INFO:transformers.trainer:{'loss': 3.226139542579651, 'learning_rate': 4.197471917970974e-05, 'epoch': 0.4815168492174158, 'step': 2673500}
INFO:transformers.trainer:{'loss': 3.2294673713445663, 'learning_rate': 4.1973218285597096e-05, 'epoch': 0.48160690286417424, 'step': 2674000}
INFO:transformers.trainer:{'loss': 3.20097707259655, 'learning_rate': 4.1971717391484455e-05, 'epoch': 0.4816969565109327, 'step': 2674500}
INFO:transformers.trainer:{'loss': 3.2351118342876433, 'learning_rate': 4.1970216497371815e-05, 'epoch': 0.48178701015769115, 'step': 2675000}
INFO:transformers.trainer:{'loss': 3.234713556051254, 'learning_rate': 4.1968715603259174e-05, 'epoch': 0.4818770638044496, 'step': 2675500}
INFO:transformers.trainer:{'loss': 3.173189583301544, 'learning_rate': 4.196721470914653e-05, 'epoch': 0.481967117451208, 'step': 2676000}
INFO:transformers.trainer:{'loss': 3.176879684627056, 'learning_rate': 4.196571381503389e-05, 'epoch': 0.4820571710979665, 'step': 2676500}
INFO:transformers.trainer:{'loss': 3.2200780301094056, 'learning_rate': 4.196421292092125e-05, 'epoch': 0.48214722474472493, 'step': 2677000}
INFO:transformers.trainer:{'loss': 3.199158545732498, 'learning_rate': 4.1962712026808617e-05, 'epoch': 0.4822372783914834, 'step': 2677500}
INFO:transformers.trainer:{'loss': 3.2149496417045595, 'learning_rate': 4.196121113269597e-05, 'epoch': 0.4823273320382418, 'step': 2678000}
INFO:transformers.trainer:{'loss': 3.1658605372905733, 'learning_rate': 4.1959710238583335e-05, 'epoch': 0.48241738568500026, 'step': 2678500}
INFO:transformers.trainer:{'loss': 3.200155483841896, 'learning_rate': 4.195820934447069e-05, 'epoch': 0.4825074393317587, 'step': 2679000}
INFO:transformers.trainer:{'loss': 3.1611047575473785, 'learning_rate': 4.195670845035805e-05, 'epoch': 0.4825974929785172, 'step': 2679500}
INFO:transformers.trainer:{'loss': 3.148185991168022, 'learning_rate': 4.1955207556245405e-05, 'epoch': 0.48268754662527563, 'step': 2680000}
INFO:transformers.trainer:{'loss': 3.2097351610660554, 'learning_rate': 4.195370666213277e-05, 'epoch': 0.48277760027203404, 'step': 2680500}
INFO:transformers.trainer:{'loss': 3.205338224411011, 'learning_rate': 4.195220576802012e-05, 'epoch': 0.4828676539187925, 'step': 2681000}
INFO:transformers.trainer:{'loss': 3.2185526678562164, 'learning_rate': 4.195070487390749e-05, 'epoch': 0.48295770756555095, 'step': 2681500}
INFO:transformers.trainer:{'loss': 3.21602925658226, 'learning_rate': 4.194920397979484e-05, 'epoch': 0.4830477612123094, 'step': 2682000}
INFO:transformers.trainer:{'loss': 3.194739105463028, 'learning_rate': 4.194770308568221e-05, 'epoch': 0.48313781485906787, 'step': 2682500}
INFO:transformers.trainer:{'loss': 3.191241629362106, 'learning_rate': 4.194620219156956e-05, 'epoch': 0.4832278685058263, 'step': 2683000}
INFO:transformers.trainer:{'loss': 3.2499690358638764, 'learning_rate': 4.1944701297456925e-05, 'epoch': 0.48331792215258473, 'step': 2683500}
INFO:transformers.trainer:{'loss': 3.2231786135435105, 'learning_rate': 4.1943200403344284e-05, 'epoch': 0.4834079757993432, 'step': 2684000}
INFO:transformers.trainer:{'loss': 3.1668630912303923, 'learning_rate': 4.194169950923164e-05, 'epoch': 0.48349802944610165, 'step': 2684500}
INFO:transformers.trainer:{'loss': 3.195128139138222, 'learning_rate': 4.1940198615119e-05, 'epoch': 0.48358808309286005, 'step': 2685000}
INFO:transformers.trainer:{'loss': 3.2371997997760773, 'learning_rate': 4.193869772100636e-05, 'epoch': 0.4836781367396185, 'step': 2685500}
INFO:transformers.trainer:{'loss': 3.189533981561661, 'learning_rate': 4.193719682689372e-05, 'epoch': 0.483768190386377, 'step': 2686000}
INFO:transformers.trainer:{'loss': 3.195784476995468, 'learning_rate': 4.193569593278108e-05, 'epoch': 0.48385824403313543, 'step': 2686500}
INFO:transformers.trainer:{'loss': 3.194799950003624, 'learning_rate': 4.193419503866844e-05, 'epoch': 0.4839482976798939, 'step': 2687000}
INFO:transformers.trainer:{'loss': 3.2132951059341432, 'learning_rate': 4.19326941445558e-05, 'epoch': 0.4840383513266523, 'step': 2687500}
INFO:transformers.trainer:{'loss': 3.0992027757167815, 'learning_rate': 4.193119325044316e-05, 'epoch': 0.48412840497341075, 'step': 2688000}
INFO:transformers.trainer:{'loss': 3.189251892566681, 'learning_rate': 4.1929692356330516e-05, 'epoch': 0.4842184586201692, 'step': 2688500}
INFO:transformers.trainer:{'loss': 3.184187759399414, 'learning_rate': 4.1928191462217875e-05, 'epoch': 0.48430851226692767, 'step': 2689000}
INFO:transformers.trainer:{'loss': 3.1541926444768906, 'learning_rate': 4.1926690568105234e-05, 'epoch': 0.4843985659136861, 'step': 2689500}
INFO:transformers.trainer:{'loss': 3.1687942526340485, 'learning_rate': 4.192518967399259e-05, 'epoch': 0.48448861956044453, 'step': 2690000}
INFO:transformers.trainer:{'loss': 3.2080321247577666, 'learning_rate': 4.192368877987995e-05, 'epoch': 0.484578673207203, 'step': 2690500}
INFO:transformers.trainer:{'loss': 3.227102956533432, 'learning_rate': 4.192218788576731e-05, 'epoch': 0.48466872685396145, 'step': 2691000}
INFO:transformers.trainer:{'loss': 3.171668388605118, 'learning_rate': 4.192068699165467e-05, 'epoch': 0.4847587805007199, 'step': 2691500}
INFO:transformers.trainer:{'loss': 3.1410803649425505, 'learning_rate': 4.191918609754203e-05, 'epoch': 0.4848488341474783, 'step': 2692000}
INFO:transformers.trainer:{'loss': 3.138335709810257, 'learning_rate': 4.191768520342939e-05, 'epoch': 0.4849388877942368, 'step': 2692500}
INFO:transformers.trainer:{'loss': 3.1911325483322144, 'learning_rate': 4.191618430931675e-05, 'epoch': 0.48502894144099523, 'step': 2693000}
INFO:transformers.trainer:{'loss': 3.204294913768768, 'learning_rate': 4.1914683415204106e-05, 'epoch': 0.4851189950877537, 'step': 2693500}
INFO:transformers.trainer:{'loss': 3.1745354762077334, 'learning_rate': 4.1913182521091465e-05, 'epoch': 0.48520904873451215, 'step': 2694000}
INFO:transformers.trainer:{'loss': 3.175161689519882, 'learning_rate': 4.1911681626978824e-05, 'epoch': 0.48529910238127055, 'step': 2694500}
INFO:transformers.trainer:{'loss': 3.177364889621735, 'learning_rate': 4.191018073286618e-05, 'epoch': 0.485389156028029, 'step': 2695000}
INFO:transformers.trainer:{'loss': 3.231540580034256, 'learning_rate': 4.190867983875354e-05, 'epoch': 0.48547920967478747, 'step': 2695500}
INFO:transformers.trainer:{'loss': 3.164468702316284, 'learning_rate': 4.19071789446409e-05, 'epoch': 0.48556926332154593, 'step': 2696000}
INFO:transformers.trainer:{'loss': 3.194395633816719, 'learning_rate': 4.190567805052826e-05, 'epoch': 0.48565931696830433, 'step': 2696500}
INFO:transformers.trainer:{'loss': 3.200303194999695, 'learning_rate': 4.190417715641562e-05, 'epoch': 0.4857493706150628, 'step': 2697000}
INFO:transformers.trainer:{'loss': 3.170497854232788, 'learning_rate': 4.190267626230298e-05, 'epoch': 0.48583942426182125, 'step': 2697500}
INFO:transformers.trainer:{'loss': 3.2199647715091704, 'learning_rate': 4.1901175368190344e-05, 'epoch': 0.4859294779085797, 'step': 2698000}
INFO:transformers.trainer:{'loss': 3.1243484878540038, 'learning_rate': 4.18996744740777e-05, 'epoch': 0.48601953155533817, 'step': 2698500}
INFO:transformers.trainer:{'loss': 3.2115920782089233, 'learning_rate': 4.189817357996506e-05, 'epoch': 0.4861095852020966, 'step': 2699000}
INFO:transformers.trainer:{'loss': 3.2363459756374358, 'learning_rate': 4.1896672685852415e-05, 'epoch': 0.48619963884885503, 'step': 2699500}
INFO:transformers.trainer:{'loss': 3.202615686416626, 'learning_rate': 4.189517179173978e-05, 'epoch': 0.4862896924956135, 'step': 2700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1709463419914248, 'learning_rate': 4.189367089762713e-05, 'epoch': 0.48637974614237195, 'step': 2700500}
INFO:transformers.trainer:{'loss': 3.164814872145653, 'learning_rate': 4.18921700035145e-05, 'epoch': 0.4864697997891304, 'step': 2701000}
INFO:transformers.trainer:{'loss': 3.1558048020601275, 'learning_rate': 4.189066910940185e-05, 'epoch': 0.4865598534358888, 'step': 2701500}
INFO:transformers.trainer:{'loss': 3.204085428953171, 'learning_rate': 4.188916821528922e-05, 'epoch': 0.48664990708264727, 'step': 2702000}
INFO:transformers.trainer:{'loss': 3.2081648671627043, 'learning_rate': 4.188766732117657e-05, 'epoch': 0.48673996072940573, 'step': 2702500}
INFO:transformers.trainer:{'loss': 3.179251051425934, 'learning_rate': 4.1886166427063935e-05, 'epoch': 0.4868300143761642, 'step': 2703000}
INFO:transformers.trainer:{'loss': 3.262104133605957, 'learning_rate': 4.188466553295129e-05, 'epoch': 0.4869200680229226, 'step': 2703500}
INFO:transformers.trainer:{'loss': 3.1482151404619216, 'learning_rate': 4.188316463883865e-05, 'epoch': 0.48701012166968105, 'step': 2704000}
INFO:transformers.trainer:{'loss': 3.1774365854263307, 'learning_rate': 4.188166374472601e-05, 'epoch': 0.4871001753164395, 'step': 2704500}
INFO:transformers.trainer:{'loss': 3.2554904510974882, 'learning_rate': 4.188016285061337e-05, 'epoch': 0.48719022896319797, 'step': 2705000}
INFO:transformers.trainer:{'loss': 3.156084367275238, 'learning_rate': 4.187866195650073e-05, 'epoch': 0.4872802826099564, 'step': 2705500}
INFO:transformers.trainer:{'loss': 3.1527149379253387, 'learning_rate': 4.187716106238809e-05, 'epoch': 0.48737033625671483, 'step': 2706000}
INFO:transformers.trainer:{'loss': 3.147065486907959, 'learning_rate': 4.187566016827545e-05, 'epoch': 0.4874603899034733, 'step': 2706500}
INFO:transformers.trainer:{'loss': 3.152080406665802, 'learning_rate': 4.187415927416281e-05, 'epoch': 0.48755044355023175, 'step': 2707000}
INFO:transformers.trainer:{'loss': 3.2206669845581053, 'learning_rate': 4.1872658380050166e-05, 'epoch': 0.4876404971969902, 'step': 2707500}
INFO:transformers.trainer:{'loss': 3.182849008321762, 'learning_rate': 4.1871157485937525e-05, 'epoch': 0.4877305508437486, 'step': 2708000}
INFO:transformers.trainer:{'loss': 3.180129966020584, 'learning_rate': 4.1869656591824884e-05, 'epoch': 0.48782060449050707, 'step': 2708500}
INFO:transformers.trainer:{'loss': 3.179515988230705, 'learning_rate': 4.1868155697712244e-05, 'epoch': 0.48791065813726553, 'step': 2709000}
INFO:transformers.trainer:{'loss': 3.199018894433975, 'learning_rate': 4.18666548035996e-05, 'epoch': 0.488000711784024, 'step': 2709500}
INFO:transformers.trainer:{'loss': 3.194664689540863, 'learning_rate': 4.186515390948696e-05, 'epoch': 0.48809076543078245, 'step': 2710000}
INFO:transformers.trainer:{'loss': 3.178941397428513, 'learning_rate': 4.186365301537432e-05, 'epoch': 0.48818081907754085, 'step': 2710500}
INFO:transformers.trainer:{'loss': 3.207408942937851, 'learning_rate': 4.186215212126168e-05, 'epoch': 0.4882708727242993, 'step': 2711000}
INFO:transformers.trainer:{'loss': 3.236321289777756, 'learning_rate': 4.186065122714904e-05, 'epoch': 0.48836092637105777, 'step': 2711500}
INFO:transformers.trainer:{'loss': 3.1829695773124693, 'learning_rate': 4.18591503330364e-05, 'epoch': 0.4884509800178162, 'step': 2712000}
INFO:transformers.trainer:{'loss': 3.1503863182067873, 'learning_rate': 4.185764943892376e-05, 'epoch': 0.4885410336645747, 'step': 2712500}
INFO:transformers.trainer:{'loss': 3.16644437789917, 'learning_rate': 4.1856148544811116e-05, 'epoch': 0.4886310873113331, 'step': 2713000}
INFO:transformers.trainer:{'loss': 3.2365670483112337, 'learning_rate': 4.1854647650698475e-05, 'epoch': 0.48872114095809155, 'step': 2713500}
INFO:transformers.trainer:{'loss': 3.2056870970726012, 'learning_rate': 4.1853146756585834e-05, 'epoch': 0.48881119460485, 'step': 2714000}
INFO:transformers.trainer:{'loss': 3.1499188067913058, 'learning_rate': 4.185164586247319e-05, 'epoch': 0.48890124825160847, 'step': 2714500}
INFO:transformers.trainer:{'loss': 3.2471035826206207, 'learning_rate': 4.185014496836055e-05, 'epoch': 0.48899130189836687, 'step': 2715000}
INFO:transformers.trainer:{'loss': 3.2198454670906065, 'learning_rate': 4.184864407424791e-05, 'epoch': 0.48908135554512533, 'step': 2715500}
INFO:transformers.trainer:{'loss': 3.16926566529274, 'learning_rate': 4.184714318013527e-05, 'epoch': 0.4891714091918838, 'step': 2716000}
INFO:transformers.trainer:{'loss': 3.21336354970932, 'learning_rate': 4.184564228602263e-05, 'epoch': 0.48926146283864225, 'step': 2716500}
INFO:transformers.trainer:{'loss': 3.2410249326229095, 'learning_rate': 4.184414139190999e-05, 'epoch': 0.4893515164854007, 'step': 2717000}
INFO:transformers.trainer:{'loss': 3.2460733370780943, 'learning_rate': 4.184264049779735e-05, 'epoch': 0.4894415701321591, 'step': 2717500}
INFO:transformers.trainer:{'loss': 3.193657393693924, 'learning_rate': 4.1841139603684706e-05, 'epoch': 0.48953162377891757, 'step': 2718000}
INFO:transformers.trainer:{'loss': 3.144742259025574, 'learning_rate': 4.183963870957207e-05, 'epoch': 0.489621677425676, 'step': 2718500}
INFO:transformers.trainer:{'loss': 3.155276183605194, 'learning_rate': 4.1838137815459425e-05, 'epoch': 0.4897117310724345, 'step': 2719000}
INFO:transformers.trainer:{'loss': 3.132233104467392, 'learning_rate': 4.183663692134679e-05, 'epoch': 0.48980178471919295, 'step': 2719500}
INFO:transformers.trainer:{'loss': 3.199184070110321, 'learning_rate': 4.183513602723414e-05, 'epoch': 0.48989183836595135, 'step': 2720000}
INFO:transformers.trainer:{'loss': 3.2438681392669677, 'learning_rate': 4.183363513312151e-05, 'epoch': 0.4899818920127098, 'step': 2720500}
INFO:transformers.trainer:{'loss': 3.1409463441371916, 'learning_rate': 4.183213423900886e-05, 'epoch': 0.49007194565946827, 'step': 2721000}
INFO:transformers.trainer:{'loss': 3.20208171081543, 'learning_rate': 4.1830633344896227e-05, 'epoch': 0.4901619993062267, 'step': 2721500}
INFO:transformers.trainer:{'loss': 3.189670215129852, 'learning_rate': 4.182913245078358e-05, 'epoch': 0.49025205295298513, 'step': 2722000}
INFO:transformers.trainer:{'loss': 3.147116586923599, 'learning_rate': 4.1827631556670945e-05, 'epoch': 0.4903421065997436, 'step': 2722500}
INFO:transformers.trainer:{'loss': 3.205805108785629, 'learning_rate': 4.18261306625583e-05, 'epoch': 0.49043216024650205, 'step': 2723000}
INFO:transformers.trainer:{'loss': 3.196104510307312, 'learning_rate': 4.182462976844566e-05, 'epoch': 0.4905222138932605, 'step': 2723500}
INFO:transformers.trainer:{'loss': 3.184148414373398, 'learning_rate': 4.1823128874333015e-05, 'epoch': 0.49061226754001896, 'step': 2724000}
INFO:transformers.trainer:{'loss': 3.225427704334259, 'learning_rate': 4.182162798022038e-05, 'epoch': 0.49070232118677737, 'step': 2724500}
INFO:transformers.trainer:{'loss': 3.208611491203308, 'learning_rate': 4.182012708610773e-05, 'epoch': 0.4907923748335358, 'step': 2725000}
INFO:transformers.trainer:{'loss': 3.2031092462539674, 'learning_rate': 4.18186261919951e-05, 'epoch': 0.4908824284802943, 'step': 2725500}
INFO:transformers.trainer:{'loss': 3.1886242587566374, 'learning_rate': 4.181712529788246e-05, 'epoch': 0.49097248212705275, 'step': 2726000}
INFO:transformers.trainer:{'loss': 3.180555551767349, 'learning_rate': 4.181562440376982e-05, 'epoch': 0.49106253577381115, 'step': 2726500}
INFO:transformers.trainer:{'loss': 3.1858058755397796, 'learning_rate': 4.1814123509657176e-05, 'epoch': 0.4911525894205696, 'step': 2727000}
INFO:transformers.trainer:{'loss': 3.202857746601105, 'learning_rate': 4.1812622615544535e-05, 'epoch': 0.49124264306732807, 'step': 2727500}
INFO:transformers.trainer:{'loss': 3.2204798848629, 'learning_rate': 4.1811121721431894e-05, 'epoch': 0.4913326967140865, 'step': 2728000}
INFO:transformers.trainer:{'loss': 3.180247874498367, 'learning_rate': 4.180962082731925e-05, 'epoch': 0.491422750360845, 'step': 2728500}
INFO:transformers.trainer:{'loss': 3.1536684126853944, 'learning_rate': 4.180811993320661e-05, 'epoch': 0.4915128040076034, 'step': 2729000}
INFO:transformers.trainer:{'loss': 3.2372277009487154, 'learning_rate': 4.180661903909397e-05, 'epoch': 0.49160285765436185, 'step': 2729500}
INFO:transformers.trainer:{'loss': 3.1798672696352006, 'learning_rate': 4.180511814498133e-05, 'epoch': 0.4916929113011203, 'step': 2730000}
INFO:transformers.trainer:{'loss': 3.1429149467945097, 'learning_rate': 4.180361725086869e-05, 'epoch': 0.49178296494787876, 'step': 2730500}
INFO:transformers.trainer:{'loss': 3.155577452421188, 'learning_rate': 4.180211635675605e-05, 'epoch': 0.4918730185946372, 'step': 2731000}
INFO:transformers.trainer:{'loss': 3.131037948846817, 'learning_rate': 4.180061546264341e-05, 'epoch': 0.4919630722413956, 'step': 2731500}
INFO:transformers.trainer:{'loss': 3.1532299897670746, 'learning_rate': 4.1799114568530767e-05, 'epoch': 0.4920531258881541, 'step': 2732000}
INFO:transformers.trainer:{'loss': 3.1603857047557833, 'learning_rate': 4.179761367441813e-05, 'epoch': 0.49214317953491254, 'step': 2732500}
INFO:transformers.trainer:{'loss': 3.1916248672008516, 'learning_rate': 4.1796112780305485e-05, 'epoch': 0.492233233181671, 'step': 2733000}
INFO:transformers.trainer:{'loss': 3.1195288368463516, 'learning_rate': 4.1794611886192844e-05, 'epoch': 0.4923232868284294, 'step': 2733500}
INFO:transformers.trainer:{'loss': 3.2003844981193543, 'learning_rate': 4.17931109920802e-05, 'epoch': 0.49241334047518787, 'step': 2734000}
INFO:transformers.trainer:{'loss': 3.1596160678863527, 'learning_rate': 4.179161009796756e-05, 'epoch': 0.4925033941219463, 'step': 2734500}
INFO:transformers.trainer:{'loss': 3.188110636472702, 'learning_rate': 4.179010920385492e-05, 'epoch': 0.4925934477687048, 'step': 2735000}
INFO:transformers.trainer:{'loss': 3.162088264465332, 'learning_rate': 4.178860830974228e-05, 'epoch': 0.49268350141546324, 'step': 2735500}
INFO:transformers.trainer:{'loss': 3.1840714757442474, 'learning_rate': 4.178710741562964e-05, 'epoch': 0.49277355506222165, 'step': 2736000}
INFO:transformers.trainer:{'loss': 3.1742259230613707, 'learning_rate': 4.1785606521517e-05, 'epoch': 0.4928636087089801, 'step': 2736500}
INFO:transformers.trainer:{'loss': 3.1782272708415986, 'learning_rate': 4.178410562740436e-05, 'epoch': 0.49295366235573856, 'step': 2737000}
INFO:transformers.trainer:{'loss': 3.224122328519821, 'learning_rate': 4.1782604733291716e-05, 'epoch': 0.493043716002497, 'step': 2737500}
INFO:transformers.trainer:{'loss': 3.140493100762367, 'learning_rate': 4.1781103839179075e-05, 'epoch': 0.4931337696492554, 'step': 2738000}
INFO:transformers.trainer:{'loss': 3.1844599843025208, 'learning_rate': 4.1779602945066434e-05, 'epoch': 0.4932238232960139, 'step': 2738500}
INFO:transformers.trainer:{'loss': 3.1944430177211762, 'learning_rate': 4.177810205095379e-05, 'epoch': 0.49331387694277234, 'step': 2739000}
INFO:transformers.trainer:{'loss': 3.219579918384552, 'learning_rate': 4.177660115684115e-05, 'epoch': 0.4934039305895308, 'step': 2739500}
INFO:transformers.trainer:{'loss': 3.2017060317993162, 'learning_rate': 4.177510026272852e-05, 'epoch': 0.49349398423628926, 'step': 2740000}
INFO:transformers.trainer:{'loss': 3.1574410293102266, 'learning_rate': 4.177359936861587e-05, 'epoch': 0.49358403788304767, 'step': 2740500}
INFO:transformers.trainer:{'loss': 3.139728533267975, 'learning_rate': 4.1772098474503236e-05, 'epoch': 0.4936740915298061, 'step': 2741000}
INFO:transformers.trainer:{'loss': 3.1795162383317948, 'learning_rate': 4.177059758039059e-05, 'epoch': 0.4937641451765646, 'step': 2741500}
INFO:transformers.trainer:{'loss': 3.160271550655365, 'learning_rate': 4.1769096686277954e-05, 'epoch': 0.49385419882332304, 'step': 2742000}
INFO:transformers.trainer:{'loss': 3.1316141488552094, 'learning_rate': 4.176759579216531e-05, 'epoch': 0.4939442524700815, 'step': 2742500}
INFO:transformers.trainer:{'loss': 3.0869931547641754, 'learning_rate': 4.176609489805267e-05, 'epoch': 0.4940343061168399, 'step': 2743000}
INFO:transformers.trainer:{'loss': 3.220250464439392, 'learning_rate': 4.1764594003940025e-05, 'epoch': 0.49412435976359836, 'step': 2743500}
INFO:transformers.trainer:{'loss': 3.1437422311306, 'learning_rate': 4.176309310982739e-05, 'epoch': 0.4942144134103568, 'step': 2744000}
INFO:transformers.trainer:{'loss': 3.2383466242551804, 'learning_rate': 4.176159221571474e-05, 'epoch': 0.4943044670571153, 'step': 2744500}
INFO:transformers.trainer:{'loss': 3.165875023365021, 'learning_rate': 4.176009132160211e-05, 'epoch': 0.4943945207038737, 'step': 2745000}
INFO:transformers.trainer:{'loss': 3.2062063331604005, 'learning_rate': 4.175859042748946e-05, 'epoch': 0.49448457435063214, 'step': 2745500}
INFO:transformers.trainer:{'loss': 3.167475455403328, 'learning_rate': 4.175708953337683e-05, 'epoch': 0.4945746279973906, 'step': 2746000}
INFO:transformers.trainer:{'loss': 3.1582797067165376, 'learning_rate': 4.1755588639264186e-05, 'epoch': 0.49466468164414906, 'step': 2746500}
INFO:transformers.trainer:{'loss': 3.1730676825046538, 'learning_rate': 4.1754087745151545e-05, 'epoch': 0.4947547352909075, 'step': 2747000}
INFO:transformers.trainer:{'loss': 3.1975778863430024, 'learning_rate': 4.1752586851038904e-05, 'epoch': 0.4948447889376659, 'step': 2747500}
INFO:transformers.trainer:{'loss': 3.196519052028656, 'learning_rate': 4.175108595692626e-05, 'epoch': 0.4949348425844244, 'step': 2748000}
INFO:transformers.trainer:{'loss': 3.2184109873771667, 'learning_rate': 4.174958506281362e-05, 'epoch': 0.49502489623118284, 'step': 2748500}
INFO:transformers.trainer:{'loss': 3.2150898418426515, 'learning_rate': 4.174808416870098e-05, 'epoch': 0.4951149498779413, 'step': 2749000}
INFO:transformers.trainer:{'loss': 3.173485831975937, 'learning_rate': 4.174658327458834e-05, 'epoch': 0.49520500352469976, 'step': 2749500}
INFO:transformers.trainer:{'loss': 3.1489264516830446, 'learning_rate': 4.17450823804757e-05, 'epoch': 0.49529505717145816, 'step': 2750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.279786126613617, 'learning_rate': 4.174358148636306e-05, 'epoch': 0.4953851108182166, 'step': 2750500}
INFO:transformers.trainer:{'loss': 3.162196382522583, 'learning_rate': 4.174208059225042e-05, 'epoch': 0.4954751644649751, 'step': 2751000}
INFO:transformers.trainer:{'loss': 3.1765840475559233, 'learning_rate': 4.1740579698137776e-05, 'epoch': 0.49556521811173354, 'step': 2751500}
INFO:transformers.trainer:{'loss': 3.194238994598389, 'learning_rate': 4.1739078804025135e-05, 'epoch': 0.49565527175849194, 'step': 2752000}
INFO:transformers.trainer:{'loss': 3.197390950679779, 'learning_rate': 4.1737577909912494e-05, 'epoch': 0.4957453254052504, 'step': 2752500}
INFO:transformers.trainer:{'loss': 3.1465123720169066, 'learning_rate': 4.1736077015799853e-05, 'epoch': 0.49583537905200886, 'step': 2753000}
INFO:transformers.trainer:{'loss': 3.1281573718786237, 'learning_rate': 4.173457612168721e-05, 'epoch': 0.4959254326987673, 'step': 2753500}
INFO:transformers.trainer:{'loss': 3.169826820850372, 'learning_rate': 4.173307522757458e-05, 'epoch': 0.4960154863455258, 'step': 2754000}
INFO:transformers.trainer:{'loss': 3.145503495454788, 'learning_rate': 4.173157433346193e-05, 'epoch': 0.4961055399922842, 'step': 2754500}
INFO:transformers.trainer:{'loss': 3.206432411193848, 'learning_rate': 4.1730073439349296e-05, 'epoch': 0.49619559363904264, 'step': 2755000}
INFO:transformers.trainer:{'loss': 3.1872984964847566, 'learning_rate': 4.172857254523665e-05, 'epoch': 0.4962856472858011, 'step': 2755500}
INFO:transformers.trainer:{'loss': 3.23090393280983, 'learning_rate': 4.1727071651124015e-05, 'epoch': 0.49637570093255956, 'step': 2756000}
INFO:transformers.trainer:{'loss': 3.1798690378665926, 'learning_rate': 4.172557075701137e-05, 'epoch': 0.49646575457931796, 'step': 2756500}
INFO:transformers.trainer:{'loss': 3.156912067651749, 'learning_rate': 4.1724069862898726e-05, 'epoch': 0.4965558082260764, 'step': 2757000}
INFO:transformers.trainer:{'loss': 3.1882963614463806, 'learning_rate': 4.1722568968786085e-05, 'epoch': 0.4966458618728349, 'step': 2757500}
INFO:transformers.trainer:{'loss': 3.181383563518524, 'learning_rate': 4.1721068074673444e-05, 'epoch': 0.49673591551959334, 'step': 2758000}
INFO:transformers.trainer:{'loss': 3.158778540611267, 'learning_rate': 4.17195671805608e-05, 'epoch': 0.4968259691663518, 'step': 2758500}
INFO:transformers.trainer:{'loss': 3.1541054120063783, 'learning_rate': 4.171806628644816e-05, 'epoch': 0.4969160228131102, 'step': 2759000}
INFO:transformers.trainer:{'loss': 3.1694756817817686, 'learning_rate': 4.171656539233552e-05, 'epoch': 0.49700607645986866, 'step': 2759500}
INFO:transformers.trainer:{'loss': 3.1489876732826234, 'learning_rate': 4.171506449822288e-05, 'epoch': 0.4970961301066271, 'step': 2760000}
INFO:transformers.trainer:{'loss': 3.1492871475219726, 'learning_rate': 4.1713563604110246e-05, 'epoch': 0.4971861837533856, 'step': 2760500}
INFO:transformers.trainer:{'loss': 3.1683136546611785, 'learning_rate': 4.17120627099976e-05, 'epoch': 0.49727623740014404, 'step': 2761000}
INFO:transformers.trainer:{'loss': 3.2018062222003936, 'learning_rate': 4.1710561815884964e-05, 'epoch': 0.49736629104690244, 'step': 2761500}
INFO:transformers.trainer:{'loss': 3.1980220067501066, 'learning_rate': 4.1709060921772316e-05, 'epoch': 0.4974563446936609, 'step': 2762000}
INFO:transformers.trainer:{'loss': 3.204916750788689, 'learning_rate': 4.170756002765968e-05, 'epoch': 0.49754639834041936, 'step': 2762500}
INFO:transformers.trainer:{'loss': 3.175127695083618, 'learning_rate': 4.1706059133547034e-05, 'epoch': 0.4976364519871778, 'step': 2763000}
INFO:transformers.trainer:{'loss': 3.172859087228775, 'learning_rate': 4.17045582394344e-05, 'epoch': 0.4977265056339362, 'step': 2763500}
INFO:transformers.trainer:{'loss': 3.1610226821899414, 'learning_rate': 4.170305734532175e-05, 'epoch': 0.4978165592806947, 'step': 2764000}
INFO:transformers.trainer:{'loss': 3.1705714061260224, 'learning_rate': 4.170155645120912e-05, 'epoch': 0.49790661292745314, 'step': 2764500}
INFO:transformers.trainer:{'loss': 3.124728379249573, 'learning_rate': 4.170005555709647e-05, 'epoch': 0.4979966665742116, 'step': 2765000}
INFO:transformers.trainer:{'loss': 3.2156109554767607, 'learning_rate': 4.1698554662983836e-05, 'epoch': 0.49808672022097006, 'step': 2765500}
INFO:transformers.trainer:{'loss': 3.197995671272278, 'learning_rate': 4.169705376887119e-05, 'epoch': 0.49817677386772846, 'step': 2766000}
INFO:transformers.trainer:{'loss': 3.212310588359833, 'learning_rate': 4.1695552874758555e-05, 'epoch': 0.4982668275144869, 'step': 2766500}
INFO:transformers.trainer:{'loss': 3.136760448694229, 'learning_rate': 4.1694051980645914e-05, 'epoch': 0.4983568811612454, 'step': 2767000}
INFO:transformers.trainer:{'loss': 3.2200827214717864, 'learning_rate': 4.169255108653327e-05, 'epoch': 0.49844693480800384, 'step': 2767500}
INFO:transformers.trainer:{'loss': 3.1547525463104247, 'learning_rate': 4.169105019242063e-05, 'epoch': 0.4985369884547623, 'step': 2768000}
INFO:transformers.trainer:{'loss': 3.154535644054413, 'learning_rate': 4.168954929830799e-05, 'epoch': 0.4986270421015207, 'step': 2768500}
INFO:transformers.trainer:{'loss': 3.17582243514061, 'learning_rate': 4.168804840419535e-05, 'epoch': 0.49871709574827916, 'step': 2769000}
INFO:transformers.trainer:{'loss': 3.222590219974518, 'learning_rate': 4.168654751008271e-05, 'epoch': 0.4988071493950376, 'step': 2769500}
INFO:transformers.trainer:{'loss': 3.2094917018413542, 'learning_rate': 4.168504661597007e-05, 'epoch': 0.4988972030417961, 'step': 2770000}
INFO:transformers.trainer:{'loss': 3.167945605516434, 'learning_rate': 4.168354572185743e-05, 'epoch': 0.4989872566885545, 'step': 2770500}
INFO:transformers.trainer:{'loss': 3.223899158000946, 'learning_rate': 4.1682044827744786e-05, 'epoch': 0.49907731033531294, 'step': 2771000}
INFO:transformers.trainer:{'loss': 3.2056036694049834, 'learning_rate': 4.1680543933632145e-05, 'epoch': 0.4991673639820714, 'step': 2771500}
INFO:transformers.trainer:{'loss': 3.1676519899368287, 'learning_rate': 4.1679043039519504e-05, 'epoch': 0.49925741762882986, 'step': 2772000}
INFO:transformers.trainer:{'loss': 3.1419270553588867, 'learning_rate': 4.167754214540686e-05, 'epoch': 0.4993474712755883, 'step': 2772500}
INFO:transformers.trainer:{'loss': 3.140898554801941, 'learning_rate': 4.167604125129422e-05, 'epoch': 0.4994375249223467, 'step': 2773000}
INFO:transformers.trainer:{'loss': 3.1585124509334563, 'learning_rate': 4.167454035718158e-05, 'epoch': 0.4995275785691052, 'step': 2773500}
INFO:transformers.trainer:{'loss': 3.1579290923476218, 'learning_rate': 4.167303946306894e-05, 'epoch': 0.49961763221586364, 'step': 2774000}
INFO:transformers.trainer:{'loss': 3.2116215400695802, 'learning_rate': 4.1671538568956306e-05, 'epoch': 0.4997076858626221, 'step': 2774500}
INFO:transformers.trainer:{'loss': 3.179265200138092, 'learning_rate': 4.167003767484366e-05, 'epoch': 0.4997977395093805, 'step': 2775000}
INFO:transformers.trainer:{'loss': 3.2069249312877655, 'learning_rate': 4.1668536780731024e-05, 'epoch': 0.49988779315613896, 'step': 2775500}
INFO:transformers.trainer:{'loss': 3.2093416805267334, 'learning_rate': 4.1667035886618377e-05, 'epoch': 0.4999778468028974, 'step': 2776000}
INFO:transformers.trainer:{'loss': 3.1668644082546233, 'learning_rate': 4.166553499250574e-05, 'epoch': 0.5000679004496559, 'step': 2776500}
INFO:transformers.trainer:{'loss': 3.1730682821273803, 'learning_rate': 4.1664034098393095e-05, 'epoch': 0.5001579540964143, 'step': 2777000}
INFO:transformers.trainer:{'loss': 3.181715054512024, 'learning_rate': 4.166253320428046e-05, 'epoch': 0.5002480077431728, 'step': 2777500}
INFO:transformers.trainer:{'loss': 3.181792483091354, 'learning_rate': 4.166103231016781e-05, 'epoch': 0.5003380613899312, 'step': 2778000}
INFO:transformers.trainer:{'loss': 3.216296745300293, 'learning_rate': 4.165953141605518e-05, 'epoch': 0.5004281150366896, 'step': 2778500}
INFO:transformers.trainer:{'loss': 3.1760874246358872, 'learning_rate': 4.165803052194253e-05, 'epoch': 0.5005181686834481, 'step': 2779000}
INFO:transformers.trainer:{'loss': 3.185685970544815, 'learning_rate': 4.16565296278299e-05, 'epoch': 0.5006082223302065, 'step': 2779500}
INFO:transformers.trainer:{'loss': 3.158391828298569, 'learning_rate': 4.165502873371725e-05, 'epoch': 0.500698275976965, 'step': 2780000}
INFO:transformers.trainer:{'loss': 3.258278226017952, 'learning_rate': 4.165352783960461e-05, 'epoch': 0.5007883296237234, 'step': 2780500}
INFO:transformers.trainer:{'loss': 3.1498152265548707, 'learning_rate': 4.1652026945491974e-05, 'epoch': 0.5008783832704818, 'step': 2781000}
INFO:transformers.trainer:{'loss': 3.1782618374824523, 'learning_rate': 4.1650526051379326e-05, 'epoch': 0.5009684369172404, 'step': 2781500}
INFO:transformers.trainer:{'loss': 3.1940779576301574, 'learning_rate': 4.164902515726669e-05, 'epoch': 0.5010584905639988, 'step': 2782000}
INFO:transformers.trainer:{'loss': 3.225786925315857, 'learning_rate': 4.1647524263154044e-05, 'epoch': 0.5011485442107573, 'step': 2782500}
INFO:transformers.trainer:{'loss': 3.1421098257303237, 'learning_rate': 4.164602336904141e-05, 'epoch': 0.5012385978575157, 'step': 2783000}
INFO:transformers.trainer:{'loss': 3.1348939814567567, 'learning_rate': 4.164452247492876e-05, 'epoch': 0.5013286515042741, 'step': 2783500}
INFO:transformers.trainer:{'loss': 3.243687949895859, 'learning_rate': 4.164302158081613e-05, 'epoch': 0.5014187051510326, 'step': 2784000}
INFO:transformers.trainer:{'loss': 3.1848561112880707, 'learning_rate': 4.164152068670348e-05, 'epoch': 0.501508758797791, 'step': 2784500}
INFO:transformers.trainer:{'loss': 3.1386447324752806, 'learning_rate': 4.1640019792590846e-05, 'epoch': 0.5015988124445495, 'step': 2785000}
INFO:transformers.trainer:{'loss': 3.1693134249448778, 'learning_rate': 4.16385188984782e-05, 'epoch': 0.5016888660913079, 'step': 2785500}
INFO:transformers.trainer:{'loss': 3.158514548778534, 'learning_rate': 4.1637018004365564e-05, 'epoch': 0.5017789197380663, 'step': 2786000}
INFO:transformers.trainer:{'loss': 3.1517661170959475, 'learning_rate': 4.1635517110252917e-05, 'epoch': 0.5018689733848248, 'step': 2786500}
INFO:transformers.trainer:{'loss': 3.224046679496765, 'learning_rate': 4.163401621614028e-05, 'epoch': 0.5019590270315832, 'step': 2787000}
INFO:transformers.trainer:{'loss': 3.2023551626205444, 'learning_rate': 4.1632515322027635e-05, 'epoch': 0.5020490806783418, 'step': 2787500}
INFO:transformers.trainer:{'loss': 3.1947325687408448, 'learning_rate': 4.1631014427915e-05, 'epoch': 0.5021391343251002, 'step': 2788000}
INFO:transformers.trainer:{'loss': 3.1890126397609713, 'learning_rate': 4.162951353380236e-05, 'epoch': 0.5022291879718586, 'step': 2788500}
INFO:transformers.trainer:{'loss': 3.1560357741117477, 'learning_rate': 4.162801263968972e-05, 'epoch': 0.5023192416186171, 'step': 2789000}
INFO:transformers.trainer:{'loss': 3.171183245420456, 'learning_rate': 4.162651174557708e-05, 'epoch': 0.5024092952653755, 'step': 2789500}
INFO:transformers.trainer:{'loss': 3.205915622115135, 'learning_rate': 4.162501085146444e-05, 'epoch': 0.502499348912134, 'step': 2790000}
INFO:transformers.trainer:{'loss': 3.176192821621895, 'learning_rate': 4.1623509957351796e-05, 'epoch': 0.5025894025588924, 'step': 2790500}
INFO:transformers.trainer:{'loss': 3.148820210456848, 'learning_rate': 4.1622009063239155e-05, 'epoch': 0.5026794562056508, 'step': 2791000}
INFO:transformers.trainer:{'loss': 3.2061170816421507, 'learning_rate': 4.1620508169126514e-05, 'epoch': 0.5027695098524093, 'step': 2791500}
INFO:transformers.trainer:{'loss': 3.1651261727809907, 'learning_rate': 4.161900727501387e-05, 'epoch': 0.5028595634991677, 'step': 2792000}
INFO:transformers.trainer:{'loss': 3.2006300015449525, 'learning_rate': 4.161750638090123e-05, 'epoch': 0.5029496171459261, 'step': 2792500}
INFO:transformers.trainer:{'loss': 3.222779283285141, 'learning_rate': 4.161600548678859e-05, 'epoch': 0.5030396707926846, 'step': 2793000}
INFO:transformers.trainer:{'loss': 3.176627713680267, 'learning_rate': 4.161450459267595e-05, 'epoch': 0.503129724439443, 'step': 2793500}
INFO:transformers.trainer:{'loss': 3.1605440320968627, 'learning_rate': 4.161300369856331e-05, 'epoch': 0.5032197780862016, 'step': 2794000}
INFO:transformers.trainer:{'loss': 3.201156718492508, 'learning_rate': 4.161150280445067e-05, 'epoch': 0.50330983173296, 'step': 2794500}
INFO:transformers.trainer:{'loss': 3.220675091743469, 'learning_rate': 4.1610001910338034e-05, 'epoch': 0.5033998853797184, 'step': 2795000}
INFO:transformers.trainer:{'loss': 3.178328082323074, 'learning_rate': 4.1608501016225386e-05, 'epoch': 0.5034899390264769, 'step': 2795500}
INFO:transformers.trainer:{'loss': 3.189798943161964, 'learning_rate': 4.160700012211275e-05, 'epoch': 0.5035799926732353, 'step': 2796000}
INFO:transformers.trainer:{'loss': 3.1804117045402527, 'learning_rate': 4.1605499228000104e-05, 'epoch': 0.5036700463199938, 'step': 2796500}
INFO:transformers.trainer:{'loss': 3.2785595058202746, 'learning_rate': 4.160399833388747e-05, 'epoch': 0.5037600999667522, 'step': 2797000}
INFO:transformers.trainer:{'loss': 3.1879341588020327, 'learning_rate': 4.160249743977482e-05, 'epoch': 0.5038501536135106, 'step': 2797500}
INFO:transformers.trainer:{'loss': 3.2087829337120057, 'learning_rate': 4.160099654566219e-05, 'epoch': 0.5039402072602691, 'step': 2798000}
INFO:transformers.trainer:{'loss': 3.2004538407325747, 'learning_rate': 4.159949565154954e-05, 'epoch': 0.5040302609070275, 'step': 2798500}
INFO:transformers.trainer:{'loss': 3.222358501672745, 'learning_rate': 4.1597994757436906e-05, 'epoch': 0.504120314553786, 'step': 2799000}
INFO:transformers.trainer:{'loss': 3.213052222490311, 'learning_rate': 4.159649386332426e-05, 'epoch': 0.5042103682005444, 'step': 2799500}
INFO:transformers.trainer:{'loss': 3.1869597566127776, 'learning_rate': 4.1594992969211624e-05, 'epoch': 0.5043004218473028, 'step': 2800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.169142134428024, 'learning_rate': 4.159349207509898e-05, 'epoch': 0.5043904754940614, 'step': 2800500}
INFO:transformers.trainer:{'loss': 3.1913356857299804, 'learning_rate': 4.159199118098634e-05, 'epoch': 0.5044805291408198, 'step': 2801000}
INFO:transformers.trainer:{'loss': 3.1525372233390807, 'learning_rate': 4.1590490286873695e-05, 'epoch': 0.5045705827875783, 'step': 2801500}
INFO:transformers.trainer:{'loss': 3.1897855323553084, 'learning_rate': 4.158898939276106e-05, 'epoch': 0.5046606364343367, 'step': 2802000}
INFO:transformers.trainer:{'loss': 3.2031019067764284, 'learning_rate': 4.158748849864842e-05, 'epoch': 0.5047506900810951, 'step': 2802500}
INFO:transformers.trainer:{'loss': 3.1542975475788118, 'learning_rate': 4.158598760453578e-05, 'epoch': 0.5048407437278536, 'step': 2803000}
INFO:transformers.trainer:{'loss': 3.180189040660858, 'learning_rate': 4.158448671042314e-05, 'epoch': 0.504930797374612, 'step': 2803500}
INFO:transformers.trainer:{'loss': 3.172762653708458, 'learning_rate': 4.15829858163105e-05, 'epoch': 0.5050208510213704, 'step': 2804000}
INFO:transformers.trainer:{'loss': 3.200430657625198, 'learning_rate': 4.1581484922197856e-05, 'epoch': 0.5051109046681289, 'step': 2804500}
INFO:transformers.trainer:{'loss': 3.2011869492530822, 'learning_rate': 4.157998402808521e-05, 'epoch': 0.5052009583148873, 'step': 2805000}
INFO:transformers.trainer:{'loss': 3.1952265045642854, 'learning_rate': 4.1578483133972574e-05, 'epoch': 0.5052910119616458, 'step': 2805500}
INFO:transformers.trainer:{'loss': 3.173148265719414, 'learning_rate': 4.1576982239859926e-05, 'epoch': 0.5053810656084042, 'step': 2806000}
INFO:transformers.trainer:{'loss': 3.142440399289131, 'learning_rate': 4.157548134574729e-05, 'epoch': 0.5054711192551626, 'step': 2806500}
INFO:transformers.trainer:{'loss': 3.184382478713989, 'learning_rate': 4.1573980451634644e-05, 'epoch': 0.5055611729019212, 'step': 2807000}
INFO:transformers.trainer:{'loss': 3.193957765340805, 'learning_rate': 4.157247955752201e-05, 'epoch': 0.5056512265486796, 'step': 2807500}
INFO:transformers.trainer:{'loss': 3.190224900960922, 'learning_rate': 4.157097866340936e-05, 'epoch': 0.5057412801954381, 'step': 2808000}
INFO:transformers.trainer:{'loss': 3.2136285758018492, 'learning_rate': 4.156947776929673e-05, 'epoch': 0.5058313338421965, 'step': 2808500}
INFO:transformers.trainer:{'loss': 3.176518447637558, 'learning_rate': 4.156797687518409e-05, 'epoch': 0.5059213874889549, 'step': 2809000}
INFO:transformers.trainer:{'loss': 3.1243632576465608, 'learning_rate': 4.1566475981071446e-05, 'epoch': 0.5060114411357134, 'step': 2809500}
INFO:transformers.trainer:{'loss': 3.160027363538742, 'learning_rate': 4.1564975086958805e-05, 'epoch': 0.5061014947824718, 'step': 2810000}
INFO:transformers.trainer:{'loss': 3.132105908155441, 'learning_rate': 4.1563474192846165e-05, 'epoch': 0.5061915484292303, 'step': 2810500}
INFO:transformers.trainer:{'loss': 3.211032889842987, 'learning_rate': 4.1561973298733524e-05, 'epoch': 0.5062816020759887, 'step': 2811000}
INFO:transformers.trainer:{'loss': 3.1850795130729677, 'learning_rate': 4.156047240462088e-05, 'epoch': 0.5063716557227471, 'step': 2811500}
INFO:transformers.trainer:{'loss': 3.1543296694755556, 'learning_rate': 4.155897151050824e-05, 'epoch': 0.5064617093695056, 'step': 2812000}
INFO:transformers.trainer:{'loss': 3.1513198492527006, 'learning_rate': 4.15574706163956e-05, 'epoch': 0.506551763016264, 'step': 2812500}
INFO:transformers.trainer:{'loss': 3.1675819740295412, 'learning_rate': 4.155596972228296e-05, 'epoch': 0.5066418166630225, 'step': 2813000}
INFO:transformers.trainer:{'loss': 3.228883547782898, 'learning_rate': 4.155446882817032e-05, 'epoch': 0.506731870309781, 'step': 2813500}
INFO:transformers.trainer:{'loss': 3.1937294414043427, 'learning_rate': 4.155296793405768e-05, 'epoch': 0.5068219239565394, 'step': 2814000}
INFO:transformers.trainer:{'loss': 3.1864168643951416, 'learning_rate': 4.155146703994504e-05, 'epoch': 0.5069119776032979, 'step': 2814500}
INFO:transformers.trainer:{'loss': 3.228908482551575, 'learning_rate': 4.1549966145832396e-05, 'epoch': 0.5070020312500563, 'step': 2815000}
INFO:transformers.trainer:{'loss': 3.132247871875763, 'learning_rate': 4.154846525171976e-05, 'epoch': 0.5070920848968147, 'step': 2815500}
INFO:transformers.trainer:{'loss': 3.204904691696167, 'learning_rate': 4.1546964357607114e-05, 'epoch': 0.5071821385435732, 'step': 2816000}
INFO:transformers.trainer:{'loss': 3.170534484624863, 'learning_rate': 4.154546346349448e-05, 'epoch': 0.5072721921903316, 'step': 2816500}
INFO:transformers.trainer:{'loss': 3.1766542997360228, 'learning_rate': 4.154396256938183e-05, 'epoch': 0.5073622458370901, 'step': 2817000}
INFO:transformers.trainer:{'loss': 3.1780430195331575, 'learning_rate': 4.15424616752692e-05, 'epoch': 0.5074522994838485, 'step': 2817500}
INFO:transformers.trainer:{'loss': 3.1840883440971375, 'learning_rate': 4.154096078115655e-05, 'epoch': 0.5075423531306069, 'step': 2818000}
INFO:transformers.trainer:{'loss': 3.1432292487621307, 'learning_rate': 4.1539459887043916e-05, 'epoch': 0.5076324067773654, 'step': 2818500}
INFO:transformers.trainer:{'loss': 3.20329101228714, 'learning_rate': 4.153795899293127e-05, 'epoch': 0.5077224604241238, 'step': 2819000}
INFO:transformers.trainer:{'loss': 3.206320697784424, 'learning_rate': 4.1536458098818634e-05, 'epoch': 0.5078125140708823, 'step': 2819500}
INFO:transformers.trainer:{'loss': 3.205422570228577, 'learning_rate': 4.1534957204705986e-05, 'epoch': 0.5079025677176408, 'step': 2820000}
INFO:transformers.trainer:{'loss': 3.133223724126816, 'learning_rate': 4.153345631059335e-05, 'epoch': 0.5079926213643992, 'step': 2820500}
INFO:transformers.trainer:{'loss': 3.1804231121540067, 'learning_rate': 4.1531955416480705e-05, 'epoch': 0.5080826750111577, 'step': 2821000}
INFO:transformers.trainer:{'loss': 3.1748297073841094, 'learning_rate': 4.153045452236807e-05, 'epoch': 0.5081727286579161, 'step': 2821500}
INFO:transformers.trainer:{'loss': 3.196472297668457, 'learning_rate': 4.152895362825542e-05, 'epoch': 0.5082627823046746, 'step': 2822000}
INFO:transformers.trainer:{'loss': 3.210079093694687, 'learning_rate': 4.152745273414279e-05, 'epoch': 0.508352835951433, 'step': 2822500}
INFO:transformers.trainer:{'loss': 3.2275251593589784, 'learning_rate': 4.152595184003015e-05, 'epoch': 0.5084428895981914, 'step': 2823000}
INFO:transformers.trainer:{'loss': 3.170659405231476, 'learning_rate': 4.152445094591751e-05, 'epoch': 0.5085329432449499, 'step': 2823500}
INFO:transformers.trainer:{'loss': 3.16461952829361, 'learning_rate': 4.1522950051804866e-05, 'epoch': 0.5086229968917083, 'step': 2824000}
INFO:transformers.trainer:{'loss': 3.107877044677734, 'learning_rate': 4.1521449157692225e-05, 'epoch': 0.5087130505384668, 'step': 2824500}
INFO:transformers.trainer:{'loss': 3.207061192512512, 'learning_rate': 4.1519948263579584e-05, 'epoch': 0.5088031041852252, 'step': 2825000}
INFO:transformers.trainer:{'loss': 3.1536923525333402, 'learning_rate': 4.151844736946694e-05, 'epoch': 0.5088931578319836, 'step': 2825500}
INFO:transformers.trainer:{'loss': 3.161978858709335, 'learning_rate': 4.15169464753543e-05, 'epoch': 0.5089832114787421, 'step': 2826000}
INFO:transformers.trainer:{'loss': 3.1926537318229675, 'learning_rate': 4.151544558124166e-05, 'epoch': 0.5090732651255006, 'step': 2826500}
INFO:transformers.trainer:{'loss': 3.230770420193672, 'learning_rate': 4.151394468712902e-05, 'epoch': 0.509163318772259, 'step': 2827000}
INFO:transformers.trainer:{'loss': 3.1817890820503236, 'learning_rate': 4.151244379301638e-05, 'epoch': 0.5092533724190175, 'step': 2827500}
INFO:transformers.trainer:{'loss': 3.1433355414867403, 'learning_rate': 4.151094289890374e-05, 'epoch': 0.5093434260657759, 'step': 2828000}
INFO:transformers.trainer:{'loss': 3.15413426554203, 'learning_rate': 4.150944200479109e-05, 'epoch': 0.5094334797125344, 'step': 2828500}
INFO:transformers.trainer:{'loss': 3.1769851138591765, 'learning_rate': 4.1507941110678456e-05, 'epoch': 0.5095235333592928, 'step': 2829000}
INFO:transformers.trainer:{'loss': 3.202139822483063, 'learning_rate': 4.1506440216565815e-05, 'epoch': 0.5096135870060512, 'step': 2829500}
INFO:transformers.trainer:{'loss': 3.1616759808063506, 'learning_rate': 4.1504939322453174e-05, 'epoch': 0.5097036406528097, 'step': 2830000}
INFO:transformers.trainer:{'loss': 3.1524758784770968, 'learning_rate': 4.150343842834053e-05, 'epoch': 0.5097936942995681, 'step': 2830500}
INFO:transformers.trainer:{'loss': 3.205245030403137, 'learning_rate': 4.150193753422789e-05, 'epoch': 0.5098837479463266, 'step': 2831000}
INFO:transformers.trainer:{'loss': 3.1533024792671203, 'learning_rate': 4.150043664011525e-05, 'epoch': 0.509973801593085, 'step': 2831500}
INFO:transformers.trainer:{'loss': 3.2122272698879244, 'learning_rate': 4.149893574600261e-05, 'epoch': 0.5100638552398434, 'step': 2832000}
INFO:transformers.trainer:{'loss': 3.1423387832641603, 'learning_rate': 4.149743485188997e-05, 'epoch': 0.510153908886602, 'step': 2832500}
INFO:transformers.trainer:{'loss': 3.2123698632717135, 'learning_rate': 4.149593395777733e-05, 'epoch': 0.5102439625333604, 'step': 2833000}
INFO:transformers.trainer:{'loss': 3.1502472909092902, 'learning_rate': 4.149443306366469e-05, 'epoch': 0.5103340161801189, 'step': 2833500}
INFO:transformers.trainer:{'loss': 3.1367475993037224, 'learning_rate': 4.149293216955205e-05, 'epoch': 0.5104240698268773, 'step': 2834000}
INFO:transformers.trainer:{'loss': 3.1580641090869905, 'learning_rate': 4.1491431275439406e-05, 'epoch': 0.5105141234736357, 'step': 2834500}
INFO:transformers.trainer:{'loss': 3.2100538899898527, 'learning_rate': 4.1489930381326765e-05, 'epoch': 0.5106041771203942, 'step': 2835000}
INFO:transformers.trainer:{'loss': 3.2065241270065306, 'learning_rate': 4.1488429487214124e-05, 'epoch': 0.5106942307671526, 'step': 2835500}
INFO:transformers.trainer:{'loss': 3.1748874852657316, 'learning_rate': 4.148692859310148e-05, 'epoch': 0.5107842844139111, 'step': 2836000}
INFO:transformers.trainer:{'loss': 3.161437523007393, 'learning_rate': 4.148542769898884e-05, 'epoch': 0.5108743380606695, 'step': 2836500}
INFO:transformers.trainer:{'loss': 3.2011699987649918, 'learning_rate': 4.148392680487621e-05, 'epoch': 0.5109643917074279, 'step': 2837000}
INFO:transformers.trainer:{'loss': 3.177399488687515, 'learning_rate': 4.148242591076356e-05, 'epoch': 0.5110544453541864, 'step': 2837500}
INFO:transformers.trainer:{'loss': 3.0991909358501433, 'learning_rate': 4.1480925016650926e-05, 'epoch': 0.5111444990009448, 'step': 2838000}
INFO:transformers.trainer:{'loss': 3.184932133436203, 'learning_rate': 4.147942412253828e-05, 'epoch': 0.5112345526477033, 'step': 2838500}
INFO:transformers.trainer:{'loss': 3.180909170150757, 'learning_rate': 4.1477923228425644e-05, 'epoch': 0.5113246062944617, 'step': 2839000}
INFO:transformers.trainer:{'loss': 3.164784560203552, 'learning_rate': 4.1476422334312996e-05, 'epoch': 0.5114146599412202, 'step': 2839500}
INFO:transformers.trainer:{'loss': 3.126217402935028, 'learning_rate': 4.147492144020036e-05, 'epoch': 0.5115047135879787, 'step': 2840000}
INFO:transformers.trainer:{'loss': 3.1794033734798433, 'learning_rate': 4.1473420546087714e-05, 'epoch': 0.5115947672347371, 'step': 2840500}
INFO:transformers.trainer:{'loss': 3.216713552236557, 'learning_rate': 4.147191965197508e-05, 'epoch': 0.5116848208814955, 'step': 2841000}
INFO:transformers.trainer:{'loss': 3.2031853470802307, 'learning_rate': 4.147041875786243e-05, 'epoch': 0.511774874528254, 'step': 2841500}
INFO:transformers.trainer:{'loss': 3.2296144151687622, 'learning_rate': 4.14689178637498e-05, 'epoch': 0.5118649281750124, 'step': 2842000}
INFO:transformers.trainer:{'loss': 3.157528984546661, 'learning_rate': 4.146741696963715e-05, 'epoch': 0.5119549818217709, 'step': 2842500}
INFO:transformers.trainer:{'loss': 3.156113100528717, 'learning_rate': 4.1465916075524516e-05, 'epoch': 0.5120450354685293, 'step': 2843000}
INFO:transformers.trainer:{'loss': 3.1617526326179504, 'learning_rate': 4.1464415181411875e-05, 'epoch': 0.5121350891152877, 'step': 2843500}
INFO:transformers.trainer:{'loss': 3.1822760429382324, 'learning_rate': 4.1462914287299234e-05, 'epoch': 0.5122251427620462, 'step': 2844000}
INFO:transformers.trainer:{'loss': 3.161569473028183, 'learning_rate': 4.1461413393186593e-05, 'epoch': 0.5123151964088046, 'step': 2844500}
INFO:transformers.trainer:{'loss': 3.160803312063217, 'learning_rate': 4.145991249907395e-05, 'epoch': 0.5124052500555631, 'step': 2845000}
INFO:transformers.trainer:{'loss': 3.1465656408071516, 'learning_rate': 4.145841160496131e-05, 'epoch': 0.5124953037023215, 'step': 2845500}
INFO:transformers.trainer:{'loss': 3.0959262177944185, 'learning_rate': 4.145691071084867e-05, 'epoch': 0.51258535734908, 'step': 2846000}
INFO:transformers.trainer:{'loss': 3.1774390609264374, 'learning_rate': 4.145540981673603e-05, 'epoch': 0.5126754109958385, 'step': 2846500}
INFO:transformers.trainer:{'loss': 3.179458567619324, 'learning_rate': 4.145390892262339e-05, 'epoch': 0.5127654646425969, 'step': 2847000}
INFO:transformers.trainer:{'loss': 3.2124663751125335, 'learning_rate': 4.145240802851075e-05, 'epoch': 0.5128555182893554, 'step': 2847500}
INFO:transformers.trainer:{'loss': 3.1375860810279845, 'learning_rate': 4.145090713439811e-05, 'epoch': 0.5129455719361138, 'step': 2848000}
INFO:transformers.trainer:{'loss': 3.2077395129203796, 'learning_rate': 4.1449406240285466e-05, 'epoch': 0.5130356255828722, 'step': 2848500}
INFO:transformers.trainer:{'loss': 3.225493721008301, 'learning_rate': 4.1447905346172825e-05, 'epoch': 0.5131256792296307, 'step': 2849000}
INFO:transformers.trainer:{'loss': 3.1580820047855376, 'learning_rate': 4.1446404452060184e-05, 'epoch': 0.5132157328763891, 'step': 2849500}
INFO:transformers.trainer:{'loss': 3.175344701528549, 'learning_rate': 4.144490355794754e-05, 'epoch': 0.5133057865231476, 'step': 2850000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2850000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2850000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2850000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2750000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.191489813685417, 'learning_rate': 4.14434026638349e-05, 'epoch': 0.513395840169906, 'step': 2850500}
INFO:transformers.trainer:{'loss': 3.1205162086486817, 'learning_rate': 4.144190176972226e-05, 'epoch': 0.5134858938166644, 'step': 2851000}
INFO:transformers.trainer:{'loss': 3.188238804578781, 'learning_rate': 4.144040087560962e-05, 'epoch': 0.5135759474634229, 'step': 2851500}
INFO:transformers.trainer:{'loss': 3.1521741058826445, 'learning_rate': 4.143889998149698e-05, 'epoch': 0.5136660011101813, 'step': 2852000}
INFO:transformers.trainer:{'loss': 3.1613920398950577, 'learning_rate': 4.143739908738434e-05, 'epoch': 0.5137560547569398, 'step': 2852500}
INFO:transformers.trainer:{'loss': 3.1757424179315565, 'learning_rate': 4.14358981932717e-05, 'epoch': 0.5138461084036983, 'step': 2853000}
INFO:transformers.trainer:{'loss': 3.2267529520988463, 'learning_rate': 4.1434397299159056e-05, 'epoch': 0.5139361620504567, 'step': 2853500}
INFO:transformers.trainer:{'loss': 3.232834667444229, 'learning_rate': 4.1432896405046415e-05, 'epoch': 0.5140262156972152, 'step': 2854000}
INFO:transformers.trainer:{'loss': 3.1633310519456863, 'learning_rate': 4.1431395510933774e-05, 'epoch': 0.5141162693439736, 'step': 2854500}
INFO:transformers.trainer:{'loss': 3.1551551468372345, 'learning_rate': 4.1429894616821134e-05, 'epoch': 0.514206322990732, 'step': 2855000}
INFO:transformers.trainer:{'loss': 3.172039091348648, 'learning_rate': 4.142839372270849e-05, 'epoch': 0.5142963766374905, 'step': 2855500}
INFO:transformers.trainer:{'loss': 3.1569051537513735, 'learning_rate': 4.142689282859585e-05, 'epoch': 0.5143864302842489, 'step': 2856000}
INFO:transformers.trainer:{'loss': 3.1472558240890502, 'learning_rate': 4.142539193448321e-05, 'epoch': 0.5144764839310074, 'step': 2856500}
INFO:transformers.trainer:{'loss': 3.1530305025577543, 'learning_rate': 4.142389104037057e-05, 'epoch': 0.5145665375777658, 'step': 2857000}
INFO:transformers.trainer:{'loss': 3.2470720558166506, 'learning_rate': 4.1422390146257936e-05, 'epoch': 0.5146565912245242, 'step': 2857500}
INFO:transformers.trainer:{'loss': 3.1121574485301973, 'learning_rate': 4.142088925214529e-05, 'epoch': 0.5147466448712827, 'step': 2858000}
INFO:transformers.trainer:{'loss': 3.1521254012584685, 'learning_rate': 4.1419388358032654e-05, 'epoch': 0.5148366985180411, 'step': 2858500}
INFO:transformers.trainer:{'loss': 3.1426932817697524, 'learning_rate': 4.1417887463920006e-05, 'epoch': 0.5149267521647997, 'step': 2859000}
INFO:transformers.trainer:{'loss': 3.167824404716492, 'learning_rate': 4.141638656980737e-05, 'epoch': 0.5150168058115581, 'step': 2859500}
INFO:transformers.trainer:{'loss': 3.2171972916126252, 'learning_rate': 4.1414885675694724e-05, 'epoch': 0.5151068594583165, 'step': 2860000}
INFO:transformers.trainer:{'loss': 3.1852718031406404, 'learning_rate': 4.141338478158209e-05, 'epoch': 0.515196913105075, 'step': 2860500}
INFO:transformers.trainer:{'loss': 3.202894855737686, 'learning_rate': 4.141188388746944e-05, 'epoch': 0.5152869667518334, 'step': 2861000}
INFO:transformers.trainer:{'loss': 3.1840913707017897, 'learning_rate': 4.141038299335681e-05, 'epoch': 0.5153770203985919, 'step': 2861500}
INFO:transformers.trainer:{'loss': 3.2178868527412416, 'learning_rate': 4.140888209924416e-05, 'epoch': 0.5154670740453503, 'step': 2862000}
INFO:transformers.trainer:{'loss': 3.2195204167366027, 'learning_rate': 4.1407381205131526e-05, 'epoch': 0.5155571276921087, 'step': 2862500}
INFO:transformers.trainer:{'loss': 3.167957551240921, 'learning_rate': 4.140588031101888e-05, 'epoch': 0.5156471813388672, 'step': 2863000}
INFO:transformers.trainer:{'loss': 3.1808478486537934, 'learning_rate': 4.1404379416906244e-05, 'epoch': 0.5157372349856256, 'step': 2863500}
INFO:transformers.trainer:{'loss': 3.112047378540039, 'learning_rate': 4.14028785227936e-05, 'epoch': 0.515827288632384, 'step': 2864000}
INFO:transformers.trainer:{'loss': 3.141574939489365, 'learning_rate': 4.140137762868096e-05, 'epoch': 0.5159173422791425, 'step': 2864500}
INFO:transformers.trainer:{'loss': 3.132283180952072, 'learning_rate': 4.139987673456832e-05, 'epoch': 0.516007395925901, 'step': 2865000}
INFO:transformers.trainer:{'loss': 3.1999256529808044, 'learning_rate': 4.139837584045568e-05, 'epoch': 0.5160974495726595, 'step': 2865500}
INFO:transformers.trainer:{'loss': 3.1006976010799407, 'learning_rate': 4.139687494634304e-05, 'epoch': 0.5161875032194179, 'step': 2866000}
INFO:transformers.trainer:{'loss': 3.1463008372187615, 'learning_rate': 4.13953740522304e-05, 'epoch': 0.5162775568661763, 'step': 2866500}
INFO:transformers.trainer:{'loss': 3.160941093444824, 'learning_rate': 4.139387315811776e-05, 'epoch': 0.5163676105129348, 'step': 2867000}
INFO:transformers.trainer:{'loss': 3.133226266860962, 'learning_rate': 4.1392372264005117e-05, 'epoch': 0.5164576641596932, 'step': 2867500}
INFO:transformers.trainer:{'loss': 3.1602790319919585, 'learning_rate': 4.1390871369892476e-05, 'epoch': 0.5165477178064517, 'step': 2868000}
INFO:transformers.trainer:{'loss': 3.2059994440078734, 'learning_rate': 4.1389370475779835e-05, 'epoch': 0.5166377714532101, 'step': 2868500}
INFO:transformers.trainer:{'loss': 3.137250292301178, 'learning_rate': 4.1387869581667194e-05, 'epoch': 0.5167278250999685, 'step': 2869000}
INFO:transformers.trainer:{'loss': 3.216237134695053, 'learning_rate': 4.138636868755455e-05, 'epoch': 0.516817878746727, 'step': 2869500}
INFO:transformers.trainer:{'loss': 3.2107594858407973, 'learning_rate': 4.138486779344191e-05, 'epoch': 0.5169079323934854, 'step': 2870000}
INFO:transformers.trainer:{'loss': 3.1547673220634462, 'learning_rate': 4.138336689932927e-05, 'epoch': 0.5169979860402439, 'step': 2870500}
INFO:transformers.trainer:{'loss': 3.1571231570243836, 'learning_rate': 4.138186600521663e-05, 'epoch': 0.5170880396870023, 'step': 2871000}
INFO:transformers.trainer:{'loss': 3.1795312614440916, 'learning_rate': 4.138036511110399e-05, 'epoch': 0.5171780933337607, 'step': 2871500}
INFO:transformers.trainer:{'loss': 3.15579980802536, 'learning_rate': 4.137886421699135e-05, 'epoch': 0.5172681469805193, 'step': 2872000}
INFO:transformers.trainer:{'loss': 3.177414432287216, 'learning_rate': 4.137736332287871e-05, 'epoch': 0.5173582006272777, 'step': 2872500}
INFO:transformers.trainer:{'loss': 3.181326080083847, 'learning_rate': 4.1375862428766066e-05, 'epoch': 0.5174482542740362, 'step': 2873000}
INFO:transformers.trainer:{'loss': 3.1527813863754273, 'learning_rate': 4.1374361534653425e-05, 'epoch': 0.5175383079207946, 'step': 2873500}
INFO:transformers.trainer:{'loss': 3.1453765600919725, 'learning_rate': 4.1372860640540784e-05, 'epoch': 0.517628361567553, 'step': 2874000}
INFO:transformers.trainer:{'loss': 3.1833464047908784, 'learning_rate': 4.137135974642814e-05, 'epoch': 0.5177184152143115, 'step': 2874500}
INFO:transformers.trainer:{'loss': 3.2033660299777984, 'learning_rate': 4.13698588523155e-05, 'epoch': 0.5178084688610699, 'step': 2875000}
INFO:transformers.trainer:{'loss': 3.177765503406525, 'learning_rate': 4.136835795820286e-05, 'epoch': 0.5178985225078284, 'step': 2875500}
INFO:transformers.trainer:{'loss': 3.117844393014908, 'learning_rate': 4.136685706409022e-05, 'epoch': 0.5179885761545868, 'step': 2876000}
INFO:transformers.trainer:{'loss': 3.174818798661232, 'learning_rate': 4.136535616997758e-05, 'epoch': 0.5180786298013452, 'step': 2876500}
INFO:transformers.trainer:{'loss': 3.1897056195735933, 'learning_rate': 4.136385527586494e-05, 'epoch': 0.5181686834481037, 'step': 2877000}
INFO:transformers.trainer:{'loss': 3.233892433166504, 'learning_rate': 4.13623543817523e-05, 'epoch': 0.5182587370948621, 'step': 2877500}
INFO:transformers.trainer:{'loss': 3.1877385103702545, 'learning_rate': 4.1360853487639663e-05, 'epoch': 0.5183487907416205, 'step': 2878000}
INFO:transformers.trainer:{'loss': 3.2161296167373656, 'learning_rate': 4.1359352593527016e-05, 'epoch': 0.5184388443883791, 'step': 2878500}
INFO:transformers.trainer:{'loss': 3.1549082789421083, 'learning_rate': 4.135785169941438e-05, 'epoch': 0.5185288980351375, 'step': 2879000}
INFO:transformers.trainer:{'loss': 3.189640896320343, 'learning_rate': 4.1356350805301734e-05, 'epoch': 0.518618951681896, 'step': 2879500}
INFO:transformers.trainer:{'loss': 3.1991056022644044, 'learning_rate': 4.13548499111891e-05, 'epoch': 0.5187090053286544, 'step': 2880000}
INFO:transformers.trainer:{'loss': 3.141984278798103, 'learning_rate': 4.135334901707645e-05, 'epoch': 0.5187990589754128, 'step': 2880500}
INFO:transformers.trainer:{'loss': 3.179205497741699, 'learning_rate': 4.135184812296382e-05, 'epoch': 0.5188891126221713, 'step': 2881000}
INFO:transformers.trainer:{'loss': 3.1792782771587373, 'learning_rate': 4.135034722885117e-05, 'epoch': 0.5189791662689297, 'step': 2881500}
INFO:transformers.trainer:{'loss': 3.193135504722595, 'learning_rate': 4.1348846334738536e-05, 'epoch': 0.5190692199156882, 'step': 2882000}
INFO:transformers.trainer:{'loss': 3.2039449071884154, 'learning_rate': 4.134734544062589e-05, 'epoch': 0.5191592735624466, 'step': 2882500}
INFO:transformers.trainer:{'loss': 3.1755123817920685, 'learning_rate': 4.1345844546513254e-05, 'epoch': 0.519249327209205, 'step': 2883000}
INFO:transformers.trainer:{'loss': 3.182458226442337, 'learning_rate': 4.1344343652400606e-05, 'epoch': 0.5193393808559635, 'step': 2883500}
INFO:transformers.trainer:{'loss': 3.1683037185668947, 'learning_rate': 4.134284275828797e-05, 'epoch': 0.5194294345027219, 'step': 2884000}
INFO:transformers.trainer:{'loss': 3.162523190498352, 'learning_rate': 4.1341341864175324e-05, 'epoch': 0.5195194881494805, 'step': 2884500}
INFO:transformers.trainer:{'loss': 3.1326226618289947, 'learning_rate': 4.133984097006269e-05, 'epoch': 0.5196095417962389, 'step': 2885000}
INFO:transformers.trainer:{'loss': 3.1950194875001907, 'learning_rate': 4.133834007595005e-05, 'epoch': 0.5196995954429973, 'step': 2885500}
INFO:transformers.trainer:{'loss': 3.1538162953853606, 'learning_rate': 4.133683918183741e-05, 'epoch': 0.5197896490897558, 'step': 2886000}
INFO:transformers.trainer:{'loss': 3.1914413744211196, 'learning_rate': 4.133533828772477e-05, 'epoch': 0.5198797027365142, 'step': 2886500}
INFO:transformers.trainer:{'loss': 3.206624169111252, 'learning_rate': 4.1333837393612126e-05, 'epoch': 0.5199697563832727, 'step': 2887000}
INFO:transformers.trainer:{'loss': 3.21880735373497, 'learning_rate': 4.1332336499499485e-05, 'epoch': 0.5200598100300311, 'step': 2887500}
INFO:transformers.trainer:{'loss': 3.2081658179759978, 'learning_rate': 4.1330835605386844e-05, 'epoch': 0.5201498636767895, 'step': 2888000}
INFO:transformers.trainer:{'loss': 3.1725605524778366, 'learning_rate': 4.1329334711274203e-05, 'epoch': 0.520239917323548, 'step': 2888500}
INFO:transformers.trainer:{'loss': 3.223859282493591, 'learning_rate': 4.132783381716156e-05, 'epoch': 0.5203299709703064, 'step': 2889000}
INFO:transformers.trainer:{'loss': 3.1849211794137955, 'learning_rate': 4.132633292304892e-05, 'epoch': 0.5204200246170648, 'step': 2889500}
INFO:transformers.trainer:{'loss': 3.2183627483844757, 'learning_rate': 4.132483202893628e-05, 'epoch': 0.5205100782638233, 'step': 2890000}
INFO:transformers.trainer:{'loss': 3.167123565196991, 'learning_rate': 4.132333113482364e-05, 'epoch': 0.5206001319105817, 'step': 2890500}
INFO:transformers.trainer:{'loss': 3.1809072861671446, 'learning_rate': 4.1321830240711e-05, 'epoch': 0.5206901855573403, 'step': 2891000}
INFO:transformers.trainer:{'loss': 3.1517089803218843, 'learning_rate': 4.132032934659836e-05, 'epoch': 0.5207802392040987, 'step': 2891500}
INFO:transformers.trainer:{'loss': 3.185851699590683, 'learning_rate': 4.131882845248572e-05, 'epoch': 0.5208702928508571, 'step': 2892000}
INFO:transformers.trainer:{'loss': 3.1253875176906587, 'learning_rate': 4.1317327558373076e-05, 'epoch': 0.5209603464976156, 'step': 2892500}
INFO:transformers.trainer:{'loss': 3.2065258736610414, 'learning_rate': 4.1315826664260435e-05, 'epoch': 0.521050400144374, 'step': 2893000}
INFO:transformers.trainer:{'loss': 3.172264438867569, 'learning_rate': 4.1314325770147794e-05, 'epoch': 0.5211404537911325, 'step': 2893500}
INFO:transformers.trainer:{'loss': 3.212624598145485, 'learning_rate': 4.131282487603515e-05, 'epoch': 0.5212305074378909, 'step': 2894000}
INFO:transformers.trainer:{'loss': 3.234142917752266, 'learning_rate': 4.131132398192251e-05, 'epoch': 0.5213205610846493, 'step': 2894500}
INFO:transformers.trainer:{'loss': 3.1572659927606583, 'learning_rate': 4.130982308780987e-05, 'epoch': 0.5214106147314078, 'step': 2895000}
INFO:transformers.trainer:{'loss': 3.1645764899253845, 'learning_rate': 4.130832219369723e-05, 'epoch': 0.5215006683781662, 'step': 2895500}
INFO:transformers.trainer:{'loss': 3.204822041273117, 'learning_rate': 4.130682129958459e-05, 'epoch': 0.5215907220249247, 'step': 2896000}
INFO:transformers.trainer:{'loss': 3.1470568749904633, 'learning_rate': 4.130532040547195e-05, 'epoch': 0.5216807756716831, 'step': 2896500}
INFO:transformers.trainer:{'loss': 3.206460602760315, 'learning_rate': 4.130381951135931e-05, 'epoch': 0.5217708293184415, 'step': 2897000}
INFO:transformers.trainer:{'loss': 3.1384552479982375, 'learning_rate': 4.1302318617246666e-05, 'epoch': 0.5218608829652001, 'step': 2897500}
INFO:transformers.trainer:{'loss': 3.1494010254144666, 'learning_rate': 4.1300817723134025e-05, 'epoch': 0.5219509366119585, 'step': 2898000}
INFO:transformers.trainer:{'loss': 3.2071982667446135, 'learning_rate': 4.1299316829021384e-05, 'epoch': 0.522040990258717, 'step': 2898500}
INFO:transformers.trainer:{'loss': 3.2119150829315184, 'learning_rate': 4.1297815934908744e-05, 'epoch': 0.5221310439054754, 'step': 2899000}
INFO:transformers.trainer:{'loss': 3.252827239513397, 'learning_rate': 4.129631504079611e-05, 'epoch': 0.5222210975522338, 'step': 2899500}
INFO:transformers.trainer:{'loss': 3.176713825583458, 'learning_rate': 4.129481414668346e-05, 'epoch': 0.5223111511989923, 'step': 2900000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2900000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2900000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2900000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2800000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.185548245668411, 'learning_rate': 4.129331325257083e-05, 'epoch': 0.5224012048457507, 'step': 2900500}
INFO:transformers.trainer:{'loss': 3.266370431661606, 'learning_rate': 4.129181235845818e-05, 'epoch': 0.5224912584925091, 'step': 2901000}
INFO:transformers.trainer:{'loss': 3.1728188617229462, 'learning_rate': 4.1290311464345546e-05, 'epoch': 0.5225813121392676, 'step': 2901500}
INFO:transformers.trainer:{'loss': 3.2322545832395555, 'learning_rate': 4.12888105702329e-05, 'epoch': 0.522671365786026, 'step': 2902000}
INFO:transformers.trainer:{'loss': 3.125592857837677, 'learning_rate': 4.1287309676120264e-05, 'epoch': 0.5227614194327845, 'step': 2902500}
INFO:transformers.trainer:{'loss': 3.1970894147157667, 'learning_rate': 4.1285808782007616e-05, 'epoch': 0.5228514730795429, 'step': 2903000}
INFO:transformers.trainer:{'loss': 3.234407190322876, 'learning_rate': 4.128430788789498e-05, 'epoch': 0.5229415267263013, 'step': 2903500}
INFO:transformers.trainer:{'loss': 3.148507432937622, 'learning_rate': 4.1282806993782334e-05, 'epoch': 0.5230315803730599, 'step': 2904000}
INFO:transformers.trainer:{'loss': 3.1524962157011034, 'learning_rate': 4.12813060996697e-05, 'epoch': 0.5231216340198183, 'step': 2904500}
INFO:transformers.trainer:{'loss': 3.1775873479843137, 'learning_rate': 4.127980520555705e-05, 'epoch': 0.5232116876665768, 'step': 2905000}
INFO:transformers.trainer:{'loss': 3.1794499216079712, 'learning_rate': 4.127830431144442e-05, 'epoch': 0.5233017413133352, 'step': 2905500}
INFO:transformers.trainer:{'loss': 3.194080964565277, 'learning_rate': 4.127680341733178e-05, 'epoch': 0.5233917949600936, 'step': 2906000}
INFO:transformers.trainer:{'loss': 3.173025423526764, 'learning_rate': 4.1275302523219136e-05, 'epoch': 0.5234818486068521, 'step': 2906500}
INFO:transformers.trainer:{'loss': 3.1779362626075747, 'learning_rate': 4.1273801629106495e-05, 'epoch': 0.5235719022536105, 'step': 2907000}
INFO:transformers.trainer:{'loss': 3.1437636942863465, 'learning_rate': 4.1272300734993854e-05, 'epoch': 0.523661955900369, 'step': 2907500}
INFO:transformers.trainer:{'loss': 3.1583668794631956, 'learning_rate': 4.127079984088121e-05, 'epoch': 0.5237520095471274, 'step': 2908000}
INFO:transformers.trainer:{'loss': 3.166489839553833, 'learning_rate': 4.126929894676857e-05, 'epoch': 0.5238420631938858, 'step': 2908500}
INFO:transformers.trainer:{'loss': 3.1529660859107973, 'learning_rate': 4.126779805265593e-05, 'epoch': 0.5239321168406443, 'step': 2909000}
INFO:transformers.trainer:{'loss': 3.1958743493556976, 'learning_rate': 4.126629715854329e-05, 'epoch': 0.5240221704874027, 'step': 2909500}
INFO:transformers.trainer:{'loss': 3.1538087384700777, 'learning_rate': 4.126479626443065e-05, 'epoch': 0.5241122241341613, 'step': 2910000}
INFO:transformers.trainer:{'loss': 3.182061432361603, 'learning_rate': 4.126329537031801e-05, 'epoch': 0.5242022777809197, 'step': 2910500}
INFO:transformers.trainer:{'loss': 3.112062973022461, 'learning_rate': 4.126179447620537e-05, 'epoch': 0.5242923314276781, 'step': 2911000}
INFO:transformers.trainer:{'loss': 3.1895216162204743, 'learning_rate': 4.1260293582092727e-05, 'epoch': 0.5243823850744366, 'step': 2911500}
INFO:transformers.trainer:{'loss': 3.173097455024719, 'learning_rate': 4.1258792687980086e-05, 'epoch': 0.524472438721195, 'step': 2912000}
INFO:transformers.trainer:{'loss': 3.1961147286891936, 'learning_rate': 4.1257291793867445e-05, 'epoch': 0.5245624923679535, 'step': 2912500}
INFO:transformers.trainer:{'loss': 3.18312291097641, 'learning_rate': 4.1255790899754804e-05, 'epoch': 0.5246525460147119, 'step': 2913000}
INFO:transformers.trainer:{'loss': 3.163097706437111, 'learning_rate': 4.125429000564216e-05, 'epoch': 0.5247425996614703, 'step': 2913500}
INFO:transformers.trainer:{'loss': 3.1357398717403413, 'learning_rate': 4.125278911152952e-05, 'epoch': 0.5248326533082288, 'step': 2914000}
INFO:transformers.trainer:{'loss': 3.1397625465393064, 'learning_rate': 4.125128821741688e-05, 'epoch': 0.5249227069549872, 'step': 2914500}
INFO:transformers.trainer:{'loss': 3.189454162120819, 'learning_rate': 4.124978732330424e-05, 'epoch': 0.5250127606017456, 'step': 2915000}
INFO:transformers.trainer:{'loss': 3.216157250404358, 'learning_rate': 4.12482864291916e-05, 'epoch': 0.5251028142485041, 'step': 2915500}
INFO:transformers.trainer:{'loss': 3.1811389820575715, 'learning_rate': 4.124678553507896e-05, 'epoch': 0.5251928678952625, 'step': 2916000}
INFO:transformers.trainer:{'loss': 3.1867719547748568, 'learning_rate': 4.124528464096632e-05, 'epoch': 0.525282921542021, 'step': 2916500}
INFO:transformers.trainer:{'loss': 3.179856085896492, 'learning_rate': 4.1243783746853676e-05, 'epoch': 0.5253729751887795, 'step': 2917000}
INFO:transformers.trainer:{'loss': 3.1585224120616915, 'learning_rate': 4.1242282852741035e-05, 'epoch': 0.5254630288355379, 'step': 2917500}
INFO:transformers.trainer:{'loss': 3.23046009683609, 'learning_rate': 4.1240781958628394e-05, 'epoch': 0.5255530824822964, 'step': 2918000}
INFO:transformers.trainer:{'loss': 3.2166214587688446, 'learning_rate': 4.123928106451575e-05, 'epoch': 0.5256431361290548, 'step': 2918500}
INFO:transformers.trainer:{'loss': 3.189798095703125, 'learning_rate': 4.123778017040311e-05, 'epoch': 0.5257331897758133, 'step': 2919000}
INFO:transformers.trainer:{'loss': 3.2248538172245027, 'learning_rate': 4.123627927629047e-05, 'epoch': 0.5258232434225717, 'step': 2919500}
INFO:transformers.trainer:{'loss': 3.1512580991983414, 'learning_rate': 4.123477838217784e-05, 'epoch': 0.5259132970693301, 'step': 2920000}
INFO:transformers.trainer:{'loss': 3.1382120648622513, 'learning_rate': 4.123327748806519e-05, 'epoch': 0.5260033507160886, 'step': 2920500}
INFO:transformers.trainer:{'loss': 3.1824329929351807, 'learning_rate': 4.1231776593952555e-05, 'epoch': 0.526093404362847, 'step': 2921000}
INFO:transformers.trainer:{'loss': 3.1917321951389312, 'learning_rate': 4.123027569983991e-05, 'epoch': 0.5261834580096055, 'step': 2921500}
INFO:transformers.trainer:{'loss': 3.1301958585977556, 'learning_rate': 4.122877480572727e-05, 'epoch': 0.5262735116563639, 'step': 2922000}
INFO:transformers.trainer:{'loss': 3.199126530647278, 'learning_rate': 4.1227273911614626e-05, 'epoch': 0.5263635653031223, 'step': 2922500}
INFO:transformers.trainer:{'loss': 3.2339139077663424, 'learning_rate': 4.122577301750199e-05, 'epoch': 0.5264536189498809, 'step': 2923000}
INFO:transformers.trainer:{'loss': 3.184922945737839, 'learning_rate': 4.1224272123389344e-05, 'epoch': 0.5265436725966393, 'step': 2923500}
INFO:transformers.trainer:{'loss': 3.202725643157959, 'learning_rate': 4.122277122927671e-05, 'epoch': 0.5266337262433978, 'step': 2924000}
INFO:transformers.trainer:{'loss': 3.1957486617565154, 'learning_rate': 4.122127033516406e-05, 'epoch': 0.5267237798901562, 'step': 2924500}
INFO:transformers.trainer:{'loss': 3.2328157937526703, 'learning_rate': 4.121976944105143e-05, 'epoch': 0.5268138335369146, 'step': 2925000}
INFO:transformers.trainer:{'loss': 3.182039347410202, 'learning_rate': 4.121826854693878e-05, 'epoch': 0.5269038871836731, 'step': 2925500}
INFO:transformers.trainer:{'loss': 3.1715846719741823, 'learning_rate': 4.1216767652826146e-05, 'epoch': 0.5269939408304315, 'step': 2926000}
INFO:transformers.trainer:{'loss': 3.158808819293976, 'learning_rate': 4.1215266758713505e-05, 'epoch': 0.5270839944771899, 'step': 2926500}
INFO:transformers.trainer:{'loss': 3.1252747659683227, 'learning_rate': 4.1213765864600864e-05, 'epoch': 0.5271740481239484, 'step': 2927000}
INFO:transformers.trainer:{'loss': 3.2096538698673247, 'learning_rate': 4.121226497048822e-05, 'epoch': 0.5272641017707068, 'step': 2927500}
INFO:transformers.trainer:{'loss': 3.091790458679199, 'learning_rate': 4.121076407637558e-05, 'epoch': 0.5273541554174653, 'step': 2928000}
INFO:transformers.trainer:{'loss': 3.1567064340114595, 'learning_rate': 4.120926318226294e-05, 'epoch': 0.5274442090642237, 'step': 2928500}
INFO:transformers.trainer:{'loss': 3.1569878410100936, 'learning_rate': 4.12077622881503e-05, 'epoch': 0.5275342627109821, 'step': 2929000}
INFO:transformers.trainer:{'loss': 3.1757356511354446, 'learning_rate': 4.120626139403766e-05, 'epoch': 0.5276243163577407, 'step': 2929500}
INFO:transformers.trainer:{'loss': 3.1504689617156982, 'learning_rate': 4.120476049992502e-05, 'epoch': 0.5277143700044991, 'step': 2930000}
INFO:transformers.trainer:{'loss': 3.200951366186142, 'learning_rate': 4.120325960581238e-05, 'epoch': 0.5278044236512576, 'step': 2930500}
INFO:transformers.trainer:{'loss': 3.125773545742035, 'learning_rate': 4.1201758711699736e-05, 'epoch': 0.527894477298016, 'step': 2931000}
INFO:transformers.trainer:{'loss': 3.2186838042736055, 'learning_rate': 4.1200257817587095e-05, 'epoch': 0.5279845309447744, 'step': 2931500}
INFO:transformers.trainer:{'loss': 3.2019982199668884, 'learning_rate': 4.1198756923474454e-05, 'epoch': 0.5280745845915329, 'step': 2932000}
INFO:transformers.trainer:{'loss': 3.16592167031765, 'learning_rate': 4.1197256029361813e-05, 'epoch': 0.5281646382382913, 'step': 2932500}
INFO:transformers.trainer:{'loss': 3.124050454378128, 'learning_rate': 4.119575513524917e-05, 'epoch': 0.5282546918850498, 'step': 2933000}
INFO:transformers.trainer:{'loss': 3.1876683280467986, 'learning_rate': 4.119425424113653e-05, 'epoch': 0.5283447455318082, 'step': 2933500}
INFO:transformers.trainer:{'loss': 3.134669060230255, 'learning_rate': 4.119275334702389e-05, 'epoch': 0.5284347991785666, 'step': 2934000}
INFO:transformers.trainer:{'loss': 3.2009309413433074, 'learning_rate': 4.119125245291125e-05, 'epoch': 0.5285248528253251, 'step': 2934500}
INFO:transformers.trainer:{'loss': 3.159200773715973, 'learning_rate': 4.118975155879861e-05, 'epoch': 0.5286149064720835, 'step': 2935000}
INFO:transformers.trainer:{'loss': 3.1389759848117826, 'learning_rate': 4.118825066468597e-05, 'epoch': 0.528704960118842, 'step': 2935500}
INFO:transformers.trainer:{'loss': 3.1830622305870055, 'learning_rate': 4.118674977057333e-05, 'epoch': 0.5287950137656005, 'step': 2936000}
INFO:transformers.trainer:{'loss': 3.151230579137802, 'learning_rate': 4.1185248876460686e-05, 'epoch': 0.5288850674123589, 'step': 2936500}
INFO:transformers.trainer:{'loss': 3.1389265320301054, 'learning_rate': 4.1183747982348045e-05, 'epoch': 0.5289751210591174, 'step': 2937000}
INFO:transformers.trainer:{'loss': 3.1565015807151795, 'learning_rate': 4.1182247088235404e-05, 'epoch': 0.5290651747058758, 'step': 2937500}
INFO:transformers.trainer:{'loss': 3.1618594423532485, 'learning_rate': 4.118074619412276e-05, 'epoch': 0.5291552283526342, 'step': 2938000}
INFO:transformers.trainer:{'loss': 3.1991712234020233, 'learning_rate': 4.117924530001012e-05, 'epoch': 0.5292452819993927, 'step': 2938500}
INFO:transformers.trainer:{'loss': 3.1538938014507294, 'learning_rate': 4.117774440589748e-05, 'epoch': 0.5293353356461511, 'step': 2939000}
INFO:transformers.trainer:{'loss': 3.173773451805115, 'learning_rate': 4.117624351178484e-05, 'epoch': 0.5294253892929096, 'step': 2939500}
INFO:transformers.trainer:{'loss': 3.1846662724018096, 'learning_rate': 4.11747426176722e-05, 'epoch': 0.529515442939668, 'step': 2940000}
INFO:transformers.trainer:{'loss': 3.162986977338791, 'learning_rate': 4.1173241723559565e-05, 'epoch': 0.5296054965864264, 'step': 2940500}
INFO:transformers.trainer:{'loss': 3.1611665885448454, 'learning_rate': 4.117174082944692e-05, 'epoch': 0.5296955502331849, 'step': 2941000}
INFO:transformers.trainer:{'loss': 3.1721310670375824, 'learning_rate': 4.117023993533428e-05, 'epoch': 0.5297856038799433, 'step': 2941500}
INFO:transformers.trainer:{'loss': 3.192619218349457, 'learning_rate': 4.1168739041221635e-05, 'epoch': 0.5298756575267018, 'step': 2942000}
INFO:transformers.trainer:{'loss': 3.1416563642024995, 'learning_rate': 4.1167238147109e-05, 'epoch': 0.5299657111734603, 'step': 2942500}
INFO:transformers.trainer:{'loss': 3.1488739266395567, 'learning_rate': 4.1165737252996353e-05, 'epoch': 0.5300557648202187, 'step': 2943000}
INFO:transformers.trainer:{'loss': 3.169901098251343, 'learning_rate': 4.116423635888372e-05, 'epoch': 0.5301458184669772, 'step': 2943500}
INFO:transformers.trainer:{'loss': 3.175975422024727, 'learning_rate': 4.116273546477107e-05, 'epoch': 0.5302358721137356, 'step': 2944000}
INFO:transformers.trainer:{'loss': 3.205944767475128, 'learning_rate': 4.116123457065844e-05, 'epoch': 0.5303259257604941, 'step': 2944500}
INFO:transformers.trainer:{'loss': 3.1112342715263366, 'learning_rate': 4.115973367654579e-05, 'epoch': 0.5304159794072525, 'step': 2945000}
INFO:transformers.trainer:{'loss': 3.146444606304169, 'learning_rate': 4.1158232782433155e-05, 'epoch': 0.5305060330540109, 'step': 2945500}
INFO:transformers.trainer:{'loss': 3.135360726118088, 'learning_rate': 4.115673188832051e-05, 'epoch': 0.5305960867007694, 'step': 2946000}
INFO:transformers.trainer:{'loss': 3.184603040456772, 'learning_rate': 4.1155230994207874e-05, 'epoch': 0.5306861403475278, 'step': 2946500}
INFO:transformers.trainer:{'loss': 3.0936888556480406, 'learning_rate': 4.1153730100095226e-05, 'epoch': 0.5307761939942863, 'step': 2947000}
INFO:transformers.trainer:{'loss': 3.111335488796234, 'learning_rate': 4.115222920598259e-05, 'epoch': 0.5308662476410447, 'step': 2947500}
INFO:transformers.trainer:{'loss': 3.176616007566452, 'learning_rate': 4.115072831186995e-05, 'epoch': 0.5309563012878031, 'step': 2948000}
INFO:transformers.trainer:{'loss': 3.1564361369609832, 'learning_rate': 4.114922741775731e-05, 'epoch': 0.5310463549345616, 'step': 2948500}
INFO:transformers.trainer:{'loss': 3.135039360046387, 'learning_rate': 4.114772652364467e-05, 'epoch': 0.53113640858132, 'step': 2949000}
INFO:transformers.trainer:{'loss': 3.227342265367508, 'learning_rate': 4.114622562953203e-05, 'epoch': 0.5312264622280786, 'step': 2949500}
INFO:transformers.trainer:{'loss': 3.1144135608673094, 'learning_rate': 4.114472473541939e-05, 'epoch': 0.531316515874837, 'step': 2950000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-2950000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2950000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-2950000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2850000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.131310207366943, 'learning_rate': 4.1143223841306746e-05, 'epoch': 0.5314065695215954, 'step': 2950500}
INFO:transformers.trainer:{'loss': 3.16082319688797, 'learning_rate': 4.1141722947194105e-05, 'epoch': 0.5314966231683539, 'step': 2951000}
INFO:transformers.trainer:{'loss': 3.1451242127418517, 'learning_rate': 4.1140222053081464e-05, 'epoch': 0.5315866768151123, 'step': 2951500}
INFO:transformers.trainer:{'loss': 3.2069520637989046, 'learning_rate': 4.113872115896882e-05, 'epoch': 0.5316767304618707, 'step': 2952000}
INFO:transformers.trainer:{'loss': 3.1246767815351486, 'learning_rate': 4.113722026485618e-05, 'epoch': 0.5317667841086292, 'step': 2952500}
INFO:transformers.trainer:{'loss': 3.137694795846939, 'learning_rate': 4.113571937074354e-05, 'epoch': 0.5318568377553876, 'step': 2953000}
INFO:transformers.trainer:{'loss': 3.2247116737365724, 'learning_rate': 4.11342184766309e-05, 'epoch': 0.5319468914021461, 'step': 2953500}
INFO:transformers.trainer:{'loss': 3.1862196085453034, 'learning_rate': 4.113271758251826e-05, 'epoch': 0.5320369450489045, 'step': 2954000}
INFO:transformers.trainer:{'loss': 3.146351980924606, 'learning_rate': 4.113121668840562e-05, 'epoch': 0.5321269986956629, 'step': 2954500}
INFO:transformers.trainer:{'loss': 3.1854487581253053, 'learning_rate': 4.112971579429298e-05, 'epoch': 0.5322170523424214, 'step': 2955000}
INFO:transformers.trainer:{'loss': 3.230098200559616, 'learning_rate': 4.1128214900180336e-05, 'epoch': 0.5323071059891799, 'step': 2955500}
INFO:transformers.trainer:{'loss': 3.23810804605484, 'learning_rate': 4.1126714006067696e-05, 'epoch': 0.5323971596359384, 'step': 2956000}
INFO:transformers.trainer:{'loss': 3.1947501710653303, 'learning_rate': 4.1125213111955055e-05, 'epoch': 0.5324872132826968, 'step': 2956500}
INFO:transformers.trainer:{'loss': 3.1430927896499634, 'learning_rate': 4.1123712217842414e-05, 'epoch': 0.5325772669294552, 'step': 2957000}
INFO:transformers.trainer:{'loss': 3.2178925273418426, 'learning_rate': 4.112221132372977e-05, 'epoch': 0.5326673205762137, 'step': 2957500}
INFO:transformers.trainer:{'loss': 3.1409703645706175, 'learning_rate': 4.112071042961713e-05, 'epoch': 0.5327573742229721, 'step': 2958000}
INFO:transformers.trainer:{'loss': 3.1803759632110595, 'learning_rate': 4.111920953550449e-05, 'epoch': 0.5328474278697306, 'step': 2958500}
INFO:transformers.trainer:{'loss': 3.2695460382699966, 'learning_rate': 4.111770864139185e-05, 'epoch': 0.532937481516489, 'step': 2959000}
INFO:transformers.trainer:{'loss': 3.172545756816864, 'learning_rate': 4.111620774727921e-05, 'epoch': 0.5330275351632474, 'step': 2959500}
INFO:transformers.trainer:{'loss': 3.1860022991895676, 'learning_rate': 4.111470685316657e-05, 'epoch': 0.5331175888100059, 'step': 2960000}
INFO:transformers.trainer:{'loss': 3.214360083818436, 'learning_rate': 4.111320595905393e-05, 'epoch': 0.5332076424567643, 'step': 2960500}
INFO:transformers.trainer:{'loss': 3.107859618186951, 'learning_rate': 4.1111705064941286e-05, 'epoch': 0.5332976961035228, 'step': 2961000}
INFO:transformers.trainer:{'loss': 3.1435139696598053, 'learning_rate': 4.1110204170828645e-05, 'epoch': 0.5333877497502812, 'step': 2961500}
INFO:transformers.trainer:{'loss': 3.1531247134208678, 'learning_rate': 4.110870327671601e-05, 'epoch': 0.5334778033970397, 'step': 2962000}
INFO:transformers.trainer:{'loss': 3.1544676544666292, 'learning_rate': 4.110720238260336e-05, 'epoch': 0.5335678570437982, 'step': 2962500}
INFO:transformers.trainer:{'loss': 3.149999181985855, 'learning_rate': 4.110570148849073e-05, 'epoch': 0.5336579106905566, 'step': 2963000}
INFO:transformers.trainer:{'loss': 3.142416187763214, 'learning_rate': 4.110420059437808e-05, 'epoch': 0.533747964337315, 'step': 2963500}
INFO:transformers.trainer:{'loss': 3.1297241748571394, 'learning_rate': 4.110269970026545e-05, 'epoch': 0.5338380179840735, 'step': 2964000}
INFO:transformers.trainer:{'loss': 3.164658471107483, 'learning_rate': 4.11011988061528e-05, 'epoch': 0.5339280716308319, 'step': 2964500}
INFO:transformers.trainer:{'loss': 3.184975371718407, 'learning_rate': 4.1099697912040165e-05, 'epoch': 0.5340181252775904, 'step': 2965000}
INFO:transformers.trainer:{'loss': 3.1339222843647003, 'learning_rate': 4.109819701792752e-05, 'epoch': 0.5341081789243488, 'step': 2965500}
INFO:transformers.trainer:{'loss': 3.2111433132886886, 'learning_rate': 4.109669612381488e-05, 'epoch': 0.5341982325711072, 'step': 2966000}
INFO:transformers.trainer:{'loss': 3.187769401550293, 'learning_rate': 4.1095195229702236e-05, 'epoch': 0.5342882862178657, 'step': 2966500}
INFO:transformers.trainer:{'loss': 3.1318068612813947, 'learning_rate': 4.10936943355896e-05, 'epoch': 0.5343783398646241, 'step': 2967000}
INFO:transformers.trainer:{'loss': 3.1657775330543516, 'learning_rate': 4.1092193441476954e-05, 'epoch': 0.5344683935113826, 'step': 2967500}
INFO:transformers.trainer:{'loss': 3.18249086022377, 'learning_rate': 4.109069254736432e-05, 'epoch': 0.534558447158141, 'step': 2968000}
INFO:transformers.trainer:{'loss': 3.2075136934518813, 'learning_rate': 4.108919165325168e-05, 'epoch': 0.5346485008048995, 'step': 2968500}
INFO:transformers.trainer:{'loss': 3.074984843492508, 'learning_rate': 4.108769075913904e-05, 'epoch': 0.534738554451658, 'step': 2969000}
INFO:transformers.trainer:{'loss': 3.1431539754867552, 'learning_rate': 4.10861898650264e-05, 'epoch': 0.5348286080984164, 'step': 2969500}
INFO:transformers.trainer:{'loss': 3.168740291595459, 'learning_rate': 4.1084688970913756e-05, 'epoch': 0.5349186617451749, 'step': 2970000}
INFO:transformers.trainer:{'loss': 3.188949618816376, 'learning_rate': 4.1083188076801115e-05, 'epoch': 0.5350087153919333, 'step': 2970500}
INFO:transformers.trainer:{'loss': 3.1741264526844026, 'learning_rate': 4.1081687182688474e-05, 'epoch': 0.5350987690386917, 'step': 2971000}
INFO:transformers.trainer:{'loss': 3.1192759511470793, 'learning_rate': 4.108018628857583e-05, 'epoch': 0.5351888226854502, 'step': 2971500}
INFO:transformers.trainer:{'loss': 3.173710183620453, 'learning_rate': 4.107868539446319e-05, 'epoch': 0.5352788763322086, 'step': 2972000}
INFO:transformers.trainer:{'loss': 3.1825512280464174, 'learning_rate': 4.107718450035055e-05, 'epoch': 0.5353689299789671, 'step': 2972500}
INFO:transformers.trainer:{'loss': 3.161253257751465, 'learning_rate': 4.107568360623791e-05, 'epoch': 0.5354589836257255, 'step': 2973000}
INFO:transformers.trainer:{'loss': 3.1432685117721557, 'learning_rate': 4.107418271212527e-05, 'epoch': 0.5355490372724839, 'step': 2973500}
INFO:transformers.trainer:{'loss': 3.196253876686096, 'learning_rate': 4.107268181801263e-05, 'epoch': 0.5356390909192424, 'step': 2974000}
INFO:transformers.trainer:{'loss': 3.203404541015625, 'learning_rate': 4.107118092389999e-05, 'epoch': 0.5357291445660008, 'step': 2974500}
INFO:transformers.trainer:{'loss': 3.1836075944900513, 'learning_rate': 4.106968002978735e-05, 'epoch': 0.5358191982127593, 'step': 2975000}
INFO:transformers.trainer:{'loss': 3.205452135920525, 'learning_rate': 4.1068179135674705e-05, 'epoch': 0.5359092518595178, 'step': 2975500}
INFO:transformers.trainer:{'loss': 3.190004481911659, 'learning_rate': 4.1066678241562064e-05, 'epoch': 0.5359993055062762, 'step': 2976000}
INFO:transformers.trainer:{'loss': 3.138774823665619, 'learning_rate': 4.106517734744942e-05, 'epoch': 0.5360893591530347, 'step': 2976500}
INFO:transformers.trainer:{'loss': 3.1459924010038374, 'learning_rate': 4.106367645333678e-05, 'epoch': 0.5361794127997931, 'step': 2977000}
INFO:transformers.trainer:{'loss': 3.1295593633651735, 'learning_rate': 4.106217555922414e-05, 'epoch': 0.5362694664465515, 'step': 2977500}
INFO:transformers.trainer:{'loss': 3.1784080560207366, 'learning_rate': 4.10606746651115e-05, 'epoch': 0.53635952009331, 'step': 2978000}
INFO:transformers.trainer:{'loss': 3.2064661232233047, 'learning_rate': 4.105917377099886e-05, 'epoch': 0.5364495737400684, 'step': 2978500}
INFO:transformers.trainer:{'loss': 3.0754304344654084, 'learning_rate': 4.105767287688622e-05, 'epoch': 0.5365396273868269, 'step': 2979000}
INFO:transformers.trainer:{'loss': 3.094698751449585, 'learning_rate': 4.105617198277358e-05, 'epoch': 0.5366296810335853, 'step': 2979500}
INFO:transformers.trainer:{'loss': 3.104941017985344, 'learning_rate': 4.105467108866094e-05, 'epoch': 0.5367197346803437, 'step': 2980000}
INFO:transformers.trainer:{'loss': 3.149350911736488, 'learning_rate': 4.1053170194548296e-05, 'epoch': 0.5368097883271022, 'step': 2980500}
INFO:transformers.trainer:{'loss': 3.055184649705887, 'learning_rate': 4.1051669300435655e-05, 'epoch': 0.5368998419738606, 'step': 2981000}
INFO:transformers.trainer:{'loss': 3.143453286409378, 'learning_rate': 4.1050168406323014e-05, 'epoch': 0.5369898956206192, 'step': 2981500}
INFO:transformers.trainer:{'loss': 3.126012101173401, 'learning_rate': 4.104866751221037e-05, 'epoch': 0.5370799492673776, 'step': 2982000}
INFO:transformers.trainer:{'loss': 3.1756902196407317, 'learning_rate': 4.104716661809774e-05, 'epoch': 0.537170002914136, 'step': 2982500}
INFO:transformers.trainer:{'loss': 3.141347205400467, 'learning_rate': 4.104566572398509e-05, 'epoch': 0.5372600565608945, 'step': 2983000}
INFO:transformers.trainer:{'loss': 3.218366036295891, 'learning_rate': 4.104416482987246e-05, 'epoch': 0.5373501102076529, 'step': 2983500}
INFO:transformers.trainer:{'loss': 3.0766200127601624, 'learning_rate': 4.104266393575981e-05, 'epoch': 0.5374401638544114, 'step': 2984000}
INFO:transformers.trainer:{'loss': 3.167066409111023, 'learning_rate': 4.1041163041647175e-05, 'epoch': 0.5375302175011698, 'step': 2984500}
INFO:transformers.trainer:{'loss': 3.168973495721817, 'learning_rate': 4.103966214753453e-05, 'epoch': 0.5376202711479282, 'step': 2985000}
INFO:transformers.trainer:{'loss': 3.1175515179634092, 'learning_rate': 4.103816125342189e-05, 'epoch': 0.5377103247946867, 'step': 2985500}
INFO:transformers.trainer:{'loss': 3.1471295025348662, 'learning_rate': 4.1036660359309245e-05, 'epoch': 0.5378003784414451, 'step': 2986000}
INFO:transformers.trainer:{'loss': 3.220403949022293, 'learning_rate': 4.103515946519661e-05, 'epoch': 0.5378904320882035, 'step': 2986500}
INFO:transformers.trainer:{'loss': 3.1555663998126984, 'learning_rate': 4.1033658571083963e-05, 'epoch': 0.537980485734962, 'step': 2987000}
INFO:transformers.trainer:{'loss': 3.1808784701824186, 'learning_rate': 4.103215767697133e-05, 'epoch': 0.5380705393817204, 'step': 2987500}
INFO:transformers.trainer:{'loss': 3.235906319856644, 'learning_rate': 4.103065678285868e-05, 'epoch': 0.538160593028479, 'step': 2988000}
INFO:transformers.trainer:{'loss': 3.129697893857956, 'learning_rate': 4.102915588874605e-05, 'epoch': 0.5382506466752374, 'step': 2988500}
INFO:transformers.trainer:{'loss': 3.2275758464336395, 'learning_rate': 4.1027654994633406e-05, 'epoch': 0.5383407003219958, 'step': 2989000}
INFO:transformers.trainer:{'loss': 3.216599328279495, 'learning_rate': 4.1026154100520765e-05, 'epoch': 0.5384307539687543, 'step': 2989500}
INFO:transformers.trainer:{'loss': 3.1818487894535066, 'learning_rate': 4.1024653206408124e-05, 'epoch': 0.5385208076155127, 'step': 2990000}
INFO:transformers.trainer:{'loss': 3.1723358051776884, 'learning_rate': 4.1023152312295484e-05, 'epoch': 0.5386108612622712, 'step': 2990500}
INFO:transformers.trainer:{'loss': 3.12425132727623, 'learning_rate': 4.102165141818284e-05, 'epoch': 0.5387009149090296, 'step': 2991000}
INFO:transformers.trainer:{'loss': 3.076231492161751, 'learning_rate': 4.10201505240702e-05, 'epoch': 0.538790968555788, 'step': 2991500}
INFO:transformers.trainer:{'loss': 3.21178785610199, 'learning_rate': 4.101864962995756e-05, 'epoch': 0.5388810222025465, 'step': 2992000}
INFO:transformers.trainer:{'loss': 3.17803933429718, 'learning_rate': 4.101714873584492e-05, 'epoch': 0.5389710758493049, 'step': 2992500}
INFO:transformers.trainer:{'loss': 3.1254015040397642, 'learning_rate': 4.101564784173228e-05, 'epoch': 0.5390611294960634, 'step': 2993000}
INFO:transformers.trainer:{'loss': 3.2057507939338685, 'learning_rate': 4.101414694761964e-05, 'epoch': 0.5391511831428218, 'step': 2993500}
INFO:transformers.trainer:{'loss': 3.179776422381401, 'learning_rate': 4.1012646053507e-05, 'epoch': 0.5392412367895802, 'step': 2994000}
INFO:transformers.trainer:{'loss': 3.184961587190628, 'learning_rate': 4.1011145159394356e-05, 'epoch': 0.5393312904363388, 'step': 2994500}
INFO:transformers.trainer:{'loss': 3.1359095816612244, 'learning_rate': 4.1009644265281715e-05, 'epoch': 0.5394213440830972, 'step': 2995000}
INFO:transformers.trainer:{'loss': 3.1332747015953064, 'learning_rate': 4.1008143371169074e-05, 'epoch': 0.5395113977298557, 'step': 2995500}
INFO:transformers.trainer:{'loss': 3.1876601605415344, 'learning_rate': 4.100664247705643e-05, 'epoch': 0.5396014513766141, 'step': 2996000}
INFO:transformers.trainer:{'loss': 3.1242931213378906, 'learning_rate': 4.10051415829438e-05, 'epoch': 0.5396915050233725, 'step': 2996500}
INFO:transformers.trainer:{'loss': 3.188582580089569, 'learning_rate': 4.100364068883115e-05, 'epoch': 0.539781558670131, 'step': 2997000}
INFO:transformers.trainer:{'loss': 3.1196728105545044, 'learning_rate': 4.100213979471852e-05, 'epoch': 0.5398716123168894, 'step': 2997500}
INFO:transformers.trainer:{'loss': 3.154254407286644, 'learning_rate': 4.100063890060587e-05, 'epoch': 0.5399616659636479, 'step': 2998000}
INFO:transformers.trainer:{'loss': 3.138962136745453, 'learning_rate': 4.0999138006493235e-05, 'epoch': 0.5400517196104063, 'step': 2998500}
INFO:transformers.trainer:{'loss': 3.2111149513721466, 'learning_rate': 4.099763711238059e-05, 'epoch': 0.5401417732571647, 'step': 2999000}
INFO:transformers.trainer:{'loss': 3.250900309085846, 'learning_rate': 4.0996136218267946e-05, 'epoch': 0.5402318269039232, 'step': 2999500}
INFO:transformers.trainer:{'loss': 3.1926591012477874, 'learning_rate': 4.0994635324155305e-05, 'epoch': 0.5403218805506816, 'step': 3000000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3000000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3000000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3000000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2900000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1671463713645935, 'learning_rate': 4.0993134430042665e-05, 'epoch': 0.54041193419744, 'step': 3000500}
INFO:transformers.trainer:{'loss': 3.1536894278526306, 'learning_rate': 4.0991633535930024e-05, 'epoch': 0.5405019878441986, 'step': 3001000}
INFO:transformers.trainer:{'loss': 3.231331463575363, 'learning_rate': 4.099013264181738e-05, 'epoch': 0.540592041490957, 'step': 3001500}
INFO:transformers.trainer:{'loss': 3.1455498876571655, 'learning_rate': 4.098863174770474e-05, 'epoch': 0.5406820951377155, 'step': 3002000}
INFO:transformers.trainer:{'loss': 3.1580689759254454, 'learning_rate': 4.09871308535921e-05, 'epoch': 0.5407721487844739, 'step': 3002500}
INFO:transformers.trainer:{'loss': 3.155046303510666, 'learning_rate': 4.0985629959479467e-05, 'epoch': 0.5408622024312323, 'step': 3003000}
INFO:transformers.trainer:{'loss': 3.118694548845291, 'learning_rate': 4.098412906536682e-05, 'epoch': 0.5409522560779908, 'step': 3003500}
INFO:transformers.trainer:{'loss': 3.1795273940563202, 'learning_rate': 4.0982628171254185e-05, 'epoch': 0.5410423097247492, 'step': 3004000}
INFO:transformers.trainer:{'loss': 3.20225165784359, 'learning_rate': 4.098112727714154e-05, 'epoch': 0.5411323633715077, 'step': 3004500}
INFO:transformers.trainer:{'loss': 3.165663735151291, 'learning_rate': 4.09796263830289e-05, 'epoch': 0.5412224170182661, 'step': 3005000}
INFO:transformers.trainer:{'loss': 3.190672429561615, 'learning_rate': 4.0978125488916255e-05, 'epoch': 0.5413124706650245, 'step': 3005500}
INFO:transformers.trainer:{'loss': 3.1684133052825927, 'learning_rate': 4.097662459480362e-05, 'epoch': 0.541402524311783, 'step': 3006000}
INFO:transformers.trainer:{'loss': 3.1372572500705718, 'learning_rate': 4.097512370069097e-05, 'epoch': 0.5414925779585414, 'step': 3006500}
INFO:transformers.trainer:{'loss': 3.1878676478862764, 'learning_rate': 4.097362280657834e-05, 'epoch': 0.5415826316053, 'step': 3007000}
INFO:transformers.trainer:{'loss': 3.1334085816144945, 'learning_rate': 4.097212191246569e-05, 'epoch': 0.5416726852520584, 'step': 3007500}
INFO:transformers.trainer:{'loss': 3.1652136068344117, 'learning_rate': 4.097062101835306e-05, 'epoch': 0.5417627388988168, 'step': 3008000}
INFO:transformers.trainer:{'loss': 3.1464802502393723, 'learning_rate': 4.096912012424041e-05, 'epoch': 0.5418527925455753, 'step': 3008500}
INFO:transformers.trainer:{'loss': 3.2038801374435426, 'learning_rate': 4.0967619230127775e-05, 'epoch': 0.5419428461923337, 'step': 3009000}
INFO:transformers.trainer:{'loss': 3.1343097190856932, 'learning_rate': 4.096611833601513e-05, 'epoch': 0.5420328998390922, 'step': 3009500}
INFO:transformers.trainer:{'loss': 3.2280377659797668, 'learning_rate': 4.096461744190249e-05, 'epoch': 0.5421229534858506, 'step': 3010000}
INFO:transformers.trainer:{'loss': 3.1356236641407014, 'learning_rate': 4.096311654778985e-05, 'epoch': 0.542213007132609, 'step': 3010500}
INFO:transformers.trainer:{'loss': 3.212500982284546, 'learning_rate': 4.096161565367721e-05, 'epoch': 0.5423030607793675, 'step': 3011000}
INFO:transformers.trainer:{'loss': 3.162449329853058, 'learning_rate': 4.096011475956457e-05, 'epoch': 0.5423931144261259, 'step': 3011500}
INFO:transformers.trainer:{'loss': 3.1430275723934176, 'learning_rate': 4.095861386545193e-05, 'epoch': 0.5424831680728843, 'step': 3012000}
INFO:transformers.trainer:{'loss': 3.098311665058136, 'learning_rate': 4.095711297133929e-05, 'epoch': 0.5425732217196428, 'step': 3012500}
INFO:transformers.trainer:{'loss': 3.139329629898071, 'learning_rate': 4.095561207722665e-05, 'epoch': 0.5426632753664012, 'step': 3013000}
INFO:transformers.trainer:{'loss': 3.1780526167154313, 'learning_rate': 4.095411118311401e-05, 'epoch': 0.5427533290131598, 'step': 3013500}
INFO:transformers.trainer:{'loss': 3.094571283698082, 'learning_rate': 4.0952610289001366e-05, 'epoch': 0.5428433826599182, 'step': 3014000}
INFO:transformers.trainer:{'loss': 3.131476361989975, 'learning_rate': 4.0951109394888725e-05, 'epoch': 0.5429334363066766, 'step': 3014500}
INFO:transformers.trainer:{'loss': 3.1935260491371156, 'learning_rate': 4.0949608500776084e-05, 'epoch': 0.5430234899534351, 'step': 3015000}
INFO:transformers.trainer:{'loss': 3.2148038513660433, 'learning_rate': 4.094810760666344e-05, 'epoch': 0.5431135436001935, 'step': 3015500}
INFO:transformers.trainer:{'loss': 3.12681169462204, 'learning_rate': 4.09466067125508e-05, 'epoch': 0.543203597246952, 'step': 3016000}
INFO:transformers.trainer:{'loss': 3.139738811135292, 'learning_rate': 4.094510581843816e-05, 'epoch': 0.5432936508937104, 'step': 3016500}
INFO:transformers.trainer:{'loss': 3.160078324317932, 'learning_rate': 4.094360492432553e-05, 'epoch': 0.5433837045404688, 'step': 3017000}
INFO:transformers.trainer:{'loss': 3.122388016581535, 'learning_rate': 4.094210403021288e-05, 'epoch': 0.5434737581872273, 'step': 3017500}
INFO:transformers.trainer:{'loss': 3.111876658678055, 'learning_rate': 4.0940603136100245e-05, 'epoch': 0.5435638118339857, 'step': 3018000}
INFO:transformers.trainer:{'loss': 3.199141634941101, 'learning_rate': 4.09391022419876e-05, 'epoch': 0.5436538654807442, 'step': 3018500}
INFO:transformers.trainer:{'loss': 3.1696292538642883, 'learning_rate': 4.093760134787496e-05, 'epoch': 0.5437439191275026, 'step': 3019000}
INFO:transformers.trainer:{'loss': 3.2221578040122987, 'learning_rate': 4.0936100453762315e-05, 'epoch': 0.543833972774261, 'step': 3019500}
INFO:transformers.trainer:{'loss': 3.173159388780594, 'learning_rate': 4.093459955964968e-05, 'epoch': 0.5439240264210196, 'step': 3020000}
INFO:transformers.trainer:{'loss': 3.212110711336136, 'learning_rate': 4.093309866553703e-05, 'epoch': 0.544014080067778, 'step': 3020500}
INFO:transformers.trainer:{'loss': 3.157405606508255, 'learning_rate': 4.09315977714244e-05, 'epoch': 0.5441041337145365, 'step': 3021000}
INFO:transformers.trainer:{'loss': 3.130265022993088, 'learning_rate': 4.093009687731175e-05, 'epoch': 0.5441941873612949, 'step': 3021500}
INFO:transformers.trainer:{'loss': 3.1711977503299713, 'learning_rate': 4.092859598319912e-05, 'epoch': 0.5442842410080533, 'step': 3022000}
INFO:transformers.trainer:{'loss': 3.1766240813732147, 'learning_rate': 4.092709508908647e-05, 'epoch': 0.5443742946548118, 'step': 3022500}
INFO:transformers.trainer:{'loss': 3.161329222202301, 'learning_rate': 4.0925594194973835e-05, 'epoch': 0.5444643483015702, 'step': 3023000}
INFO:transformers.trainer:{'loss': 3.1365986180305483, 'learning_rate': 4.0924093300861194e-05, 'epoch': 0.5445544019483286, 'step': 3023500}
INFO:transformers.trainer:{'loss': 3.2091664185523987, 'learning_rate': 4.092259240674855e-05, 'epoch': 0.5446444555950871, 'step': 3024000}
INFO:transformers.trainer:{'loss': 3.184870607614517, 'learning_rate': 4.092109151263591e-05, 'epoch': 0.5447345092418455, 'step': 3024500}
INFO:transformers.trainer:{'loss': 3.162762652873993, 'learning_rate': 4.0919590618523265e-05, 'epoch': 0.544824562888604, 'step': 3025000}
INFO:transformers.trainer:{'loss': 3.1724591562747957, 'learning_rate': 4.091808972441063e-05, 'epoch': 0.5449146165353624, 'step': 3025500}
INFO:transformers.trainer:{'loss': 3.189871198654175, 'learning_rate': 4.091658883029798e-05, 'epoch': 0.5450046701821208, 'step': 3026000}
INFO:transformers.trainer:{'loss': 3.1514132447242735, 'learning_rate': 4.091508793618535e-05, 'epoch': 0.5450947238288794, 'step': 3026500}
INFO:transformers.trainer:{'loss': 3.1417119405269625, 'learning_rate': 4.09135870420727e-05, 'epoch': 0.5451847774756378, 'step': 3027000}
INFO:transformers.trainer:{'loss': 3.1353274466991423, 'learning_rate': 4.091208614796007e-05, 'epoch': 0.5452748311223963, 'step': 3027500}
INFO:transformers.trainer:{'loss': 3.1829666492938995, 'learning_rate': 4.091058525384742e-05, 'epoch': 0.5453648847691547, 'step': 3028000}
INFO:transformers.trainer:{'loss': 3.1601386878490447, 'learning_rate': 4.0909084359734785e-05, 'epoch': 0.5454549384159131, 'step': 3028500}
INFO:transformers.trainer:{'loss': 3.170632874727249, 'learning_rate': 4.090758346562214e-05, 'epoch': 0.5455449920626716, 'step': 3029000}
INFO:transformers.trainer:{'loss': 3.1649352734088896, 'learning_rate': 4.09060825715095e-05, 'epoch': 0.54563504570943, 'step': 3029500}
INFO:transformers.trainer:{'loss': 3.1491101547479627, 'learning_rate': 4.0904581677396855e-05, 'epoch': 0.5457250993561885, 'step': 3030000}
INFO:transformers.trainer:{'loss': 3.143058390617371, 'learning_rate': 4.090308078328422e-05, 'epoch': 0.5458151530029469, 'step': 3030500}
INFO:transformers.trainer:{'loss': 3.2110596199035646, 'learning_rate': 4.090157988917158e-05, 'epoch': 0.5459052066497053, 'step': 3031000}
INFO:transformers.trainer:{'loss': 3.171464171886444, 'learning_rate': 4.090007899505894e-05, 'epoch': 0.5459952602964638, 'step': 3031500}
INFO:transformers.trainer:{'loss': 3.12931720995903, 'learning_rate': 4.08985781009463e-05, 'epoch': 0.5460853139432222, 'step': 3032000}
INFO:transformers.trainer:{'loss': 3.1680854365825653, 'learning_rate': 4.089707720683366e-05, 'epoch': 0.5461753675899808, 'step': 3032500}
INFO:transformers.trainer:{'loss': 3.108938952088356, 'learning_rate': 4.0895576312721016e-05, 'epoch': 0.5462654212367392, 'step': 3033000}
INFO:transformers.trainer:{'loss': 3.1711280088424685, 'learning_rate': 4.0894075418608375e-05, 'epoch': 0.5463554748834976, 'step': 3033500}
INFO:transformers.trainer:{'loss': 3.1890364515781404, 'learning_rate': 4.0892574524495734e-05, 'epoch': 0.5464455285302561, 'step': 3034000}
INFO:transformers.trainer:{'loss': 3.1925177230834962, 'learning_rate': 4.0891073630383093e-05, 'epoch': 0.5465355821770145, 'step': 3034500}
INFO:transformers.trainer:{'loss': 3.1144481046199797, 'learning_rate': 4.088957273627045e-05, 'epoch': 0.546625635823773, 'step': 3035000}
INFO:transformers.trainer:{'loss': 3.174659250020981, 'learning_rate': 4.088807184215781e-05, 'epoch': 0.5467156894705314, 'step': 3035500}
INFO:transformers.trainer:{'loss': 3.24646342420578, 'learning_rate': 4.088657094804517e-05, 'epoch': 0.5468057431172898, 'step': 3036000}
INFO:transformers.trainer:{'loss': 3.1403882055282595, 'learning_rate': 4.088507005393253e-05, 'epoch': 0.5468957967640483, 'step': 3036500}
INFO:transformers.trainer:{'loss': 3.1849583418369294, 'learning_rate': 4.088356915981989e-05, 'epoch': 0.5469858504108067, 'step': 3037000}
INFO:transformers.trainer:{'loss': 3.1460073977708816, 'learning_rate': 4.0882068265707255e-05, 'epoch': 0.5470759040575651, 'step': 3037500}
INFO:transformers.trainer:{'loss': 3.1877315418720245, 'learning_rate': 4.088056737159461e-05, 'epoch': 0.5471659577043236, 'step': 3038000}
INFO:transformers.trainer:{'loss': 3.126444525718689, 'learning_rate': 4.087906647748197e-05, 'epoch': 0.547256011351082, 'step': 3038500}
INFO:transformers.trainer:{'loss': 3.1691391488313676, 'learning_rate': 4.0877565583369325e-05, 'epoch': 0.5473460649978406, 'step': 3039000}
INFO:transformers.trainer:{'loss': 3.160881994009018, 'learning_rate': 4.087606468925669e-05, 'epoch': 0.547436118644599, 'step': 3039500}
INFO:transformers.trainer:{'loss': 3.2233879742622373, 'learning_rate': 4.087456379514404e-05, 'epoch': 0.5475261722913574, 'step': 3040000}
INFO:transformers.trainer:{'loss': 3.2217806156873703, 'learning_rate': 4.087306290103141e-05, 'epoch': 0.5476162259381159, 'step': 3040500}
INFO:transformers.trainer:{'loss': 3.1813174571990968, 'learning_rate': 4.087156200691876e-05, 'epoch': 0.5477062795848743, 'step': 3041000}
INFO:transformers.trainer:{'loss': 3.1804984407424928, 'learning_rate': 4.087006111280613e-05, 'epoch': 0.5477963332316328, 'step': 3041500}
INFO:transformers.trainer:{'loss': 3.1192244029045106, 'learning_rate': 4.086856021869348e-05, 'epoch': 0.5478863868783912, 'step': 3042000}
INFO:transformers.trainer:{'loss': 3.1543094421625137, 'learning_rate': 4.0867059324580845e-05, 'epoch': 0.5479764405251496, 'step': 3042500}
INFO:transformers.trainer:{'loss': 3.1651261414289475, 'learning_rate': 4.08655584304682e-05, 'epoch': 0.5480664941719081, 'step': 3043000}
INFO:transformers.trainer:{'loss': 3.1649800207614898, 'learning_rate': 4.086405753635556e-05, 'epoch': 0.5481565478186665, 'step': 3043500}
INFO:transformers.trainer:{'loss': 3.121893291950226, 'learning_rate': 4.0862556642242915e-05, 'epoch': 0.548246601465425, 'step': 3044000}
INFO:transformers.trainer:{'loss': 3.1543676385879516, 'learning_rate': 4.086105574813028e-05, 'epoch': 0.5483366551121834, 'step': 3044500}
INFO:transformers.trainer:{'loss': 3.2354711065292356, 'learning_rate': 4.085955485401764e-05, 'epoch': 0.5484267087589418, 'step': 3045000}
INFO:transformers.trainer:{'loss': 3.123039535999298, 'learning_rate': 4.0858053959905e-05, 'epoch': 0.5485167624057004, 'step': 3045500}
INFO:transformers.trainer:{'loss': 3.176746577143669, 'learning_rate': 4.085655306579236e-05, 'epoch': 0.5486068160524588, 'step': 3046000}
INFO:transformers.trainer:{'loss': 3.1080697503089905, 'learning_rate': 4.085505217167972e-05, 'epoch': 0.5486968696992173, 'step': 3046500}
INFO:transformers.trainer:{'loss': 3.1052981374263764, 'learning_rate': 4.0853551277567077e-05, 'epoch': 0.5487869233459757, 'step': 3047000}
INFO:transformers.trainer:{'loss': 3.2078125598430636, 'learning_rate': 4.085205038345443e-05, 'epoch': 0.5488769769927341, 'step': 3047500}
INFO:transformers.trainer:{'loss': 3.1730436058044433, 'learning_rate': 4.0850549489341795e-05, 'epoch': 0.5489670306394926, 'step': 3048000}
INFO:transformers.trainer:{'loss': 3.1420699865818023, 'learning_rate': 4.084904859522915e-05, 'epoch': 0.549057084286251, 'step': 3048500}
INFO:transformers.trainer:{'loss': 3.160711410522461, 'learning_rate': 4.084754770111651e-05, 'epoch': 0.5491471379330094, 'step': 3049000}
INFO:transformers.trainer:{'loss': 3.0964915692806243, 'learning_rate': 4.0846046807003865e-05, 'epoch': 0.5492371915797679, 'step': 3049500}
INFO:transformers.trainer:{'loss': 3.1552074887752535, 'learning_rate': 4.084454591289123e-05, 'epoch': 0.5493272452265263, 'step': 3050000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3050000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3050000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3050000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-2950000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.138232224225998, 'learning_rate': 4.084304501877858e-05, 'epoch': 0.5494172988732848, 'step': 3050500}
INFO:transformers.trainer:{'loss': 3.2151198980808258, 'learning_rate': 4.084154412466595e-05, 'epoch': 0.5495073525200432, 'step': 3051000}
INFO:transformers.trainer:{'loss': 3.1740000183582304, 'learning_rate': 4.084004323055331e-05, 'epoch': 0.5495974061668016, 'step': 3051500}
INFO:transformers.trainer:{'loss': 3.2434074792861938, 'learning_rate': 4.083854233644067e-05, 'epoch': 0.5496874598135602, 'step': 3052000}
INFO:transformers.trainer:{'loss': 3.1518263392448427, 'learning_rate': 4.0837041442328026e-05, 'epoch': 0.5497775134603186, 'step': 3052500}
INFO:transformers.trainer:{'loss': 3.1883458623886107, 'learning_rate': 4.0835540548215385e-05, 'epoch': 0.5498675671070771, 'step': 3053000}
INFO:transformers.trainer:{'loss': 3.2080577340126037, 'learning_rate': 4.0834039654102744e-05, 'epoch': 0.5499576207538355, 'step': 3053500}
INFO:transformers.trainer:{'loss': 3.1605359842777254, 'learning_rate': 4.08325387599901e-05, 'epoch': 0.5500476744005939, 'step': 3054000}
INFO:transformers.trainer:{'loss': 3.174566708803177, 'learning_rate': 4.083103786587746e-05, 'epoch': 0.5501377280473524, 'step': 3054500}
INFO:transformers.trainer:{'loss': 3.1364219439029695, 'learning_rate': 4.082953697176482e-05, 'epoch': 0.5502277816941108, 'step': 3055000}
INFO:transformers.trainer:{'loss': 3.1583013310432433, 'learning_rate': 4.082803607765218e-05, 'epoch': 0.5503178353408693, 'step': 3055500}
INFO:transformers.trainer:{'loss': 3.162069195866585, 'learning_rate': 4.082653518353954e-05, 'epoch': 0.5504078889876277, 'step': 3056000}
INFO:transformers.trainer:{'loss': 3.206043752193451, 'learning_rate': 4.08250342894269e-05, 'epoch': 0.5504979426343861, 'step': 3056500}
INFO:transformers.trainer:{'loss': 3.114312546491623, 'learning_rate': 4.082353339531426e-05, 'epoch': 0.5505879962811446, 'step': 3057000}
INFO:transformers.trainer:{'loss': 3.1966125128269196, 'learning_rate': 4.0822032501201617e-05, 'epoch': 0.550678049927903, 'step': 3057500}
INFO:transformers.trainer:{'loss': 3.199029048204422, 'learning_rate': 4.0820531607088976e-05, 'epoch': 0.5507681035746615, 'step': 3058000}
INFO:transformers.trainer:{'loss': 3.1325225780010224, 'learning_rate': 4.0819030712976335e-05, 'epoch': 0.55085815722142, 'step': 3058500}
INFO:transformers.trainer:{'loss': 3.038512060880661, 'learning_rate': 4.08175298188637e-05, 'epoch': 0.5509482108681784, 'step': 3059000}
INFO:transformers.trainer:{'loss': 3.1755139969587325, 'learning_rate': 4.081602892475105e-05, 'epoch': 0.5510382645149369, 'step': 3059500}
INFO:transformers.trainer:{'loss': 3.1709621100425722, 'learning_rate': 4.081452803063842e-05, 'epoch': 0.5511283181616953, 'step': 3060000}
INFO:transformers.trainer:{'loss': 3.185318152666092, 'learning_rate': 4.081302713652577e-05, 'epoch': 0.5512183718084537, 'step': 3060500}
INFO:transformers.trainer:{'loss': 3.1600941178798676, 'learning_rate': 4.081152624241314e-05, 'epoch': 0.5513084254552122, 'step': 3061000}
INFO:transformers.trainer:{'loss': 3.1799655467271806, 'learning_rate': 4.081002534830049e-05, 'epoch': 0.5513984791019706, 'step': 3061500}
INFO:transformers.trainer:{'loss': 3.1353645565509796, 'learning_rate': 4.0808524454187855e-05, 'epoch': 0.5514885327487291, 'step': 3062000}
INFO:transformers.trainer:{'loss': 3.170481541752815, 'learning_rate': 4.080702356007521e-05, 'epoch': 0.5515785863954875, 'step': 3062500}
INFO:transformers.trainer:{'loss': 3.1811894006729124, 'learning_rate': 4.080552266596257e-05, 'epoch': 0.5516686400422459, 'step': 3063000}
INFO:transformers.trainer:{'loss': 3.16126517534256, 'learning_rate': 4.0804021771849925e-05, 'epoch': 0.5517586936890044, 'step': 3063500}
INFO:transformers.trainer:{'loss': 3.16275191450119, 'learning_rate': 4.080252087773729e-05, 'epoch': 0.5518487473357628, 'step': 3064000}
INFO:transformers.trainer:{'loss': 3.211462270975113, 'learning_rate': 4.080101998362464e-05, 'epoch': 0.5519388009825213, 'step': 3064500}
INFO:transformers.trainer:{'loss': 3.1680116794109345, 'learning_rate': 4.079951908951201e-05, 'epoch': 0.5520288546292798, 'step': 3065000}
INFO:transformers.trainer:{'loss': 3.185737407207489, 'learning_rate': 4.079801819539937e-05, 'epoch': 0.5521189082760382, 'step': 3065500}
INFO:transformers.trainer:{'loss': 3.1790429251194, 'learning_rate': 4.079651730128673e-05, 'epoch': 0.5522089619227967, 'step': 3066000}
INFO:transformers.trainer:{'loss': 3.169626673460007, 'learning_rate': 4.0795016407174086e-05, 'epoch': 0.5522990155695551, 'step': 3066500}
INFO:transformers.trainer:{'loss': 3.156122407197952, 'learning_rate': 4.0793515513061445e-05, 'epoch': 0.5523890692163136, 'step': 3067000}
INFO:transformers.trainer:{'loss': 3.2191548273563386, 'learning_rate': 4.0792014618948804e-05, 'epoch': 0.552479122863072, 'step': 3067500}
INFO:transformers.trainer:{'loss': 3.183542655587196, 'learning_rate': 4.0790513724836163e-05, 'epoch': 0.5525691765098304, 'step': 3068000}
INFO:transformers.trainer:{'loss': 3.125700208902359, 'learning_rate': 4.078901283072352e-05, 'epoch': 0.5526592301565889, 'step': 3068500}
INFO:transformers.trainer:{'loss': 3.1793759043216707, 'learning_rate': 4.078751193661088e-05, 'epoch': 0.5527492838033473, 'step': 3069000}
INFO:transformers.trainer:{'loss': 3.1562230682373045, 'learning_rate': 4.078601104249824e-05, 'epoch': 0.5528393374501058, 'step': 3069500}
INFO:transformers.trainer:{'loss': 3.1783558094501494, 'learning_rate': 4.07845101483856e-05, 'epoch': 0.5529293910968642, 'step': 3070000}
INFO:transformers.trainer:{'loss': 3.1769595963954926, 'learning_rate': 4.078300925427296e-05, 'epoch': 0.5530194447436226, 'step': 3070500}
INFO:transformers.trainer:{'loss': 3.1607764184474947, 'learning_rate': 4.078150836016031e-05, 'epoch': 0.5531094983903811, 'step': 3071000}
INFO:transformers.trainer:{'loss': 3.104261902213097, 'learning_rate': 4.078000746604768e-05, 'epoch': 0.5531995520371396, 'step': 3071500}
INFO:transformers.trainer:{'loss': 3.1791771719455717, 'learning_rate': 4.077850657193503e-05, 'epoch': 0.5532896056838981, 'step': 3072000}
INFO:transformers.trainer:{'loss': 3.1648214528560636, 'learning_rate': 4.0777005677822395e-05, 'epoch': 0.5533796593306565, 'step': 3072500}
INFO:transformers.trainer:{'loss': 3.2368139421939848, 'learning_rate': 4.0775504783709754e-05, 'epoch': 0.5534697129774149, 'step': 3073000}
INFO:transformers.trainer:{'loss': 3.133508135557175, 'learning_rate': 4.077400388959711e-05, 'epoch': 0.5535597666241734, 'step': 3073500}
INFO:transformers.trainer:{'loss': 3.1238994451761246, 'learning_rate': 4.077250299548447e-05, 'epoch': 0.5536498202709318, 'step': 3074000}
INFO:transformers.trainer:{'loss': 3.1613400704860686, 'learning_rate': 4.077100210137183e-05, 'epoch': 0.5537398739176902, 'step': 3074500}
INFO:transformers.trainer:{'loss': 3.103738076210022, 'learning_rate': 4.076950120725919e-05, 'epoch': 0.5538299275644487, 'step': 3075000}
INFO:transformers.trainer:{'loss': 3.16029612326622, 'learning_rate': 4.076800031314655e-05, 'epoch': 0.5539199812112071, 'step': 3075500}
INFO:transformers.trainer:{'loss': 3.162524028301239, 'learning_rate': 4.076649941903391e-05, 'epoch': 0.5540100348579656, 'step': 3076000}
INFO:transformers.trainer:{'loss': 3.1474260597229002, 'learning_rate': 4.076499852492127e-05, 'epoch': 0.554100088504724, 'step': 3076500}
INFO:transformers.trainer:{'loss': 3.1890137641429903, 'learning_rate': 4.0763497630808626e-05, 'epoch': 0.5541901421514824, 'step': 3077000}
INFO:transformers.trainer:{'loss': 3.129184447646141, 'learning_rate': 4.0761996736695985e-05, 'epoch': 0.554280195798241, 'step': 3077500}
INFO:transformers.trainer:{'loss': 3.2102128312587737, 'learning_rate': 4.0760495842583344e-05, 'epoch': 0.5543702494449994, 'step': 3078000}
INFO:transformers.trainer:{'loss': 3.1486736898422243, 'learning_rate': 4.0758994948470703e-05, 'epoch': 0.5544603030917579, 'step': 3078500}
INFO:transformers.trainer:{'loss': 3.2259482955932617, 'learning_rate': 4.075749405435806e-05, 'epoch': 0.5545503567385163, 'step': 3079000}
INFO:transformers.trainer:{'loss': 3.1127573153972627, 'learning_rate': 4.075599316024543e-05, 'epoch': 0.5546404103852747, 'step': 3079500}
INFO:transformers.trainer:{'loss': 3.146689513206482, 'learning_rate': 4.075449226613278e-05, 'epoch': 0.5547304640320332, 'step': 3080000}
INFO:transformers.trainer:{'loss': 3.188790480852127, 'learning_rate': 4.0752991372020146e-05, 'epoch': 0.5548205176787916, 'step': 3080500}
INFO:transformers.trainer:{'loss': 3.137579098343849, 'learning_rate': 4.07514904779075e-05, 'epoch': 0.5549105713255501, 'step': 3081000}
INFO:transformers.trainer:{'loss': 3.1520201894044875, 'learning_rate': 4.0749989583794865e-05, 'epoch': 0.5550006249723085, 'step': 3081500}
INFO:transformers.trainer:{'loss': 3.1746517219543455, 'learning_rate': 4.074848868968222e-05, 'epoch': 0.5550906786190669, 'step': 3082000}
INFO:transformers.trainer:{'loss': 3.172142392396927, 'learning_rate': 4.074698779556958e-05, 'epoch': 0.5551807322658254, 'step': 3082500}
INFO:transformers.trainer:{'loss': 3.1740236883163453, 'learning_rate': 4.0745486901456935e-05, 'epoch': 0.5552707859125838, 'step': 3083000}
INFO:transformers.trainer:{'loss': 3.1511535618305206, 'learning_rate': 4.07439860073443e-05, 'epoch': 0.5553608395593423, 'step': 3083500}
INFO:transformers.trainer:{'loss': 3.176824326515198, 'learning_rate': 4.074248511323165e-05, 'epoch': 0.5554508932061007, 'step': 3084000}
INFO:transformers.trainer:{'loss': 3.149479737997055, 'learning_rate': 4.074098421911902e-05, 'epoch': 0.5555409468528592, 'step': 3084500}
INFO:transformers.trainer:{'loss': 3.1572629721164702, 'learning_rate': 4.073948332500637e-05, 'epoch': 0.5556310004996177, 'step': 3085000}
INFO:transformers.trainer:{'loss': 3.1822133733034135, 'learning_rate': 4.073798243089374e-05, 'epoch': 0.5557210541463761, 'step': 3085500}
INFO:transformers.trainer:{'loss': 3.167148362874985, 'learning_rate': 4.0736481536781096e-05, 'epoch': 0.5558111077931345, 'step': 3086000}
INFO:transformers.trainer:{'loss': 3.186903935670853, 'learning_rate': 4.0734980642668455e-05, 'epoch': 0.555901161439893, 'step': 3086500}
INFO:transformers.trainer:{'loss': 3.1737761070728303, 'learning_rate': 4.0733479748555814e-05, 'epoch': 0.5559912150866514, 'step': 3087000}
INFO:transformers.trainer:{'loss': 3.121458653926849, 'learning_rate': 4.073197885444317e-05, 'epoch': 0.5560812687334099, 'step': 3087500}
INFO:transformers.trainer:{'loss': 3.198845148563385, 'learning_rate': 4.073047796033053e-05, 'epoch': 0.5561713223801683, 'step': 3088000}
INFO:transformers.trainer:{'loss': 3.092090885281563, 'learning_rate': 4.072897706621789e-05, 'epoch': 0.5562613760269267, 'step': 3088500}
INFO:transformers.trainer:{'loss': 3.198425134062767, 'learning_rate': 4.072747617210525e-05, 'epoch': 0.5563514296736852, 'step': 3089000}
INFO:transformers.trainer:{'loss': 3.141634020328522, 'learning_rate': 4.072597527799261e-05, 'epoch': 0.5564414833204436, 'step': 3089500}
INFO:transformers.trainer:{'loss': 3.159337344646454, 'learning_rate': 4.072447438387997e-05, 'epoch': 0.5565315369672021, 'step': 3090000}
INFO:transformers.trainer:{'loss': 3.166637307405472, 'learning_rate': 4.072297348976733e-05, 'epoch': 0.5566215906139605, 'step': 3090500}
INFO:transformers.trainer:{'loss': 3.079614195585251, 'learning_rate': 4.0721472595654686e-05, 'epoch': 0.556711644260719, 'step': 3091000}
INFO:transformers.trainer:{'loss': 3.139307846903801, 'learning_rate': 4.0719971701542046e-05, 'epoch': 0.5568016979074775, 'step': 3091500}
INFO:transformers.trainer:{'loss': 3.1987883796691894, 'learning_rate': 4.0718470807429405e-05, 'epoch': 0.5568917515542359, 'step': 3092000}
INFO:transformers.trainer:{'loss': 3.1432219157218935, 'learning_rate': 4.0716969913316764e-05, 'epoch': 0.5569818052009944, 'step': 3092500}
INFO:transformers.trainer:{'loss': 3.1545300259590148, 'learning_rate': 4.071546901920412e-05, 'epoch': 0.5570718588477528, 'step': 3093000}
INFO:transformers.trainer:{'loss': 3.1252856090068817, 'learning_rate': 4.071396812509148e-05, 'epoch': 0.5571619124945112, 'step': 3093500}
INFO:transformers.trainer:{'loss': 3.1391657643318176, 'learning_rate': 4.071246723097884e-05, 'epoch': 0.5572519661412697, 'step': 3094000}
INFO:transformers.trainer:{'loss': 3.1299035651683806, 'learning_rate': 4.07109663368662e-05, 'epoch': 0.5573420197880281, 'step': 3094500}
INFO:transformers.trainer:{'loss': 3.0971454219818115, 'learning_rate': 4.070946544275356e-05, 'epoch': 0.5574320734347866, 'step': 3095000}
INFO:transformers.trainer:{'loss': 3.1397111659049988, 'learning_rate': 4.070796454864092e-05, 'epoch': 0.557522127081545, 'step': 3095500}
INFO:transformers.trainer:{'loss': 3.2053099317550657, 'learning_rate': 4.070646365452828e-05, 'epoch': 0.5576121807283034, 'step': 3096000}
INFO:transformers.trainer:{'loss': 3.1804058413505554, 'learning_rate': 4.0704962760415636e-05, 'epoch': 0.557702234375062, 'step': 3096500}
INFO:transformers.trainer:{'loss': 3.1074034185409545, 'learning_rate': 4.0703461866302995e-05, 'epoch': 0.5577922880218203, 'step': 3097000}
INFO:transformers.trainer:{'loss': 3.1932681612968445, 'learning_rate': 4.0701960972190354e-05, 'epoch': 0.5578823416685788, 'step': 3097500}
INFO:transformers.trainer:{'loss': 3.1518579666614532, 'learning_rate': 4.070046007807771e-05, 'epoch': 0.5579723953153373, 'step': 3098000}
INFO:transformers.trainer:{'loss': 3.209070039510727, 'learning_rate': 4.069895918396507e-05, 'epoch': 0.5580624489620957, 'step': 3098500}
INFO:transformers.trainer:{'loss': 3.215112763881683, 'learning_rate': 4.069745828985243e-05, 'epoch': 0.5581525026088542, 'step': 3099000}
INFO:transformers.trainer:{'loss': 3.2091142649650575, 'learning_rate': 4.069595739573979e-05, 'epoch': 0.5582425562556126, 'step': 3099500}
INFO:transformers.trainer:{'loss': 3.2122750852108, 'learning_rate': 4.0694456501627156e-05, 'epoch': 0.558332609902371, 'step': 3100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3100000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3000000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.166253448724747, 'learning_rate': 4.069295560751451e-05, 'epoch': 0.5584226635491295, 'step': 3100500}
INFO:transformers.trainer:{'loss': 3.191863303184509, 'learning_rate': 4.0691454713401874e-05, 'epoch': 0.5585127171958879, 'step': 3101000}
INFO:transformers.trainer:{'loss': 3.1938577655553817, 'learning_rate': 4.0689953819289227e-05, 'epoch': 0.5586027708426464, 'step': 3101500}
INFO:transformers.trainer:{'loss': 3.1627044470310213, 'learning_rate': 4.068845292517659e-05, 'epoch': 0.5586928244894048, 'step': 3102000}
INFO:transformers.trainer:{'loss': 3.180409371137619, 'learning_rate': 4.0686952031063945e-05, 'epoch': 0.5587828781361632, 'step': 3102500}
INFO:transformers.trainer:{'loss': 3.151773087978363, 'learning_rate': 4.068545113695131e-05, 'epoch': 0.5588729317829217, 'step': 3103000}
INFO:transformers.trainer:{'loss': 3.186428388595581, 'learning_rate': 4.068395024283866e-05, 'epoch': 0.5589629854296801, 'step': 3103500}
INFO:transformers.trainer:{'loss': 3.102265827417374, 'learning_rate': 4.068244934872603e-05, 'epoch': 0.5590530390764387, 'step': 3104000}
INFO:transformers.trainer:{'loss': 3.193562518000603, 'learning_rate': 4.068094845461338e-05, 'epoch': 0.5591430927231971, 'step': 3104500}
INFO:transformers.trainer:{'loss': 3.169252392411232, 'learning_rate': 4.067944756050075e-05, 'epoch': 0.5592331463699555, 'step': 3105000}
INFO:transformers.trainer:{'loss': 3.0840117638111115, 'learning_rate': 4.06779466663881e-05, 'epoch': 0.559323200016714, 'step': 3105500}
INFO:transformers.trainer:{'loss': 3.169095495581627, 'learning_rate': 4.0676445772275465e-05, 'epoch': 0.5594132536634724, 'step': 3106000}
INFO:transformers.trainer:{'loss': 3.191930486679077, 'learning_rate': 4.067494487816282e-05, 'epoch': 0.5595033073102309, 'step': 3106500}
INFO:transformers.trainer:{'loss': 3.2128543634414672, 'learning_rate': 4.067344398405018e-05, 'epoch': 0.5595933609569893, 'step': 3107000}
INFO:transformers.trainer:{'loss': 3.2199516047239305, 'learning_rate': 4.067194308993754e-05, 'epoch': 0.5596834146037477, 'step': 3107500}
INFO:transformers.trainer:{'loss': 3.2118006505966186, 'learning_rate': 4.06704421958249e-05, 'epoch': 0.5597734682505062, 'step': 3108000}
INFO:transformers.trainer:{'loss': 3.224127975702286, 'learning_rate': 4.066894130171226e-05, 'epoch': 0.5598635218972646, 'step': 3108500}
INFO:transformers.trainer:{'loss': 3.1528969569206238, 'learning_rate': 4.066744040759962e-05, 'epoch': 0.559953575544023, 'step': 3109000}
INFO:transformers.trainer:{'loss': 3.2198818600177765, 'learning_rate': 4.066593951348698e-05, 'epoch': 0.5600436291907815, 'step': 3109500}
INFO:transformers.trainer:{'loss': 3.152487949371338, 'learning_rate': 4.066443861937434e-05, 'epoch': 0.56013368283754, 'step': 3110000}
INFO:transformers.trainer:{'loss': 3.1387241464853286, 'learning_rate': 4.0662937725261696e-05, 'epoch': 0.5602237364842985, 'step': 3110500}
INFO:transformers.trainer:{'loss': 3.186606703042984, 'learning_rate': 4.0661436831149055e-05, 'epoch': 0.5603137901310569, 'step': 3111000}
INFO:transformers.trainer:{'loss': 3.183833243370056, 'learning_rate': 4.0659935937036414e-05, 'epoch': 0.5604038437778153, 'step': 3111500}
INFO:transformers.trainer:{'loss': 3.1220898065567018, 'learning_rate': 4.065843504292377e-05, 'epoch': 0.5604938974245738, 'step': 3112000}
INFO:transformers.trainer:{'loss': 3.1565241338014602, 'learning_rate': 4.065693414881113e-05, 'epoch': 0.5605839510713322, 'step': 3112500}
INFO:transformers.trainer:{'loss': 3.1949083926677706, 'learning_rate': 4.065543325469849e-05, 'epoch': 0.5606740047180907, 'step': 3113000}
INFO:transformers.trainer:{'loss': 3.156340847492218, 'learning_rate': 4.065393236058585e-05, 'epoch': 0.5607640583648491, 'step': 3113500}
INFO:transformers.trainer:{'loss': 3.140878376722336, 'learning_rate': 4.065243146647321e-05, 'epoch': 0.5608541120116075, 'step': 3114000}
INFO:transformers.trainer:{'loss': 3.1229121234416963, 'learning_rate': 4.065093057236057e-05, 'epoch': 0.560944165658366, 'step': 3114500}
INFO:transformers.trainer:{'loss': 3.1798229146003725, 'learning_rate': 4.064942967824793e-05, 'epoch': 0.5610342193051244, 'step': 3115000}
INFO:transformers.trainer:{'loss': 3.1904127005338667, 'learning_rate': 4.064792878413529e-05, 'epoch': 0.5611242729518829, 'step': 3115500}
INFO:transformers.trainer:{'loss': 3.1445736136436464, 'learning_rate': 4.0646427890022646e-05, 'epoch': 0.5612143265986413, 'step': 3116000}
INFO:transformers.trainer:{'loss': 3.1803333377838134, 'learning_rate': 4.0644926995910005e-05, 'epoch': 0.5613043802453997, 'step': 3116500}
INFO:transformers.trainer:{'loss': 3.126197422623634, 'learning_rate': 4.0643426101797364e-05, 'epoch': 0.5613944338921583, 'step': 3117000}
INFO:transformers.trainer:{'loss': 3.1290574305057524, 'learning_rate': 4.064192520768472e-05, 'epoch': 0.5614844875389167, 'step': 3117500}
INFO:transformers.trainer:{'loss': 3.1736354489326475, 'learning_rate': 4.064042431357208e-05, 'epoch': 0.5615745411856752, 'step': 3118000}
INFO:transformers.trainer:{'loss': 3.222834617853165, 'learning_rate': 4.063892341945944e-05, 'epoch': 0.5616645948324336, 'step': 3118500}
INFO:transformers.trainer:{'loss': 3.155137684583664, 'learning_rate': 4.06374225253468e-05, 'epoch': 0.561754648479192, 'step': 3119000}
INFO:transformers.trainer:{'loss': 3.088366551876068, 'learning_rate': 4.063592163123416e-05, 'epoch': 0.5618447021259505, 'step': 3119500}
INFO:transformers.trainer:{'loss': 3.1827393133640287, 'learning_rate': 4.063442073712152e-05, 'epoch': 0.5619347557727089, 'step': 3120000}
INFO:transformers.trainer:{'loss': 3.205089929819107, 'learning_rate': 4.063291984300888e-05, 'epoch': 0.5620248094194674, 'step': 3120500}
INFO:transformers.trainer:{'loss': 3.2147700301408766, 'learning_rate': 4.0631418948896236e-05, 'epoch': 0.5621148630662258, 'step': 3121000}
INFO:transformers.trainer:{'loss': 3.1256151847839355, 'learning_rate': 4.06299180547836e-05, 'epoch': 0.5622049167129842, 'step': 3121500}
INFO:transformers.trainer:{'loss': 3.1453515586853027, 'learning_rate': 4.0628417160670954e-05, 'epoch': 0.5622949703597427, 'step': 3122000}
INFO:transformers.trainer:{'loss': 3.1756969804763795, 'learning_rate': 4.062691626655832e-05, 'epoch': 0.5623850240065011, 'step': 3122500}
INFO:transformers.trainer:{'loss': 3.1857753779888154, 'learning_rate': 4.062541537244567e-05, 'epoch': 0.5624750776532595, 'step': 3123000}
INFO:transformers.trainer:{'loss': 3.1952110240459444, 'learning_rate': 4.062391447833304e-05, 'epoch': 0.5625651313000181, 'step': 3123500}
INFO:transformers.trainer:{'loss': 3.1786242394447326, 'learning_rate': 4.062241358422039e-05, 'epoch': 0.5626551849467765, 'step': 3124000}
INFO:transformers.trainer:{'loss': 3.196855168581009, 'learning_rate': 4.0620912690107756e-05, 'epoch': 0.562745238593535, 'step': 3124500}
INFO:transformers.trainer:{'loss': 3.15007392847538, 'learning_rate': 4.061941179599511e-05, 'epoch': 0.5628352922402934, 'step': 3125000}
INFO:transformers.trainer:{'loss': 3.1818632830381395, 'learning_rate': 4.0617910901882474e-05, 'epoch': 0.5629253458870518, 'step': 3125500}
INFO:transformers.trainer:{'loss': 3.1687976064682006, 'learning_rate': 4.061641000776983e-05, 'epoch': 0.5630153995338103, 'step': 3126000}
INFO:transformers.trainer:{'loss': 3.1842155839204787, 'learning_rate': 4.061490911365719e-05, 'epoch': 0.5631054531805687, 'step': 3126500}
INFO:transformers.trainer:{'loss': 3.122583400964737, 'learning_rate': 4.0613408219544545e-05, 'epoch': 0.5631955068273272, 'step': 3127000}
INFO:transformers.trainer:{'loss': 3.1601518714427947, 'learning_rate': 4.061190732543191e-05, 'epoch': 0.5632855604740856, 'step': 3127500}
INFO:transformers.trainer:{'loss': 3.1417261762619018, 'learning_rate': 4.061040643131927e-05, 'epoch': 0.563375614120844, 'step': 3128000}
INFO:transformers.trainer:{'loss': 3.163448035478592, 'learning_rate': 4.060890553720663e-05, 'epoch': 0.5634656677676025, 'step': 3128500}
INFO:transformers.trainer:{'loss': 3.084599884748459, 'learning_rate': 4.060740464309399e-05, 'epoch': 0.5635557214143609, 'step': 3129000}
INFO:transformers.trainer:{'loss': 3.1674095199108123, 'learning_rate': 4.060590374898135e-05, 'epoch': 0.5636457750611195, 'step': 3129500}
INFO:transformers.trainer:{'loss': 3.1776797456741335, 'learning_rate': 4.0604402854868706e-05, 'epoch': 0.5637358287078779, 'step': 3130000}
INFO:transformers.trainer:{'loss': 3.1457383291721346, 'learning_rate': 4.0602901960756065e-05, 'epoch': 0.5638258823546363, 'step': 3130500}
INFO:transformers.trainer:{'loss': 3.1807605719566343, 'learning_rate': 4.0601401066643424e-05, 'epoch': 0.5639159360013948, 'step': 3131000}
INFO:transformers.trainer:{'loss': 3.1302082512378693, 'learning_rate': 4.059990017253078e-05, 'epoch': 0.5640059896481532, 'step': 3131500}
INFO:transformers.trainer:{'loss': 3.1555719192028047, 'learning_rate': 4.059839927841814e-05, 'epoch': 0.5640960432949117, 'step': 3132000}
INFO:transformers.trainer:{'loss': 3.113829800724983, 'learning_rate': 4.05968983843055e-05, 'epoch': 0.5641860969416701, 'step': 3132500}
INFO:transformers.trainer:{'loss': 3.132233212471008, 'learning_rate': 4.059539749019286e-05, 'epoch': 0.5642761505884285, 'step': 3133000}
INFO:transformers.trainer:{'loss': 3.171472345113754, 'learning_rate': 4.059389659608022e-05, 'epoch': 0.564366204235187, 'step': 3133500}
INFO:transformers.trainer:{'loss': 3.1579965453147887, 'learning_rate': 4.059239570196758e-05, 'epoch': 0.5644562578819454, 'step': 3134000}
INFO:transformers.trainer:{'loss': 3.1102203340530394, 'learning_rate': 4.059089480785494e-05, 'epoch': 0.5645463115287038, 'step': 3134500}
INFO:transformers.trainer:{'loss': 3.1758729708194733, 'learning_rate': 4.0589393913742296e-05, 'epoch': 0.5646363651754623, 'step': 3135000}
INFO:transformers.trainer:{'loss': 3.1716980607509613, 'learning_rate': 4.0587893019629655e-05, 'epoch': 0.5647264188222207, 'step': 3135500}
INFO:transformers.trainer:{'loss': 3.1768581962585447, 'learning_rate': 4.0586392125517015e-05, 'epoch': 0.5648164724689793, 'step': 3136000}
INFO:transformers.trainer:{'loss': 3.1925645496845245, 'learning_rate': 4.0584891231404374e-05, 'epoch': 0.5649065261157377, 'step': 3136500}
INFO:transformers.trainer:{'loss': 3.1085042016506197, 'learning_rate': 4.058339033729173e-05, 'epoch': 0.5649965797624961, 'step': 3137000}
INFO:transformers.trainer:{'loss': 3.1864521238803865, 'learning_rate': 4.058188944317909e-05, 'epoch': 0.5650866334092546, 'step': 3137500}
INFO:transformers.trainer:{'loss': 3.118823664903641, 'learning_rate': 4.058038854906645e-05, 'epoch': 0.565176687056013, 'step': 3138000}
INFO:transformers.trainer:{'loss': 3.169583394050598, 'learning_rate': 4.057888765495381e-05, 'epoch': 0.5652667407027715, 'step': 3138500}
INFO:transformers.trainer:{'loss': 3.188135711789131, 'learning_rate': 4.057738676084117e-05, 'epoch': 0.5653567943495299, 'step': 3139000}
INFO:transformers.trainer:{'loss': 3.0750362186431883, 'learning_rate': 4.057588586672853e-05, 'epoch': 0.5654468479962883, 'step': 3139500}
INFO:transformers.trainer:{'loss': 3.135475302696228, 'learning_rate': 4.057438497261589e-05, 'epoch': 0.5655369016430468, 'step': 3140000}
INFO:transformers.trainer:{'loss': 3.1820353766679763, 'learning_rate': 4.0572884078503246e-05, 'epoch': 0.5656269552898052, 'step': 3140500}
INFO:transformers.trainer:{'loss': 3.124747352361679, 'learning_rate': 4.0571383184390605e-05, 'epoch': 0.5657170089365637, 'step': 3141000}
INFO:transformers.trainer:{'loss': 3.202185309648514, 'learning_rate': 4.0569882290277964e-05, 'epoch': 0.5658070625833221, 'step': 3141500}
INFO:transformers.trainer:{'loss': 3.178273003578186, 'learning_rate': 4.056838139616533e-05, 'epoch': 0.5658971162300805, 'step': 3142000}
INFO:transformers.trainer:{'loss': 3.1556774642467498, 'learning_rate': 4.056688050205268e-05, 'epoch': 0.5659871698768391, 'step': 3142500}
INFO:transformers.trainer:{'loss': 3.1805730893611908, 'learning_rate': 4.056537960794005e-05, 'epoch': 0.5660772235235975, 'step': 3143000}
INFO:transformers.trainer:{'loss': 3.0879737572669983, 'learning_rate': 4.05638787138274e-05, 'epoch': 0.566167277170356, 'step': 3143500}
INFO:transformers.trainer:{'loss': 3.2199191710948942, 'learning_rate': 4.0562377819714766e-05, 'epoch': 0.5662573308171144, 'step': 3144000}
INFO:transformers.trainer:{'loss': 3.1812762956619265, 'learning_rate': 4.056087692560212e-05, 'epoch': 0.5663473844638728, 'step': 3144500}
INFO:transformers.trainer:{'loss': 3.157092698931694, 'learning_rate': 4.0559376031489484e-05, 'epoch': 0.5664374381106313, 'step': 3145000}
INFO:transformers.trainer:{'loss': 3.16687552011013, 'learning_rate': 4.0557875137376836e-05, 'epoch': 0.5665274917573897, 'step': 3145500}
INFO:transformers.trainer:{'loss': 3.165959472775459, 'learning_rate': 4.05563742432642e-05, 'epoch': 0.5666175454041481, 'step': 3146000}
INFO:transformers.trainer:{'loss': 3.2104439051151274, 'learning_rate': 4.0554873349151555e-05, 'epoch': 0.5667075990509066, 'step': 3146500}
INFO:transformers.trainer:{'loss': 3.158601744890213, 'learning_rate': 4.055337245503892e-05, 'epoch': 0.566797652697665, 'step': 3147000}
INFO:transformers.trainer:{'loss': 3.1440507192611693, 'learning_rate': 4.055187156092627e-05, 'epoch': 0.5668877063444235, 'step': 3147500}
INFO:transformers.trainer:{'loss': 3.091910520672798, 'learning_rate': 4.055037066681364e-05, 'epoch': 0.5669777599911819, 'step': 3148000}
INFO:transformers.trainer:{'loss': 3.2191111621856687, 'learning_rate': 4.0548869772701e-05, 'epoch': 0.5670678136379403, 'step': 3148500}
INFO:transformers.trainer:{'loss': 3.143776230812073, 'learning_rate': 4.0547368878588357e-05, 'epoch': 0.5671578672846989, 'step': 3149000}
INFO:transformers.trainer:{'loss': 3.1935726494789125, 'learning_rate': 4.0545867984475716e-05, 'epoch': 0.5672479209314573, 'step': 3149500}
INFO:transformers.trainer:{'loss': 3.1513699824810026, 'learning_rate': 4.0544367090363075e-05, 'epoch': 0.5673379745782158, 'step': 3150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3050000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.159920162200928, 'learning_rate': 4.0542866196250434e-05, 'epoch': 0.5674280282249742, 'step': 3150500}
INFO:transformers.trainer:{'loss': 3.2003717263936995, 'learning_rate': 4.054136530213779e-05, 'epoch': 0.5675180818717326, 'step': 3151000}
INFO:transformers.trainer:{'loss': 3.141720479488373, 'learning_rate': 4.053986440802515e-05, 'epoch': 0.5676081355184911, 'step': 3151500}
INFO:transformers.trainer:{'loss': 3.1605129334926607, 'learning_rate': 4.053836351391251e-05, 'epoch': 0.5676981891652495, 'step': 3152000}
INFO:transformers.trainer:{'loss': 3.136517846465111, 'learning_rate': 4.053686261979987e-05, 'epoch': 0.567788242812008, 'step': 3152500}
INFO:transformers.trainer:{'loss': 3.132812247991562, 'learning_rate': 4.053536172568723e-05, 'epoch': 0.5678782964587664, 'step': 3153000}
INFO:transformers.trainer:{'loss': 3.158036422967911, 'learning_rate': 4.053386083157459e-05, 'epoch': 0.5679683501055248, 'step': 3153500}
INFO:transformers.trainer:{'loss': 3.108150596320629, 'learning_rate': 4.053235993746195e-05, 'epoch': 0.5680584037522833, 'step': 3154000}
INFO:transformers.trainer:{'loss': 3.168598075389862, 'learning_rate': 4.0530859043349306e-05, 'epoch': 0.5681484573990417, 'step': 3154500}
INFO:transformers.trainer:{'loss': 3.1626412794589998, 'learning_rate': 4.0529358149236665e-05, 'epoch': 0.5682385110458003, 'step': 3155000}
INFO:transformers.trainer:{'loss': 3.2275897128582, 'learning_rate': 4.0527857255124024e-05, 'epoch': 0.5683285646925587, 'step': 3155500}
INFO:transformers.trainer:{'loss': 3.160427930831909, 'learning_rate': 4.052635636101138e-05, 'epoch': 0.5684186183393171, 'step': 3156000}
INFO:transformers.trainer:{'loss': 3.136564383625984, 'learning_rate': 4.052485546689874e-05, 'epoch': 0.5685086719860756, 'step': 3156500}
INFO:transformers.trainer:{'loss': 3.1457590973377227, 'learning_rate': 4.05233545727861e-05, 'epoch': 0.568598725632834, 'step': 3157000}
INFO:transformers.trainer:{'loss': 3.1045440156459807, 'learning_rate': 4.052185367867346e-05, 'epoch': 0.5686887792795925, 'step': 3157500}
INFO:transformers.trainer:{'loss': 3.145447950601578, 'learning_rate': 4.052035278456082e-05, 'epoch': 0.5687788329263509, 'step': 3158000}
INFO:transformers.trainer:{'loss': 3.141654989719391, 'learning_rate': 4.051885189044818e-05, 'epoch': 0.5688688865731093, 'step': 3158500}
INFO:transformers.trainer:{'loss': 3.2263729612827303, 'learning_rate': 4.051735099633554e-05, 'epoch': 0.5689589402198678, 'step': 3159000}
INFO:transformers.trainer:{'loss': 3.1880257785320283, 'learning_rate': 4.05158501022229e-05, 'epoch': 0.5690489938666262, 'step': 3159500}
INFO:transformers.trainer:{'loss': 3.1354355754852294, 'learning_rate': 4.0514349208110256e-05, 'epoch': 0.5691390475133846, 'step': 3160000}
INFO:transformers.trainer:{'loss': 3.1693206083774568, 'learning_rate': 4.0512848313997615e-05, 'epoch': 0.5692291011601431, 'step': 3160500}
INFO:transformers.trainer:{'loss': 3.1358090608119964, 'learning_rate': 4.0511347419884974e-05, 'epoch': 0.5693191548069015, 'step': 3161000}
INFO:transformers.trainer:{'loss': 3.1754633452892302, 'learning_rate': 4.050984652577233e-05, 'epoch': 0.56940920845366, 'step': 3161500}
INFO:transformers.trainer:{'loss': 3.1788560490608218, 'learning_rate': 4.050834563165969e-05, 'epoch': 0.5694992621004185, 'step': 3162000}
INFO:transformers.trainer:{'loss': 3.1834814598560333, 'learning_rate': 4.050684473754706e-05, 'epoch': 0.5695893157471769, 'step': 3162500}
INFO:transformers.trainer:{'loss': 3.192544627189636, 'learning_rate': 4.050534384343441e-05, 'epoch': 0.5696793693939354, 'step': 3163000}
INFO:transformers.trainer:{'loss': 3.1774681935310363, 'learning_rate': 4.0503842949321776e-05, 'epoch': 0.5697694230406938, 'step': 3163500}
INFO:transformers.trainer:{'loss': 3.116928528547287, 'learning_rate': 4.050234205520913e-05, 'epoch': 0.5698594766874523, 'step': 3164000}
INFO:transformers.trainer:{'loss': 3.1346291093826295, 'learning_rate': 4.0500841161096494e-05, 'epoch': 0.5699495303342107, 'step': 3164500}
INFO:transformers.trainer:{'loss': 3.1608215522766114, 'learning_rate': 4.0499340266983846e-05, 'epoch': 0.5700395839809691, 'step': 3165000}
INFO:transformers.trainer:{'loss': 3.144820797920227, 'learning_rate': 4.049783937287121e-05, 'epoch': 0.5701296376277276, 'step': 3165500}
INFO:transformers.trainer:{'loss': 3.161122566461563, 'learning_rate': 4.0496338478758564e-05, 'epoch': 0.570219691274486, 'step': 3166000}
INFO:transformers.trainer:{'loss': 3.1487541012763978, 'learning_rate': 4.049483758464593e-05, 'epoch': 0.5703097449212445, 'step': 3166500}
INFO:transformers.trainer:{'loss': 3.1734819123744966, 'learning_rate': 4.049333669053328e-05, 'epoch': 0.5703997985680029, 'step': 3167000}
INFO:transformers.trainer:{'loss': 3.1575166325569155, 'learning_rate': 4.049183579642065e-05, 'epoch': 0.5704898522147613, 'step': 3167500}
INFO:transformers.trainer:{'loss': 3.1664675226211547, 'learning_rate': 4.0490334902308e-05, 'epoch': 0.5705799058615199, 'step': 3168000}
INFO:transformers.trainer:{'loss': 3.1431537771224978, 'learning_rate': 4.0488834008195366e-05, 'epoch': 0.5706699595082783, 'step': 3168500}
INFO:transformers.trainer:{'loss': 3.121923660516739, 'learning_rate': 4.048733311408272e-05, 'epoch': 0.5707600131550368, 'step': 3169000}
INFO:transformers.trainer:{'loss': 3.056314589500427, 'learning_rate': 4.0485832219970084e-05, 'epoch': 0.5708500668017952, 'step': 3169500}
INFO:transformers.trainer:{'loss': 3.198946649312973, 'learning_rate': 4.0484331325857443e-05, 'epoch': 0.5709401204485536, 'step': 3170000}
INFO:transformers.trainer:{'loss': 3.122801695108414, 'learning_rate': 4.04828304317448e-05, 'epoch': 0.5710301740953121, 'step': 3170500}
INFO:transformers.trainer:{'loss': 3.160028191566467, 'learning_rate': 4.048132953763216e-05, 'epoch': 0.5711202277420705, 'step': 3171000}
INFO:transformers.trainer:{'loss': 3.1962026960849763, 'learning_rate': 4.047982864351952e-05, 'epoch': 0.5712102813888289, 'step': 3171500}
INFO:transformers.trainer:{'loss': 3.174127030134201, 'learning_rate': 4.047832774940688e-05, 'epoch': 0.5713003350355874, 'step': 3172000}
INFO:transformers.trainer:{'loss': 3.2298387796878814, 'learning_rate': 4.047682685529424e-05, 'epoch': 0.5713903886823458, 'step': 3172500}
INFO:transformers.trainer:{'loss': 3.2029569358825682, 'learning_rate': 4.04753259611816e-05, 'epoch': 0.5714804423291043, 'step': 3173000}
INFO:transformers.trainer:{'loss': 3.145294355034828, 'learning_rate': 4.047382506706896e-05, 'epoch': 0.5715704959758627, 'step': 3173500}
INFO:transformers.trainer:{'loss': 3.147364382982254, 'learning_rate': 4.0472324172956316e-05, 'epoch': 0.5716605496226211, 'step': 3174000}
INFO:transformers.trainer:{'loss': 3.1589190492630004, 'learning_rate': 4.0470823278843675e-05, 'epoch': 0.5717506032693797, 'step': 3174500}
INFO:transformers.trainer:{'loss': 3.1040730469226836, 'learning_rate': 4.0469322384731034e-05, 'epoch': 0.5718406569161381, 'step': 3175000}
INFO:transformers.trainer:{'loss': 3.135026269197464, 'learning_rate': 4.046782149061839e-05, 'epoch': 0.5719307105628966, 'step': 3175500}
INFO:transformers.trainer:{'loss': 3.2041877562999725, 'learning_rate': 4.046632059650575e-05, 'epoch': 0.572020764209655, 'step': 3176000}
INFO:transformers.trainer:{'loss': 3.124995234966278, 'learning_rate': 4.046481970239311e-05, 'epoch': 0.5721108178564134, 'step': 3176500}
INFO:transformers.trainer:{'loss': 3.1304025441408156, 'learning_rate': 4.046331880828047e-05, 'epoch': 0.5722008715031719, 'step': 3177000}
INFO:transformers.trainer:{'loss': 3.0888353941440583, 'learning_rate': 4.046181791416783e-05, 'epoch': 0.5722909251499303, 'step': 3177500}
INFO:transformers.trainer:{'loss': 3.1593446484804155, 'learning_rate': 4.046031702005519e-05, 'epoch': 0.5723809787966888, 'step': 3178000}
INFO:transformers.trainer:{'loss': 3.1399969466924667, 'learning_rate': 4.045881612594255e-05, 'epoch': 0.5724710324434472, 'step': 3178500}
INFO:transformers.trainer:{'loss': 3.209532735824585, 'learning_rate': 4.0457315231829906e-05, 'epoch': 0.5725610860902056, 'step': 3179000}
INFO:transformers.trainer:{'loss': 3.1915074706077577, 'learning_rate': 4.0455814337717265e-05, 'epoch': 0.5726511397369641, 'step': 3179500}
INFO:transformers.trainer:{'loss': 3.1626072649955748, 'learning_rate': 4.0454313443604624e-05, 'epoch': 0.5727411933837225, 'step': 3180000}
INFO:transformers.trainer:{'loss': 3.096496779680252, 'learning_rate': 4.0452812549491984e-05, 'epoch': 0.572831247030481, 'step': 3180500}
INFO:transformers.trainer:{'loss': 3.175196185588837, 'learning_rate': 4.045131165537934e-05, 'epoch': 0.5729213006772395, 'step': 3181000}
INFO:transformers.trainer:{'loss': 3.124745218992233, 'learning_rate': 4.04498107612667e-05, 'epoch': 0.5730113543239979, 'step': 3181500}
INFO:transformers.trainer:{'loss': 3.181223056793213, 'learning_rate': 4.044830986715406e-05, 'epoch': 0.5731014079707564, 'step': 3182000}
INFO:transformers.trainer:{'loss': 3.15900691819191, 'learning_rate': 4.044680897304142e-05, 'epoch': 0.5731914616175148, 'step': 3182500}
INFO:transformers.trainer:{'loss': 3.1680232853889465, 'learning_rate': 4.0445308078928786e-05, 'epoch': 0.5732815152642732, 'step': 3183000}
INFO:transformers.trainer:{'loss': 3.1825510232448577, 'learning_rate': 4.044380718481614e-05, 'epoch': 0.5733715689110317, 'step': 3183500}
INFO:transformers.trainer:{'loss': 3.154094829082489, 'learning_rate': 4.0442306290703504e-05, 'epoch': 0.5734616225577901, 'step': 3184000}
INFO:transformers.trainer:{'loss': 3.1563845193386078, 'learning_rate': 4.0440805396590856e-05, 'epoch': 0.5735516762045486, 'step': 3184500}
INFO:transformers.trainer:{'loss': 3.174413857579231, 'learning_rate': 4.043930450247822e-05, 'epoch': 0.573641729851307, 'step': 3185000}
INFO:transformers.trainer:{'loss': 3.119562272787094, 'learning_rate': 4.0437803608365574e-05, 'epoch': 0.5737317834980654, 'step': 3185500}
INFO:transformers.trainer:{'loss': 3.1609534339904783, 'learning_rate': 4.043630271425294e-05, 'epoch': 0.5738218371448239, 'step': 3186000}
INFO:transformers.trainer:{'loss': 3.1670033268928526, 'learning_rate': 4.043480182014029e-05, 'epoch': 0.5739118907915823, 'step': 3186500}
INFO:transformers.trainer:{'loss': 3.163740000486374, 'learning_rate': 4.043330092602766e-05, 'epoch': 0.5740019444383408, 'step': 3187000}
INFO:transformers.trainer:{'loss': 3.163772371530533, 'learning_rate': 4.043180003191501e-05, 'epoch': 0.5740919980850993, 'step': 3187500}
INFO:transformers.trainer:{'loss': 3.1483536813259123, 'learning_rate': 4.0430299137802376e-05, 'epoch': 0.5741820517318577, 'step': 3188000}
INFO:transformers.trainer:{'loss': 3.179364458799362, 'learning_rate': 4.042879824368973e-05, 'epoch': 0.5742721053786162, 'step': 3188500}
INFO:transformers.trainer:{'loss': 3.1539800897836687, 'learning_rate': 4.0427297349577094e-05, 'epoch': 0.5743621590253746, 'step': 3189000}
INFO:transformers.trainer:{'loss': 3.1341328561306, 'learning_rate': 4.0425796455464446e-05, 'epoch': 0.5744522126721331, 'step': 3189500}
INFO:transformers.trainer:{'loss': 3.1618133654594422, 'learning_rate': 4.042429556135181e-05, 'epoch': 0.5745422663188915, 'step': 3190000}
INFO:transformers.trainer:{'loss': 3.174268647313118, 'learning_rate': 4.042279466723917e-05, 'epoch': 0.5746323199656499, 'step': 3190500}
INFO:transformers.trainer:{'loss': 3.1695679738521574, 'learning_rate': 4.042129377312653e-05, 'epoch': 0.5747223736124084, 'step': 3191000}
INFO:transformers.trainer:{'loss': 3.1275655192136766, 'learning_rate': 4.041979287901389e-05, 'epoch': 0.5748124272591668, 'step': 3191500}
INFO:transformers.trainer:{'loss': 3.118821563005447, 'learning_rate': 4.041829198490125e-05, 'epoch': 0.5749024809059253, 'step': 3192000}
INFO:transformers.trainer:{'loss': 3.159665514230728, 'learning_rate': 4.041679109078861e-05, 'epoch': 0.5749925345526837, 'step': 3192500}
INFO:transformers.trainer:{'loss': 3.132938719034195, 'learning_rate': 4.0415290196675967e-05, 'epoch': 0.5750825881994421, 'step': 3193000}
INFO:transformers.trainer:{'loss': 3.088220517873764, 'learning_rate': 4.0413789302563326e-05, 'epoch': 0.5751726418462006, 'step': 3193500}
INFO:transformers.trainer:{'loss': 3.194510521888733, 'learning_rate': 4.0412288408450685e-05, 'epoch': 0.575262695492959, 'step': 3194000}
INFO:transformers.trainer:{'loss': 3.1764576427936553, 'learning_rate': 4.0410787514338044e-05, 'epoch': 0.5753527491397176, 'step': 3194500}
INFO:transformers.trainer:{'loss': 3.108116969823837, 'learning_rate': 4.04092866202254e-05, 'epoch': 0.575442802786476, 'step': 3195000}
INFO:transformers.trainer:{'loss': 3.1445358347892762, 'learning_rate': 4.040778572611276e-05, 'epoch': 0.5755328564332344, 'step': 3195500}
INFO:transformers.trainer:{'loss': 3.1363668665885927, 'learning_rate': 4.040628483200012e-05, 'epoch': 0.5756229100799929, 'step': 3196000}
INFO:transformers.trainer:{'loss': 3.1386809515953065, 'learning_rate': 4.040478393788748e-05, 'epoch': 0.5757129637267513, 'step': 3196500}
INFO:transformers.trainer:{'loss': 3.113720415592194, 'learning_rate': 4.040328304377484e-05, 'epoch': 0.5758030173735097, 'step': 3197000}
INFO:transformers.trainer:{'loss': 3.1068155665397645, 'learning_rate': 4.04017821496622e-05, 'epoch': 0.5758930710202682, 'step': 3197500}
INFO:transformers.trainer:{'loss': 3.146450946092606, 'learning_rate': 4.040028125554956e-05, 'epoch': 0.5759831246670266, 'step': 3198000}
INFO:transformers.trainer:{'loss': 3.170972574710846, 'learning_rate': 4.0398780361436916e-05, 'epoch': 0.5760731783137851, 'step': 3198500}
INFO:transformers.trainer:{'loss': 3.158861495018005, 'learning_rate': 4.0397279467324275e-05, 'epoch': 0.5761632319605435, 'step': 3199000}
INFO:transformers.trainer:{'loss': 3.1453696820735932, 'learning_rate': 4.0395778573211634e-05, 'epoch': 0.5762532856073019, 'step': 3199500}
INFO:transformers.trainer:{'loss': 3.130593339204788, 'learning_rate': 4.039427767909899e-05, 'epoch': 0.5763433392540604, 'step': 3200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.174918043136597, 'learning_rate': 4.039277678498635e-05, 'epoch': 0.5764333929008189, 'step': 3200500}
INFO:transformers.trainer:{'loss': 3.145494883060455, 'learning_rate': 4.039127589087371e-05, 'epoch': 0.5765234465475774, 'step': 3201000}
INFO:transformers.trainer:{'loss': 3.2245035874843597, 'learning_rate': 4.038977499676107e-05, 'epoch': 0.5766135001943358, 'step': 3201500}
INFO:transformers.trainer:{'loss': 3.1141047894954683, 'learning_rate': 4.038827410264843e-05, 'epoch': 0.5767035538410942, 'step': 3202000}
INFO:transformers.trainer:{'loss': 3.135926464796066, 'learning_rate': 4.038677320853579e-05, 'epoch': 0.5767936074878527, 'step': 3202500}
INFO:transformers.trainer:{'loss': 3.171120921134949, 'learning_rate': 4.038527231442315e-05, 'epoch': 0.5768836611346111, 'step': 3203000}
INFO:transformers.trainer:{'loss': 3.189883411169052, 'learning_rate': 4.038377142031051e-05, 'epoch': 0.5769737147813696, 'step': 3203500}
INFO:transformers.trainer:{'loss': 3.119190507650375, 'learning_rate': 4.0382270526197866e-05, 'epoch': 0.577063768428128, 'step': 3204000}
INFO:transformers.trainer:{'loss': 3.1511633846759795, 'learning_rate': 4.038076963208523e-05, 'epoch': 0.5771538220748864, 'step': 3204500}
INFO:transformers.trainer:{'loss': 3.1694351317882536, 'learning_rate': 4.0379268737972584e-05, 'epoch': 0.5772438757216449, 'step': 3205000}
INFO:transformers.trainer:{'loss': 3.1226494241952896, 'learning_rate': 4.037776784385995e-05, 'epoch': 0.5773339293684033, 'step': 3205500}
INFO:transformers.trainer:{'loss': 3.138602805376053, 'learning_rate': 4.03762669497473e-05, 'epoch': 0.5774239830151618, 'step': 3206000}
INFO:transformers.trainer:{'loss': 3.127076892852783, 'learning_rate': 4.037476605563467e-05, 'epoch': 0.5775140366619202, 'step': 3206500}
INFO:transformers.trainer:{'loss': 3.1496120893955233, 'learning_rate': 4.037326516152202e-05, 'epoch': 0.5776040903086787, 'step': 3207000}
INFO:transformers.trainer:{'loss': 3.1677557518482207, 'learning_rate': 4.0371764267409386e-05, 'epoch': 0.5776941439554372, 'step': 3207500}
INFO:transformers.trainer:{'loss': 3.213628334760666, 'learning_rate': 4.037026337329674e-05, 'epoch': 0.5777841976021956, 'step': 3208000}
INFO:transformers.trainer:{'loss': 3.1676533336639405, 'learning_rate': 4.0368762479184104e-05, 'epoch': 0.577874251248954, 'step': 3208500}
INFO:transformers.trainer:{'loss': 3.1546628649234774, 'learning_rate': 4.0367261585071456e-05, 'epoch': 0.5779643048957125, 'step': 3209000}
INFO:transformers.trainer:{'loss': 3.143359013557434, 'learning_rate': 4.036576069095882e-05, 'epoch': 0.5780543585424709, 'step': 3209500}
INFO:transformers.trainer:{'loss': 3.1043229777812957, 'learning_rate': 4.0364259796846174e-05, 'epoch': 0.5781444121892294, 'step': 3210000}
INFO:transformers.trainer:{'loss': 3.188935951113701, 'learning_rate': 4.036275890273354e-05, 'epoch': 0.5782344658359878, 'step': 3210500}
INFO:transformers.trainer:{'loss': 3.1238283913135527, 'learning_rate': 4.03612580086209e-05, 'epoch': 0.5783245194827462, 'step': 3211000}
INFO:transformers.trainer:{'loss': 3.139985601902008, 'learning_rate': 4.035975711450826e-05, 'epoch': 0.5784145731295047, 'step': 3211500}
INFO:transformers.trainer:{'loss': 3.1873628594875334, 'learning_rate': 4.035825622039562e-05, 'epoch': 0.5785046267762631, 'step': 3212000}
INFO:transformers.trainer:{'loss': 3.2227059450149538, 'learning_rate': 4.0356755326282976e-05, 'epoch': 0.5785946804230216, 'step': 3212500}
INFO:transformers.trainer:{'loss': 3.115640270113945, 'learning_rate': 4.0355254432170335e-05, 'epoch': 0.57868473406978, 'step': 3213000}
INFO:transformers.trainer:{'loss': 3.1563096088171005, 'learning_rate': 4.0353753538057694e-05, 'epoch': 0.5787747877165385, 'step': 3213500}
INFO:transformers.trainer:{'loss': 3.1874581418037415, 'learning_rate': 4.0352252643945053e-05, 'epoch': 0.578864841363297, 'step': 3214000}
INFO:transformers.trainer:{'loss': 3.1087190697193146, 'learning_rate': 4.035075174983241e-05, 'epoch': 0.5789548950100554, 'step': 3214500}
INFO:transformers.trainer:{'loss': 3.176437415599823, 'learning_rate': 4.034925085571977e-05, 'epoch': 0.5790449486568139, 'step': 3215000}
INFO:transformers.trainer:{'loss': 3.1551915843486786, 'learning_rate': 4.034774996160713e-05, 'epoch': 0.5791350023035723, 'step': 3215500}
INFO:transformers.trainer:{'loss': 3.0912567591667175, 'learning_rate': 4.034624906749449e-05, 'epoch': 0.5792250559503307, 'step': 3216000}
INFO:transformers.trainer:{'loss': 3.1728149024248125, 'learning_rate': 4.034474817338185e-05, 'epoch': 0.5793151095970892, 'step': 3216500}
INFO:transformers.trainer:{'loss': 3.114273272037506, 'learning_rate': 4.034324727926921e-05, 'epoch': 0.5794051632438476, 'step': 3217000}
INFO:transformers.trainer:{'loss': 3.1453593324422835, 'learning_rate': 4.034174638515657e-05, 'epoch': 0.5794952168906061, 'step': 3217500}
INFO:transformers.trainer:{'loss': 3.1606702558994293, 'learning_rate': 4.0340245491043926e-05, 'epoch': 0.5795852705373645, 'step': 3218000}
INFO:transformers.trainer:{'loss': 3.128937589883804, 'learning_rate': 4.0338744596931285e-05, 'epoch': 0.5796753241841229, 'step': 3218500}
INFO:transformers.trainer:{'loss': 3.151577098608017, 'learning_rate': 4.0337243702818644e-05, 'epoch': 0.5797653778308814, 'step': 3219000}
INFO:transformers.trainer:{'loss': 3.1710090560913087, 'learning_rate': 4.0335742808706e-05, 'epoch': 0.5798554314776398, 'step': 3219500}
INFO:transformers.trainer:{'loss': 3.149244626045227, 'learning_rate': 4.033424191459336e-05, 'epoch': 0.5799454851243983, 'step': 3220000}
INFO:transformers.trainer:{'loss': 3.1642794886827468, 'learning_rate': 4.033274102048072e-05, 'epoch': 0.5800355387711568, 'step': 3220500}
INFO:transformers.trainer:{'loss': 3.109254386425018, 'learning_rate': 4.033124012636808e-05, 'epoch': 0.5801255924179152, 'step': 3221000}
INFO:transformers.trainer:{'loss': 3.082880274057388, 'learning_rate': 4.032973923225544e-05, 'epoch': 0.5802156460646737, 'step': 3221500}
INFO:transformers.trainer:{'loss': 3.1751391644477844, 'learning_rate': 4.03282383381428e-05, 'epoch': 0.5803056997114321, 'step': 3222000}
INFO:transformers.trainer:{'loss': 3.116000484228134, 'learning_rate': 4.032673744403016e-05, 'epoch': 0.5803957533581905, 'step': 3222500}
INFO:transformers.trainer:{'loss': 3.1650176746845244, 'learning_rate': 4.0325236549917516e-05, 'epoch': 0.580485807004949, 'step': 3223000}
INFO:transformers.trainer:{'loss': 3.169961385846138, 'learning_rate': 4.0323735655804875e-05, 'epoch': 0.5805758606517074, 'step': 3223500}
INFO:transformers.trainer:{'loss': 3.1738164075016977, 'learning_rate': 4.0322234761692234e-05, 'epoch': 0.5806659142984659, 'step': 3224000}
INFO:transformers.trainer:{'loss': 3.100686901092529, 'learning_rate': 4.0320733867579593e-05, 'epoch': 0.5807559679452243, 'step': 3224500}
INFO:transformers.trainer:{'loss': 3.1498205082416533, 'learning_rate': 4.031923297346696e-05, 'epoch': 0.5808460215919827, 'step': 3225000}
INFO:transformers.trainer:{'loss': 3.087686825156212, 'learning_rate': 4.031773207935431e-05, 'epoch': 0.5809360752387412, 'step': 3225500}
INFO:transformers.trainer:{'loss': 3.146439999818802, 'learning_rate': 4.031623118524168e-05, 'epoch': 0.5810261288854996, 'step': 3226000}
INFO:transformers.trainer:{'loss': 3.242095969438553, 'learning_rate': 4.031473029112903e-05, 'epoch': 0.5811161825322582, 'step': 3226500}
INFO:transformers.trainer:{'loss': 3.153841341495514, 'learning_rate': 4.0313229397016396e-05, 'epoch': 0.5812062361790166, 'step': 3227000}
INFO:transformers.trainer:{'loss': 3.1429245028495787, 'learning_rate': 4.031172850290375e-05, 'epoch': 0.581296289825775, 'step': 3227500}
INFO:transformers.trainer:{'loss': 3.1379421014785764, 'learning_rate': 4.0310227608791114e-05, 'epoch': 0.5813863434725335, 'step': 3228000}
INFO:transformers.trainer:{'loss': 3.1376287186145784, 'learning_rate': 4.0308726714678466e-05, 'epoch': 0.5814763971192919, 'step': 3228500}
INFO:transformers.trainer:{'loss': 3.112830461502075, 'learning_rate': 4.030722582056583e-05, 'epoch': 0.5815664507660504, 'step': 3229000}
INFO:transformers.trainer:{'loss': 3.117468891620636, 'learning_rate': 4.0305724926453184e-05, 'epoch': 0.5816565044128088, 'step': 3229500}
INFO:transformers.trainer:{'loss': 3.1137916088104247, 'learning_rate': 4.030422403234055e-05, 'epoch': 0.5817465580595672, 'step': 3230000}
INFO:transformers.trainer:{'loss': 3.145630815982819, 'learning_rate': 4.03027231382279e-05, 'epoch': 0.5818366117063257, 'step': 3230500}
INFO:transformers.trainer:{'loss': 3.182036566257477, 'learning_rate': 4.030122224411527e-05, 'epoch': 0.5819266653530841, 'step': 3231000}
INFO:transformers.trainer:{'loss': 3.1493258908987047, 'learning_rate': 4.029972135000262e-05, 'epoch': 0.5820167189998426, 'step': 3231500}
INFO:transformers.trainer:{'loss': 3.127929740190506, 'learning_rate': 4.0298220455889986e-05, 'epoch': 0.582106772646601, 'step': 3232000}
INFO:transformers.trainer:{'loss': 3.146953559041023, 'learning_rate': 4.0296719561777345e-05, 'epoch': 0.5821968262933594, 'step': 3232500}
INFO:transformers.trainer:{'loss': 3.1552502567768097, 'learning_rate': 4.0295218667664704e-05, 'epoch': 0.582286879940118, 'step': 3233000}
INFO:transformers.trainer:{'loss': 3.148517409801483, 'learning_rate': 4.029371777355206e-05, 'epoch': 0.5823769335868764, 'step': 3233500}
INFO:transformers.trainer:{'loss': 3.1656568355560304, 'learning_rate': 4.029221687943942e-05, 'epoch': 0.5824669872336348, 'step': 3234000}
INFO:transformers.trainer:{'loss': 3.1843187029361726, 'learning_rate': 4.029071598532678e-05, 'epoch': 0.5825570408803933, 'step': 3234500}
INFO:transformers.trainer:{'loss': 3.2165859467983244, 'learning_rate': 4.028921509121414e-05, 'epoch': 0.5826470945271517, 'step': 3235000}
INFO:transformers.trainer:{'loss': 3.1237434310913086, 'learning_rate': 4.02877141971015e-05, 'epoch': 0.5827371481739102, 'step': 3235500}
INFO:transformers.trainer:{'loss': 3.090409930706024, 'learning_rate': 4.028621330298886e-05, 'epoch': 0.5828272018206686, 'step': 3236000}
INFO:transformers.trainer:{'loss': 3.1167821924686434, 'learning_rate': 4.028471240887622e-05, 'epoch': 0.582917255467427, 'step': 3236500}
INFO:transformers.trainer:{'loss': 3.1354473838806154, 'learning_rate': 4.0283211514763577e-05, 'epoch': 0.5830073091141855, 'step': 3237000}
INFO:transformers.trainer:{'loss': 3.0939720387458802, 'learning_rate': 4.0281710620650936e-05, 'epoch': 0.5830973627609439, 'step': 3237500}
INFO:transformers.trainer:{'loss': 3.12854056930542, 'learning_rate': 4.0280209726538295e-05, 'epoch': 0.5831874164077024, 'step': 3238000}
INFO:transformers.trainer:{'loss': 3.0785445053577423, 'learning_rate': 4.0278708832425654e-05, 'epoch': 0.5832774700544608, 'step': 3238500}
INFO:transformers.trainer:{'loss': 3.095911660909653, 'learning_rate': 4.027720793831302e-05, 'epoch': 0.5833675237012192, 'step': 3239000}
INFO:transformers.trainer:{'loss': 3.192584690928459, 'learning_rate': 4.027570704420037e-05, 'epoch': 0.5834575773479778, 'step': 3239500}
INFO:transformers.trainer:{'loss': 3.1762800323963165, 'learning_rate': 4.027420615008774e-05, 'epoch': 0.5835476309947362, 'step': 3240000}
INFO:transformers.trainer:{'loss': 3.2008107049465178, 'learning_rate': 4.027270525597509e-05, 'epoch': 0.5836376846414947, 'step': 3240500}
INFO:transformers.trainer:{'loss': 3.1902915148735045, 'learning_rate': 4.0271204361862456e-05, 'epoch': 0.5837277382882531, 'step': 3241000}
INFO:transformers.trainer:{'loss': 3.1901421568393706, 'learning_rate': 4.026970346774981e-05, 'epoch': 0.5838177919350115, 'step': 3241500}
INFO:transformers.trainer:{'loss': 3.1644431273937226, 'learning_rate': 4.0268202573637174e-05, 'epoch': 0.58390784558177, 'step': 3242000}
INFO:transformers.trainer:{'loss': 3.155448328971863, 'learning_rate': 4.0266701679524526e-05, 'epoch': 0.5839978992285284, 'step': 3242500}
INFO:transformers.trainer:{'loss': 3.10395815038681, 'learning_rate': 4.0265200785411885e-05, 'epoch': 0.5840879528752869, 'step': 3243000}
INFO:transformers.trainer:{'loss': 3.127094653367996, 'learning_rate': 4.0263699891299244e-05, 'epoch': 0.5841780065220453, 'step': 3243500}
INFO:transformers.trainer:{'loss': 3.130532351732254, 'learning_rate': 4.02621989971866e-05, 'epoch': 0.5842680601688037, 'step': 3244000}
INFO:transformers.trainer:{'loss': 3.1328549196720124, 'learning_rate': 4.026069810307396e-05, 'epoch': 0.5843581138155622, 'step': 3244500}
INFO:transformers.trainer:{'loss': 3.132646274805069, 'learning_rate': 4.025919720896132e-05, 'epoch': 0.5844481674623206, 'step': 3245000}
INFO:transformers.trainer:{'loss': 3.1443644202947616, 'learning_rate': 4.025769631484869e-05, 'epoch': 0.584538221109079, 'step': 3245500}
INFO:transformers.trainer:{'loss': 3.1772009704113007, 'learning_rate': 4.025619542073604e-05, 'epoch': 0.5846282747558376, 'step': 3246000}
INFO:transformers.trainer:{'loss': 3.1970212090015413, 'learning_rate': 4.0254694526623405e-05, 'epoch': 0.584718328402596, 'step': 3246500}
INFO:transformers.trainer:{'loss': 3.1359691154956817, 'learning_rate': 4.025319363251076e-05, 'epoch': 0.5848083820493545, 'step': 3247000}
INFO:transformers.trainer:{'loss': 3.097823816537857, 'learning_rate': 4.025169273839812e-05, 'epoch': 0.5848984356961129, 'step': 3247500}
INFO:transformers.trainer:{'loss': 3.191113451719284, 'learning_rate': 4.0250191844285476e-05, 'epoch': 0.5849884893428713, 'step': 3248000}
INFO:transformers.trainer:{'loss': 3.1799930317401888, 'learning_rate': 4.024869095017284e-05, 'epoch': 0.5850785429896298, 'step': 3248500}
INFO:transformers.trainer:{'loss': 3.1874171516895293, 'learning_rate': 4.0247190056060194e-05, 'epoch': 0.5851685966363882, 'step': 3249000}
INFO:transformers.trainer:{'loss': 3.106418489933014, 'learning_rate': 4.024568916194756e-05, 'epoch': 0.5852586502831467, 'step': 3249500}
INFO:transformers.trainer:{'loss': 3.228386189699173, 'learning_rate': 4.024418826783491e-05, 'epoch': 0.5853487039299051, 'step': 3250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.157900915145874, 'learning_rate': 4.024268737372228e-05, 'epoch': 0.5854387575766635, 'step': 3250500}
INFO:transformers.trainer:{'loss': 3.07943275308609, 'learning_rate': 4.024118647960963e-05, 'epoch': 0.585528811223422, 'step': 3251000}
INFO:transformers.trainer:{'loss': 3.15224422621727, 'learning_rate': 4.0239685585496996e-05, 'epoch': 0.5856188648701804, 'step': 3251500}
INFO:transformers.trainer:{'loss': 3.1926776697635653, 'learning_rate': 4.023818469138435e-05, 'epoch': 0.585708918516939, 'step': 3252000}
INFO:transformers.trainer:{'loss': 3.1463429963588716, 'learning_rate': 4.0236683797271714e-05, 'epoch': 0.5857989721636974, 'step': 3252500}
INFO:transformers.trainer:{'loss': 3.169337397813797, 'learning_rate': 4.023518290315907e-05, 'epoch': 0.5858890258104558, 'step': 3253000}
INFO:transformers.trainer:{'loss': 3.1628806042671203, 'learning_rate': 4.023368200904643e-05, 'epoch': 0.5859790794572143, 'step': 3253500}
INFO:transformers.trainer:{'loss': 3.122230685710907, 'learning_rate': 4.023218111493379e-05, 'epoch': 0.5860691331039727, 'step': 3254000}
INFO:transformers.trainer:{'loss': 3.154158910274506, 'learning_rate': 4.023068022082115e-05, 'epoch': 0.5861591867507312, 'step': 3254500}
INFO:transformers.trainer:{'loss': 3.187510514497757, 'learning_rate': 4.022917932670851e-05, 'epoch': 0.5862492403974896, 'step': 3255000}
INFO:transformers.trainer:{'loss': 3.160554353475571, 'learning_rate': 4.022767843259587e-05, 'epoch': 0.586339294044248, 'step': 3255500}
INFO:transformers.trainer:{'loss': 3.152449612379074, 'learning_rate': 4.022617753848323e-05, 'epoch': 0.5864293476910065, 'step': 3256000}
INFO:transformers.trainer:{'loss': 3.1967112245559695, 'learning_rate': 4.0224676644370586e-05, 'epoch': 0.5865194013377649, 'step': 3256500}
INFO:transformers.trainer:{'loss': 3.153908942937851, 'learning_rate': 4.0223175750257945e-05, 'epoch': 0.5866094549845233, 'step': 3257000}
INFO:transformers.trainer:{'loss': 3.1281179398298264, 'learning_rate': 4.0221674856145304e-05, 'epoch': 0.5866995086312818, 'step': 3257500}
INFO:transformers.trainer:{'loss': 3.1216190836429596, 'learning_rate': 4.0220173962032663e-05, 'epoch': 0.5867895622780402, 'step': 3258000}
INFO:transformers.trainer:{'loss': 3.1218802347183225, 'learning_rate': 4.021867306792002e-05, 'epoch': 0.5868796159247988, 'step': 3258500}
INFO:transformers.trainer:{'loss': 3.081002206325531, 'learning_rate': 4.021717217380738e-05, 'epoch': 0.5869696695715572, 'step': 3259000}
INFO:transformers.trainer:{'loss': 3.1823012142181395, 'learning_rate': 4.021567127969475e-05, 'epoch': 0.5870597232183156, 'step': 3259500}
INFO:transformers.trainer:{'loss': 3.138043196439743, 'learning_rate': 4.02141703855821e-05, 'epoch': 0.5871497768650741, 'step': 3260000}
INFO:transformers.trainer:{'loss': 3.193713399410248, 'learning_rate': 4.0212669491469465e-05, 'epoch': 0.5872398305118325, 'step': 3260500}
INFO:transformers.trainer:{'loss': 3.091729397773743, 'learning_rate': 4.021116859735682e-05, 'epoch': 0.587329884158591, 'step': 3261000}
INFO:transformers.trainer:{'loss': 3.1572733833789823, 'learning_rate': 4.0209667703244184e-05, 'epoch': 0.5874199378053494, 'step': 3261500}
INFO:transformers.trainer:{'loss': 3.1382729464769366, 'learning_rate': 4.0208166809131536e-05, 'epoch': 0.5875099914521078, 'step': 3262000}
INFO:transformers.trainer:{'loss': 3.144074162483215, 'learning_rate': 4.02066659150189e-05, 'epoch': 0.5876000450988663, 'step': 3262500}
INFO:transformers.trainer:{'loss': 3.1300032796859742, 'learning_rate': 4.0205165020906254e-05, 'epoch': 0.5876900987456247, 'step': 3263000}
INFO:transformers.trainer:{'loss': 3.1823108558654787, 'learning_rate': 4.020366412679362e-05, 'epoch': 0.5877801523923832, 'step': 3263500}
INFO:transformers.trainer:{'loss': 3.1860600550174714, 'learning_rate': 4.020216323268097e-05, 'epoch': 0.5878702060391416, 'step': 3264000}
INFO:transformers.trainer:{'loss': 3.1245713539123536, 'learning_rate': 4.020066233856834e-05, 'epoch': 0.5879602596859, 'step': 3264500}
INFO:transformers.trainer:{'loss': 3.1243457322120665, 'learning_rate': 4.019916144445569e-05, 'epoch': 0.5880503133326586, 'step': 3265000}
INFO:transformers.trainer:{'loss': 3.1315150260925293, 'learning_rate': 4.0197660550343056e-05, 'epoch': 0.588140366979417, 'step': 3265500}
INFO:transformers.trainer:{'loss': 3.112514273405075, 'learning_rate': 4.019615965623041e-05, 'epoch': 0.5882304206261755, 'step': 3266000}
INFO:transformers.trainer:{'loss': 3.1827417722940443, 'learning_rate': 4.019465876211777e-05, 'epoch': 0.5883204742729339, 'step': 3266500}
INFO:transformers.trainer:{'loss': 3.1565079164505003, 'learning_rate': 4.019315786800513e-05, 'epoch': 0.5884105279196923, 'step': 3267000}
INFO:transformers.trainer:{'loss': 3.1472371199131013, 'learning_rate': 4.0191656973892485e-05, 'epoch': 0.5885005815664508, 'step': 3267500}
INFO:transformers.trainer:{'loss': 3.117244856595993, 'learning_rate': 4.019015607977985e-05, 'epoch': 0.5885906352132092, 'step': 3268000}
INFO:transformers.trainer:{'loss': 3.133770839691162, 'learning_rate': 4.0188655185667203e-05, 'epoch': 0.5886806888599676, 'step': 3268500}
INFO:transformers.trainer:{'loss': 3.098393028616905, 'learning_rate': 4.018715429155457e-05, 'epoch': 0.5887707425067261, 'step': 3269000}
INFO:transformers.trainer:{'loss': 3.168490906238556, 'learning_rate': 4.018565339744192e-05, 'epoch': 0.5888607961534845, 'step': 3269500}
INFO:transformers.trainer:{'loss': 3.0609485268592835, 'learning_rate': 4.018415250332929e-05, 'epoch': 0.588950849800243, 'step': 3270000}
INFO:transformers.trainer:{'loss': 3.181762180328369, 'learning_rate': 4.018265160921664e-05, 'epoch': 0.5890409034470014, 'step': 3270500}
INFO:transformers.trainer:{'loss': 3.131664131402969, 'learning_rate': 4.0181150715104005e-05, 'epoch': 0.5891309570937598, 'step': 3271000}
INFO:transformers.trainer:{'loss': 3.11153107047081, 'learning_rate': 4.017964982099136e-05, 'epoch': 0.5892210107405184, 'step': 3271500}
INFO:transformers.trainer:{'loss': 3.127588614940643, 'learning_rate': 4.0178148926878724e-05, 'epoch': 0.5893110643872768, 'step': 3272000}
INFO:transformers.trainer:{'loss': 3.11445072054863, 'learning_rate': 4.0176648032766076e-05, 'epoch': 0.5894011180340353, 'step': 3272500}
INFO:transformers.trainer:{'loss': 3.151174840450287, 'learning_rate': 4.017514713865344e-05, 'epoch': 0.5894911716807937, 'step': 3273000}
INFO:transformers.trainer:{'loss': 3.1418886597156526, 'learning_rate': 4.01736462445408e-05, 'epoch': 0.5895812253275521, 'step': 3273500}
INFO:transformers.trainer:{'loss': 3.1289514540433885, 'learning_rate': 4.017214535042816e-05, 'epoch': 0.5896712789743106, 'step': 3274000}
INFO:transformers.trainer:{'loss': 3.0651264402866363, 'learning_rate': 4.017064445631552e-05, 'epoch': 0.589761332621069, 'step': 3274500}
INFO:transformers.trainer:{'loss': 3.165799450159073, 'learning_rate': 4.016914356220288e-05, 'epoch': 0.5898513862678275, 'step': 3275000}
INFO:transformers.trainer:{'loss': 3.1293261011838913, 'learning_rate': 4.016764266809024e-05, 'epoch': 0.5899414399145859, 'step': 3275500}
INFO:transformers.trainer:{'loss': 3.1679449882507322, 'learning_rate': 4.0166141773977596e-05, 'epoch': 0.5900314935613443, 'step': 3276000}
INFO:transformers.trainer:{'loss': 3.212643794417381, 'learning_rate': 4.0164640879864955e-05, 'epoch': 0.5901215472081028, 'step': 3276500}
INFO:transformers.trainer:{'loss': 3.1628974289894103, 'learning_rate': 4.0163139985752314e-05, 'epoch': 0.5902116008548612, 'step': 3277000}
INFO:transformers.trainer:{'loss': 3.13708594584465, 'learning_rate': 4.016163909163967e-05, 'epoch': 0.5903016545016198, 'step': 3277500}
INFO:transformers.trainer:{'loss': 3.111895345211029, 'learning_rate': 4.016013819752703e-05, 'epoch': 0.5903917081483782, 'step': 3278000}
INFO:transformers.trainer:{'loss': 3.1499523582458497, 'learning_rate': 4.015863730341439e-05, 'epoch': 0.5904817617951366, 'step': 3278500}
INFO:transformers.trainer:{'loss': 3.085217126607895, 'learning_rate': 4.015713640930175e-05, 'epoch': 0.5905718154418951, 'step': 3279000}
INFO:transformers.trainer:{'loss': 3.1556894855499267, 'learning_rate': 4.015563551518911e-05, 'epoch': 0.5906618690886535, 'step': 3279500}
INFO:transformers.trainer:{'loss': 3.174627953529358, 'learning_rate': 4.015413462107647e-05, 'epoch': 0.590751922735412, 'step': 3280000}
INFO:transformers.trainer:{'loss': 3.1466687121391295, 'learning_rate': 4.015263372696383e-05, 'epoch': 0.5908419763821704, 'step': 3280500}
INFO:transformers.trainer:{'loss': 3.1395916481018067, 'learning_rate': 4.015113283285119e-05, 'epoch': 0.5909320300289288, 'step': 3281000}
INFO:transformers.trainer:{'loss': 3.1583888223171233, 'learning_rate': 4.0149631938738546e-05, 'epoch': 0.5910220836756873, 'step': 3281500}
INFO:transformers.trainer:{'loss': 3.146067539334297, 'learning_rate': 4.014813104462591e-05, 'epoch': 0.5911121373224457, 'step': 3282000}
INFO:transformers.trainer:{'loss': 3.1328474575281144, 'learning_rate': 4.0146630150513264e-05, 'epoch': 0.5912021909692041, 'step': 3282500}
INFO:transformers.trainer:{'loss': 3.1338590755462645, 'learning_rate': 4.014512925640063e-05, 'epoch': 0.5912922446159626, 'step': 3283000}
INFO:transformers.trainer:{'loss': 3.207621753692627, 'learning_rate': 4.014362836228798e-05, 'epoch': 0.591382298262721, 'step': 3283500}
INFO:transformers.trainer:{'loss': 3.1917229129076006, 'learning_rate': 4.014212746817535e-05, 'epoch': 0.5914723519094796, 'step': 3284000}
INFO:transformers.trainer:{'loss': 3.1042295310497283, 'learning_rate': 4.01406265740627e-05, 'epoch': 0.591562405556238, 'step': 3284500}
INFO:transformers.trainer:{'loss': 3.144438914179802, 'learning_rate': 4.0139125679950066e-05, 'epoch': 0.5916524592029964, 'step': 3285000}
INFO:transformers.trainer:{'loss': 3.0999772579669953, 'learning_rate': 4.013762478583742e-05, 'epoch': 0.5917425128497549, 'step': 3285500}
INFO:transformers.trainer:{'loss': 3.1924052891731263, 'learning_rate': 4.0136123891724784e-05, 'epoch': 0.5918325664965133, 'step': 3286000}
INFO:transformers.trainer:{'loss': 3.1311614166498183, 'learning_rate': 4.0134622997612136e-05, 'epoch': 0.5919226201432718, 'step': 3286500}
INFO:transformers.trainer:{'loss': 3.0930788583755495, 'learning_rate': 4.01331221034995e-05, 'epoch': 0.5920126737900302, 'step': 3287000}
INFO:transformers.trainer:{'loss': 3.1742736439704897, 'learning_rate': 4.013162120938686e-05, 'epoch': 0.5921027274367886, 'step': 3287500}
INFO:transformers.trainer:{'loss': 3.1537766628265382, 'learning_rate': 4.013012031527422e-05, 'epoch': 0.5921927810835471, 'step': 3288000}
INFO:transformers.trainer:{'loss': 3.1480743935108184, 'learning_rate': 4.012861942116158e-05, 'epoch': 0.5922828347303055, 'step': 3288500}
INFO:transformers.trainer:{'loss': 3.161608758687973, 'learning_rate': 4.012711852704894e-05, 'epoch': 0.592372888377064, 'step': 3289000}
INFO:transformers.trainer:{'loss': 3.1724627521038054, 'learning_rate': 4.01256176329363e-05, 'epoch': 0.5924629420238224, 'step': 3289500}
INFO:transformers.trainer:{'loss': 3.1456525762081147, 'learning_rate': 4.012411673882365e-05, 'epoch': 0.5925529956705808, 'step': 3290000}
INFO:transformers.trainer:{'loss': 3.176634962797165, 'learning_rate': 4.0122615844711015e-05, 'epoch': 0.5926430493173394, 'step': 3290500}
INFO:transformers.trainer:{'loss': 3.1664375174045563, 'learning_rate': 4.012111495059837e-05, 'epoch': 0.5927331029640978, 'step': 3291000}
INFO:transformers.trainer:{'loss': 3.1793778047561645, 'learning_rate': 4.011961405648573e-05, 'epoch': 0.5928231566108563, 'step': 3291500}
INFO:transformers.trainer:{'loss': 3.161598219394684, 'learning_rate': 4.0118113162373086e-05, 'epoch': 0.5929132102576147, 'step': 3292000}
INFO:transformers.trainer:{'loss': 3.1417907366752624, 'learning_rate': 4.011661226826045e-05, 'epoch': 0.5930032639043731, 'step': 3292500}
INFO:transformers.trainer:{'loss': 3.1601761293411257, 'learning_rate': 4.0115111374147804e-05, 'epoch': 0.5930933175511316, 'step': 3293000}
INFO:transformers.trainer:{'loss': 3.166947823762894, 'learning_rate': 4.011361048003517e-05, 'epoch': 0.59318337119789, 'step': 3293500}
INFO:transformers.trainer:{'loss': 3.093378497838974, 'learning_rate': 4.011210958592253e-05, 'epoch': 0.5932734248446484, 'step': 3294000}
INFO:transformers.trainer:{'loss': 3.0771489534378054, 'learning_rate': 4.011060869180989e-05, 'epoch': 0.5933634784914069, 'step': 3294500}
INFO:transformers.trainer:{'loss': 3.1551267457008363, 'learning_rate': 4.010910779769725e-05, 'epoch': 0.5934535321381653, 'step': 3295000}
INFO:transformers.trainer:{'loss': 3.1087021999359132, 'learning_rate': 4.0107606903584606e-05, 'epoch': 0.5935435857849238, 'step': 3295500}
INFO:transformers.trainer:{'loss': 3.1716499692201614, 'learning_rate': 4.0106106009471965e-05, 'epoch': 0.5936336394316822, 'step': 3296000}
INFO:transformers.trainer:{'loss': 3.1780788564682005, 'learning_rate': 4.0104605115359324e-05, 'epoch': 0.5937236930784406, 'step': 3296500}
INFO:transformers.trainer:{'loss': 3.1109755041599274, 'learning_rate': 4.010310422124668e-05, 'epoch': 0.5938137467251992, 'step': 3297000}
INFO:transformers.trainer:{'loss': 3.178832093000412, 'learning_rate': 4.010160332713404e-05, 'epoch': 0.5939038003719576, 'step': 3297500}
INFO:transformers.trainer:{'loss': 3.135244122505188, 'learning_rate': 4.01001024330214e-05, 'epoch': 0.5939938540187161, 'step': 3298000}
INFO:transformers.trainer:{'loss': 3.1110260751247405, 'learning_rate': 4.009860153890876e-05, 'epoch': 0.5940839076654745, 'step': 3298500}
INFO:transformers.trainer:{'loss': 3.14540905046463, 'learning_rate': 4.009710064479612e-05, 'epoch': 0.5941739613122329, 'step': 3299000}
INFO:transformers.trainer:{'loss': 3.1392919783592226, 'learning_rate': 4.009559975068348e-05, 'epoch': 0.5942640149589914, 'step': 3299500}
INFO:transformers.trainer:{'loss': 3.1671230832338333, 'learning_rate': 4.009409885657084e-05, 'epoch': 0.5943540686057498, 'step': 3300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.128618052959442, 'learning_rate': 4.0092597962458196e-05, 'epoch': 0.5944441222525083, 'step': 3300500}
INFO:transformers.trainer:{'loss': 3.1417062697410585, 'learning_rate': 4.0091097068345555e-05, 'epoch': 0.5945341758992667, 'step': 3301000}
INFO:transformers.trainer:{'loss': 3.0855071280002595, 'learning_rate': 4.008959617423292e-05, 'epoch': 0.5946242295460251, 'step': 3301500}
INFO:transformers.trainer:{'loss': 3.2008827996253966, 'learning_rate': 4.008809528012027e-05, 'epoch': 0.5947142831927836, 'step': 3302000}
INFO:transformers.trainer:{'loss': 3.140975927233696, 'learning_rate': 4.008659438600764e-05, 'epoch': 0.594804336839542, 'step': 3302500}
INFO:transformers.trainer:{'loss': 3.1939012384414673, 'learning_rate': 4.008509349189499e-05, 'epoch': 0.5948943904863006, 'step': 3303000}
INFO:transformers.trainer:{'loss': 3.1707697541713715, 'learning_rate': 4.008359259778236e-05, 'epoch': 0.594984444133059, 'step': 3303500}
INFO:transformers.trainer:{'loss': 3.119758688211441, 'learning_rate': 4.008209170366971e-05, 'epoch': 0.5950744977798174, 'step': 3304000}
INFO:transformers.trainer:{'loss': 3.151831489801407, 'learning_rate': 4.0080590809557075e-05, 'epoch': 0.5951645514265759, 'step': 3304500}
INFO:transformers.trainer:{'loss': 3.175983604669571, 'learning_rate': 4.007908991544443e-05, 'epoch': 0.5952546050733343, 'step': 3305000}
INFO:transformers.trainer:{'loss': 3.1903094630241395, 'learning_rate': 4.0077589021331793e-05, 'epoch': 0.5953446587200927, 'step': 3305500}
INFO:transformers.trainer:{'loss': 3.125499667406082, 'learning_rate': 4.0076088127219146e-05, 'epoch': 0.5954347123668512, 'step': 3306000}
INFO:transformers.trainer:{'loss': 3.1946844527721403, 'learning_rate': 4.007458723310651e-05, 'epoch': 0.5955247660136096, 'step': 3306500}
INFO:transformers.trainer:{'loss': 3.101349934101105, 'learning_rate': 4.0073086338993864e-05, 'epoch': 0.5956148196603681, 'step': 3307000}
INFO:transformers.trainer:{'loss': 3.134840095758438, 'learning_rate': 4.007158544488123e-05, 'epoch': 0.5957048733071265, 'step': 3307500}
INFO:transformers.trainer:{'loss': 3.154382056236267, 'learning_rate': 4.007008455076859e-05, 'epoch': 0.5957949269538849, 'step': 3308000}
INFO:transformers.trainer:{'loss': 3.1886679096221924, 'learning_rate': 4.006858365665595e-05, 'epoch': 0.5958849806006434, 'step': 3308500}
INFO:transformers.trainer:{'loss': 3.115268588781357, 'learning_rate': 4.006708276254331e-05, 'epoch': 0.5959750342474018, 'step': 3309000}
INFO:transformers.trainer:{'loss': 3.092376177072525, 'learning_rate': 4.0065581868430666e-05, 'epoch': 0.5960650878941604, 'step': 3309500}
INFO:transformers.trainer:{'loss': 3.1838651204109194, 'learning_rate': 4.0064080974318025e-05, 'epoch': 0.5961551415409188, 'step': 3310000}
INFO:transformers.trainer:{'loss': 3.177746679186821, 'learning_rate': 4.0062580080205384e-05, 'epoch': 0.5962451951876772, 'step': 3310500}
INFO:transformers.trainer:{'loss': 3.179421080112457, 'learning_rate': 4.006107918609274e-05, 'epoch': 0.5963352488344357, 'step': 3311000}
INFO:transformers.trainer:{'loss': 3.1573499488830565, 'learning_rate': 4.00595782919801e-05, 'epoch': 0.5964253024811941, 'step': 3311500}
INFO:transformers.trainer:{'loss': 3.147314567565918, 'learning_rate': 4.005807739786746e-05, 'epoch': 0.5965153561279526, 'step': 3312000}
INFO:transformers.trainer:{'loss': 3.160817753314972, 'learning_rate': 4.005657650375482e-05, 'epoch': 0.596605409774711, 'step': 3312500}
INFO:transformers.trainer:{'loss': 3.0854145927429197, 'learning_rate': 4.005507560964218e-05, 'epoch': 0.5966954634214694, 'step': 3313000}
INFO:transformers.trainer:{'loss': 3.125733530640602, 'learning_rate': 4.005357471552953e-05, 'epoch': 0.5967855170682279, 'step': 3313500}
INFO:transformers.trainer:{'loss': 3.1917941648960113, 'learning_rate': 4.00520738214169e-05, 'epoch': 0.5968755707149863, 'step': 3314000}
INFO:transformers.trainer:{'loss': 3.130963633775711, 'learning_rate': 4.005057292730425e-05, 'epoch': 0.5969656243617448, 'step': 3314500}
INFO:transformers.trainer:{'loss': 3.161816521048546, 'learning_rate': 4.0049072033191615e-05, 'epoch': 0.5970556780085032, 'step': 3315000}
INFO:transformers.trainer:{'loss': 3.110820095539093, 'learning_rate': 4.0047571139078974e-05, 'epoch': 0.5971457316552616, 'step': 3315500}
INFO:transformers.trainer:{'loss': 3.1441354987621306, 'learning_rate': 4.0046070244966334e-05, 'epoch': 0.5972357853020202, 'step': 3316000}
INFO:transformers.trainer:{'loss': 3.1450627599954606, 'learning_rate': 4.004456935085369e-05, 'epoch': 0.5973258389487786, 'step': 3316500}
INFO:transformers.trainer:{'loss': 3.1416971588134768, 'learning_rate': 4.004306845674105e-05, 'epoch': 0.5974158925955371, 'step': 3317000}
INFO:transformers.trainer:{'loss': 3.152130261182785, 'learning_rate': 4.004156756262841e-05, 'epoch': 0.5975059462422955, 'step': 3317500}
INFO:transformers.trainer:{'loss': 3.0994819840192793, 'learning_rate': 4.004006666851577e-05, 'epoch': 0.5975959998890539, 'step': 3318000}
INFO:transformers.trainer:{'loss': 3.1120923144817354, 'learning_rate': 4.003856577440313e-05, 'epoch': 0.5976860535358124, 'step': 3318500}
INFO:transformers.trainer:{'loss': 3.118800350666046, 'learning_rate': 4.003706488029049e-05, 'epoch': 0.5977761071825708, 'step': 3319000}
INFO:transformers.trainer:{'loss': 3.1224682345390318, 'learning_rate': 4.003556398617785e-05, 'epoch': 0.5978661608293292, 'step': 3319500}
INFO:transformers.trainer:{'loss': 3.120352192401886, 'learning_rate': 4.0034063092065206e-05, 'epoch': 0.5979562144760877, 'step': 3320000}
INFO:transformers.trainer:{'loss': 3.1055161232948305, 'learning_rate': 4.0032562197952565e-05, 'epoch': 0.5980462681228461, 'step': 3320500}
INFO:transformers.trainer:{'loss': 3.1784883056879045, 'learning_rate': 4.0031061303839924e-05, 'epoch': 0.5981363217696046, 'step': 3321000}
INFO:transformers.trainer:{'loss': 3.13268481361866, 'learning_rate': 4.002956040972728e-05, 'epoch': 0.598226375416363, 'step': 3321500}
INFO:transformers.trainer:{'loss': 3.1660828907489775, 'learning_rate': 4.002805951561465e-05, 'epoch': 0.5983164290631214, 'step': 3322000}
INFO:transformers.trainer:{'loss': 3.1495303791761398, 'learning_rate': 4.0026558621502e-05, 'epoch': 0.59840648270988, 'step': 3322500}
INFO:transformers.trainer:{'loss': 3.147183132171631, 'learning_rate': 4.002505772738937e-05, 'epoch': 0.5984965363566384, 'step': 3323000}
INFO:transformers.trainer:{'loss': 3.1074302740097046, 'learning_rate': 4.002355683327672e-05, 'epoch': 0.5985865900033969, 'step': 3323500}
INFO:transformers.trainer:{'loss': 3.1280601420402525, 'learning_rate': 4.0022055939164085e-05, 'epoch': 0.5986766436501553, 'step': 3324000}
INFO:transformers.trainer:{'loss': 3.195573637962341, 'learning_rate': 4.002055504505144e-05, 'epoch': 0.5987666972969137, 'step': 3324500}
INFO:transformers.trainer:{'loss': 3.110524874687195, 'learning_rate': 4.00190541509388e-05, 'epoch': 0.5988567509436722, 'step': 3325000}
INFO:transformers.trainer:{'loss': 3.0842636234760286, 'learning_rate': 4.0017553256826155e-05, 'epoch': 0.5989468045904306, 'step': 3325500}
INFO:transformers.trainer:{'loss': 3.162606704711914, 'learning_rate': 4.001605236271352e-05, 'epoch': 0.5990368582371891, 'step': 3326000}
INFO:transformers.trainer:{'loss': 3.1784222071170807, 'learning_rate': 4.0014551468600874e-05, 'epoch': 0.5991269118839475, 'step': 3326500}
INFO:transformers.trainer:{'loss': 3.1912290163040162, 'learning_rate': 4.001305057448824e-05, 'epoch': 0.5992169655307059, 'step': 3327000}
INFO:transformers.trainer:{'loss': 3.0793492126464845, 'learning_rate': 4.001154968037559e-05, 'epoch': 0.5993070191774644, 'step': 3327500}
INFO:transformers.trainer:{'loss': 3.1338415536880495, 'learning_rate': 4.001004878626296e-05, 'epoch': 0.5993970728242228, 'step': 3328000}
INFO:transformers.trainer:{'loss': 3.1115299799442293, 'learning_rate': 4.000854789215031e-05, 'epoch': 0.5994871264709813, 'step': 3328500}
INFO:transformers.trainer:{'loss': 3.114249447345734, 'learning_rate': 4.0007046998037676e-05, 'epoch': 0.5995771801177397, 'step': 3329000}
INFO:transformers.trainer:{'loss': 3.1961631295681, 'learning_rate': 4.0005546103925035e-05, 'epoch': 0.5996672337644982, 'step': 3329500}
INFO:transformers.trainer:{'loss': 3.1366549854278563, 'learning_rate': 4.0004045209812394e-05, 'epoch': 0.5997572874112567, 'step': 3330000}
INFO:transformers.trainer:{'loss': 3.200245510816574, 'learning_rate': 4.000254431569975e-05, 'epoch': 0.5998473410580151, 'step': 3330500}
INFO:transformers.trainer:{'loss': 3.0855928297042845, 'learning_rate': 4.000104342158711e-05, 'epoch': 0.5999373947047735, 'step': 3331000}
INFO:transformers.trainer:{'loss': 3.1416853985786437, 'learning_rate': 3.999954252747447e-05, 'epoch': 0.600027448351532, 'step': 3331500}
INFO:transformers.trainer:{'loss': 3.12924170255661, 'learning_rate': 3.999804163336183e-05, 'epoch': 0.6001175019982904, 'step': 3332000}
INFO:transformers.trainer:{'loss': 3.129727906703949, 'learning_rate': 3.999654073924919e-05, 'epoch': 0.6002075556450489, 'step': 3332500}
INFO:transformers.trainer:{'loss': 3.177106870174408, 'learning_rate': 3.999503984513655e-05, 'epoch': 0.6002976092918073, 'step': 3333000}
INFO:transformers.trainer:{'loss': 3.1379405460357668, 'learning_rate': 3.999353895102391e-05, 'epoch': 0.6003876629385657, 'step': 3333500}
INFO:transformers.trainer:{'loss': 3.1115577585697176, 'learning_rate': 3.9992038056911266e-05, 'epoch': 0.6004777165853242, 'step': 3334000}
INFO:transformers.trainer:{'loss': 3.16596292757988, 'learning_rate': 3.9990537162798625e-05, 'epoch': 0.6005677702320826, 'step': 3334500}
INFO:transformers.trainer:{'loss': 3.1202847228050232, 'learning_rate': 3.9989036268685984e-05, 'epoch': 0.6006578238788411, 'step': 3335000}
INFO:transformers.trainer:{'loss': 3.1151482417583467, 'learning_rate': 3.998753537457334e-05, 'epoch': 0.6007478775255995, 'step': 3335500}
INFO:transformers.trainer:{'loss': 3.1097999699115753, 'learning_rate': 3.99860344804607e-05, 'epoch': 0.600837931172358, 'step': 3336000}
INFO:transformers.trainer:{'loss': 3.118491492509842, 'learning_rate': 3.998453358634806e-05, 'epoch': 0.6009279848191165, 'step': 3336500}
INFO:transformers.trainer:{'loss': 3.1952702038288114, 'learning_rate': 3.998303269223542e-05, 'epoch': 0.6010180384658749, 'step': 3337000}
INFO:transformers.trainer:{'loss': 3.0910018255710603, 'learning_rate': 3.998153179812278e-05, 'epoch': 0.6011080921126334, 'step': 3337500}
INFO:transformers.trainer:{'loss': 3.1963062241077425, 'learning_rate': 3.998003090401014e-05, 'epoch': 0.6011981457593918, 'step': 3338000}
INFO:transformers.trainer:{'loss': 3.118790406703949, 'learning_rate': 3.99785300098975e-05, 'epoch': 0.6012881994061502, 'step': 3338500}
INFO:transformers.trainer:{'loss': 3.1308415319919587, 'learning_rate': 3.9977029115784857e-05, 'epoch': 0.6013782530529087, 'step': 3339000}
INFO:transformers.trainer:{'loss': 3.108742734670639, 'learning_rate': 3.9975528221672216e-05, 'epoch': 0.6014683066996671, 'step': 3339500}
INFO:transformers.trainer:{'loss': 3.160115134716034, 'learning_rate': 3.9974027327559575e-05, 'epoch': 0.6015583603464256, 'step': 3340000}
INFO:transformers.trainer:{'loss': 3.072894876718521, 'learning_rate': 3.9972526433446934e-05, 'epoch': 0.601648413993184, 'step': 3340500}
INFO:transformers.trainer:{'loss': 3.1440753576755522, 'learning_rate': 3.997102553933429e-05, 'epoch': 0.6017384676399424, 'step': 3341000}
INFO:transformers.trainer:{'loss': 3.191908494234085, 'learning_rate': 3.996952464522165e-05, 'epoch': 0.601828521286701, 'step': 3341500}
INFO:transformers.trainer:{'loss': 3.1066256365776064, 'learning_rate': 3.996802375110901e-05, 'epoch': 0.6019185749334593, 'step': 3342000}
INFO:transformers.trainer:{'loss': 3.165633505344391, 'learning_rate': 3.996652285699638e-05, 'epoch': 0.6020086285802178, 'step': 3342500}
INFO:transformers.trainer:{'loss': 3.2166840860843657, 'learning_rate': 3.996502196288373e-05, 'epoch': 0.6020986822269763, 'step': 3343000}
INFO:transformers.trainer:{'loss': 3.1017400281429293, 'learning_rate': 3.9963521068771095e-05, 'epoch': 0.6021887358737347, 'step': 3343500}
INFO:transformers.trainer:{'loss': 3.1007435584068297, 'learning_rate': 3.996202017465845e-05, 'epoch': 0.6022787895204932, 'step': 3344000}
INFO:transformers.trainer:{'loss': 3.0881495020389558, 'learning_rate': 3.996051928054581e-05, 'epoch': 0.6023688431672516, 'step': 3344500}
INFO:transformers.trainer:{'loss': 3.1274076883792876, 'learning_rate': 3.9959018386433165e-05, 'epoch': 0.60245889681401, 'step': 3345000}
INFO:transformers.trainer:{'loss': 3.188706812620163, 'learning_rate': 3.995751749232053e-05, 'epoch': 0.6025489504607685, 'step': 3345500}
INFO:transformers.trainer:{'loss': 3.1676076056957245, 'learning_rate': 3.995601659820788e-05, 'epoch': 0.6026390041075269, 'step': 3346000}
INFO:transformers.trainer:{'loss': 3.124933380126953, 'learning_rate': 3.995451570409525e-05, 'epoch': 0.6027290577542854, 'step': 3346500}
INFO:transformers.trainer:{'loss': 3.1349877692461012, 'learning_rate': 3.99530148099826e-05, 'epoch': 0.6028191114010438, 'step': 3347000}
INFO:transformers.trainer:{'loss': 3.1279009289741517, 'learning_rate': 3.995151391586997e-05, 'epoch': 0.6029091650478022, 'step': 3347500}
INFO:transformers.trainer:{'loss': 3.1404199920892717, 'learning_rate': 3.995001302175732e-05, 'epoch': 0.6029992186945607, 'step': 3348000}
INFO:transformers.trainer:{'loss': 3.14523619556427, 'learning_rate': 3.9948512127644685e-05, 'epoch': 0.6030892723413191, 'step': 3348500}
INFO:transformers.trainer:{'loss': 3.0732552288770676, 'learning_rate': 3.994701123353204e-05, 'epoch': 0.6031793259880777, 'step': 3349000}
INFO:transformers.trainer:{'loss': 3.132935498714447, 'learning_rate': 3.9945510339419403e-05, 'epoch': 0.6032693796348361, 'step': 3349500}
INFO:transformers.trainer:{'loss': 3.1398787442445757, 'learning_rate': 3.994400944530676e-05, 'epoch': 0.6033594332815945, 'step': 3350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1144267773628234, 'learning_rate': 3.994250855119412e-05, 'epoch': 0.603449486928353, 'step': 3350500}
INFO:transformers.trainer:{'loss': 3.171956001996994, 'learning_rate': 3.994100765708148e-05, 'epoch': 0.6035395405751114, 'step': 3351000}
INFO:transformers.trainer:{'loss': 3.1650577411651613, 'learning_rate': 3.993950676296884e-05, 'epoch': 0.6036295942218699, 'step': 3351500}
INFO:transformers.trainer:{'loss': 3.201198782444, 'learning_rate': 3.99380058688562e-05, 'epoch': 0.6037196478686283, 'step': 3352000}
INFO:transformers.trainer:{'loss': 3.1387790582180024, 'learning_rate': 3.993650497474356e-05, 'epoch': 0.6038097015153867, 'step': 3352500}
INFO:transformers.trainer:{'loss': 3.175471978187561, 'learning_rate': 3.993500408063092e-05, 'epoch': 0.6038997551621452, 'step': 3353000}
INFO:transformers.trainer:{'loss': 3.124655874252319, 'learning_rate': 3.9933503186518276e-05, 'epoch': 0.6039898088089036, 'step': 3353500}
INFO:transformers.trainer:{'loss': 3.1500931298732757, 'learning_rate': 3.9932002292405635e-05, 'epoch': 0.6040798624556621, 'step': 3354000}
INFO:transformers.trainer:{'loss': 3.122002056002617, 'learning_rate': 3.9930501398292994e-05, 'epoch': 0.6041699161024205, 'step': 3354500}
INFO:transformers.trainer:{'loss': 3.1006816530227663, 'learning_rate': 3.992900050418035e-05, 'epoch': 0.604259969749179, 'step': 3355000}
INFO:transformers.trainer:{'loss': 3.1292804292440413, 'learning_rate': 3.992749961006771e-05, 'epoch': 0.6043500233959375, 'step': 3355500}
INFO:transformers.trainer:{'loss': 3.172410856246948, 'learning_rate': 3.992599871595507e-05, 'epoch': 0.6044400770426959, 'step': 3356000}
INFO:transformers.trainer:{'loss': 3.175977105855942, 'learning_rate': 3.992449782184243e-05, 'epoch': 0.6045301306894543, 'step': 3356500}
INFO:transformers.trainer:{'loss': 3.162137513399124, 'learning_rate': 3.992299692772979e-05, 'epoch': 0.6046201843362128, 'step': 3357000}
INFO:transformers.trainer:{'loss': 3.138884637832642, 'learning_rate': 3.992149603361715e-05, 'epoch': 0.6047102379829712, 'step': 3357500}
INFO:transformers.trainer:{'loss': 3.122967615842819, 'learning_rate': 3.991999513950451e-05, 'epoch': 0.6048002916297297, 'step': 3358000}
INFO:transformers.trainer:{'loss': 3.16078377699852, 'learning_rate': 3.9918494245391866e-05, 'epoch': 0.6048903452764881, 'step': 3358500}
INFO:transformers.trainer:{'loss': 3.1283186411857606, 'learning_rate': 3.9916993351279225e-05, 'epoch': 0.6049803989232465, 'step': 3359000}
INFO:transformers.trainer:{'loss': 3.1365094912052154, 'learning_rate': 3.9915492457166584e-05, 'epoch': 0.605070452570005, 'step': 3359500}
INFO:transformers.trainer:{'loss': 3.0869179890155793, 'learning_rate': 3.9913991563053943e-05, 'epoch': 0.6051605062167634, 'step': 3360000}
INFO:transformers.trainer:{'loss': 3.181743728399277, 'learning_rate': 3.99124906689413e-05, 'epoch': 0.6052505598635219, 'step': 3360500}
INFO:transformers.trainer:{'loss': 3.137016787290573, 'learning_rate': 3.991098977482866e-05, 'epoch': 0.6053406135102803, 'step': 3361000}
INFO:transformers.trainer:{'loss': 3.138972435474396, 'learning_rate': 3.990948888071602e-05, 'epoch': 0.6054306671570387, 'step': 3361500}
INFO:transformers.trainer:{'loss': 3.1490592305660248, 'learning_rate': 3.990798798660338e-05, 'epoch': 0.6055207208037973, 'step': 3362000}
INFO:transformers.trainer:{'loss': 3.1473608067035674, 'learning_rate': 3.990648709249074e-05, 'epoch': 0.6056107744505557, 'step': 3362500}
INFO:transformers.trainer:{'loss': 3.091100558757782, 'learning_rate': 3.99049861983781e-05, 'epoch': 0.6057008280973142, 'step': 3363000}
INFO:transformers.trainer:{'loss': 3.0987081949710844, 'learning_rate': 3.990348530426546e-05, 'epoch': 0.6057908817440726, 'step': 3363500}
INFO:transformers.trainer:{'loss': 3.1400155324935914, 'learning_rate': 3.990198441015282e-05, 'epoch': 0.605880935390831, 'step': 3364000}
INFO:transformers.trainer:{'loss': 3.165077238559723, 'learning_rate': 3.9900483516040175e-05, 'epoch': 0.6059709890375895, 'step': 3364500}
INFO:transformers.trainer:{'loss': 3.1329125328063965, 'learning_rate': 3.989898262192754e-05, 'epoch': 0.6060610426843479, 'step': 3365000}
INFO:transformers.trainer:{'loss': 3.129282577753067, 'learning_rate': 3.989748172781489e-05, 'epoch': 0.6061510963311064, 'step': 3365500}
INFO:transformers.trainer:{'loss': 3.13166313123703, 'learning_rate': 3.989598083370226e-05, 'epoch': 0.6062411499778648, 'step': 3366000}
INFO:transformers.trainer:{'loss': 3.125380081415176, 'learning_rate': 3.989447993958961e-05, 'epoch': 0.6063312036246232, 'step': 3366500}
INFO:transformers.trainer:{'loss': 3.1981756000518797, 'learning_rate': 3.989297904547698e-05, 'epoch': 0.6064212572713817, 'step': 3367000}
INFO:transformers.trainer:{'loss': 3.158774539232254, 'learning_rate': 3.989147815136433e-05, 'epoch': 0.6065113109181401, 'step': 3367500}
INFO:transformers.trainer:{'loss': 3.1132264003753662, 'learning_rate': 3.9889977257251695e-05, 'epoch': 0.6066013645648985, 'step': 3368000}
INFO:transformers.trainer:{'loss': 3.1551636912822723, 'learning_rate': 3.988847636313905e-05, 'epoch': 0.6066914182116571, 'step': 3368500}
INFO:transformers.trainer:{'loss': 3.186567220211029, 'learning_rate': 3.988697546902641e-05, 'epoch': 0.6067814718584155, 'step': 3369000}
INFO:transformers.trainer:{'loss': 3.077854506254196, 'learning_rate': 3.9885474574913765e-05, 'epoch': 0.606871525505174, 'step': 3369500}
INFO:transformers.trainer:{'loss': 3.1549757368564606, 'learning_rate': 3.988397368080113e-05, 'epoch': 0.6069615791519324, 'step': 3370000}
INFO:transformers.trainer:{'loss': 3.2020553531646727, 'learning_rate': 3.988247278668849e-05, 'epoch': 0.6070516327986908, 'step': 3370500}
INFO:transformers.trainer:{'loss': 3.1565247353315353, 'learning_rate': 3.988097189257585e-05, 'epoch': 0.6071416864454493, 'step': 3371000}
INFO:transformers.trainer:{'loss': 3.194009723544121, 'learning_rate': 3.987947099846321e-05, 'epoch': 0.6072317400922077, 'step': 3371500}
INFO:transformers.trainer:{'loss': 3.102324721813202, 'learning_rate': 3.987797010435057e-05, 'epoch': 0.6073217937389662, 'step': 3372000}
INFO:transformers.trainer:{'loss': 3.1213985875844954, 'learning_rate': 3.9876469210237927e-05, 'epoch': 0.6074118473857246, 'step': 3372500}
INFO:transformers.trainer:{'loss': 3.1526440060138703, 'learning_rate': 3.9874968316125286e-05, 'epoch': 0.607501901032483, 'step': 3373000}
INFO:transformers.trainer:{'loss': 3.167305300831795, 'learning_rate': 3.9873467422012645e-05, 'epoch': 0.6075919546792415, 'step': 3373500}
INFO:transformers.trainer:{'loss': 3.1283854761123657, 'learning_rate': 3.9871966527900004e-05, 'epoch': 0.607682008326, 'step': 3374000}
INFO:transformers.trainer:{'loss': 3.138944790840149, 'learning_rate': 3.987046563378736e-05, 'epoch': 0.6077720619727585, 'step': 3374500}
INFO:transformers.trainer:{'loss': 3.1436776252985, 'learning_rate': 3.986896473967472e-05, 'epoch': 0.6078621156195169, 'step': 3375000}
INFO:transformers.trainer:{'loss': 3.1501841951608656, 'learning_rate': 3.986746384556208e-05, 'epoch': 0.6079521692662753, 'step': 3375500}
INFO:transformers.trainer:{'loss': 3.1336388120651244, 'learning_rate': 3.986596295144944e-05, 'epoch': 0.6080422229130338, 'step': 3376000}
INFO:transformers.trainer:{'loss': 3.1365286231040956, 'learning_rate': 3.98644620573368e-05, 'epoch': 0.6081322765597922, 'step': 3376500}
INFO:transformers.trainer:{'loss': 3.1642287064790726, 'learning_rate': 3.986296116322416e-05, 'epoch': 0.6082223302065507, 'step': 3377000}
INFO:transformers.trainer:{'loss': 3.175064268350601, 'learning_rate': 3.986146026911152e-05, 'epoch': 0.6083123838533091, 'step': 3377500}
INFO:transformers.trainer:{'loss': 3.175551877140999, 'learning_rate': 3.9859959374998876e-05, 'epoch': 0.6084024375000675, 'step': 3378000}
INFO:transformers.trainer:{'loss': 3.132807518959045, 'learning_rate': 3.9858458480886235e-05, 'epoch': 0.608492491146826, 'step': 3378500}
INFO:transformers.trainer:{'loss': 3.1374406082630157, 'learning_rate': 3.9856957586773594e-05, 'epoch': 0.6085825447935844, 'step': 3379000}
INFO:transformers.trainer:{'loss': 3.1537500829696654, 'learning_rate': 3.985545669266095e-05, 'epoch': 0.6086725984403428, 'step': 3379500}
INFO:transformers.trainer:{'loss': 3.124429132938385, 'learning_rate': 3.985395579854831e-05, 'epoch': 0.6087626520871013, 'step': 3380000}
INFO:transformers.trainer:{'loss': 3.1345179030895234, 'learning_rate': 3.985245490443567e-05, 'epoch': 0.6088527057338597, 'step': 3380500}
INFO:transformers.trainer:{'loss': 3.1146202211380003, 'learning_rate': 3.985095401032303e-05, 'epoch': 0.6089427593806183, 'step': 3381000}
INFO:transformers.trainer:{'loss': 3.116916172027588, 'learning_rate': 3.984945311621039e-05, 'epoch': 0.6090328130273767, 'step': 3381500}
INFO:transformers.trainer:{'loss': 3.119576164007187, 'learning_rate': 3.984795222209775e-05, 'epoch': 0.6091228666741351, 'step': 3382000}
INFO:transformers.trainer:{'loss': 3.086181732416153, 'learning_rate': 3.984645132798511e-05, 'epoch': 0.6092129203208936, 'step': 3382500}
INFO:transformers.trainer:{'loss': 3.2001706503629683, 'learning_rate': 3.9844950433872467e-05, 'epoch': 0.609302973967652, 'step': 3383000}
INFO:transformers.trainer:{'loss': 3.172205303788185, 'learning_rate': 3.9843449539759826e-05, 'epoch': 0.6093930276144105, 'step': 3383500}
INFO:transformers.trainer:{'loss': 3.1877584826946257, 'learning_rate': 3.9841948645647185e-05, 'epoch': 0.6094830812611689, 'step': 3384000}
INFO:transformers.trainer:{'loss': 3.135405091762543, 'learning_rate': 3.984044775153455e-05, 'epoch': 0.6095731349079273, 'step': 3384500}
INFO:transformers.trainer:{'loss': 3.1259897924661635, 'learning_rate': 3.98389468574219e-05, 'epoch': 0.6096631885546858, 'step': 3385000}
INFO:transformers.trainer:{'loss': 3.118734810829163, 'learning_rate': 3.983744596330927e-05, 'epoch': 0.6097532422014442, 'step': 3385500}
INFO:transformers.trainer:{'loss': 3.081352807998657, 'learning_rate': 3.983594506919662e-05, 'epoch': 0.6098432958482027, 'step': 3386000}
INFO:transformers.trainer:{'loss': 3.1371792669296266, 'learning_rate': 3.983444417508399e-05, 'epoch': 0.6099333494949611, 'step': 3386500}
INFO:transformers.trainer:{'loss': 3.0897201439142226, 'learning_rate': 3.983294328097134e-05, 'epoch': 0.6100234031417195, 'step': 3387000}
INFO:transformers.trainer:{'loss': 3.194348596274853, 'learning_rate': 3.9831442386858705e-05, 'epoch': 0.6101134567884781, 'step': 3387500}
INFO:transformers.trainer:{'loss': 3.164752929329872, 'learning_rate': 3.982994149274606e-05, 'epoch': 0.6102035104352365, 'step': 3388000}
INFO:transformers.trainer:{'loss': 3.088597821831703, 'learning_rate': 3.982844059863342e-05, 'epoch': 0.610293564081995, 'step': 3388500}
INFO:transformers.trainer:{'loss': 3.2302370901107786, 'learning_rate': 3.9826939704520775e-05, 'epoch': 0.6103836177287534, 'step': 3389000}
INFO:transformers.trainer:{'loss': 3.1537562849521636, 'learning_rate': 3.982543881040814e-05, 'epoch': 0.6104736713755118, 'step': 3389500}
INFO:transformers.trainer:{'loss': 3.117268976688385, 'learning_rate': 3.982393791629549e-05, 'epoch': 0.6105637250222703, 'step': 3390000}
INFO:transformers.trainer:{'loss': 3.138384860992432, 'learning_rate': 3.982243702218286e-05, 'epoch': 0.6106537786690287, 'step': 3390500}
INFO:transformers.trainer:{'loss': 3.1342193467617037, 'learning_rate': 3.982093612807021e-05, 'epoch': 0.6107438323157872, 'step': 3391000}
INFO:transformers.trainer:{'loss': 3.1521101641654967, 'learning_rate': 3.981943523395758e-05, 'epoch': 0.6108338859625456, 'step': 3391500}
INFO:transformers.trainer:{'loss': 3.137520479917526, 'learning_rate': 3.9817934339844936e-05, 'epoch': 0.610923939609304, 'step': 3392000}
INFO:transformers.trainer:{'loss': 3.150915848731995, 'learning_rate': 3.9816433445732295e-05, 'epoch': 0.6110139932560625, 'step': 3392500}
INFO:transformers.trainer:{'loss': 3.1407370433807373, 'learning_rate': 3.9814932551619654e-05, 'epoch': 0.6111040469028209, 'step': 3393000}
INFO:transformers.trainer:{'loss': 3.1670644602775573, 'learning_rate': 3.9813431657507013e-05, 'epoch': 0.6111941005495793, 'step': 3393500}
INFO:transformers.trainer:{'loss': 3.1954283390045166, 'learning_rate': 3.981193076339437e-05, 'epoch': 0.6112841541963379, 'step': 3394000}
INFO:transformers.trainer:{'loss': 3.1474044497013094, 'learning_rate': 3.981042986928173e-05, 'epoch': 0.6113742078430963, 'step': 3394500}
INFO:transformers.trainer:{'loss': 3.165354318857193, 'learning_rate': 3.980892897516909e-05, 'epoch': 0.6114642614898548, 'step': 3395000}
INFO:transformers.trainer:{'loss': 3.168468082785606, 'learning_rate': 3.980742808105645e-05, 'epoch': 0.6115543151366132, 'step': 3395500}
INFO:transformers.trainer:{'loss': 3.1469083461761476, 'learning_rate': 3.980592718694381e-05, 'epoch': 0.6116443687833716, 'step': 3396000}
INFO:transformers.trainer:{'loss': 3.1524775257110598, 'learning_rate': 3.980442629283117e-05, 'epoch': 0.6117344224301301, 'step': 3396500}
INFO:transformers.trainer:{'loss': 3.1539391124248506, 'learning_rate': 3.980292539871853e-05, 'epoch': 0.6118244760768885, 'step': 3397000}
INFO:transformers.trainer:{'loss': 3.118598428249359, 'learning_rate': 3.9801424504605886e-05, 'epoch': 0.611914529723647, 'step': 3397500}
INFO:transformers.trainer:{'loss': 3.217363075733185, 'learning_rate': 3.9799923610493245e-05, 'epoch': 0.6120045833704054, 'step': 3398000}
INFO:transformers.trainer:{'loss': 3.1355002250671387, 'learning_rate': 3.9798422716380604e-05, 'epoch': 0.6120946370171638, 'step': 3398500}
INFO:transformers.trainer:{'loss': 3.196673793554306, 'learning_rate': 3.979692182226796e-05, 'epoch': 0.6121846906639223, 'step': 3399000}
INFO:transformers.trainer:{'loss': 3.135227988600731, 'learning_rate': 3.979542092815532e-05, 'epoch': 0.6122747443106807, 'step': 3399500}
INFO:transformers.trainer:{'loss': 3.1466826766729357, 'learning_rate': 3.979392003404268e-05, 'epoch': 0.6123647979574393, 'step': 3400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.081646078109741, 'learning_rate': 3.979241913993004e-05, 'epoch': 0.6124548516041977, 'step': 3400500}
INFO:transformers.trainer:{'loss': 3.077531042098999, 'learning_rate': 3.97909182458174e-05, 'epoch': 0.6125449052509561, 'step': 3401000}
INFO:transformers.trainer:{'loss': 3.123365722179413, 'learning_rate': 3.978941735170476e-05, 'epoch': 0.6126349588977146, 'step': 3401500}
INFO:transformers.trainer:{'loss': 3.133226808667183, 'learning_rate': 3.978791645759212e-05, 'epoch': 0.612725012544473, 'step': 3402000}
INFO:transformers.trainer:{'loss': 3.1359019939899446, 'learning_rate': 3.9786415563479476e-05, 'epoch': 0.6128150661912315, 'step': 3402500}
INFO:transformers.trainer:{'loss': 3.123745041847229, 'learning_rate': 3.9784914669366835e-05, 'epoch': 0.6129051198379899, 'step': 3403000}
INFO:transformers.trainer:{'loss': 3.13372709608078, 'learning_rate': 3.9783413775254194e-05, 'epoch': 0.6129951734847483, 'step': 3403500}
INFO:transformers.trainer:{'loss': 3.1168985722064972, 'learning_rate': 3.9781912881141553e-05, 'epoch': 0.6130852271315068, 'step': 3404000}
INFO:transformers.trainer:{'loss': 3.1779179458618163, 'learning_rate': 3.978041198702891e-05, 'epoch': 0.6131752807782652, 'step': 3404500}
INFO:transformers.trainer:{'loss': 3.0816850848197936, 'learning_rate': 3.977891109291628e-05, 'epoch': 0.6132653344250236, 'step': 3405000}
INFO:transformers.trainer:{'loss': 3.1245924830436707, 'learning_rate': 3.977741019880363e-05, 'epoch': 0.6133553880717821, 'step': 3405500}
INFO:transformers.trainer:{'loss': 3.134837087869644, 'learning_rate': 3.9775909304690996e-05, 'epoch': 0.6134454417185405, 'step': 3406000}
INFO:transformers.trainer:{'loss': 3.1822303457260133, 'learning_rate': 3.977440841057835e-05, 'epoch': 0.613535495365299, 'step': 3406500}
INFO:transformers.trainer:{'loss': 3.12441681265831, 'learning_rate': 3.9772907516465715e-05, 'epoch': 0.6136255490120575, 'step': 3407000}
INFO:transformers.trainer:{'loss': 3.1210861959457397, 'learning_rate': 3.977140662235307e-05, 'epoch': 0.6137156026588159, 'step': 3407500}
INFO:transformers.trainer:{'loss': 3.1835910295248033, 'learning_rate': 3.976990572824043e-05, 'epoch': 0.6138056563055744, 'step': 3408000}
INFO:transformers.trainer:{'loss': 3.111579741001129, 'learning_rate': 3.9768404834127785e-05, 'epoch': 0.6138957099523328, 'step': 3408500}
INFO:transformers.trainer:{'loss': 3.140405184984207, 'learning_rate': 3.976690394001515e-05, 'epoch': 0.6139857635990913, 'step': 3409000}
INFO:transformers.trainer:{'loss': 3.131646434903145, 'learning_rate': 3.97654030459025e-05, 'epoch': 0.6140758172458497, 'step': 3409500}
INFO:transformers.trainer:{'loss': 3.135147485256195, 'learning_rate': 3.976390215178987e-05, 'epoch': 0.6141658708926081, 'step': 3410000}
INFO:transformers.trainer:{'loss': 3.1349242289066312, 'learning_rate': 3.976240125767722e-05, 'epoch': 0.6142559245393666, 'step': 3410500}
INFO:transformers.trainer:{'loss': 3.12718412232399, 'learning_rate': 3.976090036356459e-05, 'epoch': 0.614345978186125, 'step': 3411000}
INFO:transformers.trainer:{'loss': 3.1144692180156706, 'learning_rate': 3.975939946945194e-05, 'epoch': 0.6144360318328835, 'step': 3411500}
INFO:transformers.trainer:{'loss': 3.171260602712631, 'learning_rate': 3.9757898575339305e-05, 'epoch': 0.6145260854796419, 'step': 3412000}
INFO:transformers.trainer:{'loss': 3.1512620282173156, 'learning_rate': 3.9756397681226664e-05, 'epoch': 0.6146161391264003, 'step': 3412500}
INFO:transformers.trainer:{'loss': 3.1799975023269655, 'learning_rate': 3.975489678711402e-05, 'epoch': 0.6147061927731589, 'step': 3413000}
INFO:transformers.trainer:{'loss': 3.106598451137543, 'learning_rate': 3.975339589300138e-05, 'epoch': 0.6147962464199173, 'step': 3413500}
INFO:transformers.trainer:{'loss': 3.125964830636978, 'learning_rate': 3.975189499888874e-05, 'epoch': 0.6148863000666758, 'step': 3414000}
INFO:transformers.trainer:{'loss': 3.1183837094306948, 'learning_rate': 3.97503941047761e-05, 'epoch': 0.6149763537134342, 'step': 3414500}
INFO:transformers.trainer:{'loss': 3.123068319439888, 'learning_rate': 3.974889321066346e-05, 'epoch': 0.6150664073601926, 'step': 3415000}
INFO:transformers.trainer:{'loss': 3.156614161014557, 'learning_rate': 3.974739231655082e-05, 'epoch': 0.6151564610069511, 'step': 3415500}
INFO:transformers.trainer:{'loss': 3.0685401511192323, 'learning_rate': 3.974589142243818e-05, 'epoch': 0.6152465146537095, 'step': 3416000}
INFO:transformers.trainer:{'loss': 3.139345077753067, 'learning_rate': 3.9744390528325536e-05, 'epoch': 0.6153365683004679, 'step': 3416500}
INFO:transformers.trainer:{'loss': 3.116285409450531, 'learning_rate': 3.9742889634212896e-05, 'epoch': 0.6154266219472264, 'step': 3417000}
INFO:transformers.trainer:{'loss': 3.1955027499198914, 'learning_rate': 3.9741388740100255e-05, 'epoch': 0.6155166755939848, 'step': 3417500}
INFO:transformers.trainer:{'loss': 3.109254155039787, 'learning_rate': 3.9739887845987614e-05, 'epoch': 0.6156067292407433, 'step': 3418000}
INFO:transformers.trainer:{'loss': 3.1264162256717682, 'learning_rate': 3.973838695187497e-05, 'epoch': 0.6156967828875017, 'step': 3418500}
INFO:transformers.trainer:{'loss': 3.045116447210312, 'learning_rate': 3.973688605776233e-05, 'epoch': 0.6157868365342601, 'step': 3419000}
INFO:transformers.trainer:{'loss': 3.1429942977428436, 'learning_rate': 3.973538516364969e-05, 'epoch': 0.6158768901810187, 'step': 3419500}
INFO:transformers.trainer:{'loss': 3.1522247552871705, 'learning_rate': 3.973388426953705e-05, 'epoch': 0.6159669438277771, 'step': 3420000}
INFO:transformers.trainer:{'loss': 3.101389216899872, 'learning_rate': 3.973238337542441e-05, 'epoch': 0.6160569974745356, 'step': 3420500}
INFO:transformers.trainer:{'loss': 3.143982043027878, 'learning_rate': 3.973088248131177e-05, 'epoch': 0.616147051121294, 'step': 3421000}
INFO:transformers.trainer:{'loss': 3.1579953458309173, 'learning_rate': 3.972938158719913e-05, 'epoch': 0.6162371047680524, 'step': 3421500}
INFO:transformers.trainer:{'loss': 3.136034345626831, 'learning_rate': 3.9727880693086486e-05, 'epoch': 0.6163271584148109, 'step': 3422000}
INFO:transformers.trainer:{'loss': 3.1595051703453065, 'learning_rate': 3.9726379798973845e-05, 'epoch': 0.6164172120615693, 'step': 3422500}
INFO:transformers.trainer:{'loss': 3.1152205169200897, 'learning_rate': 3.9724878904861204e-05, 'epoch': 0.6165072657083278, 'step': 3423000}
INFO:transformers.trainer:{'loss': 3.1517323949337004, 'learning_rate': 3.972337801074856e-05, 'epoch': 0.6165973193550862, 'step': 3423500}
INFO:transformers.trainer:{'loss': 3.1110071692466734, 'learning_rate': 3.972187711663592e-05, 'epoch': 0.6166873730018446, 'step': 3424000}
INFO:transformers.trainer:{'loss': 3.1680719571113585, 'learning_rate': 3.972037622252328e-05, 'epoch': 0.6167774266486031, 'step': 3424500}
INFO:transformers.trainer:{'loss': 3.103541375398636, 'learning_rate': 3.971887532841064e-05, 'epoch': 0.6168674802953615, 'step': 3425000}
INFO:transformers.trainer:{'loss': 3.1327959175109865, 'learning_rate': 3.9717374434298e-05, 'epoch': 0.61695753394212, 'step': 3425500}
INFO:transformers.trainer:{'loss': 3.0810193339586256, 'learning_rate': 3.971587354018536e-05, 'epoch': 0.6170475875888785, 'step': 3426000}
INFO:transformers.trainer:{'loss': 3.185460073471069, 'learning_rate': 3.9714372646072724e-05, 'epoch': 0.6171376412356369, 'step': 3426500}
INFO:transformers.trainer:{'loss': 3.1375272636413576, 'learning_rate': 3.9712871751960077e-05, 'epoch': 0.6172276948823954, 'step': 3427000}
INFO:transformers.trainer:{'loss': 3.1311968004703523, 'learning_rate': 3.971137085784744e-05, 'epoch': 0.6173177485291538, 'step': 3427500}
INFO:transformers.trainer:{'loss': 3.129401512622833, 'learning_rate': 3.9709869963734795e-05, 'epoch': 0.6174078021759122, 'step': 3428000}
INFO:transformers.trainer:{'loss': 3.1659621531963347, 'learning_rate': 3.970836906962216e-05, 'epoch': 0.6174978558226707, 'step': 3428500}
INFO:transformers.trainer:{'loss': 3.153856523513794, 'learning_rate': 3.970686817550951e-05, 'epoch': 0.6175879094694291, 'step': 3429000}
INFO:transformers.trainer:{'loss': 3.1490591955184937, 'learning_rate': 3.970536728139688e-05, 'epoch': 0.6176779631161876, 'step': 3429500}
INFO:transformers.trainer:{'loss': 3.091965013742447, 'learning_rate': 3.970386638728423e-05, 'epoch': 0.617768016762946, 'step': 3430000}
INFO:transformers.trainer:{'loss': 3.1472653980255125, 'learning_rate': 3.97023654931716e-05, 'epoch': 0.6178580704097044, 'step': 3430500}
INFO:transformers.trainer:{'loss': 3.1372927997112274, 'learning_rate': 3.970086459905895e-05, 'epoch': 0.6179481240564629, 'step': 3431000}
INFO:transformers.trainer:{'loss': 3.0962062158584596, 'learning_rate': 3.9699363704946315e-05, 'epoch': 0.6180381777032213, 'step': 3431500}
INFO:transformers.trainer:{'loss': 3.1414253334999085, 'learning_rate': 3.969786281083367e-05, 'epoch': 0.6181282313499799, 'step': 3432000}
INFO:transformers.trainer:{'loss': 3.1950567004680632, 'learning_rate': 3.969636191672103e-05, 'epoch': 0.6182182849967383, 'step': 3432500}
INFO:transformers.trainer:{'loss': 3.1992907555103303, 'learning_rate': 3.969486102260839e-05, 'epoch': 0.6183083386434967, 'step': 3433000}
INFO:transformers.trainer:{'loss': 3.2076280558109285, 'learning_rate': 3.969336012849575e-05, 'epoch': 0.6183983922902552, 'step': 3433500}
INFO:transformers.trainer:{'loss': 3.157402618408203, 'learning_rate': 3.969185923438311e-05, 'epoch': 0.6184884459370136, 'step': 3434000}
INFO:transformers.trainer:{'loss': 3.1449958472251893, 'learning_rate': 3.969035834027047e-05, 'epoch': 0.6185784995837721, 'step': 3434500}
INFO:transformers.trainer:{'loss': 3.1306087367534636, 'learning_rate': 3.968885744615783e-05, 'epoch': 0.6186685532305305, 'step': 3435000}
INFO:transformers.trainer:{'loss': 3.0988815816640853, 'learning_rate': 3.968735655204519e-05, 'epoch': 0.6187586068772889, 'step': 3435500}
INFO:transformers.trainer:{'loss': 3.165339013338089, 'learning_rate': 3.9685855657932546e-05, 'epoch': 0.6188486605240474, 'step': 3436000}
INFO:transformers.trainer:{'loss': 3.112256204366684, 'learning_rate': 3.9684354763819905e-05, 'epoch': 0.6189387141708058, 'step': 3436500}
INFO:transformers.trainer:{'loss': 3.1202264556884765, 'learning_rate': 3.9682853869707264e-05, 'epoch': 0.6190287678175643, 'step': 3437000}
INFO:transformers.trainer:{'loss': 3.1185362401008607, 'learning_rate': 3.968135297559462e-05, 'epoch': 0.6191188214643227, 'step': 3437500}
INFO:transformers.trainer:{'loss': 3.150245351076126, 'learning_rate': 3.967985208148198e-05, 'epoch': 0.6192088751110811, 'step': 3438000}
INFO:transformers.trainer:{'loss': 3.149671067237854, 'learning_rate': 3.967835118736934e-05, 'epoch': 0.6192989287578397, 'step': 3438500}
INFO:transformers.trainer:{'loss': 3.0971680006980895, 'learning_rate': 3.96768502932567e-05, 'epoch': 0.619388982404598, 'step': 3439000}
INFO:transformers.trainer:{'loss': 3.12303208065033, 'learning_rate': 3.967534939914406e-05, 'epoch': 0.6194790360513566, 'step': 3439500}
INFO:transformers.trainer:{'loss': 3.183576204061508, 'learning_rate': 3.967384850503142e-05, 'epoch': 0.619569089698115, 'step': 3440000}
INFO:transformers.trainer:{'loss': 3.146036619544029, 'learning_rate': 3.967234761091878e-05, 'epoch': 0.6196591433448734, 'step': 3440500}
INFO:transformers.trainer:{'loss': 3.1685378170013427, 'learning_rate': 3.967084671680614e-05, 'epoch': 0.6197491969916319, 'step': 3441000}
INFO:transformers.trainer:{'loss': 3.1800189745426177, 'learning_rate': 3.9669345822693496e-05, 'epoch': 0.6198392506383903, 'step': 3441500}
INFO:transformers.trainer:{'loss': 3.1316948347091675, 'learning_rate': 3.9667844928580855e-05, 'epoch': 0.6199293042851487, 'step': 3442000}
INFO:transformers.trainer:{'loss': 3.1632190992832183, 'learning_rate': 3.9666344034468214e-05, 'epoch': 0.6200193579319072, 'step': 3442500}
INFO:transformers.trainer:{'loss': 3.1035487096309664, 'learning_rate': 3.966484314035557e-05, 'epoch': 0.6201094115786656, 'step': 3443000}
INFO:transformers.trainer:{'loss': 3.1426753985881803, 'learning_rate': 3.966334224624293e-05, 'epoch': 0.6201994652254241, 'step': 3443500}
INFO:transformers.trainer:{'loss': 3.1504701964855193, 'learning_rate': 3.966184135213029e-05, 'epoch': 0.6202895188721825, 'step': 3444000}
INFO:transformers.trainer:{'loss': 3.097652257204056, 'learning_rate': 3.966034045801765e-05, 'epoch': 0.6203795725189409, 'step': 3444500}
INFO:transformers.trainer:{'loss': 3.1820466257333755, 'learning_rate': 3.965883956390501e-05, 'epoch': 0.6204696261656995, 'step': 3445000}
INFO:transformers.trainer:{'loss': 3.108066265106201, 'learning_rate': 3.965733866979237e-05, 'epoch': 0.6205596798124579, 'step': 3445500}
INFO:transformers.trainer:{'loss': 3.200689812898636, 'learning_rate': 3.965583777567973e-05, 'epoch': 0.6206497334592164, 'step': 3446000}
INFO:transformers.trainer:{'loss': 3.115837962150574, 'learning_rate': 3.9654336881567086e-05, 'epoch': 0.6207397871059748, 'step': 3446500}
INFO:transformers.trainer:{'loss': 3.1481937334537506, 'learning_rate': 3.965283598745445e-05, 'epoch': 0.6208298407527332, 'step': 3447000}
INFO:transformers.trainer:{'loss': 3.1302899219989775, 'learning_rate': 3.9651335093341804e-05, 'epoch': 0.6209198943994917, 'step': 3447500}
INFO:transformers.trainer:{'loss': 3.162655746340752, 'learning_rate': 3.964983419922917e-05, 'epoch': 0.6210099480462501, 'step': 3448000}
INFO:transformers.trainer:{'loss': 3.1133802926540373, 'learning_rate': 3.964833330511652e-05, 'epoch': 0.6211000016930086, 'step': 3448500}
INFO:transformers.trainer:{'loss': 3.1250443341732024, 'learning_rate': 3.964683241100389e-05, 'epoch': 0.621190055339767, 'step': 3449000}
INFO:transformers.trainer:{'loss': 3.1683080151081087, 'learning_rate': 3.964533151689124e-05, 'epoch': 0.6212801089865254, 'step': 3449500}
INFO:transformers.trainer:{'loss': 3.1335691874027254, 'learning_rate': 3.9643830622778606e-05, 'epoch': 0.6213701626332839, 'step': 3450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1086376584768294, 'learning_rate': 3.964232972866596e-05, 'epoch': 0.6214602162800423, 'step': 3450500}
INFO:transformers.trainer:{'loss': 3.122414572119713, 'learning_rate': 3.9640828834553324e-05, 'epoch': 0.6215502699268008, 'step': 3451000}
INFO:transformers.trainer:{'loss': 3.169302017211914, 'learning_rate': 3.963932794044068e-05, 'epoch': 0.6216403235735593, 'step': 3451500}
INFO:transformers.trainer:{'loss': 3.122999858379364, 'learning_rate': 3.963782704632804e-05, 'epoch': 0.6217303772203177, 'step': 3452000}
INFO:transformers.trainer:{'loss': 3.1391616835594176, 'learning_rate': 3.9636326152215395e-05, 'epoch': 0.6218204308670762, 'step': 3452500}
INFO:transformers.trainer:{'loss': 3.147710059165955, 'learning_rate': 3.963482525810276e-05, 'epoch': 0.6219104845138346, 'step': 3453000}
INFO:transformers.trainer:{'loss': 3.0898326287269593, 'learning_rate': 3.963332436399012e-05, 'epoch': 0.622000538160593, 'step': 3453500}
INFO:transformers.trainer:{'loss': 3.1041604099273683, 'learning_rate': 3.963182346987748e-05, 'epoch': 0.6220905918073515, 'step': 3454000}
INFO:transformers.trainer:{'loss': 3.1233537549972534, 'learning_rate': 3.963032257576484e-05, 'epoch': 0.6221806454541099, 'step': 3454500}
INFO:transformers.trainer:{'loss': 3.1519784818887713, 'learning_rate': 3.96288216816522e-05, 'epoch': 0.6222706991008684, 'step': 3455000}
INFO:transformers.trainer:{'loss': 3.1739735441207886, 'learning_rate': 3.9627320787539556e-05, 'epoch': 0.6223607527476268, 'step': 3455500}
INFO:transformers.trainer:{'loss': 3.08631771171093, 'learning_rate': 3.9625819893426915e-05, 'epoch': 0.6224508063943852, 'step': 3456000}
INFO:transformers.trainer:{'loss': 3.1145671648979185, 'learning_rate': 3.9624318999314274e-05, 'epoch': 0.6225408600411437, 'step': 3456500}
INFO:transformers.trainer:{'loss': 3.135810963153839, 'learning_rate': 3.962281810520163e-05, 'epoch': 0.6226309136879021, 'step': 3457000}
INFO:transformers.trainer:{'loss': 3.0943255301713943, 'learning_rate': 3.962131721108899e-05, 'epoch': 0.6227209673346606, 'step': 3457500}
INFO:transformers.trainer:{'loss': 3.1891198823451994, 'learning_rate': 3.961981631697635e-05, 'epoch': 0.622811020981419, 'step': 3458000}
INFO:transformers.trainer:{'loss': 3.169809864997864, 'learning_rate': 3.961831542286371e-05, 'epoch': 0.6229010746281775, 'step': 3458500}
INFO:transformers.trainer:{'loss': 3.073602935552597, 'learning_rate': 3.961681452875107e-05, 'epoch': 0.622991128274936, 'step': 3459000}
INFO:transformers.trainer:{'loss': 3.1476333332061768, 'learning_rate': 3.961531363463843e-05, 'epoch': 0.6230811819216944, 'step': 3459500}
INFO:transformers.trainer:{'loss': 3.165817579030991, 'learning_rate': 3.961381274052579e-05, 'epoch': 0.6231712355684529, 'step': 3460000}
INFO:transformers.trainer:{'loss': 3.1265277613401414, 'learning_rate': 3.9612311846413146e-05, 'epoch': 0.6232612892152113, 'step': 3460500}
INFO:transformers.trainer:{'loss': 3.1200154371261597, 'learning_rate': 3.961081095230051e-05, 'epoch': 0.6233513428619697, 'step': 3461000}
INFO:transformers.trainer:{'loss': 3.1164043400287627, 'learning_rate': 3.9609310058187865e-05, 'epoch': 0.6234413965087282, 'step': 3461500}
INFO:transformers.trainer:{'loss': 3.102713272809982, 'learning_rate': 3.9607809164075224e-05, 'epoch': 0.6235314501554866, 'step': 3462000}
INFO:transformers.trainer:{'loss': 3.199425940871239, 'learning_rate': 3.960630826996258e-05, 'epoch': 0.6236215038022451, 'step': 3462500}
INFO:transformers.trainer:{'loss': 3.1576019089221954, 'learning_rate': 3.960480737584994e-05, 'epoch': 0.6237115574490035, 'step': 3463000}
INFO:transformers.trainer:{'loss': 3.1512342805862428, 'learning_rate': 3.96033064817373e-05, 'epoch': 0.6238016110957619, 'step': 3463500}
INFO:transformers.trainer:{'loss': 3.126354145526886, 'learning_rate': 3.960180558762466e-05, 'epoch': 0.6238916647425204, 'step': 3464000}
INFO:transformers.trainer:{'loss': 3.197262170791626, 'learning_rate': 3.960030469351202e-05, 'epoch': 0.6239817183892788, 'step': 3464500}
INFO:transformers.trainer:{'loss': 3.1084479496479034, 'learning_rate': 3.959880379939938e-05, 'epoch': 0.6240717720360373, 'step': 3465000}
INFO:transformers.trainer:{'loss': 3.1168115127086637, 'learning_rate': 3.959730290528674e-05, 'epoch': 0.6241618256827958, 'step': 3465500}
INFO:transformers.trainer:{'loss': 3.176302041053772, 'learning_rate': 3.9595802011174096e-05, 'epoch': 0.6242518793295542, 'step': 3466000}
INFO:transformers.trainer:{'loss': 3.1618530966043474, 'learning_rate': 3.9594301117061455e-05, 'epoch': 0.6243419329763127, 'step': 3466500}
INFO:transformers.trainer:{'loss': 3.129840605378151, 'learning_rate': 3.9592800222948814e-05, 'epoch': 0.6244319866230711, 'step': 3467000}
INFO:transformers.trainer:{'loss': 3.152989366531372, 'learning_rate': 3.959129932883618e-05, 'epoch': 0.6245220402698295, 'step': 3467500}
INFO:transformers.trainer:{'loss': 3.1920165338516235, 'learning_rate': 3.958979843472353e-05, 'epoch': 0.624612093916588, 'step': 3468000}
INFO:transformers.trainer:{'loss': 3.0802077751159667, 'learning_rate': 3.95882975406109e-05, 'epoch': 0.6247021475633464, 'step': 3468500}
INFO:transformers.trainer:{'loss': 3.1406284518241883, 'learning_rate': 3.958679664649825e-05, 'epoch': 0.6247922012101049, 'step': 3469000}
INFO:transformers.trainer:{'loss': 3.0947303264141084, 'learning_rate': 3.9585295752385616e-05, 'epoch': 0.6248822548568633, 'step': 3469500}
INFO:transformers.trainer:{'loss': 3.0982346909046172, 'learning_rate': 3.958379485827297e-05, 'epoch': 0.6249723085036217, 'step': 3470000}
INFO:transformers.trainer:{'loss': 3.114032343864441, 'learning_rate': 3.9582293964160334e-05, 'epoch': 0.6250623621503802, 'step': 3470500}
INFO:transformers.trainer:{'loss': 3.180426893949509, 'learning_rate': 3.9580793070047686e-05, 'epoch': 0.6251524157971386, 'step': 3471000}
INFO:transformers.trainer:{'loss': 3.0941312720775604, 'learning_rate': 3.957929217593505e-05, 'epoch': 0.6252424694438972, 'step': 3471500}
INFO:transformers.trainer:{'loss': 3.1125257283449175, 'learning_rate': 3.9577791281822405e-05, 'epoch': 0.6253325230906556, 'step': 3472000}
INFO:transformers.trainer:{'loss': 3.0766578295230866, 'learning_rate': 3.957629038770977e-05, 'epoch': 0.625422576737414, 'step': 3472500}
INFO:transformers.trainer:{'loss': 3.1546370906829835, 'learning_rate': 3.957478949359712e-05, 'epoch': 0.6255126303841725, 'step': 3473000}
INFO:transformers.trainer:{'loss': 3.136316525220871, 'learning_rate': 3.957328859948449e-05, 'epoch': 0.6256026840309309, 'step': 3473500}
INFO:transformers.trainer:{'loss': 3.1322043294906616, 'learning_rate': 3.957178770537184e-05, 'epoch': 0.6256927376776894, 'step': 3474000}
INFO:transformers.trainer:{'loss': 3.071791563749313, 'learning_rate': 3.9570286811259207e-05, 'epoch': 0.6257827913244478, 'step': 3474500}
INFO:transformers.trainer:{'loss': 3.1269737374782562, 'learning_rate': 3.9568785917146566e-05, 'epoch': 0.6258728449712062, 'step': 3475000}
INFO:transformers.trainer:{'loss': 3.1674489860534667, 'learning_rate': 3.9567285023033925e-05, 'epoch': 0.6259628986179647, 'step': 3475500}
INFO:transformers.trainer:{'loss': 3.1743104066848753, 'learning_rate': 3.9565784128921284e-05, 'epoch': 0.6260529522647231, 'step': 3476000}
INFO:transformers.trainer:{'loss': 3.138178560972214, 'learning_rate': 3.956428323480864e-05, 'epoch': 0.6261430059114816, 'step': 3476500}
INFO:transformers.trainer:{'loss': 3.1287567386627195, 'learning_rate': 3.9562782340696e-05, 'epoch': 0.62623305955824, 'step': 3477000}
INFO:transformers.trainer:{'loss': 3.1099847333431243, 'learning_rate': 3.956128144658336e-05, 'epoch': 0.6263231132049984, 'step': 3477500}
INFO:transformers.trainer:{'loss': 3.101185056209564, 'learning_rate': 3.955978055247072e-05, 'epoch': 0.626413166851757, 'step': 3478000}
INFO:transformers.trainer:{'loss': 3.1316847739219664, 'learning_rate': 3.955827965835808e-05, 'epoch': 0.6265032204985154, 'step': 3478500}
INFO:transformers.trainer:{'loss': 3.124336945772171, 'learning_rate': 3.955677876424544e-05, 'epoch': 0.6265932741452738, 'step': 3479000}
INFO:transformers.trainer:{'loss': 3.1197528643608092, 'learning_rate': 3.95552778701328e-05, 'epoch': 0.6266833277920323, 'step': 3479500}
INFO:transformers.trainer:{'loss': 3.097948806524277, 'learning_rate': 3.9553776976020156e-05, 'epoch': 0.6267733814387907, 'step': 3480000}
INFO:transformers.trainer:{'loss': 3.1578563525676726, 'learning_rate': 3.9552276081907515e-05, 'epoch': 0.6268634350855492, 'step': 3480500}
INFO:transformers.trainer:{'loss': 3.11215151309967, 'learning_rate': 3.9550775187794874e-05, 'epoch': 0.6269534887323076, 'step': 3481000}
INFO:transformers.trainer:{'loss': 3.1288316870927813, 'learning_rate': 3.954927429368224e-05, 'epoch': 0.627043542379066, 'step': 3481500}
INFO:transformers.trainer:{'loss': 3.083540591478348, 'learning_rate': 3.954777339956959e-05, 'epoch': 0.6271335960258245, 'step': 3482000}
INFO:transformers.trainer:{'loss': 3.1838033690452576, 'learning_rate': 3.954627250545696e-05, 'epoch': 0.6272236496725829, 'step': 3482500}
INFO:transformers.trainer:{'loss': 3.193622447371483, 'learning_rate': 3.954477161134431e-05, 'epoch': 0.6273137033193414, 'step': 3483000}
INFO:transformers.trainer:{'loss': 3.1222076184749605, 'learning_rate': 3.9543270717231676e-05, 'epoch': 0.6274037569660998, 'step': 3483500}
INFO:transformers.trainer:{'loss': 3.125634598493576, 'learning_rate': 3.954176982311903e-05, 'epoch': 0.6274938106128582, 'step': 3484000}
INFO:transformers.trainer:{'loss': 3.1308288843631744, 'learning_rate': 3.9540268929006394e-05, 'epoch': 0.6275838642596168, 'step': 3484500}
INFO:transformers.trainer:{'loss': 3.1472780561447142, 'learning_rate': 3.953876803489375e-05, 'epoch': 0.6276739179063752, 'step': 3485000}
INFO:transformers.trainer:{'loss': 3.092196781396866, 'learning_rate': 3.9537267140781106e-05, 'epoch': 0.6277639715531337, 'step': 3485500}
INFO:transformers.trainer:{'loss': 3.2168356635570525, 'learning_rate': 3.9535766246668465e-05, 'epoch': 0.6278540251998921, 'step': 3486000}
INFO:transformers.trainer:{'loss': 3.099580282151699, 'learning_rate': 3.9534265352555824e-05, 'epoch': 0.6279440788466505, 'step': 3486500}
INFO:transformers.trainer:{'loss': 3.1044812417030334, 'learning_rate': 3.953276445844318e-05, 'epoch': 0.628034132493409, 'step': 3487000}
INFO:transformers.trainer:{'loss': 3.156238693475723, 'learning_rate': 3.953126356433054e-05, 'epoch': 0.6281241861401674, 'step': 3487500}
INFO:transformers.trainer:{'loss': 3.1129128350019455, 'learning_rate': 3.95297626702179e-05, 'epoch': 0.6282142397869259, 'step': 3488000}
INFO:transformers.trainer:{'loss': 3.092449737071991, 'learning_rate': 3.952826177610526e-05, 'epoch': 0.6283042934336843, 'step': 3488500}
INFO:transformers.trainer:{'loss': 3.1323016703128816, 'learning_rate': 3.9526760881992626e-05, 'epoch': 0.6283943470804427, 'step': 3489000}
INFO:transformers.trainer:{'loss': 3.178283033847809, 'learning_rate': 3.952525998787998e-05, 'epoch': 0.6284844007272012, 'step': 3489500}
INFO:transformers.trainer:{'loss': 3.084995563864708, 'learning_rate': 3.9523759093767344e-05, 'epoch': 0.6285744543739596, 'step': 3490000}
INFO:transformers.trainer:{'loss': 3.131008851766586, 'learning_rate': 3.9522258199654696e-05, 'epoch': 0.628664508020718, 'step': 3490500}
INFO:transformers.trainer:{'loss': 3.1303308696746828, 'learning_rate': 3.952075730554206e-05, 'epoch': 0.6287545616674766, 'step': 3491000}
INFO:transformers.trainer:{'loss': 3.152407336235046, 'learning_rate': 3.9519256411429414e-05, 'epoch': 0.628844615314235, 'step': 3491500}
INFO:transformers.trainer:{'loss': 3.0955989100933077, 'learning_rate': 3.951775551731678e-05, 'epoch': 0.6289346689609935, 'step': 3492000}
INFO:transformers.trainer:{'loss': 3.0533503872156142, 'learning_rate': 3.951625462320413e-05, 'epoch': 0.6290247226077519, 'step': 3492500}
INFO:transformers.trainer:{'loss': 3.1840436975955964, 'learning_rate': 3.95147537290915e-05, 'epoch': 0.6291147762545103, 'step': 3493000}
INFO:transformers.trainer:{'loss': 3.0813290746212005, 'learning_rate': 3.951325283497885e-05, 'epoch': 0.6292048299012688, 'step': 3493500}
INFO:transformers.trainer:{'loss': 3.1475139036178588, 'learning_rate': 3.9511751940866216e-05, 'epoch': 0.6292948835480272, 'step': 3494000}
INFO:transformers.trainer:{'loss': 3.1123077985048293, 'learning_rate': 3.951025104675357e-05, 'epoch': 0.6293849371947857, 'step': 3494500}
INFO:transformers.trainer:{'loss': 3.1146299872398377, 'learning_rate': 3.9508750152640934e-05, 'epoch': 0.6294749908415441, 'step': 3495000}
INFO:transformers.trainer:{'loss': 3.171372972846031, 'learning_rate': 3.9507249258528293e-05, 'epoch': 0.6295650444883025, 'step': 3495500}
INFO:transformers.trainer:{'loss': 3.105380329012871, 'learning_rate': 3.950574836441565e-05, 'epoch': 0.629655098135061, 'step': 3496000}
INFO:transformers.trainer:{'loss': 3.1540856249332427, 'learning_rate': 3.950424747030301e-05, 'epoch': 0.6297451517818194, 'step': 3496500}
INFO:transformers.trainer:{'loss': 3.1355098588466643, 'learning_rate': 3.950274657619037e-05, 'epoch': 0.629835205428578, 'step': 3497000}
INFO:transformers.trainer:{'loss': 3.132650549173355, 'learning_rate': 3.950124568207773e-05, 'epoch': 0.6299252590753364, 'step': 3497500}
INFO:transformers.trainer:{'loss': 3.129685217022896, 'learning_rate': 3.949974478796509e-05, 'epoch': 0.6300153127220948, 'step': 3498000}
INFO:transformers.trainer:{'loss': 3.078206385731697, 'learning_rate': 3.949824389385245e-05, 'epoch': 0.6301053663688533, 'step': 3498500}
INFO:transformers.trainer:{'loss': 3.1262279663085937, 'learning_rate': 3.949674299973981e-05, 'epoch': 0.6301954200156117, 'step': 3499000}
INFO:transformers.trainer:{'loss': 3.1442230377197267, 'learning_rate': 3.9495242105627166e-05, 'epoch': 0.6302854736623702, 'step': 3499500}
INFO:transformers.trainer:{'loss': 3.142161534309387, 'learning_rate': 3.9493741211514525e-05, 'epoch': 0.6303755273091286, 'step': 3500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.2096842013597486, 'learning_rate': 3.9492240317401884e-05, 'epoch': 0.630465580955887, 'step': 3500500}
INFO:transformers.trainer:{'loss': 3.1443683931827544, 'learning_rate': 3.949073942328924e-05, 'epoch': 0.6305556346026455, 'step': 3501000}
INFO:transformers.trainer:{'loss': 3.184440285205841, 'learning_rate': 3.94892385291766e-05, 'epoch': 0.6306456882494039, 'step': 3501500}
INFO:transformers.trainer:{'loss': 3.0742174489498137, 'learning_rate': 3.948773763506397e-05, 'epoch': 0.6307357418961623, 'step': 3502000}
INFO:transformers.trainer:{'loss': 3.0999710757732393, 'learning_rate': 3.948623674095132e-05, 'epoch': 0.6308257955429208, 'step': 3502500}
INFO:transformers.trainer:{'loss': 3.123748392343521, 'learning_rate': 3.9484735846838686e-05, 'epoch': 0.6309158491896792, 'step': 3503000}
INFO:transformers.trainer:{'loss': 3.13253147983551, 'learning_rate': 3.948323495272604e-05, 'epoch': 0.6310059028364378, 'step': 3503500}
INFO:transformers.trainer:{'loss': 3.107771807551384, 'learning_rate': 3.9481734058613404e-05, 'epoch': 0.6310959564831962, 'step': 3504000}
INFO:transformers.trainer:{'loss': 3.1310175000429155, 'learning_rate': 3.9480233164500756e-05, 'epoch': 0.6311860101299546, 'step': 3504500}
INFO:transformers.trainer:{'loss': 3.1000853543281557, 'learning_rate': 3.947873227038812e-05, 'epoch': 0.6312760637767131, 'step': 3505000}
INFO:transformers.trainer:{'loss': 3.113489638328552, 'learning_rate': 3.9477231376275474e-05, 'epoch': 0.6313661174234715, 'step': 3505500}
INFO:transformers.trainer:{'loss': 3.099431581735611, 'learning_rate': 3.947573048216284e-05, 'epoch': 0.63145617107023, 'step': 3506000}
INFO:transformers.trainer:{'loss': 3.1155883238315583, 'learning_rate': 3.947422958805019e-05, 'epoch': 0.6315462247169884, 'step': 3506500}
INFO:transformers.trainer:{'loss': 3.1356507794857027, 'learning_rate': 3.947272869393756e-05, 'epoch': 0.6316362783637468, 'step': 3507000}
INFO:transformers.trainer:{'loss': 3.103371474504471, 'learning_rate': 3.947122779982491e-05, 'epoch': 0.6317263320105053, 'step': 3507500}
INFO:transformers.trainer:{'loss': 3.1178157773017885, 'learning_rate': 3.9469726905712277e-05, 'epoch': 0.6318163856572637, 'step': 3508000}
INFO:transformers.trainer:{'loss': 3.151843728303909, 'learning_rate': 3.946822601159963e-05, 'epoch': 0.6319064393040222, 'step': 3508500}
INFO:transformers.trainer:{'loss': 3.112125383615494, 'learning_rate': 3.946672511748699e-05, 'epoch': 0.6319964929507806, 'step': 3509000}
INFO:transformers.trainer:{'loss': 3.111570858001709, 'learning_rate': 3.9465224223374354e-05, 'epoch': 0.632086546597539, 'step': 3509500}
INFO:transformers.trainer:{'loss': 3.116780681848526, 'learning_rate': 3.9463723329261706e-05, 'epoch': 0.6321766002442976, 'step': 3510000}
INFO:transformers.trainer:{'loss': 3.0797656539678573, 'learning_rate': 3.946222243514907e-05, 'epoch': 0.632266653891056, 'step': 3510500}
INFO:transformers.trainer:{'loss': 3.0795994009971617, 'learning_rate': 3.9460721541036424e-05, 'epoch': 0.6323567075378145, 'step': 3511000}
INFO:transformers.trainer:{'loss': 3.166490773677826, 'learning_rate': 3.945922064692379e-05, 'epoch': 0.6324467611845729, 'step': 3511500}
INFO:transformers.trainer:{'loss': 3.111775249004364, 'learning_rate': 3.945771975281114e-05, 'epoch': 0.6325368148313313, 'step': 3512000}
INFO:transformers.trainer:{'loss': 3.142512117385864, 'learning_rate': 3.945621885869851e-05, 'epoch': 0.6326268684780898, 'step': 3512500}
INFO:transformers.trainer:{'loss': 3.1781024799346924, 'learning_rate': 3.945471796458586e-05, 'epoch': 0.6327169221248482, 'step': 3513000}
INFO:transformers.trainer:{'loss': 3.107486723899841, 'learning_rate': 3.9453217070473226e-05, 'epoch': 0.6328069757716067, 'step': 3513500}
INFO:transformers.trainer:{'loss': 3.127353657960892, 'learning_rate': 3.945171617636058e-05, 'epoch': 0.6328970294183651, 'step': 3514000}
INFO:transformers.trainer:{'loss': 3.106531096339226, 'learning_rate': 3.9450215282247944e-05, 'epoch': 0.6329870830651235, 'step': 3514500}
INFO:transformers.trainer:{'loss': 3.1068451762199403, 'learning_rate': 3.9448714388135296e-05, 'epoch': 0.633077136711882, 'step': 3515000}
INFO:transformers.trainer:{'loss': 3.127768725037575, 'learning_rate': 3.944721349402266e-05, 'epoch': 0.6331671903586404, 'step': 3515500}
INFO:transformers.trainer:{'loss': 3.146549425840378, 'learning_rate': 3.944571259991002e-05, 'epoch': 0.6332572440053988, 'step': 3516000}
INFO:transformers.trainer:{'loss': 3.1659000136852264, 'learning_rate': 3.944421170579738e-05, 'epoch': 0.6333472976521574, 'step': 3516500}
INFO:transformers.trainer:{'loss': 3.0922051708698275, 'learning_rate': 3.944271081168474e-05, 'epoch': 0.6334373512989158, 'step': 3517000}
INFO:transformers.trainer:{'loss': 3.1246548712253572, 'learning_rate': 3.94412099175721e-05, 'epoch': 0.6335274049456743, 'step': 3517500}
INFO:transformers.trainer:{'loss': 3.133333518266678, 'learning_rate': 3.943970902345946e-05, 'epoch': 0.6336174585924327, 'step': 3518000}
INFO:transformers.trainer:{'loss': 3.1223594796657563, 'learning_rate': 3.9438208129346817e-05, 'epoch': 0.6337075122391911, 'step': 3518500}
INFO:transformers.trainer:{'loss': 3.14913534617424, 'learning_rate': 3.9436707235234176e-05, 'epoch': 0.6337975658859496, 'step': 3519000}
INFO:transformers.trainer:{'loss': 3.1110221766233446, 'learning_rate': 3.9435206341121535e-05, 'epoch': 0.633887619532708, 'step': 3519500}
INFO:transformers.trainer:{'loss': 3.1487936708927156, 'learning_rate': 3.9433705447008894e-05, 'epoch': 0.6339776731794665, 'step': 3520000}
INFO:transformers.trainer:{'loss': 3.131903827905655, 'learning_rate': 3.943220455289625e-05, 'epoch': 0.6340677268262249, 'step': 3520500}
INFO:transformers.trainer:{'loss': 3.0983664059638976, 'learning_rate': 3.943070365878361e-05, 'epoch': 0.6341577804729833, 'step': 3521000}
INFO:transformers.trainer:{'loss': 3.07404948425293, 'learning_rate': 3.942920276467097e-05, 'epoch': 0.6342478341197418, 'step': 3521500}
INFO:transformers.trainer:{'loss': 3.1694886112213134, 'learning_rate': 3.942770187055833e-05, 'epoch': 0.6343378877665002, 'step': 3522000}
INFO:transformers.trainer:{'loss': 3.1036354240179063, 'learning_rate': 3.942620097644569e-05, 'epoch': 0.6344279414132588, 'step': 3522500}
INFO:transformers.trainer:{'loss': 3.2061158192157744, 'learning_rate': 3.942470008233305e-05, 'epoch': 0.6345179950600172, 'step': 3523000}
INFO:transformers.trainer:{'loss': 3.1795309233665465, 'learning_rate': 3.9423199188220414e-05, 'epoch': 0.6346080487067756, 'step': 3523500}
INFO:transformers.trainer:{'loss': 3.1789195222854616, 'learning_rate': 3.9421698294107766e-05, 'epoch': 0.6346981023535341, 'step': 3524000}
INFO:transformers.trainer:{'loss': 3.190275058507919, 'learning_rate': 3.942019739999513e-05, 'epoch': 0.6347881560002925, 'step': 3524500}
INFO:transformers.trainer:{'loss': 3.1546179568767547, 'learning_rate': 3.9418696505882484e-05, 'epoch': 0.634878209647051, 'step': 3525000}
INFO:transformers.trainer:{'loss': 3.1551642315387727, 'learning_rate': 3.941719561176985e-05, 'epoch': 0.6349682632938094, 'step': 3525500}
INFO:transformers.trainer:{'loss': 3.140839966535568, 'learning_rate': 3.94156947176572e-05, 'epoch': 0.6350583169405678, 'step': 3526000}
INFO:transformers.trainer:{'loss': 3.1693090702295303, 'learning_rate': 3.941419382354457e-05, 'epoch': 0.6351483705873263, 'step': 3526500}
INFO:transformers.trainer:{'loss': 3.1203478635549544, 'learning_rate': 3.941269292943192e-05, 'epoch': 0.6352384242340847, 'step': 3527000}
INFO:transformers.trainer:{'loss': 3.1467797474861143, 'learning_rate': 3.9411192035319286e-05, 'epoch': 0.6353284778808431, 'step': 3527500}
INFO:transformers.trainer:{'loss': 3.0872286880016326, 'learning_rate': 3.940969114120664e-05, 'epoch': 0.6354185315276016, 'step': 3528000}
INFO:transformers.trainer:{'loss': 3.118422220468521, 'learning_rate': 3.9408190247094004e-05, 'epoch': 0.63550858517436, 'step': 3528500}
INFO:transformers.trainer:{'loss': 3.133364725112915, 'learning_rate': 3.9406689352981357e-05, 'epoch': 0.6355986388211186, 'step': 3529000}
INFO:transformers.trainer:{'loss': 3.141698178768158, 'learning_rate': 3.940518845886872e-05, 'epoch': 0.635688692467877, 'step': 3529500}
INFO:transformers.trainer:{'loss': 3.1563552923202516, 'learning_rate': 3.940368756475608e-05, 'epoch': 0.6357787461146354, 'step': 3530000}
INFO:transformers.trainer:{'loss': 3.1074587204456328, 'learning_rate': 3.940218667064344e-05, 'epoch': 0.6358687997613939, 'step': 3530500}
INFO:transformers.trainer:{'loss': 3.083932263612747, 'learning_rate': 3.94006857765308e-05, 'epoch': 0.6359588534081523, 'step': 3531000}
INFO:transformers.trainer:{'loss': 3.168345532864332, 'learning_rate': 3.939918488241816e-05, 'epoch': 0.6360489070549108, 'step': 3531500}
INFO:transformers.trainer:{'loss': 3.136464349985123, 'learning_rate': 3.939768398830552e-05, 'epoch': 0.6361389607016692, 'step': 3532000}
INFO:transformers.trainer:{'loss': 3.12989312005043, 'learning_rate': 3.939618309419287e-05, 'epoch': 0.6362290143484276, 'step': 3532500}
INFO:transformers.trainer:{'loss': 3.185345210790634, 'learning_rate': 3.9394682200080236e-05, 'epoch': 0.6363190679951861, 'step': 3533000}
INFO:transformers.trainer:{'loss': 3.1707424783706664, 'learning_rate': 3.939318130596759e-05, 'epoch': 0.6364091216419445, 'step': 3533500}
INFO:transformers.trainer:{'loss': 3.0815516084432604, 'learning_rate': 3.9391680411854954e-05, 'epoch': 0.636499175288703, 'step': 3534000}
INFO:transformers.trainer:{'loss': 3.097262971997261, 'learning_rate': 3.9390179517742306e-05, 'epoch': 0.6365892289354614, 'step': 3534500}
INFO:transformers.trainer:{'loss': 3.1602117614746095, 'learning_rate': 3.938867862362967e-05, 'epoch': 0.6366792825822198, 'step': 3535000}
INFO:transformers.trainer:{'loss': 3.1712842255830767, 'learning_rate': 3.9387177729517024e-05, 'epoch': 0.6367693362289784, 'step': 3535500}
INFO:transformers.trainer:{'loss': 3.13692408657074, 'learning_rate': 3.938567683540439e-05, 'epoch': 0.6368593898757368, 'step': 3536000}
INFO:transformers.trainer:{'loss': 3.1451073100566864, 'learning_rate': 3.938417594129174e-05, 'epoch': 0.6369494435224953, 'step': 3536500}
INFO:transformers.trainer:{'loss': 3.2029148671627046, 'learning_rate': 3.938267504717911e-05, 'epoch': 0.6370394971692537, 'step': 3537000}
INFO:transformers.trainer:{'loss': 3.1065726387500763, 'learning_rate': 3.938117415306647e-05, 'epoch': 0.6371295508160121, 'step': 3537500}
INFO:transformers.trainer:{'loss': 3.127076611280441, 'learning_rate': 3.9379673258953826e-05, 'epoch': 0.6372196044627706, 'step': 3538000}
INFO:transformers.trainer:{'loss': 3.113976043701172, 'learning_rate': 3.9378172364841185e-05, 'epoch': 0.637309658109529, 'step': 3538500}
INFO:transformers.trainer:{'loss': 3.1206450667381285, 'learning_rate': 3.9376671470728544e-05, 'epoch': 0.6373997117562874, 'step': 3539000}
INFO:transformers.trainer:{'loss': 3.1298628568649294, 'learning_rate': 3.9375170576615903e-05, 'epoch': 0.6374897654030459, 'step': 3539500}
INFO:transformers.trainer:{'loss': 3.1472457723617553, 'learning_rate': 3.937366968250326e-05, 'epoch': 0.6375798190498043, 'step': 3540000}
INFO:transformers.trainer:{'loss': 3.085670913219452, 'learning_rate': 3.937216878839062e-05, 'epoch': 0.6376698726965628, 'step': 3540500}
INFO:transformers.trainer:{'loss': 3.117794365286827, 'learning_rate': 3.937066789427798e-05, 'epoch': 0.6377599263433212, 'step': 3541000}
INFO:transformers.trainer:{'loss': 3.0598712208271026, 'learning_rate': 3.936916700016534e-05, 'epoch': 0.6378499799900796, 'step': 3541500}
INFO:transformers.trainer:{'loss': 3.122849205493927, 'learning_rate': 3.93676661060527e-05, 'epoch': 0.6379400336368382, 'step': 3542000}
INFO:transformers.trainer:{'loss': 3.06901691699028, 'learning_rate': 3.936616521194006e-05, 'epoch': 0.6380300872835966, 'step': 3542500}
INFO:transformers.trainer:{'loss': 3.0788083622455598, 'learning_rate': 3.936466431782742e-05, 'epoch': 0.6381201409303551, 'step': 3543000}
INFO:transformers.trainer:{'loss': 3.097344667673111, 'learning_rate': 3.9363163423714776e-05, 'epoch': 0.6382101945771135, 'step': 3543500}
INFO:transformers.trainer:{'loss': 3.1210828155279158, 'learning_rate': 3.936166252960214e-05, 'epoch': 0.6383002482238719, 'step': 3544000}
INFO:transformers.trainer:{'loss': 3.142941811800003, 'learning_rate': 3.9360161635489494e-05, 'epoch': 0.6383903018706304, 'step': 3544500}
INFO:transformers.trainer:{'loss': 3.1104790907502173, 'learning_rate': 3.935866074137686e-05, 'epoch': 0.6384803555173888, 'step': 3545000}
INFO:transformers.trainer:{'loss': 3.1485181534290314, 'learning_rate': 3.935715984726421e-05, 'epoch': 0.6385704091641473, 'step': 3545500}
INFO:transformers.trainer:{'loss': 3.088665155172348, 'learning_rate': 3.935565895315158e-05, 'epoch': 0.6386604628109057, 'step': 3546000}
INFO:transformers.trainer:{'loss': 3.17584087061882, 'learning_rate': 3.935415805903893e-05, 'epoch': 0.6387505164576641, 'step': 3546500}
INFO:transformers.trainer:{'loss': 3.1473706300258635, 'learning_rate': 3.9352657164926296e-05, 'epoch': 0.6388405701044226, 'step': 3547000}
INFO:transformers.trainer:{'loss': 3.128536799073219, 'learning_rate': 3.935115627081365e-05, 'epoch': 0.638930623751181, 'step': 3547500}
INFO:transformers.trainer:{'loss': 3.1052665700912474, 'learning_rate': 3.9349655376701014e-05, 'epoch': 0.6390206773979396, 'step': 3548000}
INFO:transformers.trainer:{'loss': 3.1423036725521087, 'learning_rate': 3.9348154482588366e-05, 'epoch': 0.639110731044698, 'step': 3548500}
INFO:transformers.trainer:{'loss': 3.1390991401672363, 'learning_rate': 3.934665358847573e-05, 'epoch': 0.6392007846914564, 'step': 3549000}
INFO:transformers.trainer:{'loss': 3.1791138989925383, 'learning_rate': 3.9345152694363084e-05, 'epoch': 0.6392908383382149, 'step': 3549500}
INFO:transformers.trainer:{'loss': 3.1668015122413635, 'learning_rate': 3.934365180025045e-05, 'epoch': 0.6393808919849733, 'step': 3550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.076124930143356, 'learning_rate': 3.934215090613781e-05, 'epoch': 0.6394709456317317, 'step': 3550500}
INFO:transformers.trainer:{'loss': 3.116559378862381, 'learning_rate': 3.934065001202517e-05, 'epoch': 0.6395609992784902, 'step': 3551000}
INFO:transformers.trainer:{'loss': 3.0877665009498596, 'learning_rate': 3.933914911791253e-05, 'epoch': 0.6396510529252486, 'step': 3551500}
INFO:transformers.trainer:{'loss': 3.1589871542453767, 'learning_rate': 3.9337648223799886e-05, 'epoch': 0.6397411065720071, 'step': 3552000}
INFO:transformers.trainer:{'loss': 3.190756045341492, 'learning_rate': 3.9336147329687246e-05, 'epoch': 0.6398311602187655, 'step': 3552500}
INFO:transformers.trainer:{'loss': 3.0772719405889513, 'learning_rate': 3.9334646435574605e-05, 'epoch': 0.6399212138655239, 'step': 3553000}
INFO:transformers.trainer:{'loss': 3.161697395324707, 'learning_rate': 3.9333145541461964e-05, 'epoch': 0.6400112675122824, 'step': 3553500}
INFO:transformers.trainer:{'loss': 3.13189353621006, 'learning_rate': 3.933164464734932e-05, 'epoch': 0.6401013211590408, 'step': 3554000}
INFO:transformers.trainer:{'loss': 3.1406952451467514, 'learning_rate': 3.933014375323668e-05, 'epoch': 0.6401913748057994, 'step': 3554500}
INFO:transformers.trainer:{'loss': 3.1230645622015, 'learning_rate': 3.932864285912404e-05, 'epoch': 0.6402814284525578, 'step': 3555000}
INFO:transformers.trainer:{'loss': 3.126174605369568, 'learning_rate': 3.93271419650114e-05, 'epoch': 0.6403714820993162, 'step': 3555500}
INFO:transformers.trainer:{'loss': 3.14110604763031, 'learning_rate': 3.932564107089876e-05, 'epoch': 0.6404615357460747, 'step': 3556000}
INFO:transformers.trainer:{'loss': 3.1246176577806475, 'learning_rate': 3.932414017678612e-05, 'epoch': 0.6405515893928331, 'step': 3556500}
INFO:transformers.trainer:{'loss': 3.1512750713825226, 'learning_rate': 3.932263928267347e-05, 'epoch': 0.6406416430395916, 'step': 3557000}
INFO:transformers.trainer:{'loss': 3.1785873091220855, 'learning_rate': 3.9321138388560836e-05, 'epoch': 0.64073169668635, 'step': 3557500}
INFO:transformers.trainer:{'loss': 3.131794049024582, 'learning_rate': 3.9319637494448195e-05, 'epoch': 0.6408217503331084, 'step': 3558000}
INFO:transformers.trainer:{'loss': 3.178991195321083, 'learning_rate': 3.9318136600335554e-05, 'epoch': 0.6409118039798669, 'step': 3558500}
INFO:transformers.trainer:{'loss': 3.0966599655151366, 'learning_rate': 3.931663570622291e-05, 'epoch': 0.6410018576266253, 'step': 3559000}
INFO:transformers.trainer:{'loss': 3.1668477395176886, 'learning_rate': 3.931513481211027e-05, 'epoch': 0.6410919112733838, 'step': 3559500}
INFO:transformers.trainer:{'loss': 3.0943727346658707, 'learning_rate': 3.931363391799763e-05, 'epoch': 0.6411819649201422, 'step': 3560000}
INFO:transformers.trainer:{'loss': 3.113005178928375, 'learning_rate': 3.931213302388499e-05, 'epoch': 0.6412720185669006, 'step': 3560500}
INFO:transformers.trainer:{'loss': 3.0855886883735657, 'learning_rate': 3.931063212977235e-05, 'epoch': 0.6413620722136592, 'step': 3561000}
INFO:transformers.trainer:{'loss': 3.1495635159015656, 'learning_rate': 3.930913123565971e-05, 'epoch': 0.6414521258604176, 'step': 3561500}
INFO:transformers.trainer:{'loss': 3.142129877090454, 'learning_rate': 3.930763034154707e-05, 'epoch': 0.6415421795071761, 'step': 3562000}
INFO:transformers.trainer:{'loss': 3.1267398102283477, 'learning_rate': 3.9306129447434427e-05, 'epoch': 0.6416322331539345, 'step': 3562500}
INFO:transformers.trainer:{'loss': 3.1678048219680788, 'learning_rate': 3.9304628553321786e-05, 'epoch': 0.6417222868006929, 'step': 3563000}
INFO:transformers.trainer:{'loss': 3.148621367931366, 'learning_rate': 3.9303127659209145e-05, 'epoch': 0.6418123404474514, 'step': 3563500}
INFO:transformers.trainer:{'loss': 3.171458169221878, 'learning_rate': 3.9301626765096504e-05, 'epoch': 0.6419023940942098, 'step': 3564000}
INFO:transformers.trainer:{'loss': 3.1835368814468383, 'learning_rate': 3.930012587098387e-05, 'epoch': 0.6419924477409682, 'step': 3564500}
INFO:transformers.trainer:{'loss': 3.101735129058361, 'learning_rate': 3.929862497687122e-05, 'epoch': 0.6420825013877267, 'step': 3565000}
INFO:transformers.trainer:{'loss': 3.093735840320587, 'learning_rate': 3.929712408275859e-05, 'epoch': 0.6421725550344851, 'step': 3565500}
INFO:transformers.trainer:{'loss': 3.1652776166200636, 'learning_rate': 3.929562318864594e-05, 'epoch': 0.6422626086812436, 'step': 3566000}
INFO:transformers.trainer:{'loss': 3.1726792016029357, 'learning_rate': 3.9294122294533306e-05, 'epoch': 0.642352662328002, 'step': 3566500}
INFO:transformers.trainer:{'loss': 3.1015788465738297, 'learning_rate': 3.929262140042066e-05, 'epoch': 0.6424427159747604, 'step': 3567000}
INFO:transformers.trainer:{'loss': 3.173484387397766, 'learning_rate': 3.9291120506308024e-05, 'epoch': 0.642532769621519, 'step': 3567500}
INFO:transformers.trainer:{'loss': 3.0696479630470277, 'learning_rate': 3.9289619612195376e-05, 'epoch': 0.6426228232682774, 'step': 3568000}
INFO:transformers.trainer:{'loss': 3.158709619522095, 'learning_rate': 3.928811871808274e-05, 'epoch': 0.6427128769150359, 'step': 3568500}
INFO:transformers.trainer:{'loss': 3.1659419882297515, 'learning_rate': 3.9286617823970094e-05, 'epoch': 0.6428029305617943, 'step': 3569000}
INFO:transformers.trainer:{'loss': 3.1173295654058455, 'learning_rate': 3.928511692985746e-05, 'epoch': 0.6428929842085527, 'step': 3569500}
INFO:transformers.trainer:{'loss': 3.1609996564388276, 'learning_rate': 3.928361603574481e-05, 'epoch': 0.6429830378553112, 'step': 3570000}
INFO:transformers.trainer:{'loss': 3.083969593524933, 'learning_rate': 3.928211514163218e-05, 'epoch': 0.6430730915020696, 'step': 3570500}
INFO:transformers.trainer:{'loss': 3.1092666265964506, 'learning_rate': 3.928061424751953e-05, 'epoch': 0.6431631451488281, 'step': 3571000}
INFO:transformers.trainer:{'loss': 3.095913779258728, 'learning_rate': 3.9279113353406896e-05, 'epoch': 0.6432531987955865, 'step': 3571500}
INFO:transformers.trainer:{'loss': 3.0941511672735214, 'learning_rate': 3.9277612459294255e-05, 'epoch': 0.6433432524423449, 'step': 3572000}
INFO:transformers.trainer:{'loss': 3.101947585582733, 'learning_rate': 3.9276111565181614e-05, 'epoch': 0.6434333060891034, 'step': 3572500}
INFO:transformers.trainer:{'loss': 3.1491377053260803, 'learning_rate': 3.927461067106897e-05, 'epoch': 0.6435233597358618, 'step': 3573000}
INFO:transformers.trainer:{'loss': 3.1269280614852906, 'learning_rate': 3.927310977695633e-05, 'epoch': 0.6436134133826203, 'step': 3573500}
INFO:transformers.trainer:{'loss': 3.0965677723884584, 'learning_rate': 3.927160888284369e-05, 'epoch': 0.6437034670293788, 'step': 3574000}
INFO:transformers.trainer:{'loss': 3.120754024505615, 'learning_rate': 3.927010798873105e-05, 'epoch': 0.6437935206761372, 'step': 3574500}
INFO:transformers.trainer:{'loss': 3.1511620030403136, 'learning_rate': 3.926860709461841e-05, 'epoch': 0.6438835743228957, 'step': 3575000}
INFO:transformers.trainer:{'loss': 3.147182902574539, 'learning_rate': 3.926710620050577e-05, 'epoch': 0.6439736279696541, 'step': 3575500}
INFO:transformers.trainer:{'loss': 3.0884999150037764, 'learning_rate': 3.926560530639313e-05, 'epoch': 0.6440636816164125, 'step': 3576000}
INFO:transformers.trainer:{'loss': 3.137544049501419, 'learning_rate': 3.926410441228049e-05, 'epoch': 0.644153735263171, 'step': 3576500}
INFO:transformers.trainer:{'loss': 3.180845921039581, 'learning_rate': 3.9262603518167846e-05, 'epoch': 0.6442437889099294, 'step': 3577000}
INFO:transformers.trainer:{'loss': 3.1444727256298064, 'learning_rate': 3.9261102624055205e-05, 'epoch': 0.6443338425566879, 'step': 3577500}
INFO:transformers.trainer:{'loss': 3.095232230424881, 'learning_rate': 3.9259601729942564e-05, 'epoch': 0.6444238962034463, 'step': 3578000}
INFO:transformers.trainer:{'loss': 3.0780341947078704, 'learning_rate': 3.925810083582992e-05, 'epoch': 0.6445139498502047, 'step': 3578500}
INFO:transformers.trainer:{'loss': 3.1361093583106996, 'learning_rate': 3.925659994171728e-05, 'epoch': 0.6446040034969632, 'step': 3579000}
INFO:transformers.trainer:{'loss': 3.0398919823169708, 'learning_rate': 3.925509904760464e-05, 'epoch': 0.6446940571437216, 'step': 3579500}
INFO:transformers.trainer:{'loss': 3.1445535283088684, 'learning_rate': 3.9253598153492e-05, 'epoch': 0.6447841107904801, 'step': 3580000}
INFO:transformers.trainer:{'loss': 3.156830790042877, 'learning_rate': 3.925209725937936e-05, 'epoch': 0.6448741644372386, 'step': 3580500}
INFO:transformers.trainer:{'loss': 3.124319070100784, 'learning_rate': 3.925059636526672e-05, 'epoch': 0.644964218083997, 'step': 3581000}
INFO:transformers.trainer:{'loss': 3.110498983860016, 'learning_rate': 3.924909547115408e-05, 'epoch': 0.6450542717307555, 'step': 3581500}
INFO:transformers.trainer:{'loss': 3.1876598986387252, 'learning_rate': 3.9247594577041436e-05, 'epoch': 0.6451443253775139, 'step': 3582000}
INFO:transformers.trainer:{'loss': 3.1608519358634948, 'learning_rate': 3.9246093682928795e-05, 'epoch': 0.6452343790242724, 'step': 3582500}
INFO:transformers.trainer:{'loss': 3.1494713859558106, 'learning_rate': 3.9244592788816154e-05, 'epoch': 0.6453244326710308, 'step': 3583000}
INFO:transformers.trainer:{'loss': 3.180619717359543, 'learning_rate': 3.9243091894703513e-05, 'epoch': 0.6454144863177892, 'step': 3583500}
INFO:transformers.trainer:{'loss': 3.1048743634223936, 'learning_rate': 3.924159100059087e-05, 'epoch': 0.6455045399645477, 'step': 3584000}
INFO:transformers.trainer:{'loss': 3.17220796751976, 'learning_rate': 3.924009010647823e-05, 'epoch': 0.6455945936113061, 'step': 3584500}
INFO:transformers.trainer:{'loss': 3.059248633980751, 'learning_rate': 3.923858921236559e-05, 'epoch': 0.6456846472580646, 'step': 3585000}
INFO:transformers.trainer:{'loss': 3.146240447282791, 'learning_rate': 3.923708831825295e-05, 'epoch': 0.645774700904823, 'step': 3585500}
INFO:transformers.trainer:{'loss': 3.1209967559576035, 'learning_rate': 3.9235587424140315e-05, 'epoch': 0.6458647545515814, 'step': 3586000}
INFO:transformers.trainer:{'loss': 3.1530438739061357, 'learning_rate': 3.923408653002767e-05, 'epoch': 0.64595480819834, 'step': 3586500}
INFO:transformers.trainer:{'loss': 3.153370895624161, 'learning_rate': 3.9232585635915034e-05, 'epoch': 0.6460448618450984, 'step': 3587000}
INFO:transformers.trainer:{'loss': 3.1077544524669647, 'learning_rate': 3.9231084741802386e-05, 'epoch': 0.6461349154918568, 'step': 3587500}
INFO:transformers.trainer:{'loss': 3.0783345274925233, 'learning_rate': 3.922958384768975e-05, 'epoch': 0.6462249691386153, 'step': 3588000}
INFO:transformers.trainer:{'loss': 3.131928940296173, 'learning_rate': 3.9228082953577104e-05, 'epoch': 0.6463150227853737, 'step': 3588500}
INFO:transformers.trainer:{'loss': 3.1501730456352233, 'learning_rate': 3.922658205946447e-05, 'epoch': 0.6464050764321322, 'step': 3589000}
INFO:transformers.trainer:{'loss': 3.1525307824611666, 'learning_rate': 3.922508116535182e-05, 'epoch': 0.6464951300788906, 'step': 3589500}
INFO:transformers.trainer:{'loss': 3.1043476370573044, 'learning_rate': 3.922358027123919e-05, 'epoch': 0.646585183725649, 'step': 3590000}
INFO:transformers.trainer:{'loss': 3.1027661961317063, 'learning_rate': 3.922207937712654e-05, 'epoch': 0.6466752373724075, 'step': 3590500}
INFO:transformers.trainer:{'loss': 3.1225851869583128, 'learning_rate': 3.9220578483013906e-05, 'epoch': 0.6467652910191659, 'step': 3591000}
INFO:transformers.trainer:{'loss': 3.123930973768234, 'learning_rate': 3.921907758890126e-05, 'epoch': 0.6468553446659244, 'step': 3591500}
INFO:transformers.trainer:{'loss': 3.161577798128128, 'learning_rate': 3.9217576694788624e-05, 'epoch': 0.6469453983126828, 'step': 3592000}
INFO:transformers.trainer:{'loss': 3.177225722551346, 'learning_rate': 3.921607580067598e-05, 'epoch': 0.6470354519594412, 'step': 3592500}
INFO:transformers.trainer:{'loss': 3.0929219398498535, 'learning_rate': 3.921457490656334e-05, 'epoch': 0.6471255056061997, 'step': 3593000}
INFO:transformers.trainer:{'loss': 3.0973827959299087, 'learning_rate': 3.92130740124507e-05, 'epoch': 0.6472155592529582, 'step': 3593500}
INFO:transformers.trainer:{'loss': 3.165729229211807, 'learning_rate': 3.921157311833806e-05, 'epoch': 0.6473056128997167, 'step': 3594000}
INFO:transformers.trainer:{'loss': 3.122285737633705, 'learning_rate': 3.921007222422542e-05, 'epoch': 0.6473956665464751, 'step': 3594500}
INFO:transformers.trainer:{'loss': 3.1595378918647765, 'learning_rate': 3.920857133011278e-05, 'epoch': 0.6474857201932335, 'step': 3595000}
INFO:transformers.trainer:{'loss': 3.048068568229675, 'learning_rate': 3.920707043600014e-05, 'epoch': 0.647575773839992, 'step': 3595500}
INFO:transformers.trainer:{'loss': 3.115339873790741, 'learning_rate': 3.9205569541887496e-05, 'epoch': 0.6476658274867504, 'step': 3596000}
INFO:transformers.trainer:{'loss': 3.1328500709533693, 'learning_rate': 3.9204068647774855e-05, 'epoch': 0.6477558811335089, 'step': 3596500}
INFO:transformers.trainer:{'loss': 3.1233825187683104, 'learning_rate': 3.9202567753662215e-05, 'epoch': 0.6478459347802673, 'step': 3597000}
INFO:transformers.trainer:{'loss': 3.1784644660949706, 'learning_rate': 3.9201066859549574e-05, 'epoch': 0.6479359884270257, 'step': 3597500}
INFO:transformers.trainer:{'loss': 3.09512331533432, 'learning_rate': 3.919956596543693e-05, 'epoch': 0.6480260420737842, 'step': 3598000}
INFO:transformers.trainer:{'loss': 3.2176701974868775, 'learning_rate': 3.919806507132429e-05, 'epoch': 0.6481160957205426, 'step': 3598500}
INFO:transformers.trainer:{'loss': 3.163640596628189, 'learning_rate': 3.919656417721165e-05, 'epoch': 0.6482061493673011, 'step': 3599000}
INFO:transformers.trainer:{'loss': 3.078582765340805, 'learning_rate': 3.919506328309901e-05, 'epoch': 0.6482962030140595, 'step': 3599500}
INFO:transformers.trainer:{'loss': 3.143188717365265, 'learning_rate': 3.919356238898637e-05, 'epoch': 0.648386256660818, 'step': 3600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1862773711681367, 'learning_rate': 3.919206149487373e-05, 'epoch': 0.6484763103075765, 'step': 3600500}
INFO:transformers.trainer:{'loss': 3.141295617580414, 'learning_rate': 3.919056060076109e-05, 'epoch': 0.6485663639543349, 'step': 3601000}
INFO:transformers.trainer:{'loss': 3.1304687292575837, 'learning_rate': 3.9189059706648446e-05, 'epoch': 0.6486564176010933, 'step': 3601500}
INFO:transformers.trainer:{'loss': 3.0870288445949554, 'learning_rate': 3.9187558812535805e-05, 'epoch': 0.6487464712478518, 'step': 3602000}
INFO:transformers.trainer:{'loss': 3.134995258331299, 'learning_rate': 3.9186057918423164e-05, 'epoch': 0.6488365248946102, 'step': 3602500}
INFO:transformers.trainer:{'loss': 3.1687015513181684, 'learning_rate': 3.918455702431052e-05, 'epoch': 0.6489265785413687, 'step': 3603000}
INFO:transformers.trainer:{'loss': 3.1533872680664063, 'learning_rate': 3.918305613019788e-05, 'epoch': 0.6490166321881271, 'step': 3603500}
INFO:transformers.trainer:{'loss': 3.133002024650574, 'learning_rate': 3.918155523608524e-05, 'epoch': 0.6491066858348855, 'step': 3604000}
INFO:transformers.trainer:{'loss': 3.098095473408699, 'learning_rate': 3.91800543419726e-05, 'epoch': 0.649196739481644, 'step': 3604500}
INFO:transformers.trainer:{'loss': 3.174054168701172, 'learning_rate': 3.917855344785996e-05, 'epoch': 0.6492867931284024, 'step': 3605000}
INFO:transformers.trainer:{'loss': 3.1009875960350035, 'learning_rate': 3.917705255374732e-05, 'epoch': 0.6493768467751609, 'step': 3605500}
INFO:transformers.trainer:{'loss': 3.1598313063383103, 'learning_rate': 3.917555165963468e-05, 'epoch': 0.6494669004219193, 'step': 3606000}
INFO:transformers.trainer:{'loss': 3.115582986950874, 'learning_rate': 3.917405076552204e-05, 'epoch': 0.6495569540686777, 'step': 3606500}
INFO:transformers.trainer:{'loss': 3.1388366885185244, 'learning_rate': 3.9172549871409396e-05, 'epoch': 0.6496470077154363, 'step': 3607000}
INFO:transformers.trainer:{'loss': 3.142975344181061, 'learning_rate': 3.917104897729676e-05, 'epoch': 0.6497370613621947, 'step': 3607500}
INFO:transformers.trainer:{'loss': 3.0766987071037293, 'learning_rate': 3.9169548083184114e-05, 'epoch': 0.6498271150089532, 'step': 3608000}
INFO:transformers.trainer:{'loss': 3.1628524379730223, 'learning_rate': 3.916804718907148e-05, 'epoch': 0.6499171686557116, 'step': 3608500}
INFO:transformers.trainer:{'loss': 3.1261230702400207, 'learning_rate': 3.916654629495883e-05, 'epoch': 0.65000722230247, 'step': 3609000}
INFO:transformers.trainer:{'loss': 3.073743576526642, 'learning_rate': 3.91650454008462e-05, 'epoch': 0.6500972759492285, 'step': 3609500}
INFO:transformers.trainer:{'loss': 3.092803493976593, 'learning_rate': 3.916354450673355e-05, 'epoch': 0.6501873295959869, 'step': 3610000}
INFO:transformers.trainer:{'loss': 3.1117290579080583, 'learning_rate': 3.9162043612620916e-05, 'epoch': 0.6502773832427454, 'step': 3610500}
INFO:transformers.trainer:{'loss': 3.078256477713585, 'learning_rate': 3.916054271850827e-05, 'epoch': 0.6503674368895038, 'step': 3611000}
INFO:transformers.trainer:{'loss': 3.1108421803712845, 'learning_rate': 3.9159041824395634e-05, 'epoch': 0.6504574905362622, 'step': 3611500}
INFO:transformers.trainer:{'loss': 3.2284544858932493, 'learning_rate': 3.9157540930282986e-05, 'epoch': 0.6505475441830207, 'step': 3612000}
INFO:transformers.trainer:{'loss': 3.100346846818924, 'learning_rate': 3.915604003617035e-05, 'epoch': 0.6506375978297791, 'step': 3612500}
INFO:transformers.trainer:{'loss': 3.14480510699749, 'learning_rate': 3.915453914205771e-05, 'epoch': 0.6507276514765375, 'step': 3613000}
INFO:transformers.trainer:{'loss': 3.162768990278244, 'learning_rate': 3.915303824794507e-05, 'epoch': 0.6508177051232961, 'step': 3613500}
INFO:transformers.trainer:{'loss': 3.086921826839447, 'learning_rate': 3.915153735383243e-05, 'epoch': 0.6509077587700545, 'step': 3614000}
INFO:transformers.trainer:{'loss': 3.149548835039139, 'learning_rate': 3.915003645971979e-05, 'epoch': 0.650997812416813, 'step': 3614500}
INFO:transformers.trainer:{'loss': 3.128286587238312, 'learning_rate': 3.914853556560715e-05, 'epoch': 0.6510878660635714, 'step': 3615000}
INFO:transformers.trainer:{'loss': 3.1903154673576357, 'learning_rate': 3.9147034671494506e-05, 'epoch': 0.6511779197103298, 'step': 3615500}
INFO:transformers.trainer:{'loss': 3.0901975808143614, 'learning_rate': 3.9145533777381865e-05, 'epoch': 0.6512679733570883, 'step': 3616000}
INFO:transformers.trainer:{'loss': 3.136718874812126, 'learning_rate': 3.9144032883269224e-05, 'epoch': 0.6513580270038467, 'step': 3616500}
INFO:transformers.trainer:{'loss': 3.1612714817523955, 'learning_rate': 3.914253198915658e-05, 'epoch': 0.6514480806506052, 'step': 3617000}
INFO:transformers.trainer:{'loss': 3.1366959103345873, 'learning_rate': 3.914103109504394e-05, 'epoch': 0.6515381342973636, 'step': 3617500}
INFO:transformers.trainer:{'loss': 3.1340122356414795, 'learning_rate': 3.91395302009313e-05, 'epoch': 0.651628187944122, 'step': 3618000}
INFO:transformers.trainer:{'loss': 3.1243994905948638, 'learning_rate': 3.913802930681866e-05, 'epoch': 0.6517182415908805, 'step': 3618500}
INFO:transformers.trainer:{'loss': 3.057970960378647, 'learning_rate': 3.913652841270602e-05, 'epoch': 0.651808295237639, 'step': 3619000}
INFO:transformers.trainer:{'loss': 3.1085432014465333, 'learning_rate': 3.913502751859338e-05, 'epoch': 0.6518983488843975, 'step': 3619500}
INFO:transformers.trainer:{'loss': 3.0986479489803314, 'learning_rate': 3.913352662448074e-05, 'epoch': 0.6519884025311559, 'step': 3620000}
INFO:transformers.trainer:{'loss': 3.1503588573932646, 'learning_rate': 3.91320257303681e-05, 'epoch': 0.6520784561779143, 'step': 3620500}
INFO:transformers.trainer:{'loss': 3.1080627365112306, 'learning_rate': 3.9130524836255456e-05, 'epoch': 0.6521685098246728, 'step': 3621000}
INFO:transformers.trainer:{'loss': 3.114538809657097, 'learning_rate': 3.9129023942142815e-05, 'epoch': 0.6522585634714312, 'step': 3621500}
INFO:transformers.trainer:{'loss': 3.171487566232681, 'learning_rate': 3.9127523048030174e-05, 'epoch': 0.6523486171181897, 'step': 3622000}
INFO:transformers.trainer:{'loss': 3.208475086927414, 'learning_rate': 3.912602215391753e-05, 'epoch': 0.6524386707649481, 'step': 3622500}
INFO:transformers.trainer:{'loss': 3.02280504155159, 'learning_rate': 3.912452125980489e-05, 'epoch': 0.6525287244117065, 'step': 3623000}
INFO:transformers.trainer:{'loss': 3.1057475144863127, 'learning_rate': 3.912302036569225e-05, 'epoch': 0.652618778058465, 'step': 3623500}
INFO:transformers.trainer:{'loss': 3.131365254640579, 'learning_rate': 3.912151947157961e-05, 'epoch': 0.6527088317052234, 'step': 3624000}
INFO:transformers.trainer:{'loss': 3.169100874662399, 'learning_rate': 3.912001857746697e-05, 'epoch': 0.6527988853519818, 'step': 3624500}
INFO:transformers.trainer:{'loss': 3.1175286293029787, 'learning_rate': 3.911851768335433e-05, 'epoch': 0.6528889389987403, 'step': 3625000}
INFO:transformers.trainer:{'loss': 3.1575802277326583, 'learning_rate': 3.911701678924169e-05, 'epoch': 0.6529789926454987, 'step': 3625500}
INFO:transformers.trainer:{'loss': 3.1478738307952883, 'learning_rate': 3.9115515895129046e-05, 'epoch': 0.6530690462922573, 'step': 3626000}
INFO:transformers.trainer:{'loss': 3.1677014108896255, 'learning_rate': 3.9114015001016405e-05, 'epoch': 0.6531590999390157, 'step': 3626500}
INFO:transformers.trainer:{'loss': 3.1440994795560835, 'learning_rate': 3.911251410690377e-05, 'epoch': 0.6532491535857741, 'step': 3627000}
INFO:transformers.trainer:{'loss': 3.1530881164073943, 'learning_rate': 3.911101321279112e-05, 'epoch': 0.6533392072325326, 'step': 3627500}
INFO:transformers.trainer:{'loss': 3.1810833542346955, 'learning_rate': 3.910951231867849e-05, 'epoch': 0.653429260879291, 'step': 3628000}
INFO:transformers.trainer:{'loss': 3.1477105932235716, 'learning_rate': 3.910801142456584e-05, 'epoch': 0.6535193145260495, 'step': 3628500}
INFO:transformers.trainer:{'loss': 3.11592967748642, 'learning_rate': 3.910651053045321e-05, 'epoch': 0.6536093681728079, 'step': 3629000}
INFO:transformers.trainer:{'loss': 3.123384218931198, 'learning_rate': 3.910500963634056e-05, 'epoch': 0.6536994218195663, 'step': 3629500}
INFO:transformers.trainer:{'loss': 3.1249235470294954, 'learning_rate': 3.9103508742227925e-05, 'epoch': 0.6537894754663248, 'step': 3630000}
INFO:transformers.trainer:{'loss': 3.1339850018024444, 'learning_rate': 3.910200784811528e-05, 'epoch': 0.6538795291130832, 'step': 3630500}
INFO:transformers.trainer:{'loss': 3.1239799330234526, 'learning_rate': 3.9100506954002643e-05, 'epoch': 0.6539695827598417, 'step': 3631000}
INFO:transformers.trainer:{'loss': 3.1908734893798827, 'learning_rate': 3.9099006059889996e-05, 'epoch': 0.6540596364066001, 'step': 3631500}
INFO:transformers.trainer:{'loss': 3.160650724887848, 'learning_rate': 3.909750516577736e-05, 'epoch': 0.6541496900533585, 'step': 3632000}
INFO:transformers.trainer:{'loss': 3.103449388742447, 'learning_rate': 3.9096004271664714e-05, 'epoch': 0.6542397437001171, 'step': 3632500}
INFO:transformers.trainer:{'loss': 3.1373214324712753, 'learning_rate': 3.909450337755208e-05, 'epoch': 0.6543297973468755, 'step': 3633000}
INFO:transformers.trainer:{'loss': 3.173926309585571, 'learning_rate': 3.909300248343943e-05, 'epoch': 0.654419850993634, 'step': 3633500}
INFO:transformers.trainer:{'loss': 3.1545350550413134, 'learning_rate': 3.90915015893268e-05, 'epoch': 0.6545099046403924, 'step': 3634000}
INFO:transformers.trainer:{'loss': 3.1462833423614502, 'learning_rate': 3.909000069521416e-05, 'epoch': 0.6545999582871508, 'step': 3634500}
INFO:transformers.trainer:{'loss': 3.1423793804645537, 'learning_rate': 3.9088499801101516e-05, 'epoch': 0.6546900119339093, 'step': 3635000}
INFO:transformers.trainer:{'loss': 3.1370615849494934, 'learning_rate': 3.9086998906988875e-05, 'epoch': 0.6547800655806677, 'step': 3635500}
INFO:transformers.trainer:{'loss': 3.137653639316559, 'learning_rate': 3.9085498012876234e-05, 'epoch': 0.6548701192274262, 'step': 3636000}
INFO:transformers.trainer:{'loss': 3.1128229929208757, 'learning_rate': 3.908399711876359e-05, 'epoch': 0.6549601728741846, 'step': 3636500}
INFO:transformers.trainer:{'loss': 3.1230242965221406, 'learning_rate': 3.908249622465095e-05, 'epoch': 0.655050226520943, 'step': 3637000}
INFO:transformers.trainer:{'loss': 3.1403106524944304, 'learning_rate': 3.908099533053831e-05, 'epoch': 0.6551402801677015, 'step': 3637500}
INFO:transformers.trainer:{'loss': 3.138117557168007, 'learning_rate': 3.907949443642567e-05, 'epoch': 0.6552303338144599, 'step': 3638000}
INFO:transformers.trainer:{'loss': 3.190711899280548, 'learning_rate': 3.907799354231303e-05, 'epoch': 0.6553203874612183, 'step': 3638500}
INFO:transformers.trainer:{'loss': 3.0904583045244216, 'learning_rate': 3.907649264820039e-05, 'epoch': 0.6554104411079769, 'step': 3639000}
INFO:transformers.trainer:{'loss': 3.1551622021198273, 'learning_rate': 3.907499175408775e-05, 'epoch': 0.6555004947547353, 'step': 3639500}
INFO:transformers.trainer:{'loss': 3.161864230155945, 'learning_rate': 3.9073490859975106e-05, 'epoch': 0.6555905484014938, 'step': 3640000}
INFO:transformers.trainer:{'loss': 3.191661404848099, 'learning_rate': 3.9071989965862465e-05, 'epoch': 0.6556806020482522, 'step': 3640500}
INFO:transformers.trainer:{'loss': 3.0909643796682356, 'learning_rate': 3.9070489071749824e-05, 'epoch': 0.6557706556950106, 'step': 3641000}
INFO:transformers.trainer:{'loss': 3.1738750364780426, 'learning_rate': 3.9068988177637184e-05, 'epoch': 0.6558607093417691, 'step': 3641500}
INFO:transformers.trainer:{'loss': 3.1425426876544953, 'learning_rate': 3.906748728352454e-05, 'epoch': 0.6559507629885275, 'step': 3642000}
INFO:transformers.trainer:{'loss': 3.1084026317596436, 'learning_rate': 3.90659863894119e-05, 'epoch': 0.656040816635286, 'step': 3642500}
INFO:transformers.trainer:{'loss': 3.101140798687935, 'learning_rate': 3.906448549529926e-05, 'epoch': 0.6561308702820444, 'step': 3643000}
INFO:transformers.trainer:{'loss': 3.128196009874344, 'learning_rate': 3.906298460118662e-05, 'epoch': 0.6562209239288028, 'step': 3643500}
INFO:transformers.trainer:{'loss': 3.14664018201828, 'learning_rate': 3.906148370707398e-05, 'epoch': 0.6563109775755613, 'step': 3644000}
INFO:transformers.trainer:{'loss': 3.1124601407051085, 'learning_rate': 3.905998281296134e-05, 'epoch': 0.6564010312223197, 'step': 3644500}
INFO:transformers.trainer:{'loss': 3.105542123556137, 'learning_rate': 3.90584819188487e-05, 'epoch': 0.6564910848690783, 'step': 3645000}
INFO:transformers.trainer:{'loss': 3.108700132012367, 'learning_rate': 3.9056981024736056e-05, 'epoch': 0.6565811385158367, 'step': 3645500}
INFO:transformers.trainer:{'loss': 3.094158035039902, 'learning_rate': 3.9055480130623415e-05, 'epoch': 0.6566711921625951, 'step': 3646000}
INFO:transformers.trainer:{'loss': 3.095212640047073, 'learning_rate': 3.9053979236510774e-05, 'epoch': 0.6567612458093536, 'step': 3646500}
INFO:transformers.trainer:{'loss': 3.1477049815654756, 'learning_rate': 3.905247834239813e-05, 'epoch': 0.656851299456112, 'step': 3647000}
INFO:transformers.trainer:{'loss': 3.123207418203354, 'learning_rate': 3.905097744828549e-05, 'epoch': 0.6569413531028705, 'step': 3647500}
INFO:transformers.trainer:{'loss': 3.1164574776887894, 'learning_rate': 3.904947655417285e-05, 'epoch': 0.6570314067496289, 'step': 3648000}
INFO:transformers.trainer:{'loss': 3.165947386264801, 'learning_rate': 3.904797566006022e-05, 'epoch': 0.6571214603963873, 'step': 3648500}
INFO:transformers.trainer:{'loss': 3.1207635662555693, 'learning_rate': 3.904647476594757e-05, 'epoch': 0.6572115140431458, 'step': 3649000}
INFO:transformers.trainer:{'loss': 3.1313353481292725, 'learning_rate': 3.9044973871834935e-05, 'epoch': 0.6573015676899042, 'step': 3649500}
INFO:transformers.trainer:{'loss': 3.1485407160520555, 'learning_rate': 3.904347297772229e-05, 'epoch': 0.6573916213366626, 'step': 3650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1949499027729034, 'learning_rate': 3.904197208360965e-05, 'epoch': 0.6574816749834211, 'step': 3650500}
INFO:transformers.trainer:{'loss': 3.1368906219005583, 'learning_rate': 3.9040471189497005e-05, 'epoch': 0.6575717286301795, 'step': 3651000}
INFO:transformers.trainer:{'loss': 3.081991621136665, 'learning_rate': 3.903897029538437e-05, 'epoch': 0.6576617822769381, 'step': 3651500}
INFO:transformers.trainer:{'loss': 3.135668820858002, 'learning_rate': 3.9037469401271724e-05, 'epoch': 0.6577518359236965, 'step': 3652000}
INFO:transformers.trainer:{'loss': 3.096899475812912, 'learning_rate': 3.903596850715909e-05, 'epoch': 0.6578418895704549, 'step': 3652500}
INFO:transformers.trainer:{'loss': 3.1348422882556917, 'learning_rate': 3.903446761304644e-05, 'epoch': 0.6579319432172134, 'step': 3653000}
INFO:transformers.trainer:{'loss': 3.1440854704380037, 'learning_rate': 3.903296671893381e-05, 'epoch': 0.6580219968639718, 'step': 3653500}
INFO:transformers.trainer:{'loss': 3.1075024509429934, 'learning_rate': 3.903146582482116e-05, 'epoch': 0.6581120505107303, 'step': 3654000}
INFO:transformers.trainer:{'loss': 3.1226574602127077, 'learning_rate': 3.9029964930708526e-05, 'epoch': 0.6582021041574887, 'step': 3654500}
INFO:transformers.trainer:{'loss': 3.160763776779175, 'learning_rate': 3.9028464036595885e-05, 'epoch': 0.6582921578042471, 'step': 3655000}
INFO:transformers.trainer:{'loss': 3.1241008787155153, 'learning_rate': 3.9026963142483244e-05, 'epoch': 0.6583822114510056, 'step': 3655500}
INFO:transformers.trainer:{'loss': 3.1238106184005736, 'learning_rate': 3.90254622483706e-05, 'epoch': 0.658472265097764, 'step': 3656000}
INFO:transformers.trainer:{'loss': 3.1131646738052368, 'learning_rate': 3.902396135425796e-05, 'epoch': 0.6585623187445225, 'step': 3656500}
INFO:transformers.trainer:{'loss': 3.137987056016922, 'learning_rate': 3.902246046014532e-05, 'epoch': 0.6586523723912809, 'step': 3657000}
INFO:transformers.trainer:{'loss': 3.1527949664592745, 'learning_rate': 3.902095956603268e-05, 'epoch': 0.6587424260380393, 'step': 3657500}
INFO:transformers.trainer:{'loss': 3.0934244384765623, 'learning_rate': 3.901945867192004e-05, 'epoch': 0.6588324796847979, 'step': 3658000}
INFO:transformers.trainer:{'loss': 3.1156917315721513, 'learning_rate': 3.90179577778074e-05, 'epoch': 0.6589225333315563, 'step': 3658500}
INFO:transformers.trainer:{'loss': 3.08443026638031, 'learning_rate': 3.901645688369476e-05, 'epoch': 0.6590125869783148, 'step': 3659000}
INFO:transformers.trainer:{'loss': 3.146463463783264, 'learning_rate': 3.9014955989582116e-05, 'epoch': 0.6591026406250732, 'step': 3659500}
INFO:transformers.trainer:{'loss': 3.1449726185798643, 'learning_rate': 3.9013455095469475e-05, 'epoch': 0.6591926942718316, 'step': 3660000}
INFO:transformers.trainer:{'loss': 3.1944720824956896, 'learning_rate': 3.9011954201356834e-05, 'epoch': 0.6592827479185901, 'step': 3660500}
INFO:transformers.trainer:{'loss': 3.173716673374176, 'learning_rate': 3.901045330724419e-05, 'epoch': 0.6593728015653485, 'step': 3661000}
INFO:transformers.trainer:{'loss': 3.1259744901657105, 'learning_rate': 3.900895241313155e-05, 'epoch': 0.6594628552121069, 'step': 3661500}
INFO:transformers.trainer:{'loss': 3.1406821208000184, 'learning_rate': 3.900745151901891e-05, 'epoch': 0.6595529088588654, 'step': 3662000}
INFO:transformers.trainer:{'loss': 3.1098328306674956, 'learning_rate': 3.900595062490627e-05, 'epoch': 0.6596429625056238, 'step': 3662500}
INFO:transformers.trainer:{'loss': 3.140051109075546, 'learning_rate': 3.900444973079363e-05, 'epoch': 0.6597330161523823, 'step': 3663000}
INFO:transformers.trainer:{'loss': 3.1543590276241305, 'learning_rate': 3.900294883668099e-05, 'epoch': 0.6598230697991407, 'step': 3663500}
INFO:transformers.trainer:{'loss': 3.1246010080575943, 'learning_rate': 3.900144794256835e-05, 'epoch': 0.6599131234458991, 'step': 3664000}
INFO:transformers.trainer:{'loss': 3.147659787654877, 'learning_rate': 3.8999947048455707e-05, 'epoch': 0.6600031770926577, 'step': 3664500}
INFO:transformers.trainer:{'loss': 3.0516994804143907, 'learning_rate': 3.8998446154343066e-05, 'epoch': 0.6600932307394161, 'step': 3665000}
INFO:transformers.trainer:{'loss': 3.1200706748962403, 'learning_rate': 3.8996945260230425e-05, 'epoch': 0.6601832843861746, 'step': 3665500}
INFO:transformers.trainer:{'loss': 3.0655097774267195, 'learning_rate': 3.8995444366117784e-05, 'epoch': 0.660273338032933, 'step': 3666000}
INFO:transformers.trainer:{'loss': 3.132743032693863, 'learning_rate': 3.899394347200514e-05, 'epoch': 0.6603633916796914, 'step': 3666500}
INFO:transformers.trainer:{'loss': 3.128338060617447, 'learning_rate': 3.89924425778925e-05, 'epoch': 0.6604534453264499, 'step': 3667000}
INFO:transformers.trainer:{'loss': 3.115509070396423, 'learning_rate': 3.899094168377986e-05, 'epoch': 0.6605434989732083, 'step': 3667500}
INFO:transformers.trainer:{'loss': 3.1923159141540527, 'learning_rate': 3.898944078966722e-05, 'epoch': 0.6606335526199668, 'step': 3668000}
INFO:transformers.trainer:{'loss': 3.0958134739398955, 'learning_rate': 3.898793989555458e-05, 'epoch': 0.6607236062667252, 'step': 3668500}
INFO:transformers.trainer:{'loss': 3.13524456346035, 'learning_rate': 3.8986439001441945e-05, 'epoch': 0.6608136599134836, 'step': 3669000}
INFO:transformers.trainer:{'loss': 3.089730365514755, 'learning_rate': 3.89849381073293e-05, 'epoch': 0.6609037135602421, 'step': 3669500}
INFO:transformers.trainer:{'loss': 3.1655816793441773, 'learning_rate': 3.898343721321666e-05, 'epoch': 0.6609937672070005, 'step': 3670000}
INFO:transformers.trainer:{'loss': 3.1501477035284045, 'learning_rate': 3.8981936319104015e-05, 'epoch': 0.661083820853759, 'step': 3670500}
INFO:transformers.trainer:{'loss': 3.1107266830205917, 'learning_rate': 3.898043542499138e-05, 'epoch': 0.6611738745005175, 'step': 3671000}
INFO:transformers.trainer:{'loss': 3.0625217765569688, 'learning_rate': 3.897893453087873e-05, 'epoch': 0.6612639281472759, 'step': 3671500}
INFO:transformers.trainer:{'loss': 3.1234837543964384, 'learning_rate': 3.89774336367661e-05, 'epoch': 0.6613539817940344, 'step': 3672000}
INFO:transformers.trainer:{'loss': 3.144277103424072, 'learning_rate': 3.897593274265345e-05, 'epoch': 0.6614440354407928, 'step': 3672500}
INFO:transformers.trainer:{'loss': 3.104823247909546, 'learning_rate': 3.897443184854082e-05, 'epoch': 0.6615340890875513, 'step': 3673000}
INFO:transformers.trainer:{'loss': 3.144508550405502, 'learning_rate': 3.897293095442817e-05, 'epoch': 0.6616241427343097, 'step': 3673500}
INFO:transformers.trainer:{'loss': 3.1162750232219696, 'learning_rate': 3.8971430060315535e-05, 'epoch': 0.6617141963810681, 'step': 3674000}
INFO:transformers.trainer:{'loss': 3.1566536371707916, 'learning_rate': 3.896992916620289e-05, 'epoch': 0.6618042500278266, 'step': 3674500}
INFO:transformers.trainer:{'loss': 3.1078700523376463, 'learning_rate': 3.8968428272090253e-05, 'epoch': 0.661894303674585, 'step': 3675000}
INFO:transformers.trainer:{'loss': 3.1635972192287447, 'learning_rate': 3.896692737797761e-05, 'epoch': 0.6619843573213434, 'step': 3675500}
INFO:transformers.trainer:{'loss': 3.130504046678543, 'learning_rate': 3.896542648386497e-05, 'epoch': 0.6620744109681019, 'step': 3676000}
INFO:transformers.trainer:{'loss': 3.149535880923271, 'learning_rate': 3.896392558975233e-05, 'epoch': 0.6621644646148603, 'step': 3676500}
INFO:transformers.trainer:{'loss': 3.121088619709015, 'learning_rate': 3.896242469563969e-05, 'epoch': 0.6622545182616189, 'step': 3677000}
INFO:transformers.trainer:{'loss': 3.218232181072235, 'learning_rate': 3.896092380152705e-05, 'epoch': 0.6623445719083773, 'step': 3677500}
INFO:transformers.trainer:{'loss': 3.1812295968532562, 'learning_rate': 3.895942290741441e-05, 'epoch': 0.6624346255551357, 'step': 3678000}
INFO:transformers.trainer:{'loss': 3.141009459733963, 'learning_rate': 3.895792201330177e-05, 'epoch': 0.6625246792018942, 'step': 3678500}
INFO:transformers.trainer:{'loss': 3.136585671067238, 'learning_rate': 3.8956421119189126e-05, 'epoch': 0.6626147328486526, 'step': 3679000}
INFO:transformers.trainer:{'loss': 3.163129246354103, 'learning_rate': 3.8954920225076485e-05, 'epoch': 0.6627047864954111, 'step': 3679500}
INFO:transformers.trainer:{'loss': 3.127829965829849, 'learning_rate': 3.8953419330963844e-05, 'epoch': 0.6627948401421695, 'step': 3680000}
INFO:transformers.trainer:{'loss': 3.11152376639843, 'learning_rate': 3.89519184368512e-05, 'epoch': 0.6628848937889279, 'step': 3680500}
INFO:transformers.trainer:{'loss': 3.1810586807727814, 'learning_rate': 3.895041754273856e-05, 'epoch': 0.6629749474356864, 'step': 3681000}
INFO:transformers.trainer:{'loss': 3.151409833908081, 'learning_rate': 3.894891664862592e-05, 'epoch': 0.6630650010824448, 'step': 3681500}
INFO:transformers.trainer:{'loss': 3.091850745439529, 'learning_rate': 3.894741575451328e-05, 'epoch': 0.6631550547292033, 'step': 3682000}
INFO:transformers.trainer:{'loss': 3.1447049016952513, 'learning_rate': 3.894591486040064e-05, 'epoch': 0.6632451083759617, 'step': 3682500}
INFO:transformers.trainer:{'loss': 3.1077881028652192, 'learning_rate': 3.8944413966288e-05, 'epoch': 0.6633351620227201, 'step': 3683000}
INFO:transformers.trainer:{'loss': 3.1245609893798827, 'learning_rate': 3.894291307217536e-05, 'epoch': 0.6634252156694787, 'step': 3683500}
INFO:transformers.trainer:{'loss': 3.166810882329941, 'learning_rate': 3.8941412178062716e-05, 'epoch': 0.663515269316237, 'step': 3684000}
INFO:transformers.trainer:{'loss': 3.0991904184818266, 'learning_rate': 3.8939911283950075e-05, 'epoch': 0.6636053229629956, 'step': 3684500}
INFO:transformers.trainer:{'loss': 3.1353015315532686, 'learning_rate': 3.8938410389837434e-05, 'epoch': 0.663695376609754, 'step': 3685000}
INFO:transformers.trainer:{'loss': 3.05311394071579, 'learning_rate': 3.8936909495724793e-05, 'epoch': 0.6637854302565124, 'step': 3685500}
INFO:transformers.trainer:{'loss': 3.1160824978351593, 'learning_rate': 3.893540860161215e-05, 'epoch': 0.6638754839032709, 'step': 3686000}
INFO:transformers.trainer:{'loss': 3.172989692687988, 'learning_rate': 3.893390770749951e-05, 'epoch': 0.6639655375500293, 'step': 3686500}
INFO:transformers.trainer:{'loss': 3.115154604792595, 'learning_rate': 3.893240681338687e-05, 'epoch': 0.6640555911967877, 'step': 3687000}
INFO:transformers.trainer:{'loss': 3.0518686764240264, 'learning_rate': 3.893090591927423e-05, 'epoch': 0.6641456448435462, 'step': 3687500}
INFO:transformers.trainer:{'loss': 3.134113874912262, 'learning_rate': 3.892940502516159e-05, 'epoch': 0.6642356984903046, 'step': 3688000}
INFO:transformers.trainer:{'loss': 3.117284605264664, 'learning_rate': 3.892790413104895e-05, 'epoch': 0.6643257521370631, 'step': 3688500}
INFO:transformers.trainer:{'loss': 3.117679639458656, 'learning_rate': 3.892640323693631e-05, 'epoch': 0.6644158057838215, 'step': 3689000}
INFO:transformers.trainer:{'loss': 3.1142176015377045, 'learning_rate': 3.892490234282367e-05, 'epoch': 0.6645058594305799, 'step': 3689500}
INFO:transformers.trainer:{'loss': 3.163058095693588, 'learning_rate': 3.8923401448711025e-05, 'epoch': 0.6645959130773385, 'step': 3690000}
INFO:transformers.trainer:{'loss': 3.12395800614357, 'learning_rate': 3.892190055459839e-05, 'epoch': 0.6646859667240969, 'step': 3690500}
INFO:transformers.trainer:{'loss': 3.156098900318146, 'learning_rate': 3.892039966048574e-05, 'epoch': 0.6647760203708554, 'step': 3691000}
INFO:transformers.trainer:{'loss': 3.1399150812625884, 'learning_rate': 3.891889876637311e-05, 'epoch': 0.6648660740176138, 'step': 3691500}
INFO:transformers.trainer:{'loss': 3.136875412940979, 'learning_rate': 3.891739787226046e-05, 'epoch': 0.6649561276643722, 'step': 3692000}
INFO:transformers.trainer:{'loss': 3.08742830824852, 'learning_rate': 3.891589697814783e-05, 'epoch': 0.6650461813111307, 'step': 3692500}
INFO:transformers.trainer:{'loss': 3.064443796157837, 'learning_rate': 3.891439608403518e-05, 'epoch': 0.6651362349578891, 'step': 3693000}
INFO:transformers.trainer:{'loss': 3.1442307929992674, 'learning_rate': 3.8912895189922545e-05, 'epoch': 0.6652262886046476, 'step': 3693500}
INFO:transformers.trainer:{'loss': 3.12320921254158, 'learning_rate': 3.89113942958099e-05, 'epoch': 0.665316342251406, 'step': 3694000}
INFO:transformers.trainer:{'loss': 3.1043682420253753, 'learning_rate': 3.890989340169726e-05, 'epoch': 0.6654063958981644, 'step': 3694500}
INFO:transformers.trainer:{'loss': 3.1120124077796936, 'learning_rate': 3.8908392507584615e-05, 'epoch': 0.6654964495449229, 'step': 3695000}
INFO:transformers.trainer:{'loss': 3.134286165714264, 'learning_rate': 3.890689161347198e-05, 'epoch': 0.6655865031916813, 'step': 3695500}
INFO:transformers.trainer:{'loss': 3.173492943763733, 'learning_rate': 3.8905390719359334e-05, 'epoch': 0.6656765568384398, 'step': 3696000}
INFO:transformers.trainer:{'loss': 3.1199532729387283, 'learning_rate': 3.89038898252467e-05, 'epoch': 0.6657666104851983, 'step': 3696500}
INFO:transformers.trainer:{'loss': 3.1100559848546983, 'learning_rate': 3.890238893113406e-05, 'epoch': 0.6658566641319567, 'step': 3697000}
INFO:transformers.trainer:{'loss': 3.127173238158226, 'learning_rate': 3.890088803702142e-05, 'epoch': 0.6659467177787152, 'step': 3697500}
INFO:transformers.trainer:{'loss': 3.1368276547193528, 'learning_rate': 3.8899387142908777e-05, 'epoch': 0.6660367714254736, 'step': 3698000}
INFO:transformers.trainer:{'loss': 3.106423860549927, 'learning_rate': 3.8897886248796136e-05, 'epoch': 0.666126825072232, 'step': 3698500}
INFO:transformers.trainer:{'loss': 3.1473115541934966, 'learning_rate': 3.8896385354683495e-05, 'epoch': 0.6662168787189905, 'step': 3699000}
INFO:transformers.trainer:{'loss': 3.1810892980098724, 'learning_rate': 3.8894884460570854e-05, 'epoch': 0.6663069323657489, 'step': 3699500}
INFO:transformers.trainer:{'loss': 3.1106085288524628, 'learning_rate': 3.889338356645821e-05, 'epoch': 0.6663969860125074, 'step': 3700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1082388508319854, 'learning_rate': 3.889188267234557e-05, 'epoch': 0.6664870396592658, 'step': 3700500}
INFO:transformers.trainer:{'loss': 3.2018674104213716, 'learning_rate': 3.889038177823293e-05, 'epoch': 0.6665770933060242, 'step': 3701000}
INFO:transformers.trainer:{'loss': 3.1531932326555254, 'learning_rate': 3.888888088412029e-05, 'epoch': 0.6666671469527827, 'step': 3701500}
INFO:transformers.trainer:{'loss': 3.1606452233791353, 'learning_rate': 3.888737999000765e-05, 'epoch': 0.6667572005995411, 'step': 3702000}
INFO:transformers.trainer:{'loss': 3.158666486263275, 'learning_rate': 3.888587909589501e-05, 'epoch': 0.6668472542462996, 'step': 3702500}
INFO:transformers.trainer:{'loss': 3.1150479007959366, 'learning_rate': 3.888437820178237e-05, 'epoch': 0.666937307893058, 'step': 3703000}
INFO:transformers.trainer:{'loss': 3.1262616926431654, 'learning_rate': 3.888287730766973e-05, 'epoch': 0.6670273615398165, 'step': 3703500}
INFO:transformers.trainer:{'loss': 3.2233830260038374, 'learning_rate': 3.8881376413557085e-05, 'epoch': 0.667117415186575, 'step': 3704000}
INFO:transformers.trainer:{'loss': 3.0730087060928346, 'learning_rate': 3.8879875519444444e-05, 'epoch': 0.6672074688333334, 'step': 3704500}
INFO:transformers.trainer:{'loss': 3.096738993763924, 'learning_rate': 3.88783746253318e-05, 'epoch': 0.6672975224800919, 'step': 3705000}
INFO:transformers.trainer:{'loss': 3.093995593070984, 'learning_rate': 3.887687373121916e-05, 'epoch': 0.6673875761268503, 'step': 3705500}
INFO:transformers.trainer:{'loss': 3.077782868027687, 'learning_rate': 3.887537283710652e-05, 'epoch': 0.6674776297736087, 'step': 3706000}
INFO:transformers.trainer:{'loss': 3.161547170639038, 'learning_rate': 3.887387194299388e-05, 'epoch': 0.6675676834203672, 'step': 3706500}
INFO:transformers.trainer:{'loss': 3.2145245000123976, 'learning_rate': 3.887237104888124e-05, 'epoch': 0.6676577370671256, 'step': 3707000}
INFO:transformers.trainer:{'loss': 3.1627274478673937, 'learning_rate': 3.88708701547686e-05, 'epoch': 0.6677477907138841, 'step': 3707500}
INFO:transformers.trainer:{'loss': 3.1203786066770554, 'learning_rate': 3.886936926065596e-05, 'epoch': 0.6678378443606425, 'step': 3708000}
INFO:transformers.trainer:{'loss': 3.091556630373001, 'learning_rate': 3.8867868366543317e-05, 'epoch': 0.6679278980074009, 'step': 3708500}
INFO:transformers.trainer:{'loss': 3.1837816364765166, 'learning_rate': 3.8866367472430676e-05, 'epoch': 0.6680179516541594, 'step': 3709000}
INFO:transformers.trainer:{'loss': 3.1681165742874144, 'learning_rate': 3.8864866578318035e-05, 'epoch': 0.6681080053009179, 'step': 3709500}
INFO:transformers.trainer:{'loss': 3.1066423766613007, 'learning_rate': 3.88633656842054e-05, 'epoch': 0.6681980589476763, 'step': 3710000}
INFO:transformers.trainer:{'loss': 3.123597892999649, 'learning_rate': 3.886186479009275e-05, 'epoch': 0.6682881125944348, 'step': 3710500}
INFO:transformers.trainer:{'loss': 3.1776617300510406, 'learning_rate': 3.886036389598012e-05, 'epoch': 0.6683781662411932, 'step': 3711000}
INFO:transformers.trainer:{'loss': 3.135188899040222, 'learning_rate': 3.885886300186747e-05, 'epoch': 0.6684682198879517, 'step': 3711500}
INFO:transformers.trainer:{'loss': 3.1659491651058196, 'learning_rate': 3.885736210775484e-05, 'epoch': 0.6685582735347101, 'step': 3712000}
INFO:transformers.trainer:{'loss': 3.118674075603485, 'learning_rate': 3.885586121364219e-05, 'epoch': 0.6686483271814685, 'step': 3712500}
INFO:transformers.trainer:{'loss': 3.1621609790325165, 'learning_rate': 3.8854360319529555e-05, 'epoch': 0.668738380828227, 'step': 3713000}
INFO:transformers.trainer:{'loss': 3.1677123658657074, 'learning_rate': 3.885285942541691e-05, 'epoch': 0.6688284344749854, 'step': 3713500}
INFO:transformers.trainer:{'loss': 3.096979071855545, 'learning_rate': 3.885135853130427e-05, 'epoch': 0.6689184881217439, 'step': 3714000}
INFO:transformers.trainer:{'loss': 3.1489336013793947, 'learning_rate': 3.8849857637191625e-05, 'epoch': 0.6690085417685023, 'step': 3714500}
INFO:transformers.trainer:{'loss': 3.1330192441940308, 'learning_rate': 3.884835674307899e-05, 'epoch': 0.6690985954152607, 'step': 3715000}
INFO:transformers.trainer:{'loss': 3.1005204441547396, 'learning_rate': 3.884685584896634e-05, 'epoch': 0.6691886490620192, 'step': 3715500}
INFO:transformers.trainer:{'loss': 3.067359916687012, 'learning_rate': 3.884535495485371e-05, 'epoch': 0.6692787027087777, 'step': 3716000}
INFO:transformers.trainer:{'loss': 3.142826856613159, 'learning_rate': 3.884385406074106e-05, 'epoch': 0.6693687563555362, 'step': 3716500}
INFO:transformers.trainer:{'loss': 3.0755981384515763, 'learning_rate': 3.884235316662843e-05, 'epoch': 0.6694588100022946, 'step': 3717000}
INFO:transformers.trainer:{'loss': 3.1293899102211, 'learning_rate': 3.8840852272515786e-05, 'epoch': 0.669548863649053, 'step': 3717500}
INFO:transformers.trainer:{'loss': 3.142138906478882, 'learning_rate': 3.8839351378403145e-05, 'epoch': 0.6696389172958115, 'step': 3718000}
INFO:transformers.trainer:{'loss': 3.137102524757385, 'learning_rate': 3.8837850484290504e-05, 'epoch': 0.6697289709425699, 'step': 3718500}
INFO:transformers.trainer:{'loss': 3.1320137522220612, 'learning_rate': 3.883634959017786e-05, 'epoch': 0.6698190245893284, 'step': 3719000}
INFO:transformers.trainer:{'loss': 3.147014072179794, 'learning_rate': 3.883484869606522e-05, 'epoch': 0.6699090782360868, 'step': 3719500}
INFO:transformers.trainer:{'loss': 3.181601480960846, 'learning_rate': 3.883334780195258e-05, 'epoch': 0.6699991318828452, 'step': 3720000}
INFO:transformers.trainer:{'loss': 3.162080237388611, 'learning_rate': 3.883184690783994e-05, 'epoch': 0.6700891855296037, 'step': 3720500}
INFO:transformers.trainer:{'loss': 3.1323320813179016, 'learning_rate': 3.88303460137273e-05, 'epoch': 0.6701792391763621, 'step': 3721000}
INFO:transformers.trainer:{'loss': 3.174290416955948, 'learning_rate': 3.882884511961466e-05, 'epoch': 0.6702692928231206, 'step': 3721500}
INFO:transformers.trainer:{'loss': 3.309199166893959, 'learning_rate': 3.882734422550202e-05, 'epoch': 0.670359346469879, 'step': 3722000}
INFO:transformers.trainer:{'loss': 3.2650573501586915, 'learning_rate': 3.882584333138938e-05, 'epoch': 0.6704494001166375, 'step': 3722500}
INFO:transformers.trainer:{'loss': 3.1501457600593565, 'learning_rate': 3.8824342437276736e-05, 'epoch': 0.670539453763396, 'step': 3723000}
INFO:transformers.trainer:{'loss': 3.152852844953537, 'learning_rate': 3.8822841543164095e-05, 'epoch': 0.6706295074101544, 'step': 3723500}
INFO:transformers.trainer:{'loss': 3.0869991569519044, 'learning_rate': 3.882134064905146e-05, 'epoch': 0.6707195610569128, 'step': 3724000}
INFO:transformers.trainer:{'loss': 3.098352290153503, 'learning_rate': 3.881983975493881e-05, 'epoch': 0.6708096147036713, 'step': 3724500}
INFO:transformers.trainer:{'loss': 3.1039789249897005, 'learning_rate': 3.881833886082618e-05, 'epoch': 0.6708996683504297, 'step': 3725000}
INFO:transformers.trainer:{'loss': 3.189289723396301, 'learning_rate': 3.881683796671353e-05, 'epoch': 0.6709897219971882, 'step': 3725500}
INFO:transformers.trainer:{'loss': 3.143976683139801, 'learning_rate': 3.88153370726009e-05, 'epoch': 0.6710797756439466, 'step': 3726000}
INFO:transformers.trainer:{'loss': 3.1051198699474334, 'learning_rate': 3.881383617848825e-05, 'epoch': 0.671169829290705, 'step': 3726500}
INFO:transformers.trainer:{'loss': 3.125927025794983, 'learning_rate': 3.8812335284375615e-05, 'epoch': 0.6712598829374635, 'step': 3727000}
INFO:transformers.trainer:{'loss': 3.074906723499298, 'learning_rate': 3.881083439026297e-05, 'epoch': 0.6713499365842219, 'step': 3727500}
INFO:transformers.trainer:{'loss': 3.085879090309143, 'learning_rate': 3.8809333496150326e-05, 'epoch': 0.6714399902309804, 'step': 3728000}
INFO:transformers.trainer:{'loss': 3.1531870651245115, 'learning_rate': 3.8807832602037685e-05, 'epoch': 0.6715300438777388, 'step': 3728500}
INFO:transformers.trainer:{'loss': 3.071620455980301, 'learning_rate': 3.8806331707925044e-05, 'epoch': 0.6716200975244973, 'step': 3729000}
INFO:transformers.trainer:{'loss': 3.123184835314751, 'learning_rate': 3.8804830813812403e-05, 'epoch': 0.6717101511712558, 'step': 3729500}
INFO:transformers.trainer:{'loss': 3.112957484602928, 'learning_rate': 3.880332991969976e-05, 'epoch': 0.6718002048180142, 'step': 3730000}
INFO:transformers.trainer:{'loss': 3.078198651075363, 'learning_rate': 3.880182902558712e-05, 'epoch': 0.6718902584647727, 'step': 3730500}
INFO:transformers.trainer:{'loss': 3.1568162133693694, 'learning_rate': 3.880032813147448e-05, 'epoch': 0.6719803121115311, 'step': 3731000}
INFO:transformers.trainer:{'loss': 3.129025562286377, 'learning_rate': 3.8798827237361846e-05, 'epoch': 0.6720703657582895, 'step': 3731500}
INFO:transformers.trainer:{'loss': 3.170030277490616, 'learning_rate': 3.87973263432492e-05, 'epoch': 0.672160419405048, 'step': 3732000}
INFO:transformers.trainer:{'loss': 3.129171436548233, 'learning_rate': 3.8795825449136565e-05, 'epoch': 0.6722504730518064, 'step': 3732500}
INFO:transformers.trainer:{'loss': 3.1422611432075502, 'learning_rate': 3.879432455502392e-05, 'epoch': 0.6723405266985649, 'step': 3733000}
INFO:transformers.trainer:{'loss': 3.0959164605140685, 'learning_rate': 3.879282366091128e-05, 'epoch': 0.6724305803453233, 'step': 3733500}
INFO:transformers.trainer:{'loss': 3.110836487054825, 'learning_rate': 3.8791322766798635e-05, 'epoch': 0.6725206339920817, 'step': 3734000}
INFO:transformers.trainer:{'loss': 3.1203288917541503, 'learning_rate': 3.8789821872686e-05, 'epoch': 0.6726106876388402, 'step': 3734500}
INFO:transformers.trainer:{'loss': 3.1374799304008483, 'learning_rate': 3.878832097857335e-05, 'epoch': 0.6727007412855986, 'step': 3735000}
INFO:transformers.trainer:{'loss': 3.1537650655508043, 'learning_rate': 3.878682008446072e-05, 'epoch': 0.672790794932357, 'step': 3735500}
INFO:transformers.trainer:{'loss': 3.181593785524368, 'learning_rate': 3.878531919034807e-05, 'epoch': 0.6728808485791156, 'step': 3736000}
INFO:transformers.trainer:{'loss': 3.1923296014070512, 'learning_rate': 3.878381829623544e-05, 'epoch': 0.672970902225874, 'step': 3736500}
INFO:transformers.trainer:{'loss': 3.109509668111801, 'learning_rate': 3.878231740212279e-05, 'epoch': 0.6730609558726325, 'step': 3737000}
INFO:transformers.trainer:{'loss': 3.1680763511657717, 'learning_rate': 3.8780816508010155e-05, 'epoch': 0.6731510095193909, 'step': 3737500}
INFO:transformers.trainer:{'loss': 3.14310435795784, 'learning_rate': 3.8779315613897514e-05, 'epoch': 0.6732410631661493, 'step': 3738000}
INFO:transformers.trainer:{'loss': 3.1557442202568056, 'learning_rate': 3.877781471978487e-05, 'epoch': 0.6733311168129078, 'step': 3738500}
INFO:transformers.trainer:{'loss': 3.144245592355728, 'learning_rate': 3.877631382567223e-05, 'epoch': 0.6734211704596662, 'step': 3739000}
INFO:transformers.trainer:{'loss': 3.156243829250336, 'learning_rate': 3.877481293155959e-05, 'epoch': 0.6735112241064247, 'step': 3739500}
INFO:transformers.trainer:{'loss': 3.1501606904268264, 'learning_rate': 3.877331203744695e-05, 'epoch': 0.6736012777531831, 'step': 3740000}
INFO:transformers.trainer:{'loss': 3.153241864681244, 'learning_rate': 3.877181114333431e-05, 'epoch': 0.6736913313999415, 'step': 3740500}
INFO:transformers.trainer:{'loss': 3.052142416715622, 'learning_rate': 3.877031024922167e-05, 'epoch': 0.6737813850467, 'step': 3741000}
INFO:transformers.trainer:{'loss': 3.1241428318023683, 'learning_rate': 3.876880935510903e-05, 'epoch': 0.6738714386934584, 'step': 3741500}
INFO:transformers.trainer:{'loss': 3.1481371831893923, 'learning_rate': 3.8767308460996386e-05, 'epoch': 0.673961492340217, 'step': 3742000}
INFO:transformers.trainer:{'loss': 3.171417639732361, 'learning_rate': 3.8765807566883746e-05, 'epoch': 0.6740515459869754, 'step': 3742500}
INFO:transformers.trainer:{'loss': 3.175341715455055, 'learning_rate': 3.8764306672771105e-05, 'epoch': 0.6741415996337338, 'step': 3743000}
INFO:transformers.trainer:{'loss': 3.1877897365093233, 'learning_rate': 3.8762805778658464e-05, 'epoch': 0.6742316532804923, 'step': 3743500}
INFO:transformers.trainer:{'loss': 3.1646632048487664, 'learning_rate': 3.876130488454582e-05, 'epoch': 0.6743217069272507, 'step': 3744000}
INFO:transformers.trainer:{'loss': 3.253509866476059, 'learning_rate': 3.875980399043318e-05, 'epoch': 0.6744117605740092, 'step': 3744500}
INFO:transformers.trainer:{'loss': 3.137311481833458, 'learning_rate': 3.875830309632054e-05, 'epoch': 0.6745018142207676, 'step': 3745000}
INFO:transformers.trainer:{'loss': 3.2187149155139925, 'learning_rate': 3.8756802202207907e-05, 'epoch': 0.674591867867526, 'step': 3745500}
INFO:transformers.trainer:{'loss': 3.1722459746599196, 'learning_rate': 3.875530130809526e-05, 'epoch': 0.6746819215142845, 'step': 3746000}
INFO:transformers.trainer:{'loss': 3.207103927373886, 'learning_rate': 3.8753800413982625e-05, 'epoch': 0.6747719751610429, 'step': 3746500}
INFO:transformers.trainer:{'loss': 3.227152321100235, 'learning_rate': 3.875229951986998e-05, 'epoch': 0.6748620288078013, 'step': 3747000}
INFO:transformers.trainer:{'loss': 3.222234706997871, 'learning_rate': 3.875079862575734e-05, 'epoch': 0.6749520824545598, 'step': 3747500}
INFO:transformers.trainer:{'loss': 3.192381757736206, 'learning_rate': 3.8749297731644695e-05, 'epoch': 0.6750421361013182, 'step': 3748000}
INFO:transformers.trainer:{'loss': 3.1955192945003508, 'learning_rate': 3.874779683753206e-05, 'epoch': 0.6751321897480768, 'step': 3748500}
INFO:transformers.trainer:{'loss': 3.1487286052703856, 'learning_rate': 3.874629594341941e-05, 'epoch': 0.6752222433948352, 'step': 3749000}
INFO:transformers.trainer:{'loss': 3.173617735624313, 'learning_rate': 3.874479504930678e-05, 'epoch': 0.6753122970415936, 'step': 3749500}
INFO:transformers.trainer:{'loss': 3.2025446326732636, 'learning_rate': 3.874329415519413e-05, 'epoch': 0.6754023506883521, 'step': 3750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.154147390127182, 'learning_rate': 3.87417932610815e-05, 'epoch': 0.6754924043351105, 'step': 3750500}
INFO:transformers.trainer:{'loss': 3.1445379894971848, 'learning_rate': 3.874029236696885e-05, 'epoch': 0.675582457981869, 'step': 3751000}
INFO:transformers.trainer:{'loss': 3.192521503686905, 'learning_rate': 3.873879147285621e-05, 'epoch': 0.6756725116286274, 'step': 3751500}
INFO:transformers.trainer:{'loss': 3.3079188520908356, 'learning_rate': 3.8737290578743574e-05, 'epoch': 0.6757625652753858, 'step': 3752000}
INFO:transformers.trainer:{'loss': 3.1894913798570634, 'learning_rate': 3.8735789684630927e-05, 'epoch': 0.6758526189221443, 'step': 3752500}
INFO:transformers.trainer:{'loss': 3.2031255333423614, 'learning_rate': 3.873428879051829e-05, 'epoch': 0.6759426725689027, 'step': 3753000}
INFO:transformers.trainer:{'loss': 3.1806172153949737, 'learning_rate': 3.8732787896405645e-05, 'epoch': 0.6760327262156612, 'step': 3753500}
INFO:transformers.trainer:{'loss': 3.1308011012077333, 'learning_rate': 3.873128700229301e-05, 'epoch': 0.6761227798624196, 'step': 3754000}
INFO:transformers.trainer:{'loss': 3.134183896780014, 'learning_rate': 3.872978610818036e-05, 'epoch': 0.676212833509178, 'step': 3754500}
INFO:transformers.trainer:{'loss': 3.1704208101034164, 'learning_rate': 3.872828521406773e-05, 'epoch': 0.6763028871559366, 'step': 3755000}
INFO:transformers.trainer:{'loss': 3.2522112746238707, 'learning_rate': 3.872678431995508e-05, 'epoch': 0.676392940802695, 'step': 3755500}
INFO:transformers.trainer:{'loss': 3.165579090833664, 'learning_rate': 3.872528342584245e-05, 'epoch': 0.6764829944494535, 'step': 3756000}
INFO:transformers.trainer:{'loss': 3.1624128344058993, 'learning_rate': 3.87237825317298e-05, 'epoch': 0.6765730480962119, 'step': 3756500}
INFO:transformers.trainer:{'loss': 3.208390133857727, 'learning_rate': 3.8722281637617165e-05, 'epoch': 0.6766631017429703, 'step': 3757000}
INFO:transformers.trainer:{'loss': 3.1493554148674012, 'learning_rate': 3.872078074350452e-05, 'epoch': 0.6767531553897288, 'step': 3757500}
INFO:transformers.trainer:{'loss': 3.127001046657562, 'learning_rate': 3.871927984939188e-05, 'epoch': 0.6768432090364872, 'step': 3758000}
INFO:transformers.trainer:{'loss': 3.1720732381343844, 'learning_rate': 3.8717778955279235e-05, 'epoch': 0.6769332626832457, 'step': 3758500}
INFO:transformers.trainer:{'loss': 3.1128113055229187, 'learning_rate': 3.87162780611666e-05, 'epoch': 0.6770233163300041, 'step': 3759000}
INFO:transformers.trainer:{'loss': 3.1649650950431822, 'learning_rate': 3.871477716705396e-05, 'epoch': 0.6771133699767625, 'step': 3759500}
INFO:transformers.trainer:{'loss': 3.135033783197403, 'learning_rate': 3.871327627294132e-05, 'epoch': 0.677203423623521, 'step': 3760000}
INFO:transformers.trainer:{'loss': 3.0956194479465484, 'learning_rate': 3.871177537882868e-05, 'epoch': 0.6772934772702794, 'step': 3760500}
INFO:transformers.trainer:{'loss': 3.1769498369693756, 'learning_rate': 3.871027448471604e-05, 'epoch': 0.6773835309170378, 'step': 3761000}
INFO:transformers.trainer:{'loss': 3.1270853686332702, 'learning_rate': 3.8708773590603396e-05, 'epoch': 0.6774735845637964, 'step': 3761500}
INFO:transformers.trainer:{'loss': 3.08263103890419, 'learning_rate': 3.8707272696490755e-05, 'epoch': 0.6775636382105548, 'step': 3762000}
INFO:transformers.trainer:{'loss': 3.1798734084367752, 'learning_rate': 3.8705771802378114e-05, 'epoch': 0.6776536918573133, 'step': 3762500}
INFO:transformers.trainer:{'loss': 3.1081802775859835, 'learning_rate': 3.870427090826547e-05, 'epoch': 0.6777437455040717, 'step': 3763000}
INFO:transformers.trainer:{'loss': 3.1637600119113922, 'learning_rate': 3.870277001415283e-05, 'epoch': 0.6778337991508301, 'step': 3763500}
INFO:transformers.trainer:{'loss': 3.1104320759773256, 'learning_rate': 3.870126912004019e-05, 'epoch': 0.6779238527975886, 'step': 3764000}
INFO:transformers.trainer:{'loss': 3.123952759742737, 'learning_rate': 3.869976822592755e-05, 'epoch': 0.678013906444347, 'step': 3764500}
INFO:transformers.trainer:{'loss': 3.071982384443283, 'learning_rate': 3.869826733181491e-05, 'epoch': 0.6781039600911055, 'step': 3765000}
INFO:transformers.trainer:{'loss': 3.1132490210533144, 'learning_rate': 3.869676643770227e-05, 'epoch': 0.6781940137378639, 'step': 3765500}
INFO:transformers.trainer:{'loss': 3.1499998905658724, 'learning_rate': 3.8695265543589634e-05, 'epoch': 0.6782840673846223, 'step': 3766000}
INFO:transformers.trainer:{'loss': 3.122447670698166, 'learning_rate': 3.869376464947699e-05, 'epoch': 0.6783741210313808, 'step': 3766500}
INFO:transformers.trainer:{'loss': 3.1611798107624054, 'learning_rate': 3.869226375536435e-05, 'epoch': 0.6784641746781392, 'step': 3767000}
INFO:transformers.trainer:{'loss': 3.149965695858002, 'learning_rate': 3.8690762861251705e-05, 'epoch': 0.6785542283248978, 'step': 3767500}
INFO:transformers.trainer:{'loss': 3.133970686197281, 'learning_rate': 3.868926196713907e-05, 'epoch': 0.6786442819716562, 'step': 3768000}
INFO:transformers.trainer:{'loss': 3.140991129398346, 'learning_rate': 3.868776107302642e-05, 'epoch': 0.6787343356184146, 'step': 3768500}
INFO:transformers.trainer:{'loss': 3.1452169063091278, 'learning_rate': 3.868626017891379e-05, 'epoch': 0.6788243892651731, 'step': 3769000}
INFO:transformers.trainer:{'loss': 3.1681681714057923, 'learning_rate': 3.868475928480114e-05, 'epoch': 0.6789144429119315, 'step': 3769500}
INFO:transformers.trainer:{'loss': 3.1322589993476866, 'learning_rate': 3.868325839068851e-05, 'epoch': 0.67900449655869, 'step': 3770000}
INFO:transformers.trainer:{'loss': 3.1652544639110567, 'learning_rate': 3.868175749657586e-05, 'epoch': 0.6790945502054484, 'step': 3770500}
INFO:transformers.trainer:{'loss': 3.1151994433403014, 'learning_rate': 3.8680256602463225e-05, 'epoch': 0.6791846038522068, 'step': 3771000}
INFO:transformers.trainer:{'loss': 3.0320731122493743, 'learning_rate': 3.867875570835058e-05, 'epoch': 0.6792746574989653, 'step': 3771500}
INFO:transformers.trainer:{'loss': 3.1097415207624435, 'learning_rate': 3.867725481423794e-05, 'epoch': 0.6793647111457237, 'step': 3772000}
INFO:transformers.trainer:{'loss': 3.1013229126930235, 'learning_rate': 3.86757539201253e-05, 'epoch': 0.6794547647924821, 'step': 3772500}
INFO:transformers.trainer:{'loss': 3.0890142916440966, 'learning_rate': 3.867425302601266e-05, 'epoch': 0.6795448184392406, 'step': 3773000}
INFO:transformers.trainer:{'loss': 3.101994216442108, 'learning_rate': 3.867275213190002e-05, 'epoch': 0.679634872085999, 'step': 3773500}
INFO:transformers.trainer:{'loss': 3.227408855676651, 'learning_rate': 3.867125123778738e-05, 'epoch': 0.6797249257327576, 'step': 3774000}
INFO:transformers.trainer:{'loss': 3.156430356025696, 'learning_rate': 3.866975034367474e-05, 'epoch': 0.679814979379516, 'step': 3774500}
INFO:transformers.trainer:{'loss': 3.149804083108902, 'learning_rate': 3.86682494495621e-05, 'epoch': 0.6799050330262744, 'step': 3775000}
INFO:transformers.trainer:{'loss': 3.177759426355362, 'learning_rate': 3.8666748555449456e-05, 'epoch': 0.6799950866730329, 'step': 3775500}
INFO:transformers.trainer:{'loss': 3.1896194369792936, 'learning_rate': 3.866524766133681e-05, 'epoch': 0.6800851403197913, 'step': 3776000}
INFO:transformers.trainer:{'loss': 3.186329011917114, 'learning_rate': 3.8663746767224174e-05, 'epoch': 0.6801751939665498, 'step': 3776500}
INFO:transformers.trainer:{'loss': 3.101930339694023, 'learning_rate': 3.866224587311153e-05, 'epoch': 0.6802652476133082, 'step': 3777000}
INFO:transformers.trainer:{'loss': 3.2202173242568968, 'learning_rate': 3.866074497899889e-05, 'epoch': 0.6803553012600666, 'step': 3777500}
INFO:transformers.trainer:{'loss': 3.2144697945117953, 'learning_rate': 3.8659244084886245e-05, 'epoch': 0.6804453549068251, 'step': 3778000}
INFO:transformers.trainer:{'loss': 3.138071588754654, 'learning_rate': 3.865774319077361e-05, 'epoch': 0.6805354085535835, 'step': 3778500}
INFO:transformers.trainer:{'loss': 3.182809762239456, 'learning_rate': 3.865624229666096e-05, 'epoch': 0.680625462200342, 'step': 3779000}
INFO:transformers.trainer:{'loss': 3.156374227285385, 'learning_rate': 3.865474140254833e-05, 'epoch': 0.6807155158471004, 'step': 3779500}
INFO:transformers.trainer:{'loss': 3.182230603694916, 'learning_rate': 3.865324050843569e-05, 'epoch': 0.6808055694938588, 'step': 3780000}
INFO:transformers.trainer:{'loss': 3.1555230157375336, 'learning_rate': 3.865173961432305e-05, 'epoch': 0.6808956231406174, 'step': 3780500}
INFO:transformers.trainer:{'loss': 3.1733611328601836, 'learning_rate': 3.8650238720210406e-05, 'epoch': 0.6809856767873758, 'step': 3781000}
INFO:transformers.trainer:{'loss': 3.208649791717529, 'learning_rate': 3.8648737826097765e-05, 'epoch': 0.6810757304341343, 'step': 3781500}
INFO:transformers.trainer:{'loss': 3.1751594426631926, 'learning_rate': 3.8647236931985124e-05, 'epoch': 0.6811657840808927, 'step': 3782000}
INFO:transformers.trainer:{'loss': 3.158229500770569, 'learning_rate': 3.864573603787248e-05, 'epoch': 0.6812558377276511, 'step': 3782500}
INFO:transformers.trainer:{'loss': 3.1729275600910185, 'learning_rate': 3.864423514375984e-05, 'epoch': 0.6813458913744096, 'step': 3783000}
INFO:transformers.trainer:{'loss': 3.162454083442688, 'learning_rate': 3.86427342496472e-05, 'epoch': 0.681435945021168, 'step': 3783500}
INFO:transformers.trainer:{'loss': 3.1328374297618864, 'learning_rate': 3.864123335553456e-05, 'epoch': 0.6815259986679264, 'step': 3784000}
INFO:transformers.trainer:{'loss': 3.181675887823105, 'learning_rate': 3.863973246142192e-05, 'epoch': 0.6816160523146849, 'step': 3784500}
INFO:transformers.trainer:{'loss': 3.1557420246601104, 'learning_rate': 3.863823156730928e-05, 'epoch': 0.6817061059614433, 'step': 3785000}
INFO:transformers.trainer:{'loss': 3.2209343585968018, 'learning_rate': 3.863673067319664e-05, 'epoch': 0.6817961596082018, 'step': 3785500}
INFO:transformers.trainer:{'loss': 3.1563804668188093, 'learning_rate': 3.8635229779083996e-05, 'epoch': 0.6818862132549602, 'step': 3786000}
INFO:transformers.trainer:{'loss': 3.2301810274124145, 'learning_rate': 3.863372888497136e-05, 'epoch': 0.6819762669017186, 'step': 3786500}
INFO:transformers.trainer:{'loss': 3.1631919932365418, 'learning_rate': 3.8632227990858715e-05, 'epoch': 0.6820663205484772, 'step': 3787000}
INFO:transformers.trainer:{'loss': 3.159191834926605, 'learning_rate': 3.863072709674608e-05, 'epoch': 0.6821563741952356, 'step': 3787500}
INFO:transformers.trainer:{'loss': 3.1143828783035277, 'learning_rate': 3.862922620263343e-05, 'epoch': 0.6822464278419941, 'step': 3788000}
INFO:transformers.trainer:{'loss': 3.15375560426712, 'learning_rate': 3.86277253085208e-05, 'epoch': 0.6823364814887525, 'step': 3788500}
INFO:transformers.trainer:{'loss': 3.1237127156853677, 'learning_rate': 3.862622441440815e-05, 'epoch': 0.6824265351355109, 'step': 3789000}
INFO:transformers.trainer:{'loss': 3.2187411847114564, 'learning_rate': 3.8624723520295517e-05, 'epoch': 0.6825165887822694, 'step': 3789500}
INFO:transformers.trainer:{'loss': 3.183673238635063, 'learning_rate': 3.862322262618287e-05, 'epoch': 0.6826066424290278, 'step': 3790000}
INFO:transformers.trainer:{'loss': 3.182022212743759, 'learning_rate': 3.8621721732070235e-05, 'epoch': 0.6826966960757863, 'step': 3790500}
INFO:transformers.trainer:{'loss': 3.2369870884418486, 'learning_rate': 3.862022083795759e-05, 'epoch': 0.6827867497225447, 'step': 3791000}
INFO:transformers.trainer:{'loss': 3.2013087329864502, 'learning_rate': 3.861871994384495e-05, 'epoch': 0.6828768033693031, 'step': 3791500}
INFO:transformers.trainer:{'loss': 3.1027847685813903, 'learning_rate': 3.8617219049732305e-05, 'epoch': 0.6829668570160616, 'step': 3792000}
INFO:transformers.trainer:{'loss': 3.146037225484848, 'learning_rate': 3.861571815561967e-05, 'epoch': 0.68305691066282, 'step': 3792500}
INFO:transformers.trainer:{'loss': 3.1870103461742403, 'learning_rate': 3.861421726150702e-05, 'epoch': 0.6831469643095786, 'step': 3793000}
INFO:transformers.trainer:{'loss': 3.049997076034546, 'learning_rate': 3.861271636739439e-05, 'epoch': 0.683237017956337, 'step': 3793500}
INFO:transformers.trainer:{'loss': 3.1949760410785677, 'learning_rate': 3.861121547328175e-05, 'epoch': 0.6833270716030954, 'step': 3794000}
INFO:transformers.trainer:{'loss': 3.1565830451250076, 'learning_rate': 3.860971457916911e-05, 'epoch': 0.6834171252498539, 'step': 3794500}
INFO:transformers.trainer:{'loss': 3.1326919941902163, 'learning_rate': 3.8608213685056466e-05, 'epoch': 0.6835071788966123, 'step': 3795000}
INFO:transformers.trainer:{'loss': 3.1829896252155305, 'learning_rate': 3.8606712790943825e-05, 'epoch': 0.6835972325433708, 'step': 3795500}
INFO:transformers.trainer:{'loss': 3.194401972413063, 'learning_rate': 3.8605211896831184e-05, 'epoch': 0.6836872861901292, 'step': 3796000}
INFO:transformers.trainer:{'loss': 3.1044159660339354, 'learning_rate': 3.860371100271854e-05, 'epoch': 0.6837773398368876, 'step': 3796500}
INFO:transformers.trainer:{'loss': 3.1150271801948546, 'learning_rate': 3.86022101086059e-05, 'epoch': 0.6838673934836461, 'step': 3797000}
INFO:transformers.trainer:{'loss': 3.2407492852210997, 'learning_rate': 3.860070921449326e-05, 'epoch': 0.6839574471304045, 'step': 3797500}
INFO:transformers.trainer:{'loss': 3.4861532118320464, 'learning_rate': 3.859920832038062e-05, 'epoch': 0.6840475007771629, 'step': 3798000}
INFO:transformers.trainer:{'loss': 4.270584719657898, 'learning_rate': 3.859770742626798e-05, 'epoch': 0.6841375544239214, 'step': 3798500}
INFO:transformers.trainer:{'loss': 4.261669596672058, 'learning_rate': 3.859620653215534e-05, 'epoch': 0.6842276080706798, 'step': 3799000}
INFO:transformers.trainer:{'loss': 3.5813138103485107, 'learning_rate': 3.859470563804269e-05, 'epoch': 0.6843176617174384, 'step': 3799500}
INFO:transformers.trainer:{'loss': 3.487243702173233, 'learning_rate': 3.8593204743930057e-05, 'epoch': 0.6844077153641968, 'step': 3800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.4224159381389616, 'learning_rate': 3.8591703849817416e-05, 'epoch': 0.6844977690109552, 'step': 3800500}
INFO:transformers.trainer:{'loss': 3.2795107629299163, 'learning_rate': 3.8590202955704775e-05, 'epoch': 0.6845878226577137, 'step': 3801000}
INFO:transformers.trainer:{'loss': 3.357167123556137, 'learning_rate': 3.8588702061592134e-05, 'epoch': 0.6846778763044721, 'step': 3801500}
INFO:transformers.trainer:{'loss': 4.214460353851319, 'learning_rate': 3.858720116747949e-05, 'epoch': 0.6847679299512306, 'step': 3802000}
INFO:transformers.trainer:{'loss': 3.594534736633301, 'learning_rate': 3.858570027336685e-05, 'epoch': 0.684857983597989, 'step': 3802500}
INFO:transformers.trainer:{'loss': 4.40786078453064, 'learning_rate': 3.858419937925421e-05, 'epoch': 0.6849480372447474, 'step': 3803000}
INFO:transformers.trainer:{'loss': 4.21008633351326, 'learning_rate': 3.858269848514157e-05, 'epoch': 0.6850380908915059, 'step': 3803500}
INFO:transformers.trainer:{'loss': 3.8263344347476957, 'learning_rate': 3.858119759102893e-05, 'epoch': 0.6851281445382643, 'step': 3804000}
INFO:transformers.trainer:{'loss': 3.9164271805286406, 'learning_rate': 3.857969669691629e-05, 'epoch': 0.6852181981850228, 'step': 3804500}
INFO:transformers.trainer:{'loss': 3.9591280632019044, 'learning_rate': 3.857819580280365e-05, 'epoch': 0.6853082518317812, 'step': 3805000}
INFO:transformers.trainer:{'loss': 4.073811890363693, 'learning_rate': 3.8576694908691006e-05, 'epoch': 0.6853983054785396, 'step': 3805500}
INFO:transformers.trainer:{'loss': 3.981794737815857, 'learning_rate': 3.8575194014578365e-05, 'epoch': 0.6854883591252982, 'step': 3806000}
INFO:transformers.trainer:{'loss': 3.7015141990184786, 'learning_rate': 3.8573693120465724e-05, 'epoch': 0.6855784127720566, 'step': 3806500}
INFO:transformers.trainer:{'loss': 3.6689664833545685, 'learning_rate': 3.857219222635308e-05, 'epoch': 0.6856684664188151, 'step': 3807000}
INFO:transformers.trainer:{'loss': 4.549321027755737, 'learning_rate': 3.857069133224044e-05, 'epoch': 0.6857585200655735, 'step': 3807500}
INFO:transformers.trainer:{'loss': 4.267556630373001, 'learning_rate': 3.856919043812781e-05, 'epoch': 0.6858485737123319, 'step': 3808000}
INFO:transformers.trainer:{'loss': 4.66977392244339, 'learning_rate': 3.856768954401516e-05, 'epoch': 0.6859386273590904, 'step': 3808500}
INFO:transformers.trainer:{'loss': 4.637966275930404, 'learning_rate': 3.8566188649902526e-05, 'epoch': 0.6860286810058488, 'step': 3809000}
INFO:transformers.trainer:{'loss': 4.173046081542969, 'learning_rate': 3.856468775578988e-05, 'epoch': 0.6861187346526072, 'step': 3809500}
INFO:transformers.trainer:{'loss': 4.916459544658661, 'learning_rate': 3.8563186861677244e-05, 'epoch': 0.6862087882993657, 'step': 3810000}
INFO:transformers.trainer:{'loss': 4.58859951877594, 'learning_rate': 3.85616859675646e-05, 'epoch': 0.6862988419461241, 'step': 3810500}
INFO:transformers.trainer:{'loss': 4.1785839314460755, 'learning_rate': 3.856018507345196e-05, 'epoch': 0.6863888955928826, 'step': 3811000}
INFO:transformers.trainer:{'loss': 4.188404521226883, 'learning_rate': 3.8558684179339315e-05, 'epoch': 0.686478949239641, 'step': 3811500}
INFO:transformers.trainer:{'loss': 4.084097262859345, 'learning_rate': 3.855718328522668e-05, 'epoch': 0.6865690028863994, 'step': 3812000}
INFO:transformers.trainer:{'loss': 4.039463382959366, 'learning_rate': 3.855568239111403e-05, 'epoch': 0.686659056533158, 'step': 3812500}
INFO:transformers.trainer:{'loss': 4.3560367999076846, 'learning_rate': 3.85541814970014e-05, 'epoch': 0.6867491101799164, 'step': 3813000}
INFO:transformers.trainer:{'loss': 4.069147287845611, 'learning_rate': 3.855268060288875e-05, 'epoch': 0.6868391638266749, 'step': 3813500}
INFO:transformers.trainer:{'loss': 4.058764686346054, 'learning_rate': 3.855117970877612e-05, 'epoch': 0.6869292174734333, 'step': 3814000}
INFO:transformers.trainer:{'loss': 4.446385826349259, 'learning_rate': 3.8549678814663476e-05, 'epoch': 0.6870192711201917, 'step': 3814500}
INFO:transformers.trainer:{'loss': 4.229347160100937, 'learning_rate': 3.8548177920550835e-05, 'epoch': 0.6871093247669502, 'step': 3815000}
INFO:transformers.trainer:{'loss': 4.682123969554901, 'learning_rate': 3.8546677026438194e-05, 'epoch': 0.6871993784137086, 'step': 3815500}
INFO:transformers.trainer:{'loss': 4.575344074726105, 'learning_rate': 3.854517613232555e-05, 'epoch': 0.6872894320604671, 'step': 3816000}
INFO:transformers.trainer:{'loss': 4.890722331523896, 'learning_rate': 3.854367523821291e-05, 'epoch': 0.6873794857072255, 'step': 3816500}
INFO:transformers.trainer:{'loss': 4.683886847496033, 'learning_rate': 3.854217434410027e-05, 'epoch': 0.6874695393539839, 'step': 3817000}
INFO:transformers.trainer:{'loss': 4.814857507705688, 'learning_rate': 3.854067344998763e-05, 'epoch': 0.6875595930007424, 'step': 3817500}
INFO:transformers.trainer:{'loss': 4.633641578435898, 'learning_rate': 3.853917255587499e-05, 'epoch': 0.6876496466475008, 'step': 3818000}
INFO:transformers.trainer:{'loss': 4.498546289205551, 'learning_rate': 3.853767166176235e-05, 'epoch': 0.6877397002942593, 'step': 3818500}
INFO:transformers.trainer:{'loss': 4.675738992214203, 'learning_rate': 3.853617076764971e-05, 'epoch': 0.6878297539410178, 'step': 3819000}
INFO:transformers.trainer:{'loss': 4.805770293235779, 'learning_rate': 3.8534669873537066e-05, 'epoch': 0.6879198075877762, 'step': 3819500}
INFO:transformers.trainer:{'loss': 4.749888311386108, 'learning_rate': 3.8533168979424425e-05, 'epoch': 0.6880098612345347, 'step': 3820000}
INFO:transformers.trainer:{'loss': 4.284107985496521, 'learning_rate': 3.8531668085311784e-05, 'epoch': 0.6880999148812931, 'step': 3820500}
INFO:transformers.trainer:{'loss': 4.681476221084595, 'learning_rate': 3.8530167191199143e-05, 'epoch': 0.6881899685280515, 'step': 3821000}
INFO:transformers.trainer:{'loss': 4.674512338638306, 'learning_rate': 3.85286662970865e-05, 'epoch': 0.68828002217481, 'step': 3821500}
INFO:transformers.trainer:{'loss': 4.699013299942017, 'learning_rate': 3.852716540297386e-05, 'epoch': 0.6883700758215684, 'step': 3822000}
INFO:transformers.trainer:{'loss': 4.701871893405914, 'learning_rate': 3.852566450886122e-05, 'epoch': 0.6884601294683269, 'step': 3822500}
INFO:transformers.trainer:{'loss': 4.750000300884246, 'learning_rate': 3.852416361474858e-05, 'epoch': 0.6885501831150853, 'step': 3823000}
INFO:transformers.trainer:{'loss': 4.712078598022461, 'learning_rate': 3.852266272063594e-05, 'epoch': 0.6886402367618437, 'step': 3823500}
INFO:transformers.trainer:{'loss': 4.809114789962768, 'learning_rate': 3.85211618265233e-05, 'epoch': 0.6887302904086022, 'step': 3824000}
INFO:transformers.trainer:{'loss': 4.816608705043793, 'learning_rate': 3.851966093241066e-05, 'epoch': 0.6888203440553606, 'step': 3824500}
INFO:transformers.trainer:{'loss': 4.659496921539307, 'learning_rate': 3.8518160038298016e-05, 'epoch': 0.6889103977021191, 'step': 3825000}
INFO:transformers.trainer:{'loss': 4.1978089210987095, 'learning_rate': 3.8516659144185375e-05, 'epoch': 0.6890004513488776, 'step': 3825500}
INFO:transformers.trainer:{'loss': 4.598211769580841, 'learning_rate': 3.8515158250072734e-05, 'epoch': 0.689090504995636, 'step': 3826000}
INFO:transformers.trainer:{'loss': 4.530527586936951, 'learning_rate': 3.851365735596009e-05, 'epoch': 0.6891805586423945, 'step': 3826500}
INFO:transformers.trainer:{'loss': 4.685287986278534, 'learning_rate': 3.851215646184745e-05, 'epoch': 0.6892706122891529, 'step': 3827000}
INFO:transformers.trainer:{'loss': 4.770178821563721, 'learning_rate': 3.851065556773481e-05, 'epoch': 0.6893606659359114, 'step': 3827500}
INFO:transformers.trainer:{'loss': 4.513310336112976, 'learning_rate': 3.850915467362217e-05, 'epoch': 0.6894507195826698, 'step': 3828000}
INFO:transformers.trainer:{'loss': 4.7092312049865725, 'learning_rate': 3.8507653779509536e-05, 'epoch': 0.6895407732294282, 'step': 3828500}
INFO:transformers.trainer:{'loss': 4.646867933034897, 'learning_rate': 3.850615288539689e-05, 'epoch': 0.6896308268761867, 'step': 3829000}
INFO:transformers.trainer:{'loss': 4.346755744218826, 'learning_rate': 3.8504651991284254e-05, 'epoch': 0.6897208805229451, 'step': 3829500}
INFO:transformers.trainer:{'loss': 4.345610802173614, 'learning_rate': 3.8503151097171606e-05, 'epoch': 0.6898109341697036, 'step': 3830000}
INFO:transformers.trainer:{'loss': 4.4496493148803715, 'learning_rate': 3.850165020305897e-05, 'epoch': 0.689900987816462, 'step': 3830500}
INFO:transformers.trainer:{'loss': 4.7010947365760805, 'learning_rate': 3.8500149308946324e-05, 'epoch': 0.6899910414632204, 'step': 3831000}
INFO:transformers.trainer:{'loss': 4.912082184314728, 'learning_rate': 3.849864841483369e-05, 'epoch': 0.690081095109979, 'step': 3831500}
INFO:transformers.trainer:{'loss': 4.654121131420135, 'learning_rate': 3.849714752072104e-05, 'epoch': 0.6901711487567374, 'step': 3832000}
INFO:transformers.trainer:{'loss': 4.616036148548126, 'learning_rate': 3.849564662660841e-05, 'epoch': 0.6902612024034959, 'step': 3832500}
INFO:transformers.trainer:{'loss': 4.8920190811157225, 'learning_rate': 3.849414573249576e-05, 'epoch': 0.6903512560502543, 'step': 3833000}
INFO:transformers.trainer:{'loss': 4.862021909713745, 'learning_rate': 3.8492644838383126e-05, 'epoch': 0.6904413096970127, 'step': 3833500}
INFO:transformers.trainer:{'loss': 4.812290402889252, 'learning_rate': 3.849114394427048e-05, 'epoch': 0.6905313633437712, 'step': 3834000}
INFO:transformers.trainer:{'loss': 4.906180966854095, 'learning_rate': 3.8489643050157845e-05, 'epoch': 0.6906214169905296, 'step': 3834500}
INFO:transformers.trainer:{'loss': 4.99872811794281, 'learning_rate': 3.8488142156045204e-05, 'epoch': 0.690711470637288, 'step': 3835000}
INFO:transformers.trainer:{'loss': 4.997415315628052, 'learning_rate': 3.848664126193256e-05, 'epoch': 0.6908015242840465, 'step': 3835500}
INFO:transformers.trainer:{'loss': 4.877088066577912, 'learning_rate': 3.848514036781992e-05, 'epoch': 0.6908915779308049, 'step': 3836000}
INFO:transformers.trainer:{'loss': 4.9028799700737, 'learning_rate': 3.848363947370728e-05, 'epoch': 0.6909816315775634, 'step': 3836500}
INFO:transformers.trainer:{'loss': 4.82648569393158, 'learning_rate': 3.848213857959464e-05, 'epoch': 0.6910716852243218, 'step': 3837000}
INFO:transformers.trainer:{'loss': 4.910671638965606, 'learning_rate': 3.8480637685482e-05, 'epoch': 0.6911617388710802, 'step': 3837500}
INFO:transformers.trainer:{'loss': 4.893773144245148, 'learning_rate': 3.847913679136936e-05, 'epoch': 0.6912517925178387, 'step': 3838000}
INFO:transformers.trainer:{'loss': 4.725334441184997, 'learning_rate': 3.847763589725672e-05, 'epoch': 0.6913418461645972, 'step': 3838500}
INFO:transformers.trainer:{'loss': 4.798020783901214, 'learning_rate': 3.8476135003144076e-05, 'epoch': 0.6914318998113557, 'step': 3839000}
INFO:transformers.trainer:{'loss': 4.913717383146286, 'learning_rate': 3.8474634109031435e-05, 'epoch': 0.6915219534581141, 'step': 3839500}
INFO:transformers.trainer:{'loss': 4.839423846244812, 'learning_rate': 3.8473133214918794e-05, 'epoch': 0.6916120071048725, 'step': 3840000}
INFO:transformers.trainer:{'loss': 4.887073506832123, 'learning_rate': 3.847163232080615e-05, 'epoch': 0.691702060751631, 'step': 3840500}
INFO:transformers.trainer:{'loss': 4.754841571807861, 'learning_rate': 3.847013142669351e-05, 'epoch': 0.6917921143983894, 'step': 3841000}
INFO:transformers.trainer:{'loss': 4.579362544059753, 'learning_rate': 3.846863053258087e-05, 'epoch': 0.6918821680451479, 'step': 3841500}
INFO:transformers.trainer:{'loss': 4.810551105260849, 'learning_rate': 3.846712963846823e-05, 'epoch': 0.6919722216919063, 'step': 3842000}
INFO:transformers.trainer:{'loss': 4.994654357433319, 'learning_rate': 3.846562874435559e-05, 'epoch': 0.6920622753386647, 'step': 3842500}
INFO:transformers.trainer:{'loss': 4.993088949203491, 'learning_rate': 3.846412785024295e-05, 'epoch': 0.6921523289854232, 'step': 3843000}
INFO:transformers.trainer:{'loss': 4.888879106998443, 'learning_rate': 3.846262695613031e-05, 'epoch': 0.6922423826321816, 'step': 3843500}
INFO:transformers.trainer:{'loss': 4.855804424285889, 'learning_rate': 3.8461126062017667e-05, 'epoch': 0.6923324362789401, 'step': 3844000}
INFO:transformers.trainer:{'loss': 4.834397424221039, 'learning_rate': 3.8459625167905026e-05, 'epoch': 0.6924224899256985, 'step': 3844500}
INFO:transformers.trainer:{'loss': 4.92611213684082, 'learning_rate': 3.8458124273792385e-05, 'epoch': 0.692512543572457, 'step': 3845000}
INFO:transformers.trainer:{'loss': 4.925978141784668, 'learning_rate': 3.8456623379679744e-05, 'epoch': 0.6926025972192155, 'step': 3845500}
INFO:transformers.trainer:{'loss': 5.001615594387054, 'learning_rate': 3.84551224855671e-05, 'epoch': 0.6926926508659739, 'step': 3846000}
INFO:transformers.trainer:{'loss': 5.021662399291992, 'learning_rate': 3.845362159145446e-05, 'epoch': 0.6927827045127323, 'step': 3846500}
INFO:transformers.trainer:{'loss': 5.025707295894623, 'learning_rate': 3.845212069734182e-05, 'epoch': 0.6928727581594908, 'step': 3847000}
INFO:transformers.trainer:{'loss': 4.8556771564483645, 'learning_rate': 3.845061980322918e-05, 'epoch': 0.6929628118062492, 'step': 3847500}
INFO:transformers.trainer:{'loss': 4.933414929389953, 'learning_rate': 3.844911890911654e-05, 'epoch': 0.6930528654530077, 'step': 3848000}
INFO:transformers.trainer:{'loss': 4.83269248008728, 'learning_rate': 3.84476180150039e-05, 'epoch': 0.6931429190997661, 'step': 3848500}
INFO:transformers.trainer:{'loss': 4.948252567768097, 'learning_rate': 3.8446117120891264e-05, 'epoch': 0.6932329727465245, 'step': 3849000}
INFO:transformers.trainer:{'loss': 4.978509033679962, 'learning_rate': 3.8444616226778616e-05, 'epoch': 0.693323026393283, 'step': 3849500}
INFO:transformers.trainer:{'loss': 4.919403367042541, 'learning_rate': 3.844311533266598e-05, 'epoch': 0.6934130800400414, 'step': 3850000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3850000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3850000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3850000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3750000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.93275890827179, 'learning_rate': 3.8441614438553334e-05, 'epoch': 0.6935031336867999, 'step': 3850500}
INFO:transformers.trainer:{'loss': 4.795143754482269, 'learning_rate': 3.84401135444407e-05, 'epoch': 0.6935931873335583, 'step': 3851000}
INFO:transformers.trainer:{'loss': 4.575995315551758, 'learning_rate': 3.843861265032805e-05, 'epoch': 0.6936832409803168, 'step': 3851500}
INFO:transformers.trainer:{'loss': 4.908985424995422, 'learning_rate': 3.843711175621542e-05, 'epoch': 0.6937732946270753, 'step': 3852000}
INFO:transformers.trainer:{'loss': 4.815840393066407, 'learning_rate': 3.843561086210277e-05, 'epoch': 0.6938633482738337, 'step': 3852500}
INFO:transformers.trainer:{'loss': 4.922861122131348, 'learning_rate': 3.8434109967990136e-05, 'epoch': 0.6939534019205922, 'step': 3853000}
INFO:transformers.trainer:{'loss': 4.819098601341247, 'learning_rate': 3.843260907387749e-05, 'epoch': 0.6940434555673506, 'step': 3853500}
INFO:transformers.trainer:{'loss': 4.843796615362168, 'learning_rate': 3.8431108179764854e-05, 'epoch': 0.694133509214109, 'step': 3854000}
INFO:transformers.trainer:{'loss': 4.870040284156799, 'learning_rate': 3.8429607285652207e-05, 'epoch': 0.6942235628608675, 'step': 3854500}
INFO:transformers.trainer:{'loss': 4.569181502819061, 'learning_rate': 3.842810639153957e-05, 'epoch': 0.6943136165076259, 'step': 3855000}
INFO:transformers.trainer:{'loss': 4.444569993972778, 'learning_rate': 3.8426605497426925e-05, 'epoch': 0.6944036701543844, 'step': 3855500}
INFO:transformers.trainer:{'loss': 4.895186514854431, 'learning_rate': 3.842510460331429e-05, 'epoch': 0.6944937238011428, 'step': 3856000}
INFO:transformers.trainer:{'loss': 4.723249053955078, 'learning_rate': 3.842360370920165e-05, 'epoch': 0.6945837774479012, 'step': 3856500}
INFO:transformers.trainer:{'loss': 4.97175269985199, 'learning_rate': 3.842210281508901e-05, 'epoch': 0.6946738310946597, 'step': 3857000}
INFO:transformers.trainer:{'loss': 5.027045130729675, 'learning_rate': 3.842060192097637e-05, 'epoch': 0.6947638847414181, 'step': 3857500}
INFO:transformers.trainer:{'loss': 4.739102155208587, 'learning_rate': 3.841910102686373e-05, 'epoch': 0.6948539383881766, 'step': 3858000}
INFO:transformers.trainer:{'loss': 4.9178462972640995, 'learning_rate': 3.8417600132751086e-05, 'epoch': 0.6949439920349351, 'step': 3858500}
INFO:transformers.trainer:{'loss': 4.826866357803345, 'learning_rate': 3.8416099238638445e-05, 'epoch': 0.6950340456816935, 'step': 3859000}
INFO:transformers.trainer:{'loss': 4.878793086528778, 'learning_rate': 3.8414598344525804e-05, 'epoch': 0.695124099328452, 'step': 3859500}
INFO:transformers.trainer:{'loss': 4.878054045200348, 'learning_rate': 3.841309745041316e-05, 'epoch': 0.6952141529752104, 'step': 3860000}
INFO:transformers.trainer:{'loss': 4.746172046661377, 'learning_rate': 3.841159655630052e-05, 'epoch': 0.6953042066219688, 'step': 3860500}
INFO:transformers.trainer:{'loss': 4.8667498097419735, 'learning_rate': 3.841009566218788e-05, 'epoch': 0.6953942602687273, 'step': 3861000}
INFO:transformers.trainer:{'loss': 4.7885577864646915, 'learning_rate': 3.840859476807524e-05, 'epoch': 0.6954843139154857, 'step': 3861500}
INFO:transformers.trainer:{'loss': 4.988178613662719, 'learning_rate': 3.84070938739626e-05, 'epoch': 0.6955743675622442, 'step': 3862000}
INFO:transformers.trainer:{'loss': 5.016407615184784, 'learning_rate': 3.840559297984996e-05, 'epoch': 0.6956644212090026, 'step': 3862500}
INFO:transformers.trainer:{'loss': 5.031937229633331, 'learning_rate': 3.840409208573732e-05, 'epoch': 0.695754474855761, 'step': 3863000}
INFO:transformers.trainer:{'loss': 4.959345186948776, 'learning_rate': 3.8402591191624676e-05, 'epoch': 0.6958445285025195, 'step': 3863500}
INFO:transformers.trainer:{'loss': 4.939464200019836, 'learning_rate': 3.8401090297512035e-05, 'epoch': 0.695934582149278, 'step': 3864000}
INFO:transformers.trainer:{'loss': 4.946968444824218, 'learning_rate': 3.8399589403399394e-05, 'epoch': 0.6960246357960365, 'step': 3864500}
INFO:transformers.trainer:{'loss': 5.005115996360779, 'learning_rate': 3.8398088509286753e-05, 'epoch': 0.6961146894427949, 'step': 3865000}
INFO:transformers.trainer:{'loss': 4.895175274372101, 'learning_rate': 3.839658761517411e-05, 'epoch': 0.6962047430895533, 'step': 3865500}
INFO:transformers.trainer:{'loss': 4.859632914066315, 'learning_rate': 3.839508672106147e-05, 'epoch': 0.6962947967363118, 'step': 3866000}
INFO:transformers.trainer:{'loss': 4.946847111225128, 'learning_rate': 3.839358582694883e-05, 'epoch': 0.6963848503830702, 'step': 3866500}
INFO:transformers.trainer:{'loss': 4.9223161413669585, 'learning_rate': 3.839208493283619e-05, 'epoch': 0.6964749040298287, 'step': 3867000}
INFO:transformers.trainer:{'loss': 4.98244593667984, 'learning_rate': 3.839058403872355e-05, 'epoch': 0.6965649576765871, 'step': 3867500}
INFO:transformers.trainer:{'loss': 4.940280267238617, 'learning_rate': 3.838908314461091e-05, 'epoch': 0.6966550113233455, 'step': 3868000}
INFO:transformers.trainer:{'loss': 4.858141115665436, 'learning_rate': 3.838758225049827e-05, 'epoch': 0.696745064970104, 'step': 3868500}
INFO:transformers.trainer:{'loss': 4.911011846542358, 'learning_rate': 3.8386081356385626e-05, 'epoch': 0.6968351186168624, 'step': 3869000}
INFO:transformers.trainer:{'loss': 4.897323446512222, 'learning_rate': 3.838458046227299e-05, 'epoch': 0.6969251722636208, 'step': 3869500}
INFO:transformers.trainer:{'loss': 4.850313884735107, 'learning_rate': 3.8383079568160344e-05, 'epoch': 0.6970152259103793, 'step': 3870000}
INFO:transformers.trainer:{'loss': 4.899693281173706, 'learning_rate': 3.838157867404771e-05, 'epoch': 0.6971052795571377, 'step': 3870500}
INFO:transformers.trainer:{'loss': 4.806450251579284, 'learning_rate': 3.838007777993506e-05, 'epoch': 0.6971953332038963, 'step': 3871000}
INFO:transformers.trainer:{'loss': 4.9229505958557125, 'learning_rate': 3.837857688582243e-05, 'epoch': 0.6972853868506547, 'step': 3871500}
INFO:transformers.trainer:{'loss': 4.887639386177063, 'learning_rate': 3.837707599170978e-05, 'epoch': 0.6973754404974131, 'step': 3872000}
INFO:transformers.trainer:{'loss': 4.548320434093475, 'learning_rate': 3.8375575097597146e-05, 'epoch': 0.6974654941441716, 'step': 3872500}
INFO:transformers.trainer:{'loss': 4.871093357563018, 'learning_rate': 3.83740742034845e-05, 'epoch': 0.69755554779093, 'step': 3873000}
INFO:transformers.trainer:{'loss': 4.87613085269928, 'learning_rate': 3.8372573309371864e-05, 'epoch': 0.6976456014376885, 'step': 3873500}
INFO:transformers.trainer:{'loss': 4.880562083721161, 'learning_rate': 3.8371072415259216e-05, 'epoch': 0.6977356550844469, 'step': 3874000}
INFO:transformers.trainer:{'loss': 4.890867005825043, 'learning_rate': 3.836957152114658e-05, 'epoch': 0.6978257087312053, 'step': 3874500}
INFO:transformers.trainer:{'loss': 4.844049985408783, 'learning_rate': 3.8368070627033934e-05, 'epoch': 0.6979157623779638, 'step': 3875000}
INFO:transformers.trainer:{'loss': 4.812505279541016, 'learning_rate': 3.83665697329213e-05, 'epoch': 0.6980058160247222, 'step': 3875500}
INFO:transformers.trainer:{'loss': 4.8340724949836735, 'learning_rate': 3.836506883880865e-05, 'epoch': 0.6980958696714807, 'step': 3876000}
INFO:transformers.trainer:{'loss': 4.796763936042786, 'learning_rate': 3.836356794469602e-05, 'epoch': 0.6981859233182391, 'step': 3876500}
INFO:transformers.trainer:{'loss': 4.81059411239624, 'learning_rate': 3.836206705058338e-05, 'epoch': 0.6982759769649975, 'step': 3877000}
INFO:transformers.trainer:{'loss': 4.762474056243897, 'learning_rate': 3.8360566156470736e-05, 'epoch': 0.6983660306117561, 'step': 3877500}
INFO:transformers.trainer:{'loss': 4.777670711040497, 'learning_rate': 3.8359065262358096e-05, 'epoch': 0.6984560842585145, 'step': 3878000}
INFO:transformers.trainer:{'loss': 4.870165500164032, 'learning_rate': 3.8357564368245455e-05, 'epoch': 0.698546137905273, 'step': 3878500}
INFO:transformers.trainer:{'loss': 4.9951920580863955, 'learning_rate': 3.8356063474132814e-05, 'epoch': 0.6986361915520314, 'step': 3879000}
INFO:transformers.trainer:{'loss': 4.856197749614716, 'learning_rate': 3.835456258002017e-05, 'epoch': 0.6987262451987898, 'step': 3879500}
INFO:transformers.trainer:{'loss': 4.878393414974212, 'learning_rate': 3.835306168590753e-05, 'epoch': 0.6988162988455483, 'step': 3880000}
INFO:transformers.trainer:{'loss': 4.736452248573303, 'learning_rate': 3.835156079179489e-05, 'epoch': 0.6989063524923067, 'step': 3880500}
INFO:transformers.trainer:{'loss': 4.788133180141449, 'learning_rate': 3.835005989768225e-05, 'epoch': 0.6989964061390652, 'step': 3881000}
INFO:transformers.trainer:{'loss': 4.834199145793915, 'learning_rate': 3.834855900356961e-05, 'epoch': 0.6990864597858236, 'step': 3881500}
INFO:transformers.trainer:{'loss': 4.959199091434479, 'learning_rate': 3.834705810945697e-05, 'epoch': 0.699176513432582, 'step': 3882000}
INFO:transformers.trainer:{'loss': 4.945518427848816, 'learning_rate': 3.834555721534433e-05, 'epoch': 0.6992665670793405, 'step': 3882500}
INFO:transformers.trainer:{'loss': 4.920778719902039, 'learning_rate': 3.8344056321231686e-05, 'epoch': 0.6993566207260989, 'step': 3883000}
INFO:transformers.trainer:{'loss': 4.906340592384338, 'learning_rate': 3.8342555427119045e-05, 'epoch': 0.6994466743728573, 'step': 3883500}
INFO:transformers.trainer:{'loss': 4.631252310752869, 'learning_rate': 3.8341054533006404e-05, 'epoch': 0.6995367280196159, 'step': 3884000}
INFO:transformers.trainer:{'loss': 4.723615261554718, 'learning_rate': 3.833955363889376e-05, 'epoch': 0.6996267816663743, 'step': 3884500}
INFO:transformers.trainer:{'loss': 4.94951299905777, 'learning_rate': 3.833805274478112e-05, 'epoch': 0.6997168353131328, 'step': 3885000}
INFO:transformers.trainer:{'loss': 4.836199376106262, 'learning_rate': 3.833655185066848e-05, 'epoch': 0.6998068889598912, 'step': 3885500}
INFO:transformers.trainer:{'loss': 4.480187250137329, 'learning_rate': 3.833505095655584e-05, 'epoch': 0.6998969426066496, 'step': 3886000}
INFO:transformers.trainer:{'loss': 4.710011260032654, 'learning_rate': 3.83335500624432e-05, 'epoch': 0.6999869962534081, 'step': 3886500}
INFO:transformers.trainer:{'loss': 4.789974392414093, 'learning_rate': 3.833204916833056e-05, 'epoch': 0.7000770499001665, 'step': 3887000}
INFO:transformers.trainer:{'loss': 4.690854098796844, 'learning_rate': 3.833054827421792e-05, 'epoch': 0.700167103546925, 'step': 3887500}
INFO:transformers.trainer:{'loss': 4.567447132349014, 'learning_rate': 3.8329047380105277e-05, 'epoch': 0.7002571571936834, 'step': 3888000}
INFO:transformers.trainer:{'loss': 4.7867216205596925, 'learning_rate': 3.8327546485992636e-05, 'epoch': 0.7003472108404418, 'step': 3888500}
INFO:transformers.trainer:{'loss': 4.783384717464447, 'learning_rate': 3.8326045591879995e-05, 'epoch': 0.7004372644872003, 'step': 3889000}
INFO:transformers.trainer:{'loss': 4.724027674198151, 'learning_rate': 3.8324544697767354e-05, 'epoch': 0.7005273181339587, 'step': 3889500}
INFO:transformers.trainer:{'loss': 4.797026154518128, 'learning_rate': 3.832304380365471e-05, 'epoch': 0.7006173717807173, 'step': 3890000}
INFO:transformers.trainer:{'loss': 4.779630568027496, 'learning_rate': 3.832154290954207e-05, 'epoch': 0.7007074254274757, 'step': 3890500}
INFO:transformers.trainer:{'loss': 4.737056994915009, 'learning_rate': 3.832004201542944e-05, 'epoch': 0.7007974790742341, 'step': 3891000}
INFO:transformers.trainer:{'loss': 4.752583858013153, 'learning_rate': 3.831854112131679e-05, 'epoch': 0.7008875327209926, 'step': 3891500}
INFO:transformers.trainer:{'loss': 4.798764164924622, 'learning_rate': 3.8317040227204156e-05, 'epoch': 0.700977586367751, 'step': 3892000}
INFO:transformers.trainer:{'loss': 4.829597921848297, 'learning_rate': 3.831553933309151e-05, 'epoch': 0.7010676400145095, 'step': 3892500}
INFO:transformers.trainer:{'loss': 4.784641275882721, 'learning_rate': 3.8314038438978874e-05, 'epoch': 0.7011576936612679, 'step': 3893000}
INFO:transformers.trainer:{'loss': 4.832213216304779, 'learning_rate': 3.8312537544866226e-05, 'epoch': 0.7012477473080263, 'step': 3893500}
INFO:transformers.trainer:{'loss': 4.737475230693817, 'learning_rate': 3.831103665075359e-05, 'epoch': 0.7013378009547848, 'step': 3894000}
INFO:transformers.trainer:{'loss': 4.854617494106293, 'learning_rate': 3.8309535756640944e-05, 'epoch': 0.7014278546015432, 'step': 3894500}
INFO:transformers.trainer:{'loss': 4.902647878170013, 'learning_rate': 3.830803486252831e-05, 'epoch': 0.7015179082483016, 'step': 3895000}
INFO:transformers.trainer:{'loss': 4.830493209838867, 'learning_rate': 3.830653396841566e-05, 'epoch': 0.7016079618950601, 'step': 3895500}
INFO:transformers.trainer:{'loss': 4.601891842365265, 'learning_rate': 3.830503307430303e-05, 'epoch': 0.7016980155418185, 'step': 3896000}
INFO:transformers.trainer:{'loss': 4.764607668399811, 'learning_rate': 3.830353218019038e-05, 'epoch': 0.7017880691885771, 'step': 3896500}
INFO:transformers.trainer:{'loss': 4.880098867893219, 'learning_rate': 3.8302031286077746e-05, 'epoch': 0.7018781228353355, 'step': 3897000}
INFO:transformers.trainer:{'loss': 4.728658959388733, 'learning_rate': 3.8300530391965105e-05, 'epoch': 0.7019681764820939, 'step': 3897500}
INFO:transformers.trainer:{'loss': 4.745206921100617, 'learning_rate': 3.8299029497852464e-05, 'epoch': 0.7020582301288524, 'step': 3898000}
INFO:transformers.trainer:{'loss': 4.8280802540779115, 'learning_rate': 3.829752860373982e-05, 'epoch': 0.7021482837756108, 'step': 3898500}
INFO:transformers.trainer:{'loss': 4.8312093234062194, 'learning_rate': 3.829602770962718e-05, 'epoch': 0.7022383374223693, 'step': 3899000}
INFO:transformers.trainer:{'loss': 4.923808538913727, 'learning_rate': 3.829452681551454e-05, 'epoch': 0.7023283910691277, 'step': 3899500}
INFO:transformers.trainer:{'loss': 4.934192416667938, 'learning_rate': 3.82930259214019e-05, 'epoch': 0.7024184447158861, 'step': 3900000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3900000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3900000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3900000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3800000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.946127392292023, 'learning_rate': 3.829152502728926e-05, 'epoch': 0.7025084983626446, 'step': 3900500}
INFO:transformers.trainer:{'loss': 4.910346008777618, 'learning_rate': 3.829002413317662e-05, 'epoch': 0.702598552009403, 'step': 3901000}
INFO:transformers.trainer:{'loss': 4.890721182346344, 'learning_rate': 3.828852323906398e-05, 'epoch': 0.7026886056561615, 'step': 3901500}
INFO:transformers.trainer:{'loss': 4.862302700042725, 'learning_rate': 3.828702234495134e-05, 'epoch': 0.7027786593029199, 'step': 3902000}
INFO:transformers.trainer:{'loss': 4.927503469944, 'learning_rate': 3.8285521450838696e-05, 'epoch': 0.7028687129496783, 'step': 3902500}
INFO:transformers.trainer:{'loss': 4.901105363368988, 'learning_rate': 3.8284020556726055e-05, 'epoch': 0.7029587665964369, 'step': 3903000}
INFO:transformers.trainer:{'loss': 4.873723424911499, 'learning_rate': 3.8282519662613414e-05, 'epoch': 0.7030488202431953, 'step': 3903500}
INFO:transformers.trainer:{'loss': 4.931281517982483, 'learning_rate': 3.828101876850077e-05, 'epoch': 0.7031388738899538, 'step': 3904000}
INFO:transformers.trainer:{'loss': 4.962465456962585, 'learning_rate': 3.827951787438813e-05, 'epoch': 0.7032289275367122, 'step': 3904500}
INFO:transformers.trainer:{'loss': 5.006196841716767, 'learning_rate': 3.827801698027549e-05, 'epoch': 0.7033189811834706, 'step': 3905000}
INFO:transformers.trainer:{'loss': 4.872373914718628, 'learning_rate': 3.827651608616285e-05, 'epoch': 0.7034090348302291, 'step': 3905500}
INFO:transformers.trainer:{'loss': 4.995541110038757, 'learning_rate': 3.827501519205021e-05, 'epoch': 0.7034990884769875, 'step': 3906000}
INFO:transformers.trainer:{'loss': 5.035724504709243, 'learning_rate': 3.827351429793757e-05, 'epoch': 0.7035891421237459, 'step': 3906500}
INFO:transformers.trainer:{'loss': 4.8393035914897915, 'learning_rate': 3.827201340382493e-05, 'epoch': 0.7036791957705044, 'step': 3907000}
INFO:transformers.trainer:{'loss': 4.980037022829055, 'learning_rate': 3.8270512509712286e-05, 'epoch': 0.7037692494172628, 'step': 3907500}
INFO:transformers.trainer:{'loss': 4.89443114566803, 'learning_rate': 3.8269011615599645e-05, 'epoch': 0.7038593030640213, 'step': 3908000}
INFO:transformers.trainer:{'loss': 4.924918274879456, 'learning_rate': 3.8267510721487004e-05, 'epoch': 0.7039493567107797, 'step': 3908500}
INFO:transformers.trainer:{'loss': 4.896627944469452, 'learning_rate': 3.826600982737436e-05, 'epoch': 0.7040394103575381, 'step': 3909000}
INFO:transformers.trainer:{'loss': 4.806626575469971, 'learning_rate': 3.826450893326172e-05, 'epoch': 0.7041294640042967, 'step': 3909500}
INFO:transformers.trainer:{'loss': 4.856570223808289, 'learning_rate': 3.826300803914908e-05, 'epoch': 0.7042195176510551, 'step': 3910000}
INFO:transformers.trainer:{'loss': 4.893579896450043, 'learning_rate': 3.826150714503644e-05, 'epoch': 0.7043095712978136, 'step': 3910500}
INFO:transformers.trainer:{'loss': 4.809939535856247, 'learning_rate': 3.82600062509238e-05, 'epoch': 0.704399624944572, 'step': 3911000}
INFO:transformers.trainer:{'loss': 4.863337568759918, 'learning_rate': 3.8258505356811165e-05, 'epoch': 0.7044896785913304, 'step': 3911500}
INFO:transformers.trainer:{'loss': 4.939962416648865, 'learning_rate': 3.825700446269852e-05, 'epoch': 0.7045797322380889, 'step': 3912000}
INFO:transformers.trainer:{'loss': 4.812742432832718, 'learning_rate': 3.8255503568585884e-05, 'epoch': 0.7046697858848473, 'step': 3912500}
INFO:transformers.trainer:{'loss': 4.67704976272583, 'learning_rate': 3.8254002674473236e-05, 'epoch': 0.7047598395316058, 'step': 3913000}
INFO:transformers.trainer:{'loss': 4.856355751514434, 'learning_rate': 3.82525017803606e-05, 'epoch': 0.7048498931783642, 'step': 3913500}
INFO:transformers.trainer:{'loss': 4.844997938156128, 'learning_rate': 3.8251000886247954e-05, 'epoch': 0.7049399468251226, 'step': 3914000}
INFO:transformers.trainer:{'loss': 4.820914993286133, 'learning_rate': 3.824949999213532e-05, 'epoch': 0.7050300004718811, 'step': 3914500}
INFO:transformers.trainer:{'loss': 4.8413663702011105, 'learning_rate': 3.824799909802267e-05, 'epoch': 0.7051200541186395, 'step': 3915000}
INFO:transformers.trainer:{'loss': 4.92456086063385, 'learning_rate': 3.824649820391004e-05, 'epoch': 0.705210107765398, 'step': 3915500}
INFO:transformers.trainer:{'loss': 4.902302920341492, 'learning_rate': 3.824499730979739e-05, 'epoch': 0.7053001614121565, 'step': 3916000}
INFO:transformers.trainer:{'loss': 4.810944266557693, 'learning_rate': 3.8243496415684756e-05, 'epoch': 0.7053902150589149, 'step': 3916500}
INFO:transformers.trainer:{'loss': 4.842033845901489, 'learning_rate': 3.824199552157211e-05, 'epoch': 0.7054802687056734, 'step': 3917000}
INFO:transformers.trainer:{'loss': 4.957920147418976, 'learning_rate': 3.8240494627459474e-05, 'epoch': 0.7055703223524318, 'step': 3917500}
INFO:transformers.trainer:{'loss': 4.800871331214905, 'learning_rate': 3.8238993733346826e-05, 'epoch': 0.7056603759991903, 'step': 3918000}
INFO:transformers.trainer:{'loss': 4.741323746204376, 'learning_rate': 3.823749283923419e-05, 'epoch': 0.7057504296459487, 'step': 3918500}
INFO:transformers.trainer:{'loss': 4.773498462677002, 'learning_rate': 3.823599194512155e-05, 'epoch': 0.7058404832927071, 'step': 3919000}
INFO:transformers.trainer:{'loss': 4.877428719520569, 'learning_rate': 3.823449105100891e-05, 'epoch': 0.7059305369394656, 'step': 3919500}
INFO:transformers.trainer:{'loss': 4.851153945207596, 'learning_rate': 3.823299015689627e-05, 'epoch': 0.706020590586224, 'step': 3920000}
INFO:transformers.trainer:{'loss': 4.777461729049683, 'learning_rate': 3.823148926278363e-05, 'epoch': 0.7061106442329824, 'step': 3920500}
INFO:transformers.trainer:{'loss': 4.8968220911026, 'learning_rate': 3.822998836867099e-05, 'epoch': 0.7062006978797409, 'step': 3921000}
INFO:transformers.trainer:{'loss': 4.795888094902039, 'learning_rate': 3.8228487474558346e-05, 'epoch': 0.7062907515264993, 'step': 3921500}
INFO:transformers.trainer:{'loss': 4.779805675506592, 'learning_rate': 3.8226986580445705e-05, 'epoch': 0.7063808051732579, 'step': 3922000}
INFO:transformers.trainer:{'loss': 4.8701048803329465, 'learning_rate': 3.8225485686333065e-05, 'epoch': 0.7064708588200163, 'step': 3922500}
INFO:transformers.trainer:{'loss': 4.8432862467765805, 'learning_rate': 3.8223984792220424e-05, 'epoch': 0.7065609124667747, 'step': 3923000}
INFO:transformers.trainer:{'loss': 4.906960896968841, 'learning_rate': 3.822248389810778e-05, 'epoch': 0.7066509661135332, 'step': 3923500}
INFO:transformers.trainer:{'loss': 4.942381249904632, 'learning_rate': 3.822098300399514e-05, 'epoch': 0.7067410197602916, 'step': 3924000}
INFO:transformers.trainer:{'loss': 4.933338083744049, 'learning_rate': 3.82194821098825e-05, 'epoch': 0.7068310734070501, 'step': 3924500}
INFO:transformers.trainer:{'loss': 4.844927944660187, 'learning_rate': 3.821798121576986e-05, 'epoch': 0.7069211270538085, 'step': 3925000}
INFO:transformers.trainer:{'loss': 4.8682572507858275, 'learning_rate': 3.821648032165722e-05, 'epoch': 0.7070111807005669, 'step': 3925500}
INFO:transformers.trainer:{'loss': 4.851594058036804, 'learning_rate': 3.821497942754458e-05, 'epoch': 0.7071012343473254, 'step': 3926000}
INFO:transformers.trainer:{'loss': 4.92097504234314, 'learning_rate': 3.821347853343194e-05, 'epoch': 0.7071912879940838, 'step': 3926500}
INFO:transformers.trainer:{'loss': 4.919753662109375, 'learning_rate': 3.8211977639319296e-05, 'epoch': 0.7072813416408423, 'step': 3927000}
INFO:transformers.trainer:{'loss': 4.9327395124435425, 'learning_rate': 3.8210476745206655e-05, 'epoch': 0.7073713952876007, 'step': 3927500}
INFO:transformers.trainer:{'loss': 4.902992819309235, 'learning_rate': 3.8208975851094014e-05, 'epoch': 0.7074614489343591, 'step': 3928000}
INFO:transformers.trainer:{'loss': 4.87513944196701, 'learning_rate': 3.820747495698137e-05, 'epoch': 0.7075515025811177, 'step': 3928500}
INFO:transformers.trainer:{'loss': 4.852990982532501, 'learning_rate': 3.820597406286873e-05, 'epoch': 0.7076415562278761, 'step': 3929000}
INFO:transformers.trainer:{'loss': 4.835163813591003, 'learning_rate': 3.820447316875609e-05, 'epoch': 0.7077316098746346, 'step': 3929500}
INFO:transformers.trainer:{'loss': 4.923309128761291, 'learning_rate': 3.820297227464345e-05, 'epoch': 0.707821663521393, 'step': 3930000}
INFO:transformers.trainer:{'loss': 4.909740542888641, 'learning_rate': 3.820147138053081e-05, 'epoch': 0.7079117171681514, 'step': 3930500}
INFO:transformers.trainer:{'loss': 4.8864039669036865, 'learning_rate': 3.819997048641817e-05, 'epoch': 0.7080017708149099, 'step': 3931000}
INFO:transformers.trainer:{'loss': 4.8947473220825195, 'learning_rate': 3.819846959230553e-05, 'epoch': 0.7080918244616683, 'step': 3931500}
INFO:transformers.trainer:{'loss': 4.7609562764167785, 'learning_rate': 3.819696869819289e-05, 'epoch': 0.7081818781084267, 'step': 3932000}
INFO:transformers.trainer:{'loss': 4.865132166862487, 'learning_rate': 3.8195467804080246e-05, 'epoch': 0.7082719317551852, 'step': 3932500}
INFO:transformers.trainer:{'loss': 4.8665499610900875, 'learning_rate': 3.819396690996761e-05, 'epoch': 0.7083619854019436, 'step': 3933000}
INFO:transformers.trainer:{'loss': 4.91061279630661, 'learning_rate': 3.8192466015854964e-05, 'epoch': 0.7084520390487021, 'step': 3933500}
INFO:transformers.trainer:{'loss': 4.917379437923431, 'learning_rate': 3.819096512174233e-05, 'epoch': 0.7085420926954605, 'step': 3934000}
INFO:transformers.trainer:{'loss': 4.890588735580445, 'learning_rate': 3.818946422762968e-05, 'epoch': 0.7086321463422189, 'step': 3934500}
INFO:transformers.trainer:{'loss': 4.874539222240448, 'learning_rate': 3.818796333351705e-05, 'epoch': 0.7087221999889775, 'step': 3935000}
INFO:transformers.trainer:{'loss': 4.914743780136108, 'learning_rate': 3.81864624394044e-05, 'epoch': 0.7088122536357359, 'step': 3935500}
INFO:transformers.trainer:{'loss': 4.899228344917297, 'learning_rate': 3.8184961545291766e-05, 'epoch': 0.7089023072824944, 'step': 3936000}
INFO:transformers.trainer:{'loss': 4.809407533168793, 'learning_rate': 3.818346065117912e-05, 'epoch': 0.7089923609292528, 'step': 3936500}
INFO:transformers.trainer:{'loss': 4.917238573551178, 'learning_rate': 3.8181959757066484e-05, 'epoch': 0.7090824145760112, 'step': 3937000}
INFO:transformers.trainer:{'loss': 4.945231735706329, 'learning_rate': 3.8180458862953836e-05, 'epoch': 0.7091724682227697, 'step': 3937500}
INFO:transformers.trainer:{'loss': 4.789632402896881, 'learning_rate': 3.81789579688412e-05, 'epoch': 0.7092625218695281, 'step': 3938000}
INFO:transformers.trainer:{'loss': 4.9574159269332885, 'learning_rate': 3.8177457074728554e-05, 'epoch': 0.7093525755162866, 'step': 3938500}
INFO:transformers.trainer:{'loss': 4.786187586665154, 'learning_rate': 3.817595618061592e-05, 'epoch': 0.709442629163045, 'step': 3939000}
INFO:transformers.trainer:{'loss': 4.910368344783783, 'learning_rate': 3.817445528650328e-05, 'epoch': 0.7095326828098034, 'step': 3939500}
INFO:transformers.trainer:{'loss': 4.883163850307465, 'learning_rate': 3.817295439239064e-05, 'epoch': 0.7096227364565619, 'step': 3940000}
INFO:transformers.trainer:{'loss': 4.940075213432312, 'learning_rate': 3.8171453498278e-05, 'epoch': 0.7097127901033203, 'step': 3940500}
INFO:transformers.trainer:{'loss': 4.886387360572815, 'learning_rate': 3.8169952604165356e-05, 'epoch': 0.7098028437500788, 'step': 3941000}
INFO:transformers.trainer:{'loss': 4.8626237120628355, 'learning_rate': 3.8168451710052715e-05, 'epoch': 0.7098928973968373, 'step': 3941500}
INFO:transformers.trainer:{'loss': 4.820479217052459, 'learning_rate': 3.8166950815940074e-05, 'epoch': 0.7099829510435957, 'step': 3942000}
INFO:transformers.trainer:{'loss': 4.705229171037674, 'learning_rate': 3.816544992182743e-05, 'epoch': 0.7100730046903542, 'step': 3942500}
INFO:transformers.trainer:{'loss': 4.7932990002632145, 'learning_rate': 3.816394902771479e-05, 'epoch': 0.7101630583371126, 'step': 3943000}
INFO:transformers.trainer:{'loss': 4.775849925994873, 'learning_rate': 3.816244813360215e-05, 'epoch': 0.710253111983871, 'step': 3943500}
INFO:transformers.trainer:{'loss': 4.8294655103683475, 'learning_rate': 3.816094723948951e-05, 'epoch': 0.7103431656306295, 'step': 3944000}
INFO:transformers.trainer:{'loss': 4.629497045993805, 'learning_rate': 3.815944634537687e-05, 'epoch': 0.7104332192773879, 'step': 3944500}
INFO:transformers.trainer:{'loss': 4.8031984088420865, 'learning_rate': 3.815794545126423e-05, 'epoch': 0.7105232729241464, 'step': 3945000}
INFO:transformers.trainer:{'loss': 4.874864149332047, 'learning_rate': 3.815644455715159e-05, 'epoch': 0.7106133265709048, 'step': 3945500}
INFO:transformers.trainer:{'loss': 4.844609906673432, 'learning_rate': 3.8154943663038953e-05, 'epoch': 0.7107033802176632, 'step': 3946000}
INFO:transformers.trainer:{'loss': 4.836169427871704, 'learning_rate': 3.8153442768926306e-05, 'epoch': 0.7107934338644217, 'step': 3946500}
INFO:transformers.trainer:{'loss': 4.795917188167572, 'learning_rate': 3.8151941874813665e-05, 'epoch': 0.7108834875111801, 'step': 3947000}
INFO:transformers.trainer:{'loss': 4.893456541538239, 'learning_rate': 3.8150440980701024e-05, 'epoch': 0.7109735411579386, 'step': 3947500}
INFO:transformers.trainer:{'loss': 4.841665473937988, 'learning_rate': 3.814894008658838e-05, 'epoch': 0.711063594804697, 'step': 3948000}
INFO:transformers.trainer:{'loss': 4.729054811954498, 'learning_rate': 3.814743919247574e-05, 'epoch': 0.7111536484514555, 'step': 3948500}
INFO:transformers.trainer:{'loss': 4.698290887832641, 'learning_rate': 3.81459382983631e-05, 'epoch': 0.711243702098214, 'step': 3949000}
INFO:transformers.trainer:{'loss': 4.857990721702576, 'learning_rate': 3.814443740425046e-05, 'epoch': 0.7113337557449724, 'step': 3949500}
INFO:transformers.trainer:{'loss': 4.813513405799866, 'learning_rate': 3.814293651013782e-05, 'epoch': 0.7114238093917309, 'step': 3950000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-3950000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3950000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-3950000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3850000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.9238013114929196, 'learning_rate': 3.814143561602518e-05, 'epoch': 0.7115138630384893, 'step': 3950500}
INFO:transformers.trainer:{'loss': 4.854233354568481, 'learning_rate': 3.813993472191254e-05, 'epoch': 0.7116039166852477, 'step': 3951000}
INFO:transformers.trainer:{'loss': 4.878935506820679, 'learning_rate': 3.8138433827799896e-05, 'epoch': 0.7116939703320062, 'step': 3951500}
INFO:transformers.trainer:{'loss': 4.801304497480393, 'learning_rate': 3.8136932933687255e-05, 'epoch': 0.7117840239787646, 'step': 3952000}
INFO:transformers.trainer:{'loss': 4.862169014930725, 'learning_rate': 3.8135432039574614e-05, 'epoch': 0.7118740776255231, 'step': 3952500}
INFO:transformers.trainer:{'loss': 4.882151608467102, 'learning_rate': 3.813393114546197e-05, 'epoch': 0.7119641312722815, 'step': 3953000}
INFO:transformers.trainer:{'loss': 4.8764177069664, 'learning_rate': 3.813243025134934e-05, 'epoch': 0.7120541849190399, 'step': 3953500}
INFO:transformers.trainer:{'loss': 4.902354158639908, 'learning_rate': 3.813092935723669e-05, 'epoch': 0.7121442385657984, 'step': 3954000}
INFO:transformers.trainer:{'loss': 4.762187039136887, 'learning_rate': 3.812942846312406e-05, 'epoch': 0.7122342922125569, 'step': 3954500}
INFO:transformers.trainer:{'loss': 4.754190255641937, 'learning_rate': 3.812792756901141e-05, 'epoch': 0.7123243458593154, 'step': 3955000}
INFO:transformers.trainer:{'loss': 4.791643366336823, 'learning_rate': 3.8126426674898775e-05, 'epoch': 0.7124143995060738, 'step': 3955500}
INFO:transformers.trainer:{'loss': 4.782424057483673, 'learning_rate': 3.812492578078613e-05, 'epoch': 0.7125044531528322, 'step': 3956000}
INFO:transformers.trainer:{'loss': 4.797376133203507, 'learning_rate': 3.8123424886673493e-05, 'epoch': 0.7125945067995907, 'step': 3956500}
INFO:transformers.trainer:{'loss': 4.766025142192841, 'learning_rate': 3.8121923992560846e-05, 'epoch': 0.7126845604463491, 'step': 3957000}
INFO:transformers.trainer:{'loss': 4.75446895647049, 'learning_rate': 3.812042309844821e-05, 'epoch': 0.7127746140931075, 'step': 3957500}
INFO:transformers.trainer:{'loss': 4.726223316669464, 'learning_rate': 3.8118922204335564e-05, 'epoch': 0.712864667739866, 'step': 3958000}
INFO:transformers.trainer:{'loss': 4.72158078956604, 'learning_rate': 3.811742131022293e-05, 'epoch': 0.7129547213866244, 'step': 3958500}
INFO:transformers.trainer:{'loss': 4.720861427783966, 'learning_rate': 3.811592041611028e-05, 'epoch': 0.7130447750333829, 'step': 3959000}
INFO:transformers.trainer:{'loss': 4.764370952129364, 'learning_rate': 3.811441952199765e-05, 'epoch': 0.7131348286801413, 'step': 3959500}
INFO:transformers.trainer:{'loss': 4.775693157196045, 'learning_rate': 3.811291862788501e-05, 'epoch': 0.7132248823268997, 'step': 3960000}
INFO:transformers.trainer:{'loss': 4.784364016532898, 'learning_rate': 3.8111417733772366e-05, 'epoch': 0.7133149359736582, 'step': 3960500}
INFO:transformers.trainer:{'loss': 4.776619115829468, 'learning_rate': 3.8109916839659725e-05, 'epoch': 0.7134049896204167, 'step': 3961000}
INFO:transformers.trainer:{'loss': 4.802300990104675, 'learning_rate': 3.8108415945547084e-05, 'epoch': 0.7134950432671752, 'step': 3961500}
INFO:transformers.trainer:{'loss': 4.891625938415527, 'learning_rate': 3.810691505143444e-05, 'epoch': 0.7135850969139336, 'step': 3962000}
INFO:transformers.trainer:{'loss': 4.8300727243423465, 'learning_rate': 3.81054141573218e-05, 'epoch': 0.713675150560692, 'step': 3962500}
INFO:transformers.trainer:{'loss': 4.824252781867981, 'learning_rate': 3.810391326320916e-05, 'epoch': 0.7137652042074505, 'step': 3963000}
INFO:transformers.trainer:{'loss': 4.748311787128449, 'learning_rate': 3.810241236909652e-05, 'epoch': 0.7138552578542089, 'step': 3963500}
INFO:transformers.trainer:{'loss': 4.796436423778534, 'learning_rate': 3.810091147498388e-05, 'epoch': 0.7139453115009674, 'step': 3964000}
INFO:transformers.trainer:{'loss': 4.896095451831818, 'learning_rate': 3.809941058087124e-05, 'epoch': 0.7140353651477258, 'step': 3964500}
INFO:transformers.trainer:{'loss': 4.788796264171601, 'learning_rate': 3.80979096867586e-05, 'epoch': 0.7141254187944842, 'step': 3965000}
INFO:transformers.trainer:{'loss': 4.891632308006287, 'learning_rate': 3.8096408792645956e-05, 'epoch': 0.7142154724412427, 'step': 3965500}
INFO:transformers.trainer:{'loss': 4.733697541952133, 'learning_rate': 3.8094907898533315e-05, 'epoch': 0.7143055260880011, 'step': 3966000}
INFO:transformers.trainer:{'loss': 4.767603097915649, 'learning_rate': 3.8093407004420674e-05, 'epoch': 0.7143955797347596, 'step': 3966500}
INFO:transformers.trainer:{'loss': 4.71213976430893, 'learning_rate': 3.8091906110308034e-05, 'epoch': 0.714485633381518, 'step': 3967000}
INFO:transformers.trainer:{'loss': 4.699275437355041, 'learning_rate': 3.80904052161954e-05, 'epoch': 0.7145756870282765, 'step': 3967500}
INFO:transformers.trainer:{'loss': 4.599359154701233, 'learning_rate': 3.808890432208275e-05, 'epoch': 0.714665740675035, 'step': 3968000}
INFO:transformers.trainer:{'loss': 4.837708291053772, 'learning_rate': 3.808740342797012e-05, 'epoch': 0.7147557943217934, 'step': 3968500}
INFO:transformers.trainer:{'loss': 4.8139891219139095, 'learning_rate': 3.808590253385747e-05, 'epoch': 0.7148458479685518, 'step': 3969000}
INFO:transformers.trainer:{'loss': 4.842979331493377, 'learning_rate': 3.8084401639744836e-05, 'epoch': 0.7149359016153103, 'step': 3969500}
INFO:transformers.trainer:{'loss': 4.685997510910034, 'learning_rate': 3.808290074563219e-05, 'epoch': 0.7150259552620687, 'step': 3970000}
INFO:transformers.trainer:{'loss': 4.535729447364807, 'learning_rate': 3.808139985151955e-05, 'epoch': 0.7151160089088272, 'step': 3970500}
INFO:transformers.trainer:{'loss': 4.753398773670196, 'learning_rate': 3.8079898957406906e-05, 'epoch': 0.7152060625555856, 'step': 3971000}
INFO:transformers.trainer:{'loss': 4.757335039138794, 'learning_rate': 3.8078398063294265e-05, 'epoch': 0.715296116202344, 'step': 3971500}
INFO:transformers.trainer:{'loss': 4.961936569213867, 'learning_rate': 3.8076897169181624e-05, 'epoch': 0.7153861698491025, 'step': 3972000}
INFO:transformers.trainer:{'loss': 4.848549406051636, 'learning_rate': 3.807539627506898e-05, 'epoch': 0.7154762234958609, 'step': 3972500}
INFO:transformers.trainer:{'loss': 4.827787922382354, 'learning_rate': 3.807389538095634e-05, 'epoch': 0.7155662771426194, 'step': 3973000}
INFO:transformers.trainer:{'loss': 4.668376808166504, 'learning_rate': 3.80723944868437e-05, 'epoch': 0.7156563307893778, 'step': 3973500}
INFO:transformers.trainer:{'loss': 4.710128801345825, 'learning_rate': 3.807089359273107e-05, 'epoch': 0.7157463844361363, 'step': 3974000}
INFO:transformers.trainer:{'loss': 4.81296299123764, 'learning_rate': 3.806939269861842e-05, 'epoch': 0.7158364380828948, 'step': 3974500}
INFO:transformers.trainer:{'loss': 4.748919764995575, 'learning_rate': 3.8067891804505785e-05, 'epoch': 0.7159264917296532, 'step': 3975000}
INFO:transformers.trainer:{'loss': 4.846406431674957, 'learning_rate': 3.806639091039314e-05, 'epoch': 0.7160165453764117, 'step': 3975500}
INFO:transformers.trainer:{'loss': 4.906264976501465, 'learning_rate': 3.80648900162805e-05, 'epoch': 0.7161065990231701, 'step': 3976000}
INFO:transformers.trainer:{'loss': 4.876731832504272, 'learning_rate': 3.8063389122167855e-05, 'epoch': 0.7161966526699285, 'step': 3976500}
INFO:transformers.trainer:{'loss': 4.83671499300003, 'learning_rate': 3.806188822805522e-05, 'epoch': 0.716286706316687, 'step': 3977000}
INFO:transformers.trainer:{'loss': 4.882249418735504, 'learning_rate': 3.8060387333942574e-05, 'epoch': 0.7163767599634454, 'step': 3977500}
INFO:transformers.trainer:{'loss': 4.922359298706055, 'learning_rate': 3.805888643982994e-05, 'epoch': 0.7164668136102039, 'step': 3978000}
INFO:transformers.trainer:{'loss': 4.84019412612915, 'learning_rate': 3.805738554571729e-05, 'epoch': 0.7165568672569623, 'step': 3978500}
INFO:transformers.trainer:{'loss': 4.782777113437652, 'learning_rate': 3.805588465160466e-05, 'epoch': 0.7166469209037207, 'step': 3979000}
INFO:transformers.trainer:{'loss': 4.844476912975312, 'learning_rate': 3.805438375749201e-05, 'epoch': 0.7167369745504792, 'step': 3979500}
INFO:transformers.trainer:{'loss': 4.6960729069709775, 'learning_rate': 3.8052882863379376e-05, 'epoch': 0.7168270281972376, 'step': 3980000}
INFO:transformers.trainer:{'loss': 4.827991737365723, 'learning_rate': 3.8051381969266735e-05, 'epoch': 0.716917081843996, 'step': 3980500}
INFO:transformers.trainer:{'loss': 4.87014771604538, 'learning_rate': 3.8049881075154094e-05, 'epoch': 0.7170071354907546, 'step': 3981000}
INFO:transformers.trainer:{'loss': 4.855598673343659, 'learning_rate': 3.804838018104145e-05, 'epoch': 0.717097189137513, 'step': 3981500}
INFO:transformers.trainer:{'loss': 4.929390216827392, 'learning_rate': 3.804687928692881e-05, 'epoch': 0.7171872427842715, 'step': 3982000}
INFO:transformers.trainer:{'loss': 4.861192708015442, 'learning_rate': 3.804537839281617e-05, 'epoch': 0.7172772964310299, 'step': 3982500}
INFO:transformers.trainer:{'loss': 4.808961686134339, 'learning_rate': 3.804387749870353e-05, 'epoch': 0.7173673500777883, 'step': 3983000}
INFO:transformers.trainer:{'loss': 4.789555322647095, 'learning_rate': 3.804237660459089e-05, 'epoch': 0.7174574037245468, 'step': 3983500}
INFO:transformers.trainer:{'loss': 4.800351108551025, 'learning_rate': 3.804087571047825e-05, 'epoch': 0.7175474573713052, 'step': 3984000}
INFO:transformers.trainer:{'loss': 4.810675787448883, 'learning_rate': 3.803937481636561e-05, 'epoch': 0.7176375110180637, 'step': 3984500}
INFO:transformers.trainer:{'loss': 4.733273337364197, 'learning_rate': 3.8037873922252966e-05, 'epoch': 0.7177275646648221, 'step': 3985000}
INFO:transformers.trainer:{'loss': 4.650525873184204, 'learning_rate': 3.8036373028140325e-05, 'epoch': 0.7178176183115805, 'step': 3985500}
INFO:transformers.trainer:{'loss': 4.796473332881927, 'learning_rate': 3.8034872134027684e-05, 'epoch': 0.717907671958339, 'step': 3986000}
INFO:transformers.trainer:{'loss': 4.726536739826202, 'learning_rate': 3.803337123991504e-05, 'epoch': 0.7179977256050974, 'step': 3986500}
INFO:transformers.trainer:{'loss': 4.750666521787643, 'learning_rate': 3.80318703458024e-05, 'epoch': 0.718087779251856, 'step': 3987000}
INFO:transformers.trainer:{'loss': 4.709801779747009, 'learning_rate': 3.803036945168976e-05, 'epoch': 0.7181778328986144, 'step': 3987500}
INFO:transformers.trainer:{'loss': 4.757413394451142, 'learning_rate': 3.802886855757713e-05, 'epoch': 0.7182678865453728, 'step': 3988000}
INFO:transformers.trainer:{'loss': 4.8154846944808956, 'learning_rate': 3.802736766346448e-05, 'epoch': 0.7183579401921313, 'step': 3988500}
INFO:transformers.trainer:{'loss': 4.788095501899719, 'learning_rate': 3.8025866769351845e-05, 'epoch': 0.7184479938388897, 'step': 3989000}
INFO:transformers.trainer:{'loss': 4.843696816921234, 'learning_rate': 3.80243658752392e-05, 'epoch': 0.7185380474856482, 'step': 3989500}
INFO:transformers.trainer:{'loss': 4.728488963127136, 'learning_rate': 3.802286498112656e-05, 'epoch': 0.7186281011324066, 'step': 3990000}
INFO:transformers.trainer:{'loss': 4.883673677444458, 'learning_rate': 3.8021364087013916e-05, 'epoch': 0.718718154779165, 'step': 3990500}
INFO:transformers.trainer:{'loss': 4.7269733195304875, 'learning_rate': 3.801986319290128e-05, 'epoch': 0.7188082084259235, 'step': 3991000}
INFO:transformers.trainer:{'loss': 4.67212084531784, 'learning_rate': 3.8018362298788634e-05, 'epoch': 0.7188982620726819, 'step': 3991500}
INFO:transformers.trainer:{'loss': 4.776892477989197, 'learning_rate': 3.8016861404676e-05, 'epoch': 0.7189883157194403, 'step': 3992000}
INFO:transformers.trainer:{'loss': 4.7935499503612515, 'learning_rate': 3.801536051056335e-05, 'epoch': 0.7190783693661988, 'step': 3992500}
INFO:transformers.trainer:{'loss': 4.75118346118927, 'learning_rate': 3.801385961645072e-05, 'epoch': 0.7191684230129572, 'step': 3993000}
INFO:transformers.trainer:{'loss': 4.7899059147834775, 'learning_rate': 3.801235872233807e-05, 'epoch': 0.7192584766597158, 'step': 3993500}
INFO:transformers.trainer:{'loss': 4.757108019351959, 'learning_rate': 3.8010857828225436e-05, 'epoch': 0.7193485303064742, 'step': 3994000}
INFO:transformers.trainer:{'loss': 4.81908512878418, 'learning_rate': 3.8009356934112795e-05, 'epoch': 0.7194385839532326, 'step': 3994500}
INFO:transformers.trainer:{'loss': 4.703511496067047, 'learning_rate': 3.800785604000015e-05, 'epoch': 0.7195286375999911, 'step': 3995000}
INFO:transformers.trainer:{'loss': 4.761695502281189, 'learning_rate': 3.800635514588751e-05, 'epoch': 0.7196186912467495, 'step': 3995500}
INFO:transformers.trainer:{'loss': 4.796907225131989, 'learning_rate': 3.8004854251774865e-05, 'epoch': 0.719708744893508, 'step': 3996000}
INFO:transformers.trainer:{'loss': 4.810973261833191, 'learning_rate': 3.800335335766223e-05, 'epoch': 0.7197987985402664, 'step': 3996500}
INFO:transformers.trainer:{'loss': 4.814118824958801, 'learning_rate': 3.800185246354958e-05, 'epoch': 0.7198888521870248, 'step': 3997000}
INFO:transformers.trainer:{'loss': 4.739147848129273, 'learning_rate': 3.800035156943695e-05, 'epoch': 0.7199789058337833, 'step': 3997500}
INFO:transformers.trainer:{'loss': 4.71078355550766, 'learning_rate': 3.79988506753243e-05, 'epoch': 0.7200689594805417, 'step': 3998000}
INFO:transformers.trainer:{'loss': 4.697952108383179, 'learning_rate': 3.799734978121167e-05, 'epoch': 0.7201590131273002, 'step': 3998500}
INFO:transformers.trainer:{'loss': 4.3063004624843595, 'learning_rate': 3.799584888709902e-05, 'epoch': 0.7202490667740586, 'step': 3999000}
INFO:transformers.trainer:{'loss': 4.7628381729125975, 'learning_rate': 3.7994347992986385e-05, 'epoch': 0.720339120420817, 'step': 3999500}
INFO:transformers.trainer:{'loss': 4.9070400609970095, 'learning_rate': 3.799284709887374e-05, 'epoch': 0.7204291740675756, 'step': 4000000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4000000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4000000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4000000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3900000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.907999433517456, 'learning_rate': 3.7991346204761103e-05, 'epoch': 0.720519227714334, 'step': 4000500}
INFO:transformers.trainer:{'loss': 4.880204422473907, 'learning_rate': 3.7989845310648456e-05, 'epoch': 0.7206092813610925, 'step': 4001000}
INFO:transformers.trainer:{'loss': 4.908705478191376, 'learning_rate': 3.798834441653582e-05, 'epoch': 0.7206993350078509, 'step': 4001500}
INFO:transformers.trainer:{'loss': 4.794996240139008, 'learning_rate': 3.798684352242318e-05, 'epoch': 0.7207893886546093, 'step': 4002000}
INFO:transformers.trainer:{'loss': 4.695766860961914, 'learning_rate': 3.798534262831054e-05, 'epoch': 0.7208794423013678, 'step': 4002500}
INFO:transformers.trainer:{'loss': 4.807617865085602, 'learning_rate': 3.79838417341979e-05, 'epoch': 0.7209694959481262, 'step': 4003000}
INFO:transformers.trainer:{'loss': 4.811200927257538, 'learning_rate': 3.798234084008526e-05, 'epoch': 0.7210595495948847, 'step': 4003500}
INFO:transformers.trainer:{'loss': 4.8496618971824645, 'learning_rate': 3.798083994597262e-05, 'epoch': 0.7211496032416431, 'step': 4004000}
INFO:transformers.trainer:{'loss': 4.91605651807785, 'learning_rate': 3.7979339051859976e-05, 'epoch': 0.7212396568884015, 'step': 4004500}
INFO:transformers.trainer:{'loss': 4.914240853309631, 'learning_rate': 3.7977838157747335e-05, 'epoch': 0.72132971053516, 'step': 4005000}
INFO:transformers.trainer:{'loss': 4.764514900684357, 'learning_rate': 3.7976337263634694e-05, 'epoch': 0.7214197641819184, 'step': 4005500}
INFO:transformers.trainer:{'loss': 4.750480498790741, 'learning_rate': 3.797483636952205e-05, 'epoch': 0.7215098178286768, 'step': 4006000}
INFO:transformers.trainer:{'loss': 4.788185981750488, 'learning_rate': 3.797333547540941e-05, 'epoch': 0.7215998714754354, 'step': 4006500}
INFO:transformers.trainer:{'loss': 4.7916693415641785, 'learning_rate': 3.797183458129677e-05, 'epoch': 0.7216899251221938, 'step': 4007000}
INFO:transformers.trainer:{'loss': 4.761913343906403, 'learning_rate': 3.797033368718413e-05, 'epoch': 0.7217799787689523, 'step': 4007500}
INFO:transformers.trainer:{'loss': 4.813295733928681, 'learning_rate': 3.796883279307149e-05, 'epoch': 0.7218700324157107, 'step': 4008000}
INFO:transformers.trainer:{'loss': 4.750105691432953, 'learning_rate': 3.7967331898958855e-05, 'epoch': 0.7219600860624691, 'step': 4008500}
INFO:transformers.trainer:{'loss': 4.814755449771881, 'learning_rate': 3.796583100484621e-05, 'epoch': 0.7220501397092276, 'step': 4009000}
INFO:transformers.trainer:{'loss': 4.766919543743134, 'learning_rate': 3.796433011073357e-05, 'epoch': 0.722140193355986, 'step': 4009500}
INFO:transformers.trainer:{'loss': 4.596332900524139, 'learning_rate': 3.7962829216620925e-05, 'epoch': 0.7222302470027445, 'step': 4010000}
INFO:transformers.trainer:{'loss': 4.676295152425766, 'learning_rate': 3.796132832250829e-05, 'epoch': 0.7223203006495029, 'step': 4010500}
INFO:transformers.trainer:{'loss': 4.862062973976135, 'learning_rate': 3.7959827428395643e-05, 'epoch': 0.7224103542962613, 'step': 4011000}
INFO:transformers.trainer:{'loss': 4.776745909690857, 'learning_rate': 3.795832653428301e-05, 'epoch': 0.7225004079430198, 'step': 4011500}
INFO:transformers.trainer:{'loss': 4.775947698593139, 'learning_rate': 3.795682564017036e-05, 'epoch': 0.7225904615897782, 'step': 4012000}
INFO:transformers.trainer:{'loss': 4.908228808879852, 'learning_rate': 3.795532474605773e-05, 'epoch': 0.7226805152365368, 'step': 4012500}
INFO:transformers.trainer:{'loss': 4.805846514225006, 'learning_rate': 3.795382385194508e-05, 'epoch': 0.7227705688832952, 'step': 4013000}
INFO:transformers.trainer:{'loss': 4.885285895824432, 'learning_rate': 3.7952322957832445e-05, 'epoch': 0.7228606225300536, 'step': 4013500}
INFO:transformers.trainer:{'loss': 4.840572874069214, 'learning_rate': 3.79508220637198e-05, 'epoch': 0.7229506761768121, 'step': 4014000}
INFO:transformers.trainer:{'loss': 4.76558279299736, 'learning_rate': 3.7949321169607164e-05, 'epoch': 0.7230407298235705, 'step': 4014500}
INFO:transformers.trainer:{'loss': 4.798778850078583, 'learning_rate': 3.7947820275494516e-05, 'epoch': 0.723130783470329, 'step': 4015000}
INFO:transformers.trainer:{'loss': 4.824881459236145, 'learning_rate': 3.794631938138188e-05, 'epoch': 0.7232208371170874, 'step': 4015500}
INFO:transformers.trainer:{'loss': 4.846442792892456, 'learning_rate': 3.794481848726924e-05, 'epoch': 0.7233108907638458, 'step': 4016000}
INFO:transformers.trainer:{'loss': 4.782030277252197, 'learning_rate': 3.79433175931566e-05, 'epoch': 0.7234009444106043, 'step': 4016500}
INFO:transformers.trainer:{'loss': 4.6850948276519775, 'learning_rate': 3.794181669904396e-05, 'epoch': 0.7234909980573627, 'step': 4017000}
INFO:transformers.trainer:{'loss': 4.643924182653427, 'learning_rate': 3.794031580493132e-05, 'epoch': 0.7235810517041211, 'step': 4017500}
INFO:transformers.trainer:{'loss': 4.701161265850067, 'learning_rate': 3.793881491081868e-05, 'epoch': 0.7236711053508796, 'step': 4018000}
INFO:transformers.trainer:{'loss': 4.698459260463714, 'learning_rate': 3.793731401670603e-05, 'epoch': 0.723761158997638, 'step': 4018500}
INFO:transformers.trainer:{'loss': 4.713714931964875, 'learning_rate': 3.7935813122593395e-05, 'epoch': 0.7238512126443966, 'step': 4019000}
INFO:transformers.trainer:{'loss': 4.718668208599091, 'learning_rate': 3.793431222848075e-05, 'epoch': 0.723941266291155, 'step': 4019500}
INFO:transformers.trainer:{'loss': 4.782978202342987, 'learning_rate': 3.793281133436811e-05, 'epoch': 0.7240313199379134, 'step': 4020000}
INFO:transformers.trainer:{'loss': 4.772508263587952, 'learning_rate': 3.7931310440255465e-05, 'epoch': 0.7241213735846719, 'step': 4020500}
INFO:transformers.trainer:{'loss': 4.703286693096161, 'learning_rate': 3.792980954614283e-05, 'epoch': 0.7242114272314303, 'step': 4021000}
INFO:transformers.trainer:{'loss': 4.675969792366028, 'learning_rate': 3.7928308652030184e-05, 'epoch': 0.7243014808781888, 'step': 4021500}
INFO:transformers.trainer:{'loss': 4.748690277338028, 'learning_rate': 3.792680775791755e-05, 'epoch': 0.7243915345249472, 'step': 4022000}
INFO:transformers.trainer:{'loss': 4.738985799312592, 'learning_rate': 3.792530686380491e-05, 'epoch': 0.7244815881717056, 'step': 4022500}
INFO:transformers.trainer:{'loss': 4.775722626686096, 'learning_rate': 3.792380596969227e-05, 'epoch': 0.7245716418184641, 'step': 4023000}
INFO:transformers.trainer:{'loss': 4.7343474254608156, 'learning_rate': 3.7922305075579626e-05, 'epoch': 0.7246616954652225, 'step': 4023500}
INFO:transformers.trainer:{'loss': 4.771038749217987, 'learning_rate': 3.7920804181466986e-05, 'epoch': 0.724751749111981, 'step': 4024000}
INFO:transformers.trainer:{'loss': 4.672652983188629, 'learning_rate': 3.7919303287354345e-05, 'epoch': 0.7248418027587394, 'step': 4024500}
INFO:transformers.trainer:{'loss': 4.819690151691437, 'learning_rate': 3.7917802393241704e-05, 'epoch': 0.7249318564054978, 'step': 4025000}
INFO:transformers.trainer:{'loss': 4.816614323854447, 'learning_rate': 3.791630149912906e-05, 'epoch': 0.7250219100522564, 'step': 4025500}
INFO:transformers.trainer:{'loss': 4.8854197659492495, 'learning_rate': 3.791480060501642e-05, 'epoch': 0.7251119636990148, 'step': 4026000}
INFO:transformers.trainer:{'loss': 4.770952537536621, 'learning_rate': 3.791329971090378e-05, 'epoch': 0.7252020173457733, 'step': 4026500}
INFO:transformers.trainer:{'loss': 4.662953747749329, 'learning_rate': 3.791179881679114e-05, 'epoch': 0.7252920709925317, 'step': 4027000}
INFO:transformers.trainer:{'loss': 4.7528549370765685, 'learning_rate': 3.79102979226785e-05, 'epoch': 0.7253821246392901, 'step': 4027500}
INFO:transformers.trainer:{'loss': 4.559342132568359, 'learning_rate': 3.790879702856586e-05, 'epoch': 0.7254721782860486, 'step': 4028000}
INFO:transformers.trainer:{'loss': 4.691265431404114, 'learning_rate': 3.790729613445322e-05, 'epoch': 0.725562231932807, 'step': 4028500}
INFO:transformers.trainer:{'loss': 4.722797675848007, 'learning_rate': 3.790579524034058e-05, 'epoch': 0.7256522855795654, 'step': 4029000}
INFO:transformers.trainer:{'loss': 4.748074187755584, 'learning_rate': 3.7904294346227935e-05, 'epoch': 0.7257423392263239, 'step': 4029500}
INFO:transformers.trainer:{'loss': 4.628802864551544, 'learning_rate': 3.79027934521153e-05, 'epoch': 0.7258323928730823, 'step': 4030000}
INFO:transformers.trainer:{'loss': 4.597014287948609, 'learning_rate': 3.790129255800265e-05, 'epoch': 0.7259224465198408, 'step': 4030500}
INFO:transformers.trainer:{'loss': 4.673994184970856, 'learning_rate': 3.789979166389002e-05, 'epoch': 0.7260125001665992, 'step': 4031000}
INFO:transformers.trainer:{'loss': 4.675221388339996, 'learning_rate': 3.789829076977737e-05, 'epoch': 0.7261025538133576, 'step': 4031500}
INFO:transformers.trainer:{'loss': 4.7698794422149655, 'learning_rate': 3.789678987566474e-05, 'epoch': 0.7261926074601162, 'step': 4032000}
INFO:transformers.trainer:{'loss': 4.8366592745780945, 'learning_rate': 3.789528898155209e-05, 'epoch': 0.7262826611068746, 'step': 4032500}
INFO:transformers.trainer:{'loss': 4.8604911808967595, 'learning_rate': 3.7893788087439455e-05, 'epoch': 0.7263727147536331, 'step': 4033000}
INFO:transformers.trainer:{'loss': 4.727007059574127, 'learning_rate': 3.789228719332681e-05, 'epoch': 0.7264627684003915, 'step': 4033500}
INFO:transformers.trainer:{'loss': 4.757173535346985, 'learning_rate': 3.789078629921417e-05, 'epoch': 0.7265528220471499, 'step': 4034000}
INFO:transformers.trainer:{'loss': 4.698393959522248, 'learning_rate': 3.7889285405101526e-05, 'epoch': 0.7266428756939084, 'step': 4034500}
INFO:transformers.trainer:{'loss': 4.832357831478119, 'learning_rate': 3.788778451098889e-05, 'epoch': 0.7267329293406668, 'step': 4035000}
INFO:transformers.trainer:{'loss': 4.891549357414245, 'learning_rate': 3.7886283616876244e-05, 'epoch': 0.7268229829874253, 'step': 4035500}
INFO:transformers.trainer:{'loss': 4.775422357559204, 'learning_rate': 3.788478272276361e-05, 'epoch': 0.7269130366341837, 'step': 4036000}
INFO:transformers.trainer:{'loss': 4.849672060489654, 'learning_rate': 3.788328182865097e-05, 'epoch': 0.7270030902809421, 'step': 4036500}
INFO:transformers.trainer:{'loss': 4.829374313354492, 'learning_rate': 3.788178093453833e-05, 'epoch': 0.7270931439277006, 'step': 4037000}
INFO:transformers.trainer:{'loss': 4.782469758033752, 'learning_rate': 3.788028004042569e-05, 'epoch': 0.727183197574459, 'step': 4037500}
INFO:transformers.trainer:{'loss': 4.782894710302353, 'learning_rate': 3.7878779146313046e-05, 'epoch': 0.7272732512212176, 'step': 4038000}
INFO:transformers.trainer:{'loss': 4.807811670780182, 'learning_rate': 3.7877278252200405e-05, 'epoch': 0.727363304867976, 'step': 4038500}
INFO:transformers.trainer:{'loss': 4.758866931915283, 'learning_rate': 3.7875777358087764e-05, 'epoch': 0.7274533585147344, 'step': 4039000}
INFO:transformers.trainer:{'loss': 4.873192209720612, 'learning_rate': 3.787427646397512e-05, 'epoch': 0.7275434121614929, 'step': 4039500}
INFO:transformers.trainer:{'loss': 4.806381212711334, 'learning_rate': 3.787277556986248e-05, 'epoch': 0.7276334658082513, 'step': 4040000}
INFO:transformers.trainer:{'loss': 4.777205722332001, 'learning_rate': 3.787127467574984e-05, 'epoch': 0.7277235194550098, 'step': 4040500}
INFO:transformers.trainer:{'loss': 4.8159810090065, 'learning_rate': 3.78697737816372e-05, 'epoch': 0.7278135731017682, 'step': 4041000}
INFO:transformers.trainer:{'loss': 4.80559422826767, 'learning_rate': 3.786827288752456e-05, 'epoch': 0.7279036267485266, 'step': 4041500}
INFO:transformers.trainer:{'loss': 4.821857466220855, 'learning_rate': 3.786677199341191e-05, 'epoch': 0.7279936803952851, 'step': 4042000}
INFO:transformers.trainer:{'loss': 4.806239594936371, 'learning_rate': 3.786527109929928e-05, 'epoch': 0.7280837340420435, 'step': 4042500}
INFO:transformers.trainer:{'loss': 4.75417189502716, 'learning_rate': 3.7863770205186636e-05, 'epoch': 0.7281737876888019, 'step': 4043000}
INFO:transformers.trainer:{'loss': 4.781798941135406, 'learning_rate': 3.7862269311073995e-05, 'epoch': 0.7282638413355604, 'step': 4043500}
INFO:transformers.trainer:{'loss': 4.720963954925537, 'learning_rate': 3.7860768416961354e-05, 'epoch': 0.7283538949823188, 'step': 4044000}
INFO:transformers.trainer:{'loss': 4.778574127197266, 'learning_rate': 3.785926752284871e-05, 'epoch': 0.7284439486290774, 'step': 4044500}
INFO:transformers.trainer:{'loss': 4.736631046295166, 'learning_rate': 3.785776662873607e-05, 'epoch': 0.7285340022758358, 'step': 4045000}
INFO:transformers.trainer:{'loss': 4.775885638237, 'learning_rate': 3.785626573462343e-05, 'epoch': 0.7286240559225942, 'step': 4045500}
INFO:transformers.trainer:{'loss': 4.833843378067017, 'learning_rate': 3.785476484051079e-05, 'epoch': 0.7287141095693527, 'step': 4046000}
INFO:transformers.trainer:{'loss': 4.767002932071685, 'learning_rate': 3.785326394639815e-05, 'epoch': 0.7288041632161111, 'step': 4046500}
INFO:transformers.trainer:{'loss': 4.795148720741272, 'learning_rate': 3.785176305228551e-05, 'epoch': 0.7288942168628696, 'step': 4047000}
INFO:transformers.trainer:{'loss': 4.783460240364075, 'learning_rate': 3.785026215817287e-05, 'epoch': 0.728984270509628, 'step': 4047500}
INFO:transformers.trainer:{'loss': 4.79286200094223, 'learning_rate': 3.784876126406023e-05, 'epoch': 0.7290743241563864, 'step': 4048000}
INFO:transformers.trainer:{'loss': 4.764382834911347, 'learning_rate': 3.7847260369947586e-05, 'epoch': 0.7291643778031449, 'step': 4048500}
INFO:transformers.trainer:{'loss': 4.663161149024964, 'learning_rate': 3.7845759475834945e-05, 'epoch': 0.7292544314499033, 'step': 4049000}
INFO:transformers.trainer:{'loss': 4.6655618073940275, 'learning_rate': 3.7844258581722304e-05, 'epoch': 0.7293444850966618, 'step': 4049500}
INFO:transformers.trainer:{'loss': 4.724347100496292, 'learning_rate': 3.784275768760966e-05, 'epoch': 0.7294345387434202, 'step': 4050000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4050000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4050000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4050000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-3950000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.738441026687622, 'learning_rate': 3.784125679349703e-05, 'epoch': 0.7295245923901786, 'step': 4050500}
INFO:transformers.trainer:{'loss': 4.791479329586029, 'learning_rate': 3.783975589938438e-05, 'epoch': 0.7296146460369372, 'step': 4051000}
INFO:transformers.trainer:{'loss': 4.834666054725647, 'learning_rate': 3.783825500527175e-05, 'epoch': 0.7297046996836956, 'step': 4051500}
INFO:transformers.trainer:{'loss': 4.696818815231323, 'learning_rate': 3.78367541111591e-05, 'epoch': 0.7297947533304541, 'step': 4052000}
INFO:transformers.trainer:{'loss': 4.667349921703338, 'learning_rate': 3.7835253217046465e-05, 'epoch': 0.7298848069772125, 'step': 4052500}
INFO:transformers.trainer:{'loss': 4.762604696512223, 'learning_rate': 3.783375232293382e-05, 'epoch': 0.7299748606239709, 'step': 4053000}
INFO:transformers.trainer:{'loss': 4.824105161190033, 'learning_rate': 3.783225142882118e-05, 'epoch': 0.7300649142707294, 'step': 4053500}
INFO:transformers.trainer:{'loss': 4.79926874256134, 'learning_rate': 3.7830750534708535e-05, 'epoch': 0.7301549679174878, 'step': 4054000}
INFO:transformers.trainer:{'loss': 4.802255784988403, 'learning_rate': 3.78292496405959e-05, 'epoch': 0.7302450215642462, 'step': 4054500}
INFO:transformers.trainer:{'loss': 4.717287333488464, 'learning_rate': 3.7827748746483253e-05, 'epoch': 0.7303350752110047, 'step': 4055000}
INFO:transformers.trainer:{'loss': 4.76407066822052, 'learning_rate': 3.782624785237062e-05, 'epoch': 0.7304251288577631, 'step': 4055500}
INFO:transformers.trainer:{'loss': 4.794909908771515, 'learning_rate': 3.782474695825797e-05, 'epoch': 0.7305151825045216, 'step': 4056000}
INFO:transformers.trainer:{'loss': 4.758067679643631, 'learning_rate': 3.782324606414534e-05, 'epoch': 0.73060523615128, 'step': 4056500}
INFO:transformers.trainer:{'loss': 4.892230628490448, 'learning_rate': 3.7821745170032696e-05, 'epoch': 0.7306952897980384, 'step': 4057000}
INFO:transformers.trainer:{'loss': 4.772493387699127, 'learning_rate': 3.7820244275920055e-05, 'epoch': 0.730785343444797, 'step': 4057500}
INFO:transformers.trainer:{'loss': 4.8050544285774235, 'learning_rate': 3.7818743381807415e-05, 'epoch': 0.7308753970915554, 'step': 4058000}
INFO:transformers.trainer:{'loss': 4.812865876197815, 'learning_rate': 3.7817242487694774e-05, 'epoch': 0.7309654507383139, 'step': 4058500}
INFO:transformers.trainer:{'loss': 4.824295001506806, 'learning_rate': 3.781574159358213e-05, 'epoch': 0.7310555043850723, 'step': 4059000}
INFO:transformers.trainer:{'loss': 4.77436412858963, 'learning_rate': 3.781424069946949e-05, 'epoch': 0.7311455580318307, 'step': 4059500}
INFO:transformers.trainer:{'loss': 4.732439476966858, 'learning_rate': 3.781273980535685e-05, 'epoch': 0.7312356116785892, 'step': 4060000}
INFO:transformers.trainer:{'loss': 4.775685494422913, 'learning_rate': 3.781123891124421e-05, 'epoch': 0.7313256653253476, 'step': 4060500}
INFO:transformers.trainer:{'loss': 4.688268402576447, 'learning_rate': 3.780973801713157e-05, 'epoch': 0.7314157189721061, 'step': 4061000}
INFO:transformers.trainer:{'loss': 4.821826479911804, 'learning_rate': 3.780823712301893e-05, 'epoch': 0.7315057726188645, 'step': 4061500}
INFO:transformers.trainer:{'loss': 4.773071290969849, 'learning_rate': 3.780673622890629e-05, 'epoch': 0.7315958262656229, 'step': 4062000}
INFO:transformers.trainer:{'loss': 4.806042937755585, 'learning_rate': 3.7805235334793646e-05, 'epoch': 0.7316858799123814, 'step': 4062500}
INFO:transformers.trainer:{'loss': 4.735265778064727, 'learning_rate': 3.7803734440681005e-05, 'epoch': 0.7317759335591398, 'step': 4063000}
INFO:transformers.trainer:{'loss': 4.7610727939605715, 'learning_rate': 3.7802233546568364e-05, 'epoch': 0.7318659872058983, 'step': 4063500}
INFO:transformers.trainer:{'loss': 4.67063459444046, 'learning_rate': 3.780073265245572e-05, 'epoch': 0.7319560408526568, 'step': 4064000}
INFO:transformers.trainer:{'loss': 4.800228766918182, 'learning_rate': 3.779923175834308e-05, 'epoch': 0.7320460944994152, 'step': 4064500}
INFO:transformers.trainer:{'loss': 4.708686500549317, 'learning_rate': 3.779773086423044e-05, 'epoch': 0.7321361481461737, 'step': 4065000}
INFO:transformers.trainer:{'loss': 4.786784759998321, 'learning_rate': 3.77962299701178e-05, 'epoch': 0.7322262017929321, 'step': 4065500}
INFO:transformers.trainer:{'loss': 4.761107034683228, 'learning_rate': 3.779472907600516e-05, 'epoch': 0.7323162554396905, 'step': 4066000}
INFO:transformers.trainer:{'loss': 4.75645176744461, 'learning_rate': 3.779322818189252e-05, 'epoch': 0.732406309086449, 'step': 4066500}
INFO:transformers.trainer:{'loss': 4.857569241285324, 'learning_rate': 3.779172728777988e-05, 'epoch': 0.7324963627332074, 'step': 4067000}
INFO:transformers.trainer:{'loss': 4.767152119636536, 'learning_rate': 3.7790226393667236e-05, 'epoch': 0.7325864163799659, 'step': 4067500}
INFO:transformers.trainer:{'loss': 4.685865731716156, 'learning_rate': 3.7788725499554596e-05, 'epoch': 0.7326764700267243, 'step': 4068000}
INFO:transformers.trainer:{'loss': 4.734836999893188, 'learning_rate': 3.7787224605441955e-05, 'epoch': 0.7327665236734827, 'step': 4068500}
INFO:transformers.trainer:{'loss': 4.652226787567138, 'learning_rate': 3.7785723711329314e-05, 'epoch': 0.7328565773202412, 'step': 4069000}
INFO:transformers.trainer:{'loss': 4.6782666015625, 'learning_rate': 3.778422281721667e-05, 'epoch': 0.7329466309669996, 'step': 4069500}
INFO:transformers.trainer:{'loss': 4.725706710815429, 'learning_rate': 3.778272192310403e-05, 'epoch': 0.7330366846137581, 'step': 4070000}
INFO:transformers.trainer:{'loss': 4.806376326084137, 'learning_rate': 3.778122102899139e-05, 'epoch': 0.7331267382605166, 'step': 4070500}
INFO:transformers.trainer:{'loss': 4.6846018207073215, 'learning_rate': 3.7779720134878757e-05, 'epoch': 0.733216791907275, 'step': 4071000}
INFO:transformers.trainer:{'loss': 4.650643014907837, 'learning_rate': 3.777821924076611e-05, 'epoch': 0.7333068455540335, 'step': 4071500}
INFO:transformers.trainer:{'loss': 4.633768667697907, 'learning_rate': 3.7776718346653475e-05, 'epoch': 0.7333968992007919, 'step': 4072000}
INFO:transformers.trainer:{'loss': 4.764341074943543, 'learning_rate': 3.777521745254083e-05, 'epoch': 0.7334869528475504, 'step': 4072500}
INFO:transformers.trainer:{'loss': 4.696309655666352, 'learning_rate': 3.777371655842819e-05, 'epoch': 0.7335770064943088, 'step': 4073000}
INFO:transformers.trainer:{'loss': 4.676766181468964, 'learning_rate': 3.7772215664315545e-05, 'epoch': 0.7336670601410672, 'step': 4073500}
INFO:transformers.trainer:{'loss': 4.644357744216919, 'learning_rate': 3.777071477020291e-05, 'epoch': 0.7337571137878257, 'step': 4074000}
INFO:transformers.trainer:{'loss': 4.682004536390305, 'learning_rate': 3.776921387609026e-05, 'epoch': 0.7338471674345841, 'step': 4074500}
INFO:transformers.trainer:{'loss': 4.6953006093502045, 'learning_rate': 3.776771298197763e-05, 'epoch': 0.7339372210813426, 'step': 4075000}
INFO:transformers.trainer:{'loss': 4.762231125831604, 'learning_rate': 3.776621208786498e-05, 'epoch': 0.734027274728101, 'step': 4075500}
INFO:transformers.trainer:{'loss': 4.776403077602387, 'learning_rate': 3.776471119375235e-05, 'epoch': 0.7341173283748594, 'step': 4076000}
INFO:transformers.trainer:{'loss': 4.839259447574616, 'learning_rate': 3.77632102996397e-05, 'epoch': 0.734207382021618, 'step': 4076500}
INFO:transformers.trainer:{'loss': 4.795982594013214, 'learning_rate': 3.7761709405527065e-05, 'epoch': 0.7342974356683764, 'step': 4077000}
INFO:transformers.trainer:{'loss': 4.746114708900452, 'learning_rate': 3.776020851141442e-05, 'epoch': 0.7343874893151349, 'step': 4077500}
INFO:transformers.trainer:{'loss': 4.78358296251297, 'learning_rate': 3.775870761730178e-05, 'epoch': 0.7344775429618933, 'step': 4078000}
INFO:transformers.trainer:{'loss': 4.796655358314514, 'learning_rate': 3.775720672318914e-05, 'epoch': 0.7345675966086517, 'step': 4078500}
INFO:transformers.trainer:{'loss': 4.769048673152923, 'learning_rate': 3.77557058290765e-05, 'epoch': 0.7346576502554102, 'step': 4079000}
INFO:transformers.trainer:{'loss': 4.795032098293304, 'learning_rate': 3.775420493496386e-05, 'epoch': 0.7347477039021686, 'step': 4079500}
INFO:transformers.trainer:{'loss': 4.732264883518219, 'learning_rate': 3.775270404085122e-05, 'epoch': 0.734837757548927, 'step': 4080000}
INFO:transformers.trainer:{'loss': 4.7195049533844, 'learning_rate': 3.775120314673858e-05, 'epoch': 0.7349278111956855, 'step': 4080500}
INFO:transformers.trainer:{'loss': 4.7184919910430905, 'learning_rate': 3.774970225262594e-05, 'epoch': 0.7350178648424439, 'step': 4081000}
INFO:transformers.trainer:{'loss': 4.664584043502807, 'learning_rate': 3.77482013585133e-05, 'epoch': 0.7351079184892024, 'step': 4081500}
INFO:transformers.trainer:{'loss': 4.731965540885925, 'learning_rate': 3.7746700464400656e-05, 'epoch': 0.7351979721359608, 'step': 4082000}
INFO:transformers.trainer:{'loss': 4.708959985256195, 'learning_rate': 3.7745199570288015e-05, 'epoch': 0.7352880257827192, 'step': 4082500}
INFO:transformers.trainer:{'loss': 4.775590820550919, 'learning_rate': 3.7743698676175374e-05, 'epoch': 0.7353780794294777, 'step': 4083000}
INFO:transformers.trainer:{'loss': 4.799109930515289, 'learning_rate': 3.774219778206273e-05, 'epoch': 0.7354681330762362, 'step': 4083500}
INFO:transformers.trainer:{'loss': 4.795502881526947, 'learning_rate': 3.774069688795009e-05, 'epoch': 0.7355581867229947, 'step': 4084000}
INFO:transformers.trainer:{'loss': 4.780586412906647, 'learning_rate': 3.773919599383745e-05, 'epoch': 0.7356482403697531, 'step': 4084500}
INFO:transformers.trainer:{'loss': 4.795672752141953, 'learning_rate': 3.773769509972481e-05, 'epoch': 0.7357382940165115, 'step': 4085000}
INFO:transformers.trainer:{'loss': 4.719631970405579, 'learning_rate': 3.773619420561217e-05, 'epoch': 0.73582834766327, 'step': 4085500}
INFO:transformers.trainer:{'loss': 4.7334628591537475, 'learning_rate': 3.773469331149953e-05, 'epoch': 0.7359184013100284, 'step': 4086000}
INFO:transformers.trainer:{'loss': 4.743764912605285, 'learning_rate': 3.773319241738689e-05, 'epoch': 0.7360084549567869, 'step': 4086500}
INFO:transformers.trainer:{'loss': 4.710273181438446, 'learning_rate': 3.7731691523274246e-05, 'epoch': 0.7360985086035453, 'step': 4087000}
INFO:transformers.trainer:{'loss': 4.667479328155517, 'learning_rate': 3.7730190629161605e-05, 'epoch': 0.7361885622503037, 'step': 4087500}
INFO:transformers.trainer:{'loss': 4.732599509239197, 'learning_rate': 3.7728689735048964e-05, 'epoch': 0.7362786158970622, 'step': 4088000}
INFO:transformers.trainer:{'loss': 4.722569225311279, 'learning_rate': 3.772718884093632e-05, 'epoch': 0.7363686695438206, 'step': 4088500}
INFO:transformers.trainer:{'loss': 4.771708686828613, 'learning_rate': 3.772568794682368e-05, 'epoch': 0.7364587231905791, 'step': 4089000}
INFO:transformers.trainer:{'loss': 4.814593292236328, 'learning_rate': 3.772418705271104e-05, 'epoch': 0.7365487768373375, 'step': 4089500}
INFO:transformers.trainer:{'loss': 4.790917562961578, 'learning_rate': 3.77226861585984e-05, 'epoch': 0.736638830484096, 'step': 4090000}
INFO:transformers.trainer:{'loss': 4.722128922462463, 'learning_rate': 3.772118526448576e-05, 'epoch': 0.7367288841308545, 'step': 4090500}
INFO:transformers.trainer:{'loss': 4.827245597362518, 'learning_rate': 3.771968437037312e-05, 'epoch': 0.7368189377776129, 'step': 4091000}
INFO:transformers.trainer:{'loss': 4.814199212551117, 'learning_rate': 3.7718183476260484e-05, 'epoch': 0.7369089914243713, 'step': 4091500}
INFO:transformers.trainer:{'loss': 4.78699535036087, 'learning_rate': 3.771668258214784e-05, 'epoch': 0.7369990450711298, 'step': 4092000}
INFO:transformers.trainer:{'loss': 4.7595396580696105, 'learning_rate': 3.77151816880352e-05, 'epoch': 0.7370890987178882, 'step': 4092500}
INFO:transformers.trainer:{'loss': 4.785485573768616, 'learning_rate': 3.7713680793922555e-05, 'epoch': 0.7371791523646467, 'step': 4093000}
INFO:transformers.trainer:{'loss': 4.876745753765106, 'learning_rate': 3.771217989980992e-05, 'epoch': 0.7372692060114051, 'step': 4093500}
INFO:transformers.trainer:{'loss': 4.772447817325592, 'learning_rate': 3.771067900569727e-05, 'epoch': 0.7373592596581635, 'step': 4094000}
INFO:transformers.trainer:{'loss': 4.7593928804397585, 'learning_rate': 3.770917811158464e-05, 'epoch': 0.737449313304922, 'step': 4094500}
INFO:transformers.trainer:{'loss': 4.805238061904907, 'learning_rate': 3.770767721747199e-05, 'epoch': 0.7375393669516804, 'step': 4095000}
INFO:transformers.trainer:{'loss': 4.820041216850281, 'learning_rate': 3.770617632335936e-05, 'epoch': 0.737629420598439, 'step': 4095500}
INFO:transformers.trainer:{'loss': 4.749314338684082, 'learning_rate': 3.770467542924671e-05, 'epoch': 0.7377194742451973, 'step': 4096000}
INFO:transformers.trainer:{'loss': 4.803427155017853, 'learning_rate': 3.7703174535134075e-05, 'epoch': 0.7378095278919558, 'step': 4096500}
INFO:transformers.trainer:{'loss': 4.749292138576507, 'learning_rate': 3.770167364102143e-05, 'epoch': 0.7378995815387143, 'step': 4097000}
INFO:transformers.trainer:{'loss': 4.84401314163208, 'learning_rate': 3.770017274690879e-05, 'epoch': 0.7379896351854727, 'step': 4097500}
INFO:transformers.trainer:{'loss': 4.719861292839051, 'learning_rate': 3.7698671852796145e-05, 'epoch': 0.7380796888322312, 'step': 4098000}
INFO:transformers.trainer:{'loss': 4.794253855705262, 'learning_rate': 3.769717095868351e-05, 'epoch': 0.7381697424789896, 'step': 4098500}
INFO:transformers.trainer:{'loss': 4.771287314414978, 'learning_rate': 3.769567006457087e-05, 'epoch': 0.738259796125748, 'step': 4099000}
INFO:transformers.trainer:{'loss': 4.73688954782486, 'learning_rate': 3.769416917045823e-05, 'epoch': 0.7383498497725065, 'step': 4099500}
INFO:transformers.trainer:{'loss': 4.78717806482315, 'learning_rate': 3.769266827634559e-05, 'epoch': 0.7384399034192649, 'step': 4100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4100000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4000000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.77679456949234, 'learning_rate': 3.769116738223295e-05, 'epoch': 0.7385299570660234, 'step': 4100500}
INFO:transformers.trainer:{'loss': 4.731884747028351, 'learning_rate': 3.7689666488120306e-05, 'epoch': 0.7386200107127818, 'step': 4101000}
INFO:transformers.trainer:{'loss': 4.730357773303986, 'learning_rate': 3.7688165594007665e-05, 'epoch': 0.7387100643595402, 'step': 4101500}
INFO:transformers.trainer:{'loss': 4.702776096343994, 'learning_rate': 3.7686664699895024e-05, 'epoch': 0.7388001180062987, 'step': 4102000}
INFO:transformers.trainer:{'loss': 4.782775704860687, 'learning_rate': 3.7685163805782384e-05, 'epoch': 0.7388901716530571, 'step': 4102500}
INFO:transformers.trainer:{'loss': 4.727982339859008, 'learning_rate': 3.768366291166974e-05, 'epoch': 0.7389802252998156, 'step': 4103000}
INFO:transformers.trainer:{'loss': 4.7219219756126405, 'learning_rate': 3.76821620175571e-05, 'epoch': 0.7390702789465741, 'step': 4103500}
INFO:transformers.trainer:{'loss': 4.828482218742371, 'learning_rate': 3.768066112344446e-05, 'epoch': 0.7391603325933325, 'step': 4104000}
INFO:transformers.trainer:{'loss': 4.785435988426208, 'learning_rate': 3.767916022933182e-05, 'epoch': 0.739250386240091, 'step': 4104500}
INFO:transformers.trainer:{'loss': 4.819735228061676, 'learning_rate': 3.767765933521918e-05, 'epoch': 0.7393404398868494, 'step': 4105000}
INFO:transformers.trainer:{'loss': 4.787005542755127, 'learning_rate': 3.767615844110654e-05, 'epoch': 0.7394304935336078, 'step': 4105500}
INFO:transformers.trainer:{'loss': 4.768815520763397, 'learning_rate': 3.76746575469939e-05, 'epoch': 0.7395205471803663, 'step': 4106000}
INFO:transformers.trainer:{'loss': 4.760544736385345, 'learning_rate': 3.7673156652881256e-05, 'epoch': 0.7396106008271247, 'step': 4106500}
INFO:transformers.trainer:{'loss': 4.779560829162597, 'learning_rate': 3.7671655758768615e-05, 'epoch': 0.7397006544738832, 'step': 4107000}
INFO:transformers.trainer:{'loss': 4.720456921100617, 'learning_rate': 3.7670154864655974e-05, 'epoch': 0.7397907081206416, 'step': 4107500}
INFO:transformers.trainer:{'loss': 4.6953893246650695, 'learning_rate': 3.766865397054333e-05, 'epoch': 0.7398807617674, 'step': 4108000}
INFO:transformers.trainer:{'loss': 4.727055692434311, 'learning_rate': 3.766715307643069e-05, 'epoch': 0.7399708154141585, 'step': 4108500}
INFO:transformers.trainer:{'loss': 4.800129663467407, 'learning_rate': 3.766565218231805e-05, 'epoch': 0.740060869060917, 'step': 4109000}
INFO:transformers.trainer:{'loss': 4.9212432403564454, 'learning_rate': 3.766415128820541e-05, 'epoch': 0.7401509227076755, 'step': 4109500}
INFO:transformers.trainer:{'loss': 4.8262358751297, 'learning_rate': 3.766265039409277e-05, 'epoch': 0.7402409763544339, 'step': 4110000}
INFO:transformers.trainer:{'loss': 4.7782530865669255, 'learning_rate': 3.766114949998013e-05, 'epoch': 0.7403310300011923, 'step': 4110500}
INFO:transformers.trainer:{'loss': 4.755886900424957, 'learning_rate': 3.765964860586749e-05, 'epoch': 0.7404210836479508, 'step': 4111000}
INFO:transformers.trainer:{'loss': 4.787528680801391, 'learning_rate': 3.7658147711754846e-05, 'epoch': 0.7405111372947092, 'step': 4111500}
INFO:transformers.trainer:{'loss': 4.7794348335266115, 'learning_rate': 3.7656646817642205e-05, 'epoch': 0.7406011909414677, 'step': 4112000}
INFO:transformers.trainer:{'loss': 4.746130959510803, 'learning_rate': 3.7655145923529565e-05, 'epoch': 0.7406912445882261, 'step': 4112500}
INFO:transformers.trainer:{'loss': 4.776907955646515, 'learning_rate': 3.765364502941693e-05, 'epoch': 0.7407812982349845, 'step': 4113000}
INFO:transformers.trainer:{'loss': 4.7526636333465575, 'learning_rate': 3.765214413530428e-05, 'epoch': 0.740871351881743, 'step': 4113500}
INFO:transformers.trainer:{'loss': 4.8174889926910405, 'learning_rate': 3.765064324119165e-05, 'epoch': 0.7409614055285014, 'step': 4114000}
INFO:transformers.trainer:{'loss': 4.662782981872558, 'learning_rate': 3.7649142347079e-05, 'epoch': 0.7410514591752599, 'step': 4114500}
INFO:transformers.trainer:{'loss': 4.669856116294861, 'learning_rate': 3.7647641452966367e-05, 'epoch': 0.7411415128220183, 'step': 4115000}
INFO:transformers.trainer:{'loss': 4.715303233623505, 'learning_rate': 3.764614055885372e-05, 'epoch': 0.7412315664687767, 'step': 4115500}
INFO:transformers.trainer:{'loss': 4.811622261047363, 'learning_rate': 3.7644639664741085e-05, 'epoch': 0.7413216201155353, 'step': 4116000}
INFO:transformers.trainer:{'loss': 4.821430690526962, 'learning_rate': 3.764313877062844e-05, 'epoch': 0.7414116737622937, 'step': 4116500}
INFO:transformers.trainer:{'loss': 4.763604009151459, 'learning_rate': 3.76416378765158e-05, 'epoch': 0.7415017274090521, 'step': 4117000}
INFO:transformers.trainer:{'loss': 4.745849345207215, 'learning_rate': 3.7640136982403155e-05, 'epoch': 0.7415917810558106, 'step': 4117500}
INFO:transformers.trainer:{'loss': 4.817988868713379, 'learning_rate': 3.763863608829052e-05, 'epoch': 0.741681834702569, 'step': 4118000}
INFO:transformers.trainer:{'loss': 4.656480434417724, 'learning_rate': 3.763713519417787e-05, 'epoch': 0.7417718883493275, 'step': 4118500}
INFO:transformers.trainer:{'loss': 4.672573991298676, 'learning_rate': 3.763563430006524e-05, 'epoch': 0.7418619419960859, 'step': 4119000}
INFO:transformers.trainer:{'loss': 4.605718149423599, 'learning_rate': 3.76341334059526e-05, 'epoch': 0.7419519956428443, 'step': 4119500}
INFO:transformers.trainer:{'loss': 4.648976241111756, 'learning_rate': 3.763263251183996e-05, 'epoch': 0.7420420492896028, 'step': 4120000}
INFO:transformers.trainer:{'loss': 4.647824793338776, 'learning_rate': 3.7631131617727316e-05, 'epoch': 0.7421321029363612, 'step': 4120500}
INFO:transformers.trainer:{'loss': 4.780895511627198, 'learning_rate': 3.7629630723614675e-05, 'epoch': 0.7422221565831197, 'step': 4121000}
INFO:transformers.trainer:{'loss': 4.7586592655181885, 'learning_rate': 3.7628129829502034e-05, 'epoch': 0.7423122102298781, 'step': 4121500}
INFO:transformers.trainer:{'loss': 4.704138923168182, 'learning_rate': 3.762662893538939e-05, 'epoch': 0.7424022638766365, 'step': 4122000}
INFO:transformers.trainer:{'loss': 4.699646990776062, 'learning_rate': 3.762512804127675e-05, 'epoch': 0.7424923175233951, 'step': 4122500}
INFO:transformers.trainer:{'loss': 4.58969219827652, 'learning_rate': 3.762362714716411e-05, 'epoch': 0.7425823711701535, 'step': 4123000}
INFO:transformers.trainer:{'loss': 4.517447926044464, 'learning_rate': 3.762212625305147e-05, 'epoch': 0.742672424816912, 'step': 4123500}
INFO:transformers.trainer:{'loss': 4.693193763256073, 'learning_rate': 3.762062535893883e-05, 'epoch': 0.7427624784636704, 'step': 4124000}
INFO:transformers.trainer:{'loss': 4.662442985534668, 'learning_rate': 3.761912446482619e-05, 'epoch': 0.7428525321104288, 'step': 4124500}
INFO:transformers.trainer:{'loss': 4.678431176662445, 'learning_rate': 3.761762357071355e-05, 'epoch': 0.7429425857571873, 'step': 4125000}
INFO:transformers.trainer:{'loss': 4.552971809148788, 'learning_rate': 3.7616122676600907e-05, 'epoch': 0.7430326394039457, 'step': 4125500}
INFO:transformers.trainer:{'loss': 4.595418866634369, 'learning_rate': 3.7614621782488266e-05, 'epoch': 0.7431226930507042, 'step': 4126000}
INFO:transformers.trainer:{'loss': 4.65745946931839, 'learning_rate': 3.7613120888375625e-05, 'epoch': 0.7432127466974626, 'step': 4126500}
INFO:transformers.trainer:{'loss': 4.624184684276581, 'learning_rate': 3.7611619994262984e-05, 'epoch': 0.743302800344221, 'step': 4127000}
INFO:transformers.trainer:{'loss': 4.647787671327591, 'learning_rate': 3.761011910015034e-05, 'epoch': 0.7433928539909795, 'step': 4127500}
INFO:transformers.trainer:{'loss': 4.558036541461944, 'learning_rate': 3.76086182060377e-05, 'epoch': 0.7434829076377379, 'step': 4128000}
INFO:transformers.trainer:{'loss': 4.515491744995117, 'learning_rate': 3.760711731192506e-05, 'epoch': 0.7435729612844963, 'step': 4128500}
INFO:transformers.trainer:{'loss': 4.50266977596283, 'learning_rate': 3.760561641781242e-05, 'epoch': 0.7436630149312549, 'step': 4129000}
INFO:transformers.trainer:{'loss': 4.554406099319458, 'learning_rate': 3.760411552369978e-05, 'epoch': 0.7437530685780133, 'step': 4129500}
INFO:transformers.trainer:{'loss': 4.747343104839325, 'learning_rate': 3.760261462958714e-05, 'epoch': 0.7438431222247718, 'step': 4130000}
INFO:transformers.trainer:{'loss': 4.71827285528183, 'learning_rate': 3.76011137354745e-05, 'epoch': 0.7439331758715302, 'step': 4130500}
INFO:transformers.trainer:{'loss': 4.7025152459144595, 'learning_rate': 3.7599612841361856e-05, 'epoch': 0.7440232295182886, 'step': 4131000}
INFO:transformers.trainer:{'loss': 4.780547828674316, 'learning_rate': 3.7598111947249215e-05, 'epoch': 0.7441132831650471, 'step': 4131500}
INFO:transformers.trainer:{'loss': 4.689792000770569, 'learning_rate': 3.7596611053136574e-05, 'epoch': 0.7442033368118055, 'step': 4132000}
INFO:transformers.trainer:{'loss': 4.612635923862458, 'learning_rate': 3.759511015902393e-05, 'epoch': 0.744293390458564, 'step': 4132500}
INFO:transformers.trainer:{'loss': 4.660368493556977, 'learning_rate': 3.759360926491129e-05, 'epoch': 0.7443834441053224, 'step': 4133000}
INFO:transformers.trainer:{'loss': 4.7322972528934475, 'learning_rate': 3.759210837079866e-05, 'epoch': 0.7444734977520808, 'step': 4133500}
INFO:transformers.trainer:{'loss': 4.708534668922424, 'learning_rate': 3.759060747668601e-05, 'epoch': 0.7445635513988393, 'step': 4134000}
INFO:transformers.trainer:{'loss': 4.753034272193909, 'learning_rate': 3.7589106582573376e-05, 'epoch': 0.7446536050455977, 'step': 4134500}
INFO:transformers.trainer:{'loss': 4.79603987121582, 'learning_rate': 3.758760568846073e-05, 'epoch': 0.7447436586923563, 'step': 4135000}
INFO:transformers.trainer:{'loss': 4.734045281410217, 'learning_rate': 3.7586104794348094e-05, 'epoch': 0.7448337123391147, 'step': 4135500}
INFO:transformers.trainer:{'loss': 4.7567525100708, 'learning_rate': 3.758460390023545e-05, 'epoch': 0.7449237659858731, 'step': 4136000}
INFO:transformers.trainer:{'loss': 4.788767191410065, 'learning_rate': 3.758310300612281e-05, 'epoch': 0.7450138196326316, 'step': 4136500}
INFO:transformers.trainer:{'loss': 4.741825071811676, 'learning_rate': 3.7581602112010165e-05, 'epoch': 0.74510387327939, 'step': 4137000}
INFO:transformers.trainer:{'loss': 4.783484177589417, 'learning_rate': 3.758010121789753e-05, 'epoch': 0.7451939269261485, 'step': 4137500}
INFO:transformers.trainer:{'loss': 4.754475067138672, 'learning_rate': 3.757860032378488e-05, 'epoch': 0.7452839805729069, 'step': 4138000}
INFO:transformers.trainer:{'loss': 4.684849251270294, 'learning_rate': 3.757709942967225e-05, 'epoch': 0.7453740342196653, 'step': 4138500}
INFO:transformers.trainer:{'loss': 4.686908174037933, 'learning_rate': 3.75755985355596e-05, 'epoch': 0.7454640878664238, 'step': 4139000}
INFO:transformers.trainer:{'loss': 4.752619208812714, 'learning_rate': 3.757409764144697e-05, 'epoch': 0.7455541415131822, 'step': 4139500}
INFO:transformers.trainer:{'loss': 4.673901093006134, 'learning_rate': 3.7572596747334326e-05, 'epoch': 0.7456441951599406, 'step': 4140000}
INFO:transformers.trainer:{'loss': 4.7027942888736725, 'learning_rate': 3.7571095853221685e-05, 'epoch': 0.7457342488066991, 'step': 4140500}
INFO:transformers.trainer:{'loss': 4.679858915328979, 'learning_rate': 3.7569594959109044e-05, 'epoch': 0.7458243024534575, 'step': 4141000}
INFO:transformers.trainer:{'loss': 4.743278014183044, 'learning_rate': 3.75680940649964e-05, 'epoch': 0.7459143561002161, 'step': 4141500}
INFO:transformers.trainer:{'loss': 4.763517502784729, 'learning_rate': 3.756659317088376e-05, 'epoch': 0.7460044097469745, 'step': 4142000}
INFO:transformers.trainer:{'loss': 4.698701695680619, 'learning_rate': 3.756509227677112e-05, 'epoch': 0.7460944633937329, 'step': 4142500}
INFO:transformers.trainer:{'loss': 4.670105805873871, 'learning_rate': 3.756359138265848e-05, 'epoch': 0.7461845170404914, 'step': 4143000}
INFO:transformers.trainer:{'loss': 4.722522783279419, 'learning_rate': 3.756209048854584e-05, 'epoch': 0.7462745706872498, 'step': 4143500}
INFO:transformers.trainer:{'loss': 4.728721898555755, 'learning_rate': 3.75605895944332e-05, 'epoch': 0.7463646243340083, 'step': 4144000}
INFO:transformers.trainer:{'loss': 4.683064037799835, 'learning_rate': 3.755908870032056e-05, 'epoch': 0.7464546779807667, 'step': 4144500}
INFO:transformers.trainer:{'loss': 4.7580807309150694, 'learning_rate': 3.7557587806207916e-05, 'epoch': 0.7465447316275251, 'step': 4145000}
INFO:transformers.trainer:{'loss': 4.742801379203796, 'learning_rate': 3.7556086912095275e-05, 'epoch': 0.7466347852742836, 'step': 4145500}
INFO:transformers.trainer:{'loss': 4.83028589296341, 'learning_rate': 3.7554586017982634e-05, 'epoch': 0.746724838921042, 'step': 4146000}
INFO:transformers.trainer:{'loss': 4.794107478141784, 'learning_rate': 3.7553085123869993e-05, 'epoch': 0.7468148925678005, 'step': 4146500}
INFO:transformers.trainer:{'loss': 4.709511369466782, 'learning_rate': 3.755158422975735e-05, 'epoch': 0.7469049462145589, 'step': 4147000}
INFO:transformers.trainer:{'loss': 4.69355484342575, 'learning_rate': 3.755008333564471e-05, 'epoch': 0.7469949998613173, 'step': 4147500}
INFO:transformers.trainer:{'loss': 4.734365287303924, 'learning_rate': 3.754858244153207e-05, 'epoch': 0.7470850535080759, 'step': 4148000}
INFO:transformers.trainer:{'loss': 4.7084964027404785, 'learning_rate': 3.754708154741943e-05, 'epoch': 0.7471751071548343, 'step': 4148500}
INFO:transformers.trainer:{'loss': 4.725716342449188, 'learning_rate': 3.754558065330679e-05, 'epoch': 0.7472651608015928, 'step': 4149000}
INFO:transformers.trainer:{'loss': 4.679319455146789, 'learning_rate': 3.754407975919415e-05, 'epoch': 0.7473552144483512, 'step': 4149500}
INFO:transformers.trainer:{'loss': 4.6612243332862855, 'learning_rate': 3.754257886508151e-05, 'epoch': 0.7474452680951096, 'step': 4150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4050000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.764347971916199, 'learning_rate': 3.7541077970968866e-05, 'epoch': 0.7475353217418681, 'step': 4150500}
INFO:transformers.trainer:{'loss': 4.635043245792389, 'learning_rate': 3.7539577076856225e-05, 'epoch': 0.7476253753886265, 'step': 4151000}
INFO:transformers.trainer:{'loss': 4.648674676418304, 'learning_rate': 3.7538076182743584e-05, 'epoch': 0.7477154290353849, 'step': 4151500}
INFO:transformers.trainer:{'loss': 4.667126922607422, 'learning_rate': 3.753657528863094e-05, 'epoch': 0.7478054826821434, 'step': 4152000}
INFO:transformers.trainer:{'loss': 4.7139308848381045, 'learning_rate': 3.75350743945183e-05, 'epoch': 0.7478955363289018, 'step': 4152500}
INFO:transformers.trainer:{'loss': 4.793251780986786, 'learning_rate': 3.753357350040566e-05, 'epoch': 0.7479855899756603, 'step': 4153000}
INFO:transformers.trainer:{'loss': 4.8482169322967525, 'learning_rate': 3.753207260629302e-05, 'epoch': 0.7480756436224187, 'step': 4153500}
INFO:transformers.trainer:{'loss': 4.765837782382965, 'learning_rate': 3.7530571712180386e-05, 'epoch': 0.7481656972691771, 'step': 4154000}
INFO:transformers.trainer:{'loss': 4.701777163028717, 'learning_rate': 3.752907081806774e-05, 'epoch': 0.7482557509159357, 'step': 4154500}
INFO:transformers.trainer:{'loss': 4.678970624446869, 'learning_rate': 3.7527569923955104e-05, 'epoch': 0.7483458045626941, 'step': 4155000}
INFO:transformers.trainer:{'loss': 4.718891208171844, 'learning_rate': 3.7526069029842456e-05, 'epoch': 0.7484358582094526, 'step': 4155500}
INFO:transformers.trainer:{'loss': 4.757044544219971, 'learning_rate': 3.752456813572982e-05, 'epoch': 0.748525911856211, 'step': 4156000}
INFO:transformers.trainer:{'loss': 4.631787175655365, 'learning_rate': 3.7523067241617174e-05, 'epoch': 0.7486159655029694, 'step': 4156500}
INFO:transformers.trainer:{'loss': 4.693303289890289, 'learning_rate': 3.752156634750454e-05, 'epoch': 0.7487060191497279, 'step': 4157000}
INFO:transformers.trainer:{'loss': 4.661821074962616, 'learning_rate': 3.752006545339189e-05, 'epoch': 0.7487960727964863, 'step': 4157500}
INFO:transformers.trainer:{'loss': 4.680217225551605, 'learning_rate': 3.751856455927926e-05, 'epoch': 0.7488861264432448, 'step': 4158000}
INFO:transformers.trainer:{'loss': 4.665293834686279, 'learning_rate': 3.751706366516661e-05, 'epoch': 0.7489761800900032, 'step': 4158500}
INFO:transformers.trainer:{'loss': 4.739113167762756, 'learning_rate': 3.7515562771053976e-05, 'epoch': 0.7490662337367616, 'step': 4159000}
INFO:transformers.trainer:{'loss': 4.752518074989319, 'learning_rate': 3.751406187694133e-05, 'epoch': 0.7491562873835201, 'step': 4159500}
INFO:transformers.trainer:{'loss': 4.714024403095245, 'learning_rate': 3.7512560982828695e-05, 'epoch': 0.7492463410302785, 'step': 4160000}
INFO:transformers.trainer:{'loss': 4.617039872646332, 'learning_rate': 3.751106008871605e-05, 'epoch': 0.749336394677037, 'step': 4160500}
INFO:transformers.trainer:{'loss': 4.639935194730759, 'learning_rate': 3.750955919460341e-05, 'epoch': 0.7494264483237955, 'step': 4161000}
INFO:transformers.trainer:{'loss': 4.681108226776123, 'learning_rate': 3.750805830049077e-05, 'epoch': 0.7495165019705539, 'step': 4161500}
INFO:transformers.trainer:{'loss': 4.701941209793091, 'learning_rate': 3.750655740637813e-05, 'epoch': 0.7496065556173124, 'step': 4162000}
INFO:transformers.trainer:{'loss': 4.692611737251282, 'learning_rate': 3.750505651226549e-05, 'epoch': 0.7496966092640708, 'step': 4162500}
INFO:transformers.trainer:{'loss': 4.544662739753723, 'learning_rate': 3.750355561815285e-05, 'epoch': 0.7497866629108293, 'step': 4163000}
INFO:transformers.trainer:{'loss': 4.492161092996597, 'learning_rate': 3.750205472404021e-05, 'epoch': 0.7498767165575877, 'step': 4163500}
INFO:transformers.trainer:{'loss': 4.7205520913600925, 'learning_rate': 3.750055382992757e-05, 'epoch': 0.7499667702043461, 'step': 4164000}
INFO:transformers.trainer:{'loss': 4.692719980239868, 'learning_rate': 3.7499052935814926e-05, 'epoch': 0.7500568238511046, 'step': 4164500}
INFO:transformers.trainer:{'loss': 4.651312485694885, 'learning_rate': 3.7497552041702285e-05, 'epoch': 0.750146877497863, 'step': 4165000}
INFO:transformers.trainer:{'loss': 4.723948065280914, 'learning_rate': 3.7496051147589644e-05, 'epoch': 0.7502369311446214, 'step': 4165500}
INFO:transformers.trainer:{'loss': 4.80060730600357, 'learning_rate': 3.7494550253477e-05, 'epoch': 0.7503269847913799, 'step': 4166000}
INFO:transformers.trainer:{'loss': 4.717231236457825, 'learning_rate': 3.749304935936436e-05, 'epoch': 0.7504170384381383, 'step': 4166500}
INFO:transformers.trainer:{'loss': 4.673125415802002, 'learning_rate': 3.749154846525172e-05, 'epoch': 0.7505070920848969, 'step': 4167000}
INFO:transformers.trainer:{'loss': 4.757569680690765, 'learning_rate': 3.749004757113908e-05, 'epoch': 0.7505971457316553, 'step': 4167500}
INFO:transformers.trainer:{'loss': 4.672145431995392, 'learning_rate': 3.748854667702644e-05, 'epoch': 0.7506871993784137, 'step': 4168000}
INFO:transformers.trainer:{'loss': 4.661587116718292, 'learning_rate': 3.74870457829138e-05, 'epoch': 0.7507772530251722, 'step': 4168500}
INFO:transformers.trainer:{'loss': 4.500013881444931, 'learning_rate': 3.748554488880116e-05, 'epoch': 0.7508673066719306, 'step': 4169000}
INFO:transformers.trainer:{'loss': 4.450542443752289, 'learning_rate': 3.7484043994688517e-05, 'epoch': 0.7509573603186891, 'step': 4169500}
INFO:transformers.trainer:{'loss': 4.576215200424194, 'learning_rate': 3.7482543100575876e-05, 'epoch': 0.7510474139654475, 'step': 4170000}
INFO:transformers.trainer:{'loss': 4.3275972638130185, 'learning_rate': 3.7481042206463235e-05, 'epoch': 0.7511374676122059, 'step': 4170500}
INFO:transformers.trainer:{'loss': 4.615715257167816, 'learning_rate': 3.7479541312350594e-05, 'epoch': 0.7512275212589644, 'step': 4171000}
INFO:transformers.trainer:{'loss': 4.65131707406044, 'learning_rate': 3.747804041823795e-05, 'epoch': 0.7513175749057228, 'step': 4171500}
INFO:transformers.trainer:{'loss': 4.53138099193573, 'learning_rate': 3.747653952412531e-05, 'epoch': 0.7514076285524813, 'step': 4172000}
INFO:transformers.trainer:{'loss': 4.568831316471099, 'learning_rate': 3.747503863001267e-05, 'epoch': 0.7514976821992397, 'step': 4172500}
INFO:transformers.trainer:{'loss': 4.499786245822906, 'learning_rate': 3.747353773590003e-05, 'epoch': 0.7515877358459981, 'step': 4173000}
INFO:transformers.trainer:{'loss': 4.609427149772644, 'learning_rate': 3.747203684178739e-05, 'epoch': 0.7516777894927567, 'step': 4173500}
INFO:transformers.trainer:{'loss': 4.447708478450775, 'learning_rate': 3.747053594767475e-05, 'epoch': 0.7517678431395151, 'step': 4174000}
INFO:transformers.trainer:{'loss': 4.435475853919983, 'learning_rate': 3.746903505356211e-05, 'epoch': 0.7518578967862736, 'step': 4174500}
INFO:transformers.trainer:{'loss': 4.0394541435241695, 'learning_rate': 3.7467534159449466e-05, 'epoch': 0.751947950433032, 'step': 4175000}
INFO:transformers.trainer:{'loss': 4.215663248538971, 'learning_rate': 3.746603326533683e-05, 'epoch': 0.7520380040797904, 'step': 4175500}
INFO:transformers.trainer:{'loss': 4.253248923540116, 'learning_rate': 3.7464532371224184e-05, 'epoch': 0.7521280577265489, 'step': 4176000}
INFO:transformers.trainer:{'loss': 4.424461020946502, 'learning_rate': 3.746303147711155e-05, 'epoch': 0.7522181113733073, 'step': 4176500}
INFO:transformers.trainer:{'loss': 4.627710135936737, 'learning_rate': 3.74615305829989e-05, 'epoch': 0.7523081650200657, 'step': 4177000}
INFO:transformers.trainer:{'loss': 4.512249317169189, 'learning_rate': 3.746002968888627e-05, 'epoch': 0.7523982186668242, 'step': 4177500}
INFO:transformers.trainer:{'loss': 4.341642251968384, 'learning_rate': 3.745852879477362e-05, 'epoch': 0.7524882723135826, 'step': 4178000}
INFO:transformers.trainer:{'loss': 4.295215236663818, 'learning_rate': 3.7457027900660986e-05, 'epoch': 0.7525783259603411, 'step': 4178500}
INFO:transformers.trainer:{'loss': 4.522615055084229, 'learning_rate': 3.745552700654834e-05, 'epoch': 0.7526683796070995, 'step': 4179000}
INFO:transformers.trainer:{'loss': 4.152602282643318, 'learning_rate': 3.7454026112435704e-05, 'epoch': 0.7527584332538579, 'step': 4179500}
INFO:transformers.trainer:{'loss': 4.118521441936493, 'learning_rate': 3.7452525218323057e-05, 'epoch': 0.7528484869006165, 'step': 4180000}
INFO:transformers.trainer:{'loss': 4.248729681968689, 'learning_rate': 3.745102432421042e-05, 'epoch': 0.7529385405473749, 'step': 4180500}
INFO:transformers.trainer:{'loss': 4.513686986207962, 'learning_rate': 3.7449523430097775e-05, 'epoch': 0.7530285941941334, 'step': 4181000}
INFO:transformers.trainer:{'loss': 4.49531264257431, 'learning_rate': 3.744802253598514e-05, 'epoch': 0.7531186478408918, 'step': 4181500}
INFO:transformers.trainer:{'loss': 4.566468546390533, 'learning_rate': 3.74465216418725e-05, 'epoch': 0.7532087014876502, 'step': 4182000}
INFO:transformers.trainer:{'loss': 4.118454835891724, 'learning_rate': 3.744502074775986e-05, 'epoch': 0.7532987551344087, 'step': 4182500}
INFO:transformers.trainer:{'loss': 4.505743647575378, 'learning_rate': 3.744351985364722e-05, 'epoch': 0.7533888087811671, 'step': 4183000}
INFO:transformers.trainer:{'loss': 4.464195960998535, 'learning_rate': 3.744201895953458e-05, 'epoch': 0.7534788624279256, 'step': 4183500}
INFO:transformers.trainer:{'loss': 4.263638869524002, 'learning_rate': 3.7440518065421936e-05, 'epoch': 0.753568916074684, 'step': 4184000}
INFO:transformers.trainer:{'loss': 4.4230161089897155, 'learning_rate': 3.7439017171309295e-05, 'epoch': 0.7536589697214424, 'step': 4184500}
INFO:transformers.trainer:{'loss': 4.387990922927856, 'learning_rate': 3.7437516277196654e-05, 'epoch': 0.7537490233682009, 'step': 4185000}
INFO:transformers.trainer:{'loss': 4.4818783659934995, 'learning_rate': 3.743601538308401e-05, 'epoch': 0.7538390770149593, 'step': 4185500}
INFO:transformers.trainer:{'loss': 4.535742521286011, 'learning_rate': 3.743451448897137e-05, 'epoch': 0.7539291306617179, 'step': 4186000}
INFO:transformers.trainer:{'loss': 4.1883772075176235, 'learning_rate': 3.743301359485873e-05, 'epoch': 0.7540191843084763, 'step': 4186500}
INFO:transformers.trainer:{'loss': 4.338474834442139, 'learning_rate': 3.743151270074609e-05, 'epoch': 0.7541092379552347, 'step': 4187000}
INFO:transformers.trainer:{'loss': 4.623668188095093, 'learning_rate': 3.743001180663345e-05, 'epoch': 0.7541992916019932, 'step': 4187500}
INFO:transformers.trainer:{'loss': 4.430658388376236, 'learning_rate': 3.742851091252081e-05, 'epoch': 0.7542893452487516, 'step': 4188000}
INFO:transformers.trainer:{'loss': 4.3966100835800175, 'learning_rate': 3.7427010018408174e-05, 'epoch': 0.75437939889551, 'step': 4188500}
INFO:transformers.trainer:{'loss': 4.420641914606095, 'learning_rate': 3.7425509124295526e-05, 'epoch': 0.7544694525422685, 'step': 4189000}
INFO:transformers.trainer:{'loss': 4.393139707565307, 'learning_rate': 3.7424008230182885e-05, 'epoch': 0.7545595061890269, 'step': 4189500}
INFO:transformers.trainer:{'loss': 4.415184173107147, 'learning_rate': 3.7422507336070244e-05, 'epoch': 0.7546495598357854, 'step': 4190000}
INFO:transformers.trainer:{'loss': 4.3618234167099, 'learning_rate': 3.7421006441957603e-05, 'epoch': 0.7547396134825438, 'step': 4190500}
INFO:transformers.trainer:{'loss': 3.8630079753398894, 'learning_rate': 3.741950554784496e-05, 'epoch': 0.7548296671293022, 'step': 4191000}
INFO:transformers.trainer:{'loss': 4.168230478525162, 'learning_rate': 3.741800465373232e-05, 'epoch': 0.7549197207760607, 'step': 4191500}
INFO:transformers.trainer:{'loss': 4.186483820676804, 'learning_rate': 3.741650375961968e-05, 'epoch': 0.7550097744228191, 'step': 4192000}
INFO:transformers.trainer:{'loss': 3.903039446353912, 'learning_rate': 3.741500286550704e-05, 'epoch': 0.7550998280695776, 'step': 4192500}
INFO:transformers.trainer:{'loss': 4.275053878545761, 'learning_rate': 3.74135019713944e-05, 'epoch': 0.755189881716336, 'step': 4193000}
INFO:transformers.trainer:{'loss': 4.4473384115695955, 'learning_rate': 3.741200107728176e-05, 'epoch': 0.7552799353630945, 'step': 4193500}
INFO:transformers.trainer:{'loss': 4.242786071300507, 'learning_rate': 3.741050018316912e-05, 'epoch': 0.755369989009853, 'step': 4194000}
INFO:transformers.trainer:{'loss': 4.272930280208588, 'learning_rate': 3.7408999289056476e-05, 'epoch': 0.7554600426566114, 'step': 4194500}
INFO:transformers.trainer:{'loss': 4.247393550157547, 'learning_rate': 3.7407498394943835e-05, 'epoch': 0.7555500963033699, 'step': 4195000}
INFO:transformers.trainer:{'loss': 4.253967616319656, 'learning_rate': 3.7405997500831194e-05, 'epoch': 0.7556401499501283, 'step': 4195500}
INFO:transformers.trainer:{'loss': 4.326273296833039, 'learning_rate': 3.740449660671856e-05, 'epoch': 0.7557302035968867, 'step': 4196000}
INFO:transformers.trainer:{'loss': 4.299216090202331, 'learning_rate': 3.740299571260591e-05, 'epoch': 0.7558202572436452, 'step': 4196500}
INFO:transformers.trainer:{'loss': 4.272259487628936, 'learning_rate': 3.740149481849328e-05, 'epoch': 0.7559103108904036, 'step': 4197000}
INFO:transformers.trainer:{'loss': 4.461396276473999, 'learning_rate': 3.739999392438063e-05, 'epoch': 0.7560003645371621, 'step': 4197500}
INFO:transformers.trainer:{'loss': 4.597182517051697, 'learning_rate': 3.7398493030267996e-05, 'epoch': 0.7560904181839205, 'step': 4198000}
INFO:transformers.trainer:{'loss': 4.5638548617362975, 'learning_rate': 3.739699213615535e-05, 'epoch': 0.7561804718306789, 'step': 4198500}
INFO:transformers.trainer:{'loss': 4.547253136157989, 'learning_rate': 3.7395491242042714e-05, 'epoch': 0.7562705254774374, 'step': 4199000}
INFO:transformers.trainer:{'loss': 4.517186269283295, 'learning_rate': 3.7393990347930066e-05, 'epoch': 0.7563605791241959, 'step': 4199500}
INFO:transformers.trainer:{'loss': 4.414962248802185, 'learning_rate': 3.739248945381743e-05, 'epoch': 0.7564506327709544, 'step': 4200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.1713230118751525, 'learning_rate': 3.7390988559704784e-05, 'epoch': 0.7565406864177128, 'step': 4200500}
INFO:transformers.trainer:{'loss': 4.311176915168762, 'learning_rate': 3.738948766559215e-05, 'epoch': 0.7566307400644712, 'step': 4201000}
INFO:transformers.trainer:{'loss': 4.457942199230194, 'learning_rate': 3.73879867714795e-05, 'epoch': 0.7567207937112297, 'step': 4201500}
INFO:transformers.trainer:{'loss': 4.453733347415924, 'learning_rate': 3.738648587736687e-05, 'epoch': 0.7568108473579881, 'step': 4202000}
INFO:transformers.trainer:{'loss': 4.409235731601715, 'learning_rate': 3.738498498325423e-05, 'epoch': 0.7569009010047465, 'step': 4202500}
INFO:transformers.trainer:{'loss': 4.461577626228332, 'learning_rate': 3.7383484089141586e-05, 'epoch': 0.756990954651505, 'step': 4203000}
INFO:transformers.trainer:{'loss': 4.4651343894004825, 'learning_rate': 3.7381983195028945e-05, 'epoch': 0.7570810082982634, 'step': 4203500}
INFO:transformers.trainer:{'loss': 4.5194909491539, 'learning_rate': 3.7380482300916305e-05, 'epoch': 0.7571710619450219, 'step': 4204000}
INFO:transformers.trainer:{'loss': 4.350163980960846, 'learning_rate': 3.7378981406803664e-05, 'epoch': 0.7572611155917803, 'step': 4204500}
INFO:transformers.trainer:{'loss': 4.3239858939647675, 'learning_rate': 3.737748051269102e-05, 'epoch': 0.7573511692385387, 'step': 4205000}
INFO:transformers.trainer:{'loss': 4.279823517799377, 'learning_rate': 3.737597961857838e-05, 'epoch': 0.7574412228852972, 'step': 4205500}
INFO:transformers.trainer:{'loss': 4.331615889549256, 'learning_rate': 3.737447872446574e-05, 'epoch': 0.7575312765320557, 'step': 4206000}
INFO:transformers.trainer:{'loss': 4.326059058666229, 'learning_rate': 3.73729778303531e-05, 'epoch': 0.7576213301788142, 'step': 4206500}
INFO:transformers.trainer:{'loss': 4.405392074584961, 'learning_rate': 3.737147693624046e-05, 'epoch': 0.7577113838255726, 'step': 4207000}
INFO:transformers.trainer:{'loss': 4.214024007797241, 'learning_rate': 3.736997604212782e-05, 'epoch': 0.757801437472331, 'step': 4207500}
INFO:transformers.trainer:{'loss': 4.295274116277695, 'learning_rate': 3.736847514801518e-05, 'epoch': 0.7578914911190895, 'step': 4208000}
INFO:transformers.trainer:{'loss': 4.485045569419861, 'learning_rate': 3.7366974253902536e-05, 'epoch': 0.7579815447658479, 'step': 4208500}
INFO:transformers.trainer:{'loss': 4.502634312152862, 'learning_rate': 3.7365473359789895e-05, 'epoch': 0.7580715984126064, 'step': 4209000}
INFO:transformers.trainer:{'loss': 4.630041182994843, 'learning_rate': 3.7363972465677254e-05, 'epoch': 0.7581616520593648, 'step': 4209500}
INFO:transformers.trainer:{'loss': 4.597156888484955, 'learning_rate': 3.736247157156462e-05, 'epoch': 0.7582517057061232, 'step': 4210000}
INFO:transformers.trainer:{'loss': 4.430827850818634, 'learning_rate': 3.736097067745197e-05, 'epoch': 0.7583417593528817, 'step': 4210500}
INFO:transformers.trainer:{'loss': 4.480905172824859, 'learning_rate': 3.735946978333934e-05, 'epoch': 0.7584318129996401, 'step': 4211000}
INFO:transformers.trainer:{'loss': 4.5190420265197755, 'learning_rate': 3.735796888922669e-05, 'epoch': 0.7585218666463986, 'step': 4211500}
INFO:transformers.trainer:{'loss': 4.596779885292054, 'learning_rate': 3.7356467995114056e-05, 'epoch': 0.758611920293157, 'step': 4212000}
INFO:transformers.trainer:{'loss': 4.483753580570221, 'learning_rate': 3.735496710100141e-05, 'epoch': 0.7587019739399155, 'step': 4212500}
INFO:transformers.trainer:{'loss': 4.455147204875946, 'learning_rate': 3.7353466206888774e-05, 'epoch': 0.758792027586674, 'step': 4213000}
INFO:transformers.trainer:{'loss': 4.493108996629715, 'learning_rate': 3.7351965312776126e-05, 'epoch': 0.7588820812334324, 'step': 4213500}
INFO:transformers.trainer:{'loss': 4.582206959724426, 'learning_rate': 3.7350464418663486e-05, 'epoch': 0.7589721348801908, 'step': 4214000}
INFO:transformers.trainer:{'loss': 4.42140341591835, 'learning_rate': 3.7348963524550845e-05, 'epoch': 0.7590621885269493, 'step': 4214500}
INFO:transformers.trainer:{'loss': 4.4181704125404355, 'learning_rate': 3.7347462630438204e-05, 'epoch': 0.7591522421737077, 'step': 4215000}
INFO:transformers.trainer:{'loss': 4.509948174953461, 'learning_rate': 3.734596173632556e-05, 'epoch': 0.7592422958204662, 'step': 4215500}
INFO:transformers.trainer:{'loss': 4.683924787521362, 'learning_rate': 3.734446084221292e-05, 'epoch': 0.7593323494672246, 'step': 4216000}
INFO:transformers.trainer:{'loss': 4.5350965929031375, 'learning_rate': 3.734295994810029e-05, 'epoch': 0.759422403113983, 'step': 4216500}
INFO:transformers.trainer:{'loss': 4.535947853565216, 'learning_rate': 3.734145905398764e-05, 'epoch': 0.7595124567607415, 'step': 4217000}
INFO:transformers.trainer:{'loss': 4.610116682052612, 'learning_rate': 3.7339958159875006e-05, 'epoch': 0.7596025104074999, 'step': 4217500}
INFO:transformers.trainer:{'loss': 4.462932934761048, 'learning_rate': 3.733845726576236e-05, 'epoch': 0.7596925640542584, 'step': 4218000}
INFO:transformers.trainer:{'loss': 4.705862056732178, 'learning_rate': 3.7336956371649724e-05, 'epoch': 0.7597826177010168, 'step': 4218500}
INFO:transformers.trainer:{'loss': 4.429955430030823, 'learning_rate': 3.7335455477537076e-05, 'epoch': 0.7598726713477753, 'step': 4219000}
INFO:transformers.trainer:{'loss': 4.442383817672729, 'learning_rate': 3.733395458342444e-05, 'epoch': 0.7599627249945338, 'step': 4219500}
INFO:transformers.trainer:{'loss': 4.513672371864319, 'learning_rate': 3.7332453689311794e-05, 'epoch': 0.7600527786412922, 'step': 4220000}
INFO:transformers.trainer:{'loss': 4.670295545101165, 'learning_rate': 3.733095279519916e-05, 'epoch': 0.7601428322880507, 'step': 4220500}
INFO:transformers.trainer:{'loss': 4.667434277057648, 'learning_rate': 3.732945190108651e-05, 'epoch': 0.7602328859348091, 'step': 4221000}
INFO:transformers.trainer:{'loss': 4.533458577871323, 'learning_rate': 3.732795100697388e-05, 'epoch': 0.7603229395815675, 'step': 4221500}
INFO:transformers.trainer:{'loss': 4.614777736186981, 'learning_rate': 3.732645011286123e-05, 'epoch': 0.760412993228326, 'step': 4222000}
INFO:transformers.trainer:{'loss': 4.617711529970169, 'learning_rate': 3.7324949218748596e-05, 'epoch': 0.7605030468750844, 'step': 4222500}
INFO:transformers.trainer:{'loss': 4.589564939498901, 'learning_rate': 3.732344832463595e-05, 'epoch': 0.7605931005218429, 'step': 4223000}
INFO:transformers.trainer:{'loss': 4.493320227622986, 'learning_rate': 3.7321947430523314e-05, 'epoch': 0.7606831541686013, 'step': 4223500}
INFO:transformers.trainer:{'loss': 4.399495277404785, 'learning_rate': 3.732044653641067e-05, 'epoch': 0.7607732078153597, 'step': 4224000}
INFO:transformers.trainer:{'loss': 4.705951835632324, 'learning_rate': 3.731894564229803e-05, 'epoch': 0.7608632614621182, 'step': 4224500}
INFO:transformers.trainer:{'loss': 4.701118331909179, 'learning_rate': 3.731744474818539e-05, 'epoch': 0.7609533151088766, 'step': 4225000}
INFO:transformers.trainer:{'loss': 4.51830034160614, 'learning_rate': 3.731594385407275e-05, 'epoch': 0.761043368755635, 'step': 4225500}
INFO:transformers.trainer:{'loss': 4.583867514610291, 'learning_rate': 3.731444295996011e-05, 'epoch': 0.7611334224023936, 'step': 4226000}
INFO:transformers.trainer:{'loss': 4.4163134865760805, 'learning_rate': 3.731294206584747e-05, 'epoch': 0.761223476049152, 'step': 4226500}
INFO:transformers.trainer:{'loss': 4.453462135791779, 'learning_rate': 3.731144117173483e-05, 'epoch': 0.7613135296959105, 'step': 4227000}
INFO:transformers.trainer:{'loss': 4.297144459486008, 'learning_rate': 3.730994027762219e-05, 'epoch': 0.7614035833426689, 'step': 4227500}
INFO:transformers.trainer:{'loss': 4.388786631345749, 'learning_rate': 3.7308439383509546e-05, 'epoch': 0.7614936369894273, 'step': 4228000}
INFO:transformers.trainer:{'loss': 4.420004352092743, 'learning_rate': 3.7306938489396905e-05, 'epoch': 0.7615836906361858, 'step': 4228500}
INFO:transformers.trainer:{'loss': 4.420813231945038, 'learning_rate': 3.7305437595284264e-05, 'epoch': 0.7616737442829442, 'step': 4229000}
INFO:transformers.trainer:{'loss': 4.290364623308181, 'learning_rate': 3.730393670117162e-05, 'epoch': 0.7617637979297027, 'step': 4229500}
INFO:transformers.trainer:{'loss': 4.510037298202515, 'learning_rate': 3.730243580705898e-05, 'epoch': 0.7618538515764611, 'step': 4230000}
INFO:transformers.trainer:{'loss': 4.390658366918564, 'learning_rate': 3.730093491294635e-05, 'epoch': 0.7619439052232195, 'step': 4230500}
INFO:transformers.trainer:{'loss': 4.261403744935989, 'learning_rate': 3.72994340188337e-05, 'epoch': 0.762033958869978, 'step': 4231000}
INFO:transformers.trainer:{'loss': 4.111438366413116, 'learning_rate': 3.7297933124721066e-05, 'epoch': 0.7621240125167364, 'step': 4231500}
INFO:transformers.trainer:{'loss': 3.8651546008586886, 'learning_rate': 3.729643223060842e-05, 'epoch': 0.762214066163495, 'step': 4232000}
INFO:transformers.trainer:{'loss': 4.00980654668808, 'learning_rate': 3.7294931336495784e-05, 'epoch': 0.7623041198102534, 'step': 4232500}
INFO:transformers.trainer:{'loss': 4.199969681978225, 'learning_rate': 3.7293430442383136e-05, 'epoch': 0.7623941734570118, 'step': 4233000}
INFO:transformers.trainer:{'loss': 4.402797405004502, 'learning_rate': 3.72919295482705e-05, 'epoch': 0.7624842271037703, 'step': 4233500}
INFO:transformers.trainer:{'loss': 4.395393741607666, 'learning_rate': 3.7290428654157854e-05, 'epoch': 0.7625742807505287, 'step': 4234000}
INFO:transformers.trainer:{'loss': 4.320212058067321, 'learning_rate': 3.728892776004522e-05, 'epoch': 0.7626643343972872, 'step': 4234500}
INFO:transformers.trainer:{'loss': 4.374313425540924, 'learning_rate': 3.728742686593257e-05, 'epoch': 0.7627543880440456, 'step': 4235000}
INFO:transformers.trainer:{'loss': 4.298507239580155, 'learning_rate': 3.728592597181994e-05, 'epoch': 0.762844441690804, 'step': 4235500}
INFO:transformers.trainer:{'loss': 4.207892040729523, 'learning_rate': 3.728442507770729e-05, 'epoch': 0.7629344953375625, 'step': 4236000}
INFO:transformers.trainer:{'loss': 4.240048745632172, 'learning_rate': 3.7282924183594656e-05, 'epoch': 0.7630245489843209, 'step': 4236500}
INFO:transformers.trainer:{'loss': 4.317268297672272, 'learning_rate': 3.728142328948201e-05, 'epoch': 0.7631146026310794, 'step': 4237000}
INFO:transformers.trainer:{'loss': 4.509133276224136, 'learning_rate': 3.727992239536937e-05, 'epoch': 0.7632046562778378, 'step': 4237500}
INFO:transformers.trainer:{'loss': 4.497625715494156, 'learning_rate': 3.7278421501256734e-05, 'epoch': 0.7632947099245962, 'step': 4238000}
INFO:transformers.trainer:{'loss': 4.605197954177856, 'learning_rate': 3.7276920607144086e-05, 'epoch': 0.7633847635713548, 'step': 4238500}
INFO:transformers.trainer:{'loss': 4.365475522994995, 'learning_rate': 3.727541971303145e-05, 'epoch': 0.7634748172181132, 'step': 4239000}
INFO:transformers.trainer:{'loss': 4.315693923950195, 'learning_rate': 3.7273918818918804e-05, 'epoch': 0.7635648708648716, 'step': 4239500}
INFO:transformers.trainer:{'loss': 4.188239679098129, 'learning_rate': 3.727241792480617e-05, 'epoch': 0.7636549245116301, 'step': 4240000}
INFO:transformers.trainer:{'loss': 4.239578458309174, 'learning_rate': 3.727091703069352e-05, 'epoch': 0.7637449781583885, 'step': 4240500}
INFO:transformers.trainer:{'loss': 4.330741900920868, 'learning_rate': 3.726941613658089e-05, 'epoch': 0.763835031805147, 'step': 4241000}
INFO:transformers.trainer:{'loss': 4.473855297565461, 'learning_rate': 3.726791524246824e-05, 'epoch': 0.7639250854519054, 'step': 4241500}
INFO:transformers.trainer:{'loss': 4.313327123880386, 'learning_rate': 3.7266414348355606e-05, 'epoch': 0.7640151390986638, 'step': 4242000}
INFO:transformers.trainer:{'loss': 4.543215863227844, 'learning_rate': 3.726491345424296e-05, 'epoch': 0.7641051927454223, 'step': 4242500}
INFO:transformers.trainer:{'loss': 4.557667830705642, 'learning_rate': 3.7263412560130324e-05, 'epoch': 0.7641952463921807, 'step': 4243000}
INFO:transformers.trainer:{'loss': 4.325768403291702, 'learning_rate': 3.7261911666017676e-05, 'epoch': 0.7642853000389392, 'step': 4243500}
INFO:transformers.trainer:{'loss': 4.324125346899033, 'learning_rate': 3.726041077190504e-05, 'epoch': 0.7643753536856976, 'step': 4244000}
INFO:transformers.trainer:{'loss': 4.22173880147934, 'learning_rate': 3.72589098777924e-05, 'epoch': 0.764465407332456, 'step': 4244500}
INFO:transformers.trainer:{'loss': 4.357720693588257, 'learning_rate': 3.725740898367976e-05, 'epoch': 0.7645554609792146, 'step': 4245000}
INFO:transformers.trainer:{'loss': 4.686540006637573, 'learning_rate': 3.725590808956712e-05, 'epoch': 0.764645514625973, 'step': 4245500}
INFO:transformers.trainer:{'loss': 4.51628410077095, 'learning_rate': 3.725440719545448e-05, 'epoch': 0.7647355682727315, 'step': 4246000}
INFO:transformers.trainer:{'loss': 4.370817600250244, 'learning_rate': 3.725290630134184e-05, 'epoch': 0.7648256219194899, 'step': 4246500}
INFO:transformers.trainer:{'loss': 4.459902061939239, 'learning_rate': 3.7251405407229196e-05, 'epoch': 0.7649156755662483, 'step': 4247000}
INFO:transformers.trainer:{'loss': 4.481997462987899, 'learning_rate': 3.7249904513116555e-05, 'epoch': 0.7650057292130068, 'step': 4247500}
INFO:transformers.trainer:{'loss': 4.423892951011657, 'learning_rate': 3.7248403619003915e-05, 'epoch': 0.7650957828597652, 'step': 4248000}
INFO:transformers.trainer:{'loss': 4.590801644802093, 'learning_rate': 3.7246902724891274e-05, 'epoch': 0.7651858365065237, 'step': 4248500}
INFO:transformers.trainer:{'loss': 4.48864509010315, 'learning_rate': 3.724540183077863e-05, 'epoch': 0.7652758901532821, 'step': 4249000}
INFO:transformers.trainer:{'loss': 4.292479419469833, 'learning_rate': 3.724390093666599e-05, 'epoch': 0.7653659438000405, 'step': 4249500}
INFO:transformers.trainer:{'loss': 4.585209577560425, 'learning_rate': 3.724240004255335e-05, 'epoch': 0.765455997446799, 'step': 4250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.497973727703094, 'learning_rate': 3.724089914844071e-05, 'epoch': 0.7655460510935574, 'step': 4250500}
INFO:transformers.trainer:{'loss': 4.458375268220902, 'learning_rate': 3.7239398254328076e-05, 'epoch': 0.7656361047403158, 'step': 4251000}
INFO:transformers.trainer:{'loss': 4.0925016407966615, 'learning_rate': 3.723789736021543e-05, 'epoch': 0.7657261583870744, 'step': 4251500}
INFO:transformers.trainer:{'loss': 4.1694848918914795, 'learning_rate': 3.7236396466102794e-05, 'epoch': 0.7658162120338328, 'step': 4252000}
INFO:transformers.trainer:{'loss': 4.339233080863953, 'learning_rate': 3.7234895571990146e-05, 'epoch': 0.7659062656805913, 'step': 4252500}
INFO:transformers.trainer:{'loss': 4.32321023273468, 'learning_rate': 3.723339467787751e-05, 'epoch': 0.7659963193273497, 'step': 4253000}
INFO:transformers.trainer:{'loss': 4.490190520524979, 'learning_rate': 3.7231893783764864e-05, 'epoch': 0.7660863729741081, 'step': 4253500}
INFO:transformers.trainer:{'loss': 4.504133455276489, 'learning_rate': 3.723039288965223e-05, 'epoch': 0.7661764266208666, 'step': 4254000}
INFO:transformers.trainer:{'loss': 4.5674994821548465, 'learning_rate': 3.722889199553958e-05, 'epoch': 0.766266480267625, 'step': 4254500}
INFO:transformers.trainer:{'loss': 4.655090665340423, 'learning_rate': 3.722739110142695e-05, 'epoch': 0.7663565339143835, 'step': 4255000}
INFO:transformers.trainer:{'loss': 4.612732733249664, 'learning_rate': 3.72258902073143e-05, 'epoch': 0.7664465875611419, 'step': 4255500}
INFO:transformers.trainer:{'loss': 4.164563716888428, 'learning_rate': 3.7224389313201666e-05, 'epoch': 0.7665366412079003, 'step': 4256000}
INFO:transformers.trainer:{'loss': 4.400912666320801, 'learning_rate': 3.722288841908902e-05, 'epoch': 0.7666266948546588, 'step': 4256500}
INFO:transformers.trainer:{'loss': 4.379535640716552, 'learning_rate': 3.7221387524976384e-05, 'epoch': 0.7667167485014172, 'step': 4257000}
INFO:transformers.trainer:{'loss': 4.257918496608734, 'learning_rate': 3.7219886630863736e-05, 'epoch': 0.7668068021481758, 'step': 4257500}
INFO:transformers.trainer:{'loss': 4.176722095966339, 'learning_rate': 3.72183857367511e-05, 'epoch': 0.7668968557949342, 'step': 4258000}
INFO:transformers.trainer:{'loss': 4.50552210187912, 'learning_rate': 3.721688484263846e-05, 'epoch': 0.7669869094416926, 'step': 4258500}
INFO:transformers.trainer:{'loss': 4.558394745826721, 'learning_rate': 3.721538394852582e-05, 'epoch': 0.7670769630884511, 'step': 4259000}
INFO:transformers.trainer:{'loss': 4.548469937801361, 'learning_rate': 3.721388305441318e-05, 'epoch': 0.7671670167352095, 'step': 4259500}
INFO:transformers.trainer:{'loss': 4.571426916122436, 'learning_rate': 3.721238216030054e-05, 'epoch': 0.767257070381968, 'step': 4260000}
INFO:transformers.trainer:{'loss': 4.604984097957611, 'learning_rate': 3.72108812661879e-05, 'epoch': 0.7673471240287264, 'step': 4260500}
INFO:transformers.trainer:{'loss': 4.543792263746262, 'learning_rate': 3.720938037207525e-05, 'epoch': 0.7674371776754848, 'step': 4261000}
INFO:transformers.trainer:{'loss': 4.334362831354142, 'learning_rate': 3.7207879477962616e-05, 'epoch': 0.7675272313222433, 'step': 4261500}
INFO:transformers.trainer:{'loss': 4.288388153314591, 'learning_rate': 3.720637858384997e-05, 'epoch': 0.7676172849690017, 'step': 4262000}
INFO:transformers.trainer:{'loss': 4.487128374576568, 'learning_rate': 3.7204877689737334e-05, 'epoch': 0.7677073386157601, 'step': 4262500}
INFO:transformers.trainer:{'loss': 4.583741590023041, 'learning_rate': 3.7203376795624686e-05, 'epoch': 0.7677973922625186, 'step': 4263000}
INFO:transformers.trainer:{'loss': 4.531584315776825, 'learning_rate': 3.720187590151205e-05, 'epoch': 0.767887445909277, 'step': 4263500}
INFO:transformers.trainer:{'loss': 4.6614412274360655, 'learning_rate': 3.7200375007399404e-05, 'epoch': 0.7679774995560356, 'step': 4264000}
INFO:transformers.trainer:{'loss': 4.619409594297409, 'learning_rate': 3.719887411328677e-05, 'epoch': 0.768067553202794, 'step': 4264500}
INFO:transformers.trainer:{'loss': 4.740306292533875, 'learning_rate': 3.719737321917413e-05, 'epoch': 0.7681576068495524, 'step': 4265000}
INFO:transformers.trainer:{'loss': 4.73037365436554, 'learning_rate': 3.719587232506149e-05, 'epoch': 0.7682476604963109, 'step': 4265500}
INFO:transformers.trainer:{'loss': 4.611746651172638, 'learning_rate': 3.719437143094885e-05, 'epoch': 0.7683377141430693, 'step': 4266000}
INFO:transformers.trainer:{'loss': 4.633198515415192, 'learning_rate': 3.7192870536836206e-05, 'epoch': 0.7684277677898278, 'step': 4266500}
INFO:transformers.trainer:{'loss': 4.618256018400192, 'learning_rate': 3.7191369642723565e-05, 'epoch': 0.7685178214365862, 'step': 4267000}
INFO:transformers.trainer:{'loss': 4.507866097927094, 'learning_rate': 3.7189868748610924e-05, 'epoch': 0.7686078750833446, 'step': 4267500}
INFO:transformers.trainer:{'loss': 4.38108318901062, 'learning_rate': 3.718836785449828e-05, 'epoch': 0.7686979287301031, 'step': 4268000}
INFO:transformers.trainer:{'loss': 4.340454318523407, 'learning_rate': 3.718686696038564e-05, 'epoch': 0.7687879823768615, 'step': 4268500}
INFO:transformers.trainer:{'loss': 4.46922379732132, 'learning_rate': 3.7185366066273e-05, 'epoch': 0.76887803602362, 'step': 4269000}
INFO:transformers.trainer:{'loss': 4.427825421333313, 'learning_rate': 3.718386517216036e-05, 'epoch': 0.7689680896703784, 'step': 4269500}
INFO:transformers.trainer:{'loss': 4.446736876487732, 'learning_rate': 3.718236427804772e-05, 'epoch': 0.7690581433171368, 'step': 4270000}
INFO:transformers.trainer:{'loss': 4.252300088882446, 'learning_rate': 3.718086338393508e-05, 'epoch': 0.7691481969638954, 'step': 4270500}
INFO:transformers.trainer:{'loss': 4.31658708524704, 'learning_rate': 3.717936248982244e-05, 'epoch': 0.7692382506106538, 'step': 4271000}
INFO:transformers.trainer:{'loss': 4.119544283151627, 'learning_rate': 3.71778615957098e-05, 'epoch': 0.7693283042574123, 'step': 4271500}
INFO:transformers.trainer:{'loss': 4.375688925266266, 'learning_rate': 3.7176360701597156e-05, 'epoch': 0.7694183579041707, 'step': 4272000}
INFO:transformers.trainer:{'loss': 4.277967054367066, 'learning_rate': 3.717485980748452e-05, 'epoch': 0.7695084115509291, 'step': 4272500}
INFO:transformers.trainer:{'loss': 4.241844705104828, 'learning_rate': 3.7173358913371874e-05, 'epoch': 0.7695984651976876, 'step': 4273000}
INFO:transformers.trainer:{'loss': 4.313838555335998, 'learning_rate': 3.717185801925924e-05, 'epoch': 0.769688518844446, 'step': 4273500}
INFO:transformers.trainer:{'loss': 4.353750655651092, 'learning_rate': 3.717035712514659e-05, 'epoch': 0.7697785724912045, 'step': 4274000}
INFO:transformers.trainer:{'loss': 4.4185220956802365, 'learning_rate': 3.716885623103396e-05, 'epoch': 0.7698686261379629, 'step': 4274500}
INFO:transformers.trainer:{'loss': 4.4638890914916995, 'learning_rate': 3.716735533692131e-05, 'epoch': 0.7699586797847213, 'step': 4275000}
INFO:transformers.trainer:{'loss': 4.575910765171051, 'learning_rate': 3.7165854442808676e-05, 'epoch': 0.7700487334314798, 'step': 4275500}
INFO:transformers.trainer:{'loss': 4.474081608295441, 'learning_rate': 3.716435354869603e-05, 'epoch': 0.7701387870782382, 'step': 4276000}
INFO:transformers.trainer:{'loss': 4.496751842737198, 'learning_rate': 3.7162852654583394e-05, 'epoch': 0.7702288407249966, 'step': 4276500}
INFO:transformers.trainer:{'loss': 4.378052503108978, 'learning_rate': 3.7161351760470746e-05, 'epoch': 0.7703188943717552, 'step': 4277000}
INFO:transformers.trainer:{'loss': 4.4454027543067935, 'learning_rate': 3.715985086635811e-05, 'epoch': 0.7704089480185136, 'step': 4277500}
INFO:transformers.trainer:{'loss': 4.564023155212403, 'learning_rate': 3.7158349972245464e-05, 'epoch': 0.7704990016652721, 'step': 4278000}
INFO:transformers.trainer:{'loss': 4.325878789901734, 'learning_rate': 3.715684907813283e-05, 'epoch': 0.7705890553120305, 'step': 4278500}
INFO:transformers.trainer:{'loss': 4.424238590240479, 'learning_rate': 3.715534818402019e-05, 'epoch': 0.7706791089587889, 'step': 4279000}
INFO:transformers.trainer:{'loss': 4.309254103422165, 'learning_rate': 3.715384728990755e-05, 'epoch': 0.7707691626055474, 'step': 4279500}
INFO:transformers.trainer:{'loss': 4.52050332736969, 'learning_rate': 3.715234639579491e-05, 'epoch': 0.7708592162523058, 'step': 4280000}
INFO:transformers.trainer:{'loss': 4.421858372688294, 'learning_rate': 3.7150845501682266e-05, 'epoch': 0.7709492698990643, 'step': 4280500}
INFO:transformers.trainer:{'loss': 4.369577838420868, 'learning_rate': 3.7149344607569625e-05, 'epoch': 0.7710393235458227, 'step': 4281000}
INFO:transformers.trainer:{'loss': 4.339301187038422, 'learning_rate': 3.7147843713456984e-05, 'epoch': 0.7711293771925811, 'step': 4281500}
INFO:transformers.trainer:{'loss': 4.456181305885315, 'learning_rate': 3.7146342819344343e-05, 'epoch': 0.7712194308393396, 'step': 4282000}
INFO:transformers.trainer:{'loss': 4.501453193664551, 'learning_rate': 3.71448419252317e-05, 'epoch': 0.771309484486098, 'step': 4282500}
INFO:transformers.trainer:{'loss': 4.503494587421417, 'learning_rate': 3.714334103111906e-05, 'epoch': 0.7713995381328566, 'step': 4283000}
INFO:transformers.trainer:{'loss': 4.552844227552414, 'learning_rate': 3.714184013700642e-05, 'epoch': 0.771489591779615, 'step': 4283500}
INFO:transformers.trainer:{'loss': 4.452741237401963, 'learning_rate': 3.714033924289378e-05, 'epoch': 0.7715796454263734, 'step': 4284000}
INFO:transformers.trainer:{'loss': 4.574256532907486, 'learning_rate': 3.713883834878114e-05, 'epoch': 0.7716696990731319, 'step': 4284500}
INFO:transformers.trainer:{'loss': 4.545175798892975, 'learning_rate': 3.71373374546685e-05, 'epoch': 0.7717597527198903, 'step': 4285000}
INFO:transformers.trainer:{'loss': 4.488634847164154, 'learning_rate': 3.713583656055585e-05, 'epoch': 0.7718498063666488, 'step': 4285500}
INFO:transformers.trainer:{'loss': 4.387970324516297, 'learning_rate': 3.7134335666443216e-05, 'epoch': 0.7719398600134072, 'step': 4286000}
INFO:transformers.trainer:{'loss': 4.35362052822113, 'learning_rate': 3.7132834772330575e-05, 'epoch': 0.7720299136601656, 'step': 4286500}
INFO:transformers.trainer:{'loss': 4.275629666090012, 'learning_rate': 3.7131333878217934e-05, 'epoch': 0.7721199673069241, 'step': 4287000}
INFO:transformers.trainer:{'loss': 4.355220801353455, 'learning_rate': 3.712983298410529e-05, 'epoch': 0.7722100209536825, 'step': 4287500}
INFO:transformers.trainer:{'loss': 4.158790872573853, 'learning_rate': 3.712833208999265e-05, 'epoch': 0.7723000746004409, 'step': 4288000}
INFO:transformers.trainer:{'loss': 4.302995509147644, 'learning_rate': 3.712683119588001e-05, 'epoch': 0.7723901282471994, 'step': 4288500}
INFO:transformers.trainer:{'loss': 4.291159049510956, 'learning_rate': 3.712533030176737e-05, 'epoch': 0.7724801818939578, 'step': 4289000}
INFO:transformers.trainer:{'loss': 4.370671741962433, 'learning_rate': 3.712382940765473e-05, 'epoch': 0.7725702355407164, 'step': 4289500}
INFO:transformers.trainer:{'loss': 4.1042343454360966, 'learning_rate': 3.712232851354209e-05, 'epoch': 0.7726602891874748, 'step': 4290000}
INFO:transformers.trainer:{'loss': 4.368628113269806, 'learning_rate': 3.712082761942945e-05, 'epoch': 0.7727503428342332, 'step': 4290500}
INFO:transformers.trainer:{'loss': 4.59381641960144, 'learning_rate': 3.7119326725316806e-05, 'epoch': 0.7728403964809917, 'step': 4291000}
INFO:transformers.trainer:{'loss': 4.547840470790863, 'learning_rate': 3.7117825831204165e-05, 'epoch': 0.7729304501277501, 'step': 4291500}
INFO:transformers.trainer:{'loss': 4.438705741882324, 'learning_rate': 3.7116324937091524e-05, 'epoch': 0.7730205037745086, 'step': 4292000}
INFO:transformers.trainer:{'loss': 4.503555249214172, 'learning_rate': 3.7114824042978884e-05, 'epoch': 0.773110557421267, 'step': 4292500}
INFO:transformers.trainer:{'loss': 4.544769398212432, 'learning_rate': 3.711332314886625e-05, 'epoch': 0.7732006110680254, 'step': 4293000}
INFO:transformers.trainer:{'loss': 4.522492026805877, 'learning_rate': 3.71118222547536e-05, 'epoch': 0.7732906647147839, 'step': 4293500}
INFO:transformers.trainer:{'loss': 4.496385433197021, 'learning_rate': 3.711032136064097e-05, 'epoch': 0.7733807183615423, 'step': 4294000}
INFO:transformers.trainer:{'loss': 4.437266854763031, 'learning_rate': 3.710882046652832e-05, 'epoch': 0.7734707720083008, 'step': 4294500}
INFO:transformers.trainer:{'loss': 4.648442862987518, 'learning_rate': 3.7107319572415686e-05, 'epoch': 0.7735608256550592, 'step': 4295000}
INFO:transformers.trainer:{'loss': 4.538178537368775, 'learning_rate': 3.710581867830304e-05, 'epoch': 0.7736508793018176, 'step': 4295500}
INFO:transformers.trainer:{'loss': 4.586469641685486, 'learning_rate': 3.7104317784190404e-05, 'epoch': 0.7737409329485762, 'step': 4296000}
INFO:transformers.trainer:{'loss': 4.3703215403556825, 'learning_rate': 3.7102816890077756e-05, 'epoch': 0.7738309865953346, 'step': 4296500}
INFO:transformers.trainer:{'loss': 4.35602787232399, 'learning_rate': 3.710131599596512e-05, 'epoch': 0.7739210402420931, 'step': 4297000}
INFO:transformers.trainer:{'loss': 4.461595689535141, 'learning_rate': 3.7099815101852474e-05, 'epoch': 0.7740110938888515, 'step': 4297500}
INFO:transformers.trainer:{'loss': 4.540552071094513, 'learning_rate': 3.709831420773984e-05, 'epoch': 0.7741011475356099, 'step': 4298000}
INFO:transformers.trainer:{'loss': 4.555320149898529, 'learning_rate': 3.709681331362719e-05, 'epoch': 0.7741912011823684, 'step': 4298500}
INFO:transformers.trainer:{'loss': 4.474178508281708, 'learning_rate': 3.709531241951456e-05, 'epoch': 0.7742812548291268, 'step': 4299000}
INFO:transformers.trainer:{'loss': 4.360560260534286, 'learning_rate': 3.709381152540192e-05, 'epoch': 0.7743713084758852, 'step': 4299500}
INFO:transformers.trainer:{'loss': 4.5888231852054595, 'learning_rate': 3.7092310631289276e-05, 'epoch': 0.7744613621226437, 'step': 4300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.5804287343025205, 'learning_rate': 3.7090809737176635e-05, 'epoch': 0.7745514157694021, 'step': 4300500}
INFO:transformers.trainer:{'loss': 4.563737617015839, 'learning_rate': 3.7089308843063994e-05, 'epoch': 0.7746414694161606, 'step': 4301000}
INFO:transformers.trainer:{'loss': 4.4099399745464325, 'learning_rate': 3.708780794895135e-05, 'epoch': 0.774731523062919, 'step': 4301500}
INFO:transformers.trainer:{'loss': 4.4641688005924225, 'learning_rate': 3.708630705483871e-05, 'epoch': 0.7748215767096774, 'step': 4302000}
INFO:transformers.trainer:{'loss': 4.45217370223999, 'learning_rate': 3.708480616072607e-05, 'epoch': 0.774911630356436, 'step': 4302500}
INFO:transformers.trainer:{'loss': 4.498345470905304, 'learning_rate': 3.708330526661343e-05, 'epoch': 0.7750016840031944, 'step': 4303000}
INFO:transformers.trainer:{'loss': 4.498097641944885, 'learning_rate': 3.708180437250079e-05, 'epoch': 0.7750917376499529, 'step': 4303500}
INFO:transformers.trainer:{'loss': 4.4187648401260375, 'learning_rate': 3.708030347838815e-05, 'epoch': 0.7751817912967113, 'step': 4304000}
INFO:transformers.trainer:{'loss': 4.515603631019593, 'learning_rate': 3.707880258427551e-05, 'epoch': 0.7752718449434697, 'step': 4304500}
INFO:transformers.trainer:{'loss': 4.230323545455932, 'learning_rate': 3.7077301690162867e-05, 'epoch': 0.7753618985902282, 'step': 4305000}
INFO:transformers.trainer:{'loss': 4.0946224198341366, 'learning_rate': 3.7075800796050226e-05, 'epoch': 0.7754519522369866, 'step': 4305500}
INFO:transformers.trainer:{'loss': 4.329997861146927, 'learning_rate': 3.7074299901937585e-05, 'epoch': 0.7755420058837451, 'step': 4306000}
INFO:transformers.trainer:{'loss': 4.413926052570343, 'learning_rate': 3.7072799007824944e-05, 'epoch': 0.7756320595305035, 'step': 4306500}
INFO:transformers.trainer:{'loss': 4.424954462528229, 'learning_rate': 3.70712981137123e-05, 'epoch': 0.7757221131772619, 'step': 4307000}
INFO:transformers.trainer:{'loss': 4.494107489585876, 'learning_rate': 3.706979721959966e-05, 'epoch': 0.7758121668240204, 'step': 4307500}
INFO:transformers.trainer:{'loss': 4.597949140548706, 'learning_rate': 3.706829632548702e-05, 'epoch': 0.7759022204707788, 'step': 4308000}
INFO:transformers.trainer:{'loss': 4.632076926231385, 'learning_rate': 3.706679543137438e-05, 'epoch': 0.7759922741175374, 'step': 4308500}
INFO:transformers.trainer:{'loss': 4.568447820663452, 'learning_rate': 3.706529453726174e-05, 'epoch': 0.7760823277642958, 'step': 4309000}
INFO:transformers.trainer:{'loss': 4.507977435111999, 'learning_rate': 3.70637936431491e-05, 'epoch': 0.7761723814110542, 'step': 4309500}
INFO:transformers.trainer:{'loss': 4.487818254470826, 'learning_rate': 3.706229274903646e-05, 'epoch': 0.7762624350578127, 'step': 4310000}
INFO:transformers.trainer:{'loss': 4.410781284332275, 'learning_rate': 3.7060791854923816e-05, 'epoch': 0.7763524887045711, 'step': 4310500}
INFO:transformers.trainer:{'loss': 4.53406382226944, 'learning_rate': 3.7059290960811175e-05, 'epoch': 0.7764425423513295, 'step': 4311000}
INFO:transformers.trainer:{'loss': 4.476556728839874, 'learning_rate': 3.7057790066698534e-05, 'epoch': 0.776532595998088, 'step': 4311500}
INFO:transformers.trainer:{'loss': 4.467385736465454, 'learning_rate': 3.705628917258589e-05, 'epoch': 0.7766226496448464, 'step': 4312000}
INFO:transformers.trainer:{'loss': 4.478980932235718, 'learning_rate': 3.705478827847325e-05, 'epoch': 0.7767127032916049, 'step': 4312500}
INFO:transformers.trainer:{'loss': 4.520597651004791, 'learning_rate': 3.705328738436061e-05, 'epoch': 0.7768027569383633, 'step': 4313000}
INFO:transformers.trainer:{'loss': 4.568324798583984, 'learning_rate': 3.705178649024798e-05, 'epoch': 0.7768928105851217, 'step': 4313500}
INFO:transformers.trainer:{'loss': 4.544575837135315, 'learning_rate': 3.705028559613533e-05, 'epoch': 0.7769828642318802, 'step': 4314000}
INFO:transformers.trainer:{'loss': 4.634551561832428, 'learning_rate': 3.7048784702022695e-05, 'epoch': 0.7770729178786386, 'step': 4314500}
INFO:transformers.trainer:{'loss': 4.625576033115387, 'learning_rate': 3.704728380791005e-05, 'epoch': 0.7771629715253972, 'step': 4315000}
INFO:transformers.trainer:{'loss': 4.414485815048217, 'learning_rate': 3.704578291379741e-05, 'epoch': 0.7772530251721556, 'step': 4315500}
INFO:transformers.trainer:{'loss': 4.305431466817856, 'learning_rate': 3.7044282019684766e-05, 'epoch': 0.777343078818914, 'step': 4316000}
INFO:transformers.trainer:{'loss': 4.159642591953277, 'learning_rate': 3.704278112557213e-05, 'epoch': 0.7774331324656725, 'step': 4316500}
INFO:transformers.trainer:{'loss': 4.458217329502106, 'learning_rate': 3.7041280231459484e-05, 'epoch': 0.7775231861124309, 'step': 4317000}
INFO:transformers.trainer:{'loss': 4.4514779620170595, 'learning_rate': 3.703977933734685e-05, 'epoch': 0.7776132397591894, 'step': 4317500}
INFO:transformers.trainer:{'loss': 4.6270569791793825, 'learning_rate': 3.70382784432342e-05, 'epoch': 0.7777032934059478, 'step': 4318000}
INFO:transformers.trainer:{'loss': 4.603001345872879, 'learning_rate': 3.703677754912157e-05, 'epoch': 0.7777933470527062, 'step': 4318500}
INFO:transformers.trainer:{'loss': 4.583374022960663, 'learning_rate': 3.703527665500892e-05, 'epoch': 0.7778834006994647, 'step': 4319000}
INFO:transformers.trainer:{'loss': 4.5117445216178895, 'learning_rate': 3.7033775760896286e-05, 'epoch': 0.7779734543462231, 'step': 4319500}
INFO:transformers.trainer:{'loss': 4.506648443222046, 'learning_rate': 3.703227486678364e-05, 'epoch': 0.7780635079929816, 'step': 4320000}
INFO:transformers.trainer:{'loss': 4.422526252269745, 'learning_rate': 3.7030773972671004e-05, 'epoch': 0.77815356163974, 'step': 4320500}
INFO:transformers.trainer:{'loss': 4.478069530010224, 'learning_rate': 3.702927307855836e-05, 'epoch': 0.7782436152864984, 'step': 4321000}
INFO:transformers.trainer:{'loss': 4.233205586194992, 'learning_rate': 3.702777218444572e-05, 'epoch': 0.778333668933257, 'step': 4321500}
INFO:transformers.trainer:{'loss': 4.2745833568573, 'learning_rate': 3.702627129033308e-05, 'epoch': 0.7784237225800154, 'step': 4322000}
INFO:transformers.trainer:{'loss': 4.360063487529755, 'learning_rate': 3.702477039622044e-05, 'epoch': 0.7785137762267739, 'step': 4322500}
INFO:transformers.trainer:{'loss': 4.480203577518463, 'learning_rate': 3.70232695021078e-05, 'epoch': 0.7786038298735323, 'step': 4323000}
INFO:transformers.trainer:{'loss': 4.5513383493423465, 'learning_rate': 3.702176860799516e-05, 'epoch': 0.7786938835202907, 'step': 4323500}
INFO:transformers.trainer:{'loss': 4.551916125297546, 'learning_rate': 3.702026771388252e-05, 'epoch': 0.7787839371670492, 'step': 4324000}
INFO:transformers.trainer:{'loss': 4.351241338968277, 'learning_rate': 3.7018766819769876e-05, 'epoch': 0.7788739908138076, 'step': 4324500}
INFO:transformers.trainer:{'loss': 4.082564576148987, 'learning_rate': 3.7017265925657235e-05, 'epoch': 0.778964044460566, 'step': 4325000}
INFO:transformers.trainer:{'loss': 4.299289796352387, 'learning_rate': 3.7015765031544594e-05, 'epoch': 0.7790540981073245, 'step': 4325500}
INFO:transformers.trainer:{'loss': 4.610189430236816, 'learning_rate': 3.7014264137431953e-05, 'epoch': 0.7791441517540829, 'step': 4326000}
INFO:transformers.trainer:{'loss': 4.537138788223267, 'learning_rate': 3.701276324331931e-05, 'epoch': 0.7792342054008414, 'step': 4326500}
INFO:transformers.trainer:{'loss': 4.620089057445526, 'learning_rate': 3.701126234920667e-05, 'epoch': 0.7793242590475998, 'step': 4327000}
INFO:transformers.trainer:{'loss': 4.455820739746094, 'learning_rate': 3.700976145509403e-05, 'epoch': 0.7794143126943582, 'step': 4327500}
INFO:transformers.trainer:{'loss': 4.242933407068253, 'learning_rate': 3.700826056098139e-05, 'epoch': 0.7795043663411168, 'step': 4328000}
INFO:transformers.trainer:{'loss': 4.055009492874145, 'learning_rate': 3.700675966686875e-05, 'epoch': 0.7795944199878752, 'step': 4328500}
INFO:transformers.trainer:{'loss': 4.294637131214142, 'learning_rate': 3.700525877275611e-05, 'epoch': 0.7796844736346337, 'step': 4329000}
INFO:transformers.trainer:{'loss': 4.344720741271972, 'learning_rate': 3.700375787864347e-05, 'epoch': 0.7797745272813921, 'step': 4329500}
INFO:transformers.trainer:{'loss': 4.098006112575531, 'learning_rate': 3.7002256984530826e-05, 'epoch': 0.7798645809281505, 'step': 4330000}
INFO:transformers.trainer:{'loss': 4.259064987659454, 'learning_rate': 3.7000756090418185e-05, 'epoch': 0.779954634574909, 'step': 4330500}
INFO:transformers.trainer:{'loss': 4.276423804283142, 'learning_rate': 3.6999255196305544e-05, 'epoch': 0.7800446882216674, 'step': 4331000}
INFO:transformers.trainer:{'loss': 4.162825804233551, 'learning_rate': 3.69977543021929e-05, 'epoch': 0.7801347418684259, 'step': 4331500}
INFO:transformers.trainer:{'loss': 4.2890291576385495, 'learning_rate': 3.699625340808026e-05, 'epoch': 0.7802247955151843, 'step': 4332000}
INFO:transformers.trainer:{'loss': 4.598842113971711, 'learning_rate': 3.699475251396762e-05, 'epoch': 0.7803148491619427, 'step': 4332500}
INFO:transformers.trainer:{'loss': 4.335491723299026, 'learning_rate': 3.699325161985498e-05, 'epoch': 0.7804049028087012, 'step': 4333000}
INFO:transformers.trainer:{'loss': 4.175755037784576, 'learning_rate': 3.699175072574234e-05, 'epoch': 0.7804949564554596, 'step': 4333500}
INFO:transformers.trainer:{'loss': 4.302223950862884, 'learning_rate': 3.69902498316297e-05, 'epoch': 0.7805850101022181, 'step': 4334000}
INFO:transformers.trainer:{'loss': 4.152311695337295, 'learning_rate': 3.698874893751706e-05, 'epoch': 0.7806750637489765, 'step': 4334500}
INFO:transformers.trainer:{'loss': 4.419887856960297, 'learning_rate': 3.698724804340442e-05, 'epoch': 0.780765117395735, 'step': 4335000}
INFO:transformers.trainer:{'loss': 4.348663471221924, 'learning_rate': 3.6985747149291775e-05, 'epoch': 0.7808551710424935, 'step': 4335500}
INFO:transformers.trainer:{'loss': 4.53148716545105, 'learning_rate': 3.698424625517914e-05, 'epoch': 0.7809452246892519, 'step': 4336000}
INFO:transformers.trainer:{'loss': 4.529018290519715, 'learning_rate': 3.6982745361066493e-05, 'epoch': 0.7810352783360103, 'step': 4336500}
INFO:transformers.trainer:{'loss': 3.895658413171768, 'learning_rate': 3.698124446695386e-05, 'epoch': 0.7811253319827688, 'step': 4337000}
INFO:transformers.trainer:{'loss': 4.023289174318314, 'learning_rate': 3.697974357284121e-05, 'epoch': 0.7812153856295272, 'step': 4337500}
INFO:transformers.trainer:{'loss': 4.508715024471283, 'learning_rate': 3.697824267872858e-05, 'epoch': 0.7813054392762857, 'step': 4338000}
INFO:transformers.trainer:{'loss': 4.316240122318268, 'learning_rate': 3.697674178461593e-05, 'epoch': 0.7813954929230441, 'step': 4338500}
INFO:transformers.trainer:{'loss': 4.216686359167099, 'learning_rate': 3.6975240890503295e-05, 'epoch': 0.7814855465698025, 'step': 4339000}
INFO:transformers.trainer:{'loss': 3.9926062009334564, 'learning_rate': 3.697373999639065e-05, 'epoch': 0.781575600216561, 'step': 4339500}
INFO:transformers.trainer:{'loss': 4.1103543562889095, 'learning_rate': 3.6972239102278014e-05, 'epoch': 0.7816656538633194, 'step': 4340000}
INFO:transformers.trainer:{'loss': 4.2937497293949125, 'learning_rate': 3.6970738208165366e-05, 'epoch': 0.781755707510078, 'step': 4340500}
INFO:transformers.trainer:{'loss': 4.359738938808441, 'learning_rate': 3.696923731405273e-05, 'epoch': 0.7818457611568363, 'step': 4341000}
INFO:transformers.trainer:{'loss': 4.34206356716156, 'learning_rate': 3.696773641994009e-05, 'epoch': 0.7819358148035948, 'step': 4341500}
INFO:transformers.trainer:{'loss': 4.312133728981018, 'learning_rate': 3.696623552582745e-05, 'epoch': 0.7820258684503533, 'step': 4342000}
INFO:transformers.trainer:{'loss': 4.280839605808258, 'learning_rate': 3.696473463171481e-05, 'epoch': 0.7821159220971117, 'step': 4342500}
INFO:transformers.trainer:{'loss': 4.1424853491783145, 'learning_rate': 3.696323373760217e-05, 'epoch': 0.7822059757438702, 'step': 4343000}
INFO:transformers.trainer:{'loss': 4.470700961589813, 'learning_rate': 3.696173284348953e-05, 'epoch': 0.7822960293906286, 'step': 4343500}
INFO:transformers.trainer:{'loss': 4.457666399955749, 'learning_rate': 3.6960231949376886e-05, 'epoch': 0.782386083037387, 'step': 4344000}
INFO:transformers.trainer:{'loss': 4.185552224159241, 'learning_rate': 3.6958731055264245e-05, 'epoch': 0.7824761366841455, 'step': 4344500}
INFO:transformers.trainer:{'loss': 4.180372382879257, 'learning_rate': 3.6957230161151604e-05, 'epoch': 0.7825661903309039, 'step': 4345000}
INFO:transformers.trainer:{'loss': 4.250174948215484, 'learning_rate': 3.695572926703896e-05, 'epoch': 0.7826562439776624, 'step': 4345500}
INFO:transformers.trainer:{'loss': 4.390141966342926, 'learning_rate': 3.695422837292632e-05, 'epoch': 0.7827462976244208, 'step': 4346000}
INFO:transformers.trainer:{'loss': 4.530619740486145, 'learning_rate': 3.695272747881368e-05, 'epoch': 0.7828363512711792, 'step': 4346500}
INFO:transformers.trainer:{'loss': 4.32319118642807, 'learning_rate': 3.695122658470104e-05, 'epoch': 0.7829264049179377, 'step': 4347000}
INFO:transformers.trainer:{'loss': 4.098158731937408, 'learning_rate': 3.69497256905884e-05, 'epoch': 0.7830164585646961, 'step': 4347500}
INFO:transformers.trainer:{'loss': 4.078910508394241, 'learning_rate': 3.694822479647576e-05, 'epoch': 0.7831065122114546, 'step': 4348000}
INFO:transformers.trainer:{'loss': 4.399203960418701, 'learning_rate': 3.694672390236312e-05, 'epoch': 0.7831965658582131, 'step': 4348500}
INFO:transformers.trainer:{'loss': 4.369484462499619, 'learning_rate': 3.6945223008250476e-05, 'epoch': 0.7832866195049715, 'step': 4349000}
INFO:transformers.trainer:{'loss': 4.301862062692642, 'learning_rate': 3.6943722114137836e-05, 'epoch': 0.78337667315173, 'step': 4349500}
INFO:transformers.trainer:{'loss': 4.328966701984405, 'learning_rate': 3.6942221220025195e-05, 'epoch': 0.7834667267984884, 'step': 4350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.331820036888122, 'learning_rate': 3.6940720325912554e-05, 'epoch': 0.7835567804452468, 'step': 4350500}
INFO:transformers.trainer:{'loss': 4.472385075569153, 'learning_rate': 3.693921943179991e-05, 'epoch': 0.7836468340920053, 'step': 4351000}
INFO:transformers.trainer:{'loss': 4.441821812868119, 'learning_rate': 3.693771853768727e-05, 'epoch': 0.7837368877387637, 'step': 4351500}
INFO:transformers.trainer:{'loss': 4.6523236899375915, 'learning_rate': 3.693621764357463e-05, 'epoch': 0.7838269413855222, 'step': 4352000}
INFO:transformers.trainer:{'loss': 4.532119007587433, 'learning_rate': 3.693471674946199e-05, 'epoch': 0.7839169950322806, 'step': 4352500}
INFO:transformers.trainer:{'loss': 4.39298727273941, 'learning_rate': 3.693321585534935e-05, 'epoch': 0.784007048679039, 'step': 4353000}
INFO:transformers.trainer:{'loss': 4.459792398929596, 'learning_rate': 3.693171496123671e-05, 'epoch': 0.7840971023257975, 'step': 4353500}
INFO:transformers.trainer:{'loss': 4.497745679855346, 'learning_rate': 3.693021406712407e-05, 'epoch': 0.784187155972556, 'step': 4354000}
INFO:transformers.trainer:{'loss': 4.4915984964370725, 'learning_rate': 3.6928713173011426e-05, 'epoch': 0.7842772096193145, 'step': 4354500}
INFO:transformers.trainer:{'loss': 4.619236022472381, 'learning_rate': 3.6927212278898785e-05, 'epoch': 0.7843672632660729, 'step': 4355000}
INFO:transformers.trainer:{'loss': 4.582241804599762, 'learning_rate': 3.692571138478615e-05, 'epoch': 0.7844573169128313, 'step': 4355500}
INFO:transformers.trainer:{'loss': 4.377911532402039, 'learning_rate': 3.69242104906735e-05, 'epoch': 0.7845473705595898, 'step': 4356000}
INFO:transformers.trainer:{'loss': 4.317593855619431, 'learning_rate': 3.692270959656087e-05, 'epoch': 0.7846374242063482, 'step': 4356500}
INFO:transformers.trainer:{'loss': 4.417470213413239, 'learning_rate': 3.692120870244822e-05, 'epoch': 0.7847274778531067, 'step': 4357000}
INFO:transformers.trainer:{'loss': 4.164011707305908, 'learning_rate': 3.691970780833559e-05, 'epoch': 0.7848175314998651, 'step': 4357500}
INFO:transformers.trainer:{'loss': 4.441468500137329, 'learning_rate': 3.691820691422294e-05, 'epoch': 0.7849075851466235, 'step': 4358000}
INFO:transformers.trainer:{'loss': 4.37292936706543, 'learning_rate': 3.6916706020110305e-05, 'epoch': 0.784997638793382, 'step': 4358500}
INFO:transformers.trainer:{'loss': 4.321590815782547, 'learning_rate': 3.691520512599766e-05, 'epoch': 0.7850876924401404, 'step': 4359000}
INFO:transformers.trainer:{'loss': 4.32565876364708, 'learning_rate': 3.691370423188502e-05, 'epoch': 0.7851777460868989, 'step': 4359500}
INFO:transformers.trainer:{'loss': 4.397251789569855, 'learning_rate': 3.6912203337772376e-05, 'epoch': 0.7852677997336573, 'step': 4360000}
INFO:transformers.trainer:{'loss': 4.501188426494599, 'learning_rate': 3.691070244365974e-05, 'epoch': 0.7853578533804157, 'step': 4360500}
INFO:transformers.trainer:{'loss': 4.252249604940414, 'learning_rate': 3.6909201549547094e-05, 'epoch': 0.7854479070271743, 'step': 4361000}
INFO:transformers.trainer:{'loss': 4.292459084749222, 'learning_rate': 3.690770065543446e-05, 'epoch': 0.7855379606739327, 'step': 4361500}
INFO:transformers.trainer:{'loss': 4.479220337867737, 'learning_rate': 3.690619976132182e-05, 'epoch': 0.7856280143206911, 'step': 4362000}
INFO:transformers.trainer:{'loss': 4.495270859241486, 'learning_rate': 3.690469886720918e-05, 'epoch': 0.7857180679674496, 'step': 4362500}
INFO:transformers.trainer:{'loss': 4.462955207824707, 'learning_rate': 3.690319797309654e-05, 'epoch': 0.785808121614208, 'step': 4363000}
INFO:transformers.trainer:{'loss': 4.404738700866699, 'learning_rate': 3.6901697078983896e-05, 'epoch': 0.7858981752609665, 'step': 4363500}
INFO:transformers.trainer:{'loss': 4.50212519812584, 'learning_rate': 3.6900196184871255e-05, 'epoch': 0.7859882289077249, 'step': 4364000}
INFO:transformers.trainer:{'loss': 4.488164653778076, 'learning_rate': 3.6898695290758614e-05, 'epoch': 0.7860782825544833, 'step': 4364500}
INFO:transformers.trainer:{'loss': 4.381578849315643, 'learning_rate': 3.689719439664597e-05, 'epoch': 0.7861683362012418, 'step': 4365000}
INFO:transformers.trainer:{'loss': 4.369850712299347, 'learning_rate': 3.689569350253333e-05, 'epoch': 0.7862583898480002, 'step': 4365500}
INFO:transformers.trainer:{'loss': 4.311937903404236, 'learning_rate': 3.689419260842069e-05, 'epoch': 0.7863484434947587, 'step': 4366000}
INFO:transformers.trainer:{'loss': 4.440241307020187, 'learning_rate': 3.689269171430805e-05, 'epoch': 0.7864384971415171, 'step': 4366500}
INFO:transformers.trainer:{'loss': 4.346442029953003, 'learning_rate': 3.689119082019541e-05, 'epoch': 0.7865285507882755, 'step': 4367000}
INFO:transformers.trainer:{'loss': 4.262837722063065, 'learning_rate': 3.688968992608277e-05, 'epoch': 0.7866186044350341, 'step': 4367500}
INFO:transformers.trainer:{'loss': 4.431418607234955, 'learning_rate': 3.688818903197013e-05, 'epoch': 0.7867086580817925, 'step': 4368000}
INFO:transformers.trainer:{'loss': 4.483962645769119, 'learning_rate': 3.6886688137857486e-05, 'epoch': 0.786798711728551, 'step': 4368500}
INFO:transformers.trainer:{'loss': 4.454834604740143, 'learning_rate': 3.6885187243744845e-05, 'epoch': 0.7868887653753094, 'step': 4369000}
INFO:transformers.trainer:{'loss': 4.483564850091934, 'learning_rate': 3.6883686349632204e-05, 'epoch': 0.7869788190220678, 'step': 4369500}
INFO:transformers.trainer:{'loss': 4.60139253950119, 'learning_rate': 3.688218545551956e-05, 'epoch': 0.7870688726688263, 'step': 4370000}
INFO:transformers.trainer:{'loss': 4.566255307674408, 'learning_rate': 3.688068456140692e-05, 'epoch': 0.7871589263155847, 'step': 4370500}
INFO:transformers.trainer:{'loss': 4.501578460216522, 'learning_rate': 3.687918366729428e-05, 'epoch': 0.7872489799623432, 'step': 4371000}
INFO:transformers.trainer:{'loss': 4.513246396064758, 'learning_rate': 3.687768277318164e-05, 'epoch': 0.7873390336091016, 'step': 4371500}
INFO:transformers.trainer:{'loss': 4.655250705718994, 'learning_rate': 3.6876181879069e-05, 'epoch': 0.78742908725586, 'step': 4372000}
INFO:transformers.trainer:{'loss': 4.626844834804535, 'learning_rate': 3.687468098495636e-05, 'epoch': 0.7875191409026185, 'step': 4372500}
INFO:transformers.trainer:{'loss': 4.589570628404617, 'learning_rate': 3.687318009084372e-05, 'epoch': 0.787609194549377, 'step': 4373000}
INFO:transformers.trainer:{'loss': 4.418447807073593, 'learning_rate': 3.687167919673108e-05, 'epoch': 0.7876992481961353, 'step': 4373500}
INFO:transformers.trainer:{'loss': 4.431525473594665, 'learning_rate': 3.6870178302618436e-05, 'epoch': 0.7877893018428939, 'step': 4374000}
INFO:transformers.trainer:{'loss': 4.48215548825264, 'learning_rate': 3.6868677408505795e-05, 'epoch': 0.7878793554896523, 'step': 4374500}
INFO:transformers.trainer:{'loss': 4.513439239025116, 'learning_rate': 3.6867176514393154e-05, 'epoch': 0.7879694091364108, 'step': 4375000}
INFO:transformers.trainer:{'loss': 4.595614831924438, 'learning_rate': 3.686567562028051e-05, 'epoch': 0.7880594627831692, 'step': 4375500}
INFO:transformers.trainer:{'loss': 4.6054410009384155, 'learning_rate': 3.686417472616788e-05, 'epoch': 0.7881495164299276, 'step': 4376000}
INFO:transformers.trainer:{'loss': 4.63885557770729, 'learning_rate': 3.686267383205523e-05, 'epoch': 0.7882395700766861, 'step': 4376500}
INFO:transformers.trainer:{'loss': 4.609867167949677, 'learning_rate': 3.68611729379426e-05, 'epoch': 0.7883296237234445, 'step': 4377000}
INFO:transformers.trainer:{'loss': 4.548397793531418, 'learning_rate': 3.685967204382995e-05, 'epoch': 0.788419677370203, 'step': 4377500}
INFO:transformers.trainer:{'loss': 4.552976722240448, 'learning_rate': 3.6858171149717315e-05, 'epoch': 0.7885097310169614, 'step': 4378000}
INFO:transformers.trainer:{'loss': 4.595975801467896, 'learning_rate': 3.685667025560467e-05, 'epoch': 0.7885997846637198, 'step': 4378500}
INFO:transformers.trainer:{'loss': 4.586738106250763, 'learning_rate': 3.685516936149203e-05, 'epoch': 0.7886898383104783, 'step': 4379000}
INFO:transformers.trainer:{'loss': 4.575004607677459, 'learning_rate': 3.6853668467379385e-05, 'epoch': 0.7887798919572367, 'step': 4379500}
INFO:transformers.trainer:{'loss': 4.4819217319488525, 'learning_rate': 3.685216757326675e-05, 'epoch': 0.7888699456039953, 'step': 4380000}
INFO:transformers.trainer:{'loss': 4.422675882339478, 'learning_rate': 3.6850666679154103e-05, 'epoch': 0.7889599992507537, 'step': 4380500}
INFO:transformers.trainer:{'loss': 4.528846868515014, 'learning_rate': 3.684916578504147e-05, 'epoch': 0.7890500528975121, 'step': 4381000}
INFO:transformers.trainer:{'loss': 4.571662954330444, 'learning_rate': 3.684766489092882e-05, 'epoch': 0.7891401065442706, 'step': 4381500}
INFO:transformers.trainer:{'loss': 4.575877031803131, 'learning_rate': 3.684616399681619e-05, 'epoch': 0.789230160191029, 'step': 4382000}
INFO:transformers.trainer:{'loss': 4.4885623488426205, 'learning_rate': 3.684466310270354e-05, 'epoch': 0.7893202138377875, 'step': 4382500}
INFO:transformers.trainer:{'loss': 4.374055884838104, 'learning_rate': 3.6843162208590905e-05, 'epoch': 0.7894102674845459, 'step': 4383000}
INFO:transformers.trainer:{'loss': 4.538841701507568, 'learning_rate': 3.6841661314478264e-05, 'epoch': 0.7895003211313043, 'step': 4383500}
INFO:transformers.trainer:{'loss': 4.544883701324463, 'learning_rate': 3.6840160420365624e-05, 'epoch': 0.7895903747780628, 'step': 4384000}
INFO:transformers.trainer:{'loss': 4.442357865333557, 'learning_rate': 3.683865952625298e-05, 'epoch': 0.7896804284248212, 'step': 4384500}
INFO:transformers.trainer:{'loss': 4.453577882528305, 'learning_rate': 3.683715863214034e-05, 'epoch': 0.7897704820715796, 'step': 4385000}
INFO:transformers.trainer:{'loss': 4.621545529842376, 'learning_rate': 3.68356577380277e-05, 'epoch': 0.7898605357183381, 'step': 4385500}
INFO:transformers.trainer:{'loss': 4.663841308116913, 'learning_rate': 3.683415684391506e-05, 'epoch': 0.7899505893650965, 'step': 4386000}
INFO:transformers.trainer:{'loss': 4.726600497722626, 'learning_rate': 3.683265594980242e-05, 'epoch': 0.7900406430118551, 'step': 4386500}
INFO:transformers.trainer:{'loss': 4.55807062625885, 'learning_rate': 3.683115505568978e-05, 'epoch': 0.7901306966586135, 'step': 4387000}
INFO:transformers.trainer:{'loss': 4.496109335660934, 'learning_rate': 3.682965416157714e-05, 'epoch': 0.7902207503053719, 'step': 4387500}
INFO:transformers.trainer:{'loss': 4.518483407497406, 'learning_rate': 3.6828153267464496e-05, 'epoch': 0.7903108039521304, 'step': 4388000}
INFO:transformers.trainer:{'loss': 4.644738715171814, 'learning_rate': 3.6826652373351855e-05, 'epoch': 0.7904008575988888, 'step': 4388500}
INFO:transformers.trainer:{'loss': 4.645069596290589, 'learning_rate': 3.6825151479239214e-05, 'epoch': 0.7904909112456473, 'step': 4389000}
INFO:transformers.trainer:{'loss': 4.596087449073791, 'learning_rate': 3.682365058512657e-05, 'epoch': 0.7905809648924057, 'step': 4389500}
INFO:transformers.trainer:{'loss': 4.670608205318451, 'learning_rate': 3.682214969101393e-05, 'epoch': 0.7906710185391641, 'step': 4390000}
INFO:transformers.trainer:{'loss': 4.649832436561584, 'learning_rate': 3.682064879690129e-05, 'epoch': 0.7907610721859226, 'step': 4390500}
INFO:transformers.trainer:{'loss': 4.680595431804657, 'learning_rate': 3.681914790278865e-05, 'epoch': 0.790851125832681, 'step': 4391000}
INFO:transformers.trainer:{'loss': 4.664056961536407, 'learning_rate': 3.681764700867601e-05, 'epoch': 0.7909411794794395, 'step': 4391500}
INFO:transformers.trainer:{'loss': 4.589544215679169, 'learning_rate': 3.681614611456337e-05, 'epoch': 0.7910312331261979, 'step': 4392000}
INFO:transformers.trainer:{'loss': 4.454535021066666, 'learning_rate': 3.681464522045073e-05, 'epoch': 0.7911212867729563, 'step': 4392500}
INFO:transformers.trainer:{'loss': 4.59138209438324, 'learning_rate': 3.6813144326338086e-05, 'epoch': 0.7912113404197149, 'step': 4393000}
INFO:transformers.trainer:{'loss': 4.4995885453224185, 'learning_rate': 3.6811643432225445e-05, 'epoch': 0.7913013940664733, 'step': 4393500}
INFO:transformers.trainer:{'loss': 4.4299463300704955, 'learning_rate': 3.6810142538112805e-05, 'epoch': 0.7913914477132318, 'step': 4394000}
INFO:transformers.trainer:{'loss': 4.519139543771744, 'learning_rate': 3.6808641644000164e-05, 'epoch': 0.7914815013599902, 'step': 4394500}
INFO:transformers.trainer:{'loss': 4.559453019618988, 'learning_rate': 3.680714074988752e-05, 'epoch': 0.7915715550067486, 'step': 4395000}
INFO:transformers.trainer:{'loss': 4.503088686466217, 'learning_rate': 3.680563985577488e-05, 'epoch': 0.7916616086535071, 'step': 4395500}
INFO:transformers.trainer:{'loss': 4.645585491418839, 'learning_rate': 3.680413896166224e-05, 'epoch': 0.7917516623002655, 'step': 4396000}
INFO:transformers.trainer:{'loss': 4.618465678691864, 'learning_rate': 3.68026380675496e-05, 'epoch': 0.791841715947024, 'step': 4396500}
INFO:transformers.trainer:{'loss': 4.514500535011291, 'learning_rate': 3.680113717343696e-05, 'epoch': 0.7919317695937824, 'step': 4397000}
INFO:transformers.trainer:{'loss': 4.442162380695343, 'learning_rate': 3.6799636279324325e-05, 'epoch': 0.7920218232405408, 'step': 4397500}
INFO:transformers.trainer:{'loss': 4.500984876632691, 'learning_rate': 3.679813538521168e-05, 'epoch': 0.7921118768872993, 'step': 4398000}
INFO:transformers.trainer:{'loss': 4.60073393201828, 'learning_rate': 3.679663449109904e-05, 'epoch': 0.7922019305340577, 'step': 4398500}
INFO:transformers.trainer:{'loss': 4.554170320510864, 'learning_rate': 3.6795133596986395e-05, 'epoch': 0.7922919841808161, 'step': 4399000}
INFO:transformers.trainer:{'loss': 4.409736342430115, 'learning_rate': 3.679363270287376e-05, 'epoch': 0.7923820378275747, 'step': 4399500}
INFO:transformers.trainer:{'loss': 4.368671397209168, 'learning_rate': 3.679213180876111e-05, 'epoch': 0.7924720914743331, 'step': 4400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.2738385543823245, 'learning_rate': 3.679063091464848e-05, 'epoch': 0.7925621451210916, 'step': 4400500}
INFO:transformers.trainer:{'loss': 4.12746354842186, 'learning_rate': 3.678913002053583e-05, 'epoch': 0.79265219876785, 'step': 4401000}
INFO:transformers.trainer:{'loss': 4.350686789512634, 'learning_rate': 3.67876291264232e-05, 'epoch': 0.7927422524146084, 'step': 4401500}
INFO:transformers.trainer:{'loss': 4.265356190204621, 'learning_rate': 3.678612823231055e-05, 'epoch': 0.7928323060613669, 'step': 4402000}
INFO:transformers.trainer:{'loss': 4.351012439250946, 'learning_rate': 3.6784627338197915e-05, 'epoch': 0.7929223597081253, 'step': 4402500}
INFO:transformers.trainer:{'loss': 4.408106519699096, 'learning_rate': 3.678312644408527e-05, 'epoch': 0.7930124133548838, 'step': 4403000}
INFO:transformers.trainer:{'loss': 4.557524365901947, 'learning_rate': 3.678162554997263e-05, 'epoch': 0.7931024670016422, 'step': 4403500}
INFO:transformers.trainer:{'loss': 4.544011255264282, 'learning_rate': 3.678012465585999e-05, 'epoch': 0.7931925206484006, 'step': 4404000}
INFO:transformers.trainer:{'loss': 4.6008160142898555, 'learning_rate': 3.677862376174735e-05, 'epoch': 0.7932825742951591, 'step': 4404500}
INFO:transformers.trainer:{'loss': 4.395459537982941, 'learning_rate': 3.677712286763471e-05, 'epoch': 0.7933726279419175, 'step': 4405000}
INFO:transformers.trainer:{'loss': 4.3861770672798155, 'learning_rate': 3.677562197352207e-05, 'epoch': 0.793462681588676, 'step': 4405500}
INFO:transformers.trainer:{'loss': 4.4750107855796815, 'learning_rate': 3.677412107940943e-05, 'epoch': 0.7935527352354345, 'step': 4406000}
INFO:transformers.trainer:{'loss': 4.481531727075577, 'learning_rate': 3.677262018529679e-05, 'epoch': 0.7936427888821929, 'step': 4406500}
INFO:transformers.trainer:{'loss': 4.524293301582336, 'learning_rate': 3.677111929118415e-05, 'epoch': 0.7937328425289514, 'step': 4407000}
INFO:transformers.trainer:{'loss': 4.393367366313934, 'learning_rate': 3.6769618397071506e-05, 'epoch': 0.7938228961757098, 'step': 4407500}
INFO:transformers.trainer:{'loss': 4.566900933742523, 'learning_rate': 3.6768117502958865e-05, 'epoch': 0.7939129498224683, 'step': 4408000}
INFO:transformers.trainer:{'loss': 4.453574837207794, 'learning_rate': 3.6766616608846224e-05, 'epoch': 0.7940030034692267, 'step': 4408500}
INFO:transformers.trainer:{'loss': 4.562932133197784, 'learning_rate': 3.676511571473358e-05, 'epoch': 0.7940930571159851, 'step': 4409000}
INFO:transformers.trainer:{'loss': 4.59769183921814, 'learning_rate': 3.676361482062094e-05, 'epoch': 0.7941831107627436, 'step': 4409500}
INFO:transformers.trainer:{'loss': 4.442173527240753, 'learning_rate': 3.67621139265083e-05, 'epoch': 0.794273164409502, 'step': 4410000}
INFO:transformers.trainer:{'loss': 4.352828755378723, 'learning_rate': 3.676061303239566e-05, 'epoch': 0.7943632180562604, 'step': 4410500}
INFO:transformers.trainer:{'loss': 4.424384306907654, 'learning_rate': 3.675911213828302e-05, 'epoch': 0.7944532717030189, 'step': 4411000}
INFO:transformers.trainer:{'loss': 4.389089862346649, 'learning_rate': 3.675761124417038e-05, 'epoch': 0.7945433253497773, 'step': 4411500}
INFO:transformers.trainer:{'loss': 4.469545729160309, 'learning_rate': 3.675611035005774e-05, 'epoch': 0.7946333789965359, 'step': 4412000}
INFO:transformers.trainer:{'loss': 4.471944153785706, 'learning_rate': 3.6754609455945096e-05, 'epoch': 0.7947234326432943, 'step': 4412500}
INFO:transformers.trainer:{'loss': 4.344033263683319, 'learning_rate': 3.6753108561832455e-05, 'epoch': 0.7948134862900527, 'step': 4413000}
INFO:transformers.trainer:{'loss': 4.365893662691116, 'learning_rate': 3.6751607667719814e-05, 'epoch': 0.7949035399368112, 'step': 4413500}
INFO:transformers.trainer:{'loss': 4.446516671657562, 'learning_rate': 3.675010677360717e-05, 'epoch': 0.7949935935835696, 'step': 4414000}
INFO:transformers.trainer:{'loss': 4.283379805088043, 'learning_rate': 3.674860587949453e-05, 'epoch': 0.7950836472303281, 'step': 4414500}
INFO:transformers.trainer:{'loss': 4.404462296247482, 'learning_rate': 3.674710498538189e-05, 'epoch': 0.7951737008770865, 'step': 4415000}
INFO:transformers.trainer:{'loss': 4.323966301441192, 'learning_rate': 3.674560409126925e-05, 'epoch': 0.7952637545238449, 'step': 4415500}
INFO:transformers.trainer:{'loss': 4.383107286930084, 'learning_rate': 3.674410319715661e-05, 'epoch': 0.7953538081706034, 'step': 4416000}
INFO:transformers.trainer:{'loss': 4.423717680692673, 'learning_rate': 3.674260230304397e-05, 'epoch': 0.7954438618173618, 'step': 4416500}
INFO:transformers.trainer:{'loss': 4.361107684135437, 'learning_rate': 3.674110140893133e-05, 'epoch': 0.7955339154641203, 'step': 4417000}
INFO:transformers.trainer:{'loss': 4.285392154216766, 'learning_rate': 3.673960051481869e-05, 'epoch': 0.7956239691108787, 'step': 4417500}
INFO:transformers.trainer:{'loss': 4.0925544505119325, 'learning_rate': 3.673809962070605e-05, 'epoch': 0.7957140227576371, 'step': 4418000}
INFO:transformers.trainer:{'loss': 4.315300617456436, 'learning_rate': 3.6736598726593405e-05, 'epoch': 0.7958040764043957, 'step': 4418500}
INFO:transformers.trainer:{'loss': 4.447866016626358, 'learning_rate': 3.673509783248077e-05, 'epoch': 0.7958941300511541, 'step': 4419000}
INFO:transformers.trainer:{'loss': 4.293471122503281, 'learning_rate': 3.673359693836812e-05, 'epoch': 0.7959841836979126, 'step': 4419500}
INFO:transformers.trainer:{'loss': 4.35021984243393, 'learning_rate': 3.673209604425549e-05, 'epoch': 0.796074237344671, 'step': 4420000}
INFO:transformers.trainer:{'loss': 4.332800325393677, 'learning_rate': 3.673059515014284e-05, 'epoch': 0.7961642909914294, 'step': 4420500}
INFO:transformers.trainer:{'loss': 4.42535612487793, 'learning_rate': 3.672909425603021e-05, 'epoch': 0.7962543446381879, 'step': 4421000}
INFO:transformers.trainer:{'loss': 4.622034023284912, 'learning_rate': 3.672759336191756e-05, 'epoch': 0.7963443982849463, 'step': 4421500}
INFO:transformers.trainer:{'loss': 4.444613041877747, 'learning_rate': 3.6726092467804925e-05, 'epoch': 0.7964344519317047, 'step': 4422000}
INFO:transformers.trainer:{'loss': 4.661319052219391, 'learning_rate': 3.672459157369228e-05, 'epoch': 0.7965245055784632, 'step': 4422500}
INFO:transformers.trainer:{'loss': 4.565647801876068, 'learning_rate': 3.672309067957964e-05, 'epoch': 0.7966145592252216, 'step': 4423000}
INFO:transformers.trainer:{'loss': 4.4458528966903685, 'learning_rate': 3.6721589785466995e-05, 'epoch': 0.7967046128719801, 'step': 4423500}
INFO:transformers.trainer:{'loss': 4.489274016857147, 'learning_rate': 3.672008889135436e-05, 'epoch': 0.7967946665187385, 'step': 4424000}
INFO:transformers.trainer:{'loss': 4.522964336872101, 'learning_rate': 3.671858799724172e-05, 'epoch': 0.7968847201654969, 'step': 4424500}
INFO:transformers.trainer:{'loss': 4.580790739059449, 'learning_rate': 3.671708710312908e-05, 'epoch': 0.7969747738122555, 'step': 4425000}
INFO:transformers.trainer:{'loss': 4.514181215286255, 'learning_rate': 3.671558620901644e-05, 'epoch': 0.7970648274590139, 'step': 4425500}
INFO:transformers.trainer:{'loss': 4.574275874137879, 'learning_rate': 3.67140853149038e-05, 'epoch': 0.7971548811057724, 'step': 4426000}
INFO:transformers.trainer:{'loss': 4.5992735509872436, 'learning_rate': 3.6712584420791156e-05, 'epoch': 0.7972449347525308, 'step': 4426500}
INFO:transformers.trainer:{'loss': 4.48710786819458, 'learning_rate': 3.6711083526678515e-05, 'epoch': 0.7973349883992892, 'step': 4427000}
INFO:transformers.trainer:{'loss': 4.502841773986816, 'learning_rate': 3.6709582632565874e-05, 'epoch': 0.7974250420460477, 'step': 4427500}
INFO:transformers.trainer:{'loss': 4.434442579746246, 'learning_rate': 3.6708081738453234e-05, 'epoch': 0.7975150956928061, 'step': 4428000}
INFO:transformers.trainer:{'loss': 4.440284251213074, 'learning_rate': 3.670658084434059e-05, 'epoch': 0.7976051493395646, 'step': 4428500}
INFO:transformers.trainer:{'loss': 4.32618205499649, 'learning_rate': 3.670507995022795e-05, 'epoch': 0.797695202986323, 'step': 4429000}
INFO:transformers.trainer:{'loss': 4.352596019268036, 'learning_rate': 3.670357905611531e-05, 'epoch': 0.7977852566330814, 'step': 4429500}
INFO:transformers.trainer:{'loss': 4.4470550379753115, 'learning_rate': 3.670207816200267e-05, 'epoch': 0.7978753102798399, 'step': 4430000}
INFO:transformers.trainer:{'loss': 4.491786008358002, 'learning_rate': 3.670057726789003e-05, 'epoch': 0.7979653639265983, 'step': 4430500}
INFO:transformers.trainer:{'loss': 4.462995327949524, 'learning_rate': 3.669907637377739e-05, 'epoch': 0.7980554175733569, 'step': 4431000}
INFO:transformers.trainer:{'loss': 4.625508584976196, 'learning_rate': 3.669757547966475e-05, 'epoch': 0.7981454712201153, 'step': 4431500}
INFO:transformers.trainer:{'loss': 4.59450915145874, 'learning_rate': 3.669607458555211e-05, 'epoch': 0.7982355248668737, 'step': 4432000}
INFO:transformers.trainer:{'loss': 4.474520832777023, 'learning_rate': 3.6694573691439465e-05, 'epoch': 0.7983255785136322, 'step': 4432500}
INFO:transformers.trainer:{'loss': 4.615642359733582, 'learning_rate': 3.6693072797326824e-05, 'epoch': 0.7984156321603906, 'step': 4433000}
INFO:transformers.trainer:{'loss': 4.6031412477493285, 'learning_rate': 3.669157190321418e-05, 'epoch': 0.798505685807149, 'step': 4433500}
INFO:transformers.trainer:{'loss': 4.338359942913056, 'learning_rate': 3.669007100910154e-05, 'epoch': 0.7985957394539075, 'step': 4434000}
INFO:transformers.trainer:{'loss': 4.393690603733063, 'learning_rate': 3.66885701149889e-05, 'epoch': 0.7986857931006659, 'step': 4434500}
INFO:transformers.trainer:{'loss': 4.444400189876556, 'learning_rate': 3.668706922087626e-05, 'epoch': 0.7987758467474244, 'step': 4435000}
INFO:transformers.trainer:{'loss': 4.389620960235596, 'learning_rate': 3.668556832676362e-05, 'epoch': 0.7988659003941828, 'step': 4435500}
INFO:transformers.trainer:{'loss': 4.500576364517212, 'learning_rate': 3.668406743265098e-05, 'epoch': 0.7989559540409412, 'step': 4436000}
INFO:transformers.trainer:{'loss': 4.607176133155823, 'learning_rate': 3.668256653853834e-05, 'epoch': 0.7990460076876997, 'step': 4436500}
INFO:transformers.trainer:{'loss': 4.517218246936798, 'learning_rate': 3.6681065644425696e-05, 'epoch': 0.7991360613344581, 'step': 4437000}
INFO:transformers.trainer:{'loss': 4.524140303134918, 'learning_rate': 3.6679564750313055e-05, 'epoch': 0.7992261149812167, 'step': 4437500}
INFO:transformers.trainer:{'loss': 4.470526137828827, 'learning_rate': 3.6678063856200415e-05, 'epoch': 0.799316168627975, 'step': 4438000}
INFO:transformers.trainer:{'loss': 4.423225836753845, 'learning_rate': 3.667656296208778e-05, 'epoch': 0.7994062222747335, 'step': 4438500}
INFO:transformers.trainer:{'loss': 4.438396859645843, 'learning_rate': 3.667506206797513e-05, 'epoch': 0.799496275921492, 'step': 4439000}
INFO:transformers.trainer:{'loss': 4.397793834209442, 'learning_rate': 3.66735611738625e-05, 'epoch': 0.7995863295682504, 'step': 4439500}
INFO:transformers.trainer:{'loss': 4.328689109086991, 'learning_rate': 3.667206027974985e-05, 'epoch': 0.7996763832150089, 'step': 4440000}
INFO:transformers.trainer:{'loss': 4.380543763637543, 'learning_rate': 3.6670559385637217e-05, 'epoch': 0.7997664368617673, 'step': 4440500}
INFO:transformers.trainer:{'loss': 4.538167845487594, 'learning_rate': 3.666905849152457e-05, 'epoch': 0.7998564905085257, 'step': 4441000}
INFO:transformers.trainer:{'loss': 4.565289416313171, 'learning_rate': 3.6667557597411935e-05, 'epoch': 0.7999465441552842, 'step': 4441500}
INFO:transformers.trainer:{'loss': 4.520139200210571, 'learning_rate': 3.666605670329929e-05, 'epoch': 0.8000365978020426, 'step': 4442000}
INFO:transformers.trainer:{'loss': 4.315942164421082, 'learning_rate': 3.666455580918665e-05, 'epoch': 0.8001266514488011, 'step': 4442500}
INFO:transformers.trainer:{'loss': 4.380854996442795, 'learning_rate': 3.6663054915074005e-05, 'epoch': 0.8002167050955595, 'step': 4443000}
INFO:transformers.trainer:{'loss': 4.486901852607727, 'learning_rate': 3.666155402096137e-05, 'epoch': 0.8003067587423179, 'step': 4443500}
INFO:transformers.trainer:{'loss': 4.500972702980041, 'learning_rate': 3.666005312684872e-05, 'epoch': 0.8003968123890765, 'step': 4444000}
INFO:transformers.trainer:{'loss': 4.513040020942688, 'learning_rate': 3.665855223273609e-05, 'epoch': 0.8004868660358349, 'step': 4444500}
INFO:transformers.trainer:{'loss': 4.523671912670135, 'learning_rate': 3.665705133862344e-05, 'epoch': 0.8005769196825934, 'step': 4445000}
INFO:transformers.trainer:{'loss': 4.623454957008362, 'learning_rate': 3.665555044451081e-05, 'epoch': 0.8006669733293518, 'step': 4445500}
INFO:transformers.trainer:{'loss': 4.470836462974549, 'learning_rate': 3.6654049550398166e-05, 'epoch': 0.8007570269761102, 'step': 4446000}
INFO:transformers.trainer:{'loss': 4.538037061691284, 'learning_rate': 3.6652548656285525e-05, 'epoch': 0.8008470806228687, 'step': 4446500}
INFO:transformers.trainer:{'loss': 4.552890634536743, 'learning_rate': 3.6651047762172884e-05, 'epoch': 0.8009371342696271, 'step': 4447000}
INFO:transformers.trainer:{'loss': 4.526764048099518, 'learning_rate': 3.664954686806024e-05, 'epoch': 0.8010271879163855, 'step': 4447500}
INFO:transformers.trainer:{'loss': 4.530009173870087, 'learning_rate': 3.66480459739476e-05, 'epoch': 0.801117241563144, 'step': 4448000}
INFO:transformers.trainer:{'loss': 4.515403989315033, 'learning_rate': 3.664654507983496e-05, 'epoch': 0.8012072952099024, 'step': 4448500}
INFO:transformers.trainer:{'loss': 4.5242000374794005, 'learning_rate': 3.664504418572232e-05, 'epoch': 0.8012973488566609, 'step': 4449000}
INFO:transformers.trainer:{'loss': 4.524389817237854, 'learning_rate': 3.664354329160968e-05, 'epoch': 0.8013874025034193, 'step': 4449500}
INFO:transformers.trainer:{'loss': 4.517934213638306, 'learning_rate': 3.664204239749704e-05, 'epoch': 0.8014774561501777, 'step': 4450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.599738429546356, 'learning_rate': 3.66405415033844e-05, 'epoch': 0.8015675097969363, 'step': 4450500}
INFO:transformers.trainer:{'loss': 4.6243718485832215, 'learning_rate': 3.6639040609271757e-05, 'epoch': 0.8016575634436947, 'step': 4451000}
INFO:transformers.trainer:{'loss': 4.527910863876342, 'learning_rate': 3.6637539715159116e-05, 'epoch': 0.8017476170904532, 'step': 4451500}
INFO:transformers.trainer:{'loss': 4.589381136655808, 'learning_rate': 3.6636038821046475e-05, 'epoch': 0.8018376707372116, 'step': 4452000}
INFO:transformers.trainer:{'loss': 4.754228640317917, 'learning_rate': 3.663453792693384e-05, 'epoch': 0.80192772438397, 'step': 4452500}
INFO:transformers.trainer:{'loss': 4.597857056617737, 'learning_rate': 3.663303703282119e-05, 'epoch': 0.8020177780307285, 'step': 4453000}
INFO:transformers.trainer:{'loss': 4.648311667919159, 'learning_rate': 3.663153613870856e-05, 'epoch': 0.8021078316774869, 'step': 4453500}
INFO:transformers.trainer:{'loss': 4.60647873544693, 'learning_rate': 3.663003524459591e-05, 'epoch': 0.8021978853242454, 'step': 4454000}
INFO:transformers.trainer:{'loss': 4.643117503166199, 'learning_rate': 3.662853435048328e-05, 'epoch': 0.8022879389710038, 'step': 4454500}
INFO:transformers.trainer:{'loss': 4.6286378774642944, 'learning_rate': 3.662703345637063e-05, 'epoch': 0.8023779926177622, 'step': 4455000}
INFO:transformers.trainer:{'loss': 4.665273354768753, 'learning_rate': 3.6625532562257995e-05, 'epoch': 0.8024680462645207, 'step': 4455500}
INFO:transformers.trainer:{'loss': 4.527822568655014, 'learning_rate': 3.662403166814535e-05, 'epoch': 0.8025580999112791, 'step': 4456000}
INFO:transformers.trainer:{'loss': 4.54222030878067, 'learning_rate': 3.6622530774032706e-05, 'epoch': 0.8026481535580376, 'step': 4456500}
INFO:transformers.trainer:{'loss': 4.671107925415039, 'learning_rate': 3.6621029879920065e-05, 'epoch': 0.802738207204796, 'step': 4457000}
INFO:transformers.trainer:{'loss': 4.639636358261108, 'learning_rate': 3.6619528985807424e-05, 'epoch': 0.8028282608515545, 'step': 4457500}
INFO:transformers.trainer:{'loss': 4.603046949863434, 'learning_rate': 3.661802809169478e-05, 'epoch': 0.802918314498313, 'step': 4458000}
INFO:transformers.trainer:{'loss': 4.680860692024231, 'learning_rate': 3.661652719758214e-05, 'epoch': 0.8030083681450714, 'step': 4458500}
INFO:transformers.trainer:{'loss': 4.728547783851623, 'learning_rate': 3.661502630346951e-05, 'epoch': 0.8030984217918298, 'step': 4459000}
INFO:transformers.trainer:{'loss': 4.624021373271942, 'learning_rate': 3.661352540935686e-05, 'epoch': 0.8031884754385883, 'step': 4459500}
INFO:transformers.trainer:{'loss': 4.6419002180099485, 'learning_rate': 3.6612024515244226e-05, 'epoch': 0.8032785290853467, 'step': 4460000}
INFO:transformers.trainer:{'loss': 4.706182366371155, 'learning_rate': 3.661052362113158e-05, 'epoch': 0.8033685827321052, 'step': 4460500}
INFO:transformers.trainer:{'loss': 4.598625638246537, 'learning_rate': 3.6609022727018944e-05, 'epoch': 0.8034586363788636, 'step': 4461000}
INFO:transformers.trainer:{'loss': 4.597801545619965, 'learning_rate': 3.66075218329063e-05, 'epoch': 0.803548690025622, 'step': 4461500}
INFO:transformers.trainer:{'loss': 4.666458582878112, 'learning_rate': 3.660602093879366e-05, 'epoch': 0.8036387436723805, 'step': 4462000}
INFO:transformers.trainer:{'loss': 4.70651877117157, 'learning_rate': 3.6604520044681015e-05, 'epoch': 0.8037287973191389, 'step': 4462500}
INFO:transformers.trainer:{'loss': 4.7004690594673155, 'learning_rate': 3.660301915056838e-05, 'epoch': 0.8038188509658974, 'step': 4463000}
INFO:transformers.trainer:{'loss': 4.753933136940002, 'learning_rate': 3.660151825645573e-05, 'epoch': 0.8039089046126559, 'step': 4463500}
INFO:transformers.trainer:{'loss': 4.640077266216278, 'learning_rate': 3.66000173623431e-05, 'epoch': 0.8039989582594143, 'step': 4464000}
INFO:transformers.trainer:{'loss': 4.632808329105377, 'learning_rate': 3.659851646823045e-05, 'epoch': 0.8040890119061728, 'step': 4464500}
INFO:transformers.trainer:{'loss': 4.60573814201355, 'learning_rate': 3.659701557411782e-05, 'epoch': 0.8041790655529312, 'step': 4465000}
INFO:transformers.trainer:{'loss': 4.72545374250412, 'learning_rate': 3.659551468000517e-05, 'epoch': 0.8042691191996897, 'step': 4465500}
INFO:transformers.trainer:{'loss': 4.725728351593018, 'learning_rate': 3.6594013785892535e-05, 'epoch': 0.8043591728464481, 'step': 4466000}
INFO:transformers.trainer:{'loss': 4.651898717880249, 'learning_rate': 3.6592512891779894e-05, 'epoch': 0.8044492264932065, 'step': 4466500}
INFO:transformers.trainer:{'loss': 4.705344458580017, 'learning_rate': 3.659101199766725e-05, 'epoch': 0.804539280139965, 'step': 4467000}
INFO:transformers.trainer:{'loss': 4.648880330562592, 'learning_rate': 3.658951110355461e-05, 'epoch': 0.8046293337867234, 'step': 4467500}
INFO:transformers.trainer:{'loss': 4.581910171508789, 'learning_rate': 3.658801020944197e-05, 'epoch': 0.8047193874334819, 'step': 4468000}
INFO:transformers.trainer:{'loss': 4.63307882642746, 'learning_rate': 3.658650931532933e-05, 'epoch': 0.8048094410802403, 'step': 4468500}
INFO:transformers.trainer:{'loss': 4.549508943557739, 'learning_rate': 3.658500842121669e-05, 'epoch': 0.8048994947269987, 'step': 4469000}
INFO:transformers.trainer:{'loss': 4.439290162086487, 'learning_rate': 3.658350752710405e-05, 'epoch': 0.8049895483737572, 'step': 4469500}
INFO:transformers.trainer:{'loss': 4.475470214605331, 'learning_rate': 3.658200663299141e-05, 'epoch': 0.8050796020205157, 'step': 4470000}
INFO:transformers.trainer:{'loss': 4.607069303989411, 'learning_rate': 3.6580505738878766e-05, 'epoch': 0.805169655667274, 'step': 4470500}
INFO:transformers.trainer:{'loss': 4.581265478610993, 'learning_rate': 3.6579004844766125e-05, 'epoch': 0.8052597093140326, 'step': 4471000}
INFO:transformers.trainer:{'loss': 4.622369585037231, 'learning_rate': 3.6577503950653484e-05, 'epoch': 0.805349762960791, 'step': 4471500}
INFO:transformers.trainer:{'loss': 4.558735447406769, 'learning_rate': 3.6576003056540843e-05, 'epoch': 0.8054398166075495, 'step': 4472000}
INFO:transformers.trainer:{'loss': 4.591154334068299, 'learning_rate': 3.65745021624282e-05, 'epoch': 0.8055298702543079, 'step': 4472500}
INFO:transformers.trainer:{'loss': 4.694138488769531, 'learning_rate': 3.657300126831557e-05, 'epoch': 0.8056199239010663, 'step': 4473000}
INFO:transformers.trainer:{'loss': 4.67695690870285, 'learning_rate': 3.657150037420292e-05, 'epoch': 0.8057099775478248, 'step': 4473500}
INFO:transformers.trainer:{'loss': 4.652770536899567, 'learning_rate': 3.6569999480090286e-05, 'epoch': 0.8058000311945832, 'step': 4474000}
INFO:transformers.trainer:{'loss': 4.671591846942902, 'learning_rate': 3.656849858597764e-05, 'epoch': 0.8058900848413417, 'step': 4474500}
INFO:transformers.trainer:{'loss': 4.6061344900131225, 'learning_rate': 3.6566997691865005e-05, 'epoch': 0.8059801384881001, 'step': 4475000}
INFO:transformers.trainer:{'loss': 4.602843075037002, 'learning_rate': 3.656549679775236e-05, 'epoch': 0.8060701921348585, 'step': 4475500}
INFO:transformers.trainer:{'loss': 4.628932878017426, 'learning_rate': 3.656399590363972e-05, 'epoch': 0.806160245781617, 'step': 4476000}
INFO:transformers.trainer:{'loss': 4.546240249633789, 'learning_rate': 3.6562495009527075e-05, 'epoch': 0.8062502994283754, 'step': 4476500}
INFO:transformers.trainer:{'loss': 4.662866336345672, 'learning_rate': 3.656099411541444e-05, 'epoch': 0.806340353075134, 'step': 4477000}
INFO:transformers.trainer:{'loss': 4.740422205924988, 'learning_rate': 3.655949322130179e-05, 'epoch': 0.8064304067218924, 'step': 4477500}
INFO:transformers.trainer:{'loss': 4.580960512638092, 'learning_rate': 3.655799232718916e-05, 'epoch': 0.8065204603686508, 'step': 4478000}
INFO:transformers.trainer:{'loss': 4.677704321861267, 'learning_rate': 3.655649143307651e-05, 'epoch': 0.8066105140154093, 'step': 4478500}
INFO:transformers.trainer:{'loss': 4.892033277034759, 'learning_rate': 3.655499053896388e-05, 'epoch': 0.8067005676621677, 'step': 4479000}
INFO:transformers.trainer:{'loss': 4.585163153171539, 'learning_rate': 3.655348964485123e-05, 'epoch': 0.8067906213089262, 'step': 4479500}
INFO:transformers.trainer:{'loss': 4.583277346372604, 'learning_rate': 3.655198875073859e-05, 'epoch': 0.8068806749556846, 'step': 4480000}
INFO:transformers.trainer:{'loss': 4.702867871761322, 'learning_rate': 3.6550487856625954e-05, 'epoch': 0.806970728602443, 'step': 4480500}
INFO:transformers.trainer:{'loss': 4.625508807659149, 'learning_rate': 3.6548986962513306e-05, 'epoch': 0.8070607822492015, 'step': 4481000}
INFO:transformers.trainer:{'loss': 4.621529843330383, 'learning_rate': 3.654748606840067e-05, 'epoch': 0.8071508358959599, 'step': 4481500}
INFO:transformers.trainer:{'loss': 4.525178289890289, 'learning_rate': 3.6545985174288024e-05, 'epoch': 0.8072408895427184, 'step': 4482000}
INFO:transformers.trainer:{'loss': 4.599370940208435, 'learning_rate': 3.654448428017539e-05, 'epoch': 0.8073309431894768, 'step': 4482500}
INFO:transformers.trainer:{'loss': 4.60758000087738, 'learning_rate': 3.654298338606274e-05, 'epoch': 0.8074209968362352, 'step': 4483000}
INFO:transformers.trainer:{'loss': 4.607312452316284, 'learning_rate': 3.654148249195011e-05, 'epoch': 0.8075110504829938, 'step': 4483500}
INFO:transformers.trainer:{'loss': 4.613027565479278, 'learning_rate': 3.653998159783746e-05, 'epoch': 0.8076011041297522, 'step': 4484000}
INFO:transformers.trainer:{'loss': 4.680545622825623, 'learning_rate': 3.6538480703724826e-05, 'epoch': 0.8076911577765106, 'step': 4484500}
INFO:transformers.trainer:{'loss': 4.71868890619278, 'learning_rate': 3.653697980961218e-05, 'epoch': 0.8077812114232691, 'step': 4485000}
INFO:transformers.trainer:{'loss': 4.618254157543182, 'learning_rate': 3.6535478915499545e-05, 'epoch': 0.8078712650700275, 'step': 4485500}
INFO:transformers.trainer:{'loss': 4.642926628112793, 'learning_rate': 3.65339780213869e-05, 'epoch': 0.807961318716786, 'step': 4486000}
INFO:transformers.trainer:{'loss': 4.681047905921936, 'learning_rate': 3.653247712727426e-05, 'epoch': 0.8080513723635444, 'step': 4486500}
INFO:transformers.trainer:{'loss': 4.754231652736664, 'learning_rate': 3.653097623316162e-05, 'epoch': 0.8081414260103028, 'step': 4487000}
INFO:transformers.trainer:{'loss': 4.706406371116638, 'learning_rate': 3.652947533904898e-05, 'epoch': 0.8082314796570613, 'step': 4487500}
INFO:transformers.trainer:{'loss': 4.645855319976807, 'learning_rate': 3.652797444493634e-05, 'epoch': 0.8083215333038197, 'step': 4488000}
INFO:transformers.trainer:{'loss': 4.575755838394165, 'learning_rate': 3.65264735508237e-05, 'epoch': 0.8084115869505782, 'step': 4488500}
INFO:transformers.trainer:{'loss': 4.629731313228607, 'learning_rate': 3.652497265671106e-05, 'epoch': 0.8085016405973366, 'step': 4489000}
INFO:transformers.trainer:{'loss': 4.673439598083496, 'learning_rate': 3.652347176259842e-05, 'epoch': 0.808591694244095, 'step': 4489500}
INFO:transformers.trainer:{'loss': 4.601398441791535, 'learning_rate': 3.6521970868485776e-05, 'epoch': 0.8086817478908536, 'step': 4490000}
INFO:transformers.trainer:{'loss': 4.761831789970398, 'learning_rate': 3.6520469974373135e-05, 'epoch': 0.808771801537612, 'step': 4490500}
INFO:transformers.trainer:{'loss': 4.656500390052796, 'learning_rate': 3.6518969080260494e-05, 'epoch': 0.8088618551843705, 'step': 4491000}
INFO:transformers.trainer:{'loss': 4.613298450946808, 'learning_rate': 3.651746818614785e-05, 'epoch': 0.8089519088311289, 'step': 4491500}
INFO:transformers.trainer:{'loss': 4.663431353330612, 'learning_rate': 3.651596729203521e-05, 'epoch': 0.8090419624778873, 'step': 4492000}
INFO:transformers.trainer:{'loss': 4.787211850643158, 'learning_rate': 3.651446639792257e-05, 'epoch': 0.8091320161246458, 'step': 4492500}
INFO:transformers.trainer:{'loss': 4.6544547686576845, 'learning_rate': 3.651296550380993e-05, 'epoch': 0.8092220697714042, 'step': 4493000}
INFO:transformers.trainer:{'loss': 4.642752748966217, 'learning_rate': 3.651146460969729e-05, 'epoch': 0.8093121234181627, 'step': 4493500}
INFO:transformers.trainer:{'loss': 4.593957394599914, 'learning_rate': 3.650996371558465e-05, 'epoch': 0.8094021770649211, 'step': 4494000}
INFO:transformers.trainer:{'loss': 4.573844470024109, 'learning_rate': 3.6508462821472014e-05, 'epoch': 0.8094922307116795, 'step': 4494500}
INFO:transformers.trainer:{'loss': 4.500482186794281, 'learning_rate': 3.6506961927359367e-05, 'epoch': 0.809582284358438, 'step': 4495000}
INFO:transformers.trainer:{'loss': 4.604779562950134, 'learning_rate': 3.650546103324673e-05, 'epoch': 0.8096723380051964, 'step': 4495500}
INFO:transformers.trainer:{'loss': 4.664109679698944, 'learning_rate': 3.6503960139134085e-05, 'epoch': 0.8097623916519548, 'step': 4496000}
INFO:transformers.trainer:{'loss': 4.619698060035706, 'learning_rate': 3.650245924502145e-05, 'epoch': 0.8098524452987134, 'step': 4496500}
INFO:transformers.trainer:{'loss': 4.650107889175415, 'learning_rate': 3.65009583509088e-05, 'epoch': 0.8099424989454718, 'step': 4497000}
INFO:transformers.trainer:{'loss': 4.574153186321259, 'learning_rate': 3.649945745679617e-05, 'epoch': 0.8100325525922303, 'step': 4497500}
INFO:transformers.trainer:{'loss': 4.568322199344635, 'learning_rate': 3.649795656268352e-05, 'epoch': 0.8101226062389887, 'step': 4498000}
INFO:transformers.trainer:{'loss': 4.665836497783661, 'learning_rate': 3.649645566857089e-05, 'epoch': 0.8102126598857471, 'step': 4498500}
INFO:transformers.trainer:{'loss': 4.626554021835327, 'learning_rate': 3.649495477445824e-05, 'epoch': 0.8103027135325056, 'step': 4499000}
INFO:transformers.trainer:{'loss': 4.596705798149109, 'learning_rate': 3.6493453880345605e-05, 'epoch': 0.810392767179264, 'step': 4499500}
INFO:transformers.trainer:{'loss': 4.5825246605873104, 'learning_rate': 3.649195298623296e-05, 'epoch': 0.8104828208260225, 'step': 4500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.526294876098633, 'learning_rate': 3.649045209212032e-05, 'epoch': 0.8105728744727809, 'step': 4500500}
INFO:transformers.trainer:{'loss': 4.559318888187408, 'learning_rate': 3.648895119800768e-05, 'epoch': 0.8106629281195393, 'step': 4501000}
INFO:transformers.trainer:{'loss': 4.580510045051574, 'learning_rate': 3.648745030389504e-05, 'epoch': 0.8107529817662978, 'step': 4501500}
INFO:transformers.trainer:{'loss': 4.672257177114487, 'learning_rate': 3.64859494097824e-05, 'epoch': 0.8108430354130562, 'step': 4502000}
INFO:transformers.trainer:{'loss': 4.633672711372376, 'learning_rate': 3.648444851566976e-05, 'epoch': 0.8109330890598148, 'step': 4502500}
INFO:transformers.trainer:{'loss': 4.557099735260009, 'learning_rate': 3.648294762155712e-05, 'epoch': 0.8110231427065732, 'step': 4503000}
INFO:transformers.trainer:{'loss': 4.58335830116272, 'learning_rate': 3.648144672744448e-05, 'epoch': 0.8111131963533316, 'step': 4503500}
INFO:transformers.trainer:{'loss': 4.629182135105133, 'learning_rate': 3.6479945833331836e-05, 'epoch': 0.8112032500000901, 'step': 4504000}
INFO:transformers.trainer:{'loss': 4.5891421275138855, 'learning_rate': 3.647844493921919e-05, 'epoch': 0.8112933036468485, 'step': 4504500}
INFO:transformers.trainer:{'loss': 4.577768590927124, 'learning_rate': 3.6476944045106554e-05, 'epoch': 0.811383357293607, 'step': 4505000}
INFO:transformers.trainer:{'loss': 4.620348617553711, 'learning_rate': 3.6475443150993907e-05, 'epoch': 0.8114734109403654, 'step': 4505500}
INFO:transformers.trainer:{'loss': 4.624384082794189, 'learning_rate': 3.647394225688127e-05, 'epoch': 0.8115634645871238, 'step': 4506000}
INFO:transformers.trainer:{'loss': 4.591502822875976, 'learning_rate': 3.6472441362768625e-05, 'epoch': 0.8116535182338823, 'step': 4506500}
INFO:transformers.trainer:{'loss': 4.519830666065216, 'learning_rate': 3.647094046865599e-05, 'epoch': 0.8117435718806407, 'step': 4507000}
INFO:transformers.trainer:{'loss': 4.614721662044525, 'learning_rate': 3.646943957454335e-05, 'epoch': 0.8118336255273991, 'step': 4507500}
INFO:transformers.trainer:{'loss': 4.609833529472351, 'learning_rate': 3.646793868043071e-05, 'epoch': 0.8119236791741576, 'step': 4508000}
INFO:transformers.trainer:{'loss': 4.446949328184128, 'learning_rate': 3.646643778631807e-05, 'epoch': 0.812013732820916, 'step': 4508500}
INFO:transformers.trainer:{'loss': 4.393301140785217, 'learning_rate': 3.646493689220543e-05, 'epoch': 0.8121037864676746, 'step': 4509000}
INFO:transformers.trainer:{'loss': 4.500954912662506, 'learning_rate': 3.6463435998092786e-05, 'epoch': 0.812193840114433, 'step': 4509500}
INFO:transformers.trainer:{'loss': 4.583178230285645, 'learning_rate': 3.6461935103980145e-05, 'epoch': 0.8122838937611914, 'step': 4510000}
INFO:transformers.trainer:{'loss': 4.545542676925659, 'learning_rate': 3.6460434209867504e-05, 'epoch': 0.8123739474079499, 'step': 4510500}
INFO:transformers.trainer:{'loss': 4.50482538986206, 'learning_rate': 3.645893331575486e-05, 'epoch': 0.8124640010547083, 'step': 4511000}
INFO:transformers.trainer:{'loss': 4.477523268222809, 'learning_rate': 3.645743242164222e-05, 'epoch': 0.8125540547014668, 'step': 4511500}
INFO:transformers.trainer:{'loss': 4.509035138607025, 'learning_rate': 3.645593152752958e-05, 'epoch': 0.8126441083482252, 'step': 4512000}
INFO:transformers.trainer:{'loss': 4.598727980852127, 'learning_rate': 3.645443063341694e-05, 'epoch': 0.8127341619949836, 'step': 4512500}
INFO:transformers.trainer:{'loss': 4.547755905628204, 'learning_rate': 3.64529297393043e-05, 'epoch': 0.8128242156417421, 'step': 4513000}
INFO:transformers.trainer:{'loss': 4.377230515956879, 'learning_rate': 3.645142884519166e-05, 'epoch': 0.8129142692885005, 'step': 4513500}
INFO:transformers.trainer:{'loss': 4.321379385471344, 'learning_rate': 3.644992795107902e-05, 'epoch': 0.813004322935259, 'step': 4514000}
INFO:transformers.trainer:{'loss': 4.366994725704193, 'learning_rate': 3.6448427056966376e-05, 'epoch': 0.8130943765820174, 'step': 4514500}
INFO:transformers.trainer:{'loss': 4.416641271352768, 'learning_rate': 3.644692616285374e-05, 'epoch': 0.8131844302287758, 'step': 4515000}
INFO:transformers.trainer:{'loss': 4.418452534675598, 'learning_rate': 3.6445425268741094e-05, 'epoch': 0.8132744838755344, 'step': 4515500}
INFO:transformers.trainer:{'loss': 4.446793436288834, 'learning_rate': 3.644392437462846e-05, 'epoch': 0.8133645375222928, 'step': 4516000}
INFO:transformers.trainer:{'loss': 4.4966297192573546, 'learning_rate': 3.644242348051581e-05, 'epoch': 0.8134545911690513, 'step': 4516500}
INFO:transformers.trainer:{'loss': 4.5781516642570494, 'learning_rate': 3.644092258640318e-05, 'epoch': 0.8135446448158097, 'step': 4517000}
INFO:transformers.trainer:{'loss': 4.545749287128449, 'learning_rate': 3.643942169229053e-05, 'epoch': 0.8136346984625681, 'step': 4517500}
INFO:transformers.trainer:{'loss': 4.694037878036499, 'learning_rate': 3.6437920798177896e-05, 'epoch': 0.8137247521093266, 'step': 4518000}
INFO:transformers.trainer:{'loss': 4.604474999904633, 'learning_rate': 3.643641990406525e-05, 'epoch': 0.813814805756085, 'step': 4518500}
INFO:transformers.trainer:{'loss': 4.569047064781189, 'learning_rate': 3.6434919009952614e-05, 'epoch': 0.8139048594028435, 'step': 4519000}
INFO:transformers.trainer:{'loss': 4.648394964694977, 'learning_rate': 3.643341811583997e-05, 'epoch': 0.8139949130496019, 'step': 4519500}
INFO:transformers.trainer:{'loss': 4.616960005760193, 'learning_rate': 3.643191722172733e-05, 'epoch': 0.8140849666963603, 'step': 4520000}
INFO:transformers.trainer:{'loss': 4.634845009326935, 'learning_rate': 3.6430416327614685e-05, 'epoch': 0.8141750203431188, 'step': 4520500}
INFO:transformers.trainer:{'loss': 4.596676834583283, 'learning_rate': 3.642891543350205e-05, 'epoch': 0.8142650739898772, 'step': 4521000}
INFO:transformers.trainer:{'loss': 4.589719563484192, 'learning_rate': 3.642741453938941e-05, 'epoch': 0.8143551276366356, 'step': 4521500}
INFO:transformers.trainer:{'loss': 4.5966558585166934, 'learning_rate': 3.642591364527677e-05, 'epoch': 0.8144451812833942, 'step': 4522000}
INFO:transformers.trainer:{'loss': 4.549817245960235, 'learning_rate': 3.642441275116413e-05, 'epoch': 0.8145352349301526, 'step': 4522500}
INFO:transformers.trainer:{'loss': 4.516072604179382, 'learning_rate': 3.642291185705149e-05, 'epoch': 0.8146252885769111, 'step': 4523000}
INFO:transformers.trainer:{'loss': 4.5830524578094485, 'learning_rate': 3.6421410962938846e-05, 'epoch': 0.8147153422236695, 'step': 4523500}
INFO:transformers.trainer:{'loss': 4.636596614122391, 'learning_rate': 3.6419910068826205e-05, 'epoch': 0.8148053958704279, 'step': 4524000}
INFO:transformers.trainer:{'loss': 4.598648823261261, 'learning_rate': 3.6418409174713564e-05, 'epoch': 0.8148954495171864, 'step': 4524500}
INFO:transformers.trainer:{'loss': 4.543068890571594, 'learning_rate': 3.641690828060092e-05, 'epoch': 0.8149855031639448, 'step': 4525000}
INFO:transformers.trainer:{'loss': 4.405054733753205, 'learning_rate': 3.641540738648828e-05, 'epoch': 0.8150755568107033, 'step': 4525500}
INFO:transformers.trainer:{'loss': 4.457902275800705, 'learning_rate': 3.641390649237564e-05, 'epoch': 0.8151656104574617, 'step': 4526000}
INFO:transformers.trainer:{'loss': 4.495664540767669, 'learning_rate': 3.6412405598263e-05, 'epoch': 0.8152556641042201, 'step': 4526500}
INFO:transformers.trainer:{'loss': 4.53871559047699, 'learning_rate': 3.641090470415036e-05, 'epoch': 0.8153457177509786, 'step': 4527000}
INFO:transformers.trainer:{'loss': 4.472754986286163, 'learning_rate': 3.640940381003772e-05, 'epoch': 0.815435771397737, 'step': 4527500}
INFO:transformers.trainer:{'loss': 4.651428340435028, 'learning_rate': 3.640790291592507e-05, 'epoch': 0.8155258250444956, 'step': 4528000}
INFO:transformers.trainer:{'loss': 4.652990877151489, 'learning_rate': 3.6406402021812436e-05, 'epoch': 0.815615878691254, 'step': 4528500}
INFO:transformers.trainer:{'loss': 4.611038621902466, 'learning_rate': 3.6404901127699795e-05, 'epoch': 0.8157059323380124, 'step': 4529000}
INFO:transformers.trainer:{'loss': 4.567359045028686, 'learning_rate': 3.6403400233587155e-05, 'epoch': 0.8157959859847709, 'step': 4529500}
INFO:transformers.trainer:{'loss': 4.535787547111512, 'learning_rate': 3.6401899339474514e-05, 'epoch': 0.8158860396315293, 'step': 4530000}
INFO:transformers.trainer:{'loss': 4.449570955753327, 'learning_rate': 3.640039844536187e-05, 'epoch': 0.8159760932782878, 'step': 4530500}
INFO:transformers.trainer:{'loss': 4.554498737096787, 'learning_rate': 3.639889755124923e-05, 'epoch': 0.8160661469250462, 'step': 4531000}
INFO:transformers.trainer:{'loss': 4.501043929100037, 'learning_rate': 3.639739665713659e-05, 'epoch': 0.8161562005718046, 'step': 4531500}
INFO:transformers.trainer:{'loss': 4.582418988704681, 'learning_rate': 3.639589576302395e-05, 'epoch': 0.8162462542185631, 'step': 4532000}
INFO:transformers.trainer:{'loss': 4.601302362918854, 'learning_rate': 3.639439486891131e-05, 'epoch': 0.8163363078653215, 'step': 4532500}
INFO:transformers.trainer:{'loss': 4.559155057430267, 'learning_rate': 3.639289397479867e-05, 'epoch': 0.8164263615120799, 'step': 4533000}
INFO:transformers.trainer:{'loss': 4.612436080932617, 'learning_rate': 3.639139308068603e-05, 'epoch': 0.8165164151588384, 'step': 4533500}
INFO:transformers.trainer:{'loss': 4.55904161119461, 'learning_rate': 3.6389892186573386e-05, 'epoch': 0.8166064688055968, 'step': 4534000}
INFO:transformers.trainer:{'loss': 4.604999089241028, 'learning_rate': 3.6388391292460745e-05, 'epoch': 0.8166965224523554, 'step': 4534500}
INFO:transformers.trainer:{'loss': 4.597400740146637, 'learning_rate': 3.6386890398348104e-05, 'epoch': 0.8167865760991138, 'step': 4535000}
INFO:transformers.trainer:{'loss': 4.626243397712708, 'learning_rate': 3.638538950423547e-05, 'epoch': 0.8168766297458722, 'step': 4535500}
INFO:transformers.trainer:{'loss': 4.676320826530456, 'learning_rate': 3.638388861012282e-05, 'epoch': 0.8169666833926307, 'step': 4536000}
INFO:transformers.trainer:{'loss': 4.646865791797638, 'learning_rate': 3.638238771601019e-05, 'epoch': 0.8170567370393891, 'step': 4536500}
INFO:transformers.trainer:{'loss': 4.66666711974144, 'learning_rate': 3.638088682189754e-05, 'epoch': 0.8171467906861476, 'step': 4537000}
INFO:transformers.trainer:{'loss': 4.623716450214386, 'learning_rate': 3.6379385927784906e-05, 'epoch': 0.817236844332906, 'step': 4537500}
INFO:transformers.trainer:{'loss': 4.647905565738678, 'learning_rate': 3.637788503367226e-05, 'epoch': 0.8173268979796644, 'step': 4538000}
INFO:transformers.trainer:{'loss': 4.634855344295501, 'learning_rate': 3.6376384139559624e-05, 'epoch': 0.8174169516264229, 'step': 4538500}
INFO:transformers.trainer:{'loss': 4.544936635017395, 'learning_rate': 3.6374883245446976e-05, 'epoch': 0.8175070052731813, 'step': 4539000}
INFO:transformers.trainer:{'loss': 4.563371857643127, 'learning_rate': 3.637338235133434e-05, 'epoch': 0.8175970589199398, 'step': 4539500}
INFO:transformers.trainer:{'loss': 4.573367212057113, 'learning_rate': 3.6371881457221695e-05, 'epoch': 0.8176871125666982, 'step': 4540000}
INFO:transformers.trainer:{'loss': 4.682897250652314, 'learning_rate': 3.637038056310906e-05, 'epoch': 0.8177771662134566, 'step': 4540500}
INFO:transformers.trainer:{'loss': 4.571413827419281, 'learning_rate': 3.636887966899641e-05, 'epoch': 0.8178672198602152, 'step': 4541000}
INFO:transformers.trainer:{'loss': 4.647380330562592, 'learning_rate': 3.636737877488378e-05, 'epoch': 0.8179572735069736, 'step': 4541500}
INFO:transformers.trainer:{'loss': 4.6491302268505095, 'learning_rate': 3.636587788077113e-05, 'epoch': 0.8180473271537321, 'step': 4542000}
INFO:transformers.trainer:{'loss': 4.68485857129097, 'learning_rate': 3.63643769866585e-05, 'epoch': 0.8181373808004905, 'step': 4542500}
INFO:transformers.trainer:{'loss': 4.63272017288208, 'learning_rate': 3.6362876092545856e-05, 'epoch': 0.8182274344472489, 'step': 4543000}
INFO:transformers.trainer:{'loss': 4.503025464773178, 'learning_rate': 3.6361375198433215e-05, 'epoch': 0.8183174880940074, 'step': 4543500}
INFO:transformers.trainer:{'loss': 4.5863225836753845, 'learning_rate': 3.6359874304320574e-05, 'epoch': 0.8184075417407658, 'step': 4544000}
INFO:transformers.trainer:{'loss': 4.402963555335998, 'learning_rate': 3.635837341020793e-05, 'epoch': 0.8184975953875242, 'step': 4544500}
INFO:transformers.trainer:{'loss': 4.445508178234101, 'learning_rate': 3.635687251609529e-05, 'epoch': 0.8185876490342827, 'step': 4545000}
INFO:transformers.trainer:{'loss': 4.5015354435443875, 'learning_rate': 3.635537162198265e-05, 'epoch': 0.8186777026810411, 'step': 4545500}
INFO:transformers.trainer:{'loss': 4.561795740604401, 'learning_rate': 3.635387072787001e-05, 'epoch': 0.8187677563277996, 'step': 4546000}
INFO:transformers.trainer:{'loss': 4.571934199333191, 'learning_rate': 3.635236983375737e-05, 'epoch': 0.818857809974558, 'step': 4546500}
INFO:transformers.trainer:{'loss': 4.606574687480927, 'learning_rate': 3.635086893964473e-05, 'epoch': 0.8189478636213164, 'step': 4547000}
INFO:transformers.trainer:{'loss': 4.666141146183014, 'learning_rate': 3.634936804553209e-05, 'epoch': 0.819037917268075, 'step': 4547500}
INFO:transformers.trainer:{'loss': 4.6662000889778135, 'learning_rate': 3.6347867151419446e-05, 'epoch': 0.8191279709148334, 'step': 4548000}
INFO:transformers.trainer:{'loss': 4.557119740962982, 'learning_rate': 3.6346366257306805e-05, 'epoch': 0.8192180245615919, 'step': 4548500}
INFO:transformers.trainer:{'loss': 4.633464490413666, 'learning_rate': 3.6344865363194164e-05, 'epoch': 0.8193080782083503, 'step': 4549000}
INFO:transformers.trainer:{'loss': 4.640732784032822, 'learning_rate': 3.634336446908152e-05, 'epoch': 0.8193981318551087, 'step': 4549500}
INFO:transformers.trainer:{'loss': 4.542930490016937, 'learning_rate': 3.634186357496888e-05, 'epoch': 0.8194881855018672, 'step': 4550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.431646008968353, 'learning_rate': 3.634036268085624e-05, 'epoch': 0.8195782391486256, 'step': 4550500}
INFO:transformers.trainer:{'loss': 4.506105139732361, 'learning_rate': 3.63388617867436e-05, 'epoch': 0.8196682927953841, 'step': 4551000}
INFO:transformers.trainer:{'loss': 4.542373233318329, 'learning_rate': 3.633736089263096e-05, 'epoch': 0.8197583464421425, 'step': 4551500}
INFO:transformers.trainer:{'loss': 4.581010732650757, 'learning_rate': 3.633585999851832e-05, 'epoch': 0.8198484000889009, 'step': 4552000}
INFO:transformers.trainer:{'loss': 4.551817123174668, 'learning_rate': 3.633435910440568e-05, 'epoch': 0.8199384537356594, 'step': 4552500}
INFO:transformers.trainer:{'loss': 4.694597043514252, 'learning_rate': 3.633285821029304e-05, 'epoch': 0.8200285073824178, 'step': 4553000}
INFO:transformers.trainer:{'loss': 4.68783615398407, 'learning_rate': 3.6331357316180396e-05, 'epoch': 0.8201185610291764, 'step': 4553500}
INFO:transformers.trainer:{'loss': 4.582161358356476, 'learning_rate': 3.6329856422067755e-05, 'epoch': 0.8202086146759348, 'step': 4554000}
INFO:transformers.trainer:{'loss': 4.46346502494812, 'learning_rate': 3.6328355527955114e-05, 'epoch': 0.8202986683226932, 'step': 4554500}
INFO:transformers.trainer:{'loss': 4.505930840015411, 'learning_rate': 3.632685463384247e-05, 'epoch': 0.8203887219694517, 'step': 4555000}
INFO:transformers.trainer:{'loss': 4.504249332904815, 'learning_rate': 3.632535373972983e-05, 'epoch': 0.8204787756162101, 'step': 4555500}
INFO:transformers.trainer:{'loss': 4.55546496295929, 'learning_rate': 3.632385284561719e-05, 'epoch': 0.8205688292629686, 'step': 4556000}
INFO:transformers.trainer:{'loss': 4.52522913980484, 'learning_rate': 3.632235195150455e-05, 'epoch': 0.820658882909727, 'step': 4556500}
INFO:transformers.trainer:{'loss': 4.441038042068482, 'learning_rate': 3.6320851057391916e-05, 'epoch': 0.8207489365564854, 'step': 4557000}
INFO:transformers.trainer:{'loss': 4.467738042831421, 'learning_rate': 3.631935016327927e-05, 'epoch': 0.8208389902032439, 'step': 4557500}
INFO:transformers.trainer:{'loss': 4.507895257472992, 'learning_rate': 3.6317849269166634e-05, 'epoch': 0.8209290438500023, 'step': 4558000}
INFO:transformers.trainer:{'loss': 4.409550277709961, 'learning_rate': 3.6316348375053986e-05, 'epoch': 0.8210190974967607, 'step': 4558500}
INFO:transformers.trainer:{'loss': 4.494402297973632, 'learning_rate': 3.631484748094135e-05, 'epoch': 0.8211091511435192, 'step': 4559000}
INFO:transformers.trainer:{'loss': 4.477748945474625, 'learning_rate': 3.6313346586828704e-05, 'epoch': 0.8211992047902776, 'step': 4559500}
INFO:transformers.trainer:{'loss': 4.549184389591217, 'learning_rate': 3.631184569271607e-05, 'epoch': 0.8212892584370362, 'step': 4560000}
INFO:transformers.trainer:{'loss': 4.600404646396637, 'learning_rate': 3.631034479860342e-05, 'epoch': 0.8213793120837946, 'step': 4560500}
INFO:transformers.trainer:{'loss': 4.296443654537201, 'learning_rate': 3.630884390449079e-05, 'epoch': 0.821469365730553, 'step': 4561000}
INFO:transformers.trainer:{'loss': 4.302990316867828, 'learning_rate': 3.630734301037814e-05, 'epoch': 0.8215594193773115, 'step': 4561500}
INFO:transformers.trainer:{'loss': 4.41884126329422, 'learning_rate': 3.6305842116265506e-05, 'epoch': 0.8216494730240699, 'step': 4562000}
INFO:transformers.trainer:{'loss': 4.597657131671905, 'learning_rate': 3.630434122215286e-05, 'epoch': 0.8217395266708284, 'step': 4562500}
INFO:transformers.trainer:{'loss': 4.541971075057983, 'learning_rate': 3.6302840328040224e-05, 'epoch': 0.8218295803175868, 'step': 4563000}
INFO:transformers.trainer:{'loss': 4.607621706962585, 'learning_rate': 3.6301339433927583e-05, 'epoch': 0.8219196339643452, 'step': 4563500}
INFO:transformers.trainer:{'loss': 4.432246548891068, 'learning_rate': 3.629983853981494e-05, 'epoch': 0.8220096876111037, 'step': 4564000}
INFO:transformers.trainer:{'loss': 4.351870446205139, 'learning_rate': 3.62983376457023e-05, 'epoch': 0.8220997412578621, 'step': 4564500}
INFO:transformers.trainer:{'loss': 4.27677679681778, 'learning_rate': 3.629683675158966e-05, 'epoch': 0.8221897949046206, 'step': 4565000}
INFO:transformers.trainer:{'loss': 4.279097688436508, 'learning_rate': 3.629533585747702e-05, 'epoch': 0.822279848551379, 'step': 4565500}
INFO:transformers.trainer:{'loss': 4.346749871253968, 'learning_rate': 3.629383496336438e-05, 'epoch': 0.8223699021981374, 'step': 4566000}
INFO:transformers.trainer:{'loss': 4.532438581943512, 'learning_rate': 3.629233406925174e-05, 'epoch': 0.822459955844896, 'step': 4566500}
INFO:transformers.trainer:{'loss': 4.604405132770538, 'learning_rate': 3.62908331751391e-05, 'epoch': 0.8225500094916544, 'step': 4567000}
INFO:transformers.trainer:{'loss': 4.493804520606995, 'learning_rate': 3.6289332281026456e-05, 'epoch': 0.8226400631384129, 'step': 4567500}
INFO:transformers.trainer:{'loss': 4.5009801445007325, 'learning_rate': 3.6287831386913815e-05, 'epoch': 0.8227301167851713, 'step': 4568000}
INFO:transformers.trainer:{'loss': 4.46931188249588, 'learning_rate': 3.6286330492801174e-05, 'epoch': 0.8228201704319297, 'step': 4568500}
INFO:transformers.trainer:{'loss': 4.47960236287117, 'learning_rate': 3.628482959868853e-05, 'epoch': 0.8229102240786882, 'step': 4569000}
INFO:transformers.trainer:{'loss': 4.443936664104462, 'learning_rate': 3.628332870457589e-05, 'epoch': 0.8230002777254466, 'step': 4569500}
INFO:transformers.trainer:{'loss': 4.4744536020755765, 'learning_rate': 3.628182781046325e-05, 'epoch': 0.823090331372205, 'step': 4570000}
INFO:transformers.trainer:{'loss': 4.4723438432216645, 'learning_rate': 3.628032691635061e-05, 'epoch': 0.8231803850189635, 'step': 4570500}
INFO:transformers.trainer:{'loss': 4.501597823858261, 'learning_rate': 3.627882602223797e-05, 'epoch': 0.8232704386657219, 'step': 4571000}
INFO:transformers.trainer:{'loss': 4.460657866001129, 'learning_rate': 3.627732512812533e-05, 'epoch': 0.8233604923124804, 'step': 4571500}
INFO:transformers.trainer:{'loss': 4.518362778186798, 'learning_rate': 3.627582423401269e-05, 'epoch': 0.8234505459592388, 'step': 4572000}
INFO:transformers.trainer:{'loss': 4.530233700752258, 'learning_rate': 3.6274323339900046e-05, 'epoch': 0.8235405996059972, 'step': 4572500}
INFO:transformers.trainer:{'loss': 4.4731672058105465, 'learning_rate': 3.6272822445787405e-05, 'epoch': 0.8236306532527558, 'step': 4573000}
INFO:transformers.trainer:{'loss': 4.3698148965835575, 'learning_rate': 3.6271321551674764e-05, 'epoch': 0.8237207068995142, 'step': 4573500}
INFO:transformers.trainer:{'loss': 4.460232196331024, 'learning_rate': 3.6269820657562124e-05, 'epoch': 0.8238107605462727, 'step': 4574000}
INFO:transformers.trainer:{'loss': 4.493397746086121, 'learning_rate': 3.626831976344948e-05, 'epoch': 0.8239008141930311, 'step': 4574500}
INFO:transformers.trainer:{'loss': 4.389826902627945, 'learning_rate': 3.626681886933684e-05, 'epoch': 0.8239908678397895, 'step': 4575000}
INFO:transformers.trainer:{'loss': 4.425420292377472, 'learning_rate': 3.62653179752242e-05, 'epoch': 0.824080921486548, 'step': 4575500}
INFO:transformers.trainer:{'loss': 4.400737525939942, 'learning_rate': 3.626381708111156e-05, 'epoch': 0.8241709751333064, 'step': 4576000}
INFO:transformers.trainer:{'loss': 4.395180272579193, 'learning_rate': 3.626231618699892e-05, 'epoch': 0.8242610287800649, 'step': 4576500}
INFO:transformers.trainer:{'loss': 4.423163114070892, 'learning_rate': 3.626081529288628e-05, 'epoch': 0.8243510824268233, 'step': 4577000}
INFO:transformers.trainer:{'loss': 4.4938698201179506, 'learning_rate': 3.6259314398773644e-05, 'epoch': 0.8244411360735817, 'step': 4577500}
INFO:transformers.trainer:{'loss': 4.462186667442322, 'learning_rate': 3.6257813504660996e-05, 'epoch': 0.8245311897203402, 'step': 4578000}
INFO:transformers.trainer:{'loss': 4.427381643772125, 'learning_rate': 3.625631261054836e-05, 'epoch': 0.8246212433670986, 'step': 4578500}
INFO:transformers.trainer:{'loss': 4.445382056713104, 'learning_rate': 3.6254811716435714e-05, 'epoch': 0.8247112970138571, 'step': 4579000}
INFO:transformers.trainer:{'loss': 4.444605595111847, 'learning_rate': 3.625331082232308e-05, 'epoch': 0.8248013506606156, 'step': 4579500}
INFO:transformers.trainer:{'loss': 4.41588285279274, 'learning_rate': 3.625180992821043e-05, 'epoch': 0.824891404307374, 'step': 4580000}
INFO:transformers.trainer:{'loss': 4.499855679512024, 'learning_rate': 3.62503090340978e-05, 'epoch': 0.8249814579541325, 'step': 4580500}
INFO:transformers.trainer:{'loss': 4.5482413311004635, 'learning_rate': 3.624880813998515e-05, 'epoch': 0.8250715116008909, 'step': 4581000}
INFO:transformers.trainer:{'loss': 4.439674572467804, 'learning_rate': 3.6247307245872516e-05, 'epoch': 0.8251615652476493, 'step': 4581500}
INFO:transformers.trainer:{'loss': 4.332322051048279, 'learning_rate': 3.624580635175987e-05, 'epoch': 0.8252516188944078, 'step': 4582000}
INFO:transformers.trainer:{'loss': 4.529388737678528, 'learning_rate': 3.6244305457647234e-05, 'epoch': 0.8253416725411662, 'step': 4582500}
INFO:transformers.trainer:{'loss': 4.643582156658173, 'learning_rate': 3.6242804563534586e-05, 'epoch': 0.8254317261879247, 'step': 4583000}
INFO:transformers.trainer:{'loss': 4.533613011360169, 'learning_rate': 3.624130366942195e-05, 'epoch': 0.8255217798346831, 'step': 4583500}
INFO:transformers.trainer:{'loss': 4.520468179225921, 'learning_rate': 3.623980277530931e-05, 'epoch': 0.8256118334814415, 'step': 4584000}
INFO:transformers.trainer:{'loss': 4.5031061668396, 'learning_rate': 3.623830188119667e-05, 'epoch': 0.8257018871282, 'step': 4584500}
INFO:transformers.trainer:{'loss': 4.525960894584656, 'learning_rate': 3.623680098708403e-05, 'epoch': 0.8257919407749584, 'step': 4585000}
INFO:transformers.trainer:{'loss': 4.3802049980163575, 'learning_rate': 3.623530009297139e-05, 'epoch': 0.825881994421717, 'step': 4585500}
INFO:transformers.trainer:{'loss': 4.440084994792938, 'learning_rate': 3.623379919885875e-05, 'epoch': 0.8259720480684754, 'step': 4586000}
INFO:transformers.trainer:{'loss': 4.25498677444458, 'learning_rate': 3.6232298304746107e-05, 'epoch': 0.8260621017152338, 'step': 4586500}
INFO:transformers.trainer:{'loss': 4.620366087198257, 'learning_rate': 3.6230797410633466e-05, 'epoch': 0.8261521553619923, 'step': 4587000}
INFO:transformers.trainer:{'loss': 4.565931378602982, 'learning_rate': 3.6229296516520825e-05, 'epoch': 0.8262422090087507, 'step': 4587500}
INFO:transformers.trainer:{'loss': 4.526919597625732, 'learning_rate': 3.6227795622408184e-05, 'epoch': 0.8263322626555092, 'step': 4588000}
INFO:transformers.trainer:{'loss': 4.585365265369416, 'learning_rate': 3.622629472829554e-05, 'epoch': 0.8264223163022676, 'step': 4588500}
INFO:transformers.trainer:{'loss': 4.58896644115448, 'learning_rate': 3.62247938341829e-05, 'epoch': 0.826512369949026, 'step': 4589000}
INFO:transformers.trainer:{'loss': 4.623969348192215, 'learning_rate': 3.622329294007026e-05, 'epoch': 0.8266024235957845, 'step': 4589500}
INFO:transformers.trainer:{'loss': 4.630596193313599, 'learning_rate': 3.622179204595762e-05, 'epoch': 0.8266924772425429, 'step': 4590000}
INFO:transformers.trainer:{'loss': 4.638228928565979, 'learning_rate': 3.622029115184498e-05, 'epoch': 0.8267825308893014, 'step': 4590500}
INFO:transformers.trainer:{'loss': 4.605831511497498, 'learning_rate': 3.621879025773234e-05, 'epoch': 0.8268725845360598, 'step': 4591000}
INFO:transformers.trainer:{'loss': 4.635747411251068, 'learning_rate': 3.62172893636197e-05, 'epoch': 0.8269626381828182, 'step': 4591500}
INFO:transformers.trainer:{'loss': 4.567403218269348, 'learning_rate': 3.6215788469507056e-05, 'epoch': 0.8270526918295767, 'step': 4592000}
INFO:transformers.trainer:{'loss': 4.582715211629868, 'learning_rate': 3.6214287575394415e-05, 'epoch': 0.8271427454763352, 'step': 4592500}
INFO:transformers.trainer:{'loss': 4.602155376434326, 'learning_rate': 3.6212786681281774e-05, 'epoch': 0.8272327991230936, 'step': 4593000}
INFO:transformers.trainer:{'loss': 4.598460340499878, 'learning_rate': 3.621128578716913e-05, 'epoch': 0.8273228527698521, 'step': 4593500}
INFO:transformers.trainer:{'loss': 4.611567448616028, 'learning_rate': 3.620978489305649e-05, 'epoch': 0.8274129064166105, 'step': 4594000}
INFO:transformers.trainer:{'loss': 4.52642657661438, 'learning_rate': 3.620828399894385e-05, 'epoch': 0.827502960063369, 'step': 4594500}
INFO:transformers.trainer:{'loss': 4.66810755443573, 'learning_rate': 3.620678310483121e-05, 'epoch': 0.8275930137101274, 'step': 4595000}
INFO:transformers.trainer:{'loss': 4.572822496414185, 'learning_rate': 3.620528221071857e-05, 'epoch': 0.8276830673568858, 'step': 4595500}
INFO:transformers.trainer:{'loss': 4.615504278182984, 'learning_rate': 3.620378131660593e-05, 'epoch': 0.8277731210036443, 'step': 4596000}
INFO:transformers.trainer:{'loss': 4.674969899177551, 'learning_rate': 3.620228042249329e-05, 'epoch': 0.8278631746504027, 'step': 4596500}
INFO:transformers.trainer:{'loss': 4.635966323375702, 'learning_rate': 3.620077952838065e-05, 'epoch': 0.8279532282971612, 'step': 4597000}
INFO:transformers.trainer:{'loss': 4.567566947937012, 'learning_rate': 3.6199278634268006e-05, 'epoch': 0.8280432819439196, 'step': 4597500}
INFO:transformers.trainer:{'loss': 4.577888120651245, 'learning_rate': 3.619777774015537e-05, 'epoch': 0.828133335590678, 'step': 4598000}
INFO:transformers.trainer:{'loss': 4.521833802700042, 'learning_rate': 3.6196276846042724e-05, 'epoch': 0.8282233892374365, 'step': 4598500}
INFO:transformers.trainer:{'loss': 4.450787605285645, 'learning_rate': 3.619477595193009e-05, 'epoch': 0.828313442884195, 'step': 4599000}
INFO:transformers.trainer:{'loss': 4.577805944919586, 'learning_rate': 3.619327505781744e-05, 'epoch': 0.8284034965309535, 'step': 4599500}
INFO:transformers.trainer:{'loss': 4.6017688331604, 'learning_rate': 3.619177416370481e-05, 'epoch': 0.8284935501777119, 'step': 4600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.635841857433319, 'learning_rate': 3.619027326959216e-05, 'epoch': 0.8285836038244703, 'step': 4600500}
INFO:transformers.trainer:{'loss': 4.586357134342194, 'learning_rate': 3.6188772375479526e-05, 'epoch': 0.8286736574712288, 'step': 4601000}
INFO:transformers.trainer:{'loss': 4.617075376987457, 'learning_rate': 3.618727148136688e-05, 'epoch': 0.8287637111179872, 'step': 4601500}
INFO:transformers.trainer:{'loss': 4.511671526432037, 'learning_rate': 3.6185770587254244e-05, 'epoch': 0.8288537647647457, 'step': 4602000}
INFO:transformers.trainer:{'loss': 4.567317826747894, 'learning_rate': 3.6184269693141596e-05, 'epoch': 0.8289438184115041, 'step': 4602500}
INFO:transformers.trainer:{'loss': 4.602889504909515, 'learning_rate': 3.618276879902896e-05, 'epoch': 0.8290338720582625, 'step': 4603000}
INFO:transformers.trainer:{'loss': 4.674234248161316, 'learning_rate': 3.6181267904916314e-05, 'epoch': 0.829123925705021, 'step': 4603500}
INFO:transformers.trainer:{'loss': 4.651826339244843, 'learning_rate': 3.617976701080368e-05, 'epoch': 0.8292139793517794, 'step': 4604000}
INFO:transformers.trainer:{'loss': 4.606384996414184, 'learning_rate': 3.617826611669103e-05, 'epoch': 0.8293040329985379, 'step': 4604500}
INFO:transformers.trainer:{'loss': 4.568650007009507, 'learning_rate': 3.61767652225784e-05, 'epoch': 0.8293940866452963, 'step': 4605000}
INFO:transformers.trainer:{'loss': 4.675895209312439, 'learning_rate': 3.617526432846576e-05, 'epoch': 0.8294841402920548, 'step': 4605500}
INFO:transformers.trainer:{'loss': 4.604160747528076, 'learning_rate': 3.6173763434353116e-05, 'epoch': 0.8295741939388133, 'step': 4606000}
INFO:transformers.trainer:{'loss': 4.655830607891083, 'learning_rate': 3.6172262540240475e-05, 'epoch': 0.8296642475855717, 'step': 4606500}
INFO:transformers.trainer:{'loss': 4.6463506038188935, 'learning_rate': 3.6170761646127834e-05, 'epoch': 0.8297543012323301, 'step': 4607000}
INFO:transformers.trainer:{'loss': 4.640042012691498, 'learning_rate': 3.6169260752015193e-05, 'epoch': 0.8298443548790886, 'step': 4607500}
INFO:transformers.trainer:{'loss': 4.657450406551361, 'learning_rate': 3.616775985790255e-05, 'epoch': 0.829934408525847, 'step': 4608000}
INFO:transformers.trainer:{'loss': 4.595271242499352, 'learning_rate': 3.616625896378991e-05, 'epoch': 0.8300244621726055, 'step': 4608500}
INFO:transformers.trainer:{'loss': 4.642418386697769, 'learning_rate': 3.616475806967727e-05, 'epoch': 0.8301145158193639, 'step': 4609000}
INFO:transformers.trainer:{'loss': 4.701561406612396, 'learning_rate': 3.616325717556463e-05, 'epoch': 0.8302045694661223, 'step': 4609500}
INFO:transformers.trainer:{'loss': 4.651693167209626, 'learning_rate': 3.616175628145199e-05, 'epoch': 0.8302946231128808, 'step': 4610000}
INFO:transformers.trainer:{'loss': 4.688827680110931, 'learning_rate': 3.616025538733935e-05, 'epoch': 0.8303846767596392, 'step': 4610500}
INFO:transformers.trainer:{'loss': 4.624484947681427, 'learning_rate': 3.615875449322671e-05, 'epoch': 0.8304747304063977, 'step': 4611000}
INFO:transformers.trainer:{'loss': 4.61136821603775, 'learning_rate': 3.6157253599114066e-05, 'epoch': 0.8305647840531561, 'step': 4611500}
INFO:transformers.trainer:{'loss': 4.594756970405578, 'learning_rate': 3.6155752705001425e-05, 'epoch': 0.8306548376999145, 'step': 4612000}
INFO:transformers.trainer:{'loss': 4.545153186321259, 'learning_rate': 3.6154251810888784e-05, 'epoch': 0.8307448913466731, 'step': 4612500}
INFO:transformers.trainer:{'loss': 4.434746123790741, 'learning_rate': 3.615275091677614e-05, 'epoch': 0.8308349449934315, 'step': 4613000}
INFO:transformers.trainer:{'loss': 4.589575659751892, 'learning_rate': 3.61512500226635e-05, 'epoch': 0.83092499864019, 'step': 4613500}
INFO:transformers.trainer:{'loss': 4.643674510478974, 'learning_rate': 3.614974912855086e-05, 'epoch': 0.8310150522869484, 'step': 4614000}
INFO:transformers.trainer:{'loss': 4.577010410785675, 'learning_rate': 3.614824823443822e-05, 'epoch': 0.8311051059337068, 'step': 4614500}
INFO:transformers.trainer:{'loss': 4.601813037395477, 'learning_rate': 3.614674734032558e-05, 'epoch': 0.8311951595804653, 'step': 4615000}
INFO:transformers.trainer:{'loss': 4.5777004623413085, 'learning_rate': 3.614524644621294e-05, 'epoch': 0.8312852132272237, 'step': 4615500}
INFO:transformers.trainer:{'loss': 4.456044396877289, 'learning_rate': 3.61437455521003e-05, 'epoch': 0.8313752668739822, 'step': 4616000}
INFO:transformers.trainer:{'loss': 4.556250603675842, 'learning_rate': 3.6142244657987656e-05, 'epoch': 0.8314653205207406, 'step': 4616500}
INFO:transformers.trainer:{'loss': 4.433321373462677, 'learning_rate': 3.6140743763875015e-05, 'epoch': 0.831555374167499, 'step': 4617000}
INFO:transformers.trainer:{'loss': 4.4394689435958865, 'learning_rate': 3.6139242869762374e-05, 'epoch': 0.8316454278142575, 'step': 4617500}
INFO:transformers.trainer:{'loss': 4.346421381950378, 'learning_rate': 3.6137741975649734e-05, 'epoch': 0.831735481461016, 'step': 4618000}
INFO:transformers.trainer:{'loss': 4.275552164316178, 'learning_rate': 3.61362410815371e-05, 'epoch': 0.8318255351077743, 'step': 4618500}
INFO:transformers.trainer:{'loss': 4.237595515489578, 'learning_rate': 3.613474018742445e-05, 'epoch': 0.8319155887545329, 'step': 4619000}
INFO:transformers.trainer:{'loss': 4.366286687850952, 'learning_rate': 3.613323929331182e-05, 'epoch': 0.8320056424012913, 'step': 4619500}
INFO:transformers.trainer:{'loss': 4.528450711250305, 'learning_rate': 3.613173839919917e-05, 'epoch': 0.8320956960480498, 'step': 4620000}
INFO:transformers.trainer:{'loss': 4.542037234306336, 'learning_rate': 3.6130237505086536e-05, 'epoch': 0.8321857496948082, 'step': 4620500}
INFO:transformers.trainer:{'loss': 4.4336243517398835, 'learning_rate': 3.612873661097389e-05, 'epoch': 0.8322758033415666, 'step': 4621000}
INFO:transformers.trainer:{'loss': 4.478259533405304, 'learning_rate': 3.6127235716861254e-05, 'epoch': 0.8323658569883251, 'step': 4621500}
INFO:transformers.trainer:{'loss': 4.587357472896576, 'learning_rate': 3.6125734822748606e-05, 'epoch': 0.8324559106350835, 'step': 4622000}
INFO:transformers.trainer:{'loss': 4.597180595874787, 'learning_rate': 3.612423392863597e-05, 'epoch': 0.832545964281842, 'step': 4622500}
INFO:transformers.trainer:{'loss': 4.457329030513764, 'learning_rate': 3.6122733034523324e-05, 'epoch': 0.8326360179286004, 'step': 4623000}
INFO:transformers.trainer:{'loss': 4.411063817501068, 'learning_rate': 3.612123214041069e-05, 'epoch': 0.8327260715753588, 'step': 4623500}
INFO:transformers.trainer:{'loss': 4.370141809940338, 'learning_rate': 3.611973124629804e-05, 'epoch': 0.8328161252221173, 'step': 4624000}
INFO:transformers.trainer:{'loss': 4.316730687379837, 'learning_rate': 3.611823035218541e-05, 'epoch': 0.8329061788688757, 'step': 4624500}
INFO:transformers.trainer:{'loss': 4.1910643172264095, 'learning_rate': 3.611672945807276e-05, 'epoch': 0.8329962325156343, 'step': 4625000}
INFO:transformers.trainer:{'loss': 4.037416014909744, 'learning_rate': 3.6115228563960126e-05, 'epoch': 0.8330862861623927, 'step': 4625500}
INFO:transformers.trainer:{'loss': 4.406063635349273, 'learning_rate': 3.6113727669847485e-05, 'epoch': 0.8331763398091511, 'step': 4626000}
INFO:transformers.trainer:{'loss': 4.1869525418281555, 'learning_rate': 3.6112226775734844e-05, 'epoch': 0.8332663934559096, 'step': 4626500}
INFO:transformers.trainer:{'loss': 4.279482125043869, 'learning_rate': 3.61107258816222e-05, 'epoch': 0.833356447102668, 'step': 4627000}
INFO:transformers.trainer:{'loss': 4.23210961484909, 'learning_rate': 3.610922498750956e-05, 'epoch': 0.8334465007494265, 'step': 4627500}
INFO:transformers.trainer:{'loss': 4.14179339838028, 'learning_rate': 3.610772409339692e-05, 'epoch': 0.8335365543961849, 'step': 4628000}
INFO:transformers.trainer:{'loss': 4.3779326338768, 'learning_rate': 3.610622319928428e-05, 'epoch': 0.8336266080429433, 'step': 4628500}
INFO:transformers.trainer:{'loss': 4.492522939682007, 'learning_rate': 3.610472230517164e-05, 'epoch': 0.8337166616897018, 'step': 4629000}
INFO:transformers.trainer:{'loss': 4.4116905431747435, 'learning_rate': 3.6103221411059e-05, 'epoch': 0.8338067153364602, 'step': 4629500}
INFO:transformers.trainer:{'loss': 4.468018023014069, 'learning_rate': 3.610172051694636e-05, 'epoch': 0.8338967689832186, 'step': 4630000}
INFO:transformers.trainer:{'loss': 4.298338232517242, 'learning_rate': 3.6100219622833717e-05, 'epoch': 0.8339868226299771, 'step': 4630500}
INFO:transformers.trainer:{'loss': 4.178536546945572, 'learning_rate': 3.6098718728721076e-05, 'epoch': 0.8340768762767355, 'step': 4631000}
INFO:transformers.trainer:{'loss': 4.229200482606887, 'learning_rate': 3.6097217834608435e-05, 'epoch': 0.8341669299234941, 'step': 4631500}
INFO:transformers.trainer:{'loss': 4.299269057750702, 'learning_rate': 3.6095716940495794e-05, 'epoch': 0.8342569835702525, 'step': 4632000}
INFO:transformers.trainer:{'loss': 4.396704934835434, 'learning_rate': 3.609421604638315e-05, 'epoch': 0.8343470372170109, 'step': 4632500}
INFO:transformers.trainer:{'loss': 4.246048274993896, 'learning_rate': 3.609271515227051e-05, 'epoch': 0.8344370908637694, 'step': 4633000}
INFO:transformers.trainer:{'loss': 4.279434533596039, 'learning_rate': 3.609121425815787e-05, 'epoch': 0.8345271445105278, 'step': 4633500}
INFO:transformers.trainer:{'loss': 4.516318280220032, 'learning_rate': 3.608971336404523e-05, 'epoch': 0.8346171981572863, 'step': 4634000}
INFO:transformers.trainer:{'loss': 4.405856153488159, 'learning_rate': 3.608821246993259e-05, 'epoch': 0.8347072518040447, 'step': 4634500}
INFO:transformers.trainer:{'loss': 4.1192130975723265, 'learning_rate': 3.608671157581995e-05, 'epoch': 0.8347973054508031, 'step': 4635000}
INFO:transformers.trainer:{'loss': 4.22314267039299, 'learning_rate': 3.608521068170731e-05, 'epoch': 0.8348873590975616, 'step': 4635500}
INFO:transformers.trainer:{'loss': 4.203017311811447, 'learning_rate': 3.6083709787594666e-05, 'epoch': 0.83497741274432, 'step': 4636000}
INFO:transformers.trainer:{'loss': 4.282797290563583, 'learning_rate': 3.6082208893482025e-05, 'epoch': 0.8350674663910785, 'step': 4636500}
INFO:transformers.trainer:{'loss': 4.549776238203049, 'learning_rate': 3.6080707999369384e-05, 'epoch': 0.8351575200378369, 'step': 4637000}
INFO:transformers.trainer:{'loss': 4.597465696334839, 'learning_rate': 3.607920710525674e-05, 'epoch': 0.8352475736845953, 'step': 4637500}
INFO:transformers.trainer:{'loss': 4.522380796432495, 'learning_rate': 3.60777062111441e-05, 'epoch': 0.8353376273313539, 'step': 4638000}
INFO:transformers.trainer:{'loss': 4.555888994216919, 'learning_rate': 3.607620531703146e-05, 'epoch': 0.8354276809781123, 'step': 4638500}
INFO:transformers.trainer:{'loss': 4.579158863544464, 'learning_rate': 3.607470442291882e-05, 'epoch': 0.8355177346248708, 'step': 4639000}
INFO:transformers.trainer:{'loss': 4.505992488384247, 'learning_rate': 3.607320352880618e-05, 'epoch': 0.8356077882716292, 'step': 4639500}
INFO:transformers.trainer:{'loss': 4.486011123418808, 'learning_rate': 3.6071702634693545e-05, 'epoch': 0.8356978419183876, 'step': 4640000}
INFO:transformers.trainer:{'loss': 4.59869825220108, 'learning_rate': 3.60702017405809e-05, 'epoch': 0.8357878955651461, 'step': 4640500}
INFO:transformers.trainer:{'loss': 4.008627185106278, 'learning_rate': 3.606870084646826e-05, 'epoch': 0.8358779492119045, 'step': 4641000}
INFO:transformers.trainer:{'loss': 3.9976960589885713, 'learning_rate': 3.6067199952355616e-05, 'epoch': 0.835968002858663, 'step': 4641500}
INFO:transformers.trainer:{'loss': 4.3555108485221865, 'learning_rate': 3.606569905824298e-05, 'epoch': 0.8360580565054214, 'step': 4642000}
INFO:transformers.trainer:{'loss': 4.282591896533966, 'learning_rate': 3.6064198164130334e-05, 'epoch': 0.8361481101521798, 'step': 4642500}
INFO:transformers.trainer:{'loss': 4.5350988240242005, 'learning_rate': 3.60626972700177e-05, 'epoch': 0.8362381637989383, 'step': 4643000}
INFO:transformers.trainer:{'loss': 4.315961538314819, 'learning_rate': 3.606119637590505e-05, 'epoch': 0.8363282174456967, 'step': 4643500}
INFO:transformers.trainer:{'loss': 4.20988747215271, 'learning_rate': 3.605969548179242e-05, 'epoch': 0.8364182710924551, 'step': 4644000}
INFO:transformers.trainer:{'loss': 4.202674438476563, 'learning_rate': 3.605819458767977e-05, 'epoch': 0.8365083247392137, 'step': 4644500}
INFO:transformers.trainer:{'loss': 4.177151091098786, 'learning_rate': 3.6056693693567136e-05, 'epoch': 0.8365983783859721, 'step': 4645000}
INFO:transformers.trainer:{'loss': 4.074310637235642, 'learning_rate': 3.605519279945449e-05, 'epoch': 0.8366884320327306, 'step': 4645500}
INFO:transformers.trainer:{'loss': 4.030732508897781, 'learning_rate': 3.6053691905341854e-05, 'epoch': 0.836778485679489, 'step': 4646000}
INFO:transformers.trainer:{'loss': 4.178760210037232, 'learning_rate': 3.605219101122921e-05, 'epoch': 0.8368685393262474, 'step': 4646500}
INFO:transformers.trainer:{'loss': 4.364285865783692, 'learning_rate': 3.605069011711657e-05, 'epoch': 0.8369585929730059, 'step': 4647000}
INFO:transformers.trainer:{'loss': 4.3343932247161865, 'learning_rate': 3.604918922300393e-05, 'epoch': 0.8370486466197643, 'step': 4647500}
INFO:transformers.trainer:{'loss': 4.430353382587433, 'learning_rate': 3.604768832889129e-05, 'epoch': 0.8371387002665228, 'step': 4648000}
INFO:transformers.trainer:{'loss': 4.466615668058395, 'learning_rate': 3.604618743477865e-05, 'epoch': 0.8372287539132812, 'step': 4648500}
INFO:transformers.trainer:{'loss': 4.429360391139984, 'learning_rate': 3.604468654066601e-05, 'epoch': 0.8373188075600396, 'step': 4649000}
INFO:transformers.trainer:{'loss': 4.528008027076721, 'learning_rate': 3.604318564655337e-05, 'epoch': 0.8374088612067981, 'step': 4649500}
INFO:transformers.trainer:{'loss': 4.533502653121948, 'learning_rate': 3.6041684752440726e-05, 'epoch': 0.8374989148535565, 'step': 4650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.5772375779151915, 'learning_rate': 3.6040183858328085e-05, 'epoch': 0.8375889685003151, 'step': 4650500}
INFO:transformers.trainer:{'loss': 4.434501171588898, 'learning_rate': 3.6038682964215444e-05, 'epoch': 0.8376790221470735, 'step': 4651000}
INFO:transformers.trainer:{'loss': 4.486935527324676, 'learning_rate': 3.6037182070102803e-05, 'epoch': 0.8377690757938319, 'step': 4651500}
INFO:transformers.trainer:{'loss': 4.502281579494476, 'learning_rate': 3.603568117599016e-05, 'epoch': 0.8378591294405904, 'step': 4652000}
INFO:transformers.trainer:{'loss': 4.605061893463135, 'learning_rate': 3.603418028187752e-05, 'epoch': 0.8379491830873488, 'step': 4652500}
INFO:transformers.trainer:{'loss': 4.533533567428589, 'learning_rate': 3.603267938776488e-05, 'epoch': 0.8380392367341073, 'step': 4653000}
INFO:transformers.trainer:{'loss': 4.457543980121613, 'learning_rate': 3.603117849365224e-05, 'epoch': 0.8381292903808657, 'step': 4653500}
INFO:transformers.trainer:{'loss': 4.355838415145874, 'learning_rate': 3.60296775995396e-05, 'epoch': 0.8382193440276241, 'step': 4654000}
INFO:transformers.trainer:{'loss': 4.619895597934723, 'learning_rate': 3.602817670542696e-05, 'epoch': 0.8383093976743826, 'step': 4654500}
INFO:transformers.trainer:{'loss': 4.591816159725189, 'learning_rate': 3.602667581131432e-05, 'epoch': 0.838399451321141, 'step': 4655000}
INFO:transformers.trainer:{'loss': 4.569904524326325, 'learning_rate': 3.6025174917201676e-05, 'epoch': 0.8384895049678994, 'step': 4655500}
INFO:transformers.trainer:{'loss': 4.56449522972107, 'learning_rate': 3.6023674023089035e-05, 'epoch': 0.8385795586146579, 'step': 4656000}
INFO:transformers.trainer:{'loss': 4.48845456647873, 'learning_rate': 3.6022173128976394e-05, 'epoch': 0.8386696122614163, 'step': 4656500}
INFO:transformers.trainer:{'loss': 4.431197767734528, 'learning_rate': 3.602067223486375e-05, 'epoch': 0.8387596659081749, 'step': 4657000}
INFO:transformers.trainer:{'loss': 4.492573378562927, 'learning_rate': 3.601917134075111e-05, 'epoch': 0.8388497195549333, 'step': 4657500}
INFO:transformers.trainer:{'loss': 4.537028331279755, 'learning_rate': 3.601767044663847e-05, 'epoch': 0.8389397732016917, 'step': 4658000}
INFO:transformers.trainer:{'loss': 4.411613106489182, 'learning_rate': 3.601616955252583e-05, 'epoch': 0.8390298268484502, 'step': 4658500}
INFO:transformers.trainer:{'loss': 4.389424572229386, 'learning_rate': 3.601466865841319e-05, 'epoch': 0.8391198804952086, 'step': 4659000}
INFO:transformers.trainer:{'loss': 4.464594485998154, 'learning_rate': 3.601316776430055e-05, 'epoch': 0.8392099341419671, 'step': 4659500}
INFO:transformers.trainer:{'loss': 4.3769165947437285, 'learning_rate': 3.601166687018791e-05, 'epoch': 0.8392999877887255, 'step': 4660000}
INFO:transformers.trainer:{'loss': 4.390821613788605, 'learning_rate': 3.601016597607527e-05, 'epoch': 0.8393900414354839, 'step': 4660500}
INFO:transformers.trainer:{'loss': 4.4633066465854645, 'learning_rate': 3.6008665081962625e-05, 'epoch': 0.8394800950822424, 'step': 4661000}
INFO:transformers.trainer:{'loss': 4.582014814376831, 'learning_rate': 3.600716418784999e-05, 'epoch': 0.8395701487290008, 'step': 4661500}
INFO:transformers.trainer:{'loss': 4.505952421188354, 'learning_rate': 3.6005663293737343e-05, 'epoch': 0.8396602023757593, 'step': 4662000}
INFO:transformers.trainer:{'loss': 4.2570474019050595, 'learning_rate': 3.600416239962471e-05, 'epoch': 0.8397502560225177, 'step': 4662500}
INFO:transformers.trainer:{'loss': 4.427108205795288, 'learning_rate': 3.600266150551206e-05, 'epoch': 0.8398403096692761, 'step': 4663000}
INFO:transformers.trainer:{'loss': 4.3375448575019835, 'learning_rate': 3.600116061139943e-05, 'epoch': 0.8399303633160347, 'step': 4663500}
INFO:transformers.trainer:{'loss': 4.3630535979270935, 'learning_rate': 3.599965971728678e-05, 'epoch': 0.8400204169627931, 'step': 4664000}
INFO:transformers.trainer:{'loss': 4.274561771154404, 'learning_rate': 3.5998158823174145e-05, 'epoch': 0.8401104706095516, 'step': 4664500}
INFO:transformers.trainer:{'loss': 4.211073617458344, 'learning_rate': 3.59966579290615e-05, 'epoch': 0.84020052425631, 'step': 4665000}
INFO:transformers.trainer:{'loss': 4.271983474731445, 'learning_rate': 3.5995157034948864e-05, 'epoch': 0.8402905779030684, 'step': 4665500}
INFO:transformers.trainer:{'loss': 4.395198629379273, 'learning_rate': 3.5993656140836216e-05, 'epoch': 0.8403806315498269, 'step': 4666000}
INFO:transformers.trainer:{'loss': 4.519521755218506, 'learning_rate': 3.599215524672358e-05, 'epoch': 0.8404706851965853, 'step': 4666500}
INFO:transformers.trainer:{'loss': 4.511182484149933, 'learning_rate': 3.599065435261094e-05, 'epoch': 0.8405607388433437, 'step': 4667000}
INFO:transformers.trainer:{'loss': 4.469930963993073, 'learning_rate': 3.59891534584983e-05, 'epoch': 0.8406507924901022, 'step': 4667500}
INFO:transformers.trainer:{'loss': 4.497502420425415, 'learning_rate': 3.598765256438566e-05, 'epoch': 0.8407408461368606, 'step': 4668000}
INFO:transformers.trainer:{'loss': 4.5806996450424196, 'learning_rate': 3.598615167027302e-05, 'epoch': 0.8408308997836191, 'step': 4668500}
INFO:transformers.trainer:{'loss': 4.516603344678879, 'learning_rate': 3.598465077616038e-05, 'epoch': 0.8409209534303775, 'step': 4669000}
INFO:transformers.trainer:{'loss': 4.512261897802353, 'learning_rate': 3.5983149882047736e-05, 'epoch': 0.8410110070771359, 'step': 4669500}
INFO:transformers.trainer:{'loss': 4.459246466875077, 'learning_rate': 3.5981648987935095e-05, 'epoch': 0.8411010607238945, 'step': 4670000}
INFO:transformers.trainer:{'loss': 4.581312341213226, 'learning_rate': 3.5980148093822454e-05, 'epoch': 0.8411911143706529, 'step': 4670500}
INFO:transformers.trainer:{'loss': 4.597272257804871, 'learning_rate': 3.597864719970981e-05, 'epoch': 0.8412811680174114, 'step': 4671000}
INFO:transformers.trainer:{'loss': 4.52821238398552, 'learning_rate': 3.597714630559717e-05, 'epoch': 0.8413712216641698, 'step': 4671500}
INFO:transformers.trainer:{'loss': 4.557447720527649, 'learning_rate': 3.597564541148453e-05, 'epoch': 0.8414612753109282, 'step': 4672000}
INFO:transformers.trainer:{'loss': 4.5892161602973935, 'learning_rate': 3.597414451737189e-05, 'epoch': 0.8415513289576867, 'step': 4672500}
INFO:transformers.trainer:{'loss': 4.550196245670318, 'learning_rate': 3.597264362325925e-05, 'epoch': 0.8416413826044451, 'step': 4673000}
INFO:transformers.trainer:{'loss': 4.368390613555908, 'learning_rate': 3.597114272914661e-05, 'epoch': 0.8417314362512036, 'step': 4673500}
INFO:transformers.trainer:{'loss': 4.029768277645111, 'learning_rate': 3.596964183503397e-05, 'epoch': 0.841821489897962, 'step': 4674000}
INFO:transformers.trainer:{'loss': 4.171082546234131, 'learning_rate': 3.596814094092133e-05, 'epoch': 0.8419115435447204, 'step': 4674500}
INFO:transformers.trainer:{'loss': 4.10470110154152, 'learning_rate': 3.5966640046808686e-05, 'epoch': 0.8420015971914789, 'step': 4675000}
INFO:transformers.trainer:{'loss': 4.187141731262207, 'learning_rate': 3.5965139152696045e-05, 'epoch': 0.8420916508382373, 'step': 4675500}
INFO:transformers.trainer:{'loss': 4.324001008987427, 'learning_rate': 3.5963638258583404e-05, 'epoch': 0.8421817044849959, 'step': 4676000}
INFO:transformers.trainer:{'loss': 4.483945906639099, 'learning_rate': 3.596213736447076e-05, 'epoch': 0.8422717581317543, 'step': 4676500}
INFO:transformers.trainer:{'loss': 4.391422779083252, 'learning_rate': 3.596063647035812e-05, 'epoch': 0.8423618117785127, 'step': 4677000}
INFO:transformers.trainer:{'loss': 4.290486656188965, 'learning_rate': 3.595913557624548e-05, 'epoch': 0.8424518654252712, 'step': 4677500}
INFO:transformers.trainer:{'loss': 4.4764600830078125, 'learning_rate': 3.595763468213284e-05, 'epoch': 0.8425419190720296, 'step': 4678000}
INFO:transformers.trainer:{'loss': 4.425451149940491, 'learning_rate': 3.59561337880202e-05, 'epoch': 0.8426319727187881, 'step': 4678500}
INFO:transformers.trainer:{'loss': 4.339271624565124, 'learning_rate': 3.595463289390756e-05, 'epoch': 0.8427220263655465, 'step': 4679000}
INFO:transformers.trainer:{'loss': 4.14233391714096, 'learning_rate': 3.595313199979492e-05, 'epoch': 0.8428120800123049, 'step': 4679500}
INFO:transformers.trainer:{'loss': 3.9628093354701996, 'learning_rate': 3.5951631105682276e-05, 'epoch': 0.8429021336590634, 'step': 4680000}
INFO:transformers.trainer:{'loss': 4.03076822590828, 'learning_rate': 3.5950130211569635e-05, 'epoch': 0.8429921873058218, 'step': 4680500}
INFO:transformers.trainer:{'loss': 3.92203048491478, 'learning_rate': 3.5948629317457e-05, 'epoch': 0.8430822409525802, 'step': 4681000}
INFO:transformers.trainer:{'loss': 4.04449888753891, 'learning_rate': 3.594712842334435e-05, 'epoch': 0.8431722945993387, 'step': 4681500}
INFO:transformers.trainer:{'loss': 3.984555795907974, 'learning_rate': 3.594562752923172e-05, 'epoch': 0.8432623482460971, 'step': 4682000}
INFO:transformers.trainer:{'loss': 3.8863306658267973, 'learning_rate': 3.594412663511907e-05, 'epoch': 0.8433524018928557, 'step': 4682500}
INFO:transformers.trainer:{'loss': 4.231439565896988, 'learning_rate': 3.594262574100644e-05, 'epoch': 0.843442455539614, 'step': 4683000}
INFO:transformers.trainer:{'loss': 4.278906733512878, 'learning_rate': 3.594112484689379e-05, 'epoch': 0.8435325091863725, 'step': 4683500}
INFO:transformers.trainer:{'loss': 4.2087389550209044, 'learning_rate': 3.5939623952781155e-05, 'epoch': 0.843622562833131, 'step': 4684000}
INFO:transformers.trainer:{'loss': 4.250588975906372, 'learning_rate': 3.593812305866851e-05, 'epoch': 0.8437126164798894, 'step': 4684500}
INFO:transformers.trainer:{'loss': 4.305197740554809, 'learning_rate': 3.593662216455587e-05, 'epoch': 0.8438026701266479, 'step': 4685000}
INFO:transformers.trainer:{'loss': 4.357459064483643, 'learning_rate': 3.5935121270443226e-05, 'epoch': 0.8438927237734063, 'step': 4685500}
INFO:transformers.trainer:{'loss': 4.317165260314941, 'learning_rate': 3.593362037633059e-05, 'epoch': 0.8439827774201647, 'step': 4686000}
INFO:transformers.trainer:{'loss': 4.393730211257934, 'learning_rate': 3.5932119482217944e-05, 'epoch': 0.8440728310669232, 'step': 4686500}
INFO:transformers.trainer:{'loss': 4.266705452203751, 'learning_rate': 3.593061858810531e-05, 'epoch': 0.8441628847136816, 'step': 4687000}
INFO:transformers.trainer:{'loss': 4.2215853583812715, 'learning_rate': 3.592911769399266e-05, 'epoch': 0.8442529383604401, 'step': 4687500}
INFO:transformers.trainer:{'loss': 4.417808512210846, 'learning_rate': 3.592761679988003e-05, 'epoch': 0.8443429920071985, 'step': 4688000}
INFO:transformers.trainer:{'loss': 4.123143099784851, 'learning_rate': 3.592611590576739e-05, 'epoch': 0.8444330456539569, 'step': 4688500}
INFO:transformers.trainer:{'loss': 4.430571833610535, 'learning_rate': 3.5924615011654746e-05, 'epoch': 0.8445230993007155, 'step': 4689000}
INFO:transformers.trainer:{'loss': 4.469289915084839, 'learning_rate': 3.5923114117542105e-05, 'epoch': 0.8446131529474739, 'step': 4689500}
INFO:transformers.trainer:{'loss': 4.368296673297882, 'learning_rate': 3.5921613223429464e-05, 'epoch': 0.8447032065942324, 'step': 4690000}
INFO:transformers.trainer:{'loss': 3.961793461084366, 'learning_rate': 3.592011232931682e-05, 'epoch': 0.8447932602409908, 'step': 4690500}
INFO:transformers.trainer:{'loss': 4.1012194886207585, 'learning_rate': 3.591861143520418e-05, 'epoch': 0.8448833138877492, 'step': 4691000}
INFO:transformers.trainer:{'loss': 4.301809359788894, 'learning_rate': 3.591711054109154e-05, 'epoch': 0.8449733675345077, 'step': 4691500}
INFO:transformers.trainer:{'loss': 4.326598030090332, 'learning_rate': 3.59156096469789e-05, 'epoch': 0.8450634211812661, 'step': 4692000}
INFO:transformers.trainer:{'loss': 4.0198959126472475, 'learning_rate': 3.591410875286626e-05, 'epoch': 0.8451534748280245, 'step': 4692500}
INFO:transformers.trainer:{'loss': 3.785613343954086, 'learning_rate': 3.591260785875362e-05, 'epoch': 0.845243528474783, 'step': 4693000}
INFO:transformers.trainer:{'loss': 3.6804622046947477, 'learning_rate': 3.591110696464098e-05, 'epoch': 0.8453335821215414, 'step': 4693500}
INFO:transformers.trainer:{'loss': 3.8388757290840148, 'learning_rate': 3.5909606070528336e-05, 'epoch': 0.8454236357682999, 'step': 4694000}
INFO:transformers.trainer:{'loss': 3.812079651594162, 'learning_rate': 3.5908105176415695e-05, 'epoch': 0.8455136894150583, 'step': 4694500}
INFO:transformers.trainer:{'loss': 3.9247952663898467, 'learning_rate': 3.590660428230306e-05, 'epoch': 0.8456037430618167, 'step': 4695000}
INFO:transformers.trainer:{'loss': 4.00405407333374, 'learning_rate': 3.590510338819041e-05, 'epoch': 0.8456937967085753, 'step': 4695500}
INFO:transformers.trainer:{'loss': 4.152466098785401, 'learning_rate': 3.590360249407778e-05, 'epoch': 0.8457838503553337, 'step': 4696000}
INFO:transformers.trainer:{'loss': 4.297175977706909, 'learning_rate': 3.590210159996513e-05, 'epoch': 0.8458739040020922, 'step': 4696500}
INFO:transformers.trainer:{'loss': 4.150756935119629, 'learning_rate': 3.59006007058525e-05, 'epoch': 0.8459639576488506, 'step': 4697000}
INFO:transformers.trainer:{'loss': 4.169442204236984, 'learning_rate': 3.589909981173985e-05, 'epoch': 0.846054011295609, 'step': 4697500}
INFO:transformers.trainer:{'loss': 4.117123779773713, 'learning_rate': 3.5897598917627215e-05, 'epoch': 0.8461440649423675, 'step': 4698000}
INFO:transformers.trainer:{'loss': 4.152416854858399, 'learning_rate': 3.589609802351457e-05, 'epoch': 0.8462341185891259, 'step': 4698500}
INFO:transformers.trainer:{'loss': 4.09834485244751, 'learning_rate': 3.589459712940193e-05, 'epoch': 0.8463241722358844, 'step': 4699000}
INFO:transformers.trainer:{'loss': 4.23464390206337, 'learning_rate': 3.5893096235289286e-05, 'epoch': 0.8464142258826428, 'step': 4699500}
INFO:transformers.trainer:{'loss': 4.48198764038086, 'learning_rate': 3.5891595341176645e-05, 'epoch': 0.8465042795294012, 'step': 4700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.4799329085350035, 'learning_rate': 3.5890094447064004e-05, 'epoch': 0.8465943331761597, 'step': 4700500}
INFO:transformers.trainer:{'loss': 4.203167291402817, 'learning_rate': 3.588859355295136e-05, 'epoch': 0.8466843868229181, 'step': 4701000}
INFO:transformers.trainer:{'loss': 4.343633679866791, 'learning_rate': 3.588709265883872e-05, 'epoch': 0.8467744404696766, 'step': 4701500}
INFO:transformers.trainer:{'loss': 4.256929804325104, 'learning_rate': 3.588559176472608e-05, 'epoch': 0.846864494116435, 'step': 4702000}
INFO:transformers.trainer:{'loss': 4.290304618358612, 'learning_rate': 3.588409087061345e-05, 'epoch': 0.8469545477631935, 'step': 4702500}
INFO:transformers.trainer:{'loss': 4.502174172163009, 'learning_rate': 3.58825899765008e-05, 'epoch': 0.847044601409952, 'step': 4703000}
INFO:transformers.trainer:{'loss': 4.432601912260056, 'learning_rate': 3.5881089082388165e-05, 'epoch': 0.8471346550567104, 'step': 4703500}
INFO:transformers.trainer:{'loss': 4.221951259851456, 'learning_rate': 3.587958818827552e-05, 'epoch': 0.8472247087034688, 'step': 4704000}
INFO:transformers.trainer:{'loss': 4.187520112037658, 'learning_rate': 3.587808729416288e-05, 'epoch': 0.8473147623502273, 'step': 4704500}
INFO:transformers.trainer:{'loss': 4.08769872045517, 'learning_rate': 3.5876586400050235e-05, 'epoch': 0.8474048159969857, 'step': 4705000}
INFO:transformers.trainer:{'loss': 3.9101335594654083, 'learning_rate': 3.58750855059376e-05, 'epoch': 0.8474948696437442, 'step': 4705500}
INFO:transformers.trainer:{'loss': 3.703430135011673, 'learning_rate': 3.5873584611824953e-05, 'epoch': 0.8475849232905026, 'step': 4706000}
INFO:transformers.trainer:{'loss': 4.056865750074387, 'learning_rate': 3.587208371771232e-05, 'epoch': 0.847674976937261, 'step': 4706500}
INFO:transformers.trainer:{'loss': 4.1403218126297, 'learning_rate': 3.587058282359967e-05, 'epoch': 0.8477650305840195, 'step': 4707000}
INFO:transformers.trainer:{'loss': 4.46346177482605, 'learning_rate': 3.586908192948704e-05, 'epoch': 0.8478550842307779, 'step': 4707500}
INFO:transformers.trainer:{'loss': 4.355690711975098, 'learning_rate': 3.586758103537439e-05, 'epoch': 0.8479451378775364, 'step': 4708000}
INFO:transformers.trainer:{'loss': 4.502669159650803, 'learning_rate': 3.5866080141261755e-05, 'epoch': 0.8480351915242949, 'step': 4708500}
INFO:transformers.trainer:{'loss': 4.206089491844177, 'learning_rate': 3.5864579247149114e-05, 'epoch': 0.8481252451710533, 'step': 4709000}
INFO:transformers.trainer:{'loss': 3.9104013872146606, 'learning_rate': 3.5863078353036474e-05, 'epoch': 0.8482152988178118, 'step': 4709500}
INFO:transformers.trainer:{'loss': 3.9193480322360994, 'learning_rate': 3.586157745892383e-05, 'epoch': 0.8483053524645702, 'step': 4710000}
INFO:transformers.trainer:{'loss': 3.9925518872737884, 'learning_rate': 3.586007656481119e-05, 'epoch': 0.8483954061113287, 'step': 4710500}
INFO:transformers.trainer:{'loss': 3.8944581735134123, 'learning_rate': 3.585857567069855e-05, 'epoch': 0.8484854597580871, 'step': 4711000}
INFO:transformers.trainer:{'loss': 4.391150760173797, 'learning_rate': 3.585707477658591e-05, 'epoch': 0.8485755134048455, 'step': 4711500}
INFO:transformers.trainer:{'loss': 4.29557121181488, 'learning_rate': 3.585557388247327e-05, 'epoch': 0.848665567051604, 'step': 4712000}
INFO:transformers.trainer:{'loss': 4.409811811208725, 'learning_rate': 3.585407298836063e-05, 'epoch': 0.8487556206983624, 'step': 4712500}
INFO:transformers.trainer:{'loss': 4.226315218448639, 'learning_rate': 3.585257209424799e-05, 'epoch': 0.8488456743451209, 'step': 4713000}
INFO:transformers.trainer:{'loss': 4.177461493968964, 'learning_rate': 3.5851071200135346e-05, 'epoch': 0.8489357279918793, 'step': 4713500}
INFO:transformers.trainer:{'loss': 4.285131437301636, 'learning_rate': 3.5849570306022705e-05, 'epoch': 0.8490257816386377, 'step': 4714000}
INFO:transformers.trainer:{'loss': 4.157514450311661, 'learning_rate': 3.5848069411910064e-05, 'epoch': 0.8491158352853962, 'step': 4714500}
INFO:transformers.trainer:{'loss': 4.2974286324977875, 'learning_rate': 3.584656851779742e-05, 'epoch': 0.8492058889321547, 'step': 4715000}
INFO:transformers.trainer:{'loss': 4.129201084136963, 'learning_rate': 3.584506762368478e-05, 'epoch': 0.8492959425789132, 'step': 4715500}
INFO:transformers.trainer:{'loss': 4.25729878950119, 'learning_rate': 3.584356672957214e-05, 'epoch': 0.8493859962256716, 'step': 4716000}
INFO:transformers.trainer:{'loss': 4.447625944137573, 'learning_rate': 3.584206583545951e-05, 'epoch': 0.84947604987243, 'step': 4716500}
INFO:transformers.trainer:{'loss': 4.2439902594089505, 'learning_rate': 3.584056494134686e-05, 'epoch': 0.8495661035191885, 'step': 4717000}
INFO:transformers.trainer:{'loss': 4.22406461763382, 'learning_rate': 3.5839064047234225e-05, 'epoch': 0.8496561571659469, 'step': 4717500}
INFO:transformers.trainer:{'loss': 4.075711393833161, 'learning_rate': 3.583756315312158e-05, 'epoch': 0.8497462108127053, 'step': 4718000}
INFO:transformers.trainer:{'loss': 4.069183786869049, 'learning_rate': 3.583606225900894e-05, 'epoch': 0.8498362644594638, 'step': 4718500}
INFO:transformers.trainer:{'loss': 3.9195264818668365, 'learning_rate': 3.5834561364896295e-05, 'epoch': 0.8499263181062222, 'step': 4719000}
INFO:transformers.trainer:{'loss': 3.9150845952033997, 'learning_rate': 3.583306047078366e-05, 'epoch': 0.8500163717529807, 'step': 4719500}
INFO:transformers.trainer:{'loss': 3.919775527954102, 'learning_rate': 3.5831559576671014e-05, 'epoch': 0.8501064253997391, 'step': 4720000}
INFO:transformers.trainer:{'loss': 3.83642165517807, 'learning_rate': 3.583005868255838e-05, 'epoch': 0.8501964790464975, 'step': 4720500}
INFO:transformers.trainer:{'loss': 3.8606560695171357, 'learning_rate': 3.582855778844573e-05, 'epoch': 0.850286532693256, 'step': 4721000}
INFO:transformers.trainer:{'loss': 4.121336935043335, 'learning_rate': 3.58270568943331e-05, 'epoch': 0.8503765863400145, 'step': 4721500}
INFO:transformers.trainer:{'loss': 4.036504060983658, 'learning_rate': 3.582555600022045e-05, 'epoch': 0.850466639986773, 'step': 4722000}
INFO:transformers.trainer:{'loss': 4.136798320293426, 'learning_rate': 3.5824055106107816e-05, 'epoch': 0.8505566936335314, 'step': 4722500}
INFO:transformers.trainer:{'loss': 4.0242616558074955, 'learning_rate': 3.5822554211995175e-05, 'epoch': 0.8506467472802898, 'step': 4723000}
INFO:transformers.trainer:{'loss': 4.007676614522934, 'learning_rate': 3.582105331788253e-05, 'epoch': 0.8507368009270483, 'step': 4723500}
INFO:transformers.trainer:{'loss': 3.886956962585449, 'learning_rate': 3.581955242376989e-05, 'epoch': 0.8508268545738067, 'step': 4724000}
INFO:transformers.trainer:{'loss': 3.795646567106247, 'learning_rate': 3.5818051529657245e-05, 'epoch': 0.8509169082205652, 'step': 4724500}
INFO:transformers.trainer:{'loss': 4.060968158006668, 'learning_rate': 3.581655063554461e-05, 'epoch': 0.8510069618673236, 'step': 4725000}
INFO:transformers.trainer:{'loss': 3.8611093842983246, 'learning_rate': 3.581504974143196e-05, 'epoch': 0.851097015514082, 'step': 4725500}
INFO:transformers.trainer:{'loss': 4.048080216646195, 'learning_rate': 3.581354884731933e-05, 'epoch': 0.8511870691608405, 'step': 4726000}
INFO:transformers.trainer:{'loss': 4.109578515529632, 'learning_rate': 3.581204795320668e-05, 'epoch': 0.8512771228075989, 'step': 4726500}
INFO:transformers.trainer:{'loss': 4.217448752403259, 'learning_rate': 3.581054705909405e-05, 'epoch': 0.8513671764543574, 'step': 4727000}
INFO:transformers.trainer:{'loss': 4.346699607133865, 'learning_rate': 3.58090461649814e-05, 'epoch': 0.8514572301011158, 'step': 4727500}
INFO:transformers.trainer:{'loss': 4.336479073762893, 'learning_rate': 3.5807545270868765e-05, 'epoch': 0.8515472837478743, 'step': 4728000}
INFO:transformers.trainer:{'loss': 4.218071524381638, 'learning_rate': 3.580604437675612e-05, 'epoch': 0.8516373373946328, 'step': 4728500}
INFO:transformers.trainer:{'loss': 4.028938828706742, 'learning_rate': 3.580454348264348e-05, 'epoch': 0.8517273910413912, 'step': 4729000}
INFO:transformers.trainer:{'loss': 4.143041712760925, 'learning_rate': 3.580304258853084e-05, 'epoch': 0.8518174446881496, 'step': 4729500}
INFO:transformers.trainer:{'loss': 4.25041884970665, 'learning_rate': 3.58015416944182e-05, 'epoch': 0.8519074983349081, 'step': 4730000}
INFO:transformers.trainer:{'loss': 4.315930119276047, 'learning_rate': 3.580004080030556e-05, 'epoch': 0.8519975519816665, 'step': 4730500}
INFO:transformers.trainer:{'loss': 3.903356807947159, 'learning_rate': 3.579853990619292e-05, 'epoch': 0.852087605628425, 'step': 4731000}
INFO:transformers.trainer:{'loss': 3.9594107763767243, 'learning_rate': 3.579703901208028e-05, 'epoch': 0.8521776592751834, 'step': 4731500}
INFO:transformers.trainer:{'loss': 3.907189299821854, 'learning_rate': 3.579553811796764e-05, 'epoch': 0.8522677129219418, 'step': 4732000}
INFO:transformers.trainer:{'loss': 3.7753824939727783, 'learning_rate': 3.5794037223855e-05, 'epoch': 0.8523577665687003, 'step': 4732500}
INFO:transformers.trainer:{'loss': 3.863579348564148, 'learning_rate': 3.5792536329742356e-05, 'epoch': 0.8524478202154587, 'step': 4733000}
INFO:transformers.trainer:{'loss': 4.019585134744644, 'learning_rate': 3.5791035435629715e-05, 'epoch': 0.8525378738622172, 'step': 4733500}
INFO:transformers.trainer:{'loss': 3.7342375247478485, 'learning_rate': 3.5789534541517074e-05, 'epoch': 0.8526279275089756, 'step': 4734000}
INFO:transformers.trainer:{'loss': 3.5429093065261843, 'learning_rate': 3.578803364740443e-05, 'epoch': 0.852717981155734, 'step': 4734500}
INFO:transformers.trainer:{'loss': 3.6547000131607055, 'learning_rate': 3.578653275329179e-05, 'epoch': 0.8528080348024926, 'step': 4735000}
INFO:transformers.trainer:{'loss': 4.004872940540314, 'learning_rate': 3.578503185917915e-05, 'epoch': 0.852898088449251, 'step': 4735500}
INFO:transformers.trainer:{'loss': 4.027286642551422, 'learning_rate': 3.578353096506651e-05, 'epoch': 0.8529881420960095, 'step': 4736000}
INFO:transformers.trainer:{'loss': 3.6257065284252166, 'learning_rate': 3.578203007095387e-05, 'epoch': 0.8530781957427679, 'step': 4736500}
INFO:transformers.trainer:{'loss': 3.451769507646561, 'learning_rate': 3.5780529176841235e-05, 'epoch': 0.8531682493895263, 'step': 4737000}
INFO:transformers.trainer:{'loss': 3.641195702791214, 'learning_rate': 3.577902828272859e-05, 'epoch': 0.8532583030362848, 'step': 4737500}
INFO:transformers.trainer:{'loss': 3.630180388689041, 'learning_rate': 3.577752738861595e-05, 'epoch': 0.8533483566830432, 'step': 4738000}
INFO:transformers.trainer:{'loss': 3.7800081214904786, 'learning_rate': 3.5776026494503305e-05, 'epoch': 0.8534384103298017, 'step': 4738500}
INFO:transformers.trainer:{'loss': 4.176030709743499, 'learning_rate': 3.577452560039067e-05, 'epoch': 0.8535284639765601, 'step': 4739000}
INFO:transformers.trainer:{'loss': 4.096456001520157, 'learning_rate': 3.577302470627802e-05, 'epoch': 0.8536185176233185, 'step': 4739500}
INFO:transformers.trainer:{'loss': 4.247173895359039, 'learning_rate': 3.577152381216539e-05, 'epoch': 0.853708571270077, 'step': 4740000}
INFO:transformers.trainer:{'loss': 4.292919481277466, 'learning_rate': 3.577002291805274e-05, 'epoch': 0.8537986249168354, 'step': 4740500}
INFO:transformers.trainer:{'loss': 4.162857075452805, 'learning_rate': 3.576852202394011e-05, 'epoch': 0.8538886785635939, 'step': 4741000}
INFO:transformers.trainer:{'loss': 4.010714524030686, 'learning_rate': 3.576702112982746e-05, 'epoch': 0.8539787322103524, 'step': 4741500}
INFO:transformers.trainer:{'loss': 3.84574387049675, 'learning_rate': 3.5765520235714825e-05, 'epoch': 0.8540687858571108, 'step': 4742000}
INFO:transformers.trainer:{'loss': 4.244515149831772, 'learning_rate': 3.576401934160218e-05, 'epoch': 0.8541588395038693, 'step': 4742500}
INFO:transformers.trainer:{'loss': 4.466955699920654, 'learning_rate': 3.5762518447489543e-05, 'epoch': 0.8542488931506277, 'step': 4743000}
INFO:transformers.trainer:{'loss': 4.231126835346222, 'learning_rate': 3.57610175533769e-05, 'epoch': 0.8543389467973861, 'step': 4743500}
INFO:transformers.trainer:{'loss': 4.141687197685242, 'learning_rate': 3.575951665926426e-05, 'epoch': 0.8544290004441446, 'step': 4744000}
INFO:transformers.trainer:{'loss': 3.9725153398513795, 'learning_rate': 3.575801576515162e-05, 'epoch': 0.854519054090903, 'step': 4744500}
INFO:transformers.trainer:{'loss': 3.8522086279392243, 'learning_rate': 3.575651487103898e-05, 'epoch': 0.8546091077376615, 'step': 4745000}
INFO:transformers.trainer:{'loss': 4.088012923240662, 'learning_rate': 3.575501397692634e-05, 'epoch': 0.8546991613844199, 'step': 4745500}
INFO:transformers.trainer:{'loss': 3.9807908849716185, 'learning_rate': 3.57535130828137e-05, 'epoch': 0.8547892150311783, 'step': 4746000}
INFO:transformers.trainer:{'loss': 3.9026729378700256, 'learning_rate': 3.575201218870106e-05, 'epoch': 0.8548792686779368, 'step': 4746500}
INFO:transformers.trainer:{'loss': 3.751238574743271, 'learning_rate': 3.575051129458841e-05, 'epoch': 0.8549693223246952, 'step': 4747000}
INFO:transformers.trainer:{'loss': 3.694404539346695, 'learning_rate': 3.5749010400475775e-05, 'epoch': 0.8550593759714538, 'step': 4747500}
INFO:transformers.trainer:{'loss': 4.019623110771179, 'learning_rate': 3.574750950636313e-05, 'epoch': 0.8551494296182122, 'step': 4748000}
INFO:transformers.trainer:{'loss': 3.8346176867485045, 'learning_rate': 3.574600861225049e-05, 'epoch': 0.8552394832649706, 'step': 4748500}
INFO:transformers.trainer:{'loss': 3.748869063615799, 'learning_rate': 3.5744507718137845e-05, 'epoch': 0.8553295369117291, 'step': 4749000}
INFO:transformers.trainer:{'loss': 3.698031401395798, 'learning_rate': 3.574300682402521e-05, 'epoch': 0.8554195905584875, 'step': 4749500}
INFO:transformers.trainer:{'loss': 4.160612824916839, 'learning_rate': 3.574150592991256e-05, 'epoch': 0.855509644205246, 'step': 4750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 4.409609743595123, 'learning_rate': 3.574000503579993e-05, 'epoch': 0.8555996978520044, 'step': 4750500}
INFO:transformers.trainer:{'loss': 4.374970279693604, 'learning_rate': 3.573850414168729e-05, 'epoch': 0.8556897514987628, 'step': 4751000}
INFO:transformers.trainer:{'loss': 4.015459457397461, 'learning_rate': 3.573700324757465e-05, 'epoch': 0.8557798051455213, 'step': 4751500}
INFO:transformers.trainer:{'loss': 3.5625256485939025, 'learning_rate': 3.5735502353462006e-05, 'epoch': 0.8558698587922797, 'step': 4752000}
INFO:transformers.trainer:{'loss': 3.7658769092559816, 'learning_rate': 3.5734001459349365e-05, 'epoch': 0.8559599124390381, 'step': 4752500}
INFO:transformers.trainer:{'loss': 4.171278081178665, 'learning_rate': 3.5732500565236724e-05, 'epoch': 0.8560499660857966, 'step': 4753000}
INFO:transformers.trainer:{'loss': 4.198309421062469, 'learning_rate': 3.5730999671124083e-05, 'epoch': 0.856140019732555, 'step': 4753500}
INFO:transformers.trainer:{'loss': 3.9580361523628236, 'learning_rate': 3.572949877701144e-05, 'epoch': 0.8562300733793136, 'step': 4754000}
INFO:transformers.trainer:{'loss': 3.7983681621551515, 'learning_rate': 3.57279978828988e-05, 'epoch': 0.856320127026072, 'step': 4754500}
INFO:transformers.trainer:{'loss': 3.7137016327381134, 'learning_rate': 3.572649698878616e-05, 'epoch': 0.8564101806728304, 'step': 4755000}
INFO:transformers.trainer:{'loss': 3.593762430906296, 'learning_rate': 3.572499609467352e-05, 'epoch': 0.8565002343195889, 'step': 4755500}
INFO:transformers.trainer:{'loss': 3.2684238575696947, 'learning_rate': 3.572349520056088e-05, 'epoch': 0.8565902879663473, 'step': 4756000}
INFO:transformers.trainer:{'loss': 3.240233414411545, 'learning_rate': 3.572199430644824e-05, 'epoch': 0.8566803416131058, 'step': 4756500}
INFO:transformers.trainer:{'loss': 3.260199540376663, 'learning_rate': 3.57204934123356e-05, 'epoch': 0.8567703952598642, 'step': 4757000}
INFO:transformers.trainer:{'loss': 3.3357711248397828, 'learning_rate': 3.571899251822296e-05, 'epoch': 0.8568604489066226, 'step': 4757500}
INFO:transformers.trainer:{'loss': 3.38770446062088, 'learning_rate': 3.5717491624110315e-05, 'epoch': 0.8569505025533811, 'step': 4758000}
INFO:transformers.trainer:{'loss': 3.2940030542612075, 'learning_rate': 3.571599072999768e-05, 'epoch': 0.8570405562001395, 'step': 4758500}
INFO:transformers.trainer:{'loss': 3.2958661143779753, 'learning_rate': 3.571448983588503e-05, 'epoch': 0.857130609846898, 'step': 4759000}
INFO:transformers.trainer:{'loss': 3.2451246242523193, 'learning_rate': 3.57129889417724e-05, 'epoch': 0.8572206634936564, 'step': 4759500}
INFO:transformers.trainer:{'loss': 3.4509242079257967, 'learning_rate': 3.571148804765975e-05, 'epoch': 0.8573107171404148, 'step': 4760000}
INFO:transformers.trainer:{'loss': 3.5826832914352416, 'learning_rate': 3.570998715354712e-05, 'epoch': 0.8574007707871734, 'step': 4760500}
INFO:transformers.trainer:{'loss': 3.762273375749588, 'learning_rate': 3.570848625943447e-05, 'epoch': 0.8574908244339318, 'step': 4761000}
INFO:transformers.trainer:{'loss': 3.4495720472335814, 'learning_rate': 3.5706985365321835e-05, 'epoch': 0.8575808780806903, 'step': 4761500}
INFO:transformers.trainer:{'loss': 3.2223062616586686, 'learning_rate': 3.570548447120919e-05, 'epoch': 0.8576709317274487, 'step': 4762000}
INFO:transformers.trainer:{'loss': 3.2753940631151197, 'learning_rate': 3.570398357709655e-05, 'epoch': 0.8577609853742071, 'step': 4762500}
INFO:transformers.trainer:{'loss': 3.2903249747753143, 'learning_rate': 3.5702482682983905e-05, 'epoch': 0.8578510390209656, 'step': 4763000}
INFO:transformers.trainer:{'loss': 3.2246930723190306, 'learning_rate': 3.570098178887127e-05, 'epoch': 0.857941092667724, 'step': 4763500}
INFO:transformers.trainer:{'loss': 3.1857805495262146, 'learning_rate': 3.5699480894758624e-05, 'epoch': 0.8580311463144825, 'step': 4764000}
INFO:transformers.trainer:{'loss': 3.264038736104965, 'learning_rate': 3.569798000064599e-05, 'epoch': 0.8581211999612409, 'step': 4764500}
INFO:transformers.trainer:{'loss': 3.3389168994426726, 'learning_rate': 3.569647910653335e-05, 'epoch': 0.8582112536079993, 'step': 4765000}
INFO:transformers.trainer:{'loss': 3.2772307257652282, 'learning_rate': 3.569497821242071e-05, 'epoch': 0.8583013072547578, 'step': 4765500}
INFO:transformers.trainer:{'loss': 3.3017878811359407, 'learning_rate': 3.5693477318308067e-05, 'epoch': 0.8583913609015162, 'step': 4766000}
INFO:transformers.trainer:{'loss': 3.226319223165512, 'learning_rate': 3.5691976424195426e-05, 'epoch': 0.8584814145482746, 'step': 4766500}
INFO:transformers.trainer:{'loss': 3.2026262879371643, 'learning_rate': 3.5690475530082785e-05, 'epoch': 0.8585714681950332, 'step': 4767000}
INFO:transformers.trainer:{'loss': 3.280492270708084, 'learning_rate': 3.5688974635970144e-05, 'epoch': 0.8586615218417916, 'step': 4767500}
INFO:transformers.trainer:{'loss': 3.2222780936956408, 'learning_rate': 3.56874737418575e-05, 'epoch': 0.8587515754885501, 'step': 4768000}
INFO:transformers.trainer:{'loss': 3.2734005162715913, 'learning_rate': 3.568597284774486e-05, 'epoch': 0.8588416291353085, 'step': 4768500}
INFO:transformers.trainer:{'loss': 3.270800265312195, 'learning_rate': 3.568447195363222e-05, 'epoch': 0.8589316827820669, 'step': 4769000}
INFO:transformers.trainer:{'loss': 3.225130581140518, 'learning_rate': 3.568297105951958e-05, 'epoch': 0.8590217364288254, 'step': 4769500}
INFO:transformers.trainer:{'loss': 3.27146311545372, 'learning_rate': 3.568147016540694e-05, 'epoch': 0.8591117900755838, 'step': 4770000}
INFO:transformers.trainer:{'loss': 3.273123170733452, 'learning_rate': 3.567996927129429e-05, 'epoch': 0.8592018437223423, 'step': 4770500}
INFO:transformers.trainer:{'loss': 3.2283583151102064, 'learning_rate': 3.567846837718166e-05, 'epoch': 0.8592918973691007, 'step': 4771000}
INFO:transformers.trainer:{'loss': 3.2807368977069853, 'learning_rate': 3.5676967483069016e-05, 'epoch': 0.8593819510158591, 'step': 4771500}
INFO:transformers.trainer:{'loss': 3.4536900386810303, 'learning_rate': 3.5675466588956375e-05, 'epoch': 0.8594720046626176, 'step': 4772000}
INFO:transformers.trainer:{'loss': 3.3954550659656526, 'learning_rate': 3.5673965694843734e-05, 'epoch': 0.859562058309376, 'step': 4772500}
INFO:transformers.trainer:{'loss': 3.456145405769348, 'learning_rate': 3.567246480073109e-05, 'epoch': 0.8596521119561346, 'step': 4773000}
INFO:transformers.trainer:{'loss': 3.3264789056777953, 'learning_rate': 3.567096390661845e-05, 'epoch': 0.859742165602893, 'step': 4773500}
INFO:transformers.trainer:{'loss': 3.27193269777298, 'learning_rate': 3.566946301250581e-05, 'epoch': 0.8598322192496514, 'step': 4774000}
INFO:transformers.trainer:{'loss': 3.329630100131035, 'learning_rate': 3.566796211839317e-05, 'epoch': 0.8599222728964099, 'step': 4774500}
INFO:transformers.trainer:{'loss': 3.6808042600154876, 'learning_rate': 3.566646122428053e-05, 'epoch': 0.8600123265431683, 'step': 4775000}
INFO:transformers.trainer:{'loss': 3.4441863207817076, 'learning_rate': 3.566496033016789e-05, 'epoch': 0.8601023801899268, 'step': 4775500}
INFO:transformers.trainer:{'loss': 3.5253809633255004, 'learning_rate': 3.566345943605525e-05, 'epoch': 0.8601924338366852, 'step': 4776000}
INFO:transformers.trainer:{'loss': 3.4175832698345183, 'learning_rate': 3.5661958541942607e-05, 'epoch': 0.8602824874834436, 'step': 4776500}
INFO:transformers.trainer:{'loss': 3.434982486963272, 'learning_rate': 3.5660457647829966e-05, 'epoch': 0.8603725411302021, 'step': 4777000}
INFO:transformers.trainer:{'loss': 3.3944071422815325, 'learning_rate': 3.5658956753717325e-05, 'epoch': 0.8604625947769605, 'step': 4777500}
INFO:transformers.trainer:{'loss': 3.396812079668045, 'learning_rate': 3.565745585960469e-05, 'epoch': 0.8605526484237189, 'step': 4778000}
INFO:transformers.trainer:{'loss': 3.3933376989364623, 'learning_rate': 3.565595496549204e-05, 'epoch': 0.8606427020704774, 'step': 4778500}
INFO:transformers.trainer:{'loss': 3.4373648846149445, 'learning_rate': 3.565445407137941e-05, 'epoch': 0.8607327557172358, 'step': 4779000}
INFO:transformers.trainer:{'loss': 3.3037302029132842, 'learning_rate': 3.565295317726676e-05, 'epoch': 0.8608228093639944, 'step': 4779500}
INFO:transformers.trainer:{'loss': 3.444287736535072, 'learning_rate': 3.565145228315413e-05, 'epoch': 0.8609128630107528, 'step': 4780000}
INFO:transformers.trainer:{'loss': 3.3960192406177523, 'learning_rate': 3.564995138904148e-05, 'epoch': 0.8610029166575112, 'step': 4780500}
INFO:transformers.trainer:{'loss': 3.343394550561905, 'learning_rate': 3.5648450494928845e-05, 'epoch': 0.8610929703042697, 'step': 4781000}
INFO:transformers.trainer:{'loss': 3.429484972953796, 'learning_rate': 3.56469496008162e-05, 'epoch': 0.8611830239510281, 'step': 4781500}
INFO:transformers.trainer:{'loss': 3.4380788860321045, 'learning_rate': 3.564544870670356e-05, 'epoch': 0.8612730775977866, 'step': 4782000}
INFO:transformers.trainer:{'loss': 3.319076024055481, 'learning_rate': 3.5643947812590915e-05, 'epoch': 0.861363131244545, 'step': 4782500}
INFO:transformers.trainer:{'loss': 3.4316455607414245, 'learning_rate': 3.564244691847828e-05, 'epoch': 0.8614531848913034, 'step': 4783000}
INFO:transformers.trainer:{'loss': 3.3525205321311953, 'learning_rate': 3.564094602436563e-05, 'epoch': 0.8615432385380619, 'step': 4783500}
INFO:transformers.trainer:{'loss': 3.358103664398193, 'learning_rate': 3.5639445130253e-05, 'epoch': 0.8616332921848203, 'step': 4784000}
INFO:transformers.trainer:{'loss': 3.276479447245598, 'learning_rate': 3.563794423614035e-05, 'epoch': 0.8617233458315788, 'step': 4784500}
INFO:transformers.trainer:{'loss': 3.3126760766506194, 'learning_rate': 3.563644334202772e-05, 'epoch': 0.8618133994783372, 'step': 4785000}
INFO:transformers.trainer:{'loss': 3.234642902135849, 'learning_rate': 3.5634942447915076e-05, 'epoch': 0.8619034531250956, 'step': 4785500}
INFO:transformers.trainer:{'loss': 3.211289069771767, 'learning_rate': 3.5633441553802435e-05, 'epoch': 0.8619935067718542, 'step': 4786000}
INFO:transformers.trainer:{'loss': 3.3501816074848176, 'learning_rate': 3.5631940659689794e-05, 'epoch': 0.8620835604186126, 'step': 4786500}
INFO:transformers.trainer:{'loss': 3.218974956035614, 'learning_rate': 3.5630439765577153e-05, 'epoch': 0.8621736140653711, 'step': 4787000}
INFO:transformers.trainer:{'loss': 3.28177987408638, 'learning_rate': 3.562893887146451e-05, 'epoch': 0.8622636677121295, 'step': 4787500}
INFO:transformers.trainer:{'loss': 3.2293959197998046, 'learning_rate': 3.562743797735187e-05, 'epoch': 0.8623537213588879, 'step': 4788000}
INFO:transformers.trainer:{'loss': 3.184526947259903, 'learning_rate': 3.562593708323923e-05, 'epoch': 0.8624437750056464, 'step': 4788500}
INFO:transformers.trainer:{'loss': 3.228417638540268, 'learning_rate': 3.562443618912659e-05, 'epoch': 0.8625338286524048, 'step': 4789000}
INFO:transformers.trainer:{'loss': 3.4448679482936857, 'learning_rate': 3.562293529501395e-05, 'epoch': 0.8626238822991632, 'step': 4789500}
INFO:transformers.trainer:{'loss': 3.449143005132675, 'learning_rate': 3.562143440090131e-05, 'epoch': 0.8627139359459217, 'step': 4790000}
INFO:transformers.trainer:{'loss': 3.3176987264156343, 'learning_rate': 3.561993350678867e-05, 'epoch': 0.8628039895926801, 'step': 4790500}
INFO:transformers.trainer:{'loss': 3.274466006398201, 'learning_rate': 3.5618432612676026e-05, 'epoch': 0.8628940432394386, 'step': 4791000}
INFO:transformers.trainer:{'loss': 3.239442844390869, 'learning_rate': 3.5616931718563385e-05, 'epoch': 0.862984096886197, 'step': 4791500}
INFO:transformers.trainer:{'loss': 3.3225851624011993, 'learning_rate': 3.5615430824450744e-05, 'epoch': 0.8630741505329554, 'step': 4792000}
INFO:transformers.trainer:{'loss': 3.238906354188919, 'learning_rate': 3.56139299303381e-05, 'epoch': 0.863164204179714, 'step': 4792500}
INFO:transformers.trainer:{'loss': 3.256580866575241, 'learning_rate': 3.561242903622546e-05, 'epoch': 0.8632542578264724, 'step': 4793000}
INFO:transformers.trainer:{'loss': 3.298550299167633, 'learning_rate': 3.561092814211282e-05, 'epoch': 0.8633443114732309, 'step': 4793500}
INFO:transformers.trainer:{'loss': 3.256199338197708, 'learning_rate': 3.560942724800018e-05, 'epoch': 0.8634343651199893, 'step': 4794000}
INFO:transformers.trainer:{'loss': 3.2135161057710646, 'learning_rate': 3.560792635388754e-05, 'epoch': 0.8635244187667477, 'step': 4794500}
INFO:transformers.trainer:{'loss': 3.1969790003299714, 'learning_rate': 3.56064254597749e-05, 'epoch': 0.8636144724135062, 'step': 4795000}
INFO:transformers.trainer:{'loss': 3.2362724578380586, 'learning_rate': 3.560492456566226e-05, 'epoch': 0.8637045260602646, 'step': 4795500}
INFO:transformers.trainer:{'loss': 3.244583642959595, 'learning_rate': 3.5603423671549616e-05, 'epoch': 0.8637945797070231, 'step': 4796000}
INFO:transformers.trainer:{'loss': 3.2514926573038103, 'learning_rate': 3.5601922777436975e-05, 'epoch': 0.8638846333537815, 'step': 4796500}
INFO:transformers.trainer:{'loss': 3.201747956752777, 'learning_rate': 3.5600421883324334e-05, 'epoch': 0.8639746870005399, 'step': 4797000}
INFO:transformers.trainer:{'loss': 3.2169928107261656, 'learning_rate': 3.5598920989211693e-05, 'epoch': 0.8640647406472984, 'step': 4797500}
INFO:transformers.trainer:{'loss': 3.5014577703475953, 'learning_rate': 3.559742009509905e-05, 'epoch': 0.8641547942940568, 'step': 4798000}
INFO:transformers.trainer:{'loss': 3.3136788744926453, 'learning_rate': 3.559591920098641e-05, 'epoch': 0.8642448479408154, 'step': 4798500}
INFO:transformers.trainer:{'loss': 3.2163786237239838, 'learning_rate': 3.559441830687377e-05, 'epoch': 0.8643349015875738, 'step': 4799000}
INFO:transformers.trainer:{'loss': 3.1643106536865235, 'learning_rate': 3.5592917412761136e-05, 'epoch': 0.8644249552343322, 'step': 4799500}
INFO:transformers.trainer:{'loss': 3.2338926384449005, 'learning_rate': 3.559141651864849e-05, 'epoch': 0.8645150088810907, 'step': 4800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.17644233417511, 'learning_rate': 3.5589915624535855e-05, 'epoch': 0.8646050625278491, 'step': 4800500}
INFO:transformers.trainer:{'loss': 3.1810994153022767, 'learning_rate': 3.558841473042321e-05, 'epoch': 0.8646951161746076, 'step': 4801000}
INFO:transformers.trainer:{'loss': 3.230936188697815, 'learning_rate': 3.558691383631057e-05, 'epoch': 0.864785169821366, 'step': 4801500}
INFO:transformers.trainer:{'loss': 3.2019686987400053, 'learning_rate': 3.5585412942197925e-05, 'epoch': 0.8648752234681244, 'step': 4802000}
INFO:transformers.trainer:{'loss': 3.2333663275241853, 'learning_rate': 3.558391204808529e-05, 'epoch': 0.8649652771148829, 'step': 4802500}
INFO:transformers.trainer:{'loss': 3.204450061559677, 'learning_rate': 3.558241115397264e-05, 'epoch': 0.8650553307616413, 'step': 4803000}
INFO:transformers.trainer:{'loss': 3.194075956106186, 'learning_rate': 3.558091025986001e-05, 'epoch': 0.8651453844083997, 'step': 4803500}
INFO:transformers.trainer:{'loss': 3.240543318748474, 'learning_rate': 3.557940936574736e-05, 'epoch': 0.8652354380551582, 'step': 4804000}
INFO:transformers.trainer:{'loss': 3.266352017402649, 'learning_rate': 3.557790847163473e-05, 'epoch': 0.8653254917019166, 'step': 4804500}
INFO:transformers.trainer:{'loss': 3.3328946871757505, 'learning_rate': 3.557640757752208e-05, 'epoch': 0.8654155453486752, 'step': 4805000}
INFO:transformers.trainer:{'loss': 3.336569876432419, 'learning_rate': 3.5574906683409445e-05, 'epoch': 0.8655055989954336, 'step': 4805500}
INFO:transformers.trainer:{'loss': 3.3103645706176756, 'learning_rate': 3.5573405789296804e-05, 'epoch': 0.865595652642192, 'step': 4806000}
INFO:transformers.trainer:{'loss': 3.4105510828495027, 'learning_rate': 3.557190489518416e-05, 'epoch': 0.8656857062889505, 'step': 4806500}
INFO:transformers.trainer:{'loss': 3.3612951436042784, 'learning_rate': 3.557040400107152e-05, 'epoch': 0.8657757599357089, 'step': 4807000}
INFO:transformers.trainer:{'loss': 3.2306930618286134, 'learning_rate': 3.556890310695888e-05, 'epoch': 0.8658658135824674, 'step': 4807500}
INFO:transformers.trainer:{'loss': 3.2761451145410536, 'learning_rate': 3.556740221284624e-05, 'epoch': 0.8659558672292258, 'step': 4808000}
INFO:transformers.trainer:{'loss': 3.280668720006943, 'learning_rate': 3.55659013187336e-05, 'epoch': 0.8660459208759842, 'step': 4808500}
INFO:transformers.trainer:{'loss': 3.3898439927101136, 'learning_rate': 3.556440042462096e-05, 'epoch': 0.8661359745227427, 'step': 4809000}
INFO:transformers.trainer:{'loss': 3.3365852134227754, 'learning_rate': 3.556289953050832e-05, 'epoch': 0.8662260281695011, 'step': 4809500}
INFO:transformers.trainer:{'loss': 3.3717279682159425, 'learning_rate': 3.5561398636395676e-05, 'epoch': 0.8663160818162596, 'step': 4810000}
INFO:transformers.trainer:{'loss': 3.381535242319107, 'learning_rate': 3.5559897742283036e-05, 'epoch': 0.866406135463018, 'step': 4810500}
INFO:transformers.trainer:{'loss': 3.3209723765850065, 'learning_rate': 3.5558396848170395e-05, 'epoch': 0.8664961891097764, 'step': 4811000}
INFO:transformers.trainer:{'loss': 3.2489705529212953, 'learning_rate': 3.5556895954057754e-05, 'epoch': 0.866586242756535, 'step': 4811500}
INFO:transformers.trainer:{'loss': 3.24026379609108, 'learning_rate': 3.555539505994511e-05, 'epoch': 0.8666762964032934, 'step': 4812000}
INFO:transformers.trainer:{'loss': 3.276362106323242, 'learning_rate': 3.555389416583247e-05, 'epoch': 0.8667663500500519, 'step': 4812500}
INFO:transformers.trainer:{'loss': 3.2618418531417848, 'learning_rate': 3.555239327171983e-05, 'epoch': 0.8668564036968103, 'step': 4813000}
INFO:transformers.trainer:{'loss': 3.155498435020447, 'learning_rate': 3.555089237760719e-05, 'epoch': 0.8669464573435687, 'step': 4813500}
INFO:transformers.trainer:{'loss': 3.189037227153778, 'learning_rate': 3.554939148349455e-05, 'epoch': 0.8670365109903272, 'step': 4814000}
INFO:transformers.trainer:{'loss': 3.242566425561905, 'learning_rate': 3.554789058938191e-05, 'epoch': 0.8671265646370856, 'step': 4814500}
INFO:transformers.trainer:{'loss': 3.282865824699402, 'learning_rate': 3.554638969526927e-05, 'epoch': 0.867216618283844, 'step': 4815000}
INFO:transformers.trainer:{'loss': 3.2528222527503967, 'learning_rate': 3.5544888801156626e-05, 'epoch': 0.8673066719306025, 'step': 4815500}
INFO:transformers.trainer:{'loss': 3.219961422920227, 'learning_rate': 3.5543387907043985e-05, 'epoch': 0.8673967255773609, 'step': 4816000}
INFO:transformers.trainer:{'loss': 3.2078990408182144, 'learning_rate': 3.5541887012931344e-05, 'epoch': 0.8674867792241194, 'step': 4816500}
INFO:transformers.trainer:{'loss': 3.2260069415569306, 'learning_rate': 3.55403861188187e-05, 'epoch': 0.8675768328708778, 'step': 4817000}
INFO:transformers.trainer:{'loss': 3.274415296316147, 'learning_rate': 3.553888522470606e-05, 'epoch': 0.8676668865176362, 'step': 4817500}
INFO:transformers.trainer:{'loss': 3.2119492571353914, 'learning_rate': 3.553738433059342e-05, 'epoch': 0.8677569401643948, 'step': 4818000}
INFO:transformers.trainer:{'loss': 3.2267122801542283, 'learning_rate': 3.553588343648078e-05, 'epoch': 0.8678469938111532, 'step': 4818500}
INFO:transformers.trainer:{'loss': 3.238153758049011, 'learning_rate': 3.553438254236814e-05, 'epoch': 0.8679370474579117, 'step': 4819000}
INFO:transformers.trainer:{'loss': 3.217809302806854, 'learning_rate': 3.55328816482555e-05, 'epoch': 0.8680271011046701, 'step': 4819500}
INFO:transformers.trainer:{'loss': 3.2375630570650102, 'learning_rate': 3.5531380754142864e-05, 'epoch': 0.8681171547514285, 'step': 4820000}
INFO:transformers.trainer:{'loss': 3.191281486034393, 'learning_rate': 3.5529879860030217e-05, 'epoch': 0.868207208398187, 'step': 4820500}
INFO:transformers.trainer:{'loss': 3.246395023345947, 'learning_rate': 3.552837896591758e-05, 'epoch': 0.8682972620449454, 'step': 4821000}
INFO:transformers.trainer:{'loss': 3.2375076403617857, 'learning_rate': 3.5526878071804935e-05, 'epoch': 0.8683873156917039, 'step': 4821500}
INFO:transformers.trainer:{'loss': 3.1863907327651977, 'learning_rate': 3.55253771776923e-05, 'epoch': 0.8684773693384623, 'step': 4822000}
INFO:transformers.trainer:{'loss': 3.2085583000183107, 'learning_rate': 3.552387628357965e-05, 'epoch': 0.8685674229852207, 'step': 4822500}
INFO:transformers.trainer:{'loss': 3.2456183202266695, 'learning_rate': 3.552237538946702e-05, 'epoch': 0.8686574766319792, 'step': 4823000}
INFO:transformers.trainer:{'loss': 3.242161657810211, 'learning_rate': 3.552087449535437e-05, 'epoch': 0.8687475302787376, 'step': 4823500}
INFO:transformers.trainer:{'loss': 3.207602034330368, 'learning_rate': 3.551937360124174e-05, 'epoch': 0.8688375839254961, 'step': 4824000}
INFO:transformers.trainer:{'loss': 3.251270287036896, 'learning_rate': 3.551787270712909e-05, 'epoch': 0.8689276375722546, 'step': 4824500}
INFO:transformers.trainer:{'loss': 3.2339743196964266, 'learning_rate': 3.5516371813016455e-05, 'epoch': 0.869017691219013, 'step': 4825000}
INFO:transformers.trainer:{'loss': 3.149982257723808, 'learning_rate': 3.551487091890381e-05, 'epoch': 0.8691077448657715, 'step': 4825500}
INFO:transformers.trainer:{'loss': 3.260793566226959, 'learning_rate': 3.551337002479117e-05, 'epoch': 0.8691977985125299, 'step': 4826000}
INFO:transformers.trainer:{'loss': 3.180698564529419, 'learning_rate': 3.551186913067853e-05, 'epoch': 0.8692878521592883, 'step': 4826500}
INFO:transformers.trainer:{'loss': 3.178060212135315, 'learning_rate': 3.551036823656589e-05, 'epoch': 0.8693779058060468, 'step': 4827000}
INFO:transformers.trainer:{'loss': 3.2960635673999787, 'learning_rate': 3.550886734245325e-05, 'epoch': 0.8694679594528052, 'step': 4827500}
INFO:transformers.trainer:{'loss': 3.2277351784706116, 'learning_rate': 3.550736644834061e-05, 'epoch': 0.8695580130995637, 'step': 4828000}
INFO:transformers.trainer:{'loss': 3.1863944585323334, 'learning_rate': 3.550586555422797e-05, 'epoch': 0.8696480667463221, 'step': 4828500}
INFO:transformers.trainer:{'loss': 3.2090497949123384, 'learning_rate': 3.550436466011533e-05, 'epoch': 0.8697381203930805, 'step': 4829000}
INFO:transformers.trainer:{'loss': 3.1894204642772674, 'learning_rate': 3.5502863766002686e-05, 'epoch': 0.869828174039839, 'step': 4829500}
INFO:transformers.trainer:{'loss': 3.164918893098831, 'learning_rate': 3.5501362871890045e-05, 'epoch': 0.8699182276865974, 'step': 4830000}
INFO:transformers.trainer:{'loss': 3.275274319410324, 'learning_rate': 3.5499861977777404e-05, 'epoch': 0.870008281333356, 'step': 4830500}
INFO:transformers.trainer:{'loss': 3.2497142118215563, 'learning_rate': 3.549836108366476e-05, 'epoch': 0.8700983349801144, 'step': 4831000}
INFO:transformers.trainer:{'loss': 3.3107685334682464, 'learning_rate': 3.549686018955212e-05, 'epoch': 0.8701883886268728, 'step': 4831500}
INFO:transformers.trainer:{'loss': 3.2027929310798644, 'learning_rate': 3.549535929543948e-05, 'epoch': 0.8702784422736313, 'step': 4832000}
INFO:transformers.trainer:{'loss': 3.278192487478256, 'learning_rate': 3.549385840132684e-05, 'epoch': 0.8703684959203897, 'step': 4832500}
INFO:transformers.trainer:{'loss': 3.2445950572490694, 'learning_rate': 3.54923575072142e-05, 'epoch': 0.8704585495671482, 'step': 4833000}
INFO:transformers.trainer:{'loss': 3.2245586948394775, 'learning_rate': 3.549085661310156e-05, 'epoch': 0.8705486032139066, 'step': 4833500}
INFO:transformers.trainer:{'loss': 3.1760738368034365, 'learning_rate': 3.548935571898892e-05, 'epoch': 0.870638656860665, 'step': 4834000}
INFO:transformers.trainer:{'loss': 3.1927258579730986, 'learning_rate': 3.548785482487628e-05, 'epoch': 0.8707287105074235, 'step': 4834500}
INFO:transformers.trainer:{'loss': 3.1041653385162356, 'learning_rate': 3.5486353930763636e-05, 'epoch': 0.8708187641541819, 'step': 4835000}
INFO:transformers.trainer:{'loss': 3.20265217423439, 'learning_rate': 3.5484853036650995e-05, 'epoch': 0.8709088178009404, 'step': 4835500}
INFO:transformers.trainer:{'loss': 3.1885506397485734, 'learning_rate': 3.5483352142538354e-05, 'epoch': 0.8709988714476988, 'step': 4836000}
INFO:transformers.trainer:{'loss': 3.1994750373363496, 'learning_rate': 3.548185124842571e-05, 'epoch': 0.8710889250944572, 'step': 4836500}
INFO:transformers.trainer:{'loss': 3.1915606472492217, 'learning_rate': 3.548035035431307e-05, 'epoch': 0.8711789787412157, 'step': 4837000}
INFO:transformers.trainer:{'loss': 3.307356369972229, 'learning_rate': 3.547884946020043e-05, 'epoch': 0.8712690323879742, 'step': 4837500}
INFO:transformers.trainer:{'loss': 3.1827374567985536, 'learning_rate': 3.547734856608779e-05, 'epoch': 0.8713590860347327, 'step': 4838000}
INFO:transformers.trainer:{'loss': 3.173370003223419, 'learning_rate': 3.547584767197515e-05, 'epoch': 0.8714491396814911, 'step': 4838500}
INFO:transformers.trainer:{'loss': 3.2008748862743377, 'learning_rate': 3.547434677786251e-05, 'epoch': 0.8715391933282495, 'step': 4839000}
INFO:transformers.trainer:{'loss': 3.210257264614105, 'learning_rate': 3.547284588374987e-05, 'epoch': 0.871629246975008, 'step': 4839500}
INFO:transformers.trainer:{'loss': 3.1832804362773897, 'learning_rate': 3.5471344989637226e-05, 'epoch': 0.8717193006217664, 'step': 4840000}
INFO:transformers.trainer:{'loss': 3.1737892854213716, 'learning_rate': 3.546984409552459e-05, 'epoch': 0.8718093542685248, 'step': 4840500}
INFO:transformers.trainer:{'loss': 3.225889467597008, 'learning_rate': 3.5468343201411944e-05, 'epoch': 0.8718994079152833, 'step': 4841000}
INFO:transformers.trainer:{'loss': 3.3528353021144865, 'learning_rate': 3.546684230729931e-05, 'epoch': 0.8719894615620417, 'step': 4841500}
INFO:transformers.trainer:{'loss': 3.3153141183853148, 'learning_rate': 3.546534141318666e-05, 'epoch': 0.8720795152088002, 'step': 4842000}
INFO:transformers.trainer:{'loss': 3.212051168680191, 'learning_rate': 3.546384051907403e-05, 'epoch': 0.8721695688555586, 'step': 4842500}
INFO:transformers.trainer:{'loss': 3.3262839291095734, 'learning_rate': 3.546233962496138e-05, 'epoch': 0.872259622502317, 'step': 4843000}
INFO:transformers.trainer:{'loss': 3.314751093149185, 'learning_rate': 3.5460838730848746e-05, 'epoch': 0.8723496761490755, 'step': 4843500}
INFO:transformers.trainer:{'loss': 3.2871747217178346, 'learning_rate': 3.54593378367361e-05, 'epoch': 0.872439729795834, 'step': 4844000}
INFO:transformers.trainer:{'loss': 3.190219629049301, 'learning_rate': 3.5457836942623464e-05, 'epoch': 0.8725297834425925, 'step': 4844500}
INFO:transformers.trainer:{'loss': 3.198039882659912, 'learning_rate': 3.545633604851082e-05, 'epoch': 0.8726198370893509, 'step': 4845000}
INFO:transformers.trainer:{'loss': 3.20700745511055, 'learning_rate': 3.545483515439818e-05, 'epoch': 0.8727098907361093, 'step': 4845500}
INFO:transformers.trainer:{'loss': 3.256548120737076, 'learning_rate': 3.5453334260285535e-05, 'epoch': 0.8727999443828678, 'step': 4846000}
INFO:transformers.trainer:{'loss': 3.153081259727478, 'learning_rate': 3.54518333661729e-05, 'epoch': 0.8728899980296262, 'step': 4846500}
INFO:transformers.trainer:{'loss': 3.228129189491272, 'learning_rate': 3.545033247206025e-05, 'epoch': 0.8729800516763847, 'step': 4847000}
INFO:transformers.trainer:{'loss': 3.157225815296173, 'learning_rate': 3.544883157794762e-05, 'epoch': 0.8730701053231431, 'step': 4847500}
INFO:transformers.trainer:{'loss': 3.1950264976024627, 'learning_rate': 3.544733068383498e-05, 'epoch': 0.8731601589699015, 'step': 4848000}
INFO:transformers.trainer:{'loss': 3.132521542787552, 'learning_rate': 3.544582978972234e-05, 'epoch': 0.87325021261666, 'step': 4848500}
INFO:transformers.trainer:{'loss': 3.1539091796875, 'learning_rate': 3.5444328895609696e-05, 'epoch': 0.8733402662634184, 'step': 4849000}
INFO:transformers.trainer:{'loss': 3.2393181828260422, 'learning_rate': 3.5442828001497055e-05, 'epoch': 0.8734303199101769, 'step': 4849500}
INFO:transformers.trainer:{'loss': 3.140975042819977, 'learning_rate': 3.5441327107384414e-05, 'epoch': 0.8735203735569353, 'step': 4850000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4850000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4850000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4850000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4750000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.178920778155327, 'learning_rate': 3.543982621327177e-05, 'epoch': 0.8736104272036938, 'step': 4850500}
INFO:transformers.trainer:{'loss': 3.1583463695049288, 'learning_rate': 3.543832531915913e-05, 'epoch': 0.8737004808504523, 'step': 4851000}
INFO:transformers.trainer:{'loss': 3.1042183849811553, 'learning_rate': 3.543682442504649e-05, 'epoch': 0.8737905344972107, 'step': 4851500}
INFO:transformers.trainer:{'loss': 3.1362334191799164, 'learning_rate': 3.543532353093385e-05, 'epoch': 0.8738805881439691, 'step': 4852000}
INFO:transformers.trainer:{'loss': 3.208644598007202, 'learning_rate': 3.543382263682121e-05, 'epoch': 0.8739706417907276, 'step': 4852500}
INFO:transformers.trainer:{'loss': 3.2203966495990755, 'learning_rate': 3.543232174270857e-05, 'epoch': 0.874060695437486, 'step': 4853000}
INFO:transformers.trainer:{'loss': 3.155245868444443, 'learning_rate': 3.543082084859593e-05, 'epoch': 0.8741507490842445, 'step': 4853500}
INFO:transformers.trainer:{'loss': 3.1689564309120177, 'learning_rate': 3.5429319954483286e-05, 'epoch': 0.8742408027310029, 'step': 4854000}
INFO:transformers.trainer:{'loss': 3.1976187193393706, 'learning_rate': 3.5427819060370645e-05, 'epoch': 0.8743308563777613, 'step': 4854500}
INFO:transformers.trainer:{'loss': 3.1494974105358122, 'learning_rate': 3.5426318166258005e-05, 'epoch': 0.8744209100245198, 'step': 4855000}
INFO:transformers.trainer:{'loss': 3.196993090391159, 'learning_rate': 3.5424817272145364e-05, 'epoch': 0.8745109636712782, 'step': 4855500}
INFO:transformers.trainer:{'loss': 3.1291580879688263, 'learning_rate': 3.542331637803272e-05, 'epoch': 0.8746010173180367, 'step': 4856000}
INFO:transformers.trainer:{'loss': 3.170673624038696, 'learning_rate': 3.542181548392008e-05, 'epoch': 0.8746910709647951, 'step': 4856500}
INFO:transformers.trainer:{'loss': 3.2168664672374727, 'learning_rate': 3.542031458980744e-05, 'epoch': 0.8747811246115536, 'step': 4857000}
INFO:transformers.trainer:{'loss': 3.188816391944885, 'learning_rate': 3.54188136956948e-05, 'epoch': 0.8748711782583121, 'step': 4857500}
INFO:transformers.trainer:{'loss': 3.211198272585869, 'learning_rate': 3.541731280158216e-05, 'epoch': 0.8749612319050705, 'step': 4858000}
INFO:transformers.trainer:{'loss': 3.1850133171081545, 'learning_rate': 3.541581190746952e-05, 'epoch': 0.875051285551829, 'step': 4858500}
INFO:transformers.trainer:{'loss': 3.1665428307056427, 'learning_rate': 3.541431101335688e-05, 'epoch': 0.8751413391985874, 'step': 4859000}
INFO:transformers.trainer:{'loss': 3.174358823299408, 'learning_rate': 3.5412810119244236e-05, 'epoch': 0.8752313928453458, 'step': 4859500}
INFO:transformers.trainer:{'loss': 3.1872926646471025, 'learning_rate': 3.5411309225131595e-05, 'epoch': 0.8753214464921043, 'step': 4860000}
INFO:transformers.trainer:{'loss': 3.1603044407367706, 'learning_rate': 3.5409808331018954e-05, 'epoch': 0.8754115001388627, 'step': 4860500}
INFO:transformers.trainer:{'loss': 3.173547547698021, 'learning_rate': 3.540830743690631e-05, 'epoch': 0.8755015537856212, 'step': 4861000}
INFO:transformers.trainer:{'loss': 3.23338768529892, 'learning_rate': 3.540680654279367e-05, 'epoch': 0.8755916074323796, 'step': 4861500}
INFO:transformers.trainer:{'loss': 3.1117845044136048, 'learning_rate': 3.540530564868104e-05, 'epoch': 0.875681661079138, 'step': 4862000}
INFO:transformers.trainer:{'loss': 3.1767519707679748, 'learning_rate': 3.540380475456839e-05, 'epoch': 0.8757717147258965, 'step': 4862500}
INFO:transformers.trainer:{'loss': 3.136017520904541, 'learning_rate': 3.5402303860455756e-05, 'epoch': 0.875861768372655, 'step': 4863000}
INFO:transformers.trainer:{'loss': 3.201238335609436, 'learning_rate': 3.540080296634311e-05, 'epoch': 0.8759518220194134, 'step': 4863500}
INFO:transformers.trainer:{'loss': 3.165826080530882, 'learning_rate': 3.5399302072230474e-05, 'epoch': 0.8760418756661719, 'step': 4864000}
INFO:transformers.trainer:{'loss': 3.1337877379655836, 'learning_rate': 3.5397801178117826e-05, 'epoch': 0.8761319293129303, 'step': 4864500}
INFO:transformers.trainer:{'loss': 3.190645654439926, 'learning_rate': 3.539630028400519e-05, 'epoch': 0.8762219829596888, 'step': 4865000}
INFO:transformers.trainer:{'loss': 3.18987045276165, 'learning_rate': 3.5394799389892545e-05, 'epoch': 0.8763120366064472, 'step': 4865500}
INFO:transformers.trainer:{'loss': 3.229077257633209, 'learning_rate': 3.539329849577991e-05, 'epoch': 0.8764020902532056, 'step': 4866000}
INFO:transformers.trainer:{'loss': 3.184733740568161, 'learning_rate': 3.539179760166726e-05, 'epoch': 0.8764921438999641, 'step': 4866500}
INFO:transformers.trainer:{'loss': 3.17639817905426, 'learning_rate': 3.539029670755463e-05, 'epoch': 0.8765821975467225, 'step': 4867000}
INFO:transformers.trainer:{'loss': 3.250474339723587, 'learning_rate': 3.538879581344198e-05, 'epoch': 0.876672251193481, 'step': 4867500}
INFO:transformers.trainer:{'loss': 3.160870395898819, 'learning_rate': 3.5387294919329347e-05, 'epoch': 0.8767623048402394, 'step': 4868000}
INFO:transformers.trainer:{'loss': 3.324168020963669, 'learning_rate': 3.5385794025216706e-05, 'epoch': 0.8768523584869978, 'step': 4868500}
INFO:transformers.trainer:{'loss': 3.3249710171222686, 'learning_rate': 3.5384293131104065e-05, 'epoch': 0.8769424121337563, 'step': 4869000}
INFO:transformers.trainer:{'loss': 3.319354035615921, 'learning_rate': 3.5382792236991424e-05, 'epoch': 0.8770324657805147, 'step': 4869500}
INFO:transformers.trainer:{'loss': 3.2247619193792345, 'learning_rate': 3.538129134287878e-05, 'epoch': 0.8771225194272733, 'step': 4870000}
INFO:transformers.trainer:{'loss': 3.255861437559128, 'learning_rate': 3.537979044876614e-05, 'epoch': 0.8772125730740317, 'step': 4870500}
INFO:transformers.trainer:{'loss': 3.201155445575714, 'learning_rate': 3.53782895546535e-05, 'epoch': 0.8773026267207901, 'step': 4871000}
INFO:transformers.trainer:{'loss': 3.189112623691559, 'learning_rate': 3.537678866054086e-05, 'epoch': 0.8773926803675486, 'step': 4871500}
INFO:transformers.trainer:{'loss': 3.1996919972896576, 'learning_rate': 3.537528776642822e-05, 'epoch': 0.877482734014307, 'step': 4872000}
INFO:transformers.trainer:{'loss': 3.2019137823581696, 'learning_rate': 3.537378687231558e-05, 'epoch': 0.8775727876610655, 'step': 4872500}
INFO:transformers.trainer:{'loss': 3.2258791151046755, 'learning_rate': 3.537228597820294e-05, 'epoch': 0.8776628413078239, 'step': 4873000}
INFO:transformers.trainer:{'loss': 3.213920306444168, 'learning_rate': 3.5370785084090296e-05, 'epoch': 0.8777528949545823, 'step': 4873500}
INFO:transformers.trainer:{'loss': 3.1933364980220795, 'learning_rate': 3.5369284189977655e-05, 'epoch': 0.8778429486013408, 'step': 4874000}
INFO:transformers.trainer:{'loss': 3.2122118220329283, 'learning_rate': 3.5367783295865014e-05, 'epoch': 0.8779330022480992, 'step': 4874500}
INFO:transformers.trainer:{'loss': 3.197141726732254, 'learning_rate': 3.536628240175237e-05, 'epoch': 0.8780230558948576, 'step': 4875000}
INFO:transformers.trainer:{'loss': 3.201810510396957, 'learning_rate': 3.536478150763973e-05, 'epoch': 0.8781131095416161, 'step': 4875500}
INFO:transformers.trainer:{'loss': 3.153567171573639, 'learning_rate': 3.536328061352709e-05, 'epoch': 0.8782031631883745, 'step': 4876000}
INFO:transformers.trainer:{'loss': 3.2559021062850952, 'learning_rate': 3.536177971941445e-05, 'epoch': 0.8782932168351331, 'step': 4876500}
INFO:transformers.trainer:{'loss': 3.2588781986236572, 'learning_rate': 3.536027882530181e-05, 'epoch': 0.8783832704818915, 'step': 4877000}
INFO:transformers.trainer:{'loss': 3.22083563041687, 'learning_rate': 3.535877793118917e-05, 'epoch': 0.8784733241286499, 'step': 4877500}
INFO:transformers.trainer:{'loss': 3.261812910318375, 'learning_rate': 3.535727703707653e-05, 'epoch': 0.8785633777754084, 'step': 4878000}
INFO:transformers.trainer:{'loss': 3.1721117649078368, 'learning_rate': 3.535577614296389e-05, 'epoch': 0.8786534314221668, 'step': 4878500}
INFO:transformers.trainer:{'loss': 3.1627981913089753, 'learning_rate': 3.5354275248851246e-05, 'epoch': 0.8787434850689253, 'step': 4879000}
INFO:transformers.trainer:{'loss': 3.196932496547699, 'learning_rate': 3.5352774354738605e-05, 'epoch': 0.8788335387156837, 'step': 4879500}
INFO:transformers.trainer:{'loss': 3.18979700088501, 'learning_rate': 3.5351273460625964e-05, 'epoch': 0.8789235923624421, 'step': 4880000}
INFO:transformers.trainer:{'loss': 3.1919942532777785, 'learning_rate': 3.534977256651332e-05, 'epoch': 0.8790136460092006, 'step': 4880500}
INFO:transformers.trainer:{'loss': 3.191653570652008, 'learning_rate': 3.534827167240068e-05, 'epoch': 0.879103699655959, 'step': 4881000}
INFO:transformers.trainer:{'loss': 3.1870854337215424, 'learning_rate': 3.534677077828804e-05, 'epoch': 0.8791937533027175, 'step': 4881500}
INFO:transformers.trainer:{'loss': 3.1548868783712387, 'learning_rate': 3.53452698841754e-05, 'epoch': 0.8792838069494759, 'step': 4882000}
INFO:transformers.trainer:{'loss': 3.1889625285863876, 'learning_rate': 3.5343768990062766e-05, 'epoch': 0.8793738605962343, 'step': 4882500}
INFO:transformers.trainer:{'loss': 3.102574612855911, 'learning_rate': 3.534226809595012e-05, 'epoch': 0.8794639142429929, 'step': 4883000}
INFO:transformers.trainer:{'loss': 3.175397824525833, 'learning_rate': 3.5340767201837484e-05, 'epoch': 0.8795539678897513, 'step': 4883500}
INFO:transformers.trainer:{'loss': 3.159819221019745, 'learning_rate': 3.5339266307724836e-05, 'epoch': 0.8796440215365098, 'step': 4884000}
INFO:transformers.trainer:{'loss': 3.1547037432193754, 'learning_rate': 3.53377654136122e-05, 'epoch': 0.8797340751832682, 'step': 4884500}
INFO:transformers.trainer:{'loss': 3.1603344148397445, 'learning_rate': 3.5336264519499554e-05, 'epoch': 0.8798241288300266, 'step': 4885000}
INFO:transformers.trainer:{'loss': 3.2213464143276216, 'learning_rate': 3.533476362538692e-05, 'epoch': 0.8799141824767851, 'step': 4885500}
INFO:transformers.trainer:{'loss': 3.2104211056232455, 'learning_rate': 3.533326273127427e-05, 'epoch': 0.8800042361235435, 'step': 4886000}
INFO:transformers.trainer:{'loss': 3.1373770573139192, 'learning_rate': 3.533176183716164e-05, 'epoch': 0.880094289770302, 'step': 4886500}
INFO:transformers.trainer:{'loss': 3.1534929428100584, 'learning_rate': 3.533026094304899e-05, 'epoch': 0.8801843434170604, 'step': 4887000}
INFO:transformers.trainer:{'loss': 3.07983852148056, 'learning_rate': 3.5328760048936356e-05, 'epoch': 0.8802743970638188, 'step': 4887500}
INFO:transformers.trainer:{'loss': 3.188726915359497, 'learning_rate': 3.532725915482371e-05, 'epoch': 0.8803644507105773, 'step': 4888000}
INFO:transformers.trainer:{'loss': 3.2035522899627686, 'learning_rate': 3.5325758260711074e-05, 'epoch': 0.8804545043573357, 'step': 4888500}
INFO:transformers.trainer:{'loss': 3.1530907967090607, 'learning_rate': 3.5324257366598433e-05, 'epoch': 0.8805445580040941, 'step': 4889000}
INFO:transformers.trainer:{'loss': 3.1756323409080505, 'learning_rate': 3.532275647248579e-05, 'epoch': 0.8806346116508527, 'step': 4889500}
INFO:transformers.trainer:{'loss': 3.08538352560997, 'learning_rate': 3.532125557837315e-05, 'epoch': 0.8807246652976111, 'step': 4890000}
INFO:transformers.trainer:{'loss': 3.160401384592056, 'learning_rate': 3.531975468426051e-05, 'epoch': 0.8808147189443696, 'step': 4890500}
INFO:transformers.trainer:{'loss': 3.1504562945365904, 'learning_rate': 3.531825379014787e-05, 'epoch': 0.880904772591128, 'step': 4891000}
INFO:transformers.trainer:{'loss': 3.11150172996521, 'learning_rate': 3.531675289603523e-05, 'epoch': 0.8809948262378864, 'step': 4891500}
INFO:transformers.trainer:{'loss': 3.165242946147919, 'learning_rate': 3.531525200192259e-05, 'epoch': 0.8810848798846449, 'step': 4892000}
INFO:transformers.trainer:{'loss': 3.3758088612556456, 'learning_rate': 3.531375110780995e-05, 'epoch': 0.8811749335314033, 'step': 4892500}
INFO:transformers.trainer:{'loss': 3.186146535396576, 'learning_rate': 3.5312250213697306e-05, 'epoch': 0.8812649871781618, 'step': 4893000}
INFO:transformers.trainer:{'loss': 3.2491909091472624, 'learning_rate': 3.5310749319584665e-05, 'epoch': 0.8813550408249202, 'step': 4893500}
INFO:transformers.trainer:{'loss': 3.201682163476944, 'learning_rate': 3.5309248425472024e-05, 'epoch': 0.8814450944716786, 'step': 4894000}
INFO:transformers.trainer:{'loss': 3.1603140884637835, 'learning_rate': 3.530774753135938e-05, 'epoch': 0.8815351481184371, 'step': 4894500}
INFO:transformers.trainer:{'loss': 3.209746877670288, 'learning_rate': 3.530624663724674e-05, 'epoch': 0.8816252017651955, 'step': 4895000}
INFO:transformers.trainer:{'loss': 3.145972191572189, 'learning_rate': 3.53047457431341e-05, 'epoch': 0.8817152554119541, 'step': 4895500}
INFO:transformers.trainer:{'loss': 3.20437438249588, 'learning_rate': 3.530324484902146e-05, 'epoch': 0.8818053090587125, 'step': 4896000}
INFO:transformers.trainer:{'loss': 3.152832854986191, 'learning_rate': 3.530174395490882e-05, 'epoch': 0.8818953627054709, 'step': 4896500}
INFO:transformers.trainer:{'loss': 3.161415843486786, 'learning_rate': 3.530024306079618e-05, 'epoch': 0.8819854163522294, 'step': 4897000}
INFO:transformers.trainer:{'loss': 3.176655641078949, 'learning_rate': 3.529874216668354e-05, 'epoch': 0.8820754699989878, 'step': 4897500}
INFO:transformers.trainer:{'loss': 3.228761897802353, 'learning_rate': 3.5297241272570896e-05, 'epoch': 0.8821655236457463, 'step': 4898000}
INFO:transformers.trainer:{'loss': 3.11636763048172, 'learning_rate': 3.5295740378458255e-05, 'epoch': 0.8822555772925047, 'step': 4898500}
INFO:transformers.trainer:{'loss': 3.1829594411849977, 'learning_rate': 3.5294239484345614e-05, 'epoch': 0.8823456309392631, 'step': 4899000}
INFO:transformers.trainer:{'loss': 3.185243636608124, 'learning_rate': 3.5292738590232974e-05, 'epoch': 0.8824356845860216, 'step': 4899500}
INFO:transformers.trainer:{'loss': 3.2272218995094297, 'learning_rate': 3.529123769612033e-05, 'epoch': 0.88252573823278, 'step': 4900000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4900000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4900000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4900000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4800000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1163035480976107, 'learning_rate': 3.528973680200769e-05, 'epoch': 0.8826157918795384, 'step': 4900500}
INFO:transformers.trainer:{'loss': 3.2228456448316574, 'learning_rate': 3.528823590789505e-05, 'epoch': 0.8827058455262969, 'step': 4901000}
INFO:transformers.trainer:{'loss': 3.1201413419246675, 'learning_rate': 3.528673501378241e-05, 'epoch': 0.8827958991730553, 'step': 4901500}
INFO:transformers.trainer:{'loss': 3.1865033802986145, 'learning_rate': 3.528523411966977e-05, 'epoch': 0.8828859528198139, 'step': 4902000}
INFO:transformers.trainer:{'loss': 3.1341291983127593, 'learning_rate': 3.528373322555713e-05, 'epoch': 0.8829760064665723, 'step': 4902500}
INFO:transformers.trainer:{'loss': 3.2067025485038756, 'learning_rate': 3.5282232331444494e-05, 'epoch': 0.8830660601133307, 'step': 4903000}
INFO:transformers.trainer:{'loss': 3.1922830884456634, 'learning_rate': 3.5280731437331846e-05, 'epoch': 0.8831561137600892, 'step': 4903500}
INFO:transformers.trainer:{'loss': 3.186917835712433, 'learning_rate': 3.527923054321921e-05, 'epoch': 0.8832461674068476, 'step': 4904000}
INFO:transformers.trainer:{'loss': 3.1833716740608216, 'learning_rate': 3.5277729649106564e-05, 'epoch': 0.8833362210536061, 'step': 4904500}
INFO:transformers.trainer:{'loss': 3.13341571688652, 'learning_rate': 3.527622875499393e-05, 'epoch': 0.8834262747003645, 'step': 4905000}
INFO:transformers.trainer:{'loss': 3.2197996549606325, 'learning_rate': 3.527472786088128e-05, 'epoch': 0.8835163283471229, 'step': 4905500}
INFO:transformers.trainer:{'loss': 3.1532301180362703, 'learning_rate': 3.527322696676865e-05, 'epoch': 0.8836063819938814, 'step': 4906000}
INFO:transformers.trainer:{'loss': 3.229145157456398, 'learning_rate': 3.5271726072656e-05, 'epoch': 0.8836964356406398, 'step': 4906500}
INFO:transformers.trainer:{'loss': 3.184279277801514, 'learning_rate': 3.5270225178543366e-05, 'epoch': 0.8837864892873983, 'step': 4907000}
INFO:transformers.trainer:{'loss': 3.1558348898887636, 'learning_rate': 3.526872428443072e-05, 'epoch': 0.8838765429341567, 'step': 4907500}
INFO:transformers.trainer:{'loss': 3.1132432730197905, 'learning_rate': 3.5267223390318084e-05, 'epoch': 0.8839665965809151, 'step': 4908000}
INFO:transformers.trainer:{'loss': 3.1554259009361267, 'learning_rate': 3.5265722496205436e-05, 'epoch': 0.8840566502276737, 'step': 4908500}
INFO:transformers.trainer:{'loss': 3.1736343315839766, 'learning_rate': 3.52642216020928e-05, 'epoch': 0.8841467038744321, 'step': 4909000}
INFO:transformers.trainer:{'loss': 3.169532294511795, 'learning_rate': 3.5262720707980155e-05, 'epoch': 0.8842367575211906, 'step': 4909500}
INFO:transformers.trainer:{'loss': 3.164531793832779, 'learning_rate': 3.526121981386752e-05, 'epoch': 0.884326811167949, 'step': 4910000}
INFO:transformers.trainer:{'loss': 3.133848860025406, 'learning_rate': 3.525971891975488e-05, 'epoch': 0.8844168648147074, 'step': 4910500}
INFO:transformers.trainer:{'loss': 3.153490860939026, 'learning_rate': 3.525821802564224e-05, 'epoch': 0.8845069184614659, 'step': 4911000}
INFO:transformers.trainer:{'loss': 3.195951179265976, 'learning_rate': 3.52567171315296e-05, 'epoch': 0.8845969721082243, 'step': 4911500}
INFO:transformers.trainer:{'loss': 3.126179894685745, 'learning_rate': 3.5255216237416957e-05, 'epoch': 0.8846870257549827, 'step': 4912000}
INFO:transformers.trainer:{'loss': 3.169719113945961, 'learning_rate': 3.5253715343304316e-05, 'epoch': 0.8847770794017412, 'step': 4912500}
INFO:transformers.trainer:{'loss': 3.1381223134994505, 'learning_rate': 3.5252214449191675e-05, 'epoch': 0.8848671330484996, 'step': 4913000}
INFO:transformers.trainer:{'loss': 3.1527620003223418, 'learning_rate': 3.5250713555079034e-05, 'epoch': 0.8849571866952581, 'step': 4913500}
INFO:transformers.trainer:{'loss': 3.1374514162540437, 'learning_rate': 3.524921266096639e-05, 'epoch': 0.8850472403420165, 'step': 4914000}
INFO:transformers.trainer:{'loss': 3.2276607229709624, 'learning_rate': 3.524771176685375e-05, 'epoch': 0.8851372939887749, 'step': 4914500}
INFO:transformers.trainer:{'loss': 3.1436609303951264, 'learning_rate': 3.524621087274111e-05, 'epoch': 0.8852273476355335, 'step': 4915000}
INFO:transformers.trainer:{'loss': 3.200213378429413, 'learning_rate': 3.524470997862847e-05, 'epoch': 0.8853174012822919, 'step': 4915500}
INFO:transformers.trainer:{'loss': 3.1456340713500976, 'learning_rate': 3.524320908451583e-05, 'epoch': 0.8854074549290504, 'step': 4916000}
INFO:transformers.trainer:{'loss': 3.160215363740921, 'learning_rate': 3.524170819040319e-05, 'epoch': 0.8854975085758088, 'step': 4916500}
INFO:transformers.trainer:{'loss': 3.3054946136474608, 'learning_rate': 3.5240207296290554e-05, 'epoch': 0.8855875622225672, 'step': 4917000}
INFO:transformers.trainer:{'loss': 3.2321669204235075, 'learning_rate': 3.5238706402177906e-05, 'epoch': 0.8856776158693257, 'step': 4917500}
INFO:transformers.trainer:{'loss': 3.1516426496505736, 'learning_rate': 3.5237205508065265e-05, 'epoch': 0.8857676695160841, 'step': 4918000}
INFO:transformers.trainer:{'loss': 3.1877713627815245, 'learning_rate': 3.5235704613952624e-05, 'epoch': 0.8858577231628426, 'step': 4918500}
INFO:transformers.trainer:{'loss': 3.2216334972381593, 'learning_rate': 3.523420371983998e-05, 'epoch': 0.885947776809601, 'step': 4919000}
INFO:transformers.trainer:{'loss': 3.1767713108062745, 'learning_rate': 3.523270282572734e-05, 'epoch': 0.8860378304563594, 'step': 4919500}
INFO:transformers.trainer:{'loss': 3.1573210307359694, 'learning_rate': 3.52312019316147e-05, 'epoch': 0.8861278841031179, 'step': 4920000}
INFO:transformers.trainer:{'loss': 3.1780107283592223, 'learning_rate': 3.522970103750206e-05, 'epoch': 0.8862179377498763, 'step': 4920500}
INFO:transformers.trainer:{'loss': 3.1447757682800295, 'learning_rate': 3.522820014338942e-05, 'epoch': 0.8863079913966349, 'step': 4921000}
INFO:transformers.trainer:{'loss': 3.1660077302455902, 'learning_rate': 3.522669924927678e-05, 'epoch': 0.8863980450433933, 'step': 4921500}
INFO:transformers.trainer:{'loss': 3.201001670360565, 'learning_rate': 3.522519835516414e-05, 'epoch': 0.8864880986901517, 'step': 4922000}
INFO:transformers.trainer:{'loss': 3.168195277571678, 'learning_rate': 3.52236974610515e-05, 'epoch': 0.8865781523369102, 'step': 4922500}
INFO:transformers.trainer:{'loss': 3.1323891599178313, 'learning_rate': 3.5222196566938856e-05, 'epoch': 0.8866682059836686, 'step': 4923000}
INFO:transformers.trainer:{'loss': 3.158785538673401, 'learning_rate': 3.5220695672826215e-05, 'epoch': 0.8867582596304271, 'step': 4923500}
INFO:transformers.trainer:{'loss': 3.2249794130325315, 'learning_rate': 3.5219194778713574e-05, 'epoch': 0.8868483132771855, 'step': 4924000}
INFO:transformers.trainer:{'loss': 3.1688951208591463, 'learning_rate': 3.521769388460094e-05, 'epoch': 0.8869383669239439, 'step': 4924500}
INFO:transformers.trainer:{'loss': 3.205347976922989, 'learning_rate': 3.521619299048829e-05, 'epoch': 0.8870284205707024, 'step': 4925000}
INFO:transformers.trainer:{'loss': 3.206292348027229, 'learning_rate': 3.521469209637566e-05, 'epoch': 0.8871184742174608, 'step': 4925500}
INFO:transformers.trainer:{'loss': 3.311325689315796, 'learning_rate': 3.521319120226301e-05, 'epoch': 0.8872085278642192, 'step': 4926000}
INFO:transformers.trainer:{'loss': 3.1776849459409715, 'learning_rate': 3.5211690308150376e-05, 'epoch': 0.8872985815109777, 'step': 4926500}
INFO:transformers.trainer:{'loss': 3.171685443878174, 'learning_rate': 3.521018941403773e-05, 'epoch': 0.8873886351577361, 'step': 4927000}
INFO:transformers.trainer:{'loss': 3.1191578452587128, 'learning_rate': 3.5208688519925094e-05, 'epoch': 0.8874786888044947, 'step': 4927500}
INFO:transformers.trainer:{'loss': 3.1763824634552003, 'learning_rate': 3.5207187625812446e-05, 'epoch': 0.8875687424512531, 'step': 4928000}
INFO:transformers.trainer:{'loss': 3.1540374705791474, 'learning_rate': 3.520568673169981e-05, 'epoch': 0.8876587960980115, 'step': 4928500}
INFO:transformers.trainer:{'loss': 3.188082670688629, 'learning_rate': 3.5204185837587164e-05, 'epoch': 0.88774884974477, 'step': 4929000}
INFO:transformers.trainer:{'loss': 3.11705501639843, 'learning_rate': 3.520268494347453e-05, 'epoch': 0.8878389033915284, 'step': 4929500}
INFO:transformers.trainer:{'loss': 3.2000111145973205, 'learning_rate': 3.520118404936188e-05, 'epoch': 0.8879289570382869, 'step': 4930000}
INFO:transformers.trainer:{'loss': 3.3088008160591125, 'learning_rate': 3.519968315524925e-05, 'epoch': 0.8880190106850453, 'step': 4930500}
INFO:transformers.trainer:{'loss': 3.2132366988658907, 'learning_rate': 3.519818226113661e-05, 'epoch': 0.8881090643318037, 'step': 4931000}
INFO:transformers.trainer:{'loss': 3.147384251832962, 'learning_rate': 3.5196681367023966e-05, 'epoch': 0.8881991179785622, 'step': 4931500}
INFO:transformers.trainer:{'loss': 3.1391016926765443, 'learning_rate': 3.5195180472911325e-05, 'epoch': 0.8882891716253206, 'step': 4932000}
INFO:transformers.trainer:{'loss': 3.1269948003292085, 'learning_rate': 3.5193679578798684e-05, 'epoch': 0.8883792252720791, 'step': 4932500}
INFO:transformers.trainer:{'loss': 3.112424188733101, 'learning_rate': 3.5192178684686043e-05, 'epoch': 0.8884692789188375, 'step': 4933000}
INFO:transformers.trainer:{'loss': 3.1724535672664644, 'learning_rate': 3.51906777905734e-05, 'epoch': 0.8885593325655959, 'step': 4933500}
INFO:transformers.trainer:{'loss': 3.118326702594757, 'learning_rate': 3.518917689646076e-05, 'epoch': 0.8886493862123545, 'step': 4934000}
INFO:transformers.trainer:{'loss': 3.1586346205472946, 'learning_rate': 3.518767600234812e-05, 'epoch': 0.8887394398591129, 'step': 4934500}
INFO:transformers.trainer:{'loss': 3.2332228515148165, 'learning_rate': 3.518617510823548e-05, 'epoch': 0.8888294935058714, 'step': 4935000}
INFO:transformers.trainer:{'loss': 3.1456833912134172, 'learning_rate': 3.518467421412284e-05, 'epoch': 0.8889195471526298, 'step': 4935500}
INFO:transformers.trainer:{'loss': 3.1330151722431183, 'learning_rate': 3.51831733200102e-05, 'epoch': 0.8890096007993882, 'step': 4936000}
INFO:transformers.trainer:{'loss': 3.192866096973419, 'learning_rate': 3.518167242589756e-05, 'epoch': 0.8890996544461467, 'step': 4936500}
INFO:transformers.trainer:{'loss': 3.1786386189460756, 'learning_rate': 3.5180171531784916e-05, 'epoch': 0.8891897080929051, 'step': 4937000}
INFO:transformers.trainer:{'loss': 3.1548447093963623, 'learning_rate': 3.517867063767228e-05, 'epoch': 0.8892797617396635, 'step': 4937500}
INFO:transformers.trainer:{'loss': 3.202929152727127, 'learning_rate': 3.5177169743559634e-05, 'epoch': 0.889369815386422, 'step': 4938000}
INFO:transformers.trainer:{'loss': 3.11740358376503, 'learning_rate': 3.5175668849447e-05, 'epoch': 0.8894598690331804, 'step': 4938500}
INFO:transformers.trainer:{'loss': 3.1582346965074537, 'learning_rate': 3.517416795533435e-05, 'epoch': 0.8895499226799389, 'step': 4939000}
INFO:transformers.trainer:{'loss': 3.183547471046448, 'learning_rate': 3.517266706122172e-05, 'epoch': 0.8896399763266973, 'step': 4939500}
INFO:transformers.trainer:{'loss': 3.183445934534073, 'learning_rate': 3.517116616710907e-05, 'epoch': 0.8897300299734557, 'step': 4940000}
INFO:transformers.trainer:{'loss': 3.138689578294754, 'learning_rate': 3.5169665272996436e-05, 'epoch': 0.8898200836202143, 'step': 4940500}
INFO:transformers.trainer:{'loss': 3.096839423418045, 'learning_rate': 3.516816437888379e-05, 'epoch': 0.8899101372669727, 'step': 4941000}
INFO:transformers.trainer:{'loss': 3.159779193162918, 'learning_rate': 3.5166663484771154e-05, 'epoch': 0.8900001909137312, 'step': 4941500}
INFO:transformers.trainer:{'loss': 3.1301217036247255, 'learning_rate': 3.5165162590658506e-05, 'epoch': 0.8900902445604896, 'step': 4942000}
INFO:transformers.trainer:{'loss': 3.244460299253464, 'learning_rate': 3.5163661696545865e-05, 'epoch': 0.890180298207248, 'step': 4942500}
INFO:transformers.trainer:{'loss': 3.160548887014389, 'learning_rate': 3.5162160802433224e-05, 'epoch': 0.8902703518540065, 'step': 4943000}
INFO:transformers.trainer:{'loss': 3.1286475694179536, 'learning_rate': 3.5160659908320583e-05, 'epoch': 0.8903604055007649, 'step': 4943500}
INFO:transformers.trainer:{'loss': 3.1662748603820803, 'learning_rate': 3.515915901420794e-05, 'epoch': 0.8904504591475234, 'step': 4944000}
INFO:transformers.trainer:{'loss': 3.1422336421012877, 'learning_rate': 3.51576581200953e-05, 'epoch': 0.8905405127942818, 'step': 4944500}
INFO:transformers.trainer:{'loss': 3.1547739410400393, 'learning_rate': 3.515615722598267e-05, 'epoch': 0.8906305664410402, 'step': 4945000}
INFO:transformers.trainer:{'loss': 3.1281222692728043, 'learning_rate': 3.515465633187002e-05, 'epoch': 0.8907206200877987, 'step': 4945500}
INFO:transformers.trainer:{'loss': 3.2113246705532075, 'learning_rate': 3.5153155437757386e-05, 'epoch': 0.8908106737345571, 'step': 4946000}
INFO:transformers.trainer:{'loss': 3.2363400375843048, 'learning_rate': 3.515165454364474e-05, 'epoch': 0.8909007273813156, 'step': 4946500}
INFO:transformers.trainer:{'loss': 3.1795931515693665, 'learning_rate': 3.5150153649532104e-05, 'epoch': 0.890990781028074, 'step': 4947000}
INFO:transformers.trainer:{'loss': 3.1912238562107085, 'learning_rate': 3.5148652755419456e-05, 'epoch': 0.8910808346748325, 'step': 4947500}
INFO:transformers.trainer:{'loss': 3.1363298037052156, 'learning_rate': 3.514715186130682e-05, 'epoch': 0.891170888321591, 'step': 4948000}
INFO:transformers.trainer:{'loss': 3.1105848380923273, 'learning_rate': 3.5145650967194174e-05, 'epoch': 0.8912609419683494, 'step': 4948500}
INFO:transformers.trainer:{'loss': 3.1109121000766753, 'learning_rate': 3.514415007308154e-05, 'epoch': 0.8913509956151078, 'step': 4949000}
INFO:transformers.trainer:{'loss': 3.1604068076610563, 'learning_rate': 3.514264917896889e-05, 'epoch': 0.8914410492618663, 'step': 4949500}
INFO:transformers.trainer:{'loss': 3.151084824323654, 'learning_rate': 3.514114828485626e-05, 'epoch': 0.8915311029086247, 'step': 4950000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-4950000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4950000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-4950000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4850000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1510753296613694, 'learning_rate': 3.513964739074361e-05, 'epoch': 0.8916211565553832, 'step': 4950500}
INFO:transformers.trainer:{'loss': 3.1489081909656527, 'learning_rate': 3.5138146496630976e-05, 'epoch': 0.8917112102021416, 'step': 4951000}
INFO:transformers.trainer:{'loss': 3.1448631035089494, 'learning_rate': 3.5136645602518335e-05, 'epoch': 0.8918012638489, 'step': 4951500}
INFO:transformers.trainer:{'loss': 3.1981881988048553, 'learning_rate': 3.5135144708405694e-05, 'epoch': 0.8918913174956585, 'step': 4952000}
INFO:transformers.trainer:{'loss': 3.1385461136102677, 'learning_rate': 3.513364381429305e-05, 'epoch': 0.8919813711424169, 'step': 4952500}
INFO:transformers.trainer:{'loss': 3.167216566324234, 'learning_rate': 3.513214292018041e-05, 'epoch': 0.8920714247891754, 'step': 4953000}
INFO:transformers.trainer:{'loss': 3.203870186805725, 'learning_rate': 3.513064202606777e-05, 'epoch': 0.8921614784359339, 'step': 4953500}
INFO:transformers.trainer:{'loss': 3.1660887118577956, 'learning_rate': 3.512914113195513e-05, 'epoch': 0.8922515320826923, 'step': 4954000}
INFO:transformers.trainer:{'loss': 3.086993216753006, 'learning_rate': 3.512764023784249e-05, 'epoch': 0.8923415857294508, 'step': 4954500}
INFO:transformers.trainer:{'loss': 3.1676080677509306, 'learning_rate': 3.512613934372985e-05, 'epoch': 0.8924316393762092, 'step': 4955000}
INFO:transformers.trainer:{'loss': 3.162643962144852, 'learning_rate': 3.512463844961721e-05, 'epoch': 0.8925216930229677, 'step': 4955500}
INFO:transformers.trainer:{'loss': 3.127826112985611, 'learning_rate': 3.5123137555504567e-05, 'epoch': 0.8926117466697261, 'step': 4956000}
INFO:transformers.trainer:{'loss': 3.1373510360717773, 'learning_rate': 3.5121636661391926e-05, 'epoch': 0.8927018003164845, 'step': 4956500}
INFO:transformers.trainer:{'loss': 3.131067592382431, 'learning_rate': 3.5120135767279285e-05, 'epoch': 0.892791853963243, 'step': 4957000}
INFO:transformers.trainer:{'loss': 3.114352245569229, 'learning_rate': 3.5118634873166644e-05, 'epoch': 0.8928819076100014, 'step': 4957500}
INFO:transformers.trainer:{'loss': 3.2207890325784683, 'learning_rate': 3.5117133979054e-05, 'epoch': 0.8929719612567599, 'step': 4958000}
INFO:transformers.trainer:{'loss': 3.1273699810504914, 'learning_rate': 3.511563308494136e-05, 'epoch': 0.8930620149035183, 'step': 4958500}
INFO:transformers.trainer:{'loss': 3.1841018099784852, 'learning_rate': 3.511413219082873e-05, 'epoch': 0.8931520685502767, 'step': 4959000}
INFO:transformers.trainer:{'loss': 3.114016676902771, 'learning_rate': 3.511263129671608e-05, 'epoch': 0.8932421221970352, 'step': 4959500}
INFO:transformers.trainer:{'loss': 3.1915608751773834, 'learning_rate': 3.5111130402603446e-05, 'epoch': 0.8933321758437937, 'step': 4960000}
INFO:transformers.trainer:{'loss': 3.1928458561897277, 'learning_rate': 3.51096295084908e-05, 'epoch': 0.8934222294905522, 'step': 4960500}
INFO:transformers.trainer:{'loss': 3.144783317267895, 'learning_rate': 3.5108128614378164e-05, 'epoch': 0.8935122831373106, 'step': 4961000}
INFO:transformers.trainer:{'loss': 3.18969068813324, 'learning_rate': 3.5106627720265516e-05, 'epoch': 0.893602336784069, 'step': 4961500}
INFO:transformers.trainer:{'loss': 3.1052767205238343, 'learning_rate': 3.510512682615288e-05, 'epoch': 0.8936923904308275, 'step': 4962000}
INFO:transformers.trainer:{'loss': 3.183009484052658, 'learning_rate': 3.5103625932040234e-05, 'epoch': 0.8937824440775859, 'step': 4962500}
INFO:transformers.trainer:{'loss': 3.110369810342789, 'learning_rate': 3.51021250379276e-05, 'epoch': 0.8938724977243443, 'step': 4963000}
INFO:transformers.trainer:{'loss': 3.1335507278442383, 'learning_rate': 3.510062414381495e-05, 'epoch': 0.8939625513711028, 'step': 4963500}
INFO:transformers.trainer:{'loss': 3.1862065060138702, 'learning_rate': 3.509912324970232e-05, 'epoch': 0.8940526050178612, 'step': 4964000}
INFO:transformers.trainer:{'loss': 3.1666940695047376, 'learning_rate': 3.509762235558967e-05, 'epoch': 0.8941426586646197, 'step': 4964500}
INFO:transformers.trainer:{'loss': 3.1220720106363298, 'learning_rate': 3.5096121461477036e-05, 'epoch': 0.8942327123113781, 'step': 4965000}
INFO:transformers.trainer:{'loss': 3.1247846183776855, 'learning_rate': 3.5094620567364395e-05, 'epoch': 0.8943227659581365, 'step': 4965500}
INFO:transformers.trainer:{'loss': 3.2012467445135115, 'learning_rate': 3.509311967325175e-05, 'epoch': 0.894412819604895, 'step': 4966000}
INFO:transformers.trainer:{'loss': 3.1110081770420073, 'learning_rate': 3.509161877913911e-05, 'epoch': 0.8945028732516535, 'step': 4966500}
INFO:transformers.trainer:{'loss': 3.1404540622234345, 'learning_rate': 3.5090117885026466e-05, 'epoch': 0.894592926898412, 'step': 4967000}
INFO:transformers.trainer:{'loss': 3.1296511116027834, 'learning_rate': 3.508861699091383e-05, 'epoch': 0.8946829805451704, 'step': 4967500}
INFO:transformers.trainer:{'loss': 3.2094587519168853, 'learning_rate': 3.5087116096801184e-05, 'epoch': 0.8947730341919288, 'step': 4968000}
INFO:transformers.trainer:{'loss': 3.1602892537117, 'learning_rate': 3.508561520268855e-05, 'epoch': 0.8948630878386873, 'step': 4968500}
INFO:transformers.trainer:{'loss': 3.148961332321167, 'learning_rate': 3.50841143085759e-05, 'epoch': 0.8949531414854457, 'step': 4969000}
INFO:transformers.trainer:{'loss': 3.1478015599250795, 'learning_rate': 3.508261341446327e-05, 'epoch': 0.8950431951322042, 'step': 4969500}
INFO:transformers.trainer:{'loss': 3.162778224945068, 'learning_rate': 3.508111252035062e-05, 'epoch': 0.8951332487789626, 'step': 4970000}
INFO:transformers.trainer:{'loss': 3.210184355735779, 'learning_rate': 3.5079611626237986e-05, 'epoch': 0.895223302425721, 'step': 4970500}
INFO:transformers.trainer:{'loss': 3.1638027982711794, 'learning_rate': 3.507811073212534e-05, 'epoch': 0.8953133560724795, 'step': 4971000}
INFO:transformers.trainer:{'loss': 3.1116409054994585, 'learning_rate': 3.5076609838012704e-05, 'epoch': 0.8954034097192379, 'step': 4971500}
INFO:transformers.trainer:{'loss': 3.155812208890915, 'learning_rate': 3.5075108943900056e-05, 'epoch': 0.8954934633659964, 'step': 4972000}
INFO:transformers.trainer:{'loss': 3.153143097639084, 'learning_rate': 3.507360804978742e-05, 'epoch': 0.8955835170127548, 'step': 4972500}
INFO:transformers.trainer:{'loss': 3.1280452551841735, 'learning_rate': 3.507210715567478e-05, 'epoch': 0.8956735706595133, 'step': 4973000}
INFO:transformers.trainer:{'loss': 3.136545968532562, 'learning_rate': 3.507060626156214e-05, 'epoch': 0.8957636243062718, 'step': 4973500}
INFO:transformers.trainer:{'loss': 3.13041511452198, 'learning_rate': 3.50691053674495e-05, 'epoch': 0.8958536779530302, 'step': 4974000}
INFO:transformers.trainer:{'loss': 3.1849787616729737, 'learning_rate': 3.506760447333686e-05, 'epoch': 0.8959437315997886, 'step': 4974500}
INFO:transformers.trainer:{'loss': 3.1976154725551607, 'learning_rate': 3.506610357922422e-05, 'epoch': 0.8960337852465471, 'step': 4975000}
INFO:transformers.trainer:{'loss': 3.1374883940219878, 'learning_rate': 3.5064602685111576e-05, 'epoch': 0.8961238388933055, 'step': 4975500}
INFO:transformers.trainer:{'loss': 3.149739281654358, 'learning_rate': 3.5063101790998935e-05, 'epoch': 0.896213892540064, 'step': 4976000}
INFO:transformers.trainer:{'loss': 3.174184047460556, 'learning_rate': 3.5061600896886294e-05, 'epoch': 0.8963039461868224, 'step': 4976500}
INFO:transformers.trainer:{'loss': 3.2471715047359466, 'learning_rate': 3.5060100002773653e-05, 'epoch': 0.8963939998335808, 'step': 4977000}
INFO:transformers.trainer:{'loss': 3.1533630273342133, 'learning_rate': 3.505859910866101e-05, 'epoch': 0.8964840534803393, 'step': 4977500}
INFO:transformers.trainer:{'loss': 3.2245755598545074, 'learning_rate': 3.505709821454837e-05, 'epoch': 0.8965741071270977, 'step': 4978000}
INFO:transformers.trainer:{'loss': 3.117822240114212, 'learning_rate': 3.505559732043573e-05, 'epoch': 0.8966641607738562, 'step': 4978500}
INFO:transformers.trainer:{'loss': 3.1676360141038895, 'learning_rate': 3.505409642632309e-05, 'epoch': 0.8967542144206146, 'step': 4979000}
INFO:transformers.trainer:{'loss': 3.09794848549366, 'learning_rate': 3.5052595532210455e-05, 'epoch': 0.896844268067373, 'step': 4979500}
INFO:transformers.trainer:{'loss': 3.1737899632453916, 'learning_rate': 3.505109463809781e-05, 'epoch': 0.8969343217141316, 'step': 4980000}
INFO:transformers.trainer:{'loss': 3.122686695098877, 'learning_rate': 3.5049593743985174e-05, 'epoch': 0.89702437536089, 'step': 4980500}
INFO:transformers.trainer:{'loss': 3.1352165739536284, 'learning_rate': 3.5048092849872526e-05, 'epoch': 0.8971144290076485, 'step': 4981000}
INFO:transformers.trainer:{'loss': 3.1118058581352233, 'learning_rate': 3.504659195575989e-05, 'epoch': 0.8972044826544069, 'step': 4981500}
INFO:transformers.trainer:{'loss': 3.144852479696274, 'learning_rate': 3.5045091061647244e-05, 'epoch': 0.8972945363011653, 'step': 4982000}
INFO:transformers.trainer:{'loss': 3.25962043094635, 'learning_rate': 3.504359016753461e-05, 'epoch': 0.8973845899479238, 'step': 4982500}
INFO:transformers.trainer:{'loss': 3.1731046929359437, 'learning_rate': 3.504208927342196e-05, 'epoch': 0.8974746435946822, 'step': 4983000}
INFO:transformers.trainer:{'loss': 3.07646648645401, 'learning_rate': 3.504058837930933e-05, 'epoch': 0.8975646972414407, 'step': 4983500}
INFO:transformers.trainer:{'loss': 3.1142892980575563, 'learning_rate': 3.503908748519668e-05, 'epoch': 0.8976547508881991, 'step': 4984000}
INFO:transformers.trainer:{'loss': 3.19663964343071, 'learning_rate': 3.5037586591084046e-05, 'epoch': 0.8977448045349575, 'step': 4984500}
INFO:transformers.trainer:{'loss': 3.1251159538030624, 'learning_rate': 3.50360856969714e-05, 'epoch': 0.897834858181716, 'step': 4985000}
INFO:transformers.trainer:{'loss': 3.1754717803001404, 'learning_rate': 3.5034584802858764e-05, 'epoch': 0.8979249118284744, 'step': 4985500}
INFO:transformers.trainer:{'loss': 3.186861343383789, 'learning_rate': 3.503308390874612e-05, 'epoch': 0.8980149654752329, 'step': 4986000}
INFO:transformers.trainer:{'loss': 3.1775339215993883, 'learning_rate': 3.503158301463348e-05, 'epoch': 0.8981050191219914, 'step': 4986500}
INFO:transformers.trainer:{'loss': 3.170879896044731, 'learning_rate': 3.503008212052084e-05, 'epoch': 0.8981950727687498, 'step': 4987000}
INFO:transformers.trainer:{'loss': 3.1290351009368895, 'learning_rate': 3.50285812264082e-05, 'epoch': 0.8982851264155083, 'step': 4987500}
INFO:transformers.trainer:{'loss': 3.1910679607391357, 'learning_rate': 3.502708033229556e-05, 'epoch': 0.8983751800622667, 'step': 4988000}
INFO:transformers.trainer:{'loss': 3.1440566747188567, 'learning_rate': 3.502557943818292e-05, 'epoch': 0.8984652337090251, 'step': 4988500}
INFO:transformers.trainer:{'loss': 3.1841394073963167, 'learning_rate': 3.502407854407028e-05, 'epoch': 0.8985552873557836, 'step': 4989000}
INFO:transformers.trainer:{'loss': 3.196203638315201, 'learning_rate': 3.502257764995763e-05, 'epoch': 0.898645341002542, 'step': 4989500}
INFO:transformers.trainer:{'loss': 3.1350819051265715, 'learning_rate': 3.5021076755844995e-05, 'epoch': 0.8987353946493005, 'step': 4990000}
INFO:transformers.trainer:{'loss': 3.214302612543106, 'learning_rate': 3.501957586173235e-05, 'epoch': 0.8988254482960589, 'step': 4990500}
INFO:transformers.trainer:{'loss': 3.2106193716526032, 'learning_rate': 3.5018074967619714e-05, 'epoch': 0.8989155019428173, 'step': 4991000}
INFO:transformers.trainer:{'loss': 3.1175054478645325, 'learning_rate': 3.5016574073507066e-05, 'epoch': 0.8990055555895758, 'step': 4991500}
INFO:transformers.trainer:{'loss': 3.1198433717489245, 'learning_rate': 3.501507317939443e-05, 'epoch': 0.8990956092363342, 'step': 4992000}
INFO:transformers.trainer:{'loss': 3.1689209175109863, 'learning_rate': 3.5013572285281784e-05, 'epoch': 0.8991856628830928, 'step': 4992500}
INFO:transformers.trainer:{'loss': 3.1550218410491944, 'learning_rate': 3.501207139116915e-05, 'epoch': 0.8992757165298512, 'step': 4993000}
INFO:transformers.trainer:{'loss': 3.1214818015098573, 'learning_rate': 3.501057049705651e-05, 'epoch': 0.8993657701766096, 'step': 4993500}
INFO:transformers.trainer:{'loss': 3.2031416611671446, 'learning_rate': 3.500906960294387e-05, 'epoch': 0.8994558238233681, 'step': 4994000}
INFO:transformers.trainer:{'loss': 3.196937889814377, 'learning_rate': 3.500756870883123e-05, 'epoch': 0.8995458774701265, 'step': 4994500}
INFO:transformers.trainer:{'loss': 3.224063549280167, 'learning_rate': 3.5006067814718586e-05, 'epoch': 0.899635931116885, 'step': 4995000}
INFO:transformers.trainer:{'loss': 3.1688771414756776, 'learning_rate': 3.5004566920605945e-05, 'epoch': 0.8997259847636434, 'step': 4995500}
INFO:transformers.trainer:{'loss': 3.1422243115901947, 'learning_rate': 3.5003066026493304e-05, 'epoch': 0.8998160384104018, 'step': 4996000}
INFO:transformers.trainer:{'loss': 3.098042753458023, 'learning_rate': 3.500156513238066e-05, 'epoch': 0.8999060920571603, 'step': 4996500}
INFO:transformers.trainer:{'loss': 3.13416609197855, 'learning_rate': 3.500006423826802e-05, 'epoch': 0.8999961457039187, 'step': 4997000}
INFO:transformers.trainer:{'loss': 3.199183225631714, 'learning_rate': 3.499856334415538e-05, 'epoch': 0.9000861993506772, 'step': 4997500}
INFO:transformers.trainer:{'loss': 3.111215234160423, 'learning_rate': 3.499706245004274e-05, 'epoch': 0.9001762529974356, 'step': 4998000}
INFO:transformers.trainer:{'loss': 3.1383351600170135, 'learning_rate': 3.49955615559301e-05, 'epoch': 0.900266306644194, 'step': 4998500}
INFO:transformers.trainer:{'loss': 3.1319190325737, 'learning_rate': 3.499406066181746e-05, 'epoch': 0.9003563602909526, 'step': 4999000}
INFO:transformers.trainer:{'loss': 3.0947831976413727, 'learning_rate': 3.499255976770482e-05, 'epoch': 0.900446413937711, 'step': 4999500}
INFO:transformers.trainer:{'loss': 3.2429298601150514, 'learning_rate': 3.499105887359218e-05, 'epoch': 0.9005364675844694, 'step': 5000000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5000000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5000000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5000000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4900000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1357572908401488, 'learning_rate': 3.4989557979479536e-05, 'epoch': 0.9006265212312279, 'step': 5000500}
INFO:transformers.trainer:{'loss': 3.1082969782352445, 'learning_rate': 3.49880570853669e-05, 'epoch': 0.9007165748779863, 'step': 5001000}
INFO:transformers.trainer:{'loss': 3.1453376774787905, 'learning_rate': 3.4986556191254254e-05, 'epoch': 0.9008066285247448, 'step': 5001500}
INFO:transformers.trainer:{'loss': 3.1844136626720427, 'learning_rate': 3.498505529714162e-05, 'epoch': 0.9008966821715032, 'step': 5002000}
INFO:transformers.trainer:{'loss': 3.1928046638965606, 'learning_rate': 3.498355440302897e-05, 'epoch': 0.9009867358182616, 'step': 5002500}
INFO:transformers.trainer:{'loss': 3.1281238075494766, 'learning_rate': 3.498205350891634e-05, 'epoch': 0.9010767894650201, 'step': 5003000}
INFO:transformers.trainer:{'loss': 3.2249746358394624, 'learning_rate': 3.498055261480369e-05, 'epoch': 0.9011668431117785, 'step': 5003500}
INFO:transformers.trainer:{'loss': 3.1221115546226503, 'learning_rate': 3.4979051720691056e-05, 'epoch': 0.901256896758537, 'step': 5004000}
INFO:transformers.trainer:{'loss': 3.126943551778793, 'learning_rate': 3.497755082657841e-05, 'epoch': 0.9013469504052954, 'step': 5004500}
INFO:transformers.trainer:{'loss': 3.154403537273407, 'learning_rate': 3.4976049932465774e-05, 'epoch': 0.9014370040520538, 'step': 5005000}
INFO:transformers.trainer:{'loss': 3.1174204046726226, 'learning_rate': 3.4974549038353126e-05, 'epoch': 0.9015270576988124, 'step': 5005500}
INFO:transformers.trainer:{'loss': 3.1085567519664763, 'learning_rate': 3.497304814424049e-05, 'epoch': 0.9016171113455708, 'step': 5006000}
INFO:transformers.trainer:{'loss': 3.188593084335327, 'learning_rate': 3.4971547250127844e-05, 'epoch': 0.9017071649923293, 'step': 5006500}
INFO:transformers.trainer:{'loss': 3.1228040215969086, 'learning_rate': 3.497004635601521e-05, 'epoch': 0.9017972186390877, 'step': 5007000}
INFO:transformers.trainer:{'loss': 3.190786426305771, 'learning_rate': 3.496854546190257e-05, 'epoch': 0.9018872722858461, 'step': 5007500}
INFO:transformers.trainer:{'loss': 3.2339271904230116, 'learning_rate': 3.496704456778993e-05, 'epoch': 0.9019773259326046, 'step': 5008000}
INFO:transformers.trainer:{'loss': 3.100517411708832, 'learning_rate': 3.496554367367729e-05, 'epoch': 0.902067379579363, 'step': 5008500}
INFO:transformers.trainer:{'loss': 3.1290698627233504, 'learning_rate': 3.4964042779564646e-05, 'epoch': 0.9021574332261215, 'step': 5009000}
INFO:transformers.trainer:{'loss': 3.187117626667023, 'learning_rate': 3.4962541885452005e-05, 'epoch': 0.9022474868728799, 'step': 5009500}
INFO:transformers.trainer:{'loss': 3.220290603160858, 'learning_rate': 3.4961040991339364e-05, 'epoch': 0.9023375405196383, 'step': 5010000}
INFO:transformers.trainer:{'loss': 3.17241822886467, 'learning_rate': 3.495954009722672e-05, 'epoch': 0.9024275941663968, 'step': 5010500}
INFO:transformers.trainer:{'loss': 3.1462974627017974, 'learning_rate': 3.495803920311408e-05, 'epoch': 0.9025176478131552, 'step': 5011000}
INFO:transformers.trainer:{'loss': 3.128747958421707, 'learning_rate': 3.495653830900144e-05, 'epoch': 0.9026077014599136, 'step': 5011500}
INFO:transformers.trainer:{'loss': 3.2019344687461855, 'learning_rate': 3.49550374148888e-05, 'epoch': 0.9026977551066722, 'step': 5012000}
INFO:transformers.trainer:{'loss': 3.190611859083176, 'learning_rate': 3.495353652077616e-05, 'epoch': 0.9027878087534306, 'step': 5012500}
INFO:transformers.trainer:{'loss': 3.11814031457901, 'learning_rate': 3.495203562666351e-05, 'epoch': 0.9028778624001891, 'step': 5013000}
INFO:transformers.trainer:{'loss': 3.169179315328598, 'learning_rate': 3.495053473255088e-05, 'epoch': 0.9029679160469475, 'step': 5013500}
INFO:transformers.trainer:{'loss': 3.203806956291199, 'learning_rate': 3.494903383843824e-05, 'epoch': 0.9030579696937059, 'step': 5014000}
INFO:transformers.trainer:{'loss': 3.164296021103859, 'learning_rate': 3.4947532944325596e-05, 'epoch': 0.9031480233404644, 'step': 5014500}
INFO:transformers.trainer:{'loss': 3.17303591299057, 'learning_rate': 3.4946032050212955e-05, 'epoch': 0.9032380769872228, 'step': 5015000}
INFO:transformers.trainer:{'loss': 3.1626374731063844, 'learning_rate': 3.4944531156100314e-05, 'epoch': 0.9033281306339813, 'step': 5015500}
INFO:transformers.trainer:{'loss': 3.122967034101486, 'learning_rate': 3.494303026198767e-05, 'epoch': 0.9034181842807397, 'step': 5016000}
INFO:transformers.trainer:{'loss': 3.118851430416107, 'learning_rate': 3.494152936787503e-05, 'epoch': 0.9035082379274981, 'step': 5016500}
INFO:transformers.trainer:{'loss': 3.156418443441391, 'learning_rate': 3.494002847376239e-05, 'epoch': 0.9035982915742566, 'step': 5017000}
INFO:transformers.trainer:{'loss': 3.1102083407640455, 'learning_rate': 3.493852757964975e-05, 'epoch': 0.903688345221015, 'step': 5017500}
INFO:transformers.trainer:{'loss': 3.1881449074745176, 'learning_rate': 3.493702668553711e-05, 'epoch': 0.9037783988677736, 'step': 5018000}
INFO:transformers.trainer:{'loss': 3.1796215649843216, 'learning_rate': 3.493552579142447e-05, 'epoch': 0.903868452514532, 'step': 5018500}
INFO:transformers.trainer:{'loss': 3.1848246874809267, 'learning_rate': 3.493402489731183e-05, 'epoch': 0.9039585061612904, 'step': 5019000}
INFO:transformers.trainer:{'loss': 3.1513723270893097, 'learning_rate': 3.4932524003199186e-05, 'epoch': 0.9040485598080489, 'step': 5019500}
INFO:transformers.trainer:{'loss': 3.126153333425522, 'learning_rate': 3.4931023109086545e-05, 'epoch': 0.9041386134548073, 'step': 5020000}
INFO:transformers.trainer:{'loss': 3.1618496692180633, 'learning_rate': 3.4929522214973904e-05, 'epoch': 0.9042286671015658, 'step': 5020500}
INFO:transformers.trainer:{'loss': 3.1142317398786545, 'learning_rate': 3.492802132086126e-05, 'epoch': 0.9043187207483242, 'step': 5021000}
INFO:transformers.trainer:{'loss': 3.167668991565704, 'learning_rate': 3.492652042674863e-05, 'epoch': 0.9044087743950826, 'step': 5021500}
INFO:transformers.trainer:{'loss': 3.115677853345871, 'learning_rate': 3.492501953263598e-05, 'epoch': 0.9044988280418411, 'step': 5022000}
INFO:transformers.trainer:{'loss': 3.191905139684677, 'learning_rate': 3.492351863852335e-05, 'epoch': 0.9045888816885995, 'step': 5022500}
INFO:transformers.trainer:{'loss': 3.1805686299800873, 'learning_rate': 3.49220177444107e-05, 'epoch': 0.9046789353353579, 'step': 5023000}
INFO:transformers.trainer:{'loss': 3.1381281485557557, 'learning_rate': 3.4920516850298065e-05, 'epoch': 0.9047689889821164, 'step': 5023500}
INFO:transformers.trainer:{'loss': 3.1636329156160357, 'learning_rate': 3.491901595618542e-05, 'epoch': 0.9048590426288748, 'step': 5024000}
INFO:transformers.trainer:{'loss': 3.0994913377165796, 'learning_rate': 3.4917515062072783e-05, 'epoch': 0.9049490962756334, 'step': 5024500}
INFO:transformers.trainer:{'loss': 3.1507488865852356, 'learning_rate': 3.4916014167960136e-05, 'epoch': 0.9050391499223918, 'step': 5025000}
INFO:transformers.trainer:{'loss': 3.1344126300811768, 'learning_rate': 3.49145132738475e-05, 'epoch': 0.9051292035691502, 'step': 5025500}
INFO:transformers.trainer:{'loss': 3.1514789271354675, 'learning_rate': 3.4913012379734854e-05, 'epoch': 0.9052192572159087, 'step': 5026000}
INFO:transformers.trainer:{'loss': 3.169679535984993, 'learning_rate': 3.491151148562222e-05, 'epoch': 0.9053093108626671, 'step': 5026500}
INFO:transformers.trainer:{'loss': 3.159517659187317, 'learning_rate': 3.491001059150957e-05, 'epoch': 0.9053993645094256, 'step': 5027000}
INFO:transformers.trainer:{'loss': 3.171152549743652, 'learning_rate': 3.490850969739694e-05, 'epoch': 0.905489418156184, 'step': 5027500}
INFO:transformers.trainer:{'loss': 3.140473459482193, 'learning_rate': 3.49070088032843e-05, 'epoch': 0.9055794718029424, 'step': 5028000}
INFO:transformers.trainer:{'loss': 3.129471920490265, 'learning_rate': 3.4905507909171656e-05, 'epoch': 0.9056695254497009, 'step': 5028500}
INFO:transformers.trainer:{'loss': 3.2127605414390565, 'learning_rate': 3.4904007015059015e-05, 'epoch': 0.9057595790964593, 'step': 5029000}
INFO:transformers.trainer:{'loss': 3.162879504442215, 'learning_rate': 3.4902506120946374e-05, 'epoch': 0.9058496327432178, 'step': 5029500}
INFO:transformers.trainer:{'loss': 3.1279960792064667, 'learning_rate': 3.490100522683373e-05, 'epoch': 0.9059396863899762, 'step': 5030000}
INFO:transformers.trainer:{'loss': 3.0657696647644044, 'learning_rate': 3.489950433272109e-05, 'epoch': 0.9060297400367346, 'step': 5030500}
INFO:transformers.trainer:{'loss': 3.150932502746582, 'learning_rate': 3.489800343860845e-05, 'epoch': 0.9061197936834932, 'step': 5031000}
INFO:transformers.trainer:{'loss': 3.182519613146782, 'learning_rate': 3.489650254449581e-05, 'epoch': 0.9062098473302516, 'step': 5031500}
INFO:transformers.trainer:{'loss': 3.159289737701416, 'learning_rate': 3.489500165038317e-05, 'epoch': 0.9062999009770101, 'step': 5032000}
INFO:transformers.trainer:{'loss': 3.1365556782484054, 'learning_rate': 3.489350075627053e-05, 'epoch': 0.9063899546237685, 'step': 5032500}
INFO:transformers.trainer:{'loss': 3.1376734364032743, 'learning_rate': 3.489199986215789e-05, 'epoch': 0.9064800082705269, 'step': 5033000}
INFO:transformers.trainer:{'loss': 3.1163294731378555, 'learning_rate': 3.4890498968045246e-05, 'epoch': 0.9065700619172854, 'step': 5033500}
INFO:transformers.trainer:{'loss': 3.164938309431076, 'learning_rate': 3.4888998073932605e-05, 'epoch': 0.9066601155640438, 'step': 5034000}
INFO:transformers.trainer:{'loss': 3.181458959817886, 'learning_rate': 3.4887497179819964e-05, 'epoch': 0.9067501692108022, 'step': 5034500}
INFO:transformers.trainer:{'loss': 3.089017845392227, 'learning_rate': 3.4885996285707324e-05, 'epoch': 0.9068402228575607, 'step': 5035000}
INFO:transformers.trainer:{'loss': 3.1491188471317293, 'learning_rate': 3.488449539159468e-05, 'epoch': 0.9069302765043191, 'step': 5035500}
INFO:transformers.trainer:{'loss': 3.145681635260582, 'learning_rate': 3.488299449748204e-05, 'epoch': 0.9070203301510776, 'step': 5036000}
INFO:transformers.trainer:{'loss': 3.185929702758789, 'learning_rate': 3.48814936033694e-05, 'epoch': 0.907110383797836, 'step': 5036500}
INFO:transformers.trainer:{'loss': 3.1095236485004425, 'learning_rate': 3.487999270925676e-05, 'epoch': 0.9072004374445944, 'step': 5037000}
INFO:transformers.trainer:{'loss': 3.1331664333343507, 'learning_rate': 3.487849181514412e-05, 'epoch': 0.907290491091353, 'step': 5037500}
INFO:transformers.trainer:{'loss': 3.110743961572647, 'learning_rate': 3.487699092103148e-05, 'epoch': 0.9073805447381114, 'step': 5038000}
INFO:transformers.trainer:{'loss': 3.170133337020874, 'learning_rate': 3.487549002691884e-05, 'epoch': 0.9074705983848699, 'step': 5038500}
INFO:transformers.trainer:{'loss': 3.111087029695511, 'learning_rate': 3.4873989132806196e-05, 'epoch': 0.9075606520316283, 'step': 5039000}
INFO:transformers.trainer:{'loss': 3.1233833093643186, 'learning_rate': 3.4872488238693555e-05, 'epoch': 0.9076507056783867, 'step': 5039500}
INFO:transformers.trainer:{'loss': 3.1726414297819137, 'learning_rate': 3.4870987344580914e-05, 'epoch': 0.9077407593251452, 'step': 5040000}
INFO:transformers.trainer:{'loss': 3.266965612888336, 'learning_rate': 3.486948645046827e-05, 'epoch': 0.9078308129719036, 'step': 5040500}
INFO:transformers.trainer:{'loss': 3.1508110806941985, 'learning_rate': 3.486798555635563e-05, 'epoch': 0.9079208666186621, 'step': 5041000}
INFO:transformers.trainer:{'loss': 3.14972158241272, 'learning_rate': 3.486648466224299e-05, 'epoch': 0.9080109202654205, 'step': 5041500}
INFO:transformers.trainer:{'loss': 3.168522418498993, 'learning_rate': 3.486498376813036e-05, 'epoch': 0.9081009739121789, 'step': 5042000}
INFO:transformers.trainer:{'loss': 3.188974595308304, 'learning_rate': 3.486348287401771e-05, 'epoch': 0.9081910275589374, 'step': 5042500}
INFO:transformers.trainer:{'loss': 3.200231441259384, 'learning_rate': 3.4861981979905075e-05, 'epoch': 0.9082810812056958, 'step': 5043000}
INFO:transformers.trainer:{'loss': 3.1349094393253325, 'learning_rate': 3.486048108579243e-05, 'epoch': 0.9083711348524544, 'step': 5043500}
INFO:transformers.trainer:{'loss': 3.1270343821048736, 'learning_rate': 3.485898019167979e-05, 'epoch': 0.9084611884992128, 'step': 5044000}
INFO:transformers.trainer:{'loss': 3.1509753346443174, 'learning_rate': 3.4857479297567145e-05, 'epoch': 0.9085512421459712, 'step': 5044500}
INFO:transformers.trainer:{'loss': 3.1471720712184905, 'learning_rate': 3.485597840345451e-05, 'epoch': 0.9086412957927297, 'step': 5045000}
INFO:transformers.trainer:{'loss': 3.2248881657123567, 'learning_rate': 3.4854477509341864e-05, 'epoch': 0.9087313494394881, 'step': 5045500}
INFO:transformers.trainer:{'loss': 3.1774492888450623, 'learning_rate': 3.485297661522923e-05, 'epoch': 0.9088214030862466, 'step': 5046000}
INFO:transformers.trainer:{'loss': 3.0995751299858094, 'learning_rate': 3.485147572111658e-05, 'epoch': 0.908911456733005, 'step': 5046500}
INFO:transformers.trainer:{'loss': 3.1753100438117983, 'learning_rate': 3.484997482700395e-05, 'epoch': 0.9090015103797634, 'step': 5047000}
INFO:transformers.trainer:{'loss': 3.154348392724991, 'learning_rate': 3.48484739328913e-05, 'epoch': 0.9090915640265219, 'step': 5047500}
INFO:transformers.trainer:{'loss': 3.1489146242141723, 'learning_rate': 3.4846973038778666e-05, 'epoch': 0.9091816176732803, 'step': 5048000}
INFO:transformers.trainer:{'loss': 3.145390983343124, 'learning_rate': 3.4845472144666025e-05, 'epoch': 0.9092716713200387, 'step': 5048500}
INFO:transformers.trainer:{'loss': 3.070988869071007, 'learning_rate': 3.4843971250553384e-05, 'epoch': 0.9093617249667972, 'step': 5049000}
INFO:transformers.trainer:{'loss': 3.1770843913555145, 'learning_rate': 3.484247035644074e-05, 'epoch': 0.9094517786135556, 'step': 5049500}
INFO:transformers.trainer:{'loss': 3.161205649137497, 'learning_rate': 3.48409694623281e-05, 'epoch': 0.9095418322603142, 'step': 5050000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5050000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5050000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5050000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-4950000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0947218790054323, 'learning_rate': 3.483946856821546e-05, 'epoch': 0.9096318859070726, 'step': 5050500}
INFO:transformers.trainer:{'loss': 3.1320574407577513, 'learning_rate': 3.483796767410282e-05, 'epoch': 0.909721939553831, 'step': 5051000}
INFO:transformers.trainer:{'loss': 3.1567247507572174, 'learning_rate': 3.483646677999018e-05, 'epoch': 0.9098119932005895, 'step': 5051500}
INFO:transformers.trainer:{'loss': 3.1512422852516173, 'learning_rate': 3.483496588587754e-05, 'epoch': 0.9099020468473479, 'step': 5052000}
INFO:transformers.trainer:{'loss': 3.168911953806877, 'learning_rate': 3.48334649917649e-05, 'epoch': 0.9099921004941064, 'step': 5052500}
INFO:transformers.trainer:{'loss': 3.199401213645935, 'learning_rate': 3.4831964097652256e-05, 'epoch': 0.9100821541408648, 'step': 5053000}
INFO:transformers.trainer:{'loss': 3.116349821090698, 'learning_rate': 3.4830463203539615e-05, 'epoch': 0.9101722077876232, 'step': 5053500}
INFO:transformers.trainer:{'loss': 3.176075929403305, 'learning_rate': 3.4828962309426974e-05, 'epoch': 0.9102622614343817, 'step': 5054000}
INFO:transformers.trainer:{'loss': 3.164444068193436, 'learning_rate': 3.482746141531433e-05, 'epoch': 0.9103523150811401, 'step': 5054500}
INFO:transformers.trainer:{'loss': 3.1393116896152495, 'learning_rate': 3.482596052120169e-05, 'epoch': 0.9104423687278986, 'step': 5055000}
INFO:transformers.trainer:{'loss': 3.155467987060547, 'learning_rate': 3.482445962708905e-05, 'epoch': 0.910532422374657, 'step': 5055500}
INFO:transformers.trainer:{'loss': 3.1153946077823638, 'learning_rate': 3.482295873297641e-05, 'epoch': 0.9106224760214154, 'step': 5056000}
INFO:transformers.trainer:{'loss': 3.1109731912612917, 'learning_rate': 3.482145783886377e-05, 'epoch': 0.910712529668174, 'step': 5056500}
INFO:transformers.trainer:{'loss': 3.1630576362609863, 'learning_rate': 3.481995694475113e-05, 'epoch': 0.9108025833149324, 'step': 5057000}
INFO:transformers.trainer:{'loss': 3.117420957326889, 'learning_rate': 3.481845605063849e-05, 'epoch': 0.9108926369616909, 'step': 5057500}
INFO:transformers.trainer:{'loss': 3.066861306667328, 'learning_rate': 3.4816955156525847e-05, 'epoch': 0.9109826906084493, 'step': 5058000}
INFO:transformers.trainer:{'loss': 3.1434606368541718, 'learning_rate': 3.4815454262413206e-05, 'epoch': 0.9110727442552077, 'step': 5058500}
INFO:transformers.trainer:{'loss': 3.1620859981775284, 'learning_rate': 3.4813953368300565e-05, 'epoch': 0.9111627979019662, 'step': 5059000}
INFO:transformers.trainer:{'loss': 3.1937432750463484, 'learning_rate': 3.4812452474187924e-05, 'epoch': 0.9112528515487246, 'step': 5059500}
INFO:transformers.trainer:{'loss': 3.140149239063263, 'learning_rate': 3.481095158007528e-05, 'epoch': 0.911342905195483, 'step': 5060000}
INFO:transformers.trainer:{'loss': 3.131391257405281, 'learning_rate': 3.480945068596264e-05, 'epoch': 0.9114329588422415, 'step': 5060500}
INFO:transformers.trainer:{'loss': 3.102666256904602, 'learning_rate': 3.480794979185e-05, 'epoch': 0.9115230124889999, 'step': 5061000}
INFO:transformers.trainer:{'loss': 3.1214092888832092, 'learning_rate': 3.480644889773736e-05, 'epoch': 0.9116130661357584, 'step': 5061500}
INFO:transformers.trainer:{'loss': 3.148646980047226, 'learning_rate': 3.480494800362472e-05, 'epoch': 0.9117031197825168, 'step': 5062000}
INFO:transformers.trainer:{'loss': 3.1780879955291748, 'learning_rate': 3.4803447109512085e-05, 'epoch': 0.9117931734292752, 'step': 5062500}
INFO:transformers.trainer:{'loss': 3.091423775076866, 'learning_rate': 3.480194621539944e-05, 'epoch': 0.9118832270760338, 'step': 5063000}
INFO:transformers.trainer:{'loss': 3.1465307796001434, 'learning_rate': 3.48004453212868e-05, 'epoch': 0.9119732807227922, 'step': 5063500}
INFO:transformers.trainer:{'loss': 3.1716151247024538, 'learning_rate': 3.4798944427174155e-05, 'epoch': 0.9120633343695507, 'step': 5064000}
INFO:transformers.trainer:{'loss': 3.1341544954776763, 'learning_rate': 3.479744353306152e-05, 'epoch': 0.9121533880163091, 'step': 5064500}
INFO:transformers.trainer:{'loss': 3.146019146442413, 'learning_rate': 3.479594263894887e-05, 'epoch': 0.9122434416630675, 'step': 5065000}
INFO:transformers.trainer:{'loss': 3.0717500622272493, 'learning_rate': 3.479444174483624e-05, 'epoch': 0.912333495309826, 'step': 5065500}
INFO:transformers.trainer:{'loss': 3.100457818031311, 'learning_rate': 3.479294085072359e-05, 'epoch': 0.9124235489565844, 'step': 5066000}
INFO:transformers.trainer:{'loss': 3.1337926704883574, 'learning_rate': 3.479143995661096e-05, 'epoch': 0.9125136026033429, 'step': 5066500}
INFO:transformers.trainer:{'loss': 3.21192777967453, 'learning_rate': 3.478993906249831e-05, 'epoch': 0.9126036562501013, 'step': 5067000}
INFO:transformers.trainer:{'loss': 3.1574061102867126, 'learning_rate': 3.4788438168385675e-05, 'epoch': 0.9126937098968597, 'step': 5067500}
INFO:transformers.trainer:{'loss': 3.1452342131137847, 'learning_rate': 3.478693727427303e-05, 'epoch': 0.9127837635436182, 'step': 5068000}
INFO:transformers.trainer:{'loss': 3.0969583953619004, 'learning_rate': 3.4785436380160393e-05, 'epoch': 0.9128738171903766, 'step': 5068500}
INFO:transformers.trainer:{'loss': 3.173157725095749, 'learning_rate': 3.4783935486047746e-05, 'epoch': 0.9129638708371351, 'step': 5069000}
INFO:transformers.trainer:{'loss': 3.1029213495254515, 'learning_rate': 3.478243459193511e-05, 'epoch': 0.9130539244838936, 'step': 5069500}
INFO:transformers.trainer:{'loss': 3.1693426823616027, 'learning_rate': 3.478093369782247e-05, 'epoch': 0.913143978130652, 'step': 5070000}
INFO:transformers.trainer:{'loss': 3.133227548122406, 'learning_rate': 3.477943280370983e-05, 'epoch': 0.9132340317774105, 'step': 5070500}
INFO:transformers.trainer:{'loss': 3.1633798674345015, 'learning_rate': 3.477793190959719e-05, 'epoch': 0.9133240854241689, 'step': 5071000}
INFO:transformers.trainer:{'loss': 3.122585837602615, 'learning_rate': 3.477643101548455e-05, 'epoch': 0.9134141390709273, 'step': 5071500}
INFO:transformers.trainer:{'loss': 3.110799369096756, 'learning_rate': 3.477493012137191e-05, 'epoch': 0.9135041927176858, 'step': 5072000}
INFO:transformers.trainer:{'loss': 3.0623064830303193, 'learning_rate': 3.4773429227259266e-05, 'epoch': 0.9135942463644442, 'step': 5072500}
INFO:transformers.trainer:{'loss': 3.1175148923397065, 'learning_rate': 3.4771928333146625e-05, 'epoch': 0.9136843000112027, 'step': 5073000}
INFO:transformers.trainer:{'loss': 3.0930335030555725, 'learning_rate': 3.4770427439033984e-05, 'epoch': 0.9137743536579611, 'step': 5073500}
INFO:transformers.trainer:{'loss': 3.166264587879181, 'learning_rate': 3.476892654492134e-05, 'epoch': 0.9138644073047195, 'step': 5074000}
INFO:transformers.trainer:{'loss': 3.1353889741897585, 'learning_rate': 3.47674256508087e-05, 'epoch': 0.913954460951478, 'step': 5074500}
INFO:transformers.trainer:{'loss': 3.1406780664920806, 'learning_rate': 3.476592475669606e-05, 'epoch': 0.9140445145982364, 'step': 5075000}
INFO:transformers.trainer:{'loss': 3.09478709924221, 'learning_rate': 3.476442386258342e-05, 'epoch': 0.914134568244995, 'step': 5075500}
INFO:transformers.trainer:{'loss': 3.104738939523697, 'learning_rate': 3.476292296847078e-05, 'epoch': 0.9142246218917534, 'step': 5076000}
INFO:transformers.trainer:{'loss': 3.12608227622509, 'learning_rate': 3.476142207435814e-05, 'epoch': 0.9143146755385118, 'step': 5076500}
INFO:transformers.trainer:{'loss': 3.1784783288240432, 'learning_rate': 3.47599211802455e-05, 'epoch': 0.9144047291852703, 'step': 5077000}
INFO:transformers.trainer:{'loss': 3.093654076576233, 'learning_rate': 3.4758420286132856e-05, 'epoch': 0.9144947828320287, 'step': 5077500}
INFO:transformers.trainer:{'loss': 3.12862212228775, 'learning_rate': 3.4756919392020215e-05, 'epoch': 0.9145848364787872, 'step': 5078000}
INFO:transformers.trainer:{'loss': 3.147402611732483, 'learning_rate': 3.4755418497907574e-05, 'epoch': 0.9146748901255456, 'step': 5078500}
INFO:transformers.trainer:{'loss': 3.107677657365799, 'learning_rate': 3.4753917603794933e-05, 'epoch': 0.914764943772304, 'step': 5079000}
INFO:transformers.trainer:{'loss': 3.125130991220474, 'learning_rate': 3.475241670968229e-05, 'epoch': 0.9148549974190625, 'step': 5079500}
INFO:transformers.trainer:{'loss': 3.165521936416626, 'learning_rate': 3.475091581556965e-05, 'epoch': 0.9149450510658209, 'step': 5080000}
INFO:transformers.trainer:{'loss': 3.120527868747711, 'learning_rate': 3.474941492145701e-05, 'epoch': 0.9150351047125794, 'step': 5080500}
INFO:transformers.trainer:{'loss': 3.1191832100152967, 'learning_rate': 3.474791402734437e-05, 'epoch': 0.9151251583593378, 'step': 5081000}
INFO:transformers.trainer:{'loss': 3.1747343215942383, 'learning_rate': 3.474641313323173e-05, 'epoch': 0.9152152120060962, 'step': 5081500}
INFO:transformers.trainer:{'loss': 3.150667655944824, 'learning_rate': 3.474491223911909e-05, 'epoch': 0.9153052656528547, 'step': 5082000}
INFO:transformers.trainer:{'loss': 3.142053598165512, 'learning_rate': 3.474341134500645e-05, 'epoch': 0.9153953192996132, 'step': 5082500}
INFO:transformers.trainer:{'loss': 3.1642330632209776, 'learning_rate': 3.4741910450893806e-05, 'epoch': 0.9154853729463717, 'step': 5083000}
INFO:transformers.trainer:{'loss': 3.172382211446762, 'learning_rate': 3.4740409556781165e-05, 'epoch': 0.9155754265931301, 'step': 5083500}
INFO:transformers.trainer:{'loss': 3.146508425116539, 'learning_rate': 3.473890866266853e-05, 'epoch': 0.9156654802398885, 'step': 5084000}
INFO:transformers.trainer:{'loss': 3.113829741239548, 'learning_rate': 3.473740776855588e-05, 'epoch': 0.915755533886647, 'step': 5084500}
INFO:transformers.trainer:{'loss': 3.131166755735874, 'learning_rate': 3.473590687444325e-05, 'epoch': 0.9158455875334054, 'step': 5085000}
INFO:transformers.trainer:{'loss': 3.135087794542313, 'learning_rate': 3.47344059803306e-05, 'epoch': 0.9159356411801638, 'step': 5085500}
INFO:transformers.trainer:{'loss': 3.113008536338806, 'learning_rate': 3.473290508621797e-05, 'epoch': 0.9160256948269223, 'step': 5086000}
INFO:transformers.trainer:{'loss': 3.069319307565689, 'learning_rate': 3.473140419210532e-05, 'epoch': 0.9161157484736807, 'step': 5086500}
INFO:transformers.trainer:{'loss': 3.1495160336494448, 'learning_rate': 3.4729903297992685e-05, 'epoch': 0.9162058021204392, 'step': 5087000}
INFO:transformers.trainer:{'loss': 3.1976098620891573, 'learning_rate': 3.472840240388004e-05, 'epoch': 0.9162958557671976, 'step': 5087500}
INFO:transformers.trainer:{'loss': 3.169183692932129, 'learning_rate': 3.47269015097674e-05, 'epoch': 0.916385909413956, 'step': 5088000}
INFO:transformers.trainer:{'loss': 3.1278824714422226, 'learning_rate': 3.4725400615654755e-05, 'epoch': 0.9164759630607145, 'step': 5088500}
INFO:transformers.trainer:{'loss': 3.1816733379364015, 'learning_rate': 3.472389972154212e-05, 'epoch': 0.916566016707473, 'step': 5089000}
INFO:transformers.trainer:{'loss': 3.1496357553005216, 'learning_rate': 3.4722398827429474e-05, 'epoch': 0.9166560703542315, 'step': 5089500}
INFO:transformers.trainer:{'loss': 3.148451558113098, 'learning_rate': 3.472089793331684e-05, 'epoch': 0.9167461240009899, 'step': 5090000}
INFO:transformers.trainer:{'loss': 3.149035977602005, 'learning_rate': 3.47193970392042e-05, 'epoch': 0.9168361776477483, 'step': 5090500}
INFO:transformers.trainer:{'loss': 3.1803038420677185, 'learning_rate': 3.471789614509156e-05, 'epoch': 0.9169262312945068, 'step': 5091000}
INFO:transformers.trainer:{'loss': 3.0985852102041243, 'learning_rate': 3.4716395250978917e-05, 'epoch': 0.9170162849412652, 'step': 5091500}
INFO:transformers.trainer:{'loss': 3.22205708026886, 'learning_rate': 3.4714894356866276e-05, 'epoch': 0.9171063385880237, 'step': 5092000}
INFO:transformers.trainer:{'loss': 3.163378062725067, 'learning_rate': 3.4713393462753635e-05, 'epoch': 0.9171963922347821, 'step': 5092500}
INFO:transformers.trainer:{'loss': 3.175973084449768, 'learning_rate': 3.4711892568640994e-05, 'epoch': 0.9172864458815405, 'step': 5093000}
INFO:transformers.trainer:{'loss': 3.0997196264266966, 'learning_rate': 3.471039167452835e-05, 'epoch': 0.917376499528299, 'step': 5093500}
INFO:transformers.trainer:{'loss': 3.2253376928567885, 'learning_rate': 3.470889078041571e-05, 'epoch': 0.9174665531750574, 'step': 5094000}
INFO:transformers.trainer:{'loss': 3.1612535774707795, 'learning_rate': 3.470738988630307e-05, 'epoch': 0.917556606821816, 'step': 5094500}
INFO:transformers.trainer:{'loss': 3.1829991326332094, 'learning_rate': 3.470588899219043e-05, 'epoch': 0.9176466604685743, 'step': 5095000}
INFO:transformers.trainer:{'loss': 3.1599293887615203, 'learning_rate': 3.470438809807779e-05, 'epoch': 0.9177367141153328, 'step': 5095500}
INFO:transformers.trainer:{'loss': 3.1514761687517168, 'learning_rate': 3.470288720396515e-05, 'epoch': 0.9178267677620913, 'step': 5096000}
INFO:transformers.trainer:{'loss': 3.2053372616767883, 'learning_rate': 3.470138630985251e-05, 'epoch': 0.9179168214088497, 'step': 5096500}
INFO:transformers.trainer:{'loss': 3.1779636229276655, 'learning_rate': 3.4699885415739866e-05, 'epoch': 0.9180068750556081, 'step': 5097000}
INFO:transformers.trainer:{'loss': 3.2235065534114837, 'learning_rate': 3.4698384521627225e-05, 'epoch': 0.9180969287023666, 'step': 5097500}
INFO:transformers.trainer:{'loss': 3.176464322805405, 'learning_rate': 3.4696883627514584e-05, 'epoch': 0.918186982349125, 'step': 5098000}
INFO:transformers.trainer:{'loss': 3.1685085670948028, 'learning_rate': 3.469538273340194e-05, 'epoch': 0.9182770359958835, 'step': 5098500}
INFO:transformers.trainer:{'loss': 3.1255973851680756, 'learning_rate': 3.46938818392893e-05, 'epoch': 0.9183670896426419, 'step': 5099000}
INFO:transformers.trainer:{'loss': 3.1548087491989136, 'learning_rate': 3.469238094517666e-05, 'epoch': 0.9184571432894003, 'step': 5099500}
INFO:transformers.trainer:{'loss': 3.1134840173721314, 'learning_rate': 3.469088005106402e-05, 'epoch': 0.9185471969361588, 'step': 5100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5100000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5000000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1828822009563447, 'learning_rate': 3.468937915695138e-05, 'epoch': 0.9186372505829172, 'step': 5100500}
INFO:transformers.trainer:{'loss': 3.2476067721843718, 'learning_rate': 3.468787826283874e-05, 'epoch': 0.9187273042296757, 'step': 5101000}
INFO:transformers.trainer:{'loss': 3.193744820356369, 'learning_rate': 3.46863773687261e-05, 'epoch': 0.9188173578764341, 'step': 5101500}
INFO:transformers.trainer:{'loss': 3.1829607899188996, 'learning_rate': 3.4684876474613457e-05, 'epoch': 0.9189074115231926, 'step': 5102000}
INFO:transformers.trainer:{'loss': 3.2251427742242815, 'learning_rate': 3.4683375580500816e-05, 'epoch': 0.9189974651699511, 'step': 5102500}
INFO:transformers.trainer:{'loss': 3.167315017461777, 'learning_rate': 3.4681874686388175e-05, 'epoch': 0.9190875188167095, 'step': 5103000}
INFO:transformers.trainer:{'loss': 3.2400823538303376, 'learning_rate': 3.4680373792275534e-05, 'epoch': 0.919177572463468, 'step': 5103500}
INFO:transformers.trainer:{'loss': 3.1890703897476196, 'learning_rate': 3.467887289816289e-05, 'epoch': 0.9192676261102264, 'step': 5104000}
INFO:transformers.trainer:{'loss': 3.165410171508789, 'learning_rate': 3.467737200405026e-05, 'epoch': 0.9193576797569848, 'step': 5104500}
INFO:transformers.trainer:{'loss': 3.1254094290733336, 'learning_rate': 3.467587110993761e-05, 'epoch': 0.9194477334037433, 'step': 5105000}
INFO:transformers.trainer:{'loss': 3.0876453810930253, 'learning_rate': 3.467437021582498e-05, 'epoch': 0.9195377870505017, 'step': 5105500}
INFO:transformers.trainer:{'loss': 3.1311333923339846, 'learning_rate': 3.467286932171233e-05, 'epoch': 0.9196278406972602, 'step': 5106000}
INFO:transformers.trainer:{'loss': 3.1529696567058565, 'learning_rate': 3.4671368427599695e-05, 'epoch': 0.9197178943440186, 'step': 5106500}
INFO:transformers.trainer:{'loss': 3.162899714231491, 'learning_rate': 3.466986753348705e-05, 'epoch': 0.919807947990777, 'step': 5107000}
INFO:transformers.trainer:{'loss': 3.179276933670044, 'learning_rate': 3.466836663937441e-05, 'epoch': 0.9198980016375355, 'step': 5107500}
INFO:transformers.trainer:{'loss': 3.1951929059028625, 'learning_rate': 3.4666865745261765e-05, 'epoch': 0.919988055284294, 'step': 5108000}
INFO:transformers.trainer:{'loss': 3.176112982749939, 'learning_rate': 3.466536485114913e-05, 'epoch': 0.9200781089310524, 'step': 5108500}
INFO:transformers.trainer:{'loss': 3.102647402524948, 'learning_rate': 3.466386395703648e-05, 'epoch': 0.9201681625778109, 'step': 5109000}
INFO:transformers.trainer:{'loss': 3.156536409378052, 'learning_rate': 3.466236306292385e-05, 'epoch': 0.9202582162245693, 'step': 5109500}
INFO:transformers.trainer:{'loss': 3.116115446448326, 'learning_rate': 3.46608621688112e-05, 'epoch': 0.9203482698713278, 'step': 5110000}
INFO:transformers.trainer:{'loss': 3.18467037153244, 'learning_rate': 3.465936127469857e-05, 'epoch': 0.9204383235180862, 'step': 5110500}
INFO:transformers.trainer:{'loss': 3.1568020324707033, 'learning_rate': 3.4657860380585926e-05, 'epoch': 0.9205283771648446, 'step': 5111000}
INFO:transformers.trainer:{'loss': 3.216062576532364, 'learning_rate': 3.4656359486473285e-05, 'epoch': 0.9206184308116031, 'step': 5111500}
INFO:transformers.trainer:{'loss': 3.1338434417247774, 'learning_rate': 3.4654858592360644e-05, 'epoch': 0.9207084844583615, 'step': 5112000}
INFO:transformers.trainer:{'loss': 3.155906039714813, 'learning_rate': 3.4653357698248003e-05, 'epoch': 0.92079853810512, 'step': 5112500}
INFO:transformers.trainer:{'loss': 3.152351540803909, 'learning_rate': 3.465185680413536e-05, 'epoch': 0.9208885917518784, 'step': 5113000}
INFO:transformers.trainer:{'loss': 3.159823067545891, 'learning_rate': 3.465035591002272e-05, 'epoch': 0.9209786453986368, 'step': 5113500}
INFO:transformers.trainer:{'loss': 3.080837800741196, 'learning_rate': 3.464885501591008e-05, 'epoch': 0.9210686990453953, 'step': 5114000}
INFO:transformers.trainer:{'loss': 3.0802057588100435, 'learning_rate': 3.464735412179744e-05, 'epoch': 0.9211587526921537, 'step': 5114500}
INFO:transformers.trainer:{'loss': 3.2232304842472077, 'learning_rate': 3.46458532276848e-05, 'epoch': 0.9212488063389123, 'step': 5115000}
INFO:transformers.trainer:{'loss': 3.0777634897232056, 'learning_rate': 3.464435233357216e-05, 'epoch': 0.9213388599856707, 'step': 5115500}
INFO:transformers.trainer:{'loss': 3.1244113891124727, 'learning_rate': 3.464285143945952e-05, 'epoch': 0.9214289136324291, 'step': 5116000}
INFO:transformers.trainer:{'loss': 3.09589624106884, 'learning_rate': 3.4641350545346876e-05, 'epoch': 0.9215189672791876, 'step': 5116500}
INFO:transformers.trainer:{'loss': 3.109727937102318, 'learning_rate': 3.4639849651234235e-05, 'epoch': 0.921609020925946, 'step': 5117000}
INFO:transformers.trainer:{'loss': 3.1133018696308135, 'learning_rate': 3.4638348757121594e-05, 'epoch': 0.9216990745727045, 'step': 5117500}
INFO:transformers.trainer:{'loss': 3.105387316942215, 'learning_rate': 3.463684786300895e-05, 'epoch': 0.9217891282194629, 'step': 5118000}
INFO:transformers.trainer:{'loss': 3.1087618434429167, 'learning_rate': 3.463534696889631e-05, 'epoch': 0.9218791818662213, 'step': 5118500}
INFO:transformers.trainer:{'loss': 3.200933445215225, 'learning_rate': 3.463384607478367e-05, 'epoch': 0.9219692355129798, 'step': 5119000}
INFO:transformers.trainer:{'loss': 3.1386072602272033, 'learning_rate': 3.463234518067103e-05, 'epoch': 0.9220592891597382, 'step': 5119500}
INFO:transformers.trainer:{'loss': 3.1322010157108306, 'learning_rate': 3.463084428655839e-05, 'epoch': 0.9221493428064967, 'step': 5120000}
INFO:transformers.trainer:{'loss': 3.147277592897415, 'learning_rate': 3.462934339244575e-05, 'epoch': 0.9222393964532551, 'step': 5120500}
INFO:transformers.trainer:{'loss': 3.1949180629253386, 'learning_rate': 3.462784249833311e-05, 'epoch': 0.9223294501000135, 'step': 5121000}
INFO:transformers.trainer:{'loss': 3.075120489835739, 'learning_rate': 3.4626341604220466e-05, 'epoch': 0.9224195037467721, 'step': 5121500}
INFO:transformers.trainer:{'loss': 3.1617492026090623, 'learning_rate': 3.4624840710107825e-05, 'epoch': 0.9225095573935305, 'step': 5122000}
INFO:transformers.trainer:{'loss': 3.1528279128074645, 'learning_rate': 3.4623339815995184e-05, 'epoch': 0.9225996110402889, 'step': 5122500}
INFO:transformers.trainer:{'loss': 3.1192804465293884, 'learning_rate': 3.4621838921882543e-05, 'epoch': 0.9226896646870474, 'step': 5123000}
INFO:transformers.trainer:{'loss': 3.1211219255924223, 'learning_rate': 3.46203380277699e-05, 'epoch': 0.9227797183338058, 'step': 5123500}
INFO:transformers.trainer:{'loss': 3.1386162827014923, 'learning_rate': 3.461883713365726e-05, 'epoch': 0.9228697719805643, 'step': 5124000}
INFO:transformers.trainer:{'loss': 3.1437407755851745, 'learning_rate': 3.461733623954462e-05, 'epoch': 0.9229598256273227, 'step': 5124500}
INFO:transformers.trainer:{'loss': 3.134058074235916, 'learning_rate': 3.4615835345431986e-05, 'epoch': 0.9230498792740811, 'step': 5125000}
INFO:transformers.trainer:{'loss': 3.143092108249664, 'learning_rate': 3.461433445131934e-05, 'epoch': 0.9231399329208396, 'step': 5125500}
INFO:transformers.trainer:{'loss': 3.141383176088333, 'learning_rate': 3.4612833557206705e-05, 'epoch': 0.923229986567598, 'step': 5126000}
INFO:transformers.trainer:{'loss': 3.195012601733208, 'learning_rate': 3.461133266309406e-05, 'epoch': 0.9233200402143565, 'step': 5126500}
INFO:transformers.trainer:{'loss': 3.1690448248386383, 'learning_rate': 3.460983176898142e-05, 'epoch': 0.923410093861115, 'step': 5127000}
INFO:transformers.trainer:{'loss': 3.1563224712610243, 'learning_rate': 3.4608330874868775e-05, 'epoch': 0.9235001475078733, 'step': 5127500}
INFO:transformers.trainer:{'loss': 3.119021424293518, 'learning_rate': 3.460682998075614e-05, 'epoch': 0.9235902011546319, 'step': 5128000}
INFO:transformers.trainer:{'loss': 3.137983897447586, 'learning_rate': 3.460532908664349e-05, 'epoch': 0.9236802548013903, 'step': 5128500}
INFO:transformers.trainer:{'loss': 3.1376604659557343, 'learning_rate': 3.460382819253086e-05, 'epoch': 0.9237703084481488, 'step': 5129000}
INFO:transformers.trainer:{'loss': 3.1509014707803726, 'learning_rate': 3.460232729841821e-05, 'epoch': 0.9238603620949072, 'step': 5129500}
INFO:transformers.trainer:{'loss': 3.134374483346939, 'learning_rate': 3.460082640430558e-05, 'epoch': 0.9239504157416656, 'step': 5130000}
INFO:transformers.trainer:{'loss': 3.149776996135712, 'learning_rate': 3.459932551019293e-05, 'epoch': 0.9240404693884241, 'step': 5130500}
INFO:transformers.trainer:{'loss': 3.137264696121216, 'learning_rate': 3.4597824616080295e-05, 'epoch': 0.9241305230351825, 'step': 5131000}
INFO:transformers.trainer:{'loss': 3.1045917418003084, 'learning_rate': 3.459632372196765e-05, 'epoch': 0.924220576681941, 'step': 5131500}
INFO:transformers.trainer:{'loss': 3.124485095739365, 'learning_rate': 3.459482282785501e-05, 'epoch': 0.9243106303286994, 'step': 5132000}
INFO:transformers.trainer:{'loss': 3.091859464287758, 'learning_rate': 3.459332193374237e-05, 'epoch': 0.9244006839754578, 'step': 5132500}
INFO:transformers.trainer:{'loss': 3.0980176577568055, 'learning_rate': 3.459182103962973e-05, 'epoch': 0.9244907376222163, 'step': 5133000}
INFO:transformers.trainer:{'loss': 3.1886478319168092, 'learning_rate': 3.459032014551709e-05, 'epoch': 0.9245807912689747, 'step': 5133500}
INFO:transformers.trainer:{'loss': 3.020324731349945, 'learning_rate': 3.458881925140445e-05, 'epoch': 0.9246708449157331, 'step': 5134000}
INFO:transformers.trainer:{'loss': 3.138341587305069, 'learning_rate': 3.458731835729181e-05, 'epoch': 0.9247608985624917, 'step': 5134500}
INFO:transformers.trainer:{'loss': 3.123733979701996, 'learning_rate': 3.458581746317917e-05, 'epoch': 0.9248509522092501, 'step': 5135000}
INFO:transformers.trainer:{'loss': 3.108605993747711, 'learning_rate': 3.4584316569066526e-05, 'epoch': 0.9249410058560086, 'step': 5135500}
INFO:transformers.trainer:{'loss': 3.1504275362491607, 'learning_rate': 3.4582815674953886e-05, 'epoch': 0.925031059502767, 'step': 5136000}
INFO:transformers.trainer:{'loss': 3.1016884937286378, 'learning_rate': 3.4581314780841245e-05, 'epoch': 0.9251211131495254, 'step': 5136500}
INFO:transformers.trainer:{'loss': 3.141890318989754, 'learning_rate': 3.4579813886728604e-05, 'epoch': 0.9252111667962839, 'step': 5137000}
INFO:transformers.trainer:{'loss': 3.1399372382164, 'learning_rate': 3.457831299261596e-05, 'epoch': 0.9253012204430423, 'step': 5137500}
INFO:transformers.trainer:{'loss': 3.143608235001564, 'learning_rate': 3.457681209850332e-05, 'epoch': 0.9253912740898008, 'step': 5138000}
INFO:transformers.trainer:{'loss': 3.135926914215088, 'learning_rate': 3.457531120439068e-05, 'epoch': 0.9254813277365592, 'step': 5138500}
INFO:transformers.trainer:{'loss': 3.1666905584335328, 'learning_rate': 3.457381031027804e-05, 'epoch': 0.9255713813833176, 'step': 5139000}
INFO:transformers.trainer:{'loss': 3.1629999969005587, 'learning_rate': 3.45723094161654e-05, 'epoch': 0.9256614350300761, 'step': 5139500}
INFO:transformers.trainer:{'loss': 3.14296604013443, 'learning_rate': 3.457080852205276e-05, 'epoch': 0.9257514886768345, 'step': 5140000}
INFO:transformers.trainer:{'loss': 3.077445132255554, 'learning_rate': 3.456930762794012e-05, 'epoch': 0.9258415423235931, 'step': 5140500}
INFO:transformers.trainer:{'loss': 3.163807939529419, 'learning_rate': 3.4567806733827476e-05, 'epoch': 0.9259315959703515, 'step': 5141000}
INFO:transformers.trainer:{'loss': 3.1442933492660523, 'learning_rate': 3.4566305839714835e-05, 'epoch': 0.9260216496171099, 'step': 5141500}
INFO:transformers.trainer:{'loss': 3.137467115879059, 'learning_rate': 3.4564804945602194e-05, 'epoch': 0.9261117032638684, 'step': 5142000}
INFO:transformers.trainer:{'loss': 3.142065936565399, 'learning_rate': 3.456330405148955e-05, 'epoch': 0.9262017569106268, 'step': 5142500}
INFO:transformers.trainer:{'loss': 3.1389126055240633, 'learning_rate': 3.456180315737691e-05, 'epoch': 0.9262918105573853, 'step': 5143000}
INFO:transformers.trainer:{'loss': 3.142622205734253, 'learning_rate': 3.456030226326427e-05, 'epoch': 0.9263818642041437, 'step': 5143500}
INFO:transformers.trainer:{'loss': 3.1115434646606444, 'learning_rate': 3.455880136915163e-05, 'epoch': 0.9264719178509021, 'step': 5144000}
INFO:transformers.trainer:{'loss': 3.102474308013916, 'learning_rate': 3.455730047503899e-05, 'epoch': 0.9265619714976606, 'step': 5144500}
INFO:transformers.trainer:{'loss': 3.0943267440795896, 'learning_rate': 3.455579958092635e-05, 'epoch': 0.926652025144419, 'step': 5145000}
INFO:transformers.trainer:{'loss': 3.1939753468036653, 'learning_rate': 3.4554298686813714e-05, 'epoch': 0.9267420787911774, 'step': 5145500}
INFO:transformers.trainer:{'loss': 3.1356857657432555, 'learning_rate': 3.4552797792701067e-05, 'epoch': 0.9268321324379359, 'step': 5146000}
INFO:transformers.trainer:{'loss': 3.1526657005548477, 'learning_rate': 3.455129689858843e-05, 'epoch': 0.9269221860846943, 'step': 5146500}
INFO:transformers.trainer:{'loss': 3.1276566861867905, 'learning_rate': 3.4549796004475785e-05, 'epoch': 0.9270122397314529, 'step': 5147000}
INFO:transformers.trainer:{'loss': 3.108709604918957, 'learning_rate': 3.454829511036315e-05, 'epoch': 0.9271022933782113, 'step': 5147500}
INFO:transformers.trainer:{'loss': 3.1189484713077547, 'learning_rate': 3.45467942162505e-05, 'epoch': 0.9271923470249697, 'step': 5148000}
INFO:transformers.trainer:{'loss': 3.1387576899528504, 'learning_rate': 3.454529332213787e-05, 'epoch': 0.9272824006717282, 'step': 5148500}
INFO:transformers.trainer:{'loss': 3.0920127556324006, 'learning_rate': 3.454379242802522e-05, 'epoch': 0.9273724543184866, 'step': 5149000}
INFO:transformers.trainer:{'loss': 3.136194313287735, 'learning_rate': 3.454229153391259e-05, 'epoch': 0.9274625079652451, 'step': 5149500}
INFO:transformers.trainer:{'loss': 3.1163147439956664, 'learning_rate': 3.454079063979994e-05, 'epoch': 0.9275525616120035, 'step': 5150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5050000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.192492507696152, 'learning_rate': 3.4539289745687305e-05, 'epoch': 0.9276426152587619, 'step': 5150500}
INFO:transformers.trainer:{'loss': 3.134820530176163, 'learning_rate': 3.453778885157466e-05, 'epoch': 0.9277326689055204, 'step': 5151000}
INFO:transformers.trainer:{'loss': 3.092789862036705, 'learning_rate': 3.453628795746202e-05, 'epoch': 0.9278227225522788, 'step': 5151500}
INFO:transformers.trainer:{'loss': 3.16565313398838, 'learning_rate': 3.4534787063349375e-05, 'epoch': 0.9279127761990373, 'step': 5152000}
INFO:transformers.trainer:{'loss': 3.156294434785843, 'learning_rate': 3.453328616923674e-05, 'epoch': 0.9280028298457957, 'step': 5152500}
INFO:transformers.trainer:{'loss': 3.1403989458084105, 'learning_rate': 3.45317852751241e-05, 'epoch': 0.9280928834925541, 'step': 5153000}
INFO:transformers.trainer:{'loss': 3.083311406135559, 'learning_rate': 3.453028438101146e-05, 'epoch': 0.9281829371393127, 'step': 5153500}
INFO:transformers.trainer:{'loss': 3.1369196243286135, 'learning_rate': 3.452878348689882e-05, 'epoch': 0.9282729907860711, 'step': 5154000}
INFO:transformers.trainer:{'loss': 3.1272420781850814, 'learning_rate': 3.452728259278618e-05, 'epoch': 0.9283630444328296, 'step': 5154500}
INFO:transformers.trainer:{'loss': 3.1132074398994445, 'learning_rate': 3.4525781698673536e-05, 'epoch': 0.928453098079588, 'step': 5155000}
INFO:transformers.trainer:{'loss': 3.113113092660904, 'learning_rate': 3.4524280804560895e-05, 'epoch': 0.9285431517263464, 'step': 5155500}
INFO:transformers.trainer:{'loss': 3.1295254046916963, 'learning_rate': 3.4522779910448254e-05, 'epoch': 0.9286332053731049, 'step': 5156000}
INFO:transformers.trainer:{'loss': 3.2055952734947204, 'learning_rate': 3.452127901633561e-05, 'epoch': 0.9287232590198633, 'step': 5156500}
INFO:transformers.trainer:{'loss': 3.142351597547531, 'learning_rate': 3.451977812222297e-05, 'epoch': 0.9288133126666218, 'step': 5157000}
INFO:transformers.trainer:{'loss': 3.1395068564414976, 'learning_rate': 3.451827722811033e-05, 'epoch': 0.9289033663133802, 'step': 5157500}
INFO:transformers.trainer:{'loss': 3.094413533806801, 'learning_rate': 3.451677633399769e-05, 'epoch': 0.9289934199601386, 'step': 5158000}
INFO:transformers.trainer:{'loss': 3.092754680633545, 'learning_rate': 3.451527543988505e-05, 'epoch': 0.9290834736068971, 'step': 5158500}
INFO:transformers.trainer:{'loss': 3.1170711896419525, 'learning_rate': 3.451377454577241e-05, 'epoch': 0.9291735272536555, 'step': 5159000}
INFO:transformers.trainer:{'loss': 3.110054978609085, 'learning_rate': 3.4512273651659774e-05, 'epoch': 0.9292635809004139, 'step': 5159500}
INFO:transformers.trainer:{'loss': 3.103062075138092, 'learning_rate': 3.451077275754713e-05, 'epoch': 0.9293536345471725, 'step': 5160000}
INFO:transformers.trainer:{'loss': 3.1675899180173874, 'learning_rate': 3.450927186343449e-05, 'epoch': 0.9294436881939309, 'step': 5160500}
INFO:transformers.trainer:{'loss': 3.068761967897415, 'learning_rate': 3.4507770969321845e-05, 'epoch': 0.9295337418406894, 'step': 5161000}
INFO:transformers.trainer:{'loss': 3.2116965667009354, 'learning_rate': 3.4506270075209204e-05, 'epoch': 0.9296237954874478, 'step': 5161500}
INFO:transformers.trainer:{'loss': 3.1399937999248504, 'learning_rate': 3.450476918109656e-05, 'epoch': 0.9297138491342062, 'step': 5162000}
INFO:transformers.trainer:{'loss': 3.048954766750336, 'learning_rate': 3.450326828698392e-05, 'epoch': 0.9298039027809647, 'step': 5162500}
INFO:transformers.trainer:{'loss': 3.146172033786774, 'learning_rate': 3.450176739287128e-05, 'epoch': 0.9298939564277231, 'step': 5163000}
INFO:transformers.trainer:{'loss': 3.0633363362550736, 'learning_rate': 3.450026649875864e-05, 'epoch': 0.9299840100744816, 'step': 5163500}
INFO:transformers.trainer:{'loss': 3.168738401412964, 'learning_rate': 3.4498765604646e-05, 'epoch': 0.93007406372124, 'step': 5164000}
INFO:transformers.trainer:{'loss': 3.1255402135849, 'learning_rate': 3.449726471053336e-05, 'epoch': 0.9301641173679984, 'step': 5164500}
INFO:transformers.trainer:{'loss': 3.1458757796287538, 'learning_rate': 3.449576381642072e-05, 'epoch': 0.9302541710147569, 'step': 5165000}
INFO:transformers.trainer:{'loss': 3.1221332201957703, 'learning_rate': 3.4494262922308076e-05, 'epoch': 0.9303442246615153, 'step': 5165500}
INFO:transformers.trainer:{'loss': 3.201568489789963, 'learning_rate': 3.4492762028195435e-05, 'epoch': 0.9304342783082739, 'step': 5166000}
INFO:transformers.trainer:{'loss': 3.087546236515045, 'learning_rate': 3.4491261134082794e-05, 'epoch': 0.9305243319550323, 'step': 5166500}
INFO:transformers.trainer:{'loss': 3.1349292862415314, 'learning_rate': 3.448976023997016e-05, 'epoch': 0.9306143856017907, 'step': 5167000}
INFO:transformers.trainer:{'loss': 3.1807757532596588, 'learning_rate': 3.448825934585751e-05, 'epoch': 0.9307044392485492, 'step': 5167500}
INFO:transformers.trainer:{'loss': 3.1223810946941377, 'learning_rate': 3.448675845174488e-05, 'epoch': 0.9307944928953076, 'step': 5168000}
INFO:transformers.trainer:{'loss': 3.1333927533626555, 'learning_rate': 3.448525755763223e-05, 'epoch': 0.9308845465420661, 'step': 5168500}
INFO:transformers.trainer:{'loss': 3.189821006298065, 'learning_rate': 3.4483756663519596e-05, 'epoch': 0.9309746001888245, 'step': 5169000}
INFO:transformers.trainer:{'loss': 3.082553375482559, 'learning_rate': 3.448225576940695e-05, 'epoch': 0.9310646538355829, 'step': 5169500}
INFO:transformers.trainer:{'loss': 3.160915230989456, 'learning_rate': 3.4480754875294314e-05, 'epoch': 0.9311547074823414, 'step': 5170000}
INFO:transformers.trainer:{'loss': 3.1601789107322693, 'learning_rate': 3.447925398118167e-05, 'epoch': 0.9312447611290998, 'step': 5170500}
INFO:transformers.trainer:{'loss': 3.1134434809684755, 'learning_rate': 3.447775308706903e-05, 'epoch': 0.9313348147758582, 'step': 5171000}
INFO:transformers.trainer:{'loss': 3.133390328645706, 'learning_rate': 3.4476252192956385e-05, 'epoch': 0.9314248684226167, 'step': 5171500}
INFO:transformers.trainer:{'loss': 3.1944067072868347, 'learning_rate': 3.447475129884375e-05, 'epoch': 0.9315149220693751, 'step': 5172000}
INFO:transformers.trainer:{'loss': 3.113926336288452, 'learning_rate': 3.44732504047311e-05, 'epoch': 0.9316049757161337, 'step': 5172500}
INFO:transformers.trainer:{'loss': 3.1462830243110655, 'learning_rate': 3.447174951061847e-05, 'epoch': 0.9316950293628921, 'step': 5173000}
INFO:transformers.trainer:{'loss': 3.084802882909775, 'learning_rate': 3.447024861650583e-05, 'epoch': 0.9317850830096505, 'step': 5173500}
INFO:transformers.trainer:{'loss': 3.162526720523834, 'learning_rate': 3.446874772239319e-05, 'epoch': 0.931875136656409, 'step': 5174000}
INFO:transformers.trainer:{'loss': 3.119773282289505, 'learning_rate': 3.4467246828280546e-05, 'epoch': 0.9319651903031674, 'step': 5174500}
INFO:transformers.trainer:{'loss': 3.137473023414612, 'learning_rate': 3.4465745934167905e-05, 'epoch': 0.9320552439499259, 'step': 5175000}
INFO:transformers.trainer:{'loss': 3.1770600128173827, 'learning_rate': 3.4464245040055264e-05, 'epoch': 0.9321452975966843, 'step': 5175500}
INFO:transformers.trainer:{'loss': 3.0665633873939515, 'learning_rate': 3.446274414594262e-05, 'epoch': 0.9322353512434427, 'step': 5176000}
INFO:transformers.trainer:{'loss': 3.125074555397034, 'learning_rate': 3.446124325182998e-05, 'epoch': 0.9323254048902012, 'step': 5176500}
INFO:transformers.trainer:{'loss': 3.0915372585058214, 'learning_rate': 3.445974235771734e-05, 'epoch': 0.9324154585369596, 'step': 5177000}
INFO:transformers.trainer:{'loss': 3.1456239976882934, 'learning_rate': 3.44582414636047e-05, 'epoch': 0.9325055121837181, 'step': 5177500}
INFO:transformers.trainer:{'loss': 3.14573367023468, 'learning_rate': 3.445674056949206e-05, 'epoch': 0.9325955658304765, 'step': 5178000}
INFO:transformers.trainer:{'loss': 3.1405603543519973, 'learning_rate': 3.445523967537942e-05, 'epoch': 0.9326856194772349, 'step': 5178500}
INFO:transformers.trainer:{'loss': 3.107029592514038, 'learning_rate': 3.445373878126678e-05, 'epoch': 0.9327756731239935, 'step': 5179000}
INFO:transformers.trainer:{'loss': 3.184199469089508, 'learning_rate': 3.4452237887154136e-05, 'epoch': 0.9328657267707519, 'step': 5179500}
INFO:transformers.trainer:{'loss': 3.0936140019893648, 'learning_rate': 3.4450736993041495e-05, 'epoch': 0.9329557804175104, 'step': 5180000}
INFO:transformers.trainer:{'loss': 3.1277197766304017, 'learning_rate': 3.4449236098928855e-05, 'epoch': 0.9330458340642688, 'step': 5180500}
INFO:transformers.trainer:{'loss': 3.1563609886169433, 'learning_rate': 3.444773520481622e-05, 'epoch': 0.9331358877110272, 'step': 5181000}
INFO:transformers.trainer:{'loss': 3.0686397643089296, 'learning_rate': 3.444623431070357e-05, 'epoch': 0.9332259413577857, 'step': 5181500}
INFO:transformers.trainer:{'loss': 3.176565605163574, 'learning_rate': 3.444473341659094e-05, 'epoch': 0.9333159950045441, 'step': 5182000}
INFO:transformers.trainer:{'loss': 3.147942886829376, 'learning_rate': 3.444323252247829e-05, 'epoch': 0.9334060486513025, 'step': 5182500}
INFO:transformers.trainer:{'loss': 3.127716045856476, 'learning_rate': 3.4441731628365657e-05, 'epoch': 0.933496102298061, 'step': 5183000}
INFO:transformers.trainer:{'loss': 3.1144204289913175, 'learning_rate': 3.444023073425301e-05, 'epoch': 0.9335861559448194, 'step': 5183500}
INFO:transformers.trainer:{'loss': 3.1251334767341614, 'learning_rate': 3.4438729840140375e-05, 'epoch': 0.9336762095915779, 'step': 5184000}
INFO:transformers.trainer:{'loss': 3.1308848481178284, 'learning_rate': 3.443722894602773e-05, 'epoch': 0.9337662632383363, 'step': 5184500}
INFO:transformers.trainer:{'loss': 3.0927905571460723, 'learning_rate': 3.4435728051915086e-05, 'epoch': 0.9338563168850947, 'step': 5185000}
INFO:transformers.trainer:{'loss': 3.1105969395637514, 'learning_rate': 3.4434227157802445e-05, 'epoch': 0.9339463705318533, 'step': 5185500}
INFO:transformers.trainer:{'loss': 3.1209875519275667, 'learning_rate': 3.4432726263689804e-05, 'epoch': 0.9340364241786117, 'step': 5186000}
INFO:transformers.trainer:{'loss': 3.1198943109512327, 'learning_rate': 3.443122536957716e-05, 'epoch': 0.9341264778253702, 'step': 5186500}
INFO:transformers.trainer:{'loss': 3.0894544351100923, 'learning_rate': 3.442972447546452e-05, 'epoch': 0.9342165314721286, 'step': 5187000}
INFO:transformers.trainer:{'loss': 3.1081591479778288, 'learning_rate': 3.442822358135189e-05, 'epoch': 0.934306585118887, 'step': 5187500}
INFO:transformers.trainer:{'loss': 3.1707237734794615, 'learning_rate': 3.442672268723924e-05, 'epoch': 0.9343966387656455, 'step': 5188000}
INFO:transformers.trainer:{'loss': 3.1432404602766035, 'learning_rate': 3.4425221793126606e-05, 'epoch': 0.9344866924124039, 'step': 5188500}
INFO:transformers.trainer:{'loss': 3.1326741335392, 'learning_rate': 3.442372089901396e-05, 'epoch': 0.9345767460591624, 'step': 5189000}
INFO:transformers.trainer:{'loss': 3.1834777200222018, 'learning_rate': 3.4422220004901324e-05, 'epoch': 0.9346667997059208, 'step': 5189500}
INFO:transformers.trainer:{'loss': 3.0851258070468903, 'learning_rate': 3.4420719110788676e-05, 'epoch': 0.9347568533526792, 'step': 5190000}
INFO:transformers.trainer:{'loss': 3.1008839057683946, 'learning_rate': 3.441921821667604e-05, 'epoch': 0.9348469069994377, 'step': 5190500}
INFO:transformers.trainer:{'loss': 3.1569791543483734, 'learning_rate': 3.4417717322563395e-05, 'epoch': 0.9349369606461961, 'step': 5191000}
INFO:transformers.trainer:{'loss': 3.030420737504959, 'learning_rate': 3.441621642845076e-05, 'epoch': 0.9350270142929547, 'step': 5191500}
INFO:transformers.trainer:{'loss': 3.187598726272583, 'learning_rate': 3.441471553433811e-05, 'epoch': 0.935117067939713, 'step': 5192000}
INFO:transformers.trainer:{'loss': 3.143199693441391, 'learning_rate': 3.441321464022548e-05, 'epoch': 0.9352071215864715, 'step': 5192500}
INFO:transformers.trainer:{'loss': 3.1361155672073364, 'learning_rate': 3.441171374611283e-05, 'epoch': 0.93529717523323, 'step': 5193000}
INFO:transformers.trainer:{'loss': 3.1654682030677797, 'learning_rate': 3.4410212852000197e-05, 'epoch': 0.9353872288799884, 'step': 5193500}
INFO:transformers.trainer:{'loss': 3.1279830503463746, 'learning_rate': 3.4408711957887556e-05, 'epoch': 0.9354772825267468, 'step': 5194000}
INFO:transformers.trainer:{'loss': 3.16430703663826, 'learning_rate': 3.4407211063774915e-05, 'epoch': 0.9355673361735053, 'step': 5194500}
INFO:transformers.trainer:{'loss': 3.1076807650327685, 'learning_rate': 3.4405710169662274e-05, 'epoch': 0.9356573898202637, 'step': 5195000}
INFO:transformers.trainer:{'loss': 3.179438514828682, 'learning_rate': 3.440420927554963e-05, 'epoch': 0.9357474434670222, 'step': 5195500}
INFO:transformers.trainer:{'loss': 3.1678147027492525, 'learning_rate': 3.440270838143699e-05, 'epoch': 0.9358374971137806, 'step': 5196000}
INFO:transformers.trainer:{'loss': 3.1600250556468965, 'learning_rate': 3.440120748732435e-05, 'epoch': 0.935927550760539, 'step': 5196500}
INFO:transformers.trainer:{'loss': 3.127180680036545, 'learning_rate': 3.439970659321171e-05, 'epoch': 0.9360176044072975, 'step': 5197000}
INFO:transformers.trainer:{'loss': 3.1423836324214935, 'learning_rate': 3.439820569909907e-05, 'epoch': 0.9361076580540559, 'step': 5197500}
INFO:transformers.trainer:{'loss': 3.1300291533470155, 'learning_rate': 3.439670480498643e-05, 'epoch': 0.9361977117008144, 'step': 5198000}
INFO:transformers.trainer:{'loss': 3.094924533843994, 'learning_rate': 3.439520391087379e-05, 'epoch': 0.9362877653475729, 'step': 5198500}
INFO:transformers.trainer:{'loss': 3.153987998008728, 'learning_rate': 3.4393703016761146e-05, 'epoch': 0.9363778189943313, 'step': 5199000}
INFO:transformers.trainer:{'loss': 3.1716205446720123, 'learning_rate': 3.4392202122648505e-05, 'epoch': 0.9364678726410898, 'step': 5199500}
INFO:transformers.trainer:{'loss': 3.127243366956711, 'learning_rate': 3.4390701228535864e-05, 'epoch': 0.9365579262878482, 'step': 5200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.151356095075607, 'learning_rate': 3.438920033442322e-05, 'epoch': 0.9366479799346067, 'step': 5200500}
INFO:transformers.trainer:{'loss': 3.1711661295890807, 'learning_rate': 3.438769944031058e-05, 'epoch': 0.9367380335813651, 'step': 5201000}
INFO:transformers.trainer:{'loss': 3.1171347808837893, 'learning_rate': 3.438619854619795e-05, 'epoch': 0.9368280872281235, 'step': 5201500}
INFO:transformers.trainer:{'loss': 3.1611855709552765, 'learning_rate': 3.43846976520853e-05, 'epoch': 0.936918140874882, 'step': 5202000}
INFO:transformers.trainer:{'loss': 3.129058156013489, 'learning_rate': 3.4383196757972666e-05, 'epoch': 0.9370081945216404, 'step': 5202500}
INFO:transformers.trainer:{'loss': 3.1185662274360655, 'learning_rate': 3.438169586386002e-05, 'epoch': 0.9370982481683989, 'step': 5203000}
INFO:transformers.trainer:{'loss': 3.1408937678337097, 'learning_rate': 3.4380194969747384e-05, 'epoch': 0.9371883018151573, 'step': 5203500}
INFO:transformers.trainer:{'loss': 3.164096961021423, 'learning_rate': 3.437869407563474e-05, 'epoch': 0.9372783554619157, 'step': 5204000}
INFO:transformers.trainer:{'loss': 3.1939816880226135, 'learning_rate': 3.43771931815221e-05, 'epoch': 0.9373684091086742, 'step': 5204500}
INFO:transformers.trainer:{'loss': 3.0985916707515715, 'learning_rate': 3.4375692287409455e-05, 'epoch': 0.9374584627554327, 'step': 5205000}
INFO:transformers.trainer:{'loss': 3.095100015759468, 'learning_rate': 3.437419139329682e-05, 'epoch': 0.9375485164021912, 'step': 5205500}
INFO:transformers.trainer:{'loss': 3.105475739955902, 'learning_rate': 3.437269049918417e-05, 'epoch': 0.9376385700489496, 'step': 5206000}
INFO:transformers.trainer:{'loss': 3.146544425487518, 'learning_rate': 3.437118960507154e-05, 'epoch': 0.937728623695708, 'step': 5206500}
INFO:transformers.trainer:{'loss': 3.1175407719612123, 'learning_rate': 3.436968871095889e-05, 'epoch': 0.9378186773424665, 'step': 5207000}
INFO:transformers.trainer:{'loss': 3.1097828657627105, 'learning_rate': 3.436818781684626e-05, 'epoch': 0.9379087309892249, 'step': 5207500}
INFO:transformers.trainer:{'loss': 3.142793939113617, 'learning_rate': 3.4366686922733616e-05, 'epoch': 0.9379987846359833, 'step': 5208000}
INFO:transformers.trainer:{'loss': 3.138073784351349, 'learning_rate': 3.436518602862097e-05, 'epoch': 0.9380888382827418, 'step': 5208500}
INFO:transformers.trainer:{'loss': 3.167095278739929, 'learning_rate': 3.4363685134508334e-05, 'epoch': 0.9381788919295002, 'step': 5209000}
INFO:transformers.trainer:{'loss': 3.112002539873123, 'learning_rate': 3.4362184240395686e-05, 'epoch': 0.9382689455762587, 'step': 5209500}
INFO:transformers.trainer:{'loss': 3.1218119337558745, 'learning_rate': 3.436068334628305e-05, 'epoch': 0.9383589992230171, 'step': 5210000}
INFO:transformers.trainer:{'loss': 3.1149077396392824, 'learning_rate': 3.4359182452170404e-05, 'epoch': 0.9384490528697755, 'step': 5210500}
INFO:transformers.trainer:{'loss': 3.1694823071956635, 'learning_rate': 3.435768155805777e-05, 'epoch': 0.938539106516534, 'step': 5211000}
INFO:transformers.trainer:{'loss': 3.1135221883058546, 'learning_rate': 3.435618066394512e-05, 'epoch': 0.9386291601632925, 'step': 5211500}
INFO:transformers.trainer:{'loss': 3.0990579855442046, 'learning_rate': 3.435467976983249e-05, 'epoch': 0.938719213810051, 'step': 5212000}
INFO:transformers.trainer:{'loss': 3.15522514128685, 'learning_rate': 3.435317887571984e-05, 'epoch': 0.9388092674568094, 'step': 5212500}
INFO:transformers.trainer:{'loss': 3.096463568687439, 'learning_rate': 3.4351677981607206e-05, 'epoch': 0.9388993211035678, 'step': 5213000}
INFO:transformers.trainer:{'loss': 3.1621391503810883, 'learning_rate': 3.435017708749456e-05, 'epoch': 0.9389893747503263, 'step': 5213500}
INFO:transformers.trainer:{'loss': 3.1377537194490435, 'learning_rate': 3.4348676193381924e-05, 'epoch': 0.9390794283970847, 'step': 5214000}
INFO:transformers.trainer:{'loss': 3.114254256486893, 'learning_rate': 3.434717529926928e-05, 'epoch': 0.9391694820438432, 'step': 5214500}
INFO:transformers.trainer:{'loss': 3.1120519917607306, 'learning_rate': 3.434567440515664e-05, 'epoch': 0.9392595356906016, 'step': 5215000}
INFO:transformers.trainer:{'loss': 3.1335848088264466, 'learning_rate': 3.4344173511044e-05, 'epoch': 0.93934958933736, 'step': 5215500}
INFO:transformers.trainer:{'loss': 3.1357970464229585, 'learning_rate': 3.434267261693136e-05, 'epoch': 0.9394396429841185, 'step': 5216000}
INFO:transformers.trainer:{'loss': 3.1387796347141266, 'learning_rate': 3.434117172281872e-05, 'epoch': 0.9395296966308769, 'step': 5216500}
INFO:transformers.trainer:{'loss': 3.122164410352707, 'learning_rate': 3.433967082870608e-05, 'epoch': 0.9396197502776354, 'step': 5217000}
INFO:transformers.trainer:{'loss': 3.1625206694602968, 'learning_rate': 3.433816993459344e-05, 'epoch': 0.9397098039243938, 'step': 5217500}
INFO:transformers.trainer:{'loss': 3.137147765040398, 'learning_rate': 3.43366690404808e-05, 'epoch': 0.9397998575711523, 'step': 5218000}
INFO:transformers.trainer:{'loss': 3.061581554889679, 'learning_rate': 3.4335168146368156e-05, 'epoch': 0.9398899112179108, 'step': 5218500}
INFO:transformers.trainer:{'loss': 3.1205255165100096, 'learning_rate': 3.4333667252255515e-05, 'epoch': 0.9399799648646692, 'step': 5219000}
INFO:transformers.trainer:{'loss': 3.110465067386627, 'learning_rate': 3.4332166358142874e-05, 'epoch': 0.9400700185114276, 'step': 5219500}
INFO:transformers.trainer:{'loss': 3.160405634641647, 'learning_rate': 3.433066546403023e-05, 'epoch': 0.9401600721581861, 'step': 5220000}
INFO:transformers.trainer:{'loss': 3.136597651004791, 'learning_rate': 3.432916456991759e-05, 'epoch': 0.9402501258049445, 'step': 5220500}
INFO:transformers.trainer:{'loss': 3.1243222832679747, 'learning_rate': 3.432766367580495e-05, 'epoch': 0.940340179451703, 'step': 5221000}
INFO:transformers.trainer:{'loss': 3.1369163973331453, 'learning_rate': 3.432616278169231e-05, 'epoch': 0.9404302330984614, 'step': 5221500}
INFO:transformers.trainer:{'loss': 3.1065489497184755, 'learning_rate': 3.4324661887579676e-05, 'epoch': 0.9405202867452198, 'step': 5222000}
INFO:transformers.trainer:{'loss': 3.1742670725584032, 'learning_rate': 3.432316099346703e-05, 'epoch': 0.9406103403919783, 'step': 5222500}
INFO:transformers.trainer:{'loss': 3.1323383786678316, 'learning_rate': 3.4321660099354394e-05, 'epoch': 0.9407003940387367, 'step': 5223000}
INFO:transformers.trainer:{'loss': 3.145455139398575, 'learning_rate': 3.4320159205241746e-05, 'epoch': 0.9407904476854952, 'step': 5223500}
INFO:transformers.trainer:{'loss': 3.1440474121570587, 'learning_rate': 3.431865831112911e-05, 'epoch': 0.9408805013322536, 'step': 5224000}
INFO:transformers.trainer:{'loss': 3.129216493368149, 'learning_rate': 3.4317157417016464e-05, 'epoch': 0.940970554979012, 'step': 5224500}
INFO:transformers.trainer:{'loss': 3.127403461933136, 'learning_rate': 3.431565652290383e-05, 'epoch': 0.9410606086257706, 'step': 5225000}
INFO:transformers.trainer:{'loss': 3.1292173874378206, 'learning_rate': 3.431415562879118e-05, 'epoch': 0.941150662272529, 'step': 5225500}
INFO:transformers.trainer:{'loss': 3.174075426340103, 'learning_rate': 3.431265473467855e-05, 'epoch': 0.9412407159192875, 'step': 5226000}
INFO:transformers.trainer:{'loss': 3.191720759034157, 'learning_rate': 3.43111538405659e-05, 'epoch': 0.9413307695660459, 'step': 5226500}
INFO:transformers.trainer:{'loss': 3.1423199779987336, 'learning_rate': 3.4309652946453267e-05, 'epoch': 0.9414208232128043, 'step': 5227000}
INFO:transformers.trainer:{'loss': 3.14871612238884, 'learning_rate': 3.430815205234062e-05, 'epoch': 0.9415108768595628, 'step': 5227500}
INFO:transformers.trainer:{'loss': 3.1304652901887895, 'learning_rate': 3.4306651158227985e-05, 'epoch': 0.9416009305063212, 'step': 5228000}
INFO:transformers.trainer:{'loss': 3.12976686501503, 'learning_rate': 3.430515026411534e-05, 'epoch': 0.9416909841530797, 'step': 5228500}
INFO:transformers.trainer:{'loss': 3.1045696580410005, 'learning_rate': 3.43036493700027e-05, 'epoch': 0.9417810377998381, 'step': 5229000}
INFO:transformers.trainer:{'loss': 3.098833882331848, 'learning_rate': 3.430214847589006e-05, 'epoch': 0.9418710914465965, 'step': 5229500}
INFO:transformers.trainer:{'loss': 3.123943847298622, 'learning_rate': 3.430064758177742e-05, 'epoch': 0.941961145093355, 'step': 5230000}
INFO:transformers.trainer:{'loss': 3.0855371685028077, 'learning_rate': 3.429914668766478e-05, 'epoch': 0.9420511987401134, 'step': 5230500}
INFO:transformers.trainer:{'loss': 3.1121213569641113, 'learning_rate': 3.429764579355214e-05, 'epoch': 0.9421412523868719, 'step': 5231000}
INFO:transformers.trainer:{'loss': 3.051641470193863, 'learning_rate': 3.42961448994395e-05, 'epoch': 0.9422313060336304, 'step': 5231500}
INFO:transformers.trainer:{'loss': 3.185449617266655, 'learning_rate': 3.429464400532686e-05, 'epoch': 0.9423213596803888, 'step': 5232000}
INFO:transformers.trainer:{'loss': 3.144837999820709, 'learning_rate': 3.4293143111214216e-05, 'epoch': 0.9424114133271473, 'step': 5232500}
INFO:transformers.trainer:{'loss': 3.0680733218193055, 'learning_rate': 3.429164221710157e-05, 'epoch': 0.9425014669739057, 'step': 5233000}
INFO:transformers.trainer:{'loss': 3.1395837084054947, 'learning_rate': 3.4290141322988934e-05, 'epoch': 0.9425915206206641, 'step': 5233500}
INFO:transformers.trainer:{'loss': 3.1689112687110903, 'learning_rate': 3.4288640428876286e-05, 'epoch': 0.9426815742674226, 'step': 5234000}
INFO:transformers.trainer:{'loss': 3.1108690190315245, 'learning_rate': 3.428713953476365e-05, 'epoch': 0.942771627914181, 'step': 5234500}
INFO:transformers.trainer:{'loss': 3.0624072866439818, 'learning_rate': 3.4285638640651005e-05, 'epoch': 0.9428616815609395, 'step': 5235000}
INFO:transformers.trainer:{'loss': 3.133521065711975, 'learning_rate': 3.428413774653837e-05, 'epoch': 0.9429517352076979, 'step': 5235500}
INFO:transformers.trainer:{'loss': 3.1404651765823366, 'learning_rate': 3.428263685242573e-05, 'epoch': 0.9430417888544563, 'step': 5236000}
INFO:transformers.trainer:{'loss': 3.114418867111206, 'learning_rate': 3.428113595831309e-05, 'epoch': 0.9431318425012148, 'step': 5236500}
INFO:transformers.trainer:{'loss': 3.1433627371788027, 'learning_rate': 3.427963506420045e-05, 'epoch': 0.9432218961479732, 'step': 5237000}
INFO:transformers.trainer:{'loss': 3.0742280703783034, 'learning_rate': 3.4278134170087807e-05, 'epoch': 0.9433119497947318, 'step': 5237500}
INFO:transformers.trainer:{'loss': 3.148745693206787, 'learning_rate': 3.4276633275975166e-05, 'epoch': 0.9434020034414902, 'step': 5238000}
INFO:transformers.trainer:{'loss': 3.1335240875482557, 'learning_rate': 3.4275132381862525e-05, 'epoch': 0.9434920570882486, 'step': 5238500}
INFO:transformers.trainer:{'loss': 3.120712595462799, 'learning_rate': 3.4273631487749884e-05, 'epoch': 0.9435821107350071, 'step': 5239000}
INFO:transformers.trainer:{'loss': 3.119747382879257, 'learning_rate': 3.427213059363724e-05, 'epoch': 0.9436721643817655, 'step': 5239500}
INFO:transformers.trainer:{'loss': 3.055614976167679, 'learning_rate': 3.42706296995246e-05, 'epoch': 0.943762218028524, 'step': 5240000}
INFO:transformers.trainer:{'loss': 3.180148663520813, 'learning_rate': 3.426912880541196e-05, 'epoch': 0.9438522716752824, 'step': 5240500}
INFO:transformers.trainer:{'loss': 3.16158686208725, 'learning_rate': 3.426762791129932e-05, 'epoch': 0.9439423253220408, 'step': 5241000}
INFO:transformers.trainer:{'loss': 3.1652777948379516, 'learning_rate': 3.426612701718668e-05, 'epoch': 0.9440323789687993, 'step': 5241500}
INFO:transformers.trainer:{'loss': 3.1799705052375793, 'learning_rate': 3.426462612307404e-05, 'epoch': 0.9441224326155577, 'step': 5242000}
INFO:transformers.trainer:{'loss': 3.1637944424152376, 'learning_rate': 3.42631252289614e-05, 'epoch': 0.9442124862623162, 'step': 5242500}
INFO:transformers.trainer:{'loss': 3.1201031324267388, 'learning_rate': 3.4261624334848756e-05, 'epoch': 0.9443025399090746, 'step': 5243000}
INFO:transformers.trainer:{'loss': 3.0751994881629945, 'learning_rate': 3.426012344073612e-05, 'epoch': 0.944392593555833, 'step': 5243500}
INFO:transformers.trainer:{'loss': 3.092475250482559, 'learning_rate': 3.4258622546623474e-05, 'epoch': 0.9444826472025916, 'step': 5244000}
INFO:transformers.trainer:{'loss': 3.1125938137769698, 'learning_rate': 3.425712165251084e-05, 'epoch': 0.94457270084935, 'step': 5244500}
INFO:transformers.trainer:{'loss': 3.1382833313941956, 'learning_rate': 3.425562075839819e-05, 'epoch': 0.9446627544961084, 'step': 5245000}
INFO:transformers.trainer:{'loss': 3.0978135998249052, 'learning_rate': 3.425411986428556e-05, 'epoch': 0.9447528081428669, 'step': 5245500}
INFO:transformers.trainer:{'loss': 3.099125329852104, 'learning_rate': 3.425261897017291e-05, 'epoch': 0.9448428617896253, 'step': 5246000}
INFO:transformers.trainer:{'loss': 3.166623488664627, 'learning_rate': 3.4251118076060276e-05, 'epoch': 0.9449329154363838, 'step': 5246500}
INFO:transformers.trainer:{'loss': 3.1057834095954897, 'learning_rate': 3.424961718194763e-05, 'epoch': 0.9450229690831422, 'step': 5247000}
INFO:transformers.trainer:{'loss': 3.1772225234508515, 'learning_rate': 3.4248116287834994e-05, 'epoch': 0.9451130227299006, 'step': 5247500}
INFO:transformers.trainer:{'loss': 3.1122044982910158, 'learning_rate': 3.4246615393722347e-05, 'epoch': 0.9452030763766591, 'step': 5248000}
INFO:transformers.trainer:{'loss': 3.140711941957474, 'learning_rate': 3.424511449960971e-05, 'epoch': 0.9452931300234175, 'step': 5248500}
INFO:transformers.trainer:{'loss': 3.1165462794303895, 'learning_rate': 3.4243613605497065e-05, 'epoch': 0.945383183670176, 'step': 5249000}
INFO:transformers.trainer:{'loss': 3.059308461070061, 'learning_rate': 3.424211271138443e-05, 'epoch': 0.9454732373169344, 'step': 5249500}
INFO:transformers.trainer:{'loss': 3.114671070933342, 'learning_rate': 3.424061181727179e-05, 'epoch': 0.9455632909636928, 'step': 5250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1096397442817687, 'learning_rate': 3.423911092315915e-05, 'epoch': 0.9456533446104514, 'step': 5250500}
INFO:transformers.trainer:{'loss': 3.14952922809124, 'learning_rate': 3.423761002904651e-05, 'epoch': 0.9457433982572098, 'step': 5251000}
INFO:transformers.trainer:{'loss': 3.1328544223308565, 'learning_rate': 3.423610913493387e-05, 'epoch': 0.9458334519039683, 'step': 5251500}
INFO:transformers.trainer:{'loss': 3.1078179852962493, 'learning_rate': 3.4234608240821226e-05, 'epoch': 0.9459235055507267, 'step': 5252000}
INFO:transformers.trainer:{'loss': 3.097601248025894, 'learning_rate': 3.4233107346708585e-05, 'epoch': 0.9460135591974851, 'step': 5252500}
INFO:transformers.trainer:{'loss': 3.062738058924675, 'learning_rate': 3.4231606452595944e-05, 'epoch': 0.9461036128442436, 'step': 5253000}
INFO:transformers.trainer:{'loss': 3.148337846159935, 'learning_rate': 3.42301055584833e-05, 'epoch': 0.946193666491002, 'step': 5253500}
INFO:transformers.trainer:{'loss': 3.1216272504329683, 'learning_rate': 3.422860466437066e-05, 'epoch': 0.9462837201377605, 'step': 5254000}
INFO:transformers.trainer:{'loss': 3.1151274762153625, 'learning_rate': 3.422710377025802e-05, 'epoch': 0.9463737737845189, 'step': 5254500}
INFO:transformers.trainer:{'loss': 3.103699050426483, 'learning_rate': 3.422560287614538e-05, 'epoch': 0.9464638274312773, 'step': 5255000}
INFO:transformers.trainer:{'loss': 3.108898444890976, 'learning_rate': 3.422410198203274e-05, 'epoch': 0.9465538810780358, 'step': 5255500}
INFO:transformers.trainer:{'loss': 3.1287523316144945, 'learning_rate': 3.42226010879201e-05, 'epoch': 0.9466439347247942, 'step': 5256000}
INFO:transformers.trainer:{'loss': 3.0861379134655, 'learning_rate': 3.422110019380746e-05, 'epoch': 0.9467339883715526, 'step': 5256500}
INFO:transformers.trainer:{'loss': 3.187705762863159, 'learning_rate': 3.4219599299694816e-05, 'epoch': 0.9468240420183112, 'step': 5257000}
INFO:transformers.trainer:{'loss': 3.069498855113983, 'learning_rate': 3.4218098405582175e-05, 'epoch': 0.9469140956650696, 'step': 5257500}
INFO:transformers.trainer:{'loss': 3.1131357713937757, 'learning_rate': 3.4216597511469534e-05, 'epoch': 0.9470041493118281, 'step': 5258000}
INFO:transformers.trainer:{'loss': 3.1851740970611573, 'learning_rate': 3.4215096617356893e-05, 'epoch': 0.9470942029585865, 'step': 5258500}
INFO:transformers.trainer:{'loss': 3.1070211460590365, 'learning_rate': 3.421359572324425e-05, 'epoch': 0.9471842566053449, 'step': 5259000}
INFO:transformers.trainer:{'loss': 3.113864589214325, 'learning_rate': 3.421209482913161e-05, 'epoch': 0.9472743102521034, 'step': 5259500}
INFO:transformers.trainer:{'loss': 3.080622848033905, 'learning_rate': 3.421059393501897e-05, 'epoch': 0.9473643638988618, 'step': 5260000}
INFO:transformers.trainer:{'loss': 3.105828045129776, 'learning_rate': 3.420909304090633e-05, 'epoch': 0.9474544175456203, 'step': 5260500}
INFO:transformers.trainer:{'loss': 3.0944222004413606, 'learning_rate': 3.420759214679369e-05, 'epoch': 0.9475444711923787, 'step': 5261000}
INFO:transformers.trainer:{'loss': 3.1058632535934447, 'learning_rate': 3.420609125268105e-05, 'epoch': 0.9476345248391371, 'step': 5261500}
INFO:transformers.trainer:{'loss': 3.163129696846008, 'learning_rate': 3.420459035856841e-05, 'epoch': 0.9477245784858956, 'step': 5262000}
INFO:transformers.trainer:{'loss': 3.1662982008457186, 'learning_rate': 3.4203089464455766e-05, 'epoch': 0.947814632132654, 'step': 5262500}
INFO:transformers.trainer:{'loss': 3.080625375032425, 'learning_rate': 3.4201588570343125e-05, 'epoch': 0.9479046857794126, 'step': 5263000}
INFO:transformers.trainer:{'loss': 3.108243785381317, 'learning_rate': 3.4200087676230484e-05, 'epoch': 0.947994739426171, 'step': 5263500}
INFO:transformers.trainer:{'loss': 3.0617394214868545, 'learning_rate': 3.419858678211785e-05, 'epoch': 0.9480847930729294, 'step': 5264000}
INFO:transformers.trainer:{'loss': 3.134103399038315, 'learning_rate': 3.41970858880052e-05, 'epoch': 0.9481748467196879, 'step': 5264500}
INFO:transformers.trainer:{'loss': 3.1156043050289153, 'learning_rate': 3.419558499389257e-05, 'epoch': 0.9482649003664463, 'step': 5265000}
INFO:transformers.trainer:{'loss': 3.1806678867340086, 'learning_rate': 3.419408409977992e-05, 'epoch': 0.9483549540132048, 'step': 5265500}
INFO:transformers.trainer:{'loss': 3.0653515976667403, 'learning_rate': 3.4192583205667286e-05, 'epoch': 0.9484450076599632, 'step': 5266000}
INFO:transformers.trainer:{'loss': 3.123486513376236, 'learning_rate': 3.419108231155464e-05, 'epoch': 0.9485350613067216, 'step': 5266500}
INFO:transformers.trainer:{'loss': 3.1423254678249357, 'learning_rate': 3.4189581417442004e-05, 'epoch': 0.9486251149534801, 'step': 5267000}
INFO:transformers.trainer:{'loss': 3.1057154154777527, 'learning_rate': 3.4188080523329356e-05, 'epoch': 0.9487151686002385, 'step': 5267500}
INFO:transformers.trainer:{'loss': 3.1364538909196855, 'learning_rate': 3.418657962921672e-05, 'epoch': 0.9488052222469969, 'step': 5268000}
INFO:transformers.trainer:{'loss': 3.1310858018398284, 'learning_rate': 3.4185078735104074e-05, 'epoch': 0.9488952758937554, 'step': 5268500}
INFO:transformers.trainer:{'loss': 3.117272565603256, 'learning_rate': 3.418357784099144e-05, 'epoch': 0.9489853295405138, 'step': 5269000}
INFO:transformers.trainer:{'loss': 3.12376878118515, 'learning_rate': 3.418207694687879e-05, 'epoch': 0.9490753831872724, 'step': 5269500}
INFO:transformers.trainer:{'loss': 3.1156139841079713, 'learning_rate': 3.418057605276616e-05, 'epoch': 0.9491654368340308, 'step': 5270000}
INFO:transformers.trainer:{'loss': 3.1064311952590944, 'learning_rate': 3.417907515865352e-05, 'epoch': 0.9492554904807892, 'step': 5270500}
INFO:transformers.trainer:{'loss': 3.3360800671577455, 'learning_rate': 3.4177574264540876e-05, 'epoch': 0.9493455441275477, 'step': 5271000}
INFO:transformers.trainer:{'loss': 3.459308777689934, 'learning_rate': 3.4176073370428236e-05, 'epoch': 0.9494355977743061, 'step': 5271500}
INFO:transformers.trainer:{'loss': 3.5497868231534957, 'learning_rate': 3.4174572476315595e-05, 'epoch': 0.9495256514210646, 'step': 5272000}
INFO:transformers.trainer:{'loss': 3.1690543942451477, 'learning_rate': 3.4173071582202954e-05, 'epoch': 0.949615705067823, 'step': 5272500}
INFO:transformers.trainer:{'loss': 3.1644433916807175, 'learning_rate': 3.417157068809031e-05, 'epoch': 0.9497057587145814, 'step': 5273000}
INFO:transformers.trainer:{'loss': 3.1146582620143892, 'learning_rate': 3.417006979397767e-05, 'epoch': 0.9497958123613399, 'step': 5273500}
INFO:transformers.trainer:{'loss': 3.145376004874706, 'learning_rate': 3.416856889986503e-05, 'epoch': 0.9498858660080983, 'step': 5274000}
INFO:transformers.trainer:{'loss': 3.174879559278488, 'learning_rate': 3.416706800575239e-05, 'epoch': 0.9499759196548568, 'step': 5274500}
INFO:transformers.trainer:{'loss': 3.203463276863098, 'learning_rate': 3.416556711163975e-05, 'epoch': 0.9500659733016152, 'step': 5275000}
INFO:transformers.trainer:{'loss': 3.1129546706676483, 'learning_rate': 3.416406621752711e-05, 'epoch': 0.9501560269483736, 'step': 5275500}
INFO:transformers.trainer:{'loss': 3.130791763305664, 'learning_rate': 3.416256532341447e-05, 'epoch': 0.9502460805951322, 'step': 5276000}
INFO:transformers.trainer:{'loss': 3.136929556131363, 'learning_rate': 3.4161064429301826e-05, 'epoch': 0.9503361342418906, 'step': 5276500}
INFO:transformers.trainer:{'loss': 3.1123179228305817, 'learning_rate': 3.4159563535189185e-05, 'epoch': 0.9504261878886491, 'step': 5277000}
INFO:transformers.trainer:{'loss': 3.132751799583435, 'learning_rate': 3.4158062641076544e-05, 'epoch': 0.9505162415354075, 'step': 5277500}
INFO:transformers.trainer:{'loss': 3.176466529369354, 'learning_rate': 3.41565617469639e-05, 'epoch': 0.9506062951821659, 'step': 5278000}
INFO:transformers.trainer:{'loss': 3.1227764298915863, 'learning_rate': 3.415506085285126e-05, 'epoch': 0.9506963488289244, 'step': 5278500}
INFO:transformers.trainer:{'loss': 3.1124746012687683, 'learning_rate': 3.415355995873862e-05, 'epoch': 0.9507864024756828, 'step': 5279000}
INFO:transformers.trainer:{'loss': 3.0857463998794556, 'learning_rate': 3.415205906462598e-05, 'epoch': 0.9508764561224413, 'step': 5279500}
INFO:transformers.trainer:{'loss': 3.142753467798233, 'learning_rate': 3.415055817051334e-05, 'epoch': 0.9509665097691997, 'step': 5280000}
INFO:transformers.trainer:{'loss': 3.1130202493667603, 'learning_rate': 3.41490572764007e-05, 'epoch': 0.9510565634159581, 'step': 5280500}
INFO:transformers.trainer:{'loss': 3.13233475792408, 'learning_rate': 3.414755638228806e-05, 'epoch': 0.9511466170627166, 'step': 5281000}
INFO:transformers.trainer:{'loss': 3.141981023788452, 'learning_rate': 3.4146055488175417e-05, 'epoch': 0.951236670709475, 'step': 5281500}
INFO:transformers.trainer:{'loss': 3.0945205371379854, 'learning_rate': 3.4144554594062776e-05, 'epoch': 0.9513267243562334, 'step': 5282000}
INFO:transformers.trainer:{'loss': 3.126372486948967, 'learning_rate': 3.4143053699950135e-05, 'epoch': 0.951416778002992, 'step': 5282500}
INFO:transformers.trainer:{'loss': 3.1171026031970976, 'learning_rate': 3.4141552805837494e-05, 'epoch': 0.9515068316497504, 'step': 5283000}
INFO:transformers.trainer:{'loss': 3.0914969005584716, 'learning_rate': 3.414005191172485e-05, 'epoch': 0.9515968852965089, 'step': 5283500}
INFO:transformers.trainer:{'loss': 3.160542243719101, 'learning_rate': 3.413855101761221e-05, 'epoch': 0.9516869389432673, 'step': 5284000}
INFO:transformers.trainer:{'loss': 3.105574761390686, 'learning_rate': 3.413705012349958e-05, 'epoch': 0.9517769925900257, 'step': 5284500}
INFO:transformers.trainer:{'loss': 3.1093632626533507, 'learning_rate': 3.413554922938693e-05, 'epoch': 0.9518670462367842, 'step': 5285000}
INFO:transformers.trainer:{'loss': 3.1609513149261477, 'learning_rate': 3.4134048335274296e-05, 'epoch': 0.9519570998835426, 'step': 5285500}
INFO:transformers.trainer:{'loss': 3.114264961481094, 'learning_rate': 3.413254744116165e-05, 'epoch': 0.9520471535303011, 'step': 5286000}
INFO:transformers.trainer:{'loss': 3.1581953634023665, 'learning_rate': 3.4131046547049014e-05, 'epoch': 0.9521372071770595, 'step': 5286500}
INFO:transformers.trainer:{'loss': 3.1709537336826323, 'learning_rate': 3.4129545652936366e-05, 'epoch': 0.9522272608238179, 'step': 5287000}
INFO:transformers.trainer:{'loss': 3.0972727410793306, 'learning_rate': 3.412804475882373e-05, 'epoch': 0.9523173144705764, 'step': 5287500}
INFO:transformers.trainer:{'loss': 3.0526326040029526, 'learning_rate': 3.4126543864711084e-05, 'epoch': 0.9524073681173348, 'step': 5288000}
INFO:transformers.trainer:{'loss': 3.1314854300022126, 'learning_rate': 3.412504297059845e-05, 'epoch': 0.9524974217640934, 'step': 5288500}
INFO:transformers.trainer:{'loss': 3.070800068736076, 'learning_rate': 3.41235420764858e-05, 'epoch': 0.9525874754108518, 'step': 5289000}
INFO:transformers.trainer:{'loss': 3.103915508270264, 'learning_rate': 3.412204118237317e-05, 'epoch': 0.9526775290576102, 'step': 5289500}
INFO:transformers.trainer:{'loss': 3.149755034685135, 'learning_rate': 3.412054028826052e-05, 'epoch': 0.9527675827043687, 'step': 5290000}
INFO:transformers.trainer:{'loss': 3.1957723574638366, 'learning_rate': 3.4119039394147886e-05, 'epoch': 0.9528576363511271, 'step': 5290500}
INFO:transformers.trainer:{'loss': 3.174873010635376, 'learning_rate': 3.411753850003524e-05, 'epoch': 0.9529476899978856, 'step': 5291000}
INFO:transformers.trainer:{'loss': 3.09091919195652, 'learning_rate': 3.4116037605922604e-05, 'epoch': 0.953037743644644, 'step': 5291500}
INFO:transformers.trainer:{'loss': 3.0987930898666383, 'learning_rate': 3.411453671180996e-05, 'epoch': 0.9531277972914024, 'step': 5292000}
INFO:transformers.trainer:{'loss': 3.133606518507004, 'learning_rate': 3.411303581769732e-05, 'epoch': 0.9532178509381609, 'step': 5292500}
INFO:transformers.trainer:{'loss': 3.1410972561836243, 'learning_rate': 3.411153492358468e-05, 'epoch': 0.9533079045849193, 'step': 5293000}
INFO:transformers.trainer:{'loss': 3.121175487995148, 'learning_rate': 3.411003402947204e-05, 'epoch': 0.9533979582316777, 'step': 5293500}
INFO:transformers.trainer:{'loss': 3.1238216876983644, 'learning_rate': 3.41085331353594e-05, 'epoch': 0.9534880118784362, 'step': 5294000}
INFO:transformers.trainer:{'loss': 3.143953243732452, 'learning_rate': 3.410703224124676e-05, 'epoch': 0.9535780655251946, 'step': 5294500}
INFO:transformers.trainer:{'loss': 3.0768698779344557, 'learning_rate': 3.410553134713412e-05, 'epoch': 0.9536681191719532, 'step': 5295000}
INFO:transformers.trainer:{'loss': 3.141821273803711, 'learning_rate': 3.410403045302148e-05, 'epoch': 0.9537581728187116, 'step': 5295500}
INFO:transformers.trainer:{'loss': 3.1300514936447144, 'learning_rate': 3.4102529558908836e-05, 'epoch': 0.95384822646547, 'step': 5296000}
INFO:transformers.trainer:{'loss': 3.067430302262306, 'learning_rate': 3.4101028664796195e-05, 'epoch': 0.9539382801122285, 'step': 5296500}
INFO:transformers.trainer:{'loss': 3.0865364379882814, 'learning_rate': 3.4099527770683554e-05, 'epoch': 0.9540283337589869, 'step': 5297000}
INFO:transformers.trainer:{'loss': 3.131374618649483, 'learning_rate': 3.409802687657091e-05, 'epoch': 0.9541183874057454, 'step': 5297500}
INFO:transformers.trainer:{'loss': 3.0992772809267044, 'learning_rate': 3.409652598245827e-05, 'epoch': 0.9542084410525038, 'step': 5298000}
INFO:transformers.trainer:{'loss': 3.1019868824481964, 'learning_rate': 3.409502508834563e-05, 'epoch': 0.9542984946992622, 'step': 5298500}
INFO:transformers.trainer:{'loss': 3.148325900554657, 'learning_rate': 3.409352419423299e-05, 'epoch': 0.9543885483460207, 'step': 5299000}
INFO:transformers.trainer:{'loss': 3.16437594640255, 'learning_rate': 3.409202330012035e-05, 'epoch': 0.9544786019927791, 'step': 5299500}
INFO:transformers.trainer:{'loss': 3.0872809410095217, 'learning_rate': 3.409052240600771e-05, 'epoch': 0.9545686556395376, 'step': 5300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.173094928264618, 'learning_rate': 3.408902151189507e-05, 'epoch': 0.954658709286296, 'step': 5300500}
INFO:transformers.trainer:{'loss': 3.1367711625099184, 'learning_rate': 3.4087520617782426e-05, 'epoch': 0.9547487629330544, 'step': 5301000}
INFO:transformers.trainer:{'loss': 3.1515990331172943, 'learning_rate': 3.4086019723669785e-05, 'epoch': 0.954838816579813, 'step': 5301500}
INFO:transformers.trainer:{'loss': 3.1649603612422945, 'learning_rate': 3.4084518829557144e-05, 'epoch': 0.9549288702265714, 'step': 5302000}
INFO:transformers.trainer:{'loss': 3.098964381337166, 'learning_rate': 3.4083017935444503e-05, 'epoch': 0.9550189238733299, 'step': 5302500}
INFO:transformers.trainer:{'loss': 3.0808325510025023, 'learning_rate': 3.408151704133186e-05, 'epoch': 0.9551089775200883, 'step': 5303000}
INFO:transformers.trainer:{'loss': 3.1591320147514343, 'learning_rate': 3.408001614721922e-05, 'epoch': 0.9551990311668467, 'step': 5303500}
INFO:transformers.trainer:{'loss': 3.0778863530158995, 'learning_rate': 3.407851525310658e-05, 'epoch': 0.9552890848136052, 'step': 5304000}
INFO:transformers.trainer:{'loss': 3.06390641272068, 'learning_rate': 3.407701435899394e-05, 'epoch': 0.9553791384603636, 'step': 5304500}
INFO:transformers.trainer:{'loss': 3.164901379823685, 'learning_rate': 3.4075513464881305e-05, 'epoch': 0.955469192107122, 'step': 5305000}
INFO:transformers.trainer:{'loss': 3.0901732704639433, 'learning_rate': 3.407401257076866e-05, 'epoch': 0.9555592457538805, 'step': 5305500}
INFO:transformers.trainer:{'loss': 3.1055872347354887, 'learning_rate': 3.4072511676656024e-05, 'epoch': 0.9556492994006389, 'step': 5306000}
INFO:transformers.trainer:{'loss': 3.1412191972732546, 'learning_rate': 3.4071010782543376e-05, 'epoch': 0.9557393530473974, 'step': 5306500}
INFO:transformers.trainer:{'loss': 3.074767428278923, 'learning_rate': 3.406950988843074e-05, 'epoch': 0.9558294066941558, 'step': 5307000}
INFO:transformers.trainer:{'loss': 3.0077570474147794, 'learning_rate': 3.4068008994318094e-05, 'epoch': 0.9559194603409142, 'step': 5307500}
INFO:transformers.trainer:{'loss': 3.1081019245386123, 'learning_rate': 3.406650810020546e-05, 'epoch': 0.9560095139876728, 'step': 5308000}
INFO:transformers.trainer:{'loss': 3.0826625022888186, 'learning_rate': 3.406500720609281e-05, 'epoch': 0.9560995676344312, 'step': 5308500}
INFO:transformers.trainer:{'loss': 3.097317161798477, 'learning_rate': 3.406350631198018e-05, 'epoch': 0.9561896212811897, 'step': 5309000}
INFO:transformers.trainer:{'loss': 3.1479641329050065, 'learning_rate': 3.406200541786753e-05, 'epoch': 0.9562796749279481, 'step': 5309500}
INFO:transformers.trainer:{'loss': 3.129764285326004, 'learning_rate': 3.4060504523754896e-05, 'epoch': 0.9563697285747065, 'step': 5310000}
INFO:transformers.trainer:{'loss': 3.0871573281288147, 'learning_rate': 3.405900362964225e-05, 'epoch': 0.956459782221465, 'step': 5310500}
INFO:transformers.trainer:{'loss': 3.143506048202515, 'learning_rate': 3.4057502735529614e-05, 'epoch': 0.9565498358682234, 'step': 5311000}
INFO:transformers.trainer:{'loss': 3.078905622124672, 'learning_rate': 3.4056001841416966e-05, 'epoch': 0.9566398895149819, 'step': 5311500}
INFO:transformers.trainer:{'loss': 3.197377469539642, 'learning_rate': 3.405450094730433e-05, 'epoch': 0.9567299431617403, 'step': 5312000}
INFO:transformers.trainer:{'loss': 3.0983982384204865, 'learning_rate': 3.405300005319169e-05, 'epoch': 0.9568199968084987, 'step': 5312500}
INFO:transformers.trainer:{'loss': 3.11906451189518, 'learning_rate': 3.405149915907905e-05, 'epoch': 0.9569100504552572, 'step': 5313000}
INFO:transformers.trainer:{'loss': 3.1523055193424225, 'learning_rate': 3.404999826496641e-05, 'epoch': 0.9570001041020156, 'step': 5313500}
INFO:transformers.trainer:{'loss': 3.0386656645536423, 'learning_rate': 3.404849737085377e-05, 'epoch': 0.9570901577487742, 'step': 5314000}
INFO:transformers.trainer:{'loss': 3.0922241235971453, 'learning_rate': 3.404699647674113e-05, 'epoch': 0.9571802113955326, 'step': 5314500}
INFO:transformers.trainer:{'loss': 3.1164084278345108, 'learning_rate': 3.4045495582628486e-05, 'epoch': 0.957270265042291, 'step': 5315000}
INFO:transformers.trainer:{'loss': 3.137204526424408, 'learning_rate': 3.4043994688515845e-05, 'epoch': 0.9573603186890495, 'step': 5315500}
INFO:transformers.trainer:{'loss': 3.0657707197666166, 'learning_rate': 3.4042493794403205e-05, 'epoch': 0.9574503723358079, 'step': 5316000}
INFO:transformers.trainer:{'loss': 3.140678142786026, 'learning_rate': 3.4040992900290564e-05, 'epoch': 0.9575404259825663, 'step': 5316500}
INFO:transformers.trainer:{'loss': 3.1247584958076478, 'learning_rate': 3.403949200617792e-05, 'epoch': 0.9576304796293248, 'step': 5317000}
INFO:transformers.trainer:{'loss': 3.1524893274307253, 'learning_rate': 3.403799111206528e-05, 'epoch': 0.9577205332760832, 'step': 5317500}
INFO:transformers.trainer:{'loss': 3.0964135251045226, 'learning_rate': 3.403649021795264e-05, 'epoch': 0.9578105869228417, 'step': 5318000}
INFO:transformers.trainer:{'loss': 3.069366183757782, 'learning_rate': 3.403498932384e-05, 'epoch': 0.9579006405696001, 'step': 5318500}
INFO:transformers.trainer:{'loss': 3.1697813200950624, 'learning_rate': 3.403348842972736e-05, 'epoch': 0.9579906942163585, 'step': 5319000}
INFO:transformers.trainer:{'loss': 3.0658192937374116, 'learning_rate': 3.403198753561472e-05, 'epoch': 0.958080747863117, 'step': 5319500}
INFO:transformers.trainer:{'loss': 3.1234606659412383, 'learning_rate': 3.403048664150208e-05, 'epoch': 0.9581708015098754, 'step': 5320000}
INFO:transformers.trainer:{'loss': 3.1080343081951143, 'learning_rate': 3.4028985747389436e-05, 'epoch': 0.958260855156634, 'step': 5320500}
INFO:transformers.trainer:{'loss': 3.1154515150785445, 'learning_rate': 3.4027484853276795e-05, 'epoch': 0.9583509088033924, 'step': 5321000}
INFO:transformers.trainer:{'loss': 3.0911268430948255, 'learning_rate': 3.4025983959164154e-05, 'epoch': 0.9584409624501508, 'step': 5321500}
INFO:transformers.trainer:{'loss': 3.1581334242820738, 'learning_rate': 3.402448306505151e-05, 'epoch': 0.9585310160969093, 'step': 5322000}
INFO:transformers.trainer:{'loss': 3.0782509007453918, 'learning_rate': 3.402298217093887e-05, 'epoch': 0.9586210697436677, 'step': 5322500}
INFO:transformers.trainer:{'loss': 3.1327275185585024, 'learning_rate': 3.402148127682623e-05, 'epoch': 0.9587111233904262, 'step': 5323000}
INFO:transformers.trainer:{'loss': 3.1045302991867065, 'learning_rate': 3.401998038271359e-05, 'epoch': 0.9588011770371846, 'step': 5323500}
INFO:transformers.trainer:{'loss': 3.1461189048290255, 'learning_rate': 3.401847948860095e-05, 'epoch': 0.958891230683943, 'step': 5324000}
INFO:transformers.trainer:{'loss': 3.195958996772766, 'learning_rate': 3.401697859448831e-05, 'epoch': 0.9589812843307015, 'step': 5324500}
INFO:transformers.trainer:{'loss': 3.179776129245758, 'learning_rate': 3.401547770037567e-05, 'epoch': 0.9590713379774599, 'step': 5325000}
INFO:transformers.trainer:{'loss': 3.120455104470253, 'learning_rate': 3.4013976806263026e-05, 'epoch': 0.9591613916242184, 'step': 5325500}
INFO:transformers.trainer:{'loss': 3.1558041524887086, 'learning_rate': 3.4012475912150386e-05, 'epoch': 0.9592514452709768, 'step': 5326000}
INFO:transformers.trainer:{'loss': 3.0753313558101656, 'learning_rate': 3.401097501803775e-05, 'epoch': 0.9593414989177352, 'step': 5326500}
INFO:transformers.trainer:{'loss': 3.1291162571907045, 'learning_rate': 3.4009474123925104e-05, 'epoch': 0.9594315525644938, 'step': 5327000}
INFO:transformers.trainer:{'loss': 3.074198459625244, 'learning_rate': 3.400797322981247e-05, 'epoch': 0.9595216062112522, 'step': 5327500}
INFO:transformers.trainer:{'loss': 3.0578735359311104, 'learning_rate': 3.400647233569982e-05, 'epoch': 0.9596116598580107, 'step': 5328000}
INFO:transformers.trainer:{'loss': 3.020510913491249, 'learning_rate': 3.400497144158719e-05, 'epoch': 0.9597017135047691, 'step': 5328500}
INFO:transformers.trainer:{'loss': 3.129932660698891, 'learning_rate': 3.400347054747454e-05, 'epoch': 0.9597917671515275, 'step': 5329000}
INFO:transformers.trainer:{'loss': 3.096790524959564, 'learning_rate': 3.4001969653361906e-05, 'epoch': 0.959881820798286, 'step': 5329500}
INFO:transformers.trainer:{'loss': 3.0860634725093843, 'learning_rate': 3.400046875924926e-05, 'epoch': 0.9599718744450444, 'step': 5330000}
INFO:transformers.trainer:{'loss': 3.105775633215904, 'learning_rate': 3.3998967865136624e-05, 'epoch': 0.9600619280918028, 'step': 5330500}
INFO:transformers.trainer:{'loss': 3.0583580968379973, 'learning_rate': 3.3997466971023976e-05, 'epoch': 0.9601519817385613, 'step': 5331000}
INFO:transformers.trainer:{'loss': 3.0865616235733033, 'learning_rate': 3.399596607691134e-05, 'epoch': 0.9602420353853197, 'step': 5331500}
INFO:transformers.trainer:{'loss': 3.1196108860969542, 'learning_rate': 3.3994465182798694e-05, 'epoch': 0.9603320890320782, 'step': 5332000}
INFO:transformers.trainer:{'loss': 3.112484523534775, 'learning_rate': 3.399296428868606e-05, 'epoch': 0.9604221426788366, 'step': 5332500}
INFO:transformers.trainer:{'loss': 3.1327898119688036, 'learning_rate': 3.399146339457342e-05, 'epoch': 0.960512196325595, 'step': 5333000}
INFO:transformers.trainer:{'loss': 3.1002484245300295, 'learning_rate': 3.398996250046078e-05, 'epoch': 0.9606022499723536, 'step': 5333500}
INFO:transformers.trainer:{'loss': 3.0980958743095397, 'learning_rate': 3.398846160634814e-05, 'epoch': 0.960692303619112, 'step': 5334000}
INFO:transformers.trainer:{'loss': 3.1352224566936493, 'learning_rate': 3.3986960712235496e-05, 'epoch': 0.9607823572658705, 'step': 5334500}
INFO:transformers.trainer:{'loss': 3.173565059542656, 'learning_rate': 3.3985459818122855e-05, 'epoch': 0.9608724109126289, 'step': 5335000}
INFO:transformers.trainer:{'loss': 3.082326399087906, 'learning_rate': 3.3983958924010214e-05, 'epoch': 0.9609624645593873, 'step': 5335500}
INFO:transformers.trainer:{'loss': 3.190097241640091, 'learning_rate': 3.398245802989757e-05, 'epoch': 0.9610525182061458, 'step': 5336000}
INFO:transformers.trainer:{'loss': 3.097803159356117, 'learning_rate': 3.398095713578493e-05, 'epoch': 0.9611425718529042, 'step': 5336500}
INFO:transformers.trainer:{'loss': 3.107729729294777, 'learning_rate': 3.397945624167229e-05, 'epoch': 0.9612326254996627, 'step': 5337000}
INFO:transformers.trainer:{'loss': 3.140723599076271, 'learning_rate': 3.397795534755965e-05, 'epoch': 0.9613226791464211, 'step': 5337500}
INFO:transformers.trainer:{'loss': 3.1278105804920195, 'learning_rate': 3.397645445344701e-05, 'epoch': 0.9614127327931795, 'step': 5338000}
INFO:transformers.trainer:{'loss': 3.128197541952133, 'learning_rate': 3.397495355933437e-05, 'epoch': 0.961502786439938, 'step': 5338500}
INFO:transformers.trainer:{'loss': 3.1438266596794127, 'learning_rate': 3.397345266522173e-05, 'epoch': 0.9615928400866964, 'step': 5339000}
INFO:transformers.trainer:{'loss': 3.0948964258432388, 'learning_rate': 3.397195177110909e-05, 'epoch': 0.961682893733455, 'step': 5339500}
INFO:transformers.trainer:{'loss': 3.1860047137737273, 'learning_rate': 3.3970450876996446e-05, 'epoch': 0.9617729473802133, 'step': 5340000}
INFO:transformers.trainer:{'loss': 3.1514563384056093, 'learning_rate': 3.3968949982883805e-05, 'epoch': 0.9618630010269718, 'step': 5340500}
INFO:transformers.trainer:{'loss': 3.0295034618377685, 'learning_rate': 3.3967449088771164e-05, 'epoch': 0.9619530546737303, 'step': 5341000}
INFO:transformers.trainer:{'loss': 3.1415130667686464, 'learning_rate': 3.396594819465852e-05, 'epoch': 0.9620431083204887, 'step': 5341500}
INFO:transformers.trainer:{'loss': 3.101290806055069, 'learning_rate': 3.396444730054588e-05, 'epoch': 0.9621331619672471, 'step': 5342000}
INFO:transformers.trainer:{'loss': 3.072339822769165, 'learning_rate': 3.396294640643324e-05, 'epoch': 0.9622232156140056, 'step': 5342500}
INFO:transformers.trainer:{'loss': 3.096817090034485, 'learning_rate': 3.39614455123206e-05, 'epoch': 0.962313269260764, 'step': 5343000}
INFO:transformers.trainer:{'loss': 3.131972789287567, 'learning_rate': 3.395994461820796e-05, 'epoch': 0.9624033229075225, 'step': 5343500}
INFO:transformers.trainer:{'loss': 3.144970300912857, 'learning_rate': 3.395844372409532e-05, 'epoch': 0.9624933765542809, 'step': 5344000}
INFO:transformers.trainer:{'loss': 3.076554010391235, 'learning_rate': 3.395694282998268e-05, 'epoch': 0.9625834302010393, 'step': 5344500}
INFO:transformers.trainer:{'loss': 3.190475129842758, 'learning_rate': 3.3955441935870036e-05, 'epoch': 0.9626734838477978, 'step': 5345000}
INFO:transformers.trainer:{'loss': 3.1281104350090025, 'learning_rate': 3.3953941041757395e-05, 'epoch': 0.9627635374945562, 'step': 5345500}
INFO:transformers.trainer:{'loss': 3.105291745901108, 'learning_rate': 3.3952440147644754e-05, 'epoch': 0.9628535911413147, 'step': 5346000}
INFO:transformers.trainer:{'loss': 3.114137612581253, 'learning_rate': 3.395093925353211e-05, 'epoch': 0.9629436447880731, 'step': 5346500}
INFO:transformers.trainer:{'loss': 3.1023149862289428, 'learning_rate': 3.394943835941948e-05, 'epoch': 0.9630336984348316, 'step': 5347000}
INFO:transformers.trainer:{'loss': 3.1011973136663435, 'learning_rate': 3.394793746530683e-05, 'epoch': 0.9631237520815901, 'step': 5347500}
INFO:transformers.trainer:{'loss': 3.159615969181061, 'learning_rate': 3.39464365711942e-05, 'epoch': 0.9632138057283485, 'step': 5348000}
INFO:transformers.trainer:{'loss': 3.141937204837799, 'learning_rate': 3.394493567708155e-05, 'epoch': 0.963303859375107, 'step': 5348500}
INFO:transformers.trainer:{'loss': 3.123751456975937, 'learning_rate': 3.3943434782968915e-05, 'epoch': 0.9633939130218654, 'step': 5349000}
INFO:transformers.trainer:{'loss': 3.1150333006381987, 'learning_rate': 3.394193388885627e-05, 'epoch': 0.9634839666686238, 'step': 5349500}
INFO:transformers.trainer:{'loss': 3.107296116352081, 'learning_rate': 3.3940432994743633e-05, 'epoch': 0.9635740203153823, 'step': 5350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.110735588669777, 'learning_rate': 3.3938932100630986e-05, 'epoch': 0.9636640739621407, 'step': 5350500}
INFO:transformers.trainer:{'loss': 3.0738666014671328, 'learning_rate': 3.393743120651835e-05, 'epoch': 0.9637541276088992, 'step': 5351000}
INFO:transformers.trainer:{'loss': 3.014219540834427, 'learning_rate': 3.3935930312405704e-05, 'epoch': 0.9638441812556576, 'step': 5351500}
INFO:transformers.trainer:{'loss': 3.1221550738811494, 'learning_rate': 3.393442941829307e-05, 'epoch': 0.963934234902416, 'step': 5352000}
INFO:transformers.trainer:{'loss': 3.0726690356731416, 'learning_rate': 3.393292852418042e-05, 'epoch': 0.9640242885491745, 'step': 5352500}
INFO:transformers.trainer:{'loss': 3.157231795668602, 'learning_rate': 3.393142763006779e-05, 'epoch': 0.964114342195933, 'step': 5353000}
INFO:transformers.trainer:{'loss': 3.1445357481241225, 'learning_rate': 3.392992673595515e-05, 'epoch': 0.9642043958426914, 'step': 5353500}
INFO:transformers.trainer:{'loss': 3.0941920771598816, 'learning_rate': 3.3928425841842506e-05, 'epoch': 0.9642944494894499, 'step': 5354000}
INFO:transformers.trainer:{'loss': 3.167012666940689, 'learning_rate': 3.3926924947729865e-05, 'epoch': 0.9643845031362083, 'step': 5354500}
INFO:transformers.trainer:{'loss': 3.0536198337078093, 'learning_rate': 3.3925424053617224e-05, 'epoch': 0.9644745567829668, 'step': 5355000}
INFO:transformers.trainer:{'loss': 3.1527144997119905, 'learning_rate': 3.392392315950458e-05, 'epoch': 0.9645646104297252, 'step': 5355500}
INFO:transformers.trainer:{'loss': 3.1037839367389677, 'learning_rate': 3.392242226539194e-05, 'epoch': 0.9646546640764836, 'step': 5356000}
INFO:transformers.trainer:{'loss': 3.1032503442764283, 'learning_rate': 3.39209213712793e-05, 'epoch': 0.9647447177232421, 'step': 5356500}
INFO:transformers.trainer:{'loss': 3.115870479106903, 'learning_rate': 3.391942047716666e-05, 'epoch': 0.9648347713700005, 'step': 5357000}
INFO:transformers.trainer:{'loss': 3.106145581007004, 'learning_rate': 3.391791958305402e-05, 'epoch': 0.964924825016759, 'step': 5357500}
INFO:transformers.trainer:{'loss': 3.1464461290836336, 'learning_rate': 3.391641868894138e-05, 'epoch': 0.9650148786635174, 'step': 5358000}
INFO:transformers.trainer:{'loss': 3.190877016544342, 'learning_rate': 3.391491779482874e-05, 'epoch': 0.9651049323102758, 'step': 5358500}
INFO:transformers.trainer:{'loss': 3.091142534375191, 'learning_rate': 3.3913416900716096e-05, 'epoch': 0.9651949859570343, 'step': 5359000}
INFO:transformers.trainer:{'loss': 3.149923301696777, 'learning_rate': 3.3911916006603455e-05, 'epoch': 0.9652850396037927, 'step': 5359500}
INFO:transformers.trainer:{'loss': 3.1656503891944885, 'learning_rate': 3.3910415112490814e-05, 'epoch': 0.9653750932505513, 'step': 5360000}
INFO:transformers.trainer:{'loss': 3.1607842807769777, 'learning_rate': 3.3908914218378174e-05, 'epoch': 0.9654651468973097, 'step': 5360500}
INFO:transformers.trainer:{'loss': 3.140590090751648, 'learning_rate': 3.390741332426553e-05, 'epoch': 0.9655552005440681, 'step': 5361000}
INFO:transformers.trainer:{'loss': 3.071178790092468, 'learning_rate': 3.390591243015289e-05, 'epoch': 0.9656452541908266, 'step': 5361500}
INFO:transformers.trainer:{'loss': 3.0972860295772553, 'learning_rate': 3.390441153604025e-05, 'epoch': 0.965735307837585, 'step': 5362000}
INFO:transformers.trainer:{'loss': 3.0891426482200623, 'learning_rate': 3.390291064192761e-05, 'epoch': 0.9658253614843435, 'step': 5362500}
INFO:transformers.trainer:{'loss': 3.174428129553795, 'learning_rate': 3.390140974781497e-05, 'epoch': 0.9659154151311019, 'step': 5363000}
INFO:transformers.trainer:{'loss': 3.135284227371216, 'learning_rate': 3.389990885370233e-05, 'epoch': 0.9660054687778603, 'step': 5363500}
INFO:transformers.trainer:{'loss': 3.138280019521713, 'learning_rate': 3.389840795958969e-05, 'epoch': 0.9660955224246188, 'step': 5364000}
INFO:transformers.trainer:{'loss': 3.1652070016860963, 'learning_rate': 3.3896907065477046e-05, 'epoch': 0.9661855760713772, 'step': 5364500}
INFO:transformers.trainer:{'loss': 3.2318905639648436, 'learning_rate': 3.3895406171364405e-05, 'epoch': 0.9662756297181357, 'step': 5365000}
INFO:transformers.trainer:{'loss': 3.1143342597484587, 'learning_rate': 3.3893905277251764e-05, 'epoch': 0.9663656833648941, 'step': 5365500}
INFO:transformers.trainer:{'loss': 3.1147103431224825, 'learning_rate': 3.389240438313912e-05, 'epoch': 0.9664557370116525, 'step': 5366000}
INFO:transformers.trainer:{'loss': 3.1565125949382784, 'learning_rate': 3.389090348902648e-05, 'epoch': 0.9665457906584111, 'step': 5366500}
INFO:transformers.trainer:{'loss': 3.181767592668533, 'learning_rate': 3.388940259491384e-05, 'epoch': 0.9666358443051695, 'step': 5367000}
INFO:transformers.trainer:{'loss': 3.110543222904205, 'learning_rate': 3.388790170080121e-05, 'epoch': 0.9667258979519279, 'step': 5367500}
INFO:transformers.trainer:{'loss': 3.1026148128509523, 'learning_rate': 3.388640080668856e-05, 'epoch': 0.9668159515986864, 'step': 5368000}
INFO:transformers.trainer:{'loss': 3.11535898566246, 'learning_rate': 3.3884899912575925e-05, 'epoch': 0.9669060052454448, 'step': 5368500}
INFO:transformers.trainer:{'loss': 3.0545846235752108, 'learning_rate': 3.388339901846328e-05, 'epoch': 0.9669960588922033, 'step': 5369000}
INFO:transformers.trainer:{'loss': 3.185750926017761, 'learning_rate': 3.388189812435064e-05, 'epoch': 0.9670861125389617, 'step': 5369500}
INFO:transformers.trainer:{'loss': 3.0867095263004303, 'learning_rate': 3.3880397230237995e-05, 'epoch': 0.9671761661857201, 'step': 5370000}
INFO:transformers.trainer:{'loss': 3.1466439216136934, 'learning_rate': 3.387889633612536e-05, 'epoch': 0.9672662198324786, 'step': 5370500}
INFO:transformers.trainer:{'loss': 3.114968923449516, 'learning_rate': 3.3877395442012714e-05, 'epoch': 0.967356273479237, 'step': 5371000}
INFO:transformers.trainer:{'loss': 3.1001302696466446, 'learning_rate': 3.387589454790008e-05, 'epoch': 0.9674463271259955, 'step': 5371500}
INFO:transformers.trainer:{'loss': 3.0862434043884277, 'learning_rate': 3.387439365378743e-05, 'epoch': 0.967536380772754, 'step': 5372000}
INFO:transformers.trainer:{'loss': 3.146289506196976, 'learning_rate': 3.38728927596748e-05, 'epoch': 0.9676264344195123, 'step': 5372500}
INFO:transformers.trainer:{'loss': 3.1407570593357086, 'learning_rate': 3.387139186556215e-05, 'epoch': 0.9677164880662709, 'step': 5373000}
INFO:transformers.trainer:{'loss': 3.0852402355670927, 'learning_rate': 3.3869890971449516e-05, 'epoch': 0.9678065417130293, 'step': 5373500}
INFO:transformers.trainer:{'loss': 3.123218726873398, 'learning_rate': 3.386839007733687e-05, 'epoch': 0.9678965953597878, 'step': 5374000}
INFO:transformers.trainer:{'loss': 3.0922780623435973, 'learning_rate': 3.3866889183224234e-05, 'epoch': 0.9679866490065462, 'step': 5374500}
INFO:transformers.trainer:{'loss': 3.1279964628219603, 'learning_rate': 3.386538828911159e-05, 'epoch': 0.9680767026533046, 'step': 5375000}
INFO:transformers.trainer:{'loss': 3.1067761857509613, 'learning_rate': 3.386388739499895e-05, 'epoch': 0.9681667563000631, 'step': 5375500}
INFO:transformers.trainer:{'loss': 3.072959513425827, 'learning_rate': 3.386238650088631e-05, 'epoch': 0.9682568099468215, 'step': 5376000}
INFO:transformers.trainer:{'loss': 3.1128843705654146, 'learning_rate': 3.386088560677367e-05, 'epoch': 0.96834686359358, 'step': 5376500}
INFO:transformers.trainer:{'loss': 3.108225506782532, 'learning_rate': 3.385938471266103e-05, 'epoch': 0.9684369172403384, 'step': 5377000}
INFO:transformers.trainer:{'loss': 3.137458706974983, 'learning_rate': 3.385788381854839e-05, 'epoch': 0.9685269708870968, 'step': 5377500}
INFO:transformers.trainer:{'loss': 3.070298429727554, 'learning_rate': 3.385638292443575e-05, 'epoch': 0.9686170245338553, 'step': 5378000}
INFO:transformers.trainer:{'loss': 3.0878910155296326, 'learning_rate': 3.3854882030323106e-05, 'epoch': 0.9687070781806137, 'step': 5378500}
INFO:transformers.trainer:{'loss': 3.0983700964450835, 'learning_rate': 3.3853381136210465e-05, 'epoch': 0.9687971318273721, 'step': 5379000}
INFO:transformers.trainer:{'loss': 3.0960214557647707, 'learning_rate': 3.3851880242097824e-05, 'epoch': 0.9688871854741307, 'step': 5379500}
INFO:transformers.trainer:{'loss': 3.066548653960228, 'learning_rate': 3.385037934798518e-05, 'epoch': 0.9689772391208891, 'step': 5380000}
INFO:transformers.trainer:{'loss': 3.1271821765899657, 'learning_rate': 3.384887845387254e-05, 'epoch': 0.9690672927676476, 'step': 5380500}
INFO:transformers.trainer:{'loss': 3.105370089173317, 'learning_rate': 3.38473775597599e-05, 'epoch': 0.969157346414406, 'step': 5381000}
INFO:transformers.trainer:{'loss': 3.079236216545105, 'learning_rate': 3.384587666564726e-05, 'epoch': 0.9692474000611644, 'step': 5381500}
INFO:transformers.trainer:{'loss': 3.109829712510109, 'learning_rate': 3.384437577153462e-05, 'epoch': 0.9693374537079229, 'step': 5382000}
INFO:transformers.trainer:{'loss': 3.078907230257988, 'learning_rate': 3.384287487742198e-05, 'epoch': 0.9694275073546813, 'step': 5382500}
INFO:transformers.trainer:{'loss': 3.0516840748786924, 'learning_rate': 3.384137398330934e-05, 'epoch': 0.9695175610014398, 'step': 5383000}
INFO:transformers.trainer:{'loss': 3.126562198638916, 'learning_rate': 3.3839873089196697e-05, 'epoch': 0.9696076146481982, 'step': 5383500}
INFO:transformers.trainer:{'loss': 3.121222389817238, 'learning_rate': 3.3838372195084056e-05, 'epoch': 0.9696976682949566, 'step': 5384000}
INFO:transformers.trainer:{'loss': 3.127260568857193, 'learning_rate': 3.3836871300971415e-05, 'epoch': 0.9697877219417151, 'step': 5384500}
INFO:transformers.trainer:{'loss': 3.110526371717453, 'learning_rate': 3.3835370406858774e-05, 'epoch': 0.9698777755884735, 'step': 5385000}
INFO:transformers.trainer:{'loss': 3.1236182091236113, 'learning_rate': 3.383386951274613e-05, 'epoch': 0.9699678292352321, 'step': 5385500}
INFO:transformers.trainer:{'loss': 3.158601017475128, 'learning_rate': 3.383236861863349e-05, 'epoch': 0.9700578828819905, 'step': 5386000}
INFO:transformers.trainer:{'loss': 3.1485364921092986, 'learning_rate': 3.383086772452085e-05, 'epoch': 0.9701479365287489, 'step': 5386500}
INFO:transformers.trainer:{'loss': 3.0857803883552553, 'learning_rate': 3.382936683040821e-05, 'epoch': 0.9702379901755074, 'step': 5387000}
INFO:transformers.trainer:{'loss': 3.1269350193738936, 'learning_rate': 3.382786593629557e-05, 'epoch': 0.9703280438222658, 'step': 5387500}
INFO:transformers.trainer:{'loss': 3.0813759746551512, 'learning_rate': 3.382636504218293e-05, 'epoch': 0.9704180974690243, 'step': 5388000}
INFO:transformers.trainer:{'loss': 3.1368410861492158, 'learning_rate': 3.382486414807029e-05, 'epoch': 0.9705081511157827, 'step': 5388500}
INFO:transformers.trainer:{'loss': 3.1102969772815703, 'learning_rate': 3.382336325395765e-05, 'epoch': 0.9705982047625411, 'step': 5389000}
INFO:transformers.trainer:{'loss': 3.091852034330368, 'learning_rate': 3.3821862359845005e-05, 'epoch': 0.9706882584092996, 'step': 5389500}
INFO:transformers.trainer:{'loss': 3.098418834209442, 'learning_rate': 3.382036146573237e-05, 'epoch': 0.970778312056058, 'step': 5390000}
INFO:transformers.trainer:{'loss': 3.131784945011139, 'learning_rate': 3.381886057161972e-05, 'epoch': 0.9708683657028164, 'step': 5390500}
INFO:transformers.trainer:{'loss': 3.1532449059486387, 'learning_rate': 3.381735967750709e-05, 'epoch': 0.9709584193495749, 'step': 5391000}
INFO:transformers.trainer:{'loss': 3.1373795632123946, 'learning_rate': 3.381585878339444e-05, 'epoch': 0.9710484729963333, 'step': 5391500}
INFO:transformers.trainer:{'loss': 3.1292371695041656, 'learning_rate': 3.381435788928181e-05, 'epoch': 0.9711385266430919, 'step': 5392000}
INFO:transformers.trainer:{'loss': 3.1440316033363342, 'learning_rate': 3.381285699516916e-05, 'epoch': 0.9712285802898503, 'step': 5392500}
INFO:transformers.trainer:{'loss': 3.0950234508514405, 'learning_rate': 3.3811356101056525e-05, 'epoch': 0.9713186339366087, 'step': 5393000}
INFO:transformers.trainer:{'loss': 3.0911233196258543, 'learning_rate': 3.380985520694388e-05, 'epoch': 0.9714086875833672, 'step': 5393500}
INFO:transformers.trainer:{'loss': 3.1080012531280516, 'learning_rate': 3.3808354312831243e-05, 'epoch': 0.9714987412301256, 'step': 5394000}
INFO:transformers.trainer:{'loss': 3.115526276111603, 'learning_rate': 3.3806853418718596e-05, 'epoch': 0.9715887948768841, 'step': 5394500}
INFO:transformers.trainer:{'loss': 3.053658319711685, 'learning_rate': 3.380535252460596e-05, 'epoch': 0.9716788485236425, 'step': 5395000}
INFO:transformers.trainer:{'loss': 3.108257229089737, 'learning_rate': 3.380385163049332e-05, 'epoch': 0.9717689021704009, 'step': 5395500}
INFO:transformers.trainer:{'loss': 3.1063951094150544, 'learning_rate': 3.380235073638068e-05, 'epoch': 0.9718589558171594, 'step': 5396000}
INFO:transformers.trainer:{'loss': 3.0934838675260545, 'learning_rate': 3.380084984226804e-05, 'epoch': 0.9719490094639178, 'step': 5396500}
INFO:transformers.trainer:{'loss': 3.1018693833351136, 'learning_rate': 3.37993489481554e-05, 'epoch': 0.9720390631106763, 'step': 5397000}
INFO:transformers.trainer:{'loss': 3.091459108233452, 'learning_rate': 3.379784805404276e-05, 'epoch': 0.9721291167574347, 'step': 5397500}
INFO:transformers.trainer:{'loss': 3.106009231567383, 'learning_rate': 3.3796347159930116e-05, 'epoch': 0.9722191704041931, 'step': 5398000}
INFO:transformers.trainer:{'loss': 3.0969638470411303, 'learning_rate': 3.3794846265817475e-05, 'epoch': 0.9723092240509517, 'step': 5398500}
INFO:transformers.trainer:{'loss': 3.092454047679901, 'learning_rate': 3.3793345371704834e-05, 'epoch': 0.9723992776977101, 'step': 5399000}
INFO:transformers.trainer:{'loss': 3.114430720806122, 'learning_rate': 3.379184447759219e-05, 'epoch': 0.9724893313444686, 'step': 5399500}
INFO:transformers.trainer:{'loss': 3.1610940573215482, 'learning_rate': 3.379034358347955e-05, 'epoch': 0.972579384991227, 'step': 5400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0943492603302003, 'learning_rate': 3.378884268936691e-05, 'epoch': 0.9726694386379854, 'step': 5400500}
INFO:transformers.trainer:{'loss': 3.156978235721588, 'learning_rate': 3.378734179525427e-05, 'epoch': 0.9727594922847439, 'step': 5401000}
INFO:transformers.trainer:{'loss': 3.116989775776863, 'learning_rate': 3.378584090114163e-05, 'epoch': 0.9728495459315023, 'step': 5401500}
INFO:transformers.trainer:{'loss': 3.1443639419078826, 'learning_rate': 3.378434000702899e-05, 'epoch': 0.9729395995782608, 'step': 5402000}
INFO:transformers.trainer:{'loss': 3.1239672448635103, 'learning_rate': 3.378283911291635e-05, 'epoch': 0.9730296532250192, 'step': 5402500}
INFO:transformers.trainer:{'loss': 3.068677972793579, 'learning_rate': 3.378133821880371e-05, 'epoch': 0.9731197068717776, 'step': 5403000}
INFO:transformers.trainer:{'loss': 3.095251187324524, 'learning_rate': 3.3779837324691065e-05, 'epoch': 0.9732097605185361, 'step': 5403500}
INFO:transformers.trainer:{'loss': 3.1133697056770324, 'learning_rate': 3.3778336430578424e-05, 'epoch': 0.9732998141652945, 'step': 5404000}
INFO:transformers.trainer:{'loss': 3.092467799782753, 'learning_rate': 3.3776835536465783e-05, 'epoch': 0.973389867812053, 'step': 5404500}
INFO:transformers.trainer:{'loss': 3.1608066074848176, 'learning_rate': 3.377533464235314e-05, 'epoch': 0.9734799214588115, 'step': 5405000}
INFO:transformers.trainer:{'loss': 3.190453086137772, 'learning_rate': 3.37738337482405e-05, 'epoch': 0.9735699751055699, 'step': 5405500}
INFO:transformers.trainer:{'loss': 3.058261193394661, 'learning_rate': 3.377233285412786e-05, 'epoch': 0.9736600287523284, 'step': 5406000}
INFO:transformers.trainer:{'loss': 3.109861754655838, 'learning_rate': 3.377083196001522e-05, 'epoch': 0.9737500823990868, 'step': 5406500}
INFO:transformers.trainer:{'loss': 3.198784411430359, 'learning_rate': 3.376933106590258e-05, 'epoch': 0.9738401360458452, 'step': 5407000}
INFO:transformers.trainer:{'loss': 3.2131472399234773, 'learning_rate': 3.376783017178994e-05, 'epoch': 0.9739301896926037, 'step': 5407500}
INFO:transformers.trainer:{'loss': 3.1164773547649385, 'learning_rate': 3.37663292776773e-05, 'epoch': 0.9740202433393621, 'step': 5408000}
INFO:transformers.trainer:{'loss': 3.1325283912420274, 'learning_rate': 3.3764828383564656e-05, 'epoch': 0.9741102969861206, 'step': 5408500}
INFO:transformers.trainer:{'loss': 3.2164142651557923, 'learning_rate': 3.3763327489452015e-05, 'epoch': 0.974200350632879, 'step': 5409000}
INFO:transformers.trainer:{'loss': 3.1153210866451264, 'learning_rate': 3.376182659533938e-05, 'epoch': 0.9742904042796374, 'step': 5409500}
INFO:transformers.trainer:{'loss': 3.112414082765579, 'learning_rate': 3.376032570122673e-05, 'epoch': 0.9743804579263959, 'step': 5410000}
INFO:transformers.trainer:{'loss': 3.1060878759622574, 'learning_rate': 3.37588248071141e-05, 'epoch': 0.9744705115731543, 'step': 5410500}
INFO:transformers.trainer:{'loss': 3.0924435601234435, 'learning_rate': 3.375732391300145e-05, 'epoch': 0.9745605652199129, 'step': 5411000}
INFO:transformers.trainer:{'loss': 3.126606711268425, 'learning_rate': 3.375582301888882e-05, 'epoch': 0.9746506188666713, 'step': 5411500}
INFO:transformers.trainer:{'loss': 3.105315998673439, 'learning_rate': 3.375432212477617e-05, 'epoch': 0.9747406725134297, 'step': 5412000}
INFO:transformers.trainer:{'loss': 3.126879811525345, 'learning_rate': 3.3752821230663535e-05, 'epoch': 0.9748307261601882, 'step': 5412500}
INFO:transformers.trainer:{'loss': 3.1240847902297975, 'learning_rate': 3.375132033655089e-05, 'epoch': 0.9749207798069466, 'step': 5413000}
INFO:transformers.trainer:{'loss': 3.109625922203064, 'learning_rate': 3.374981944243825e-05, 'epoch': 0.9750108334537051, 'step': 5413500}
INFO:transformers.trainer:{'loss': 3.042936049461365, 'learning_rate': 3.3748318548325605e-05, 'epoch': 0.9751008871004635, 'step': 5414000}
INFO:transformers.trainer:{'loss': 3.103260444879532, 'learning_rate': 3.374681765421297e-05, 'epoch': 0.9751909407472219, 'step': 5414500}
INFO:transformers.trainer:{'loss': 3.1974828782081604, 'learning_rate': 3.3745316760100324e-05, 'epoch': 0.9752809943939804, 'step': 5415000}
INFO:transformers.trainer:{'loss': 3.116513673186302, 'learning_rate': 3.374381586598769e-05, 'epoch': 0.9753710480407388, 'step': 5415500}
INFO:transformers.trainer:{'loss': 3.1219192786216734, 'learning_rate': 3.374231497187505e-05, 'epoch': 0.9754611016874972, 'step': 5416000}
INFO:transformers.trainer:{'loss': 3.1285402808189393, 'learning_rate': 3.374081407776241e-05, 'epoch': 0.9755511553342557, 'step': 5416500}
INFO:transformers.trainer:{'loss': 3.1414466774463654, 'learning_rate': 3.3739313183649767e-05, 'epoch': 0.9756412089810141, 'step': 5417000}
INFO:transformers.trainer:{'loss': 3.174779199719429, 'learning_rate': 3.3737812289537126e-05, 'epoch': 0.9757312626277727, 'step': 5417500}
INFO:transformers.trainer:{'loss': 3.129302048444748, 'learning_rate': 3.3736311395424485e-05, 'epoch': 0.9758213162745311, 'step': 5418000}
INFO:transformers.trainer:{'loss': 3.0796630733013153, 'learning_rate': 3.3734810501311844e-05, 'epoch': 0.9759113699212895, 'step': 5418500}
INFO:transformers.trainer:{'loss': 3.1558260082006453, 'learning_rate': 3.37333096071992e-05, 'epoch': 0.976001423568048, 'step': 5419000}
INFO:transformers.trainer:{'loss': 3.1352783629894256, 'learning_rate': 3.373180871308656e-05, 'epoch': 0.9760914772148064, 'step': 5419500}
INFO:transformers.trainer:{'loss': 3.118656808376312, 'learning_rate': 3.373030781897392e-05, 'epoch': 0.9761815308615649, 'step': 5420000}
INFO:transformers.trainer:{'loss': 3.1084566133022307, 'learning_rate': 3.372880692486128e-05, 'epoch': 0.9762715845083233, 'step': 5420500}
INFO:transformers.trainer:{'loss': 3.134891487598419, 'learning_rate': 3.372730603074864e-05, 'epoch': 0.9763616381550817, 'step': 5421000}
INFO:transformers.trainer:{'loss': 3.140734064102173, 'learning_rate': 3.3725805136636e-05, 'epoch': 0.9764516918018402, 'step': 5421500}
INFO:transformers.trainer:{'loss': 3.085851279377937, 'learning_rate': 3.372430424252336e-05, 'epoch': 0.9765417454485986, 'step': 5422000}
INFO:transformers.trainer:{'loss': 3.1247696042060853, 'learning_rate': 3.3722803348410716e-05, 'epoch': 0.9766317990953571, 'step': 5422500}
INFO:transformers.trainer:{'loss': 3.0450572476387023, 'learning_rate': 3.3721302454298075e-05, 'epoch': 0.9767218527421155, 'step': 5423000}
INFO:transformers.trainer:{'loss': 3.111850208759308, 'learning_rate': 3.371980156018544e-05, 'epoch': 0.9768119063888739, 'step': 5423500}
INFO:transformers.trainer:{'loss': 3.0853628852367403, 'learning_rate': 3.371830066607279e-05, 'epoch': 0.9769019600356325, 'step': 5424000}
INFO:transformers.trainer:{'loss': 3.0858718793392184, 'learning_rate': 3.371679977196016e-05, 'epoch': 0.9769920136823909, 'step': 5424500}
INFO:transformers.trainer:{'loss': 3.0776114808321, 'learning_rate': 3.371529887784751e-05, 'epoch': 0.9770820673291494, 'step': 5425000}
INFO:transformers.trainer:{'loss': 3.1424882664680482, 'learning_rate': 3.371379798373488e-05, 'epoch': 0.9771721209759078, 'step': 5425500}
INFO:transformers.trainer:{'loss': 3.1208059937953947, 'learning_rate': 3.371229708962223e-05, 'epoch': 0.9772621746226662, 'step': 5426000}
INFO:transformers.trainer:{'loss': 3.106189535856247, 'learning_rate': 3.3710796195509595e-05, 'epoch': 0.9773522282694247, 'step': 5426500}
INFO:transformers.trainer:{'loss': 3.073789128780365, 'learning_rate': 3.370929530139695e-05, 'epoch': 0.9774422819161831, 'step': 5427000}
INFO:transformers.trainer:{'loss': 3.125629912018776, 'learning_rate': 3.3707794407284307e-05, 'epoch': 0.9775323355629415, 'step': 5427500}
INFO:transformers.trainer:{'loss': 3.102642634391785, 'learning_rate': 3.3706293513171666e-05, 'epoch': 0.9776223892097, 'step': 5428000}
INFO:transformers.trainer:{'loss': 3.0879928959608076, 'learning_rate': 3.3704792619059025e-05, 'epoch': 0.9777124428564584, 'step': 5428500}
INFO:transformers.trainer:{'loss': 3.1504205548763276, 'learning_rate': 3.3703291724946384e-05, 'epoch': 0.9778024965032169, 'step': 5429000}
INFO:transformers.trainer:{'loss': 3.1055724840164185, 'learning_rate': 3.370179083083374e-05, 'epoch': 0.9778925501499753, 'step': 5429500}
INFO:transformers.trainer:{'loss': 3.0883168976306914, 'learning_rate': 3.370028993672111e-05, 'epoch': 0.9779826037967337, 'step': 5430000}
INFO:transformers.trainer:{'loss': 3.10556968832016, 'learning_rate': 3.369878904260846e-05, 'epoch': 0.9780726574434923, 'step': 5430500}
INFO:transformers.trainer:{'loss': 3.0556182651519777, 'learning_rate': 3.369728814849583e-05, 'epoch': 0.9781627110902507, 'step': 5431000}
INFO:transformers.trainer:{'loss': 3.0998295128345488, 'learning_rate': 3.369578725438318e-05, 'epoch': 0.9782527647370092, 'step': 5431500}
INFO:transformers.trainer:{'loss': 3.0776248140335083, 'learning_rate': 3.3694286360270545e-05, 'epoch': 0.9783428183837676, 'step': 5432000}
INFO:transformers.trainer:{'loss': 3.0523949995040893, 'learning_rate': 3.36927854661579e-05, 'epoch': 0.978432872030526, 'step': 5432500}
INFO:transformers.trainer:{'loss': 3.0880619215965273, 'learning_rate': 3.369128457204526e-05, 'epoch': 0.9785229256772845, 'step': 5433000}
INFO:transformers.trainer:{'loss': 3.096600881576538, 'learning_rate': 3.3689783677932615e-05, 'epoch': 0.9786129793240429, 'step': 5433500}
INFO:transformers.trainer:{'loss': 3.1292446594238283, 'learning_rate': 3.368828278381998e-05, 'epoch': 0.9787030329708014, 'step': 5434000}
INFO:transformers.trainer:{'loss': 3.13469758272171, 'learning_rate': 3.368678188970733e-05, 'epoch': 0.9787930866175598, 'step': 5434500}
INFO:transformers.trainer:{'loss': 3.111224712371826, 'learning_rate': 3.36852809955947e-05, 'epoch': 0.9788831402643182, 'step': 5435000}
INFO:transformers.trainer:{'loss': 3.094303708076477, 'learning_rate': 3.368378010148205e-05, 'epoch': 0.9789731939110767, 'step': 5435500}
INFO:transformers.trainer:{'loss': 3.1799965777397157, 'learning_rate': 3.368227920736942e-05, 'epoch': 0.9790632475578351, 'step': 5436000}
INFO:transformers.trainer:{'loss': 3.068432082414627, 'learning_rate': 3.368077831325677e-05, 'epoch': 0.9791533012045937, 'step': 5436500}
INFO:transformers.trainer:{'loss': 3.147742255449295, 'learning_rate': 3.3679277419144135e-05, 'epoch': 0.979243354851352, 'step': 5437000}
INFO:transformers.trainer:{'loss': 3.05299972987175, 'learning_rate': 3.3677776525031494e-05, 'epoch': 0.9793334084981105, 'step': 5437500}
INFO:transformers.trainer:{'loss': 3.105727854132652, 'learning_rate': 3.367627563091885e-05, 'epoch': 0.979423462144869, 'step': 5438000}
INFO:transformers.trainer:{'loss': 3.096776626586914, 'learning_rate': 3.367477473680621e-05, 'epoch': 0.9795135157916274, 'step': 5438500}
INFO:transformers.trainer:{'loss': 3.091706013917923, 'learning_rate': 3.367327384269357e-05, 'epoch': 0.9796035694383859, 'step': 5439000}
INFO:transformers.trainer:{'loss': 3.0637032170295715, 'learning_rate': 3.367177294858093e-05, 'epoch': 0.9796936230851443, 'step': 5439500}
INFO:transformers.trainer:{'loss': 3.1109896290302275, 'learning_rate': 3.367027205446829e-05, 'epoch': 0.9797836767319027, 'step': 5440000}
INFO:transformers.trainer:{'loss': 3.128714575767517, 'learning_rate': 3.366877116035565e-05, 'epoch': 0.9798737303786612, 'step': 5440500}
INFO:transformers.trainer:{'loss': 3.1071483256816865, 'learning_rate': 3.366727026624301e-05, 'epoch': 0.9799637840254196, 'step': 5441000}
INFO:transformers.trainer:{'loss': 3.15704128909111, 'learning_rate': 3.366576937213037e-05, 'epoch': 0.980053837672178, 'step': 5441500}
INFO:transformers.trainer:{'loss': 3.1251515176296234, 'learning_rate': 3.3664268478017726e-05, 'epoch': 0.9801438913189365, 'step': 5442000}
INFO:transformers.trainer:{'loss': 3.0524808282852174, 'learning_rate': 3.3662767583905085e-05, 'epoch': 0.9802339449656949, 'step': 5442500}
INFO:transformers.trainer:{'loss': 3.0896662442684173, 'learning_rate': 3.3661266689792444e-05, 'epoch': 0.9803239986124535, 'step': 5443000}
INFO:transformers.trainer:{'loss': 3.069942625284195, 'learning_rate': 3.36597657956798e-05, 'epoch': 0.9804140522592119, 'step': 5443500}
INFO:transformers.trainer:{'loss': 3.0892015886306763, 'learning_rate': 3.365826490156717e-05, 'epoch': 0.9805041059059703, 'step': 5444000}
INFO:transformers.trainer:{'loss': 3.109468852996826, 'learning_rate': 3.365676400745452e-05, 'epoch': 0.9805941595527288, 'step': 5444500}
INFO:transformers.trainer:{'loss': 3.083935915470123, 'learning_rate': 3.365526311334189e-05, 'epoch': 0.9806842131994872, 'step': 5445000}
INFO:transformers.trainer:{'loss': 3.073383682847023, 'learning_rate': 3.365376221922924e-05, 'epoch': 0.9807742668462457, 'step': 5445500}
INFO:transformers.trainer:{'loss': 3.0838390913009643, 'learning_rate': 3.3652261325116605e-05, 'epoch': 0.9808643204930041, 'step': 5446000}
INFO:transformers.trainer:{'loss': 3.1593127174377442, 'learning_rate': 3.365076043100396e-05, 'epoch': 0.9809543741397625, 'step': 5446500}
INFO:transformers.trainer:{'loss': 3.0830570805072783, 'learning_rate': 3.364925953689132e-05, 'epoch': 0.981044427786521, 'step': 5447000}
INFO:transformers.trainer:{'loss': 3.1374850609302523, 'learning_rate': 3.3647758642778675e-05, 'epoch': 0.9811344814332794, 'step': 5447500}
INFO:transformers.trainer:{'loss': 3.1392490057945253, 'learning_rate': 3.364625774866604e-05, 'epoch': 0.9812245350800379, 'step': 5448000}
INFO:transformers.trainer:{'loss': 3.0775008358955382, 'learning_rate': 3.3644756854553393e-05, 'epoch': 0.9813145887267963, 'step': 5448500}
INFO:transformers.trainer:{'loss': 3.1246209478378297, 'learning_rate': 3.364325596044076e-05, 'epoch': 0.9814046423735547, 'step': 5449000}
INFO:transformers.trainer:{'loss': 3.0484787611961366, 'learning_rate': 3.364175506632811e-05, 'epoch': 0.9814946960203133, 'step': 5449500}
INFO:transformers.trainer:{'loss': 3.109108755350113, 'learning_rate': 3.364025417221548e-05, 'epoch': 0.9815847496670717, 'step': 5450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.11563674557209, 'learning_rate': 3.363875327810283e-05, 'epoch': 0.9816748033138302, 'step': 5450500}
INFO:transformers.trainer:{'loss': 3.1366868045330047, 'learning_rate': 3.3637252383990195e-05, 'epoch': 0.9817648569605886, 'step': 5451000}
INFO:transformers.trainer:{'loss': 3.1316968314647675, 'learning_rate': 3.3635751489877555e-05, 'epoch': 0.981854910607347, 'step': 5451500}
INFO:transformers.trainer:{'loss': 3.141088486671448, 'learning_rate': 3.363425059576491e-05, 'epoch': 0.9819449642541055, 'step': 5452000}
INFO:transformers.trainer:{'loss': 3.0548763089179993, 'learning_rate': 3.363274970165227e-05, 'epoch': 0.9820350179008639, 'step': 5452500}
INFO:transformers.trainer:{'loss': 3.1169095435142515, 'learning_rate': 3.3631248807539625e-05, 'epoch': 0.9821250715476223, 'step': 5453000}
INFO:transformers.trainer:{'loss': 3.1019767096042634, 'learning_rate': 3.362974791342699e-05, 'epoch': 0.9822151251943808, 'step': 5453500}
INFO:transformers.trainer:{'loss': 3.109540271759033, 'learning_rate': 3.362824701931434e-05, 'epoch': 0.9823051788411392, 'step': 5454000}
INFO:transformers.trainer:{'loss': 3.0957116651535035, 'learning_rate': 3.362674612520171e-05, 'epoch': 0.9823952324878977, 'step': 5454500}
INFO:transformers.trainer:{'loss': 3.137196613550186, 'learning_rate': 3.362524523108906e-05, 'epoch': 0.9824852861346561, 'step': 5455000}
INFO:transformers.trainer:{'loss': 3.0316777622699735, 'learning_rate': 3.362374433697643e-05, 'epoch': 0.9825753397814145, 'step': 5455500}
INFO:transformers.trainer:{'loss': 3.1386854367256163, 'learning_rate': 3.362224344286378e-05, 'epoch': 0.982665393428173, 'step': 5456000}
INFO:transformers.trainer:{'loss': 3.1180045144557953, 'learning_rate': 3.3620742548751145e-05, 'epoch': 0.9827554470749315, 'step': 5456500}
INFO:transformers.trainer:{'loss': 3.0900897221565247, 'learning_rate': 3.36192416546385e-05, 'epoch': 0.98284550072169, 'step': 5457000}
INFO:transformers.trainer:{'loss': 3.122586846113205, 'learning_rate': 3.361774076052586e-05, 'epoch': 0.9829355543684484, 'step': 5457500}
INFO:transformers.trainer:{'loss': 3.1027336111068724, 'learning_rate': 3.361623986641322e-05, 'epoch': 0.9830256080152068, 'step': 5458000}
INFO:transformers.trainer:{'loss': 3.108659004688263, 'learning_rate': 3.361473897230058e-05, 'epoch': 0.9831156616619653, 'step': 5458500}
INFO:transformers.trainer:{'loss': 3.108762232065201, 'learning_rate': 3.361323807818794e-05, 'epoch': 0.9832057153087237, 'step': 5459000}
INFO:transformers.trainer:{'loss': 3.0828415622711183, 'learning_rate': 3.36117371840753e-05, 'epoch': 0.9832957689554822, 'step': 5459500}
INFO:transformers.trainer:{'loss': 3.141103533267975, 'learning_rate': 3.361023628996266e-05, 'epoch': 0.9833858226022406, 'step': 5460000}
INFO:transformers.trainer:{'loss': 3.0868213655948638, 'learning_rate': 3.360873539585002e-05, 'epoch': 0.983475876248999, 'step': 5460500}
INFO:transformers.trainer:{'loss': 3.0941616706848145, 'learning_rate': 3.3607234501737376e-05, 'epoch': 0.9835659298957575, 'step': 5461000}
INFO:transformers.trainer:{'loss': 3.0841883263587953, 'learning_rate': 3.3605733607624736e-05, 'epoch': 0.9836559835425159, 'step': 5461500}
INFO:transformers.trainer:{'loss': 3.1201680803298952, 'learning_rate': 3.3604232713512095e-05, 'epoch': 0.9837460371892744, 'step': 5462000}
INFO:transformers.trainer:{'loss': 3.126995994091034, 'learning_rate': 3.3602731819399454e-05, 'epoch': 0.9838360908360329, 'step': 5462500}
INFO:transformers.trainer:{'loss': 3.09359331035614, 'learning_rate': 3.360123092528681e-05, 'epoch': 0.9839261444827913, 'step': 5463000}
INFO:transformers.trainer:{'loss': 3.1232105185985564, 'learning_rate': 3.359973003117417e-05, 'epoch': 0.9840161981295498, 'step': 5463500}
INFO:transformers.trainer:{'loss': 3.1376729131937027, 'learning_rate': 3.359822913706153e-05, 'epoch': 0.9841062517763082, 'step': 5464000}
INFO:transformers.trainer:{'loss': 3.086857078075409, 'learning_rate': 3.3596728242948897e-05, 'epoch': 0.9841963054230666, 'step': 5464500}
INFO:transformers.trainer:{'loss': 3.055461604118347, 'learning_rate': 3.359522734883625e-05, 'epoch': 0.9842863590698251, 'step': 5465000}
INFO:transformers.trainer:{'loss': 3.0966794838905334, 'learning_rate': 3.3593726454723615e-05, 'epoch': 0.9843764127165835, 'step': 5465500}
INFO:transformers.trainer:{'loss': 3.090788120508194, 'learning_rate': 3.359222556061097e-05, 'epoch': 0.984466466363342, 'step': 5466000}
INFO:transformers.trainer:{'loss': 3.1450593485832212, 'learning_rate': 3.359072466649833e-05, 'epoch': 0.9845565200101004, 'step': 5466500}
INFO:transformers.trainer:{'loss': 3.076434983253479, 'learning_rate': 3.3589223772385685e-05, 'epoch': 0.9846465736568588, 'step': 5467000}
INFO:transformers.trainer:{'loss': 3.172938234090805, 'learning_rate': 3.358772287827305e-05, 'epoch': 0.9847366273036173, 'step': 5467500}
INFO:transformers.trainer:{'loss': 3.096150689601898, 'learning_rate': 3.35862219841604e-05, 'epoch': 0.9848266809503757, 'step': 5468000}
INFO:transformers.trainer:{'loss': 3.1082810690402987, 'learning_rate': 3.358472109004777e-05, 'epoch': 0.9849167345971342, 'step': 5468500}
INFO:transformers.trainer:{'loss': 3.1185717599391936, 'learning_rate': 3.358322019593512e-05, 'epoch': 0.9850067882438927, 'step': 5469000}
INFO:transformers.trainer:{'loss': 3.1562970530986787, 'learning_rate': 3.358171930182249e-05, 'epoch': 0.985096841890651, 'step': 5469500}
INFO:transformers.trainer:{'loss': 3.1744724526405332, 'learning_rate': 3.358021840770984e-05, 'epoch': 0.9851868955374096, 'step': 5470000}
INFO:transformers.trainer:{'loss': 3.144106998920441, 'learning_rate': 3.3578717513597205e-05, 'epoch': 0.985276949184168, 'step': 5470500}
INFO:transformers.trainer:{'loss': 3.0558137320280077, 'learning_rate': 3.357721661948456e-05, 'epoch': 0.9853670028309265, 'step': 5471000}
INFO:transformers.trainer:{'loss': 3.1850407671928407, 'learning_rate': 3.357571572537192e-05, 'epoch': 0.9854570564776849, 'step': 5471500}
INFO:transformers.trainer:{'loss': 3.091115969657898, 'learning_rate': 3.357421483125928e-05, 'epoch': 0.9855471101244433, 'step': 5472000}
INFO:transformers.trainer:{'loss': 3.056130921125412, 'learning_rate': 3.357271393714664e-05, 'epoch': 0.9856371637712018, 'step': 5472500}
INFO:transformers.trainer:{'loss': 3.1650852658748625, 'learning_rate': 3.3571213043034e-05, 'epoch': 0.9857272174179602, 'step': 5473000}
INFO:transformers.trainer:{'loss': 3.1199610726833344, 'learning_rate': 3.356971214892136e-05, 'epoch': 0.9858172710647187, 'step': 5473500}
INFO:transformers.trainer:{'loss': 3.10309523499012, 'learning_rate': 3.356821125480872e-05, 'epoch': 0.9859073247114771, 'step': 5474000}
INFO:transformers.trainer:{'loss': 3.1850866458415985, 'learning_rate': 3.356671036069608e-05, 'epoch': 0.9859973783582355, 'step': 5474500}
INFO:transformers.trainer:{'loss': 3.1733486647605895, 'learning_rate': 3.356520946658344e-05, 'epoch': 0.986087432004994, 'step': 5475000}
INFO:transformers.trainer:{'loss': 3.119779632091522, 'learning_rate': 3.356370857247079e-05, 'epoch': 0.9861774856517525, 'step': 5475500}
INFO:transformers.trainer:{'loss': 3.09979859662056, 'learning_rate': 3.3562207678358155e-05, 'epoch': 0.9862675392985109, 'step': 5476000}
INFO:transformers.trainer:{'loss': 3.090060932517052, 'learning_rate': 3.356070678424551e-05, 'epoch': 0.9863575929452694, 'step': 5476500}
INFO:transformers.trainer:{'loss': 3.117967370271683, 'learning_rate': 3.355920589013287e-05, 'epoch': 0.9864476465920278, 'step': 5477000}
INFO:transformers.trainer:{'loss': 3.0718397257328034, 'learning_rate': 3.3557704996020225e-05, 'epoch': 0.9865377002387863, 'step': 5477500}
INFO:transformers.trainer:{'loss': 3.094793054819107, 'learning_rate': 3.355620410190759e-05, 'epoch': 0.9866277538855447, 'step': 5478000}
INFO:transformers.trainer:{'loss': 3.0883629364967344, 'learning_rate': 3.355470320779495e-05, 'epoch': 0.9867178075323031, 'step': 5478500}
INFO:transformers.trainer:{'loss': 3.0776379371881486, 'learning_rate': 3.355320231368231e-05, 'epoch': 0.9868078611790616, 'step': 5479000}
INFO:transformers.trainer:{'loss': 3.13707865190506, 'learning_rate': 3.355170141956967e-05, 'epoch': 0.98689791482582, 'step': 5479500}
INFO:transformers.trainer:{'loss': 3.065691335320473, 'learning_rate': 3.355020052545703e-05, 'epoch': 0.9869879684725785, 'step': 5480000}
INFO:transformers.trainer:{'loss': 3.0781558569669722, 'learning_rate': 3.3548699631344386e-05, 'epoch': 0.9870780221193369, 'step': 5480500}
INFO:transformers.trainer:{'loss': 3.112938731431961, 'learning_rate': 3.3547198737231745e-05, 'epoch': 0.9871680757660953, 'step': 5481000}
INFO:transformers.trainer:{'loss': 3.0787353219985962, 'learning_rate': 3.3545697843119104e-05, 'epoch': 0.9872581294128538, 'step': 5481500}
INFO:transformers.trainer:{'loss': 3.134569201231003, 'learning_rate': 3.354419694900646e-05, 'epoch': 0.9873481830596122, 'step': 5482000}
INFO:transformers.trainer:{'loss': 3.0750873308181763, 'learning_rate': 3.354269605489382e-05, 'epoch': 0.9874382367063708, 'step': 5482500}
INFO:transformers.trainer:{'loss': 3.143501344919205, 'learning_rate': 3.354119516078118e-05, 'epoch': 0.9875282903531292, 'step': 5483000}
INFO:transformers.trainer:{'loss': 3.072531674861908, 'learning_rate': 3.353969426666854e-05, 'epoch': 0.9876183439998876, 'step': 5483500}
INFO:transformers.trainer:{'loss': 3.145318125247955, 'learning_rate': 3.35381933725559e-05, 'epoch': 0.9877083976466461, 'step': 5484000}
INFO:transformers.trainer:{'loss': 3.1138011137247084, 'learning_rate': 3.353669247844326e-05, 'epoch': 0.9877984512934045, 'step': 5484500}
INFO:transformers.trainer:{'loss': 3.1717687643766403, 'learning_rate': 3.353519158433062e-05, 'epoch': 0.987888504940163, 'step': 5485000}
INFO:transformers.trainer:{'loss': 3.0673206697702406, 'learning_rate': 3.353369069021798e-05, 'epoch': 0.9879785585869214, 'step': 5485500}
INFO:transformers.trainer:{'loss': 3.106157400369644, 'learning_rate': 3.353218979610534e-05, 'epoch': 0.9880686122336798, 'step': 5486000}
INFO:transformers.trainer:{'loss': 3.0888939282894134, 'learning_rate': 3.3530688901992695e-05, 'epoch': 0.9881586658804383, 'step': 5486500}
INFO:transformers.trainer:{'loss': 3.089641241312027, 'learning_rate': 3.352918800788006e-05, 'epoch': 0.9882487195271967, 'step': 5487000}
INFO:transformers.trainer:{'loss': 3.076812960386276, 'learning_rate': 3.352768711376741e-05, 'epoch': 0.9883387731739552, 'step': 5487500}
INFO:transformers.trainer:{'loss': 3.097287880897522, 'learning_rate': 3.352618621965478e-05, 'epoch': 0.9884288268207136, 'step': 5488000}
INFO:transformers.trainer:{'loss': 3.0577281013727187, 'learning_rate': 3.352468532554213e-05, 'epoch': 0.988518880467472, 'step': 5488500}
INFO:transformers.trainer:{'loss': 3.157682978153229, 'learning_rate': 3.35231844314295e-05, 'epoch': 0.9886089341142306, 'step': 5489000}
INFO:transformers.trainer:{'loss': 3.1066884076595307, 'learning_rate': 3.352168353731685e-05, 'epoch': 0.988698987760989, 'step': 5489500}
INFO:transformers.trainer:{'loss': 3.142587876200676, 'learning_rate': 3.3520182643204215e-05, 'epoch': 0.9887890414077474, 'step': 5490000}
INFO:transformers.trainer:{'loss': 3.0930143160820007, 'learning_rate': 3.351868174909157e-05, 'epoch': 0.9888790950545059, 'step': 5490500}
INFO:transformers.trainer:{'loss': 3.080437638759613, 'learning_rate': 3.351718085497893e-05, 'epoch': 0.9889691487012643, 'step': 5491000}
INFO:transformers.trainer:{'loss': 3.1277309092283248, 'learning_rate': 3.3515679960866285e-05, 'epoch': 0.9890592023480228, 'step': 5491500}
INFO:transformers.trainer:{'loss': 3.09517790555954, 'learning_rate': 3.351417906675365e-05, 'epoch': 0.9891492559947812, 'step': 5492000}
INFO:transformers.trainer:{'loss': 3.0709267489910124, 'learning_rate': 3.351267817264101e-05, 'epoch': 0.9892393096415396, 'step': 5492500}
INFO:transformers.trainer:{'loss': 3.1298283116817474, 'learning_rate': 3.351117727852837e-05, 'epoch': 0.9893293632882981, 'step': 5493000}
INFO:transformers.trainer:{'loss': 3.0460346002578733, 'learning_rate': 3.350967638441573e-05, 'epoch': 0.9894194169350565, 'step': 5493500}
INFO:transformers.trainer:{'loss': 3.0411010279655457, 'learning_rate': 3.350817549030309e-05, 'epoch': 0.989509470581815, 'step': 5494000}
INFO:transformers.trainer:{'loss': 3.115433552503586, 'learning_rate': 3.3506674596190446e-05, 'epoch': 0.9895995242285734, 'step': 5494500}
INFO:transformers.trainer:{'loss': 3.0771254177093508, 'learning_rate': 3.3505173702077805e-05, 'epoch': 0.9896895778753318, 'step': 5495000}
INFO:transformers.trainer:{'loss': 3.095049790740013, 'learning_rate': 3.3503672807965164e-05, 'epoch': 0.9897796315220904, 'step': 5495500}
INFO:transformers.trainer:{'loss': 3.1246481380462647, 'learning_rate': 3.3502171913852524e-05, 'epoch': 0.9898696851688488, 'step': 5496000}
INFO:transformers.trainer:{'loss': 3.1413153070509434, 'learning_rate': 3.350067101973988e-05, 'epoch': 0.9899597388156073, 'step': 5496500}
INFO:transformers.trainer:{'loss': 3.0717475645542143, 'learning_rate': 3.349917012562724e-05, 'epoch': 0.9900497924623657, 'step': 5497000}
INFO:transformers.trainer:{'loss': 3.075224748134613, 'learning_rate': 3.34976692315146e-05, 'epoch': 0.9901398461091241, 'step': 5497500}
INFO:transformers.trainer:{'loss': 3.1260884819030763, 'learning_rate': 3.349616833740196e-05, 'epoch': 0.9902298997558826, 'step': 5498000}
INFO:transformers.trainer:{'loss': 3.0202488491535187, 'learning_rate': 3.349466744328932e-05, 'epoch': 0.990319953402641, 'step': 5498500}
INFO:transformers.trainer:{'loss': 3.1011571707725527, 'learning_rate': 3.349316654917667e-05, 'epoch': 0.9904100070493995, 'step': 5499000}
INFO:transformers.trainer:{'loss': 3.102628128528595, 'learning_rate': 3.349166565506404e-05, 'epoch': 0.9905000606961579, 'step': 5499500}
INFO:transformers.trainer:{'loss': 3.116945818901062, 'learning_rate': 3.3490164760951396e-05, 'epoch': 0.9905901143429163, 'step': 5500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.177539981842041, 'learning_rate': 3.3488663866838755e-05, 'epoch': 0.9906801679896748, 'step': 5500500}
INFO:transformers.trainer:{'loss': 3.0792094386816027, 'learning_rate': 3.3487162972726114e-05, 'epoch': 0.9907702216364332, 'step': 5501000}
INFO:transformers.trainer:{'loss': 3.051043905496597, 'learning_rate': 3.348566207861347e-05, 'epoch': 0.9908602752831916, 'step': 5501500}
INFO:transformers.trainer:{'loss': 3.162878966331482, 'learning_rate': 3.348416118450083e-05, 'epoch': 0.9909503289299502, 'step': 5502000}
INFO:transformers.trainer:{'loss': 3.0937436904907227, 'learning_rate': 3.348266029038819e-05, 'epoch': 0.9910403825767086, 'step': 5502500}
INFO:transformers.trainer:{'loss': 3.090315646290779, 'learning_rate': 3.348115939627555e-05, 'epoch': 0.9911304362234671, 'step': 5503000}
INFO:transformers.trainer:{'loss': 3.134410173892975, 'learning_rate': 3.347965850216291e-05, 'epoch': 0.9912204898702255, 'step': 5503500}
INFO:transformers.trainer:{'loss': 3.119020261526108, 'learning_rate': 3.347815760805027e-05, 'epoch': 0.9913105435169839, 'step': 5504000}
INFO:transformers.trainer:{'loss': 3.1141998341083528, 'learning_rate': 3.347665671393763e-05, 'epoch': 0.9914005971637424, 'step': 5504500}
INFO:transformers.trainer:{'loss': 3.031305158019066, 'learning_rate': 3.3475155819824986e-05, 'epoch': 0.9914906508105008, 'step': 5505000}
INFO:transformers.trainer:{'loss': 3.1265132892131806, 'learning_rate': 3.3473654925712345e-05, 'epoch': 0.9915807044572593, 'step': 5505500}
INFO:transformers.trainer:{'loss': 3.056429075717926, 'learning_rate': 3.3472154031599705e-05, 'epoch': 0.9916707581040177, 'step': 5506000}
INFO:transformers.trainer:{'loss': 3.102314518213272, 'learning_rate': 3.347065313748707e-05, 'epoch': 0.9917608117507761, 'step': 5506500}
INFO:transformers.trainer:{'loss': 3.059633617401123, 'learning_rate': 3.346915224337442e-05, 'epoch': 0.9918508653975346, 'step': 5507000}
INFO:transformers.trainer:{'loss': 3.0936375505924225, 'learning_rate': 3.346765134926179e-05, 'epoch': 0.991940919044293, 'step': 5507500}
INFO:transformers.trainer:{'loss': 3.1065944402217864, 'learning_rate': 3.346615045514914e-05, 'epoch': 0.9920309726910516, 'step': 5508000}
INFO:transformers.trainer:{'loss': 3.1224961551427843, 'learning_rate': 3.3464649561036507e-05, 'epoch': 0.99212102633781, 'step': 5508500}
INFO:transformers.trainer:{'loss': 3.1422256627082823, 'learning_rate': 3.346314866692386e-05, 'epoch': 0.9922110799845684, 'step': 5509000}
INFO:transformers.trainer:{'loss': 3.124283759832382, 'learning_rate': 3.3461647772811225e-05, 'epoch': 0.9923011336313269, 'step': 5509500}
INFO:transformers.trainer:{'loss': 3.076730915784836, 'learning_rate': 3.346014687869858e-05, 'epoch': 0.9923911872780853, 'step': 5510000}
INFO:transformers.trainer:{'loss': 3.104954281449318, 'learning_rate': 3.345864598458594e-05, 'epoch': 0.9924812409248438, 'step': 5510500}
INFO:transformers.trainer:{'loss': 3.1006735193729402, 'learning_rate': 3.3457145090473295e-05, 'epoch': 0.9925712945716022, 'step': 5511000}
INFO:transformers.trainer:{'loss': 3.050682824254036, 'learning_rate': 3.345564419636066e-05, 'epoch': 0.9926613482183606, 'step': 5511500}
INFO:transformers.trainer:{'loss': 3.0938157838582994, 'learning_rate': 3.345414330224801e-05, 'epoch': 0.9927514018651191, 'step': 5512000}
INFO:transformers.trainer:{'loss': 3.140987685203552, 'learning_rate': 3.345264240813538e-05, 'epoch': 0.9928414555118775, 'step': 5512500}
INFO:transformers.trainer:{'loss': 3.119468423128128, 'learning_rate': 3.345114151402274e-05, 'epoch': 0.9929315091586359, 'step': 5513000}
INFO:transformers.trainer:{'loss': 3.137527625799179, 'learning_rate': 3.34496406199101e-05, 'epoch': 0.9930215628053944, 'step': 5513500}
INFO:transformers.trainer:{'loss': 3.141932110071182, 'learning_rate': 3.3448139725797456e-05, 'epoch': 0.9931116164521528, 'step': 5514000}
INFO:transformers.trainer:{'loss': 3.1186091680526733, 'learning_rate': 3.3446638831684815e-05, 'epoch': 0.9932016700989114, 'step': 5514500}
INFO:transformers.trainer:{'loss': 3.0561942524909975, 'learning_rate': 3.3445137937572174e-05, 'epoch': 0.9932917237456698, 'step': 5515000}
INFO:transformers.trainer:{'loss': 3.1094625316858293, 'learning_rate': 3.344363704345953e-05, 'epoch': 0.9933817773924282, 'step': 5515500}
INFO:transformers.trainer:{'loss': 3.1439650626182556, 'learning_rate': 3.344213614934689e-05, 'epoch': 0.9934718310391867, 'step': 5516000}
INFO:transformers.trainer:{'loss': 3.1063526006937026, 'learning_rate': 3.344063525523425e-05, 'epoch': 0.9935618846859451, 'step': 5516500}
INFO:transformers.trainer:{'loss': 3.0784554327726363, 'learning_rate': 3.343913436112161e-05, 'epoch': 0.9936519383327036, 'step': 5517000}
INFO:transformers.trainer:{'loss': 3.0534303896427155, 'learning_rate': 3.343763346700897e-05, 'epoch': 0.993741991979462, 'step': 5517500}
INFO:transformers.trainer:{'loss': 3.079797949075699, 'learning_rate': 3.343613257289633e-05, 'epoch': 0.9938320456262204, 'step': 5518000}
INFO:transformers.trainer:{'loss': 3.119345033288002, 'learning_rate': 3.343463167878369e-05, 'epoch': 0.9939220992729789, 'step': 5518500}
INFO:transformers.trainer:{'loss': 3.131413572311401, 'learning_rate': 3.3433130784671047e-05, 'epoch': 0.9940121529197373, 'step': 5519000}
INFO:transformers.trainer:{'loss': 3.133246528983116, 'learning_rate': 3.3431629890558406e-05, 'epoch': 0.9941022065664958, 'step': 5519500}
INFO:transformers.trainer:{'loss': 3.1008991248607636, 'learning_rate': 3.3430128996445765e-05, 'epoch': 0.9941922602132542, 'step': 5520000}
INFO:transformers.trainer:{'loss': 3.0730827331542967, 'learning_rate': 3.3428628102333124e-05, 'epoch': 0.9942823138600126, 'step': 5520500}
INFO:transformers.trainer:{'loss': 3.091503194689751, 'learning_rate': 3.342712720822048e-05, 'epoch': 0.9943723675067712, 'step': 5521000}
INFO:transformers.trainer:{'loss': 3.0426371092796325, 'learning_rate': 3.342562631410784e-05, 'epoch': 0.9944624211535296, 'step': 5521500}
INFO:transformers.trainer:{'loss': 3.1495065021514894, 'learning_rate': 3.34241254199952e-05, 'epoch': 0.9945524748002881, 'step': 5522000}
INFO:transformers.trainer:{'loss': 3.0596048043966295, 'learning_rate': 3.342262452588256e-05, 'epoch': 0.9946425284470465, 'step': 5522500}
INFO:transformers.trainer:{'loss': 3.1087768778800964, 'learning_rate': 3.342112363176992e-05, 'epoch': 0.9947325820938049, 'step': 5523000}
INFO:transformers.trainer:{'loss': 3.053208597779274, 'learning_rate': 3.341962273765728e-05, 'epoch': 0.9948226357405634, 'step': 5523500}
INFO:transformers.trainer:{'loss': 3.154182643175125, 'learning_rate': 3.341812184354464e-05, 'epoch': 0.9949126893873218, 'step': 5524000}
INFO:transformers.trainer:{'loss': 3.103072749495506, 'learning_rate': 3.3416620949431996e-05, 'epoch': 0.9950027430340803, 'step': 5524500}
INFO:transformers.trainer:{'loss': 3.099190826535225, 'learning_rate': 3.3415120055319355e-05, 'epoch': 0.9950927966808387, 'step': 5525000}
INFO:transformers.trainer:{'loss': 3.0848819406032564, 'learning_rate': 3.3413619161206714e-05, 'epoch': 0.9951828503275971, 'step': 5525500}
INFO:transformers.trainer:{'loss': 3.030143049955368, 'learning_rate': 3.341211826709407e-05, 'epoch': 0.9952729039743556, 'step': 5526000}
INFO:transformers.trainer:{'loss': 3.08946936583519, 'learning_rate': 3.341061737298143e-05, 'epoch': 0.995362957621114, 'step': 5526500}
INFO:transformers.trainer:{'loss': 3.0712789832353593, 'learning_rate': 3.34091164788688e-05, 'epoch': 0.9954530112678724, 'step': 5527000}
INFO:transformers.trainer:{'loss': 3.1049294286966322, 'learning_rate': 3.340761558475615e-05, 'epoch': 0.995543064914631, 'step': 5527500}
INFO:transformers.trainer:{'loss': 3.074254650473595, 'learning_rate': 3.3406114690643516e-05, 'epoch': 0.9956331185613894, 'step': 5528000}
INFO:transformers.trainer:{'loss': 3.1062568271160127, 'learning_rate': 3.340461379653087e-05, 'epoch': 0.9957231722081479, 'step': 5528500}
INFO:transformers.trainer:{'loss': 3.106860300540924, 'learning_rate': 3.3403112902418234e-05, 'epoch': 0.9958132258549063, 'step': 5529000}
INFO:transformers.trainer:{'loss': 3.1578003734350206, 'learning_rate': 3.340161200830559e-05, 'epoch': 0.9959032795016647, 'step': 5529500}
INFO:transformers.trainer:{'loss': 3.0820957341194153, 'learning_rate': 3.340011111419295e-05, 'epoch': 0.9959933331484232, 'step': 5530000}
INFO:transformers.trainer:{'loss': 3.106562168955803, 'learning_rate': 3.3398610220080305e-05, 'epoch': 0.9960833867951816, 'step': 5530500}
INFO:transformers.trainer:{'loss': 3.1129536677598955, 'learning_rate': 3.339710932596767e-05, 'epoch': 0.9961734404419401, 'step': 5531000}
INFO:transformers.trainer:{'loss': 3.1520394961833955, 'learning_rate': 3.339560843185502e-05, 'epoch': 0.9962634940886985, 'step': 5531500}
INFO:transformers.trainer:{'loss': 3.0880898656845095, 'learning_rate': 3.339410753774239e-05, 'epoch': 0.9963535477354569, 'step': 5532000}
INFO:transformers.trainer:{'loss': 3.13083483722806, 'learning_rate': 3.339260664362974e-05, 'epoch': 0.9964436013822154, 'step': 5532500}
INFO:transformers.trainer:{'loss': 3.0461710786819456, 'learning_rate': 3.339110574951711e-05, 'epoch': 0.9965336550289738, 'step': 5533000}
INFO:transformers.trainer:{'loss': 3.106371616601944, 'learning_rate': 3.338960485540446e-05, 'epoch': 0.9966237086757324, 'step': 5533500}
INFO:transformers.trainer:{'loss': 3.114429198741913, 'learning_rate': 3.3388103961291825e-05, 'epoch': 0.9967137623224908, 'step': 5534000}
INFO:transformers.trainer:{'loss': 3.1340740641355516, 'learning_rate': 3.3386603067179184e-05, 'epoch': 0.9968038159692492, 'step': 5534500}
INFO:transformers.trainer:{'loss': 3.178558571100235, 'learning_rate': 3.338510217306654e-05, 'epoch': 0.9968938696160077, 'step': 5535000}
INFO:transformers.trainer:{'loss': 3.09911692237854, 'learning_rate': 3.33836012789539e-05, 'epoch': 0.9969839232627661, 'step': 5535500}
INFO:transformers.trainer:{'loss': 3.109684884786606, 'learning_rate': 3.338210038484126e-05, 'epoch': 0.9970739769095246, 'step': 5536000}
INFO:transformers.trainer:{'loss': 3.1402409241199494, 'learning_rate': 3.338059949072862e-05, 'epoch': 0.997164030556283, 'step': 5536500}
INFO:transformers.trainer:{'loss': 3.1427195261716845, 'learning_rate': 3.337909859661598e-05, 'epoch': 0.9972540842030414, 'step': 5537000}
INFO:transformers.trainer:{'loss': 3.1047278687953948, 'learning_rate': 3.337759770250334e-05, 'epoch': 0.9973441378497999, 'step': 5537500}
INFO:transformers.trainer:{'loss': 3.157415592432022, 'learning_rate': 3.33760968083907e-05, 'epoch': 0.9974341914965583, 'step': 5538000}
INFO:transformers.trainer:{'loss': 3.1392823930978775, 'learning_rate': 3.3374595914278056e-05, 'epoch': 0.9975242451433167, 'step': 5538500}
INFO:transformers.trainer:{'loss': 3.089702790141106, 'learning_rate': 3.3373095020165415e-05, 'epoch': 0.9976142987900752, 'step': 5539000}
INFO:transformers.trainer:{'loss': 3.0698297193050386, 'learning_rate': 3.3371594126052774e-05, 'epoch': 0.9977043524368336, 'step': 5539500}
INFO:transformers.trainer:{'loss': 3.0692272689342497, 'learning_rate': 3.3370093231940133e-05, 'epoch': 0.9977944060835922, 'step': 5540000}
INFO:transformers.trainer:{'loss': 3.143539563655853, 'learning_rate': 3.336859233782749e-05, 'epoch': 0.9978844597303506, 'step': 5540500}
INFO:transformers.trainer:{'loss': 3.090884693622589, 'learning_rate': 3.336709144371485e-05, 'epoch': 0.997974513377109, 'step': 5541000}
INFO:transformers.trainer:{'loss': 3.0988986728191374, 'learning_rate': 3.336559054960221e-05, 'epoch': 0.9980645670238675, 'step': 5541500}
INFO:transformers.trainer:{'loss': 3.1062611010074614, 'learning_rate': 3.336408965548957e-05, 'epoch': 0.9981546206706259, 'step': 5542000}
INFO:transformers.trainer:{'loss': 3.1213670114278793, 'learning_rate': 3.336258876137693e-05, 'epoch': 0.9982446743173844, 'step': 5542500}
INFO:transformers.trainer:{'loss': 3.03181170630455, 'learning_rate': 3.336108786726429e-05, 'epoch': 0.9983347279641428, 'step': 5543000}
INFO:transformers.trainer:{'loss': 3.109486310005188, 'learning_rate': 3.335958697315165e-05, 'epoch': 0.9984247816109012, 'step': 5543500}
INFO:transformers.trainer:{'loss': 3.0882084414958952, 'learning_rate': 3.3358086079039006e-05, 'epoch': 0.9985148352576597, 'step': 5544000}
INFO:transformers.trainer:{'loss': 3.0609277230501175, 'learning_rate': 3.3356585184926365e-05, 'epoch': 0.9986048889044181, 'step': 5544500}
INFO:transformers.trainer:{'loss': 3.0501245033740996, 'learning_rate': 3.3355084290813724e-05, 'epoch': 0.9986949425511766, 'step': 5545000}
INFO:transformers.trainer:{'loss': 3.079624072790146, 'learning_rate': 3.335358339670108e-05, 'epoch': 0.998784996197935, 'step': 5545500}
INFO:transformers.trainer:{'loss': 3.085488509654999, 'learning_rate': 3.335208250258844e-05, 'epoch': 0.9988750498446934, 'step': 5546000}
INFO:transformers.trainer:{'loss': 3.1420211124420168, 'learning_rate': 3.33505816084758e-05, 'epoch': 0.998965103491452, 'step': 5546500}
INFO:transformers.trainer:{'loss': 3.113977716445923, 'learning_rate': 3.334908071436316e-05, 'epoch': 0.9990551571382104, 'step': 5547000}
INFO:transformers.trainer:{'loss': 3.091230692982674, 'learning_rate': 3.334757982025052e-05, 'epoch': 0.9991452107849689, 'step': 5547500}
INFO:transformers.trainer:{'loss': 3.184405302286148, 'learning_rate': 3.334607892613788e-05, 'epoch': 0.9992352644317273, 'step': 5548000}
INFO:transformers.trainer:{'loss': 3.102907103061676, 'learning_rate': 3.3344578032025244e-05, 'epoch': 0.9993253180784857, 'step': 5548500}
INFO:transformers.trainer:{'loss': 3.0536370329856872, 'learning_rate': 3.3343077137912596e-05, 'epoch': 0.9994153717252442, 'step': 5549000}
INFO:transformers.trainer:{'loss': 3.131416392803192, 'learning_rate': 3.334157624379996e-05, 'epoch': 0.9995054253720026, 'step': 5549500}
INFO:transformers.trainer:{'loss': 3.1287381970882415, 'learning_rate': 3.3340075349687314e-05, 'epoch': 0.999595479018761, 'step': 5550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0987999165058135, 'learning_rate': 3.333857445557468e-05, 'epoch': 0.9996855326655195, 'step': 5550500}
INFO:transformers.trainer:{'loss': 3.188873075604439, 'learning_rate': 3.333707356146203e-05, 'epoch': 0.9997755863122779, 'step': 5551000}
INFO:transformers.trainer:{'loss': 3.1168282034397126, 'learning_rate': 3.33355726673494e-05, 'epoch': 0.9998656399590364, 'step': 5551500}
INFO:transformers.trainer:{'loss': 3.1013210297226905, 'learning_rate': 3.333407177323675e-05, 'epoch': 0.9999556936057948, 'step': 5552000}
INFO:transformers.trainer:{'loss': 3.1024600721597673, 'learning_rate': 3.3332570879124116e-05, 'epoch': 1.0000457472525532, 'step': 5552500}
INFO:transformers.trainer:{'loss': 3.0365156738758086, 'learning_rate': 3.333106998501147e-05, 'epoch': 1.0001358008993118, 'step': 5553000}
INFO:transformers.trainer:{'loss': 3.073482258796692, 'learning_rate': 3.3329569090898835e-05, 'epoch': 1.0002258545460703, 'step': 5553500}
INFO:transformers.trainer:{'loss': 3.1232120223045348, 'learning_rate': 3.332806819678619e-05, 'epoch': 1.0003159081928286, 'step': 5554000}
INFO:transformers.trainer:{'loss': 3.0863470034599305, 'learning_rate': 3.332656730267355e-05, 'epoch': 1.000405961839587, 'step': 5554500}
INFO:transformers.trainer:{'loss': 3.0935212609767913, 'learning_rate': 3.332506640856091e-05, 'epoch': 1.0004960154863456, 'step': 5555000}
INFO:transformers.trainer:{'loss': 3.0996331453323362, 'learning_rate': 3.332356551444827e-05, 'epoch': 1.0005860691331039, 'step': 5555500}
INFO:transformers.trainer:{'loss': 3.1110111001729965, 'learning_rate': 3.332206462033563e-05, 'epoch': 1.0006761227798624, 'step': 5556000}
INFO:transformers.trainer:{'loss': 3.0727391543388367, 'learning_rate': 3.332056372622299e-05, 'epoch': 1.000766176426621, 'step': 5556500}
INFO:transformers.trainer:{'loss': 3.145827392101288, 'learning_rate': 3.331906283211035e-05, 'epoch': 1.0008562300733792, 'step': 5557000}
INFO:transformers.trainer:{'loss': 3.1215545748472215, 'learning_rate': 3.331756193799771e-05, 'epoch': 1.0009462837201377, 'step': 5557500}
INFO:transformers.trainer:{'loss': 3.0705997011661528, 'learning_rate': 3.3316061043885066e-05, 'epoch': 1.0010363373668962, 'step': 5558000}
INFO:transformers.trainer:{'loss': 3.0073243732452393, 'learning_rate': 3.3314560149772425e-05, 'epoch': 1.0011263910136547, 'step': 5558500}
INFO:transformers.trainer:{'loss': 3.1930447058677673, 'learning_rate': 3.3313059255659784e-05, 'epoch': 1.001216444660413, 'step': 5559000}
INFO:transformers.trainer:{'loss': 3.1185422518253327, 'learning_rate': 3.331155836154714e-05, 'epoch': 1.0013064983071716, 'step': 5559500}
INFO:transformers.trainer:{'loss': 3.12794842004776, 'learning_rate': 3.33100574674345e-05, 'epoch': 1.00139655195393, 'step': 5560000}
INFO:transformers.trainer:{'loss': 3.1306593244075773, 'learning_rate': 3.330855657332186e-05, 'epoch': 1.0014866056006884, 'step': 5560500}
INFO:transformers.trainer:{'loss': 3.128292892456055, 'learning_rate': 3.330705567920922e-05, 'epoch': 1.0015766592474469, 'step': 5561000}
INFO:transformers.trainer:{'loss': 3.1056032972335816, 'learning_rate': 3.330555478509658e-05, 'epoch': 1.0016667128942054, 'step': 5561500}
INFO:transformers.trainer:{'loss': 3.078559122800827, 'learning_rate': 3.330405389098394e-05, 'epoch': 1.0017567665409637, 'step': 5562000}
INFO:transformers.trainer:{'loss': 3.1087174377441404, 'learning_rate': 3.33025529968713e-05, 'epoch': 1.0018468201877222, 'step': 5562500}
INFO:transformers.trainer:{'loss': 3.164688866019249, 'learning_rate': 3.3301052102758657e-05, 'epoch': 1.0019368738344807, 'step': 5563000}
INFO:transformers.trainer:{'loss': 3.08037630879879, 'learning_rate': 3.3299551208646016e-05, 'epoch': 1.0020269274812392, 'step': 5563500}
INFO:transformers.trainer:{'loss': 3.1024970252513886, 'learning_rate': 3.3298050314533375e-05, 'epoch': 1.0021169811279975, 'step': 5564000}
INFO:transformers.trainer:{'loss': 3.0462820699214936, 'learning_rate': 3.3296549420420734e-05, 'epoch': 1.002207034774756, 'step': 5564500}
INFO:transformers.trainer:{'loss': 3.091930942773819, 'learning_rate': 3.329504852630809e-05, 'epoch': 1.0022970884215145, 'step': 5565000}
INFO:transformers.trainer:{'loss': 3.0844190980196, 'learning_rate': 3.329354763219545e-05, 'epoch': 1.0023871420682728, 'step': 5565500}
INFO:transformers.trainer:{'loss': 3.070137819290161, 'learning_rate': 3.329204673808281e-05, 'epoch': 1.0024771957150314, 'step': 5566000}
INFO:transformers.trainer:{'loss': 3.1630488097667695, 'learning_rate': 3.329054584397017e-05, 'epoch': 1.0025672493617899, 'step': 5566500}
INFO:transformers.trainer:{'loss': 3.0439805862903593, 'learning_rate': 3.328904494985753e-05, 'epoch': 1.0026573030085482, 'step': 5567000}
INFO:transformers.trainer:{'loss': 3.106903979301453, 'learning_rate': 3.328754405574489e-05, 'epoch': 1.0027473566553067, 'step': 5567500}
INFO:transformers.trainer:{'loss': 3.049990401506424, 'learning_rate': 3.328604316163225e-05, 'epoch': 1.0028374103020652, 'step': 5568000}
INFO:transformers.trainer:{'loss': 3.1775224595069886, 'learning_rate': 3.3284542267519606e-05, 'epoch': 1.0029274639488235, 'step': 5568500}
INFO:transformers.trainer:{'loss': 3.0985369482040404, 'learning_rate': 3.328304137340697e-05, 'epoch': 1.003017517595582, 'step': 5569000}
INFO:transformers.trainer:{'loss': 3.1150887783765793, 'learning_rate': 3.3281540479294324e-05, 'epoch': 1.0031075712423405, 'step': 5569500}
INFO:transformers.trainer:{'loss': 3.1337679826021194, 'learning_rate': 3.328003958518169e-05, 'epoch': 1.003197624889099, 'step': 5570000}
INFO:transformers.trainer:{'loss': 3.0609473379850387, 'learning_rate': 3.327853869106904e-05, 'epoch': 1.0032876785358573, 'step': 5570500}
INFO:transformers.trainer:{'loss': 3.145351392388344, 'learning_rate': 3.327703779695641e-05, 'epoch': 1.0033777321826158, 'step': 5571000}
INFO:transformers.trainer:{'loss': 3.0601987706422804, 'learning_rate': 3.327553690284376e-05, 'epoch': 1.0034677858293743, 'step': 5571500}
INFO:transformers.trainer:{'loss': 3.136579221844673, 'learning_rate': 3.3274036008731126e-05, 'epoch': 1.0035578394761326, 'step': 5572000}
INFO:transformers.trainer:{'loss': 3.0737369661331178, 'learning_rate': 3.327253511461848e-05, 'epoch': 1.0036478931228912, 'step': 5572500}
INFO:transformers.trainer:{'loss': 3.0940542652606964, 'learning_rate': 3.3271034220505844e-05, 'epoch': 1.0037379467696497, 'step': 5573000}
INFO:transformers.trainer:{'loss': 3.0901153717041017, 'learning_rate': 3.3269533326393197e-05, 'epoch': 1.003828000416408, 'step': 5573500}
INFO:transformers.trainer:{'loss': 3.0482211713790894, 'learning_rate': 3.326803243228056e-05, 'epoch': 1.0039180540631665, 'step': 5574000}
INFO:transformers.trainer:{'loss': 3.104155653953552, 'learning_rate': 3.3266531538167915e-05, 'epoch': 1.004008107709925, 'step': 5574500}
INFO:transformers.trainer:{'loss': 3.144699241399765, 'learning_rate': 3.326503064405528e-05, 'epoch': 1.0040981613566835, 'step': 5575000}
INFO:transformers.trainer:{'loss': 3.044893676638603, 'learning_rate': 3.326352974994264e-05, 'epoch': 1.0041882150034418, 'step': 5575500}
INFO:transformers.trainer:{'loss': 3.0663146276474, 'learning_rate': 3.326202885583e-05, 'epoch': 1.0042782686502003, 'step': 5576000}
INFO:transformers.trainer:{'loss': 3.0822703182697295, 'learning_rate': 3.326052796171736e-05, 'epoch': 1.0043683222969588, 'step': 5576500}
INFO:transformers.trainer:{'loss': 3.118523342370987, 'learning_rate': 3.325902706760472e-05, 'epoch': 1.0044583759437171, 'step': 5577000}
INFO:transformers.trainer:{'loss': 3.0615250623226165, 'learning_rate': 3.3257526173492076e-05, 'epoch': 1.0045484295904756, 'step': 5577500}
INFO:transformers.trainer:{'loss': 3.103946332454681, 'learning_rate': 3.3256025279379435e-05, 'epoch': 1.0046384832372341, 'step': 5578000}
INFO:transformers.trainer:{'loss': 3.088489555358887, 'learning_rate': 3.3254524385266794e-05, 'epoch': 1.0047285368839924, 'step': 5578500}
INFO:transformers.trainer:{'loss': 3.0180624709129336, 'learning_rate': 3.325302349115415e-05, 'epoch': 1.004818590530751, 'step': 5579000}
INFO:transformers.trainer:{'loss': 3.1864815702438354, 'learning_rate': 3.325152259704151e-05, 'epoch': 1.0049086441775095, 'step': 5579500}
INFO:transformers.trainer:{'loss': 3.0805173016786576, 'learning_rate': 3.325002170292887e-05, 'epoch': 1.0049986978242678, 'step': 5580000}
INFO:transformers.trainer:{'loss': 3.098302048802376, 'learning_rate': 3.324852080881623e-05, 'epoch': 1.0050887514710263, 'step': 5580500}
INFO:transformers.trainer:{'loss': 3.1296911983489992, 'learning_rate': 3.324701991470359e-05, 'epoch': 1.0051788051177848, 'step': 5581000}
INFO:transformers.trainer:{'loss': 3.0806508316993715, 'learning_rate': 3.324551902059095e-05, 'epoch': 1.0052688587645433, 'step': 5581500}
INFO:transformers.trainer:{'loss': 3.090211959838867, 'learning_rate': 3.324401812647831e-05, 'epoch': 1.0053589124113016, 'step': 5582000}
INFO:transformers.trainer:{'loss': 3.132195071697235, 'learning_rate': 3.3242517232365666e-05, 'epoch': 1.0054489660580601, 'step': 5582500}
INFO:transformers.trainer:{'loss': 3.1580778760910033, 'learning_rate': 3.3241016338253025e-05, 'epoch': 1.0055390197048186, 'step': 5583000}
INFO:transformers.trainer:{'loss': 3.1323986325263977, 'learning_rate': 3.3239515444140384e-05, 'epoch': 1.005629073351577, 'step': 5583500}
INFO:transformers.trainer:{'loss': 3.0987812547683715, 'learning_rate': 3.3238014550027743e-05, 'epoch': 1.0057191269983354, 'step': 5584000}
INFO:transformers.trainer:{'loss': 3.1658708003759384, 'learning_rate': 3.32365136559151e-05, 'epoch': 1.005809180645094, 'step': 5584500}
INFO:transformers.trainer:{'loss': 3.1152368961572647, 'learning_rate': 3.323501276180246e-05, 'epoch': 1.0058992342918522, 'step': 5585000}
INFO:transformers.trainer:{'loss': 3.0918948159217834, 'learning_rate': 3.323351186768982e-05, 'epoch': 1.0059892879386108, 'step': 5585500}
INFO:transformers.trainer:{'loss': 3.103149252653122, 'learning_rate': 3.323201097357718e-05, 'epoch': 1.0060793415853693, 'step': 5586000}
INFO:transformers.trainer:{'loss': 3.0639343218803408, 'learning_rate': 3.323051007946454e-05, 'epoch': 1.0061693952321278, 'step': 5586500}
INFO:transformers.trainer:{'loss': 3.1019758086204527, 'learning_rate': 3.32290091853519e-05, 'epoch': 1.006259448878886, 'step': 5587000}
INFO:transformers.trainer:{'loss': 3.08521392595768, 'learning_rate': 3.322750829123926e-05, 'epoch': 1.0063495025256446, 'step': 5587500}
INFO:transformers.trainer:{'loss': 3.0609311077594756, 'learning_rate': 3.3226007397126616e-05, 'epoch': 1.006439556172403, 'step': 5588000}
INFO:transformers.trainer:{'loss': 3.053265743732452, 'learning_rate': 3.3224506503013975e-05, 'epoch': 1.0065296098191614, 'step': 5588500}
INFO:transformers.trainer:{'loss': 3.060464229106903, 'learning_rate': 3.3223005608901334e-05, 'epoch': 1.00661966346592, 'step': 5589000}
INFO:transformers.trainer:{'loss': 3.0629495475292208, 'learning_rate': 3.32215047147887e-05, 'epoch': 1.0067097171126784, 'step': 5589500}
INFO:transformers.trainer:{'loss': 3.0473179495334626, 'learning_rate': 3.322000382067605e-05, 'epoch': 1.0067997707594367, 'step': 5590000}
INFO:transformers.trainer:{'loss': 3.121865518569946, 'learning_rate': 3.321850292656342e-05, 'epoch': 1.0068898244061952, 'step': 5590500}
INFO:transformers.trainer:{'loss': 3.1642393913269045, 'learning_rate': 3.321700203245077e-05, 'epoch': 1.0069798780529537, 'step': 5591000}
INFO:transformers.trainer:{'loss': 3.1326311273574827, 'learning_rate': 3.3215501138338136e-05, 'epoch': 1.0070699316997123, 'step': 5591500}
INFO:transformers.trainer:{'loss': 3.1422643860578536, 'learning_rate': 3.321400024422549e-05, 'epoch': 1.0071599853464706, 'step': 5592000}
INFO:transformers.trainer:{'loss': 3.067775546312332, 'learning_rate': 3.3212499350112854e-05, 'epoch': 1.007250038993229, 'step': 5592500}
INFO:transformers.trainer:{'loss': 3.1421300127506258, 'learning_rate': 3.3210998456000206e-05, 'epoch': 1.0073400926399876, 'step': 5593000}
INFO:transformers.trainer:{'loss': 3.0835646699666976, 'learning_rate': 3.320949756188757e-05, 'epoch': 1.0074301462867459, 'step': 5593500}
INFO:transformers.trainer:{'loss': 3.091366229772568, 'learning_rate': 3.3207996667774924e-05, 'epoch': 1.0075201999335044, 'step': 5594000}
INFO:transformers.trainer:{'loss': 3.140559994459152, 'learning_rate': 3.320649577366229e-05, 'epoch': 1.007610253580263, 'step': 5594500}
INFO:transformers.trainer:{'loss': 3.0862101999521254, 'learning_rate': 3.320499487954964e-05, 'epoch': 1.0077003072270212, 'step': 5595000}
INFO:transformers.trainer:{'loss': 3.027956055164337, 'learning_rate': 3.320349398543701e-05, 'epoch': 1.0077903608737797, 'step': 5595500}
INFO:transformers.trainer:{'loss': 3.1003564935922623, 'learning_rate': 3.320199309132436e-05, 'epoch': 1.0078804145205382, 'step': 5596000}
INFO:transformers.trainer:{'loss': 3.102537867188454, 'learning_rate': 3.3200492197211726e-05, 'epoch': 1.0079704681672965, 'step': 5596500}
INFO:transformers.trainer:{'loss': 3.1955921683311463, 'learning_rate': 3.3198991303099086e-05, 'epoch': 1.008060521814055, 'step': 5597000}
INFO:transformers.trainer:{'loss': 3.0961183443069458, 'learning_rate': 3.3197490408986445e-05, 'epoch': 1.0081505754608135, 'step': 5597500}
INFO:transformers.trainer:{'loss': 3.0766605978012085, 'learning_rate': 3.3195989514873804e-05, 'epoch': 1.008240629107572, 'step': 5598000}
INFO:transformers.trainer:{'loss': 3.0813748449087144, 'learning_rate': 3.319448862076116e-05, 'epoch': 1.0083306827543304, 'step': 5598500}
INFO:transformers.trainer:{'loss': 3.066451729655266, 'learning_rate': 3.319298772664852e-05, 'epoch': 1.0084207364010889, 'step': 5599000}
INFO:transformers.trainer:{'loss': 3.069471517324448, 'learning_rate': 3.319148683253588e-05, 'epoch': 1.0085107900478474, 'step': 5599500}
INFO:transformers.trainer:{'loss': 3.0825705711841582, 'learning_rate': 3.318998593842324e-05, 'epoch': 1.0086008436946057, 'step': 5600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0947284405231477, 'learning_rate': 3.31884850443106e-05, 'epoch': 1.0086908973413642, 'step': 5600500}
INFO:transformers.trainer:{'loss': 3.1355309946537018, 'learning_rate': 3.318698415019796e-05, 'epoch': 1.0087809509881227, 'step': 5601000}
INFO:transformers.trainer:{'loss': 3.102760133266449, 'learning_rate': 3.318548325608532e-05, 'epoch': 1.008871004634881, 'step': 5601500}
INFO:transformers.trainer:{'loss': 3.116319009065628, 'learning_rate': 3.3183982361972676e-05, 'epoch': 1.0089610582816395, 'step': 5602000}
INFO:transformers.trainer:{'loss': 3.1298364474773406, 'learning_rate': 3.3182481467860035e-05, 'epoch': 1.009051111928398, 'step': 5602500}
INFO:transformers.trainer:{'loss': 3.061372113704681, 'learning_rate': 3.3180980573747394e-05, 'epoch': 1.0091411655751565, 'step': 5603000}
INFO:transformers.trainer:{'loss': 3.104166391968727, 'learning_rate': 3.317947967963475e-05, 'epoch': 1.0092312192219148, 'step': 5603500}
INFO:transformers.trainer:{'loss': 3.0778944079875945, 'learning_rate': 3.317797878552211e-05, 'epoch': 1.0093212728686733, 'step': 5604000}
INFO:transformers.trainer:{'loss': 3.0691398351192474, 'learning_rate': 3.317647789140947e-05, 'epoch': 1.0094113265154319, 'step': 5604500}
INFO:transformers.trainer:{'loss': 3.112838876724243, 'learning_rate': 3.317497699729683e-05, 'epoch': 1.0095013801621902, 'step': 5605000}
INFO:transformers.trainer:{'loss': 3.0992937898039816, 'learning_rate': 3.317347610318419e-05, 'epoch': 1.0095914338089487, 'step': 5605500}
INFO:transformers.trainer:{'loss': 3.0463016121387483, 'learning_rate': 3.317197520907155e-05, 'epoch': 1.0096814874557072, 'step': 5606000}
INFO:transformers.trainer:{'loss': 3.0644288444519043, 'learning_rate': 3.317047431495891e-05, 'epoch': 1.0097715411024655, 'step': 5606500}
INFO:transformers.trainer:{'loss': 3.0534503083229065, 'learning_rate': 3.3168973420846267e-05, 'epoch': 1.009861594749224, 'step': 5607000}
INFO:transformers.trainer:{'loss': 3.1446630365848542, 'learning_rate': 3.3167472526733626e-05, 'epoch': 1.0099516483959825, 'step': 5607500}
INFO:transformers.trainer:{'loss': 3.082859806776047, 'learning_rate': 3.3165971632620985e-05, 'epoch': 1.0100417020427408, 'step': 5608000}
INFO:transformers.trainer:{'loss': 3.0741942732334135, 'learning_rate': 3.3164470738508344e-05, 'epoch': 1.0101317556894993, 'step': 5608500}
INFO:transformers.trainer:{'loss': 3.074159518957138, 'learning_rate': 3.31629698443957e-05, 'epoch': 1.0102218093362578, 'step': 5609000}
INFO:transformers.trainer:{'loss': 3.057051851987839, 'learning_rate': 3.316146895028306e-05, 'epoch': 1.0103118629830163, 'step': 5609500}
INFO:transformers.trainer:{'loss': 3.1488563027381895, 'learning_rate': 3.315996805617042e-05, 'epoch': 1.0104019166297746, 'step': 5610000}
INFO:transformers.trainer:{'loss': 3.061210187792778, 'learning_rate': 3.315846716205778e-05, 'epoch': 1.0104919702765331, 'step': 5610500}
INFO:transformers.trainer:{'loss': 3.12430703997612, 'learning_rate': 3.3156966267945146e-05, 'epoch': 1.0105820239232917, 'step': 5611000}
INFO:transformers.trainer:{'loss': 3.115829702377319, 'learning_rate': 3.31554653738325e-05, 'epoch': 1.01067207757005, 'step': 5611500}
INFO:transformers.trainer:{'loss': 3.068630073428154, 'learning_rate': 3.3153964479719864e-05, 'epoch': 1.0107621312168085, 'step': 5612000}
INFO:transformers.trainer:{'loss': 3.0857958736419677, 'learning_rate': 3.3152463585607216e-05, 'epoch': 1.010852184863567, 'step': 5612500}
INFO:transformers.trainer:{'loss': 3.061009328365326, 'learning_rate': 3.315096269149458e-05, 'epoch': 1.0109422385103253, 'step': 5613000}
INFO:transformers.trainer:{'loss': 3.079277058839798, 'learning_rate': 3.3149461797381934e-05, 'epoch': 1.0110322921570838, 'step': 5613500}
INFO:transformers.trainer:{'loss': 3.081546987295151, 'learning_rate': 3.31479609032693e-05, 'epoch': 1.0111223458038423, 'step': 5614000}
INFO:transformers.trainer:{'loss': 3.0703693286180496, 'learning_rate': 3.314646000915665e-05, 'epoch': 1.0112123994506008, 'step': 5614500}
INFO:transformers.trainer:{'loss': 3.0713093724250795, 'learning_rate': 3.314495911504402e-05, 'epoch': 1.011302453097359, 'step': 5615000}
INFO:transformers.trainer:{'loss': 3.0645248136520387, 'learning_rate': 3.314345822093137e-05, 'epoch': 1.0113925067441176, 'step': 5615500}
INFO:transformers.trainer:{'loss': 3.11179483628273, 'learning_rate': 3.3141957326818736e-05, 'epoch': 1.0114825603908761, 'step': 5616000}
INFO:transformers.trainer:{'loss': 3.105250970840454, 'learning_rate': 3.314045643270609e-05, 'epoch': 1.0115726140376344, 'step': 5616500}
INFO:transformers.trainer:{'loss': 3.0878703608512876, 'learning_rate': 3.3138955538593454e-05, 'epoch': 1.011662667684393, 'step': 5617000}
INFO:transformers.trainer:{'loss': 3.1755636415481567, 'learning_rate': 3.313745464448081e-05, 'epoch': 1.0117527213311515, 'step': 5617500}
INFO:transformers.trainer:{'loss': 3.149142912387848, 'learning_rate': 3.313595375036817e-05, 'epoch': 1.0118427749779098, 'step': 5618000}
INFO:transformers.trainer:{'loss': 3.141116165399551, 'learning_rate': 3.313445285625553e-05, 'epoch': 1.0119328286246683, 'step': 5618500}
INFO:transformers.trainer:{'loss': 3.075092300653458, 'learning_rate': 3.313295196214289e-05, 'epoch': 1.0120228822714268, 'step': 5619000}
INFO:transformers.trainer:{'loss': 3.120266960144043, 'learning_rate': 3.313145106803025e-05, 'epoch': 1.012112935918185, 'step': 5619500}
INFO:transformers.trainer:{'loss': 3.1065660512447355, 'learning_rate': 3.312995017391761e-05, 'epoch': 1.0122029895649436, 'step': 5620000}
INFO:transformers.trainer:{'loss': 3.096656555056572, 'learning_rate': 3.312844927980497e-05, 'epoch': 1.012293043211702, 'step': 5620500}
INFO:transformers.trainer:{'loss': 3.0918249700069427, 'learning_rate': 3.312694838569233e-05, 'epoch': 1.0123830968584606, 'step': 5621000}
INFO:transformers.trainer:{'loss': 3.078497864961624, 'learning_rate': 3.3125447491579686e-05, 'epoch': 1.012473150505219, 'step': 5621500}
INFO:transformers.trainer:{'loss': 3.0954202723503115, 'learning_rate': 3.3123946597467045e-05, 'epoch': 1.0125632041519774, 'step': 5622000}
INFO:transformers.trainer:{'loss': 3.015511885881424, 'learning_rate': 3.3122445703354404e-05, 'epoch': 1.012653257798736, 'step': 5622500}
INFO:transformers.trainer:{'loss': 3.0789962620735167, 'learning_rate': 3.312094480924176e-05, 'epoch': 1.0127433114454942, 'step': 5623000}
INFO:transformers.trainer:{'loss': 3.0187856713533403, 'learning_rate': 3.311944391512912e-05, 'epoch': 1.0128333650922527, 'step': 5623500}
INFO:transformers.trainer:{'loss': 3.1175839838981627, 'learning_rate': 3.311794302101648e-05, 'epoch': 1.0129234187390113, 'step': 5624000}
INFO:transformers.trainer:{'loss': 3.098807683467865, 'learning_rate': 3.311644212690384e-05, 'epoch': 1.0130134723857696, 'step': 5624500}
INFO:transformers.trainer:{'loss': 3.0467391307353973, 'learning_rate': 3.31149412327912e-05, 'epoch': 1.013103526032528, 'step': 5625000}
INFO:transformers.trainer:{'loss': 3.0809097225666044, 'learning_rate': 3.311344033867856e-05, 'epoch': 1.0131935796792866, 'step': 5625500}
INFO:transformers.trainer:{'loss': 3.078729467868805, 'learning_rate': 3.311193944456592e-05, 'epoch': 1.013283633326045, 'step': 5626000}
INFO:transformers.trainer:{'loss': 3.150701630115509, 'learning_rate': 3.3110438550453276e-05, 'epoch': 1.0133736869728034, 'step': 5626500}
INFO:transformers.trainer:{'loss': 3.112605152130127, 'learning_rate': 3.3108937656340635e-05, 'epoch': 1.013463740619562, 'step': 5627000}
INFO:transformers.trainer:{'loss': 3.1495653092861176, 'learning_rate': 3.3107436762227994e-05, 'epoch': 1.0135537942663204, 'step': 5627500}
INFO:transformers.trainer:{'loss': 3.1398620442152025, 'learning_rate': 3.310593586811535e-05, 'epoch': 1.0136438479130787, 'step': 5628000}
INFO:transformers.trainer:{'loss': 3.0617681579589844, 'learning_rate': 3.310443497400271e-05, 'epoch': 1.0137339015598372, 'step': 5628500}
INFO:transformers.trainer:{'loss': 3.076591434121132, 'learning_rate': 3.310293407989007e-05, 'epoch': 1.0138239552065957, 'step': 5629000}
INFO:transformers.trainer:{'loss': 3.0141655275821684, 'learning_rate': 3.310143318577743e-05, 'epoch': 1.013914008853354, 'step': 5629500}
INFO:transformers.trainer:{'loss': 3.1071348617076873, 'learning_rate': 3.309993229166479e-05, 'epoch': 1.0140040625001125, 'step': 5630000}
INFO:transformers.trainer:{'loss': 3.1266174521446226, 'learning_rate': 3.309843139755215e-05, 'epoch': 1.014094116146871, 'step': 5630500}
INFO:transformers.trainer:{'loss': 3.1010616385936736, 'learning_rate': 3.309693050343951e-05, 'epoch': 1.0141841697936294, 'step': 5631000}
INFO:transformers.trainer:{'loss': 3.1261032189130784, 'learning_rate': 3.3095429609326874e-05, 'epoch': 1.0142742234403879, 'step': 5631500}
INFO:transformers.trainer:{'loss': 3.089350028514862, 'learning_rate': 3.3093928715214226e-05, 'epoch': 1.0143642770871464, 'step': 5632000}
INFO:transformers.trainer:{'loss': 3.11816756105423, 'learning_rate': 3.309242782110159e-05, 'epoch': 1.014454330733905, 'step': 5632500}
INFO:transformers.trainer:{'loss': 3.093695301413536, 'learning_rate': 3.3090926926988944e-05, 'epoch': 1.0145443843806632, 'step': 5633000}
INFO:transformers.trainer:{'loss': 3.1081269050836564, 'learning_rate': 3.308942603287631e-05, 'epoch': 1.0146344380274217, 'step': 5633500}
INFO:transformers.trainer:{'loss': 3.0557992515563965, 'learning_rate': 3.308792513876366e-05, 'epoch': 1.0147244916741802, 'step': 5634000}
INFO:transformers.trainer:{'loss': 3.074366527080536, 'learning_rate': 3.308642424465103e-05, 'epoch': 1.0148145453209385, 'step': 5634500}
INFO:transformers.trainer:{'loss': 3.103746188879013, 'learning_rate': 3.308492335053838e-05, 'epoch': 1.014904598967697, 'step': 5635000}
INFO:transformers.trainer:{'loss': 3.079414718866348, 'learning_rate': 3.3083422456425746e-05, 'epoch': 1.0149946526144555, 'step': 5635500}
INFO:transformers.trainer:{'loss': 3.106432417392731, 'learning_rate': 3.30819215623131e-05, 'epoch': 1.0150847062612138, 'step': 5636000}
INFO:transformers.trainer:{'loss': 3.0334476754665376, 'learning_rate': 3.3080420668200464e-05, 'epoch': 1.0151747599079723, 'step': 5636500}
INFO:transformers.trainer:{'loss': 3.1213193497657774, 'learning_rate': 3.3078919774087816e-05, 'epoch': 1.0152648135547309, 'step': 5637000}
INFO:transformers.trainer:{'loss': 3.088222767472267, 'learning_rate': 3.307741887997518e-05, 'epoch': 1.0153548672014894, 'step': 5637500}
INFO:transformers.trainer:{'loss': 3.0993329095840454, 'learning_rate': 3.307591798586254e-05, 'epoch': 1.0154449208482477, 'step': 5638000}
INFO:transformers.trainer:{'loss': 3.156099514245987, 'learning_rate': 3.30744170917499e-05, 'epoch': 1.0155349744950062, 'step': 5638500}
INFO:transformers.trainer:{'loss': 3.1173517063856124, 'learning_rate': 3.307291619763726e-05, 'epoch': 1.0156250281417647, 'step': 5639000}
INFO:transformers.trainer:{'loss': 3.1050310781002044, 'learning_rate': 3.307141530352462e-05, 'epoch': 1.015715081788523, 'step': 5639500}
INFO:transformers.trainer:{'loss': 3.0870851662158967, 'learning_rate': 3.306991440941198e-05, 'epoch': 1.0158051354352815, 'step': 5640000}
INFO:transformers.trainer:{'loss': 3.119687893152237, 'learning_rate': 3.3068413515299336e-05, 'epoch': 1.01589518908204, 'step': 5640500}
INFO:transformers.trainer:{'loss': 3.1072854957580565, 'learning_rate': 3.3066912621186695e-05, 'epoch': 1.0159852427287983, 'step': 5641000}
INFO:transformers.trainer:{'loss': 3.136617509365082, 'learning_rate': 3.3065411727074055e-05, 'epoch': 1.0160752963755568, 'step': 5641500}
INFO:transformers.trainer:{'loss': 3.103124974131584, 'learning_rate': 3.3063910832961414e-05, 'epoch': 1.0161653500223153, 'step': 5642000}
INFO:transformers.trainer:{'loss': 3.05685901927948, 'learning_rate': 3.306240993884877e-05, 'epoch': 1.0162554036690736, 'step': 5642500}
INFO:transformers.trainer:{'loss': 3.138461001396179, 'learning_rate': 3.306090904473613e-05, 'epoch': 1.0163454573158321, 'step': 5643000}
INFO:transformers.trainer:{'loss': 3.0832856369018553, 'learning_rate': 3.305940815062349e-05, 'epoch': 1.0164355109625907, 'step': 5643500}
INFO:transformers.trainer:{'loss': 3.0702293422222136, 'learning_rate': 3.305790725651085e-05, 'epoch': 1.0165255646093492, 'step': 5644000}
INFO:transformers.trainer:{'loss': 3.1494217777252196, 'learning_rate': 3.305640636239821e-05, 'epoch': 1.0166156182561075, 'step': 5644500}
INFO:transformers.trainer:{'loss': 3.131461092710495, 'learning_rate': 3.305490546828557e-05, 'epoch': 1.016705671902866, 'step': 5645000}
INFO:transformers.trainer:{'loss': 3.1043205435276033, 'learning_rate': 3.3053404574172934e-05, 'epoch': 1.0167957255496245, 'step': 5645500}
INFO:transformers.trainer:{'loss': 3.1047730873823167, 'learning_rate': 3.3051903680060286e-05, 'epoch': 1.0168857791963828, 'step': 5646000}
INFO:transformers.trainer:{'loss': 3.1081467915773393, 'learning_rate': 3.3050402785947645e-05, 'epoch': 1.0169758328431413, 'step': 5646500}
INFO:transformers.trainer:{'loss': 3.1197326867580415, 'learning_rate': 3.3048901891835004e-05, 'epoch': 1.0170658864898998, 'step': 5647000}
INFO:transformers.trainer:{'loss': 3.1113550510406496, 'learning_rate': 3.304740099772236e-05, 'epoch': 1.017155940136658, 'step': 5647500}
INFO:transformers.trainer:{'loss': 3.0939518005847932, 'learning_rate': 3.304590010360972e-05, 'epoch': 1.0172459937834166, 'step': 5648000}
INFO:transformers.trainer:{'loss': 3.1358717465400696, 'learning_rate': 3.304439920949708e-05, 'epoch': 1.0173360474301751, 'step': 5648500}
INFO:transformers.trainer:{'loss': 3.0559337384700775, 'learning_rate': 3.304289831538444e-05, 'epoch': 1.0174261010769337, 'step': 5649000}
INFO:transformers.trainer:{'loss': 3.09236590385437, 'learning_rate': 3.30413974212718e-05, 'epoch': 1.017516154723692, 'step': 5649500}
INFO:transformers.trainer:{'loss': 3.0547162017822265, 'learning_rate': 3.303989652715916e-05, 'epoch': 1.0176062083704505, 'step': 5650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.120536860585213, 'learning_rate': 3.303839563304652e-05, 'epoch': 1.017696262017209, 'step': 5650500}
INFO:transformers.trainer:{'loss': 3.0746094566583633, 'learning_rate': 3.3036894738933876e-05, 'epoch': 1.0177863156639673, 'step': 5651000}
INFO:transformers.trainer:{'loss': 3.0953245487213135, 'learning_rate': 3.3035393844821236e-05, 'epoch': 1.0178763693107258, 'step': 5651500}
INFO:transformers.trainer:{'loss': 3.076068503141403, 'learning_rate': 3.30338929507086e-05, 'epoch': 1.0179664229574843, 'step': 5652000}
INFO:transformers.trainer:{'loss': 3.120124506235123, 'learning_rate': 3.3032392056595954e-05, 'epoch': 1.0180564766042426, 'step': 5652500}
INFO:transformers.trainer:{'loss': 3.063294857263565, 'learning_rate': 3.303089116248332e-05, 'epoch': 1.018146530251001, 'step': 5653000}
INFO:transformers.trainer:{'loss': 3.0495473473072052, 'learning_rate': 3.302939026837067e-05, 'epoch': 1.0182365838977596, 'step': 5653500}
INFO:transformers.trainer:{'loss': 3.113594713449478, 'learning_rate': 3.302788937425804e-05, 'epoch': 1.0183266375445181, 'step': 5654000}
INFO:transformers.trainer:{'loss': 3.1123361514806747, 'learning_rate': 3.302638848014539e-05, 'epoch': 1.0184166911912764, 'step': 5654500}
INFO:transformers.trainer:{'loss': 3.112061956882477, 'learning_rate': 3.3024887586032756e-05, 'epoch': 1.018506744838035, 'step': 5655000}
INFO:transformers.trainer:{'loss': 3.0771448984146117, 'learning_rate': 3.302338669192011e-05, 'epoch': 1.0185967984847935, 'step': 5655500}
INFO:transformers.trainer:{'loss': 3.1532926464080813, 'learning_rate': 3.3021885797807474e-05, 'epoch': 1.0186868521315517, 'step': 5656000}
INFO:transformers.trainer:{'loss': 3.1075867220163347, 'learning_rate': 3.3020384903694826e-05, 'epoch': 1.0187769057783103, 'step': 5656500}
INFO:transformers.trainer:{'loss': 3.106378726243973, 'learning_rate': 3.301888400958219e-05, 'epoch': 1.0188669594250688, 'step': 5657000}
INFO:transformers.trainer:{'loss': 3.1327035236358642, 'learning_rate': 3.3017383115469544e-05, 'epoch': 1.018957013071827, 'step': 5657500}
INFO:transformers.trainer:{'loss': 3.1761890137195588, 'learning_rate': 3.301588222135691e-05, 'epoch': 1.0190470667185856, 'step': 5658000}
INFO:transformers.trainer:{'loss': 3.0757796173095704, 'learning_rate': 3.301438132724426e-05, 'epoch': 1.019137120365344, 'step': 5658500}
INFO:transformers.trainer:{'loss': 3.0841098470687864, 'learning_rate': 3.301288043313163e-05, 'epoch': 1.0192271740121024, 'step': 5659000}
INFO:transformers.trainer:{'loss': 3.077272583961487, 'learning_rate': 3.301137953901899e-05, 'epoch': 1.019317227658861, 'step': 5659500}
INFO:transformers.trainer:{'loss': 3.1482327408790587, 'learning_rate': 3.3009878644906346e-05, 'epoch': 1.0194072813056194, 'step': 5660000}
INFO:transformers.trainer:{'loss': 3.1208780212402343, 'learning_rate': 3.3008377750793705e-05, 'epoch': 1.019497334952378, 'step': 5660500}
INFO:transformers.trainer:{'loss': 3.0338866238594053, 'learning_rate': 3.3006876856681064e-05, 'epoch': 1.0195873885991362, 'step': 5661000}
INFO:transformers.trainer:{'loss': 3.0468138403892517, 'learning_rate': 3.300537596256842e-05, 'epoch': 1.0196774422458947, 'step': 5661500}
INFO:transformers.trainer:{'loss': 3.0547309346199034, 'learning_rate': 3.300387506845578e-05, 'epoch': 1.0197674958926533, 'step': 5662000}
INFO:transformers.trainer:{'loss': 3.0444670305252077, 'learning_rate': 3.300237417434314e-05, 'epoch': 1.0198575495394115, 'step': 5662500}
INFO:transformers.trainer:{'loss': 3.121394969344139, 'learning_rate': 3.30008732802305e-05, 'epoch': 1.01994760318617, 'step': 5663000}
INFO:transformers.trainer:{'loss': 3.118132638216019, 'learning_rate': 3.299937238611786e-05, 'epoch': 1.0200376568329286, 'step': 5663500}
INFO:transformers.trainer:{'loss': 3.1023602170944216, 'learning_rate': 3.299787149200522e-05, 'epoch': 1.0201277104796869, 'step': 5664000}
INFO:transformers.trainer:{'loss': 3.0251669964790344, 'learning_rate': 3.299637059789258e-05, 'epoch': 1.0202177641264454, 'step': 5664500}
INFO:transformers.trainer:{'loss': 3.1034211132526397, 'learning_rate': 3.299486970377994e-05, 'epoch': 1.020307817773204, 'step': 5665000}
INFO:transformers.trainer:{'loss': 3.1105225138664245, 'learning_rate': 3.2993368809667296e-05, 'epoch': 1.0203978714199624, 'step': 5665500}
INFO:transformers.trainer:{'loss': 3.0789241552352906, 'learning_rate': 3.299186791555466e-05, 'epoch': 1.0204879250667207, 'step': 5666000}
INFO:transformers.trainer:{'loss': 3.1800693907737734, 'learning_rate': 3.2990367021442014e-05, 'epoch': 1.0205779787134792, 'step': 5666500}
INFO:transformers.trainer:{'loss': 3.074188951253891, 'learning_rate': 3.298886612732938e-05, 'epoch': 1.0206680323602377, 'step': 5667000}
INFO:transformers.trainer:{'loss': 3.109918961405754, 'learning_rate': 3.298736523321673e-05, 'epoch': 1.020758086006996, 'step': 5667500}
INFO:transformers.trainer:{'loss': 3.0458532168865204, 'learning_rate': 3.29858643391041e-05, 'epoch': 1.0208481396537545, 'step': 5668000}
INFO:transformers.trainer:{'loss': 3.04612308049202, 'learning_rate': 3.298436344499145e-05, 'epoch': 1.020938193300513, 'step': 5668500}
INFO:transformers.trainer:{'loss': 3.156580903530121, 'learning_rate': 3.2982862550878816e-05, 'epoch': 1.0210282469472713, 'step': 5669000}
INFO:transformers.trainer:{'loss': 3.061977437734604, 'learning_rate': 3.298136165676617e-05, 'epoch': 1.0211183005940299, 'step': 5669500}
INFO:transformers.trainer:{'loss': 3.1083631496429445, 'learning_rate': 3.2979860762653534e-05, 'epoch': 1.0212083542407884, 'step': 5670000}
INFO:transformers.trainer:{'loss': 3.0177540001869203, 'learning_rate': 3.2978359868540886e-05, 'epoch': 1.0212984078875467, 'step': 5670500}
INFO:transformers.trainer:{'loss': 3.126963366508484, 'learning_rate': 3.2976858974428245e-05, 'epoch': 1.0213884615343052, 'step': 5671000}
INFO:transformers.trainer:{'loss': 2.9955446113348008, 'learning_rate': 3.2975358080315604e-05, 'epoch': 1.0214785151810637, 'step': 5671500}
INFO:transformers.trainer:{'loss': 3.0185697441101076, 'learning_rate': 3.297385718620296e-05, 'epoch': 1.0215685688278222, 'step': 5672000}
INFO:transformers.trainer:{'loss': 3.0855077784061433, 'learning_rate': 3.297235629209033e-05, 'epoch': 1.0216586224745805, 'step': 5672500}
INFO:transformers.trainer:{'loss': 3.1019186747074126, 'learning_rate': 3.297085539797768e-05, 'epoch': 1.021748676121339, 'step': 5673000}
INFO:transformers.trainer:{'loss': 3.10304921913147, 'learning_rate': 3.296935450386505e-05, 'epoch': 1.0218387297680975, 'step': 5673500}
INFO:transformers.trainer:{'loss': 3.0839695694446565, 'learning_rate': 3.29678536097524e-05, 'epoch': 1.0219287834148558, 'step': 5674000}
INFO:transformers.trainer:{'loss': 3.1167793296575548, 'learning_rate': 3.2966352715639765e-05, 'epoch': 1.0220188370616143, 'step': 5674500}
INFO:transformers.trainer:{'loss': 3.128418818950653, 'learning_rate': 3.296485182152712e-05, 'epoch': 1.0221088907083729, 'step': 5675000}
INFO:transformers.trainer:{'loss': 3.182422595977783, 'learning_rate': 3.2963350927414483e-05, 'epoch': 1.0221989443551311, 'step': 5675500}
INFO:transformers.trainer:{'loss': 3.086155986070633, 'learning_rate': 3.2961850033301836e-05, 'epoch': 1.0222889980018897, 'step': 5676000}
INFO:transformers.trainer:{'loss': 3.1115141298770905, 'learning_rate': 3.29603491391892e-05, 'epoch': 1.0223790516486482, 'step': 5676500}
INFO:transformers.trainer:{'loss': 3.0001355607509614, 'learning_rate': 3.2958848245076554e-05, 'epoch': 1.0224691052954067, 'step': 5677000}
INFO:transformers.trainer:{'loss': 3.1437276133298875, 'learning_rate': 3.295734735096392e-05, 'epoch': 1.022559158942165, 'step': 5677500}
INFO:transformers.trainer:{'loss': 3.0186867859363558, 'learning_rate': 3.295584645685127e-05, 'epoch': 1.0226492125889235, 'step': 5678000}
INFO:transformers.trainer:{'loss': 3.0657162569761276, 'learning_rate': 3.295434556273864e-05, 'epoch': 1.022739266235682, 'step': 5678500}
INFO:transformers.trainer:{'loss': 3.108129069805145, 'learning_rate': 3.295284466862599e-05, 'epoch': 1.0228293198824403, 'step': 5679000}
INFO:transformers.trainer:{'loss': 3.08098553943634, 'learning_rate': 3.2951343774513356e-05, 'epoch': 1.0229193735291988, 'step': 5679500}
INFO:transformers.trainer:{'loss': 3.106615568161011, 'learning_rate': 3.2949842880400715e-05, 'epoch': 1.0230094271759573, 'step': 5680000}
INFO:transformers.trainer:{'loss': 3.0560157663822176, 'learning_rate': 3.2948341986288074e-05, 'epoch': 1.0230994808227156, 'step': 5680500}
INFO:transformers.trainer:{'loss': 3.044457525730133, 'learning_rate': 3.294684109217543e-05, 'epoch': 1.0231895344694741, 'step': 5681000}
INFO:transformers.trainer:{'loss': 3.0374108538627627, 'learning_rate': 3.294534019806279e-05, 'epoch': 1.0232795881162327, 'step': 5681500}
INFO:transformers.trainer:{'loss': 3.0980543117523194, 'learning_rate': 3.294383930395015e-05, 'epoch': 1.023369641762991, 'step': 5682000}
INFO:transformers.trainer:{'loss': 3.0853486287593843, 'learning_rate': 3.294233840983751e-05, 'epoch': 1.0234596954097495, 'step': 5682500}
INFO:transformers.trainer:{'loss': 3.0736486251354216, 'learning_rate': 3.294083751572487e-05, 'epoch': 1.023549749056508, 'step': 5683000}
INFO:transformers.trainer:{'loss': 3.1274035382270813, 'learning_rate': 3.293933662161223e-05, 'epoch': 1.0236398027032665, 'step': 5683500}
INFO:transformers.trainer:{'loss': 3.1573473088741304, 'learning_rate': 3.293783572749959e-05, 'epoch': 1.0237298563500248, 'step': 5684000}
INFO:transformers.trainer:{'loss': 3.0978865485191345, 'learning_rate': 3.2936334833386946e-05, 'epoch': 1.0238199099967833, 'step': 5684500}
INFO:transformers.trainer:{'loss': 3.0885138347148895, 'learning_rate': 3.2934833939274305e-05, 'epoch': 1.0239099636435418, 'step': 5685000}
INFO:transformers.trainer:{'loss': 3.088292661905289, 'learning_rate': 3.2933333045161664e-05, 'epoch': 1.0240000172903, 'step': 5685500}
INFO:transformers.trainer:{'loss': 3.0994618468284605, 'learning_rate': 3.2931832151049024e-05, 'epoch': 1.0240900709370586, 'step': 5686000}
INFO:transformers.trainer:{'loss': 3.0688444719314574, 'learning_rate': 3.293033125693639e-05, 'epoch': 1.0241801245838171, 'step': 5686500}
INFO:transformers.trainer:{'loss': 3.15488156414032, 'learning_rate': 3.292883036282374e-05, 'epoch': 1.0242701782305754, 'step': 5687000}
INFO:transformers.trainer:{'loss': 3.0674849939346314, 'learning_rate': 3.292732946871111e-05, 'epoch': 1.024360231877334, 'step': 5687500}
INFO:transformers.trainer:{'loss': 3.1000842509269715, 'learning_rate': 3.292582857459846e-05, 'epoch': 1.0244502855240925, 'step': 5688000}
INFO:transformers.trainer:{'loss': 3.1049537000656127, 'learning_rate': 3.2924327680485826e-05, 'epoch': 1.024540339170851, 'step': 5688500}
INFO:transformers.trainer:{'loss': 3.058175820827484, 'learning_rate': 3.292282678637318e-05, 'epoch': 1.0246303928176093, 'step': 5689000}
INFO:transformers.trainer:{'loss': 3.0701079301834104, 'learning_rate': 3.2921325892260544e-05, 'epoch': 1.0247204464643678, 'step': 5689500}
INFO:transformers.trainer:{'loss': 3.0913000375032427, 'learning_rate': 3.2919824998147896e-05, 'epoch': 1.0248105001111263, 'step': 5690000}
INFO:transformers.trainer:{'loss': 3.056530291557312, 'learning_rate': 3.291832410403526e-05, 'epoch': 1.0249005537578846, 'step': 5690500}
INFO:transformers.trainer:{'loss': 3.114354049682617, 'learning_rate': 3.2916823209922614e-05, 'epoch': 1.024990607404643, 'step': 5691000}
INFO:transformers.trainer:{'loss': 3.1003788514137267, 'learning_rate': 3.291532231580998e-05, 'epoch': 1.0250806610514016, 'step': 5691500}
INFO:transformers.trainer:{'loss': 3.0940026009082793, 'learning_rate': 3.291382142169733e-05, 'epoch': 1.02517071469816, 'step': 5692000}
INFO:transformers.trainer:{'loss': 3.094768984556198, 'learning_rate': 3.29123205275847e-05, 'epoch': 1.0252607683449184, 'step': 5692500}
INFO:transformers.trainer:{'loss': 3.1052178946733475, 'learning_rate': 3.291081963347205e-05, 'epoch': 1.025350821991677, 'step': 5693000}
INFO:transformers.trainer:{'loss': 3.1268576420545577, 'learning_rate': 3.2909318739359416e-05, 'epoch': 1.0254408756384352, 'step': 5693500}
INFO:transformers.trainer:{'loss': 3.0946314907073975, 'learning_rate': 3.2907817845246775e-05, 'epoch': 1.0255309292851937, 'step': 5694000}
INFO:transformers.trainer:{'loss': 3.12862735915184, 'learning_rate': 3.290631695113413e-05, 'epoch': 1.0256209829319523, 'step': 5694500}
INFO:transformers.trainer:{'loss': 3.1345349663496016, 'learning_rate': 3.290481605702149e-05, 'epoch': 1.0257110365787108, 'step': 5695000}
INFO:transformers.trainer:{'loss': 3.1118997433185576, 'learning_rate': 3.2903315162908845e-05, 'epoch': 1.025801090225469, 'step': 5695500}
INFO:transformers.trainer:{'loss': 3.1196528742313383, 'learning_rate': 3.290181426879621e-05, 'epoch': 1.0258911438722276, 'step': 5696000}
INFO:transformers.trainer:{'loss': 3.055652132034302, 'learning_rate': 3.2900313374683564e-05, 'epoch': 1.025981197518986, 'step': 5696500}
INFO:transformers.trainer:{'loss': 3.0755610504746436, 'learning_rate': 3.289881248057093e-05, 'epoch': 1.0260712511657444, 'step': 5697000}
INFO:transformers.trainer:{'loss': 3.13160240650177, 'learning_rate': 3.289731158645828e-05, 'epoch': 1.026161304812503, 'step': 5697500}
INFO:transformers.trainer:{'loss': 2.983913425564766, 'learning_rate': 3.289581069234565e-05, 'epoch': 1.0262513584592614, 'step': 5698000}
INFO:transformers.trainer:{'loss': 3.11897554397583, 'learning_rate': 3.2894309798233e-05, 'epoch': 1.0263414121060197, 'step': 5698500}
INFO:transformers.trainer:{'loss': 2.9857202756404875, 'learning_rate': 3.2892808904120366e-05, 'epoch': 1.0264314657527782, 'step': 5699000}
INFO:transformers.trainer:{'loss': 3.052074046134949, 'learning_rate': 3.289130801000772e-05, 'epoch': 1.0265215193995367, 'step': 5699500}
INFO:transformers.trainer:{'loss': 3.0866931912899016, 'learning_rate': 3.2889807115895084e-05, 'epoch': 1.0266115730462952, 'step': 5700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1298813891410826, 'learning_rate': 3.288830622178244e-05, 'epoch': 1.0267016266930535, 'step': 5700500}
INFO:transformers.trainer:{'loss': 3.14684876203537, 'learning_rate': 3.28868053276698e-05, 'epoch': 1.026791680339812, 'step': 5701000}
INFO:transformers.trainer:{'loss': 3.1818825867176055, 'learning_rate': 3.288530443355716e-05, 'epoch': 1.0268817339865706, 'step': 5701500}
INFO:transformers.trainer:{'loss': 3.092084142923355, 'learning_rate': 3.288380353944452e-05, 'epoch': 1.0269717876333289, 'step': 5702000}
INFO:transformers.trainer:{'loss': 3.0954849597215652, 'learning_rate': 3.288230264533188e-05, 'epoch': 1.0270618412800874, 'step': 5702500}
INFO:transformers.trainer:{'loss': 3.19670978474617, 'learning_rate': 3.288080175121924e-05, 'epoch': 1.0271518949268459, 'step': 5703000}
INFO:transformers.trainer:{'loss': 3.1281854193210603, 'learning_rate': 3.28793008571066e-05, 'epoch': 1.0272419485736042, 'step': 5703500}
INFO:transformers.trainer:{'loss': 3.1110341641902926, 'learning_rate': 3.2877799962993956e-05, 'epoch': 1.0273320022203627, 'step': 5704000}
INFO:transformers.trainer:{'loss': 3.1164818032979964, 'learning_rate': 3.2876299068881315e-05, 'epoch': 1.0274220558671212, 'step': 5704500}
INFO:transformers.trainer:{'loss': 3.049956353664398, 'learning_rate': 3.2874798174768674e-05, 'epoch': 1.0275121095138795, 'step': 5705000}
INFO:transformers.trainer:{'loss': 3.104338055729866, 'learning_rate': 3.287329728065603e-05, 'epoch': 1.027602163160638, 'step': 5705500}
INFO:transformers.trainer:{'loss': 3.091779382824898, 'learning_rate': 3.287179638654339e-05, 'epoch': 1.0276922168073965, 'step': 5706000}
INFO:transformers.trainer:{'loss': 3.1364048820734025, 'learning_rate': 3.287029549243075e-05, 'epoch': 1.027782270454155, 'step': 5706500}
INFO:transformers.trainer:{'loss': 3.098114307165146, 'learning_rate': 3.286879459831811e-05, 'epoch': 1.0278723241009133, 'step': 5707000}
INFO:transformers.trainer:{'loss': 3.120985000133514, 'learning_rate': 3.286729370420547e-05, 'epoch': 1.0279623777476719, 'step': 5707500}
INFO:transformers.trainer:{'loss': 3.122490639925003, 'learning_rate': 3.2865792810092835e-05, 'epoch': 1.0280524313944304, 'step': 5708000}
INFO:transformers.trainer:{'loss': 3.1038007950782776, 'learning_rate': 3.286429191598019e-05, 'epoch': 1.0281424850411887, 'step': 5708500}
INFO:transformers.trainer:{'loss': 3.1096210206747057, 'learning_rate': 3.286279102186755e-05, 'epoch': 1.0282325386879472, 'step': 5709000}
INFO:transformers.trainer:{'loss': 3.1140996927022933, 'learning_rate': 3.2861290127754906e-05, 'epoch': 1.0283225923347057, 'step': 5709500}
INFO:transformers.trainer:{'loss': 3.1073392612934114, 'learning_rate': 3.285978923364227e-05, 'epoch': 1.028412645981464, 'step': 5710000}
INFO:transformers.trainer:{'loss': 3.1011895155906677, 'learning_rate': 3.2858288339529624e-05, 'epoch': 1.0285026996282225, 'step': 5710500}
INFO:transformers.trainer:{'loss': 3.0829826295375824, 'learning_rate': 3.285678744541699e-05, 'epoch': 1.028592753274981, 'step': 5711000}
INFO:transformers.trainer:{'loss': 3.076560985326767, 'learning_rate': 3.285528655130434e-05, 'epoch': 1.0286828069217395, 'step': 5711500}
INFO:transformers.trainer:{'loss': 3.1168270988464357, 'learning_rate': 3.285378565719171e-05, 'epoch': 1.0287728605684978, 'step': 5712000}
INFO:transformers.trainer:{'loss': 3.063330779314041, 'learning_rate': 3.285228476307906e-05, 'epoch': 1.0288629142152563, 'step': 5712500}
INFO:transformers.trainer:{'loss': 3.10596836912632, 'learning_rate': 3.2850783868966426e-05, 'epoch': 1.0289529678620148, 'step': 5713000}
INFO:transformers.trainer:{'loss': 3.0479324235916136, 'learning_rate': 3.284928297485378e-05, 'epoch': 1.0290430215087731, 'step': 5713500}
INFO:transformers.trainer:{'loss': 3.0994240682125094, 'learning_rate': 3.2847782080741144e-05, 'epoch': 1.0291330751555317, 'step': 5714000}
INFO:transformers.trainer:{'loss': 3.0516127307415006, 'learning_rate': 3.28462811866285e-05, 'epoch': 1.0292231288022902, 'step': 5714500}
INFO:transformers.trainer:{'loss': 3.0759310205578805, 'learning_rate': 3.284478029251586e-05, 'epoch': 1.0293131824490485, 'step': 5715000}
INFO:transformers.trainer:{'loss': 3.093013615489006, 'learning_rate': 3.284327939840322e-05, 'epoch': 1.029403236095807, 'step': 5715500}
INFO:transformers.trainer:{'loss': 3.046022340774536, 'learning_rate': 3.284177850429058e-05, 'epoch': 1.0294932897425655, 'step': 5716000}
INFO:transformers.trainer:{'loss': 3.1123143379688263, 'learning_rate': 3.284027761017794e-05, 'epoch': 1.0295833433893238, 'step': 5716500}
INFO:transformers.trainer:{'loss': 3.1178111934661867, 'learning_rate': 3.28387767160653e-05, 'epoch': 1.0296733970360823, 'step': 5717000}
INFO:transformers.trainer:{'loss': 3.062446119785309, 'learning_rate': 3.283727582195266e-05, 'epoch': 1.0297634506828408, 'step': 5717500}
INFO:transformers.trainer:{'loss': 3.0836577587127687, 'learning_rate': 3.283577492784001e-05, 'epoch': 1.0298535043295993, 'step': 5718000}
INFO:transformers.trainer:{'loss': 3.0987691917419435, 'learning_rate': 3.2834274033727375e-05, 'epoch': 1.0299435579763576, 'step': 5718500}
INFO:transformers.trainer:{'loss': 3.111327406644821, 'learning_rate': 3.283277313961473e-05, 'epoch': 1.0300336116231161, 'step': 5719000}
INFO:transformers.trainer:{'loss': 3.0999212836027144, 'learning_rate': 3.2831272245502093e-05, 'epoch': 1.0301236652698746, 'step': 5719500}
INFO:transformers.trainer:{'loss': 3.112736701488495, 'learning_rate': 3.2829771351389446e-05, 'epoch': 1.030213718916633, 'step': 5720000}
INFO:transformers.trainer:{'loss': 3.0786265726089477, 'learning_rate': 3.282827045727681e-05, 'epoch': 1.0303037725633915, 'step': 5720500}
INFO:transformers.trainer:{'loss': 3.0549355056285856, 'learning_rate': 3.2826769563164164e-05, 'epoch': 1.03039382621015, 'step': 5721000}
INFO:transformers.trainer:{'loss': 3.100698342084885, 'learning_rate': 3.282526866905153e-05, 'epoch': 1.0304838798569083, 'step': 5721500}
INFO:transformers.trainer:{'loss': 3.118523878455162, 'learning_rate': 3.282376777493889e-05, 'epoch': 1.0305739335036668, 'step': 5722000}
INFO:transformers.trainer:{'loss': 3.1276555157899857, 'learning_rate': 3.282226688082625e-05, 'epoch': 1.0306639871504253, 'step': 5722500}
INFO:transformers.trainer:{'loss': 3.097320447206497, 'learning_rate': 3.282076598671361e-05, 'epoch': 1.0307540407971838, 'step': 5723000}
INFO:transformers.trainer:{'loss': 3.088542913198471, 'learning_rate': 3.2819265092600966e-05, 'epoch': 1.030844094443942, 'step': 5723500}
INFO:transformers.trainer:{'loss': 3.025357789516449, 'learning_rate': 3.2817764198488325e-05, 'epoch': 1.0309341480907006, 'step': 5724000}
INFO:transformers.trainer:{'loss': 3.111055117368698, 'learning_rate': 3.2816263304375684e-05, 'epoch': 1.0310242017374591, 'step': 5724500}
INFO:transformers.trainer:{'loss': 3.0922184995412825, 'learning_rate': 3.281476241026304e-05, 'epoch': 1.0311142553842174, 'step': 5725000}
INFO:transformers.trainer:{'loss': 3.126402784228325, 'learning_rate': 3.28132615161504e-05, 'epoch': 1.031204309030976, 'step': 5725500}
INFO:transformers.trainer:{'loss': 3.0786885582208634, 'learning_rate': 3.281176062203776e-05, 'epoch': 1.0312943626777344, 'step': 5726000}
INFO:transformers.trainer:{'loss': 3.076435844898224, 'learning_rate': 3.281025972792512e-05, 'epoch': 1.0313844163244927, 'step': 5726500}
INFO:transformers.trainer:{'loss': 3.1115581362247466, 'learning_rate': 3.280875883381248e-05, 'epoch': 1.0314744699712513, 'step': 5727000}
INFO:transformers.trainer:{'loss': 3.0487151811122892, 'learning_rate': 3.280725793969984e-05, 'epoch': 1.0315645236180098, 'step': 5727500}
INFO:transformers.trainer:{'loss': 3.0886742160320284, 'learning_rate': 3.28057570455872e-05, 'epoch': 1.031654577264768, 'step': 5728000}
INFO:transformers.trainer:{'loss': 3.075323296427727, 'learning_rate': 3.280425615147456e-05, 'epoch': 1.0317446309115266, 'step': 5728500}
INFO:transformers.trainer:{'loss': 3.0195245696306228, 'learning_rate': 3.2802755257361915e-05, 'epoch': 1.031834684558285, 'step': 5729000}
INFO:transformers.trainer:{'loss': 3.1039636821746828, 'learning_rate': 3.280125436324928e-05, 'epoch': 1.0319247382050436, 'step': 5729500}
INFO:transformers.trainer:{'loss': 3.1129436008930207, 'learning_rate': 3.2799753469136633e-05, 'epoch': 1.032014791851802, 'step': 5730000}
INFO:transformers.trainer:{'loss': 3.0562428282499314, 'learning_rate': 3.2798252575024e-05, 'epoch': 1.0321048454985604, 'step': 5730500}
INFO:transformers.trainer:{'loss': 3.1098597449064256, 'learning_rate': 3.279675168091135e-05, 'epoch': 1.032194899145319, 'step': 5731000}
INFO:transformers.trainer:{'loss': 3.1129549698829653, 'learning_rate': 3.279525078679872e-05, 'epoch': 1.0322849527920772, 'step': 5731500}
INFO:transformers.trainer:{'loss': 3.0622674696445467, 'learning_rate': 3.279374989268607e-05, 'epoch': 1.0323750064388357, 'step': 5732000}
INFO:transformers.trainer:{'loss': 3.0599970684051514, 'learning_rate': 3.2792248998573435e-05, 'epoch': 1.0324650600855942, 'step': 5732500}
INFO:transformers.trainer:{'loss': 3.065719538450241, 'learning_rate': 3.279074810446079e-05, 'epoch': 1.0325551137323525, 'step': 5733000}
INFO:transformers.trainer:{'loss': 3.0896663274765013, 'learning_rate': 3.2789247210348154e-05, 'epoch': 1.032645167379111, 'step': 5733500}
INFO:transformers.trainer:{'loss': 3.1316202948093412, 'learning_rate': 3.2787746316235506e-05, 'epoch': 1.0327352210258696, 'step': 5734000}
INFO:transformers.trainer:{'loss': 3.0487910759449006, 'learning_rate': 3.278624542212287e-05, 'epoch': 1.032825274672628, 'step': 5734500}
INFO:transformers.trainer:{'loss': 3.057335299372673, 'learning_rate': 3.278474452801023e-05, 'epoch': 1.0329153283193864, 'step': 5735000}
INFO:transformers.trainer:{'loss': 3.0897886934280394, 'learning_rate': 3.278324363389759e-05, 'epoch': 1.0330053819661449, 'step': 5735500}
INFO:transformers.trainer:{'loss': 3.103121733427048, 'learning_rate': 3.278174273978495e-05, 'epoch': 1.0330954356129034, 'step': 5736000}
INFO:transformers.trainer:{'loss': 3.0915403859615327, 'learning_rate': 3.278024184567231e-05, 'epoch': 1.0331854892596617, 'step': 5736500}
INFO:transformers.trainer:{'loss': 3.1349334237575532, 'learning_rate': 3.277874095155967e-05, 'epoch': 1.0332755429064202, 'step': 5737000}
INFO:transformers.trainer:{'loss': 3.086366225719452, 'learning_rate': 3.2777240057447026e-05, 'epoch': 1.0333655965531787, 'step': 5737500}
INFO:transformers.trainer:{'loss': 3.1184703677892687, 'learning_rate': 3.2775739163334385e-05, 'epoch': 1.033455650199937, 'step': 5738000}
INFO:transformers.trainer:{'loss': 3.1243375490903853, 'learning_rate': 3.2774238269221744e-05, 'epoch': 1.0335457038466955, 'step': 5738500}
INFO:transformers.trainer:{'loss': 3.1104804713726044, 'learning_rate': 3.27727373751091e-05, 'epoch': 1.033635757493454, 'step': 5739000}
INFO:transformers.trainer:{'loss': 3.056802275657654, 'learning_rate': 3.277123648099646e-05, 'epoch': 1.0337258111402123, 'step': 5739500}
INFO:transformers.trainer:{'loss': 3.1609132118225096, 'learning_rate': 3.276973558688382e-05, 'epoch': 1.0338158647869709, 'step': 5740000}
INFO:transformers.trainer:{'loss': 3.1462780705690383, 'learning_rate': 3.276823469277118e-05, 'epoch': 1.0339059184337294, 'step': 5740500}
INFO:transformers.trainer:{'loss': 3.071011323213577, 'learning_rate': 3.276673379865854e-05, 'epoch': 1.0339959720804879, 'step': 5741000}
INFO:transformers.trainer:{'loss': 3.093211458802223, 'learning_rate': 3.276523290454589e-05, 'epoch': 1.0340860257272462, 'step': 5741500}
INFO:transformers.trainer:{'loss': 3.135593106031418, 'learning_rate': 3.276373201043326e-05, 'epoch': 1.0341760793740047, 'step': 5742000}
INFO:transformers.trainer:{'loss': 3.0797302923202516, 'learning_rate': 3.2762231116320616e-05, 'epoch': 1.0342661330207632, 'step': 5742500}
INFO:transformers.trainer:{'loss': 3.1529117867946623, 'learning_rate': 3.2760730222207976e-05, 'epoch': 1.0343561866675215, 'step': 5743000}
INFO:transformers.trainer:{'loss': 3.0520461325645445, 'learning_rate': 3.2759229328095335e-05, 'epoch': 1.03444624031428, 'step': 5743500}
INFO:transformers.trainer:{'loss': 3.0941553102731705, 'learning_rate': 3.2757728433982694e-05, 'epoch': 1.0345362939610385, 'step': 5744000}
INFO:transformers.trainer:{'loss': 3.0871604638099672, 'learning_rate': 3.275622753987005e-05, 'epoch': 1.0346263476077968, 'step': 5744500}
INFO:transformers.trainer:{'loss': 3.019286247253418, 'learning_rate': 3.275472664575741e-05, 'epoch': 1.0347164012545553, 'step': 5745000}
INFO:transformers.trainer:{'loss': 3.1009515376091, 'learning_rate': 3.275322575164477e-05, 'epoch': 1.0348064549013138, 'step': 5745500}
INFO:transformers.trainer:{'loss': 3.190799632549286, 'learning_rate': 3.275172485753213e-05, 'epoch': 1.0348965085480724, 'step': 5746000}
INFO:transformers.trainer:{'loss': 3.1313667946457864, 'learning_rate': 3.275022396341949e-05, 'epoch': 1.0349865621948307, 'step': 5746500}
INFO:transformers.trainer:{'loss': 3.081739686012268, 'learning_rate': 3.274872306930685e-05, 'epoch': 1.0350766158415892, 'step': 5747000}
INFO:transformers.trainer:{'loss': 3.148333772778511, 'learning_rate': 3.274722217519421e-05, 'epoch': 1.0351666694883477, 'step': 5747500}
INFO:transformers.trainer:{'loss': 3.0541280198097227, 'learning_rate': 3.2745721281081566e-05, 'epoch': 1.035256723135106, 'step': 5748000}
INFO:transformers.trainer:{'loss': 3.1426010363101957, 'learning_rate': 3.2744220386968925e-05, 'epoch': 1.0353467767818645, 'step': 5748500}
INFO:transformers.trainer:{'loss': 3.103520154953003, 'learning_rate': 3.274271949285629e-05, 'epoch': 1.035436830428623, 'step': 5749000}
INFO:transformers.trainer:{'loss': 3.0985495965480805, 'learning_rate': 3.274121859874364e-05, 'epoch': 1.0355268840753813, 'step': 5749500}
INFO:transformers.trainer:{'loss': 3.049662823200226, 'learning_rate': 3.273971770463101e-05, 'epoch': 1.0356169377221398, 'step': 5750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1262596218585967, 'learning_rate': 3.273821681051836e-05, 'epoch': 1.0357069913688983, 'step': 5750500}
INFO:transformers.trainer:{'loss': 3.1675967742204665, 'learning_rate': 3.273671591640573e-05, 'epoch': 1.0357970450156566, 'step': 5751000}
INFO:transformers.trainer:{'loss': 3.1198954374790193, 'learning_rate': 3.273521502229308e-05, 'epoch': 1.0358870986624151, 'step': 5751500}
INFO:transformers.trainer:{'loss': 3.0681412017345426, 'learning_rate': 3.2733714128180445e-05, 'epoch': 1.0359771523091736, 'step': 5752000}
INFO:transformers.trainer:{'loss': 3.0413871104717254, 'learning_rate': 3.27322132340678e-05, 'epoch': 1.0360672059559322, 'step': 5752500}
INFO:transformers.trainer:{'loss': 3.0838929679393767, 'learning_rate': 3.273071233995516e-05, 'epoch': 1.0361572596026905, 'step': 5753000}
INFO:transformers.trainer:{'loss': 3.0687909908294677, 'learning_rate': 3.2729211445842516e-05, 'epoch': 1.036247313249449, 'step': 5753500}
INFO:transformers.trainer:{'loss': 3.102666479110718, 'learning_rate': 3.272771055172988e-05, 'epoch': 1.0363373668962075, 'step': 5754000}
INFO:transformers.trainer:{'loss': 3.0360184087753295, 'learning_rate': 3.2726209657617234e-05, 'epoch': 1.0364274205429658, 'step': 5754500}
INFO:transformers.trainer:{'loss': 3.072093291044235, 'learning_rate': 3.27247087635046e-05, 'epoch': 1.0365174741897243, 'step': 5755000}
INFO:transformers.trainer:{'loss': 3.0931244628429413, 'learning_rate': 3.272320786939195e-05, 'epoch': 1.0366075278364828, 'step': 5755500}
INFO:transformers.trainer:{'loss': 3.0730849471092223, 'learning_rate': 3.272170697527932e-05, 'epoch': 1.036697581483241, 'step': 5756000}
INFO:transformers.trainer:{'loss': 3.1046043345928194, 'learning_rate': 3.272020608116668e-05, 'epoch': 1.0367876351299996, 'step': 5756500}
INFO:transformers.trainer:{'loss': 3.0922648561000825, 'learning_rate': 3.2718705187054036e-05, 'epoch': 1.0368776887767581, 'step': 5757000}
INFO:transformers.trainer:{'loss': 3.1185478773117064, 'learning_rate': 3.2717204292941395e-05, 'epoch': 1.0369677424235166, 'step': 5757500}
INFO:transformers.trainer:{'loss': 3.10461376452446, 'learning_rate': 3.2715703398828754e-05, 'epoch': 1.037057796070275, 'step': 5758000}
INFO:transformers.trainer:{'loss': 3.098698175549507, 'learning_rate': 3.271420250471611e-05, 'epoch': 1.0371478497170334, 'step': 5758500}
INFO:transformers.trainer:{'loss': 3.1530277242660523, 'learning_rate': 3.271270161060347e-05, 'epoch': 1.037237903363792, 'step': 5759000}
INFO:transformers.trainer:{'loss': 3.077622363567352, 'learning_rate': 3.271120071649083e-05, 'epoch': 1.0373279570105503, 'step': 5759500}
INFO:transformers.trainer:{'loss': 3.040950587272644, 'learning_rate': 3.270969982237819e-05, 'epoch': 1.0374180106573088, 'step': 5760000}
INFO:transformers.trainer:{'loss': 3.100055196762085, 'learning_rate': 3.270819892826555e-05, 'epoch': 1.0375080643040673, 'step': 5760500}
INFO:transformers.trainer:{'loss': 3.1185406975746153, 'learning_rate': 3.270669803415291e-05, 'epoch': 1.0375981179508256, 'step': 5761000}
INFO:transformers.trainer:{'loss': 3.0918289192914963, 'learning_rate': 3.270519714004027e-05, 'epoch': 1.037688171597584, 'step': 5761500}
INFO:transformers.trainer:{'loss': 3.0647648717164993, 'learning_rate': 3.2703696245927626e-05, 'epoch': 1.0377782252443426, 'step': 5762000}
INFO:transformers.trainer:{'loss': 3.035373277425766, 'learning_rate': 3.2702195351814985e-05, 'epoch': 1.037868278891101, 'step': 5762500}
INFO:transformers.trainer:{'loss': 3.071265463352203, 'learning_rate': 3.2700694457702344e-05, 'epoch': 1.0379583325378594, 'step': 5763000}
INFO:transformers.trainer:{'loss': 3.119376814365387, 'learning_rate': 3.26991935635897e-05, 'epoch': 1.038048386184618, 'step': 5763500}
INFO:transformers.trainer:{'loss': 3.150219153046608, 'learning_rate': 3.269769266947706e-05, 'epoch': 1.0381384398313764, 'step': 5764000}
INFO:transformers.trainer:{'loss': 3.0720280349254607, 'learning_rate': 3.269619177536442e-05, 'epoch': 1.0382284934781347, 'step': 5764500}
INFO:transformers.trainer:{'loss': 3.1078333716392517, 'learning_rate': 3.269469088125178e-05, 'epoch': 1.0383185471248932, 'step': 5765000}
INFO:transformers.trainer:{'loss': 3.0954402047395706, 'learning_rate': 3.269318998713914e-05, 'epoch': 1.0384086007716518, 'step': 5765500}
INFO:transformers.trainer:{'loss': 3.0863341329097747, 'learning_rate': 3.26916890930265e-05, 'epoch': 1.03849865441841, 'step': 5766000}
INFO:transformers.trainer:{'loss': 3.075134561896324, 'learning_rate': 3.269018819891386e-05, 'epoch': 1.0385887080651686, 'step': 5766500}
INFO:transformers.trainer:{'loss': 3.186771469831467, 'learning_rate': 3.268868730480122e-05, 'epoch': 1.038678761711927, 'step': 5767000}
INFO:transformers.trainer:{'loss': 3.1104110467433927, 'learning_rate': 3.2687186410688576e-05, 'epoch': 1.0387688153586854, 'step': 5767500}
INFO:transformers.trainer:{'loss': 3.050794939279556, 'learning_rate': 3.2685685516575935e-05, 'epoch': 1.0388588690054439, 'step': 5768000}
INFO:transformers.trainer:{'loss': 3.126153900384903, 'learning_rate': 3.2684184622463294e-05, 'epoch': 1.0389489226522024, 'step': 5768500}
INFO:transformers.trainer:{'loss': 3.1134467269182204, 'learning_rate': 3.268268372835065e-05, 'epoch': 1.039038976298961, 'step': 5769000}
INFO:transformers.trainer:{'loss': 3.0840771651268004, 'learning_rate': 3.268118283423801e-05, 'epoch': 1.0391290299457192, 'step': 5769500}
INFO:transformers.trainer:{'loss': 3.090556118488312, 'learning_rate': 3.267968194012537e-05, 'epoch': 1.0392190835924777, 'step': 5770000}
INFO:transformers.trainer:{'loss': 3.1128573997020723, 'learning_rate': 3.267818104601274e-05, 'epoch': 1.0393091372392362, 'step': 5770500}
INFO:transformers.trainer:{'loss': 3.082861130952835, 'learning_rate': 3.267668015190009e-05, 'epoch': 1.0393991908859945, 'step': 5771000}
INFO:transformers.trainer:{'loss': 3.070236365556717, 'learning_rate': 3.2675179257787455e-05, 'epoch': 1.039489244532753, 'step': 5771500}
INFO:transformers.trainer:{'loss': 3.0556838586330413, 'learning_rate': 3.267367836367481e-05, 'epoch': 1.0395792981795116, 'step': 5772000}
INFO:transformers.trainer:{'loss': 3.0967131299972532, 'learning_rate': 3.267217746956217e-05, 'epoch': 1.0396693518262698, 'step': 5772500}
INFO:transformers.trainer:{'loss': 3.0501758110523225, 'learning_rate': 3.2670676575449525e-05, 'epoch': 1.0397594054730284, 'step': 5773000}
INFO:transformers.trainer:{'loss': 3.1360542978048325, 'learning_rate': 3.266917568133689e-05, 'epoch': 1.0398494591197869, 'step': 5773500}
INFO:transformers.trainer:{'loss': 3.0656529520750047, 'learning_rate': 3.2667674787224243e-05, 'epoch': 1.0399395127665454, 'step': 5774000}
INFO:transformers.trainer:{'loss': 3.0940420701503752, 'learning_rate': 3.266617389311161e-05, 'epoch': 1.0400295664133037, 'step': 5774500}
INFO:transformers.trainer:{'loss': 3.1069877490997313, 'learning_rate': 3.266467299899896e-05, 'epoch': 1.0401196200600622, 'step': 5775000}
INFO:transformers.trainer:{'loss': 3.134073368549347, 'learning_rate': 3.266317210488633e-05, 'epoch': 1.0402096737068207, 'step': 5775500}
INFO:transformers.trainer:{'loss': 3.1518296382427216, 'learning_rate': 3.266167121077368e-05, 'epoch': 1.040299727353579, 'step': 5776000}
INFO:transformers.trainer:{'loss': 3.102008735179901, 'learning_rate': 3.2660170316661045e-05, 'epoch': 1.0403897810003375, 'step': 5776500}
INFO:transformers.trainer:{'loss': 3.1014494388103486, 'learning_rate': 3.2658669422548405e-05, 'epoch': 1.040479834647096, 'step': 5777000}
INFO:transformers.trainer:{'loss': 3.1565080366134644, 'learning_rate': 3.2657168528435764e-05, 'epoch': 1.0405698882938543, 'step': 5777500}
INFO:transformers.trainer:{'loss': 3.100746136188507, 'learning_rate': 3.265566763432312e-05, 'epoch': 1.0406599419406128, 'step': 5778000}
INFO:transformers.trainer:{'loss': 3.130524794578552, 'learning_rate': 3.265416674021048e-05, 'epoch': 1.0407499955873714, 'step': 5778500}
INFO:transformers.trainer:{'loss': 3.1157795956134797, 'learning_rate': 3.265266584609784e-05, 'epoch': 1.0408400492341296, 'step': 5779000}
INFO:transformers.trainer:{'loss': 3.1046680569648744, 'learning_rate': 3.26511649519852e-05, 'epoch': 1.0409301028808882, 'step': 5779500}
INFO:transformers.trainer:{'loss': 3.0956218745708464, 'learning_rate': 3.264966405787256e-05, 'epoch': 1.0410201565276467, 'step': 5780000}
INFO:transformers.trainer:{'loss': 3.0777796761989595, 'learning_rate': 3.264816316375992e-05, 'epoch': 1.0411102101744052, 'step': 5780500}
INFO:transformers.trainer:{'loss': 3.1395074417591093, 'learning_rate': 3.264666226964728e-05, 'epoch': 1.0412002638211635, 'step': 5781000}
INFO:transformers.trainer:{'loss': 3.0624738664627076, 'learning_rate': 3.2645161375534636e-05, 'epoch': 1.041290317467922, 'step': 5781500}
INFO:transformers.trainer:{'loss': 3.0559214723110197, 'learning_rate': 3.2643660481421995e-05, 'epoch': 1.0413803711146805, 'step': 5782000}
INFO:transformers.trainer:{'loss': 3.128620409965515, 'learning_rate': 3.2642159587309354e-05, 'epoch': 1.0414704247614388, 'step': 5782500}
INFO:transformers.trainer:{'loss': 3.0659609714746474, 'learning_rate': 3.264065869319671e-05, 'epoch': 1.0415604784081973, 'step': 5783000}
INFO:transformers.trainer:{'loss': 3.1037923398017884, 'learning_rate': 3.263915779908407e-05, 'epoch': 1.0416505320549558, 'step': 5783500}
INFO:transformers.trainer:{'loss': 3.0717281918525696, 'learning_rate': 3.263765690497143e-05, 'epoch': 1.0417405857017141, 'step': 5784000}
INFO:transformers.trainer:{'loss': 3.0912662973403933, 'learning_rate': 3.263615601085879e-05, 'epoch': 1.0418306393484726, 'step': 5784500}
INFO:transformers.trainer:{'loss': 3.1320509516000747, 'learning_rate': 3.263465511674615e-05, 'epoch': 1.0419206929952312, 'step': 5785000}
INFO:transformers.trainer:{'loss': 3.0400226548910143, 'learning_rate': 3.263315422263351e-05, 'epoch': 1.0420107466419897, 'step': 5785500}
INFO:transformers.trainer:{'loss': 3.047507396697998, 'learning_rate': 3.263165332852087e-05, 'epoch': 1.042100800288748, 'step': 5786000}
INFO:transformers.trainer:{'loss': 3.053237288236618, 'learning_rate': 3.2630152434408226e-05, 'epoch': 1.0421908539355065, 'step': 5786500}
INFO:transformers.trainer:{'loss': 3.0309391751289367, 'learning_rate': 3.2628651540295586e-05, 'epoch': 1.042280907582265, 'step': 5787000}
INFO:transformers.trainer:{'loss': 3.0378618289232255, 'learning_rate': 3.2627150646182945e-05, 'epoch': 1.0423709612290233, 'step': 5787500}
INFO:transformers.trainer:{'loss': 3.0961355068683623, 'learning_rate': 3.2625649752070304e-05, 'epoch': 1.0424610148757818, 'step': 5788000}
INFO:transformers.trainer:{'loss': 3.0732859083414077, 'learning_rate': 3.262414885795766e-05, 'epoch': 1.0425510685225403, 'step': 5788500}
INFO:transformers.trainer:{'loss': 3.0591548056602478, 'learning_rate': 3.262264796384502e-05, 'epoch': 1.0426411221692986, 'step': 5789000}
INFO:transformers.trainer:{'loss': 3.105311613559723, 'learning_rate': 3.262114706973238e-05, 'epoch': 1.0427311758160571, 'step': 5789500}
INFO:transformers.trainer:{'loss': 3.0647556586265563, 'learning_rate': 3.261964617561974e-05, 'epoch': 1.0428212294628156, 'step': 5790000}
INFO:transformers.trainer:{'loss': 3.1558368804454804, 'learning_rate': 3.26181452815071e-05, 'epoch': 1.0429112831095741, 'step': 5790500}
INFO:transformers.trainer:{'loss': 3.0719162464141845, 'learning_rate': 3.2616644387394465e-05, 'epoch': 1.0430013367563324, 'step': 5791000}
INFO:transformers.trainer:{'loss': 3.0938125479221346, 'learning_rate': 3.261514349328182e-05, 'epoch': 1.043091390403091, 'step': 5791500}
INFO:transformers.trainer:{'loss': 3.1180625874996184, 'learning_rate': 3.261364259916918e-05, 'epoch': 1.0431814440498495, 'step': 5792000}
INFO:transformers.trainer:{'loss': 3.0753752440214157, 'learning_rate': 3.2612141705056535e-05, 'epoch': 1.0432714976966078, 'step': 5792500}
INFO:transformers.trainer:{'loss': 3.091521456003189, 'learning_rate': 3.26106408109439e-05, 'epoch': 1.0433615513433663, 'step': 5793000}
INFO:transformers.trainer:{'loss': 3.0233850972652436, 'learning_rate': 3.260913991683125e-05, 'epoch': 1.0434516049901248, 'step': 5793500}
INFO:transformers.trainer:{'loss': 3.134544203519821, 'learning_rate': 3.260763902271862e-05, 'epoch': 1.043541658636883, 'step': 5794000}
INFO:transformers.trainer:{'loss': 3.070062471985817, 'learning_rate': 3.260613812860597e-05, 'epoch': 1.0436317122836416, 'step': 5794500}
INFO:transformers.trainer:{'loss': 3.0595855283737183, 'learning_rate': 3.260463723449334e-05, 'epoch': 1.0437217659304001, 'step': 5795000}
INFO:transformers.trainer:{'loss': 3.0727312226891517, 'learning_rate': 3.260313634038069e-05, 'epoch': 1.0438118195771584, 'step': 5795500}
INFO:transformers.trainer:{'loss': 3.055623962163925, 'learning_rate': 3.2601635446268055e-05, 'epoch': 1.043901873223917, 'step': 5796000}
INFO:transformers.trainer:{'loss': 3.0757114160060883, 'learning_rate': 3.260013455215541e-05, 'epoch': 1.0439919268706754, 'step': 5796500}
INFO:transformers.trainer:{'loss': 3.114758096933365, 'learning_rate': 3.259863365804277e-05, 'epoch': 1.044081980517434, 'step': 5797000}
INFO:transformers.trainer:{'loss': 3.100644218325615, 'learning_rate': 3.259713276393013e-05, 'epoch': 1.0441720341641922, 'step': 5797500}
INFO:transformers.trainer:{'loss': 3.079118617773056, 'learning_rate': 3.259563186981749e-05, 'epoch': 1.0442620878109508, 'step': 5798000}
INFO:transformers.trainer:{'loss': 3.1067069506645204, 'learning_rate': 3.259413097570485e-05, 'epoch': 1.0443521414577093, 'step': 5798500}
INFO:transformers.trainer:{'loss': 3.1130496416091917, 'learning_rate': 3.259263008159221e-05, 'epoch': 1.0444421951044676, 'step': 5799000}
INFO:transformers.trainer:{'loss': 3.0744695558547974, 'learning_rate': 3.259112918747957e-05, 'epoch': 1.044532248751226, 'step': 5799500}
INFO:transformers.trainer:{'loss': 3.125457899570465, 'learning_rate': 3.258962829336693e-05, 'epoch': 1.0446223023979846, 'step': 5800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.114909725189209, 'learning_rate': 3.258812739925429e-05, 'epoch': 1.0447123560447429, 'step': 5800500}
INFO:transformers.trainer:{'loss': 3.0763116011619567, 'learning_rate': 3.2586626505141646e-05, 'epoch': 1.0448024096915014, 'step': 5801000}
INFO:transformers.trainer:{'loss': 3.10858256149292, 'learning_rate': 3.2585125611029005e-05, 'epoch': 1.04489246333826, 'step': 5801500}
INFO:transformers.trainer:{'loss': 3.1022292845249178, 'learning_rate': 3.2583624716916364e-05, 'epoch': 1.0449825169850184, 'step': 5802000}
INFO:transformers.trainer:{'loss': 3.0828177225589752, 'learning_rate': 3.258212382280372e-05, 'epoch': 1.0450725706317767, 'step': 5802500}
INFO:transformers.trainer:{'loss': 3.1664931544065475, 'learning_rate': 3.258062292869108e-05, 'epoch': 1.0451626242785352, 'step': 5803000}
INFO:transformers.trainer:{'loss': 3.033793930530548, 'learning_rate': 3.257912203457844e-05, 'epoch': 1.0452526779252937, 'step': 5803500}
INFO:transformers.trainer:{'loss': 3.080821946620941, 'learning_rate': 3.25776211404658e-05, 'epoch': 1.045342731572052, 'step': 5804000}
INFO:transformers.trainer:{'loss': 3.130448139667511, 'learning_rate': 3.257612024635316e-05, 'epoch': 1.0454327852188106, 'step': 5804500}
INFO:transformers.trainer:{'loss': 3.077609629511833, 'learning_rate': 3.257461935224052e-05, 'epoch': 1.045522838865569, 'step': 5805000}
INFO:transformers.trainer:{'loss': 3.036416659116745, 'learning_rate': 3.257311845812788e-05, 'epoch': 1.0456128925123274, 'step': 5805500}
INFO:transformers.trainer:{'loss': 3.0833648216724394, 'learning_rate': 3.2571617564015236e-05, 'epoch': 1.0457029461590859, 'step': 5806000}
INFO:transformers.trainer:{'loss': 3.104262608528137, 'learning_rate': 3.2570116669902595e-05, 'epoch': 1.0457929998058444, 'step': 5806500}
INFO:transformers.trainer:{'loss': 3.0069502232074736, 'learning_rate': 3.2568615775789954e-05, 'epoch': 1.0458830534526027, 'step': 5807000}
INFO:transformers.trainer:{'loss': 3.0857975296974183, 'learning_rate': 3.256711488167731e-05, 'epoch': 1.0459731070993612, 'step': 5807500}
INFO:transformers.trainer:{'loss': 3.1193455159664154, 'learning_rate': 3.256561398756467e-05, 'epoch': 1.0460631607461197, 'step': 5808000}
INFO:transformers.trainer:{'loss': 3.0470068172216416, 'learning_rate': 3.256411309345203e-05, 'epoch': 1.0461532143928782, 'step': 5808500}
INFO:transformers.trainer:{'loss': 3.0536888588666917, 'learning_rate': 3.256261219933939e-05, 'epoch': 1.0462432680396365, 'step': 5809000}
INFO:transformers.trainer:{'loss': 3.06861716234684, 'learning_rate': 3.256111130522675e-05, 'epoch': 1.046333321686395, 'step': 5809500}
INFO:transformers.trainer:{'loss': 3.0904220638275146, 'learning_rate': 3.255961041111411e-05, 'epoch': 1.0464233753331535, 'step': 5810000}
INFO:transformers.trainer:{'loss': 3.073399035215378, 'learning_rate': 3.255810951700147e-05, 'epoch': 1.0465134289799118, 'step': 5810500}
INFO:transformers.trainer:{'loss': 3.042190842628479, 'learning_rate': 3.255660862288883e-05, 'epoch': 1.0466034826266704, 'step': 5811000}
INFO:transformers.trainer:{'loss': 3.0705377361774446, 'learning_rate': 3.255510772877619e-05, 'epoch': 1.0466935362734289, 'step': 5811500}
INFO:transformers.trainer:{'loss': 3.0765207225084303, 'learning_rate': 3.2553606834663545e-05, 'epoch': 1.0467835899201872, 'step': 5812000}
INFO:transformers.trainer:{'loss': 3.1026377459764483, 'learning_rate': 3.255210594055091e-05, 'epoch': 1.0468736435669457, 'step': 5812500}
INFO:transformers.trainer:{'loss': 3.0963357603549957, 'learning_rate': 3.255060504643826e-05, 'epoch': 1.0469636972137042, 'step': 5813000}
INFO:transformers.trainer:{'loss': 3.070640244960785, 'learning_rate': 3.254910415232563e-05, 'epoch': 1.0470537508604627, 'step': 5813500}
INFO:transformers.trainer:{'loss': 3.0635661222934725, 'learning_rate': 3.254760325821298e-05, 'epoch': 1.047143804507221, 'step': 5814000}
INFO:transformers.trainer:{'loss': 3.0719173004627227, 'learning_rate': 3.254610236410035e-05, 'epoch': 1.0472338581539795, 'step': 5814500}
INFO:transformers.trainer:{'loss': 3.0576961283683777, 'learning_rate': 3.25446014699877e-05, 'epoch': 1.047323911800738, 'step': 5815000}
INFO:transformers.trainer:{'loss': 3.0931718616485595, 'learning_rate': 3.2543100575875065e-05, 'epoch': 1.0474139654474963, 'step': 5815500}
INFO:transformers.trainer:{'loss': 3.050119545459747, 'learning_rate': 3.254159968176242e-05, 'epoch': 1.0475040190942548, 'step': 5816000}
INFO:transformers.trainer:{'loss': 3.143007682800293, 'learning_rate': 3.254009878764978e-05, 'epoch': 1.0475940727410133, 'step': 5816500}
INFO:transformers.trainer:{'loss': 3.0794214556217194, 'learning_rate': 3.2538597893537135e-05, 'epoch': 1.0476841263877716, 'step': 5817000}
INFO:transformers.trainer:{'loss': 3.0658909742832186, 'learning_rate': 3.25370969994245e-05, 'epoch': 1.0477741800345302, 'step': 5817500}
INFO:transformers.trainer:{'loss': 3.0999156284332274, 'learning_rate': 3.253559610531185e-05, 'epoch': 1.0478642336812887, 'step': 5818000}
INFO:transformers.trainer:{'loss': 3.0563851217031477, 'learning_rate': 3.253409521119922e-05, 'epoch': 1.047954287328047, 'step': 5818500}
INFO:transformers.trainer:{'loss': 3.062539580821991, 'learning_rate': 3.253259431708658e-05, 'epoch': 1.0480443409748055, 'step': 5819000}
INFO:transformers.trainer:{'loss': 3.1054596347808836, 'learning_rate': 3.253109342297394e-05, 'epoch': 1.048134394621564, 'step': 5819500}
INFO:transformers.trainer:{'loss': 3.065926269412041, 'learning_rate': 3.2529592528861296e-05, 'epoch': 1.0482244482683225, 'step': 5820000}
INFO:transformers.trainer:{'loss': 3.0900826549530027, 'learning_rate': 3.2528091634748655e-05, 'epoch': 1.0483145019150808, 'step': 5820500}
INFO:transformers.trainer:{'loss': 3.0784394443035126, 'learning_rate': 3.2526590740636014e-05, 'epoch': 1.0484045555618393, 'step': 5821000}
INFO:transformers.trainer:{'loss': 3.041071989774704, 'learning_rate': 3.2525089846523374e-05, 'epoch': 1.0484946092085978, 'step': 5821500}
INFO:transformers.trainer:{'loss': 3.083414161682129, 'learning_rate': 3.252358895241073e-05, 'epoch': 1.0485846628553561, 'step': 5822000}
INFO:transformers.trainer:{'loss': 3.0940551619529724, 'learning_rate': 3.252208805829809e-05, 'epoch': 1.0486747165021146, 'step': 5822500}
INFO:transformers.trainer:{'loss': 3.12054301404953, 'learning_rate': 3.252058716418545e-05, 'epoch': 1.0487647701488731, 'step': 5823000}
INFO:transformers.trainer:{'loss': 3.1125820422172548, 'learning_rate': 3.251908627007281e-05, 'epoch': 1.0488548237956314, 'step': 5823500}
INFO:transformers.trainer:{'loss': 3.103095879971981, 'learning_rate': 3.251758537596017e-05, 'epoch': 1.04894487744239, 'step': 5824000}
INFO:transformers.trainer:{'loss': 3.0359651668071748, 'learning_rate': 3.251608448184753e-05, 'epoch': 1.0490349310891485, 'step': 5824500}
INFO:transformers.trainer:{'loss': 3.0505689764022828, 'learning_rate': 3.251458358773489e-05, 'epoch': 1.049124984735907, 'step': 5825000}
INFO:transformers.trainer:{'loss': 3.055126802563667, 'learning_rate': 3.2513082693622246e-05, 'epoch': 1.0492150383826653, 'step': 5825500}
INFO:transformers.trainer:{'loss': 3.0830542290210725, 'learning_rate': 3.2511581799509605e-05, 'epoch': 1.0493050920294238, 'step': 5826000}
INFO:transformers.trainer:{'loss': 3.0809066041707993, 'learning_rate': 3.2510080905396964e-05, 'epoch': 1.0493951456761823, 'step': 5826500}
INFO:transformers.trainer:{'loss': 2.9925097246170043, 'learning_rate': 3.250858001128432e-05, 'epoch': 1.0494851993229406, 'step': 5827000}
INFO:transformers.trainer:{'loss': 3.0444353673458098, 'learning_rate': 3.250707911717168e-05, 'epoch': 1.0495752529696991, 'step': 5827500}
INFO:transformers.trainer:{'loss': 3.0776293919086455, 'learning_rate': 3.250557822305904e-05, 'epoch': 1.0496653066164576, 'step': 5828000}
INFO:transformers.trainer:{'loss': 3.1070596207752823, 'learning_rate': 3.25040773289464e-05, 'epoch': 1.049755360263216, 'step': 5828500}
INFO:transformers.trainer:{'loss': 3.0659180204868317, 'learning_rate': 3.250257643483376e-05, 'epoch': 1.0498454139099744, 'step': 5829000}
INFO:transformers.trainer:{'loss': 3.110850769281387, 'learning_rate': 3.250107554072112e-05, 'epoch': 1.049935467556733, 'step': 5829500}
INFO:transformers.trainer:{'loss': 3.1033543531894683, 'learning_rate': 3.249957464660848e-05, 'epoch': 1.0500255212034912, 'step': 5830000}
INFO:transformers.trainer:{'loss': 3.100945905447006, 'learning_rate': 3.2498073752495836e-05, 'epoch': 1.0501155748502498, 'step': 5830500}
INFO:transformers.trainer:{'loss': 3.088514668107033, 'learning_rate': 3.2496572858383195e-05, 'epoch': 1.0502056284970083, 'step': 5831000}
INFO:transformers.trainer:{'loss': 3.0792924261093138, 'learning_rate': 3.2495071964270555e-05, 'epoch': 1.0502956821437668, 'step': 5831500}
INFO:transformers.trainer:{'loss': 3.121476895570755, 'learning_rate': 3.249357107015792e-05, 'epoch': 1.050385735790525, 'step': 5832000}
INFO:transformers.trainer:{'loss': 3.050104883670807, 'learning_rate': 3.249207017604527e-05, 'epoch': 1.0504757894372836, 'step': 5832500}
INFO:transformers.trainer:{'loss': 3.036710716485977, 'learning_rate': 3.249056928193264e-05, 'epoch': 1.050565843084042, 'step': 5833000}
INFO:transformers.trainer:{'loss': 3.0859621078968047, 'learning_rate': 3.248906838781999e-05, 'epoch': 1.0506558967308004, 'step': 5833500}
INFO:transformers.trainer:{'loss': 3.111771347999573, 'learning_rate': 3.2487567493707357e-05, 'epoch': 1.050745950377559, 'step': 5834000}
INFO:transformers.trainer:{'loss': 3.1439876482486726, 'learning_rate': 3.248606659959471e-05, 'epoch': 1.0508360040243174, 'step': 5834500}
INFO:transformers.trainer:{'loss': 3.1006085546016693, 'learning_rate': 3.2484565705482075e-05, 'epoch': 1.0509260576710757, 'step': 5835000}
INFO:transformers.trainer:{'loss': 3.087508354187012, 'learning_rate': 3.248306481136943e-05, 'epoch': 1.0510161113178342, 'step': 5835500}
INFO:transformers.trainer:{'loss': 3.1181224269866945, 'learning_rate': 3.248156391725679e-05, 'epoch': 1.0511061649645927, 'step': 5836000}
INFO:transformers.trainer:{'loss': 3.1241264839172365, 'learning_rate': 3.2480063023144145e-05, 'epoch': 1.0511962186113513, 'step': 5836500}
INFO:transformers.trainer:{'loss': 3.0800693798065186, 'learning_rate': 3.247856212903151e-05, 'epoch': 1.0512862722581096, 'step': 5837000}
INFO:transformers.trainer:{'loss': 3.1225875985622404, 'learning_rate': 3.247706123491886e-05, 'epoch': 1.051376325904868, 'step': 5837500}
INFO:transformers.trainer:{'loss': 3.101668632984161, 'learning_rate': 3.247556034080623e-05, 'epoch': 1.0514663795516266, 'step': 5838000}
INFO:transformers.trainer:{'loss': 3.149404200077057, 'learning_rate': 3.247405944669358e-05, 'epoch': 1.0515564331983849, 'step': 5838500}
INFO:transformers.trainer:{'loss': 3.0741922497749328, 'learning_rate': 3.247255855258095e-05, 'epoch': 1.0516464868451434, 'step': 5839000}
INFO:transformers.trainer:{'loss': 3.100811561703682, 'learning_rate': 3.2471057658468306e-05, 'epoch': 1.051736540491902, 'step': 5839500}
INFO:transformers.trainer:{'loss': 3.0684334100484847, 'learning_rate': 3.2469556764355665e-05, 'epoch': 1.0518265941386602, 'step': 5840000}
INFO:transformers.trainer:{'loss': 3.088304457426071, 'learning_rate': 3.2468055870243024e-05, 'epoch': 1.0519166477854187, 'step': 5840500}
INFO:transformers.trainer:{'loss': 3.035278187274933, 'learning_rate': 3.246655497613038e-05, 'epoch': 1.0520067014321772, 'step': 5841000}
INFO:transformers.trainer:{'loss': 3.067346598148346, 'learning_rate': 3.246505408201774e-05, 'epoch': 1.0520967550789355, 'step': 5841500}
INFO:transformers.trainer:{'loss': 3.0518026907444, 'learning_rate': 3.24635531879051e-05, 'epoch': 1.052186808725694, 'step': 5842000}
INFO:transformers.trainer:{'loss': 3.0354755885601046, 'learning_rate': 3.246205229379246e-05, 'epoch': 1.0522768623724525, 'step': 5842500}
INFO:transformers.trainer:{'loss': 3.1470970269441603, 'learning_rate': 3.246055139967982e-05, 'epoch': 1.052366916019211, 'step': 5843000}
INFO:transformers.trainer:{'loss': 3.0446102513074873, 'learning_rate': 3.245905050556718e-05, 'epoch': 1.0524569696659694, 'step': 5843500}
INFO:transformers.trainer:{'loss': 3.1423769283294676, 'learning_rate': 3.245754961145454e-05, 'epoch': 1.0525470233127279, 'step': 5844000}
INFO:transformers.trainer:{'loss': 3.11857120347023, 'learning_rate': 3.2456048717341897e-05, 'epoch': 1.0526370769594864, 'step': 5844500}
INFO:transformers.trainer:{'loss': 3.1825191986560823, 'learning_rate': 3.2454547823229256e-05, 'epoch': 1.0527271306062447, 'step': 5845000}
INFO:transformers.trainer:{'loss': 3.0882591701745987, 'learning_rate': 3.2453046929116615e-05, 'epoch': 1.0528171842530032, 'step': 5845500}
INFO:transformers.trainer:{'loss': 3.1154128829240797, 'learning_rate': 3.2451546035003974e-05, 'epoch': 1.0529072378997617, 'step': 5846000}
INFO:transformers.trainer:{'loss': 3.1687034883499146, 'learning_rate': 3.245004514089133e-05, 'epoch': 1.05299729154652, 'step': 5846500}
INFO:transformers.trainer:{'loss': 3.1457486062049864, 'learning_rate': 3.244854424677869e-05, 'epoch': 1.0530873451932785, 'step': 5847000}
INFO:transformers.trainer:{'loss': 3.1000627796649933, 'learning_rate': 3.244704335266605e-05, 'epoch': 1.053177398840037, 'step': 5847500}
INFO:transformers.trainer:{'loss': 3.05652219080925, 'learning_rate': 3.244554245855341e-05, 'epoch': 1.0532674524867955, 'step': 5848000}
INFO:transformers.trainer:{'loss': 3.0566477077007295, 'learning_rate': 3.244404156444077e-05, 'epoch': 1.0533575061335538, 'step': 5848500}
INFO:transformers.trainer:{'loss': 3.024102171897888, 'learning_rate': 3.244254067032813e-05, 'epoch': 1.0534475597803123, 'step': 5849000}
INFO:transformers.trainer:{'loss': 3.0838118960857392, 'learning_rate': 3.244103977621549e-05, 'epoch': 1.0535376134270709, 'step': 5849500}
INFO:transformers.trainer:{'loss': 3.1430273641347886, 'learning_rate': 3.2439538882102846e-05, 'epoch': 1.0536276670738292, 'step': 5850000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5850000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5850000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5850000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5750000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0672920718193053, 'learning_rate': 3.2438037987990205e-05, 'epoch': 1.0537177207205877, 'step': 5850500}
INFO:transformers.trainer:{'loss': 3.1150080411434176, 'learning_rate': 3.2436537093877564e-05, 'epoch': 1.0538077743673462, 'step': 5851000}
INFO:transformers.trainer:{'loss': 2.9998533310890196, 'learning_rate': 3.243503619976492e-05, 'epoch': 1.0538978280141045, 'step': 5851500}
INFO:transformers.trainer:{'loss': 3.0621184487342834, 'learning_rate': 3.243353530565228e-05, 'epoch': 1.053987881660863, 'step': 5852000}
INFO:transformers.trainer:{'loss': 3.0141791706085206, 'learning_rate': 3.243203441153964e-05, 'epoch': 1.0540779353076215, 'step': 5852500}
INFO:transformers.trainer:{'loss': 3.114911069393158, 'learning_rate': 3.2430533517427e-05, 'epoch': 1.0541679889543798, 'step': 5853000}
INFO:transformers.trainer:{'loss': 3.1205428849458694, 'learning_rate': 3.2429032623314366e-05, 'epoch': 1.0542580426011383, 'step': 5853500}
INFO:transformers.trainer:{'loss': 3.036585002183914, 'learning_rate': 3.242753172920172e-05, 'epoch': 1.0543480962478968, 'step': 5854000}
INFO:transformers.trainer:{'loss': 3.089417308807373, 'learning_rate': 3.2426030835089084e-05, 'epoch': 1.0544381498946553, 'step': 5854500}
INFO:transformers.trainer:{'loss': 3.000557305455208, 'learning_rate': 3.242452994097644e-05, 'epoch': 1.0545282035414136, 'step': 5855000}
INFO:transformers.trainer:{'loss': 2.995234414100647, 'learning_rate': 3.24230290468638e-05, 'epoch': 1.0546182571881721, 'step': 5855500}
INFO:transformers.trainer:{'loss': 3.052401271224022, 'learning_rate': 3.2421528152751155e-05, 'epoch': 1.0547083108349307, 'step': 5856000}
INFO:transformers.trainer:{'loss': 3.134778656244278, 'learning_rate': 3.242002725863852e-05, 'epoch': 1.054798364481689, 'step': 5856500}
INFO:transformers.trainer:{'loss': 3.055218513250351, 'learning_rate': 3.241852636452587e-05, 'epoch': 1.0548884181284475, 'step': 5857000}
INFO:transformers.trainer:{'loss': 3.064871864795685, 'learning_rate': 3.241702547041324e-05, 'epoch': 1.054978471775206, 'step': 5857500}
INFO:transformers.trainer:{'loss': 3.059679299354553, 'learning_rate': 3.241552457630059e-05, 'epoch': 1.0550685254219643, 'step': 5858000}
INFO:transformers.trainer:{'loss': 3.112382040262222, 'learning_rate': 3.241402368218796e-05, 'epoch': 1.0551585790687228, 'step': 5858500}
INFO:transformers.trainer:{'loss': 3.044835972547531, 'learning_rate': 3.241252278807531e-05, 'epoch': 1.0552486327154813, 'step': 5859000}
INFO:transformers.trainer:{'loss': 3.1171362662315367, 'learning_rate': 3.2411021893962675e-05, 'epoch': 1.0553386863622398, 'step': 5859500}
INFO:transformers.trainer:{'loss': 3.051485107898712, 'learning_rate': 3.2409520999850034e-05, 'epoch': 1.0554287400089981, 'step': 5860000}
INFO:transformers.trainer:{'loss': 3.053121465086937, 'learning_rate': 3.240802010573739e-05, 'epoch': 1.0555187936557566, 'step': 5860500}
INFO:transformers.trainer:{'loss': 3.0559507133960726, 'learning_rate': 3.240651921162475e-05, 'epoch': 1.0556088473025151, 'step': 5861000}
INFO:transformers.trainer:{'loss': 3.0804354062080384, 'learning_rate': 3.240501831751211e-05, 'epoch': 1.0556989009492734, 'step': 5861500}
INFO:transformers.trainer:{'loss': 3.1030343601703643, 'learning_rate': 3.240351742339947e-05, 'epoch': 1.055788954596032, 'step': 5862000}
INFO:transformers.trainer:{'loss': 3.051690689086914, 'learning_rate': 3.240201652928683e-05, 'epoch': 1.0558790082427905, 'step': 5862500}
INFO:transformers.trainer:{'loss': 3.1232520920038223, 'learning_rate': 3.240051563517419e-05, 'epoch': 1.0559690618895488, 'step': 5863000}
INFO:transformers.trainer:{'loss': 3.152652469396591, 'learning_rate': 3.239901474106155e-05, 'epoch': 1.0560591155363073, 'step': 5863500}
INFO:transformers.trainer:{'loss': 3.035463475704193, 'learning_rate': 3.2397513846948906e-05, 'epoch': 1.0561491691830658, 'step': 5864000}
INFO:transformers.trainer:{'loss': 3.0766740205287935, 'learning_rate': 3.2396012952836265e-05, 'epoch': 1.056239222829824, 'step': 5864500}
INFO:transformers.trainer:{'loss': 3.043016713261604, 'learning_rate': 3.2394512058723624e-05, 'epoch': 1.0563292764765826, 'step': 5865000}
INFO:transformers.trainer:{'loss': 3.0238957443237306, 'learning_rate': 3.2393011164610983e-05, 'epoch': 1.056419330123341, 'step': 5865500}
INFO:transformers.trainer:{'loss': 3.1191521153450013, 'learning_rate': 3.239151027049834e-05, 'epoch': 1.0565093837700996, 'step': 5866000}
INFO:transformers.trainer:{'loss': 3.078351266145706, 'learning_rate': 3.23900093763857e-05, 'epoch': 1.056599437416858, 'step': 5866500}
INFO:transformers.trainer:{'loss': 3.0659357998371126, 'learning_rate': 3.238850848227306e-05, 'epoch': 1.0566894910636164, 'step': 5867000}
INFO:transformers.trainer:{'loss': 3.1008204258680343, 'learning_rate': 3.238700758816042e-05, 'epoch': 1.056779544710375, 'step': 5867500}
INFO:transformers.trainer:{'loss': 3.150123357176781, 'learning_rate': 3.238550669404778e-05, 'epoch': 1.0568695983571332, 'step': 5868000}
INFO:transformers.trainer:{'loss': 3.1273298132419587, 'learning_rate': 3.238400579993514e-05, 'epoch': 1.0569596520038917, 'step': 5868500}
INFO:transformers.trainer:{'loss': 3.114072877883911, 'learning_rate': 3.23825049058225e-05, 'epoch': 1.0570497056506503, 'step': 5869000}
INFO:transformers.trainer:{'loss': 3.056318133831024, 'learning_rate': 3.2381004011709856e-05, 'epoch': 1.0571397592974086, 'step': 5869500}
INFO:transformers.trainer:{'loss': 3.062020858168602, 'learning_rate': 3.2379503117597215e-05, 'epoch': 1.057229812944167, 'step': 5870000}
INFO:transformers.trainer:{'loss': 3.0748759038448332, 'learning_rate': 3.2378002223484574e-05, 'epoch': 1.0573198665909256, 'step': 5870500}
INFO:transformers.trainer:{'loss': 3.1040857021808623, 'learning_rate': 3.237650132937193e-05, 'epoch': 1.057409920237684, 'step': 5871000}
INFO:transformers.trainer:{'loss': 3.105979720115662, 'learning_rate': 3.237500043525929e-05, 'epoch': 1.0574999738844424, 'step': 5871500}
INFO:transformers.trainer:{'loss': 3.0208803663253785, 'learning_rate': 3.237349954114665e-05, 'epoch': 1.057590027531201, 'step': 5872000}
INFO:transformers.trainer:{'loss': 3.124886862874031, 'learning_rate': 3.237199864703401e-05, 'epoch': 1.0576800811779594, 'step': 5872500}
INFO:transformers.trainer:{'loss': 3.0816651940345765, 'learning_rate': 3.237049775292137e-05, 'epoch': 1.0577701348247177, 'step': 5873000}
INFO:transformers.trainer:{'loss': 3.131536283016205, 'learning_rate': 3.236899685880873e-05, 'epoch': 1.0578601884714762, 'step': 5873500}
INFO:transformers.trainer:{'loss': 3.0727212274074556, 'learning_rate': 3.2367495964696094e-05, 'epoch': 1.0579502421182347, 'step': 5874000}
INFO:transformers.trainer:{'loss': 3.0368750743865967, 'learning_rate': 3.2365995070583446e-05, 'epoch': 1.058040295764993, 'step': 5874500}
INFO:transformers.trainer:{'loss': 3.0763566315174105, 'learning_rate': 3.236449417647081e-05, 'epoch': 1.0581303494117515, 'step': 5875000}
INFO:transformers.trainer:{'loss': 3.0465391051769255, 'learning_rate': 3.2362993282358164e-05, 'epoch': 1.05822040305851, 'step': 5875500}
INFO:transformers.trainer:{'loss': 3.0905138428211214, 'learning_rate': 3.236149238824553e-05, 'epoch': 1.0583104567052684, 'step': 5876000}
INFO:transformers.trainer:{'loss': 3.0960859304666517, 'learning_rate': 3.235999149413288e-05, 'epoch': 1.0584005103520269, 'step': 5876500}
INFO:transformers.trainer:{'loss': 3.1189421354532243, 'learning_rate': 3.235849060002025e-05, 'epoch': 1.0584905639987854, 'step': 5877000}
INFO:transformers.trainer:{'loss': 3.1012565733194353, 'learning_rate': 3.23569897059076e-05, 'epoch': 1.058580617645544, 'step': 5877500}
INFO:transformers.trainer:{'loss': 3.045349172592163, 'learning_rate': 3.2355488811794966e-05, 'epoch': 1.0586706712923022, 'step': 5878000}
INFO:transformers.trainer:{'loss': 3.084969047546387, 'learning_rate': 3.235398791768232e-05, 'epoch': 1.0587607249390607, 'step': 5878500}
INFO:transformers.trainer:{'loss': 3.0907551708221437, 'learning_rate': 3.2352487023569685e-05, 'epoch': 1.0588507785858192, 'step': 5879000}
INFO:transformers.trainer:{'loss': 3.124987072944641, 'learning_rate': 3.235098612945704e-05, 'epoch': 1.0589408322325775, 'step': 5879500}
INFO:transformers.trainer:{'loss': 3.0804002628326415, 'learning_rate': 3.23494852353444e-05, 'epoch': 1.059030885879336, 'step': 5880000}
INFO:transformers.trainer:{'loss': 3.0656622767448427, 'learning_rate': 3.2347984341231755e-05, 'epoch': 1.0591209395260945, 'step': 5880500}
INFO:transformers.trainer:{'loss': 3.084699505805969, 'learning_rate': 3.234648344711912e-05, 'epoch': 1.0592109931728528, 'step': 5881000}
INFO:transformers.trainer:{'loss': 3.014902188658714, 'learning_rate': 3.234498255300648e-05, 'epoch': 1.0593010468196113, 'step': 5881500}
INFO:transformers.trainer:{'loss': 3.1341387306451796, 'learning_rate': 3.234348165889384e-05, 'epoch': 1.0593911004663699, 'step': 5882000}
INFO:transformers.trainer:{'loss': 3.078395141363144, 'learning_rate': 3.23419807647812e-05, 'epoch': 1.0594811541131284, 'step': 5882500}
INFO:transformers.trainer:{'loss': 3.064284212112427, 'learning_rate': 3.234047987066856e-05, 'epoch': 1.0595712077598867, 'step': 5883000}
INFO:transformers.trainer:{'loss': 3.0795613305568694, 'learning_rate': 3.2338978976555916e-05, 'epoch': 1.0596612614066452, 'step': 5883500}
INFO:transformers.trainer:{'loss': 3.140177885055542, 'learning_rate': 3.2337478082443275e-05, 'epoch': 1.0597513150534037, 'step': 5884000}
INFO:transformers.trainer:{'loss': 3.100953491926193, 'learning_rate': 3.2335977188330634e-05, 'epoch': 1.059841368700162, 'step': 5884500}
INFO:transformers.trainer:{'loss': 3.125740826487541, 'learning_rate': 3.233447629421799e-05, 'epoch': 1.0599314223469205, 'step': 5885000}
INFO:transformers.trainer:{'loss': 3.08000126683712, 'learning_rate': 3.233297540010535e-05, 'epoch': 1.060021475993679, 'step': 5885500}
INFO:transformers.trainer:{'loss': 3.0396793692111967, 'learning_rate': 3.233147450599271e-05, 'epoch': 1.0601115296404373, 'step': 5886000}
INFO:transformers.trainer:{'loss': 3.1031034951210024, 'learning_rate': 3.232997361188007e-05, 'epoch': 1.0602015832871958, 'step': 5886500}
INFO:transformers.trainer:{'loss': 3.0964419300556183, 'learning_rate': 3.232847271776743e-05, 'epoch': 1.0602916369339543, 'step': 5887000}
INFO:transformers.trainer:{'loss': 3.1141981003284456, 'learning_rate': 3.232697182365479e-05, 'epoch': 1.0603816905807126, 'step': 5887500}
INFO:transformers.trainer:{'loss': 3.030918583869934, 'learning_rate': 3.2325470929542154e-05, 'epoch': 1.0604717442274711, 'step': 5888000}
INFO:transformers.trainer:{'loss': 3.051687394618988, 'learning_rate': 3.2323970035429507e-05, 'epoch': 1.0605617978742297, 'step': 5888500}
INFO:transformers.trainer:{'loss': 3.0966044265031814, 'learning_rate': 3.232246914131687e-05, 'epoch': 1.0606518515209882, 'step': 5889000}
INFO:transformers.trainer:{'loss': 3.1341120064258576, 'learning_rate': 3.2320968247204225e-05, 'epoch': 1.0607419051677465, 'step': 5889500}
INFO:transformers.trainer:{'loss': 3.0713614612817763, 'learning_rate': 3.2319467353091584e-05, 'epoch': 1.060831958814505, 'step': 5890000}
INFO:transformers.trainer:{'loss': 3.0889053548574448, 'learning_rate': 3.231796645897894e-05, 'epoch': 1.0609220124612635, 'step': 5890500}
INFO:transformers.trainer:{'loss': 3.073903648853302, 'learning_rate': 3.23164655648663e-05, 'epoch': 1.0610120661080218, 'step': 5891000}
INFO:transformers.trainer:{'loss': 3.0777317862510682, 'learning_rate': 3.231496467075366e-05, 'epoch': 1.0611021197547803, 'step': 5891500}
INFO:transformers.trainer:{'loss': 3.154569135427475, 'learning_rate': 3.231346377664102e-05, 'epoch': 1.0611921734015388, 'step': 5892000}
INFO:transformers.trainer:{'loss': 3.0762982522249223, 'learning_rate': 3.231196288252838e-05, 'epoch': 1.061282227048297, 'step': 5892500}
INFO:transformers.trainer:{'loss': 3.122199227333069, 'learning_rate': 3.231046198841574e-05, 'epoch': 1.0613722806950556, 'step': 5893000}
INFO:transformers.trainer:{'loss': 3.1177801554203035, 'learning_rate': 3.23089610943031e-05, 'epoch': 1.0614623343418141, 'step': 5893500}
INFO:transformers.trainer:{'loss': 3.1393703939914706, 'learning_rate': 3.2307460200190456e-05, 'epoch': 1.0615523879885727, 'step': 5894000}
INFO:transformers.trainer:{'loss': 3.121120296955109, 'learning_rate': 3.230595930607782e-05, 'epoch': 1.061642441635331, 'step': 5894500}
INFO:transformers.trainer:{'loss': 3.0783488767147063, 'learning_rate': 3.2304458411965174e-05, 'epoch': 1.0617324952820895, 'step': 5895000}
INFO:transformers.trainer:{'loss': 3.071864625930786, 'learning_rate': 3.230295751785254e-05, 'epoch': 1.061822548928848, 'step': 5895500}
INFO:transformers.trainer:{'loss': 3.0971745352745055, 'learning_rate': 3.230145662373989e-05, 'epoch': 1.0619126025756063, 'step': 5896000}
INFO:transformers.trainer:{'loss': 3.123188848733902, 'learning_rate': 3.229995572962726e-05, 'epoch': 1.0620026562223648, 'step': 5896500}
INFO:transformers.trainer:{'loss': 3.040003590941429, 'learning_rate': 3.229845483551461e-05, 'epoch': 1.0620927098691233, 'step': 5897000}
INFO:transformers.trainer:{'loss': 3.140501672029495, 'learning_rate': 3.2296953941401976e-05, 'epoch': 1.0621827635158816, 'step': 5897500}
INFO:transformers.trainer:{'loss': 3.2323494074344636, 'learning_rate': 3.229545304728933e-05, 'epoch': 1.06227281716264, 'step': 5898000}
INFO:transformers.trainer:{'loss': 3.102197122335434, 'learning_rate': 3.2293952153176694e-05, 'epoch': 1.0623628708093986, 'step': 5898500}
INFO:transformers.trainer:{'loss': 3.1144699527025224, 'learning_rate': 3.2292451259064047e-05, 'epoch': 1.062452924456157, 'step': 5899000}
INFO:transformers.trainer:{'loss': 3.119237416744232, 'learning_rate': 3.229095036495141e-05, 'epoch': 1.0625429781029154, 'step': 5899500}
INFO:transformers.trainer:{'loss': 3.0502558934688566, 'learning_rate': 3.2289449470838765e-05, 'epoch': 1.062633031749674, 'step': 5900000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5900000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5900000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5900000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5800000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.057683253288269, 'learning_rate': 3.228794857672613e-05, 'epoch': 1.0627230853964325, 'step': 5900500}
INFO:transformers.trainer:{'loss': 3.0191430530548096, 'learning_rate': 3.228644768261348e-05, 'epoch': 1.0628131390431907, 'step': 5901000}
INFO:transformers.trainer:{'loss': 3.0717568497657775, 'learning_rate': 3.228494678850085e-05, 'epoch': 1.0629031926899493, 'step': 5901500}
INFO:transformers.trainer:{'loss': 3.1028589448928834, 'learning_rate': 3.228344589438821e-05, 'epoch': 1.0629932463367078, 'step': 5902000}
INFO:transformers.trainer:{'loss': 3.1650396886467935, 'learning_rate': 3.228194500027557e-05, 'epoch': 1.063083299983466, 'step': 5902500}
INFO:transformers.trainer:{'loss': 3.0168169591426848, 'learning_rate': 3.2280444106162926e-05, 'epoch': 1.0631733536302246, 'step': 5903000}
INFO:transformers.trainer:{'loss': 3.1582900470495225, 'learning_rate': 3.2278943212050285e-05, 'epoch': 1.063263407276983, 'step': 5903500}
INFO:transformers.trainer:{'loss': 3.0914317066669463, 'learning_rate': 3.2277442317937644e-05, 'epoch': 1.0633534609237414, 'step': 5904000}
INFO:transformers.trainer:{'loss': 3.074751390814781, 'learning_rate': 3.2275941423825e-05, 'epoch': 1.0634435145705, 'step': 5904500}
INFO:transformers.trainer:{'loss': 3.0609067207574845, 'learning_rate': 3.227444052971236e-05, 'epoch': 1.0635335682172584, 'step': 5905000}
INFO:transformers.trainer:{'loss': 3.0640372738838195, 'learning_rate': 3.227293963559972e-05, 'epoch': 1.063623621864017, 'step': 5905500}
INFO:transformers.trainer:{'loss': 3.061492796421051, 'learning_rate': 3.227143874148708e-05, 'epoch': 1.0637136755107752, 'step': 5906000}
INFO:transformers.trainer:{'loss': 3.03921513402462, 'learning_rate': 3.226993784737444e-05, 'epoch': 1.0638037291575337, 'step': 5906500}
INFO:transformers.trainer:{'loss': 3.102195361375809, 'learning_rate': 3.22684369532618e-05, 'epoch': 1.0638937828042923, 'step': 5907000}
INFO:transformers.trainer:{'loss': 3.0904868948459625, 'learning_rate': 3.226693605914916e-05, 'epoch': 1.0639838364510505, 'step': 5907500}
INFO:transformers.trainer:{'loss': 3.0713401625156402, 'learning_rate': 3.2265435165036516e-05, 'epoch': 1.064073890097809, 'step': 5908000}
INFO:transformers.trainer:{'loss': 3.110011684179306, 'learning_rate': 3.226393427092388e-05, 'epoch': 1.0641639437445676, 'step': 5908500}
INFO:transformers.trainer:{'loss': 3.003946273446083, 'learning_rate': 3.2262433376811234e-05, 'epoch': 1.0642539973913259, 'step': 5909000}
INFO:transformers.trainer:{'loss': 3.123657811641693, 'learning_rate': 3.22609324826986e-05, 'epoch': 1.0643440510380844, 'step': 5909500}
INFO:transformers.trainer:{'loss': 3.087149976968765, 'learning_rate': 3.225943158858595e-05, 'epoch': 1.064434104684843, 'step': 5910000}
INFO:transformers.trainer:{'loss': 3.0634492444992065, 'learning_rate': 3.225793069447332e-05, 'epoch': 1.0645241583316012, 'step': 5910500}
INFO:transformers.trainer:{'loss': 3.1042339791059494, 'learning_rate': 3.225642980036067e-05, 'epoch': 1.0646142119783597, 'step': 5911000}
INFO:transformers.trainer:{'loss': 3.046962587594986, 'learning_rate': 3.2254928906248036e-05, 'epoch': 1.0647042656251182, 'step': 5911500}
INFO:transformers.trainer:{'loss': 3.0408475712537766, 'learning_rate': 3.225342801213539e-05, 'epoch': 1.0647943192718767, 'step': 5912000}
INFO:transformers.trainer:{'loss': 3.0516721012592316, 'learning_rate': 3.2251927118022754e-05, 'epoch': 1.064884372918635, 'step': 5912500}
INFO:transformers.trainer:{'loss': 3.0590427106618883, 'learning_rate': 3.225042622391011e-05, 'epoch': 1.0649744265653935, 'step': 5913000}
INFO:transformers.trainer:{'loss': 3.070831382751465, 'learning_rate': 3.2248925329797466e-05, 'epoch': 1.065064480212152, 'step': 5913500}
INFO:transformers.trainer:{'loss': 3.089145821094513, 'learning_rate': 3.2247424435684825e-05, 'epoch': 1.0651545338589103, 'step': 5914000}
INFO:transformers.trainer:{'loss': 3.0985988981723787, 'learning_rate': 3.2245923541572184e-05, 'epoch': 1.0652445875056689, 'step': 5914500}
INFO:transformers.trainer:{'loss': 3.0650652558803557, 'learning_rate': 3.224442264745954e-05, 'epoch': 1.0653346411524274, 'step': 5915000}
INFO:transformers.trainer:{'loss': 3.040383544921875, 'learning_rate': 3.22429217533469e-05, 'epoch': 1.0654246947991857, 'step': 5915500}
INFO:transformers.trainer:{'loss': 3.0633301514387132, 'learning_rate': 3.224142085923427e-05, 'epoch': 1.0655147484459442, 'step': 5916000}
INFO:transformers.trainer:{'loss': 3.074180200099945, 'learning_rate': 3.223991996512162e-05, 'epoch': 1.0656048020927027, 'step': 5916500}
INFO:transformers.trainer:{'loss': 3.105584525823593, 'learning_rate': 3.2238419071008986e-05, 'epoch': 1.0656948557394612, 'step': 5917000}
INFO:transformers.trainer:{'loss': 3.0503464176654815, 'learning_rate': 3.223691817689634e-05, 'epoch': 1.0657849093862195, 'step': 5917500}
INFO:transformers.trainer:{'loss': 3.094776165962219, 'learning_rate': 3.2235417282783704e-05, 'epoch': 1.065874963032978, 'step': 5918000}
INFO:transformers.trainer:{'loss': 3.139117899656296, 'learning_rate': 3.2233916388671056e-05, 'epoch': 1.0659650166797365, 'step': 5918500}
INFO:transformers.trainer:{'loss': 3.0606611738204954, 'learning_rate': 3.223241549455842e-05, 'epoch': 1.0660550703264948, 'step': 5919000}
INFO:transformers.trainer:{'loss': 3.1275278968811033, 'learning_rate': 3.2230914600445774e-05, 'epoch': 1.0661451239732533, 'step': 5919500}
INFO:transformers.trainer:{'loss': 3.1401370950937273, 'learning_rate': 3.222941370633314e-05, 'epoch': 1.0662351776200119, 'step': 5920000}
INFO:transformers.trainer:{'loss': 3.082107748508453, 'learning_rate': 3.222791281222049e-05, 'epoch': 1.0663252312667701, 'step': 5920500}
INFO:transformers.trainer:{'loss': 3.0752321286201476, 'learning_rate': 3.222641191810786e-05, 'epoch': 1.0664152849135287, 'step': 5921000}
INFO:transformers.trainer:{'loss': 3.030276990413666, 'learning_rate': 3.222491102399521e-05, 'epoch': 1.0665053385602872, 'step': 5921500}
INFO:transformers.trainer:{'loss': 3.120003971338272, 'learning_rate': 3.2223410129882576e-05, 'epoch': 1.0665953922070455, 'step': 5922000}
INFO:transformers.trainer:{'loss': 3.070939905166626, 'learning_rate': 3.2221909235769935e-05, 'epoch': 1.066685445853804, 'step': 5922500}
INFO:transformers.trainer:{'loss': 3.042737975358963, 'learning_rate': 3.2220408341657295e-05, 'epoch': 1.0667754995005625, 'step': 5923000}
INFO:transformers.trainer:{'loss': 3.0820661265850067, 'learning_rate': 3.2218907447544654e-05, 'epoch': 1.066865553147321, 'step': 5923500}
INFO:transformers.trainer:{'loss': 3.0341127506494523, 'learning_rate': 3.221740655343201e-05, 'epoch': 1.0669556067940793, 'step': 5924000}
INFO:transformers.trainer:{'loss': 3.1212037069797516, 'learning_rate': 3.221590565931937e-05, 'epoch': 1.0670456604408378, 'step': 5924500}
INFO:transformers.trainer:{'loss': 3.055973722219467, 'learning_rate': 3.221440476520673e-05, 'epoch': 1.0671357140875963, 'step': 5925000}
INFO:transformers.trainer:{'loss': 3.048861233711243, 'learning_rate': 3.221290387109409e-05, 'epoch': 1.0672257677343546, 'step': 5925500}
INFO:transformers.trainer:{'loss': 3.141716802239418, 'learning_rate': 3.221140297698145e-05, 'epoch': 1.0673158213811131, 'step': 5926000}
INFO:transformers.trainer:{'loss': 3.040602737188339, 'learning_rate': 3.220990208286881e-05, 'epoch': 1.0674058750278717, 'step': 5926500}
INFO:transformers.trainer:{'loss': 3.046515105724335, 'learning_rate': 3.220840118875617e-05, 'epoch': 1.0674959286746302, 'step': 5927000}
INFO:transformers.trainer:{'loss': 3.053761519789696, 'learning_rate': 3.2206900294643526e-05, 'epoch': 1.0675859823213885, 'step': 5927500}
INFO:transformers.trainer:{'loss': 3.129586885690689, 'learning_rate': 3.2205399400530885e-05, 'epoch': 1.067676035968147, 'step': 5928000}
INFO:transformers.trainer:{'loss': 3.0837488020658492, 'learning_rate': 3.2203898506418244e-05, 'epoch': 1.0677660896149055, 'step': 5928500}
INFO:transformers.trainer:{'loss': 3.061334826827049, 'learning_rate': 3.22023976123056e-05, 'epoch': 1.0678561432616638, 'step': 5929000}
INFO:transformers.trainer:{'loss': 3.11379585146904, 'learning_rate': 3.220089671819296e-05, 'epoch': 1.0679461969084223, 'step': 5929500}
INFO:transformers.trainer:{'loss': 3.0256268198490144, 'learning_rate': 3.219939582408033e-05, 'epoch': 1.0680362505551808, 'step': 5930000}
INFO:transformers.trainer:{'loss': 3.073177776932716, 'learning_rate': 3.219789492996768e-05, 'epoch': 1.068126304201939, 'step': 5930500}
INFO:transformers.trainer:{'loss': 3.0761734899282454, 'learning_rate': 3.2196394035855046e-05, 'epoch': 1.0682163578486976, 'step': 5931000}
INFO:transformers.trainer:{'loss': 3.11693292427063, 'learning_rate': 3.21948931417424e-05, 'epoch': 1.0683064114954561, 'step': 5931500}
INFO:transformers.trainer:{'loss': 3.078668671488762, 'learning_rate': 3.2193392247629764e-05, 'epoch': 1.0683964651422144, 'step': 5932000}
INFO:transformers.trainer:{'loss': 3.145147000670433, 'learning_rate': 3.2191891353517116e-05, 'epoch': 1.068486518788973, 'step': 5932500}
INFO:transformers.trainer:{'loss': 3.051435334920883, 'learning_rate': 3.219039045940448e-05, 'epoch': 1.0685765724357315, 'step': 5933000}
INFO:transformers.trainer:{'loss': 3.0830108659267426, 'learning_rate': 3.2188889565291835e-05, 'epoch': 1.0686666260824897, 'step': 5933500}
INFO:transformers.trainer:{'loss': 3.0821529779434202, 'learning_rate': 3.21873886711792e-05, 'epoch': 1.0687566797292483, 'step': 5934000}
INFO:transformers.trainer:{'loss': 3.091830287694931, 'learning_rate': 3.218588777706655e-05, 'epoch': 1.0688467333760068, 'step': 5934500}
INFO:transformers.trainer:{'loss': 3.0807246103286743, 'learning_rate': 3.218438688295392e-05, 'epoch': 1.0689367870227653, 'step': 5935000}
INFO:transformers.trainer:{'loss': 3.14055269575119, 'learning_rate': 3.218288598884127e-05, 'epoch': 1.0690268406695236, 'step': 5935500}
INFO:transformers.trainer:{'loss': 3.062951508998871, 'learning_rate': 3.218138509472864e-05, 'epoch': 1.069116894316282, 'step': 5936000}
INFO:transformers.trainer:{'loss': 3.0253708972930906, 'learning_rate': 3.2179884200615996e-05, 'epoch': 1.0692069479630406, 'step': 5936500}
INFO:transformers.trainer:{'loss': 3.0504955005645753, 'learning_rate': 3.217838330650335e-05, 'epoch': 1.069297001609799, 'step': 5937000}
INFO:transformers.trainer:{'loss': 3.09857754611969, 'learning_rate': 3.2176882412390714e-05, 'epoch': 1.0693870552565574, 'step': 5937500}
INFO:transformers.trainer:{'loss': 3.0750796877145765, 'learning_rate': 3.2175381518278066e-05, 'epoch': 1.069477108903316, 'step': 5938000}
INFO:transformers.trainer:{'loss': 3.0356815304756166, 'learning_rate': 3.217388062416543e-05, 'epoch': 1.0695671625500744, 'step': 5938500}
INFO:transformers.trainer:{'loss': 3.025470116376877, 'learning_rate': 3.2172379730052784e-05, 'epoch': 1.0696572161968327, 'step': 5939000}
INFO:transformers.trainer:{'loss': 3.0783830844163895, 'learning_rate': 3.217087883594015e-05, 'epoch': 1.0697472698435913, 'step': 5939500}
INFO:transformers.trainer:{'loss': 2.996960105419159, 'learning_rate': 3.21693779418275e-05, 'epoch': 1.0698373234903498, 'step': 5940000}
INFO:transformers.trainer:{'loss': 3.020525656223297, 'learning_rate': 3.216787704771487e-05, 'epoch': 1.069927377137108, 'step': 5940500}
INFO:transformers.trainer:{'loss': 3.1178468248844147, 'learning_rate': 3.216637615360222e-05, 'epoch': 1.0700174307838666, 'step': 5941000}
INFO:transformers.trainer:{'loss': 3.0411514809131623, 'learning_rate': 3.2164875259489586e-05, 'epoch': 1.070107484430625, 'step': 5941500}
INFO:transformers.trainer:{'loss': 3.0713653197288515, 'learning_rate': 3.216337436537694e-05, 'epoch': 1.0701975380773834, 'step': 5942000}
INFO:transformers.trainer:{'loss': 3.0973571228981016, 'learning_rate': 3.2161873471264304e-05, 'epoch': 1.070287591724142, 'step': 5942500}
INFO:transformers.trainer:{'loss': 3.076768588781357, 'learning_rate': 3.216037257715166e-05, 'epoch': 1.0703776453709004, 'step': 5943000}
INFO:transformers.trainer:{'loss': 3.1534411252737047, 'learning_rate': 3.215887168303902e-05, 'epoch': 1.0704676990176587, 'step': 5943500}
INFO:transformers.trainer:{'loss': 3.1047488360404967, 'learning_rate': 3.215737078892638e-05, 'epoch': 1.0705577526644172, 'step': 5944000}
INFO:transformers.trainer:{'loss': 3.1220762689113615, 'learning_rate': 3.215586989481374e-05, 'epoch': 1.0706478063111757, 'step': 5944500}
INFO:transformers.trainer:{'loss': 3.095239956021309, 'learning_rate': 3.21543690007011e-05, 'epoch': 1.070737859957934, 'step': 5945000}
INFO:transformers.trainer:{'loss': 3.042691744208336, 'learning_rate': 3.215286810658846e-05, 'epoch': 1.0708279136046925, 'step': 5945500}
INFO:transformers.trainer:{'loss': 3.061376529812813, 'learning_rate': 3.215136721247582e-05, 'epoch': 1.070917967251451, 'step': 5946000}
INFO:transformers.trainer:{'loss': 3.0764839339256285, 'learning_rate': 3.214986631836318e-05, 'epoch': 1.0710080208982096, 'step': 5946500}
INFO:transformers.trainer:{'loss': 3.057737885475159, 'learning_rate': 3.2148365424250536e-05, 'epoch': 1.0710980745449679, 'step': 5947000}
INFO:transformers.trainer:{'loss': 3.0832199627161025, 'learning_rate': 3.2146864530137895e-05, 'epoch': 1.0711881281917264, 'step': 5947500}
INFO:transformers.trainer:{'loss': 3.0284047915935517, 'learning_rate': 3.2145363636025254e-05, 'epoch': 1.0712781818384849, 'step': 5948000}
INFO:transformers.trainer:{'loss': 3.1125902092456816, 'learning_rate': 3.214386274191261e-05, 'epoch': 1.0713682354852432, 'step': 5948500}
INFO:transformers.trainer:{'loss': 3.043788339138031, 'learning_rate': 3.214236184779997e-05, 'epoch': 1.0714582891320017, 'step': 5949000}
INFO:transformers.trainer:{'loss': 3.0276411526203155, 'learning_rate': 3.214086095368733e-05, 'epoch': 1.0715483427787602, 'step': 5949500}
INFO:transformers.trainer:{'loss': 2.9869580166339875, 'learning_rate': 3.213936005957469e-05, 'epoch': 1.0716383964255187, 'step': 5950000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-5950000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5950000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-5950000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5850000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.038780979037285, 'learning_rate': 3.2137859165462056e-05, 'epoch': 1.071728450072277, 'step': 5950500}
INFO:transformers.trainer:{'loss': 3.1746272523403167, 'learning_rate': 3.213635827134941e-05, 'epoch': 1.0718185037190355, 'step': 5951000}
INFO:transformers.trainer:{'loss': 3.0838235602378847, 'learning_rate': 3.2134857377236774e-05, 'epoch': 1.071908557365794, 'step': 5951500}
INFO:transformers.trainer:{'loss': 3.0706736254692077, 'learning_rate': 3.2133356483124126e-05, 'epoch': 1.0719986110125523, 'step': 5952000}
INFO:transformers.trainer:{'loss': 3.1127264927625657, 'learning_rate': 3.213185558901149e-05, 'epoch': 1.0720886646593109, 'step': 5952500}
INFO:transformers.trainer:{'loss': 3.0521039308309557, 'learning_rate': 3.2130354694898844e-05, 'epoch': 1.0721787183060694, 'step': 5953000}
INFO:transformers.trainer:{'loss': 3.0792241257429125, 'learning_rate': 3.212885380078621e-05, 'epoch': 1.0722687719528277, 'step': 5953500}
INFO:transformers.trainer:{'loss': 3.0791039810180663, 'learning_rate': 3.212735290667356e-05, 'epoch': 1.0723588255995862, 'step': 5954000}
INFO:transformers.trainer:{'loss': 3.1342040469646455, 'learning_rate': 3.212585201256093e-05, 'epoch': 1.0724488792463447, 'step': 5954500}
INFO:transformers.trainer:{'loss': 3.0972380061149596, 'learning_rate': 3.212435111844828e-05, 'epoch': 1.072538932893103, 'step': 5955000}
INFO:transformers.trainer:{'loss': 3.0795905656814577, 'learning_rate': 3.2122850224335646e-05, 'epoch': 1.0726289865398615, 'step': 5955500}
INFO:transformers.trainer:{'loss': 3.019904756307602, 'learning_rate': 3.2121349330223e-05, 'epoch': 1.07271904018662, 'step': 5956000}
INFO:transformers.trainer:{'loss': 3.078273463487625, 'learning_rate': 3.2119848436110364e-05, 'epoch': 1.0728090938333785, 'step': 5956500}
INFO:transformers.trainer:{'loss': 3.0664313986301424, 'learning_rate': 3.2118347541997724e-05, 'epoch': 1.0728991474801368, 'step': 5957000}
INFO:transformers.trainer:{'loss': 3.0709593253135683, 'learning_rate': 3.211684664788508e-05, 'epoch': 1.0729892011268953, 'step': 5957500}
INFO:transformers.trainer:{'loss': 3.0791478197574618, 'learning_rate': 3.211534575377244e-05, 'epoch': 1.0730792547736538, 'step': 5958000}
INFO:transformers.trainer:{'loss': 3.052481313943863, 'learning_rate': 3.21138448596598e-05, 'epoch': 1.0731693084204121, 'step': 5958500}
INFO:transformers.trainer:{'loss': 3.066041767954826, 'learning_rate': 3.211234396554716e-05, 'epoch': 1.0732593620671707, 'step': 5959000}
INFO:transformers.trainer:{'loss': 3.127442630171776, 'learning_rate': 3.211084307143452e-05, 'epoch': 1.0733494157139292, 'step': 5959500}
INFO:transformers.trainer:{'loss': 3.081111169099808, 'learning_rate': 3.210934217732188e-05, 'epoch': 1.0734394693606875, 'step': 5960000}
INFO:transformers.trainer:{'loss': 3.084825464963913, 'learning_rate': 3.210784128320923e-05, 'epoch': 1.073529523007446, 'step': 5960500}
INFO:transformers.trainer:{'loss': 3.07456258225441, 'learning_rate': 3.2106340389096596e-05, 'epoch': 1.0736195766542045, 'step': 5961000}
INFO:transformers.trainer:{'loss': 3.03829911839962, 'learning_rate': 3.210483949498395e-05, 'epoch': 1.073709630300963, 'step': 5961500}
INFO:transformers.trainer:{'loss': 3.069281756877899, 'learning_rate': 3.2103338600871314e-05, 'epoch': 1.0737996839477213, 'step': 5962000}
INFO:transformers.trainer:{'loss': 3.079906315326691, 'learning_rate': 3.2101837706758666e-05, 'epoch': 1.0738897375944798, 'step': 5962500}
INFO:transformers.trainer:{'loss': 3.033470626115799, 'learning_rate': 3.210033681264603e-05, 'epoch': 1.0739797912412383, 'step': 5963000}
INFO:transformers.trainer:{'loss': 3.0733320038318634, 'learning_rate': 3.2098835918533384e-05, 'epoch': 1.0740698448879966, 'step': 5963500}
INFO:transformers.trainer:{'loss': 3.0702962770462037, 'learning_rate': 3.209733502442075e-05, 'epoch': 1.0741598985347551, 'step': 5964000}
INFO:transformers.trainer:{'loss': 3.0983287372589112, 'learning_rate': 3.209583413030811e-05, 'epoch': 1.0742499521815136, 'step': 5964500}
INFO:transformers.trainer:{'loss': 3.0864711766242983, 'learning_rate': 3.209433323619547e-05, 'epoch': 1.074340005828272, 'step': 5965000}
INFO:transformers.trainer:{'loss': 3.0857832688093185, 'learning_rate': 3.209283234208283e-05, 'epoch': 1.0744300594750305, 'step': 5965500}
INFO:transformers.trainer:{'loss': 3.139374082684517, 'learning_rate': 3.2091331447970186e-05, 'epoch': 1.074520113121789, 'step': 5966000}
INFO:transformers.trainer:{'loss': 3.078605408668518, 'learning_rate': 3.2089830553857545e-05, 'epoch': 1.0746101667685473, 'step': 5966500}
INFO:transformers.trainer:{'loss': 3.0766923215389252, 'learning_rate': 3.2088329659744905e-05, 'epoch': 1.0747002204153058, 'step': 5967000}
INFO:transformers.trainer:{'loss': 3.026133227109909, 'learning_rate': 3.2086828765632264e-05, 'epoch': 1.0747902740620643, 'step': 5967500}
INFO:transformers.trainer:{'loss': 3.026334733247757, 'learning_rate': 3.208532787151962e-05, 'epoch': 1.0748803277088228, 'step': 5968000}
INFO:transformers.trainer:{'loss': 3.039645866751671, 'learning_rate': 3.208382697740698e-05, 'epoch': 1.074970381355581, 'step': 5968500}
INFO:transformers.trainer:{'loss': 3.0941140105724334, 'learning_rate': 3.208232608329434e-05, 'epoch': 1.0750604350023396, 'step': 5969000}
INFO:transformers.trainer:{'loss': 3.049591363668442, 'learning_rate': 3.20808251891817e-05, 'epoch': 1.0751504886490981, 'step': 5969500}
INFO:transformers.trainer:{'loss': 3.016448662400246, 'learning_rate': 3.207932429506906e-05, 'epoch': 1.0752405422958564, 'step': 5970000}
INFO:transformers.trainer:{'loss': 3.039721410751343, 'learning_rate': 3.207782340095642e-05, 'epoch': 1.075330595942615, 'step': 5970500}
INFO:transformers.trainer:{'loss': 3.091075561761856, 'learning_rate': 3.2076322506843784e-05, 'epoch': 1.0754206495893734, 'step': 5971000}
INFO:transformers.trainer:{'loss': 3.0303679943084716, 'learning_rate': 3.2074821612731136e-05, 'epoch': 1.0755107032361317, 'step': 5971500}
INFO:transformers.trainer:{'loss': 3.0981490314006805, 'learning_rate': 3.20733207186185e-05, 'epoch': 1.0756007568828903, 'step': 5972000}
INFO:transformers.trainer:{'loss': 3.1003047226667406, 'learning_rate': 3.2071819824505854e-05, 'epoch': 1.0756908105296488, 'step': 5972500}
INFO:transformers.trainer:{'loss': 3.097122974693775, 'learning_rate': 3.207031893039322e-05, 'epoch': 1.0757808641764073, 'step': 5973000}
INFO:transformers.trainer:{'loss': 3.079319334387779, 'learning_rate': 3.206881803628057e-05, 'epoch': 1.0758709178231656, 'step': 5973500}
INFO:transformers.trainer:{'loss': 3.088645802140236, 'learning_rate': 3.206731714216794e-05, 'epoch': 1.075960971469924, 'step': 5974000}
INFO:transformers.trainer:{'loss': 3.0552208578586577, 'learning_rate': 3.206581624805529e-05, 'epoch': 1.0760510251166826, 'step': 5974500}
INFO:transformers.trainer:{'loss': 3.037462704658508, 'learning_rate': 3.2064315353942656e-05, 'epoch': 1.076141078763441, 'step': 5975000}
INFO:transformers.trainer:{'loss': 3.1374035434722902, 'learning_rate': 3.206281445983001e-05, 'epoch': 1.0762311324101994, 'step': 5975500}
INFO:transformers.trainer:{'loss': 3.1127310655117033, 'learning_rate': 3.2061313565717374e-05, 'epoch': 1.076321186056958, 'step': 5976000}
INFO:transformers.trainer:{'loss': 3.118413581609726, 'learning_rate': 3.2059812671604726e-05, 'epoch': 1.0764112397037162, 'step': 5976500}
INFO:transformers.trainer:{'loss': 3.0453345181941986, 'learning_rate': 3.205831177749209e-05, 'epoch': 1.0765012933504747, 'step': 5977000}
INFO:transformers.trainer:{'loss': 3.075900418877602, 'learning_rate': 3.2056810883379445e-05, 'epoch': 1.0765913469972332, 'step': 5977500}
INFO:transformers.trainer:{'loss': 3.090455708026886, 'learning_rate': 3.205530998926681e-05, 'epoch': 1.0766814006439915, 'step': 5978000}
INFO:transformers.trainer:{'loss': 3.0741286945343016, 'learning_rate': 3.205380909515417e-05, 'epoch': 1.07677145429075, 'step': 5978500}
INFO:transformers.trainer:{'loss': 3.045900253534317, 'learning_rate': 3.205230820104153e-05, 'epoch': 1.0768615079375086, 'step': 5979000}
INFO:transformers.trainer:{'loss': 3.0630999608039855, 'learning_rate': 3.205080730692889e-05, 'epoch': 1.076951561584267, 'step': 5979500}
INFO:transformers.trainer:{'loss': 3.0989243278503418, 'learning_rate': 3.2049306412816247e-05, 'epoch': 1.0770416152310254, 'step': 5980000}
INFO:transformers.trainer:{'loss': 3.1079271675348283, 'learning_rate': 3.2047805518703606e-05, 'epoch': 1.0771316688777839, 'step': 5980500}
INFO:transformers.trainer:{'loss': 3.1024527084827422, 'learning_rate': 3.2046304624590965e-05, 'epoch': 1.0772217225245424, 'step': 5981000}
INFO:transformers.trainer:{'loss': 3.096924885392189, 'learning_rate': 3.2044803730478324e-05, 'epoch': 1.0773117761713007, 'step': 5981500}
INFO:transformers.trainer:{'loss': 3.074535775184631, 'learning_rate': 3.204330283636568e-05, 'epoch': 1.0774018298180592, 'step': 5982000}
INFO:transformers.trainer:{'loss': 3.0302586479187013, 'learning_rate': 3.204180194225304e-05, 'epoch': 1.0774918834648177, 'step': 5982500}
INFO:transformers.trainer:{'loss': 3.091267584681511, 'learning_rate': 3.20403010481404e-05, 'epoch': 1.077581937111576, 'step': 5983000}
INFO:transformers.trainer:{'loss': 3.0630290579795836, 'learning_rate': 3.203880015402776e-05, 'epoch': 1.0776719907583345, 'step': 5983500}
INFO:transformers.trainer:{'loss': 3.0572551316022873, 'learning_rate': 3.203729925991512e-05, 'epoch': 1.077762044405093, 'step': 5984000}
INFO:transformers.trainer:{'loss': 3.076263619184494, 'learning_rate': 3.203579836580248e-05, 'epoch': 1.0778520980518516, 'step': 5984500}
INFO:transformers.trainer:{'loss': 3.041167332649231, 'learning_rate': 3.203429747168984e-05, 'epoch': 1.0779421516986099, 'step': 5985000}
INFO:transformers.trainer:{'loss': 3.020878514766693, 'learning_rate': 3.2032796577577196e-05, 'epoch': 1.0780322053453684, 'step': 5985500}
INFO:transformers.trainer:{'loss': 3.0365818967819216, 'learning_rate': 3.2031295683464555e-05, 'epoch': 1.0781222589921269, 'step': 5986000}
INFO:transformers.trainer:{'loss': 3.0518676228523254, 'learning_rate': 3.2029794789351914e-05, 'epoch': 1.0782123126388852, 'step': 5986500}
INFO:transformers.trainer:{'loss': 3.057631833434105, 'learning_rate': 3.202829389523927e-05, 'epoch': 1.0783023662856437, 'step': 5987000}
INFO:transformers.trainer:{'loss': 3.051219936490059, 'learning_rate': 3.202679300112663e-05, 'epoch': 1.0783924199324022, 'step': 5987500}
INFO:transformers.trainer:{'loss': 3.1128810667991638, 'learning_rate': 3.202529210701399e-05, 'epoch': 1.0784824735791605, 'step': 5988000}
INFO:transformers.trainer:{'loss': 3.1479825785160065, 'learning_rate': 3.202379121290135e-05, 'epoch': 1.078572527225919, 'step': 5988500}
INFO:transformers.trainer:{'loss': 3.092970411300659, 'learning_rate': 3.202229031878871e-05, 'epoch': 1.0786625808726775, 'step': 5989000}
INFO:transformers.trainer:{'loss': 3.0650330731868745, 'learning_rate': 3.202078942467607e-05, 'epoch': 1.0787526345194358, 'step': 5989500}
INFO:transformers.trainer:{'loss': 3.0936483715772627, 'learning_rate': 3.201928853056343e-05, 'epoch': 1.0788426881661943, 'step': 5990000}
INFO:transformers.trainer:{'loss': 3.061191680908203, 'learning_rate': 3.201778763645079e-05, 'epoch': 1.0789327418129528, 'step': 5990500}
INFO:transformers.trainer:{'loss': 3.089246144294739, 'learning_rate': 3.2016286742338146e-05, 'epoch': 1.0790227954597114, 'step': 5991000}
INFO:transformers.trainer:{'loss': 3.128842919588089, 'learning_rate': 3.201478584822551e-05, 'epoch': 1.0791128491064697, 'step': 5991500}
INFO:transformers.trainer:{'loss': 3.094754498243332, 'learning_rate': 3.2013284954112864e-05, 'epoch': 1.0792029027532282, 'step': 5992000}
INFO:transformers.trainer:{'loss': 3.082375682234764, 'learning_rate': 3.201178406000023e-05, 'epoch': 1.0792929563999867, 'step': 5992500}
INFO:transformers.trainer:{'loss': 3.0853807463645935, 'learning_rate': 3.201028316588758e-05, 'epoch': 1.079383010046745, 'step': 5993000}
INFO:transformers.trainer:{'loss': 3.087499460697174, 'learning_rate': 3.200878227177495e-05, 'epoch': 1.0794730636935035, 'step': 5993500}
INFO:transformers.trainer:{'loss': 3.0236057248115538, 'learning_rate': 3.20072813776623e-05, 'epoch': 1.079563117340262, 'step': 5994000}
INFO:transformers.trainer:{'loss': 3.1377656283378603, 'learning_rate': 3.2005780483549666e-05, 'epoch': 1.0796531709870203, 'step': 5994500}
INFO:transformers.trainer:{'loss': 3.0847065963745117, 'learning_rate': 3.200427958943702e-05, 'epoch': 1.0797432246337788, 'step': 5995000}
INFO:transformers.trainer:{'loss': 3.0799349287748337, 'learning_rate': 3.2002778695324384e-05, 'epoch': 1.0798332782805373, 'step': 5995500}
INFO:transformers.trainer:{'loss': 3.1000043745040893, 'learning_rate': 3.2001277801211736e-05, 'epoch': 1.0799233319272958, 'step': 5996000}
INFO:transformers.trainer:{'loss': 3.0849562355279923, 'learning_rate': 3.19997769070991e-05, 'epoch': 1.0800133855740541, 'step': 5996500}
INFO:transformers.trainer:{'loss': 3.0839817818403246, 'learning_rate': 3.1998276012986454e-05, 'epoch': 1.0801034392208126, 'step': 5997000}
INFO:transformers.trainer:{'loss': 3.0851010777950285, 'learning_rate': 3.199677511887382e-05, 'epoch': 1.0801934928675712, 'step': 5997500}
INFO:transformers.trainer:{'loss': 3.0724389609098433, 'learning_rate': 3.199527422476117e-05, 'epoch': 1.0802835465143295, 'step': 5998000}
INFO:transformers.trainer:{'loss': 3.069002582192421, 'learning_rate': 3.199377333064854e-05, 'epoch': 1.080373600161088, 'step': 5998500}
INFO:transformers.trainer:{'loss': 3.073599015712738, 'learning_rate': 3.19922724365359e-05, 'epoch': 1.0804636538078465, 'step': 5999000}
INFO:transformers.trainer:{'loss': 3.050084678411484, 'learning_rate': 3.1990771542423256e-05, 'epoch': 1.0805537074546048, 'step': 5999500}
INFO:transformers.trainer:{'loss': 3.098146828651428, 'learning_rate': 3.1989270648310615e-05, 'epoch': 1.0806437611013633, 'step': 6000000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6000000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6000000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6000000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5900000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0048401908874514, 'learning_rate': 3.1987769754197974e-05, 'epoch': 1.0807338147481218, 'step': 6000500}
INFO:transformers.trainer:{'loss': 3.0875692312717438, 'learning_rate': 3.1986268860085333e-05, 'epoch': 1.08082386839488, 'step': 6001000}
INFO:transformers.trainer:{'loss': 3.0660580534935, 'learning_rate': 3.198476796597269e-05, 'epoch': 1.0809139220416386, 'step': 6001500}
INFO:transformers.trainer:{'loss': 3.0838052734136583, 'learning_rate': 3.198326707186005e-05, 'epoch': 1.0810039756883971, 'step': 6002000}
INFO:transformers.trainer:{'loss': 3.1182741565704344, 'learning_rate': 3.198176617774741e-05, 'epoch': 1.0810940293351556, 'step': 6002500}
INFO:transformers.trainer:{'loss': 3.1121869375705717, 'learning_rate': 3.198026528363477e-05, 'epoch': 1.081184082981914, 'step': 6003000}
INFO:transformers.trainer:{'loss': 3.0712029002904893, 'learning_rate': 3.197876438952213e-05, 'epoch': 1.0812741366286724, 'step': 6003500}
INFO:transformers.trainer:{'loss': 3.0905686378479005, 'learning_rate': 3.197726349540949e-05, 'epoch': 1.081364190275431, 'step': 6004000}
INFO:transformers.trainer:{'loss': 3.0652859714031218, 'learning_rate': 3.197576260129685e-05, 'epoch': 1.0814542439221893, 'step': 6004500}
INFO:transformers.trainer:{'loss': 3.0857741947174073, 'learning_rate': 3.1974261707184206e-05, 'epoch': 1.0815442975689478, 'step': 6005000}
INFO:transformers.trainer:{'loss': 3.0585605511665346, 'learning_rate': 3.1972760813071565e-05, 'epoch': 1.0816343512157063, 'step': 6005500}
INFO:transformers.trainer:{'loss': 3.0828904480934143, 'learning_rate': 3.1971259918958924e-05, 'epoch': 1.0817244048624646, 'step': 6006000}
INFO:transformers.trainer:{'loss': 3.0927293298244476, 'learning_rate': 3.196975902484628e-05, 'epoch': 1.081814458509223, 'step': 6006500}
INFO:transformers.trainer:{'loss': 3.026084861755371, 'learning_rate': 3.196825813073364e-05, 'epoch': 1.0819045121559816, 'step': 6007000}
INFO:transformers.trainer:{'loss': 3.0692626487016677, 'learning_rate': 3.1966757236621e-05, 'epoch': 1.0819945658027401, 'step': 6007500}
INFO:transformers.trainer:{'loss': 3.0244871141910554, 'learning_rate': 3.196525634250836e-05, 'epoch': 1.0820846194494984, 'step': 6008000}
INFO:transformers.trainer:{'loss': 3.110761171102524, 'learning_rate': 3.196375544839572e-05, 'epoch': 1.082174673096257, 'step': 6008500}
INFO:transformers.trainer:{'loss': 3.056795185804367, 'learning_rate': 3.196225455428308e-05, 'epoch': 1.0822647267430154, 'step': 6009000}
INFO:transformers.trainer:{'loss': 3.066719382762909, 'learning_rate': 3.196075366017044e-05, 'epoch': 1.0823547803897737, 'step': 6009500}
INFO:transformers.trainer:{'loss': 3.056347642183304, 'learning_rate': 3.1959252766057796e-05, 'epoch': 1.0824448340365322, 'step': 6010000}
INFO:transformers.trainer:{'loss': 3.0971426857709883, 'learning_rate': 3.1957751871945155e-05, 'epoch': 1.0825348876832908, 'step': 6010500}
INFO:transformers.trainer:{'loss': 3.1315479547977447, 'learning_rate': 3.1956250977832514e-05, 'epoch': 1.082624941330049, 'step': 6011000}
INFO:transformers.trainer:{'loss': 3.0446953065395355, 'learning_rate': 3.1954750083719874e-05, 'epoch': 1.0827149949768076, 'step': 6011500}
INFO:transformers.trainer:{'loss': 3.110975539445877, 'learning_rate': 3.195324918960723e-05, 'epoch': 1.082805048623566, 'step': 6012000}
INFO:transformers.trainer:{'loss': 3.0670098791122435, 'learning_rate': 3.195174829549459e-05, 'epoch': 1.0828951022703244, 'step': 6012500}
INFO:transformers.trainer:{'loss': 3.041438479542732, 'learning_rate': 3.195024740138196e-05, 'epoch': 1.0829851559170829, 'step': 6013000}
INFO:transformers.trainer:{'loss': 3.0664791671037674, 'learning_rate': 3.194874650726931e-05, 'epoch': 1.0830752095638414, 'step': 6013500}
INFO:transformers.trainer:{'loss': 3.0658984837532044, 'learning_rate': 3.1947245613156676e-05, 'epoch': 1.0831652632106, 'step': 6014000}
INFO:transformers.trainer:{'loss': 3.059609163045883, 'learning_rate': 3.194574471904403e-05, 'epoch': 1.0832553168573582, 'step': 6014500}
INFO:transformers.trainer:{'loss': 3.0574082596302032, 'learning_rate': 3.1944243824931394e-05, 'epoch': 1.0833453705041167, 'step': 6015000}
INFO:transformers.trainer:{'loss': 3.068559899568558, 'learning_rate': 3.1942742930818746e-05, 'epoch': 1.0834354241508752, 'step': 6015500}
INFO:transformers.trainer:{'loss': 3.0977103550434113, 'learning_rate': 3.194124203670611e-05, 'epoch': 1.0835254777976335, 'step': 6016000}
INFO:transformers.trainer:{'loss': 3.0265142267942426, 'learning_rate': 3.1939741142593464e-05, 'epoch': 1.083615531444392, 'step': 6016500}
INFO:transformers.trainer:{'loss': 3.120729326248169, 'learning_rate': 3.193824024848083e-05, 'epoch': 1.0837055850911506, 'step': 6017000}
INFO:transformers.trainer:{'loss': 3.0771204812526705, 'learning_rate': 3.193673935436818e-05, 'epoch': 1.0837956387379089, 'step': 6017500}
INFO:transformers.trainer:{'loss': 3.126209599494934, 'learning_rate': 3.193523846025555e-05, 'epoch': 1.0838856923846674, 'step': 6018000}
INFO:transformers.trainer:{'loss': 3.1144058492183686, 'learning_rate': 3.19337375661429e-05, 'epoch': 1.0839757460314259, 'step': 6018500}
INFO:transformers.trainer:{'loss': 3.0617689465284346, 'learning_rate': 3.1932236672030266e-05, 'epoch': 1.0840657996781844, 'step': 6019000}
INFO:transformers.trainer:{'loss': 3.102013752937317, 'learning_rate': 3.1930735777917625e-05, 'epoch': 1.0841558533249427, 'step': 6019500}
INFO:transformers.trainer:{'loss': 3.078741636276245, 'learning_rate': 3.1929234883804984e-05, 'epoch': 1.0842459069717012, 'step': 6020000}
INFO:transformers.trainer:{'loss': 3.0530684838294984, 'learning_rate': 3.192773398969234e-05, 'epoch': 1.0843359606184597, 'step': 6020500}
INFO:transformers.trainer:{'loss': 3.0581839764118195, 'learning_rate': 3.19262330955797e-05, 'epoch': 1.084426014265218, 'step': 6021000}
INFO:transformers.trainer:{'loss': 3.1111041600704192, 'learning_rate': 3.192473220146706e-05, 'epoch': 1.0845160679119765, 'step': 6021500}
INFO:transformers.trainer:{'loss': 3.086485086917877, 'learning_rate': 3.192323130735442e-05, 'epoch': 1.084606121558735, 'step': 6022000}
INFO:transformers.trainer:{'loss': 3.0874930053949354, 'learning_rate': 3.192173041324178e-05, 'epoch': 1.0846961752054933, 'step': 6022500}
INFO:transformers.trainer:{'loss': 3.0661608304977417, 'learning_rate': 3.192022951912914e-05, 'epoch': 1.0847862288522518, 'step': 6023000}
INFO:transformers.trainer:{'loss': 3.0569145709276198, 'learning_rate': 3.19187286250165e-05, 'epoch': 1.0848762824990104, 'step': 6023500}
INFO:transformers.trainer:{'loss': 3.0677100794315337, 'learning_rate': 3.1917227730903857e-05, 'epoch': 1.0849663361457687, 'step': 6024000}
INFO:transformers.trainer:{'loss': 3.1259970946311952, 'learning_rate': 3.1915726836791216e-05, 'epoch': 1.0850563897925272, 'step': 6024500}
INFO:transformers.trainer:{'loss': 3.0936911640167235, 'learning_rate': 3.1914225942678575e-05, 'epoch': 1.0851464434392857, 'step': 6025000}
INFO:transformers.trainer:{'loss': 3.0341436138153077, 'learning_rate': 3.1912725048565934e-05, 'epoch': 1.0852364970860442, 'step': 6025500}
INFO:transformers.trainer:{'loss': 3.156615615725517, 'learning_rate': 3.191122415445329e-05, 'epoch': 1.0853265507328025, 'step': 6026000}
INFO:transformers.trainer:{'loss': 3.0632132958173752, 'learning_rate': 3.190972326034065e-05, 'epoch': 1.085416604379561, 'step': 6026500}
INFO:transformers.trainer:{'loss': 3.0498254072666167, 'learning_rate': 3.190822236622801e-05, 'epoch': 1.0855066580263195, 'step': 6027000}
INFO:transformers.trainer:{'loss': 3.072419149637222, 'learning_rate': 3.190672147211537e-05, 'epoch': 1.0855967116730778, 'step': 6027500}
INFO:transformers.trainer:{'loss': 3.0467371582984923, 'learning_rate': 3.190522057800273e-05, 'epoch': 1.0856867653198363, 'step': 6028000}
INFO:transformers.trainer:{'loss': 3.0311117725372316, 'learning_rate': 3.190371968389009e-05, 'epoch': 1.0857768189665948, 'step': 6028500}
INFO:transformers.trainer:{'loss': 3.078013321638107, 'learning_rate': 3.190221878977745e-05, 'epoch': 1.0858668726133531, 'step': 6029000}
INFO:transformers.trainer:{'loss': 3.0647941789627073, 'learning_rate': 3.1900717895664806e-05, 'epoch': 1.0859569262601116, 'step': 6029500}
INFO:transformers.trainer:{'loss': 3.162890313863754, 'learning_rate': 3.1899217001552165e-05, 'epoch': 1.0860469799068702, 'step': 6030000}
INFO:transformers.trainer:{'loss': 3.0473879264593124, 'learning_rate': 3.1897716107439524e-05, 'epoch': 1.0861370335536287, 'step': 6030500}
INFO:transformers.trainer:{'loss': 3.0714144685268403, 'learning_rate': 3.189621521332688e-05, 'epoch': 1.086227087200387, 'step': 6031000}
INFO:transformers.trainer:{'loss': 3.0389056088924407, 'learning_rate': 3.189471431921424e-05, 'epoch': 1.0863171408471455, 'step': 6031500}
INFO:transformers.trainer:{'loss': 3.0918247280120847, 'learning_rate': 3.18932134251016e-05, 'epoch': 1.086407194493904, 'step': 6032000}
INFO:transformers.trainer:{'loss': 3.0348633029460905, 'learning_rate': 3.189171253098896e-05, 'epoch': 1.0864972481406623, 'step': 6032500}
INFO:transformers.trainer:{'loss': 3.08408900475502, 'learning_rate': 3.189021163687632e-05, 'epoch': 1.0865873017874208, 'step': 6033000}
INFO:transformers.trainer:{'loss': 3.016454041481018, 'learning_rate': 3.1888710742763685e-05, 'epoch': 1.0866773554341793, 'step': 6033500}
INFO:transformers.trainer:{'loss': 3.054283719062805, 'learning_rate': 3.188720984865104e-05, 'epoch': 1.0867674090809376, 'step': 6034000}
INFO:transformers.trainer:{'loss': 3.076590106010437, 'learning_rate': 3.18857089545384e-05, 'epoch': 1.0868574627276961, 'step': 6034500}
INFO:transformers.trainer:{'loss': 3.0957574582099916, 'learning_rate': 3.1884208060425756e-05, 'epoch': 1.0869475163744546, 'step': 6035000}
INFO:transformers.trainer:{'loss': 3.144062649011612, 'learning_rate': 3.188270716631312e-05, 'epoch': 1.087037570021213, 'step': 6035500}
INFO:transformers.trainer:{'loss': 3.022202883481979, 'learning_rate': 3.1881206272200474e-05, 'epoch': 1.0871276236679714, 'step': 6036000}
INFO:transformers.trainer:{'loss': 3.075645828962326, 'learning_rate': 3.187970537808784e-05, 'epoch': 1.08721767731473, 'step': 6036500}
INFO:transformers.trainer:{'loss': 3.06107487475872, 'learning_rate': 3.187820448397519e-05, 'epoch': 1.0873077309614885, 'step': 6037000}
INFO:transformers.trainer:{'loss': 3.068032998085022, 'learning_rate': 3.187670358986256e-05, 'epoch': 1.0873977846082468, 'step': 6037500}
INFO:transformers.trainer:{'loss': 3.10782809817791, 'learning_rate': 3.187520269574991e-05, 'epoch': 1.0874878382550053, 'step': 6038000}
INFO:transformers.trainer:{'loss': 3.07113338971138, 'learning_rate': 3.1873701801637276e-05, 'epoch': 1.0875778919017638, 'step': 6038500}
INFO:transformers.trainer:{'loss': 3.099244597196579, 'learning_rate': 3.187220090752463e-05, 'epoch': 1.087667945548522, 'step': 6039000}
INFO:transformers.trainer:{'loss': 3.101287949323654, 'learning_rate': 3.1870700013411994e-05, 'epoch': 1.0877579991952806, 'step': 6039500}
INFO:transformers.trainer:{'loss': 3.060910205364227, 'learning_rate': 3.1869199119299346e-05, 'epoch': 1.0878480528420391, 'step': 6040000}
INFO:transformers.trainer:{'loss': 3.066178276181221, 'learning_rate': 3.186769822518671e-05, 'epoch': 1.0879381064887974, 'step': 6040500}
INFO:transformers.trainer:{'loss': 3.128985740184784, 'learning_rate': 3.186619733107407e-05, 'epoch': 1.088028160135556, 'step': 6041000}
INFO:transformers.trainer:{'loss': 3.063576154589653, 'learning_rate': 3.186469643696143e-05, 'epoch': 1.0881182137823144, 'step': 6041500}
INFO:transformers.trainer:{'loss': 3.1042737448215485, 'learning_rate': 3.186319554284879e-05, 'epoch': 1.088208267429073, 'step': 6042000}
INFO:transformers.trainer:{'loss': 3.1044617713689804, 'learning_rate': 3.186169464873615e-05, 'epoch': 1.0882983210758312, 'step': 6042500}
INFO:transformers.trainer:{'loss': 3.0455463461875913, 'learning_rate': 3.186019375462351e-05, 'epoch': 1.0883883747225898, 'step': 6043000}
INFO:transformers.trainer:{'loss': 3.125224036693573, 'learning_rate': 3.1858692860510866e-05, 'epoch': 1.0884784283693483, 'step': 6043500}
INFO:transformers.trainer:{'loss': 3.0524101214408876, 'learning_rate': 3.1857191966398225e-05, 'epoch': 1.0885684820161066, 'step': 6044000}
INFO:transformers.trainer:{'loss': 3.116807412147522, 'learning_rate': 3.1855691072285584e-05, 'epoch': 1.088658535662865, 'step': 6044500}
INFO:transformers.trainer:{'loss': 3.042681581258774, 'learning_rate': 3.1854190178172943e-05, 'epoch': 1.0887485893096236, 'step': 6045000}
INFO:transformers.trainer:{'loss': 3.1213506031036378, 'learning_rate': 3.18526892840603e-05, 'epoch': 1.0888386429563819, 'step': 6045500}
INFO:transformers.trainer:{'loss': 3.0964301685094835, 'learning_rate': 3.185118838994766e-05, 'epoch': 1.0889286966031404, 'step': 6046000}
INFO:transformers.trainer:{'loss': 3.0877642319202425, 'learning_rate': 3.184968749583502e-05, 'epoch': 1.089018750249899, 'step': 6046500}
INFO:transformers.trainer:{'loss': 3.0690560591220857, 'learning_rate': 3.184818660172238e-05, 'epoch': 1.0891088038966572, 'step': 6047000}
INFO:transformers.trainer:{'loss': 3.061571209192276, 'learning_rate': 3.184668570760974e-05, 'epoch': 1.0891988575434157, 'step': 6047500}
INFO:transformers.trainer:{'loss': 3.1031709531545637, 'learning_rate': 3.18451848134971e-05, 'epoch': 1.0892889111901742, 'step': 6048000}
INFO:transformers.trainer:{'loss': 3.1122423219680786, 'learning_rate': 3.184368391938446e-05, 'epoch': 1.0893789648369328, 'step': 6048500}
INFO:transformers.trainer:{'loss': 3.0820085245370863, 'learning_rate': 3.1842183025271816e-05, 'epoch': 1.089469018483691, 'step': 6049000}
INFO:transformers.trainer:{'loss': 3.0164987474679945, 'learning_rate': 3.1840682131159175e-05, 'epoch': 1.0895590721304496, 'step': 6049500}
INFO:transformers.trainer:{'loss': 3.114240041732788, 'learning_rate': 3.1839181237046534e-05, 'epoch': 1.089649125777208, 'step': 6050000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6050000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6050000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6050000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-5950000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0531208760738373, 'learning_rate': 3.183768034293389e-05, 'epoch': 1.0897391794239664, 'step': 6050500}
INFO:transformers.trainer:{'loss': 2.9977823815345763, 'learning_rate': 3.183617944882125e-05, 'epoch': 1.0898292330707249, 'step': 6051000}
INFO:transformers.trainer:{'loss': 3.0776324191093445, 'learning_rate': 3.183467855470861e-05, 'epoch': 1.0899192867174834, 'step': 6051500}
INFO:transformers.trainer:{'loss': 3.0578141367435454, 'learning_rate': 3.183317766059597e-05, 'epoch': 1.0900093403642417, 'step': 6052000}
INFO:transformers.trainer:{'loss': 3.05828807926178, 'learning_rate': 3.183167676648333e-05, 'epoch': 1.0900993940110002, 'step': 6052500}
INFO:transformers.trainer:{'loss': 3.129755923509598, 'learning_rate': 3.183017587237069e-05, 'epoch': 1.0901894476577587, 'step': 6053000}
INFO:transformers.trainer:{'loss': 3.0440916147232056, 'learning_rate': 3.182867497825805e-05, 'epoch': 1.0902795013045172, 'step': 6053500}
INFO:transformers.trainer:{'loss': 3.001280425786972, 'learning_rate': 3.182717408414541e-05, 'epoch': 1.0903695549512755, 'step': 6054000}
INFO:transformers.trainer:{'loss': 3.00828462600708, 'learning_rate': 3.1825673190032765e-05, 'epoch': 1.090459608598034, 'step': 6054500}
INFO:transformers.trainer:{'loss': 3.066542076230049, 'learning_rate': 3.182417229592013e-05, 'epoch': 1.0905496622447926, 'step': 6055000}
INFO:transformers.trainer:{'loss': 3.060055559396744, 'learning_rate': 3.1822671401807483e-05, 'epoch': 1.0906397158915508, 'step': 6055500}
INFO:transformers.trainer:{'loss': 3.016095231294632, 'learning_rate': 3.182117050769485e-05, 'epoch': 1.0907297695383094, 'step': 6056000}
INFO:transformers.trainer:{'loss': 3.0894895527362825, 'learning_rate': 3.18196696135822e-05, 'epoch': 1.0908198231850679, 'step': 6056500}
INFO:transformers.trainer:{'loss': 3.0822790603637698, 'learning_rate': 3.181816871946957e-05, 'epoch': 1.0909098768318262, 'step': 6057000}
INFO:transformers.trainer:{'loss': 3.1182739007472993, 'learning_rate': 3.181666782535692e-05, 'epoch': 1.0909999304785847, 'step': 6057500}
INFO:transformers.trainer:{'loss': 3.141782274723053, 'learning_rate': 3.1815166931244285e-05, 'epoch': 1.0910899841253432, 'step': 6058000}
INFO:transformers.trainer:{'loss': 3.0890584312677385, 'learning_rate': 3.181366603713164e-05, 'epoch': 1.0911800377721015, 'step': 6058500}
INFO:transformers.trainer:{'loss': 3.0689872522354125, 'learning_rate': 3.1812165143019004e-05, 'epoch': 1.09127009141886, 'step': 6059000}
INFO:transformers.trainer:{'loss': 3.0656652680635452, 'learning_rate': 3.1810664248906356e-05, 'epoch': 1.0913601450656185, 'step': 6059500}
INFO:transformers.trainer:{'loss': 3.1316410853862764, 'learning_rate': 3.180916335479372e-05, 'epoch': 1.091450198712377, 'step': 6060000}
INFO:transformers.trainer:{'loss': 3.0393251464366915, 'learning_rate': 3.1807662460681074e-05, 'epoch': 1.0915402523591353, 'step': 6060500}
INFO:transformers.trainer:{'loss': 3.0917707171440125, 'learning_rate': 3.180616156656844e-05, 'epoch': 1.0916303060058938, 'step': 6061000}
INFO:transformers.trainer:{'loss': 3.0719896268844606, 'learning_rate': 3.18046606724558e-05, 'epoch': 1.0917203596526524, 'step': 6061500}
INFO:transformers.trainer:{'loss': 3.091717206001282, 'learning_rate': 3.180315977834316e-05, 'epoch': 1.0918104132994106, 'step': 6062000}
INFO:transformers.trainer:{'loss': 3.0956337609291076, 'learning_rate': 3.180165888423052e-05, 'epoch': 1.0919004669461692, 'step': 6062500}
INFO:transformers.trainer:{'loss': 3.048460504055023, 'learning_rate': 3.1800157990117876e-05, 'epoch': 1.0919905205929277, 'step': 6063000}
INFO:transformers.trainer:{'loss': 3.077760755062103, 'learning_rate': 3.1798657096005235e-05, 'epoch': 1.092080574239686, 'step': 6063500}
INFO:transformers.trainer:{'loss': 3.027425152897835, 'learning_rate': 3.1797156201892594e-05, 'epoch': 1.0921706278864445, 'step': 6064000}
INFO:transformers.trainer:{'loss': 3.114144254922867, 'learning_rate': 3.179565530777995e-05, 'epoch': 1.092260681533203, 'step': 6064500}
INFO:transformers.trainer:{'loss': 3.074289248943329, 'learning_rate': 3.179415441366731e-05, 'epoch': 1.0923507351799615, 'step': 6065000}
INFO:transformers.trainer:{'loss': 3.083164542913437, 'learning_rate': 3.179265351955467e-05, 'epoch': 1.0924407888267198, 'step': 6065500}
INFO:transformers.trainer:{'loss': 3.0515278263092043, 'learning_rate': 3.179115262544203e-05, 'epoch': 1.0925308424734783, 'step': 6066000}
INFO:transformers.trainer:{'loss': 3.0134334528446196, 'learning_rate': 3.178965173132939e-05, 'epoch': 1.0926208961202368, 'step': 6066500}
INFO:transformers.trainer:{'loss': 3.080104169845581, 'learning_rate': 3.178815083721675e-05, 'epoch': 1.0927109497669951, 'step': 6067000}
INFO:transformers.trainer:{'loss': 3.084406678199768, 'learning_rate': 3.178664994310411e-05, 'epoch': 1.0928010034137536, 'step': 6067500}
INFO:transformers.trainer:{'loss': 3.0838045687675475, 'learning_rate': 3.1785149048991466e-05, 'epoch': 1.0928910570605121, 'step': 6068000}
INFO:transformers.trainer:{'loss': 3.063985892534256, 'learning_rate': 3.1783648154878826e-05, 'epoch': 1.0929811107072704, 'step': 6068500}
INFO:transformers.trainer:{'loss': 3.1046070004701614, 'learning_rate': 3.1782147260766185e-05, 'epoch': 1.093071164354029, 'step': 6069000}
INFO:transformers.trainer:{'loss': 3.052202097773552, 'learning_rate': 3.1780646366653544e-05, 'epoch': 1.0931612180007875, 'step': 6069500}
INFO:transformers.trainer:{'loss': 3.068768672466278, 'learning_rate': 3.17791454725409e-05, 'epoch': 1.0932512716475458, 'step': 6070000}
INFO:transformers.trainer:{'loss': 3.0527097182273866, 'learning_rate': 3.177764457842826e-05, 'epoch': 1.0933413252943043, 'step': 6070500}
INFO:transformers.trainer:{'loss': 3.1020924768447875, 'learning_rate': 3.177614368431562e-05, 'epoch': 1.0934313789410628, 'step': 6071000}
INFO:transformers.trainer:{'loss': 3.0566237778663634, 'learning_rate': 3.177464279020298e-05, 'epoch': 1.0935214325878213, 'step': 6071500}
INFO:transformers.trainer:{'loss': 3.085483207821846, 'learning_rate': 3.177314189609034e-05, 'epoch': 1.0936114862345796, 'step': 6072000}
INFO:transformers.trainer:{'loss': 3.0602876337766647, 'learning_rate': 3.17716410019777e-05, 'epoch': 1.0937015398813381, 'step': 6072500}
INFO:transformers.trainer:{'loss': 3.0800237126350405, 'learning_rate': 3.177014010786506e-05, 'epoch': 1.0937915935280966, 'step': 6073000}
INFO:transformers.trainer:{'loss': 3.0728153315782545, 'learning_rate': 3.1768639213752416e-05, 'epoch': 1.093881647174855, 'step': 6073500}
INFO:transformers.trainer:{'loss': 3.029764484882355, 'learning_rate': 3.1767138319639775e-05, 'epoch': 1.0939717008216134, 'step': 6074000}
INFO:transformers.trainer:{'loss': 3.1017654638290404, 'learning_rate': 3.1765637425527134e-05, 'epoch': 1.094061754468372, 'step': 6074500}
INFO:transformers.trainer:{'loss': 3.0281456772089004, 'learning_rate': 3.176413653141449e-05, 'epoch': 1.0941518081151302, 'step': 6075000}
INFO:transformers.trainer:{'loss': 3.0578778834342955, 'learning_rate': 3.176263563730186e-05, 'epoch': 1.0942418617618888, 'step': 6075500}
INFO:transformers.trainer:{'loss': 3.066615744113922, 'learning_rate': 3.176113474318921e-05, 'epoch': 1.0943319154086473, 'step': 6076000}
INFO:transformers.trainer:{'loss': 3.063725887775421, 'learning_rate': 3.175963384907658e-05, 'epoch': 1.0944219690554058, 'step': 6076500}
INFO:transformers.trainer:{'loss': 3.075337631225586, 'learning_rate': 3.175813295496393e-05, 'epoch': 1.094512022702164, 'step': 6077000}
INFO:transformers.trainer:{'loss': 3.1238034690618517, 'learning_rate': 3.1756632060851295e-05, 'epoch': 1.0946020763489226, 'step': 6077500}
INFO:transformers.trainer:{'loss': 3.0102212569713593, 'learning_rate': 3.175513116673865e-05, 'epoch': 1.094692129995681, 'step': 6078000}
INFO:transformers.trainer:{'loss': 3.062556239724159, 'learning_rate': 3.175363027262601e-05, 'epoch': 1.0947821836424394, 'step': 6078500}
INFO:transformers.trainer:{'loss': 3.100655827522278, 'learning_rate': 3.1752129378513366e-05, 'epoch': 1.094872237289198, 'step': 6079000}
INFO:transformers.trainer:{'loss': 3.0071089022159576, 'learning_rate': 3.175062848440073e-05, 'epoch': 1.0949622909359564, 'step': 6079500}
INFO:transformers.trainer:{'loss': 3.040869473695755, 'learning_rate': 3.1749127590288084e-05, 'epoch': 1.0950523445827147, 'step': 6080000}
INFO:transformers.trainer:{'loss': 3.0619920048713682, 'learning_rate': 3.174762669617545e-05, 'epoch': 1.0951423982294732, 'step': 6080500}
INFO:transformers.trainer:{'loss': 3.072411946773529, 'learning_rate': 3.17461258020628e-05, 'epoch': 1.0952324518762317, 'step': 6081000}
INFO:transformers.trainer:{'loss': 3.1431842947006228, 'learning_rate': 3.174462490795017e-05, 'epoch': 1.09532250552299, 'step': 6081500}
INFO:transformers.trainer:{'loss': 3.1208614954948426, 'learning_rate': 3.174312401383753e-05, 'epoch': 1.0954125591697486, 'step': 6082000}
INFO:transformers.trainer:{'loss': 3.0877109236717226, 'learning_rate': 3.1741623119724886e-05, 'epoch': 1.095502612816507, 'step': 6082500}
INFO:transformers.trainer:{'loss': 3.073829893112183, 'learning_rate': 3.1740122225612245e-05, 'epoch': 1.0955926664632656, 'step': 6083000}
INFO:transformers.trainer:{'loss': 3.051436825990677, 'learning_rate': 3.1738621331499604e-05, 'epoch': 1.0956827201100239, 'step': 6083500}
INFO:transformers.trainer:{'loss': 3.0830475001335143, 'learning_rate': 3.173712043738696e-05, 'epoch': 1.0957727737567824, 'step': 6084000}
INFO:transformers.trainer:{'loss': 3.0632409439086916, 'learning_rate': 3.173561954327432e-05, 'epoch': 1.095862827403541, 'step': 6084500}
INFO:transformers.trainer:{'loss': 3.0570119642019273, 'learning_rate': 3.173411864916168e-05, 'epoch': 1.0959528810502992, 'step': 6085000}
INFO:transformers.trainer:{'loss': 3.0532463617324828, 'learning_rate': 3.173261775504904e-05, 'epoch': 1.0960429346970577, 'step': 6085500}
INFO:transformers.trainer:{'loss': 3.1231798516511917, 'learning_rate': 3.17311168609364e-05, 'epoch': 1.0961329883438162, 'step': 6086000}
INFO:transformers.trainer:{'loss': 3.0776291146278383, 'learning_rate': 3.172961596682376e-05, 'epoch': 1.0962230419905747, 'step': 6086500}
INFO:transformers.trainer:{'loss': 2.9831125254631043, 'learning_rate': 3.172811507271112e-05, 'epoch': 1.096313095637333, 'step': 6087000}
INFO:transformers.trainer:{'loss': 3.077292709827423, 'learning_rate': 3.1726614178598476e-05, 'epoch': 1.0964031492840915, 'step': 6087500}
INFO:transformers.trainer:{'loss': 3.055248307108879, 'learning_rate': 3.1725113284485835e-05, 'epoch': 1.09649320293085, 'step': 6088000}
INFO:transformers.trainer:{'loss': 3.1420929753780364, 'learning_rate': 3.1723612390373194e-05, 'epoch': 1.0965832565776084, 'step': 6088500}
INFO:transformers.trainer:{'loss': 3.0606910054683687, 'learning_rate': 3.172211149626055e-05, 'epoch': 1.0966733102243669, 'step': 6089000}
INFO:transformers.trainer:{'loss': 3.096166491985321, 'learning_rate': 3.172061060214791e-05, 'epoch': 1.0967633638711254, 'step': 6089500}
INFO:transformers.trainer:{'loss': 3.0391251225471496, 'learning_rate': 3.171910970803527e-05, 'epoch': 1.0968534175178837, 'step': 6090000}
INFO:transformers.trainer:{'loss': 3.067968112707138, 'learning_rate': 3.171760881392263e-05, 'epoch': 1.0969434711646422, 'step': 6090500}
INFO:transformers.trainer:{'loss': 3.144799502134323, 'learning_rate': 3.171610791980999e-05, 'epoch': 1.0970335248114007, 'step': 6091000}
INFO:transformers.trainer:{'loss': 3.0286000378131868, 'learning_rate': 3.171460702569735e-05, 'epoch': 1.097123578458159, 'step': 6091500}
INFO:transformers.trainer:{'loss': 3.0687100248336794, 'learning_rate': 3.171310613158471e-05, 'epoch': 1.0972136321049175, 'step': 6092000}
INFO:transformers.trainer:{'loss': 3.1361276572942733, 'learning_rate': 3.171160523747207e-05, 'epoch': 1.097303685751676, 'step': 6092500}
INFO:transformers.trainer:{'loss': 3.0663565179109575, 'learning_rate': 3.1710104343359426e-05, 'epoch': 1.0973937393984343, 'step': 6093000}
INFO:transformers.trainer:{'loss': 3.0739816287755968, 'learning_rate': 3.1708603449246785e-05, 'epoch': 1.0974837930451928, 'step': 6093500}
INFO:transformers.trainer:{'loss': 3.0615930802822113, 'learning_rate': 3.1707102555134144e-05, 'epoch': 1.0975738466919513, 'step': 6094000}
INFO:transformers.trainer:{'loss': 3.065575081348419, 'learning_rate': 3.17056016610215e-05, 'epoch': 1.0976639003387099, 'step': 6094500}
INFO:transformers.trainer:{'loss': 3.0400244009494783, 'learning_rate': 3.170410076690886e-05, 'epoch': 1.0977539539854682, 'step': 6095000}
INFO:transformers.trainer:{'loss': 3.115831362247467, 'learning_rate': 3.170259987279622e-05, 'epoch': 1.0978440076322267, 'step': 6095500}
INFO:transformers.trainer:{'loss': 3.01069092464447, 'learning_rate': 3.170109897868359e-05, 'epoch': 1.0979340612789852, 'step': 6096000}
INFO:transformers.trainer:{'loss': 3.0808906359672545, 'learning_rate': 3.169959808457094e-05, 'epoch': 1.0980241149257435, 'step': 6096500}
INFO:transformers.trainer:{'loss': 3.0325923875570298, 'learning_rate': 3.1698097190458305e-05, 'epoch': 1.098114168572502, 'step': 6097000}
INFO:transformers.trainer:{'loss': 3.051908543109894, 'learning_rate': 3.169659629634566e-05, 'epoch': 1.0982042222192605, 'step': 6097500}
INFO:transformers.trainer:{'loss': 3.0336250507831575, 'learning_rate': 3.169509540223302e-05, 'epoch': 1.098294275866019, 'step': 6098000}
INFO:transformers.trainer:{'loss': 3.097294775724411, 'learning_rate': 3.1693594508120375e-05, 'epoch': 1.0983843295127773, 'step': 6098500}
INFO:transformers.trainer:{'loss': 3.0862319754362106, 'learning_rate': 3.169209361400774e-05, 'epoch': 1.0984743831595358, 'step': 6099000}
INFO:transformers.trainer:{'loss': 3.0749425966739654, 'learning_rate': 3.1690592719895093e-05, 'epoch': 1.0985644368062943, 'step': 6099500}
INFO:transformers.trainer:{'loss': 3.1117603816986086, 'learning_rate': 3.168909182578246e-05, 'epoch': 1.0986544904530526, 'step': 6100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6100000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6000000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1360060801506044, 'learning_rate': 3.168759093166981e-05, 'epoch': 1.0987445440998111, 'step': 6100500}
INFO:transformers.trainer:{'loss': 2.951542807340622, 'learning_rate': 3.168609003755718e-05, 'epoch': 1.0988345977465697, 'step': 6101000}
INFO:transformers.trainer:{'loss': 3.0978395330905912, 'learning_rate': 3.168458914344453e-05, 'epoch': 1.098924651393328, 'step': 6101500}
INFO:transformers.trainer:{'loss': 3.1429251697063445, 'learning_rate': 3.1683088249331895e-05, 'epoch': 1.0990147050400865, 'step': 6102000}
INFO:transformers.trainer:{'loss': 3.034153144836426, 'learning_rate': 3.1681587355219254e-05, 'epoch': 1.099104758686845, 'step': 6102500}
INFO:transformers.trainer:{'loss': 3.094278975725174, 'learning_rate': 3.1680086461106614e-05, 'epoch': 1.0991948123336033, 'step': 6103000}
INFO:transformers.trainer:{'loss': 3.1094134588241578, 'learning_rate': 3.167858556699397e-05, 'epoch': 1.0992848659803618, 'step': 6103500}
INFO:transformers.trainer:{'loss': 3.0593860561847688, 'learning_rate': 3.167708467288133e-05, 'epoch': 1.0993749196271203, 'step': 6104000}
INFO:transformers.trainer:{'loss': 3.07632778608799, 'learning_rate': 3.167558377876869e-05, 'epoch': 1.0994649732738786, 'step': 6104500}
INFO:transformers.trainer:{'loss': 3.1014960634708406, 'learning_rate': 3.167408288465605e-05, 'epoch': 1.0995550269206371, 'step': 6105000}
INFO:transformers.trainer:{'loss': 3.0456601066589357, 'learning_rate': 3.167258199054341e-05, 'epoch': 1.0996450805673956, 'step': 6105500}
INFO:transformers.trainer:{'loss': 3.1076892706155776, 'learning_rate': 3.167108109643077e-05, 'epoch': 1.0997351342141541, 'step': 6106000}
INFO:transformers.trainer:{'loss': 3.077600462913513, 'learning_rate': 3.166958020231813e-05, 'epoch': 1.0998251878609124, 'step': 6106500}
INFO:transformers.trainer:{'loss': 3.0332674003839495, 'learning_rate': 3.1668079308205486e-05, 'epoch': 1.099915241507671, 'step': 6107000}
INFO:transformers.trainer:{'loss': 3.0759920916557313, 'learning_rate': 3.1666578414092845e-05, 'epoch': 1.1000052951544295, 'step': 6107500}
INFO:transformers.trainer:{'loss': 3.0038830008506774, 'learning_rate': 3.1665077519980204e-05, 'epoch': 1.1000953488011878, 'step': 6108000}
INFO:transformers.trainer:{'loss': 3.114168306589127, 'learning_rate': 3.166357662586756e-05, 'epoch': 1.1001854024479463, 'step': 6108500}
INFO:transformers.trainer:{'loss': 3.047655009031296, 'learning_rate': 3.166207573175492e-05, 'epoch': 1.1002754560947048, 'step': 6109000}
INFO:transformers.trainer:{'loss': 3.1465326499938966, 'learning_rate': 3.166057483764228e-05, 'epoch': 1.1003655097414633, 'step': 6109500}
INFO:transformers.trainer:{'loss': 3.043449496269226, 'learning_rate': 3.165907394352964e-05, 'epoch': 1.1004555633882216, 'step': 6110000}
INFO:transformers.trainer:{'loss': 2.9785131100416185, 'learning_rate': 3.1657573049417e-05, 'epoch': 1.10054561703498, 'step': 6110500}
INFO:transformers.trainer:{'loss': 3.0028163472414016, 'learning_rate': 3.165607215530436e-05, 'epoch': 1.1006356706817386, 'step': 6111000}
INFO:transformers.trainer:{'loss': 3.132117911577225, 'learning_rate': 3.165457126119172e-05, 'epoch': 1.100725724328497, 'step': 6111500}
INFO:transformers.trainer:{'loss': 3.011777351498604, 'learning_rate': 3.1653070367079076e-05, 'epoch': 1.1008157779752554, 'step': 6112000}
INFO:transformers.trainer:{'loss': 3.1005096228122713, 'learning_rate': 3.1651569472966435e-05, 'epoch': 1.100905831622014, 'step': 6112500}
INFO:transformers.trainer:{'loss': 3.067198452949524, 'learning_rate': 3.1650068578853795e-05, 'epoch': 1.1009958852687722, 'step': 6113000}
INFO:transformers.trainer:{'loss': 3.0798682539463043, 'learning_rate': 3.1648567684741154e-05, 'epoch': 1.1010859389155307, 'step': 6113500}
INFO:transformers.trainer:{'loss': 3.0170895776748656, 'learning_rate': 3.164706679062851e-05, 'epoch': 1.1011759925622893, 'step': 6114000}
INFO:transformers.trainer:{'loss': 3.034436672925949, 'learning_rate': 3.164556589651587e-05, 'epoch': 1.1012660462090476, 'step': 6114500}
INFO:transformers.trainer:{'loss': 3.0838570046424865, 'learning_rate': 3.164406500240323e-05, 'epoch': 1.101356099855806, 'step': 6115000}
INFO:transformers.trainer:{'loss': 3.0497090435028076, 'learning_rate': 3.164256410829059e-05, 'epoch': 1.1014461535025646, 'step': 6115500}
INFO:transformers.trainer:{'loss': 3.1065589952468873, 'learning_rate': 3.164106321417795e-05, 'epoch': 1.1015362071493229, 'step': 6116000}
INFO:transformers.trainer:{'loss': 3.1091242256164553, 'learning_rate': 3.1639562320065315e-05, 'epoch': 1.1016262607960814, 'step': 6116500}
INFO:transformers.trainer:{'loss': 3.059302235484123, 'learning_rate': 3.163806142595267e-05, 'epoch': 1.10171631444284, 'step': 6117000}
INFO:transformers.trainer:{'loss': 3.0466355924606323, 'learning_rate': 3.163656053184003e-05, 'epoch': 1.1018063680895984, 'step': 6117500}
INFO:transformers.trainer:{'loss': 3.0838896185159683, 'learning_rate': 3.1635059637727385e-05, 'epoch': 1.1018964217363567, 'step': 6118000}
INFO:transformers.trainer:{'loss': 3.1234499492645265, 'learning_rate': 3.163355874361475e-05, 'epoch': 1.1019864753831152, 'step': 6118500}
INFO:transformers.trainer:{'loss': 3.0531382312774658, 'learning_rate': 3.16320578495021e-05, 'epoch': 1.1020765290298737, 'step': 6119000}
INFO:transformers.trainer:{'loss': 3.029859468817711, 'learning_rate': 3.163055695538947e-05, 'epoch': 1.102166582676632, 'step': 6119500}
INFO:transformers.trainer:{'loss': 3.1318956328630447, 'learning_rate': 3.162905606127682e-05, 'epoch': 1.1022566363233905, 'step': 6120000}
INFO:transformers.trainer:{'loss': 3.094331715345383, 'learning_rate': 3.162755516716419e-05, 'epoch': 1.102346689970149, 'step': 6120500}
INFO:transformers.trainer:{'loss': 3.131864089012146, 'learning_rate': 3.162605427305154e-05, 'epoch': 1.1024367436169076, 'step': 6121000}
INFO:transformers.trainer:{'loss': 3.0493618426322935, 'learning_rate': 3.1624553378938905e-05, 'epoch': 1.1025267972636659, 'step': 6121500}
INFO:transformers.trainer:{'loss': 3.06410187458992, 'learning_rate': 3.162305248482626e-05, 'epoch': 1.1026168509104244, 'step': 6122000}
INFO:transformers.trainer:{'loss': 3.0650068731307982, 'learning_rate': 3.162155159071362e-05, 'epoch': 1.102706904557183, 'step': 6122500}
INFO:transformers.trainer:{'loss': 3.0946637954711913, 'learning_rate': 3.1620050696600976e-05, 'epoch': 1.1027969582039412, 'step': 6123000}
INFO:transformers.trainer:{'loss': 3.055831808567047, 'learning_rate': 3.161854980248834e-05, 'epoch': 1.1028870118506997, 'step': 6123500}
INFO:transformers.trainer:{'loss': 3.101981901884079, 'learning_rate': 3.16170489083757e-05, 'epoch': 1.1029770654974582, 'step': 6124000}
INFO:transformers.trainer:{'loss': 3.078783049583435, 'learning_rate': 3.161554801426306e-05, 'epoch': 1.1030671191442165, 'step': 6124500}
INFO:transformers.trainer:{'loss': 3.080300570726395, 'learning_rate': 3.161404712015042e-05, 'epoch': 1.103157172790975, 'step': 6125000}
INFO:transformers.trainer:{'loss': 3.140833817958832, 'learning_rate': 3.161254622603778e-05, 'epoch': 1.1032472264377335, 'step': 6125500}
INFO:transformers.trainer:{'loss': 3.0776602729558946, 'learning_rate': 3.161104533192514e-05, 'epoch': 1.1033372800844918, 'step': 6126000}
INFO:transformers.trainer:{'loss': 3.083386367559433, 'learning_rate': 3.1609544437812496e-05, 'epoch': 1.1034273337312503, 'step': 6126500}
INFO:transformers.trainer:{'loss': 3.050942669868469, 'learning_rate': 3.1608043543699855e-05, 'epoch': 1.1035173873780089, 'step': 6127000}
INFO:transformers.trainer:{'loss': 3.085545140981674, 'learning_rate': 3.1606542649587214e-05, 'epoch': 1.1036074410247674, 'step': 6127500}
INFO:transformers.trainer:{'loss': 3.017828174114227, 'learning_rate': 3.160504175547457e-05, 'epoch': 1.1036974946715257, 'step': 6128000}
INFO:transformers.trainer:{'loss': 3.0303032937049865, 'learning_rate': 3.160354086136193e-05, 'epoch': 1.1037875483182842, 'step': 6128500}
INFO:transformers.trainer:{'loss': 3.055950618982315, 'learning_rate': 3.160203996724929e-05, 'epoch': 1.1038776019650427, 'step': 6129000}
INFO:transformers.trainer:{'loss': 3.0528873558044434, 'learning_rate': 3.160053907313665e-05, 'epoch': 1.103967655611801, 'step': 6129500}
INFO:transformers.trainer:{'loss': 3.0883620052337646, 'learning_rate': 3.159903817902401e-05, 'epoch': 1.1040577092585595, 'step': 6130000}
INFO:transformers.trainer:{'loss': 3.11849335026741, 'learning_rate': 3.1597537284911375e-05, 'epoch': 1.104147762905318, 'step': 6130500}
INFO:transformers.trainer:{'loss': 3.0475433752536776, 'learning_rate': 3.159603639079873e-05, 'epoch': 1.1042378165520763, 'step': 6131000}
INFO:transformers.trainer:{'loss': 3.125355650305748, 'learning_rate': 3.159453549668609e-05, 'epoch': 1.1043278701988348, 'step': 6131500}
INFO:transformers.trainer:{'loss': 3.0884034552574158, 'learning_rate': 3.1593034602573445e-05, 'epoch': 1.1044179238455933, 'step': 6132000}
INFO:transformers.trainer:{'loss': 3.1214178717136383, 'learning_rate': 3.1591533708460804e-05, 'epoch': 1.1045079774923519, 'step': 6132500}
INFO:transformers.trainer:{'loss': 3.1705740377902987, 'learning_rate': 3.159003281434816e-05, 'epoch': 1.1045980311391101, 'step': 6133000}
INFO:transformers.trainer:{'loss': 3.134320969104767, 'learning_rate': 3.158853192023552e-05, 'epoch': 1.1046880847858687, 'step': 6133500}
INFO:transformers.trainer:{'loss': 3.045743679046631, 'learning_rate': 3.158703102612288e-05, 'epoch': 1.1047781384326272, 'step': 6134000}
INFO:transformers.trainer:{'loss': 3.088481280565262, 'learning_rate': 3.158553013201024e-05, 'epoch': 1.1048681920793855, 'step': 6134500}
INFO:transformers.trainer:{'loss': 3.0952237639427187, 'learning_rate': 3.15840292378976e-05, 'epoch': 1.104958245726144, 'step': 6135000}
INFO:transformers.trainer:{'loss': 3.052313571572304, 'learning_rate': 3.158252834378496e-05, 'epoch': 1.1050482993729025, 'step': 6135500}
INFO:transformers.trainer:{'loss': 3.03932146859169, 'learning_rate': 3.158102744967232e-05, 'epoch': 1.1051383530196608, 'step': 6136000}
INFO:transformers.trainer:{'loss': 3.087768020391464, 'learning_rate': 3.157952655555968e-05, 'epoch': 1.1052284066664193, 'step': 6136500}
INFO:transformers.trainer:{'loss': 3.034432694673538, 'learning_rate': 3.1578025661447036e-05, 'epoch': 1.1053184603131778, 'step': 6137000}
INFO:transformers.trainer:{'loss': 3.0589296333789826, 'learning_rate': 3.1576524767334395e-05, 'epoch': 1.1054085139599361, 'step': 6137500}
INFO:transformers.trainer:{'loss': 3.0871984872817992, 'learning_rate': 3.157502387322176e-05, 'epoch': 1.1054985676066946, 'step': 6138000}
INFO:transformers.trainer:{'loss': 3.0859820227622987, 'learning_rate': 3.157352297910911e-05, 'epoch': 1.1055886212534531, 'step': 6138500}
INFO:transformers.trainer:{'loss': 2.988734989404678, 'learning_rate': 3.157202208499648e-05, 'epoch': 1.1056786749002117, 'step': 6139000}
INFO:transformers.trainer:{'loss': 3.085751869916916, 'learning_rate': 3.157052119088383e-05, 'epoch': 1.10576872854697, 'step': 6139500}
INFO:transformers.trainer:{'loss': 3.0854616751670836, 'learning_rate': 3.15690202967712e-05, 'epoch': 1.1058587821937285, 'step': 6140000}
INFO:transformers.trainer:{'loss': 3.013838088989258, 'learning_rate': 3.156751940265855e-05, 'epoch': 1.105948835840487, 'step': 6140500}
INFO:transformers.trainer:{'loss': 3.0910807569026946, 'learning_rate': 3.1566018508545915e-05, 'epoch': 1.1060388894872453, 'step': 6141000}
INFO:transformers.trainer:{'loss': 3.086117763519287, 'learning_rate': 3.156451761443327e-05, 'epoch': 1.1061289431340038, 'step': 6141500}
INFO:transformers.trainer:{'loss': 3.0552239394187928, 'learning_rate': 3.156301672032063e-05, 'epoch': 1.1062189967807623, 'step': 6142000}
INFO:transformers.trainer:{'loss': 3.096061492919922, 'learning_rate': 3.1561515826207985e-05, 'epoch': 1.1063090504275206, 'step': 6142500}
INFO:transformers.trainer:{'loss': 3.0442993960380553, 'learning_rate': 3.156001493209535e-05, 'epoch': 1.106399104074279, 'step': 6143000}
INFO:transformers.trainer:{'loss': 3.0582609046697615, 'learning_rate': 3.15585140379827e-05, 'epoch': 1.1064891577210376, 'step': 6143500}
INFO:transformers.trainer:{'loss': 3.08399958896637, 'learning_rate': 3.155701314387007e-05, 'epoch': 1.1065792113677961, 'step': 6144000}
INFO:transformers.trainer:{'loss': 3.0329851891994477, 'learning_rate': 3.155551224975743e-05, 'epoch': 1.1066692650145544, 'step': 6144500}
INFO:transformers.trainer:{'loss': 3.0686176986694336, 'learning_rate': 3.155401135564479e-05, 'epoch': 1.106759318661313, 'step': 6145000}
INFO:transformers.trainer:{'loss': 3.034504185438156, 'learning_rate': 3.1552510461532146e-05, 'epoch': 1.1068493723080715, 'step': 6145500}
INFO:transformers.trainer:{'loss': 3.0540265398025515, 'learning_rate': 3.1551009567419505e-05, 'epoch': 1.1069394259548297, 'step': 6146000}
INFO:transformers.trainer:{'loss': 3.0442703000307083, 'learning_rate': 3.1549508673306864e-05, 'epoch': 1.1070294796015883, 'step': 6146500}
INFO:transformers.trainer:{'loss': 3.08953241276741, 'learning_rate': 3.1548007779194224e-05, 'epoch': 1.1071195332483468, 'step': 6147000}
INFO:transformers.trainer:{'loss': 3.109861701965332, 'learning_rate': 3.154650688508158e-05, 'epoch': 1.107209586895105, 'step': 6147500}
INFO:transformers.trainer:{'loss': 3.0707268035411834, 'learning_rate': 3.154500599096894e-05, 'epoch': 1.1072996405418636, 'step': 6148000}
INFO:transformers.trainer:{'loss': 3.0596703209877014, 'learning_rate': 3.15435050968563e-05, 'epoch': 1.107389694188622, 'step': 6148500}
INFO:transformers.trainer:{'loss': 3.1067372200489043, 'learning_rate': 3.154200420274366e-05, 'epoch': 1.1074797478353804, 'step': 6149000}
INFO:transformers.trainer:{'loss': 3.1119106501340865, 'learning_rate': 3.154050330863102e-05, 'epoch': 1.107569801482139, 'step': 6149500}
INFO:transformers.trainer:{'loss': 3.112033159732819, 'learning_rate': 3.153900241451838e-05, 'epoch': 1.1076598551288974, 'step': 6150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6050000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.087210164010525, 'learning_rate': 3.153750152040574e-05, 'epoch': 1.107749908775656, 'step': 6150500}
INFO:transformers.trainer:{'loss': 3.1079148010015487, 'learning_rate': 3.15360006262931e-05, 'epoch': 1.1078399624224142, 'step': 6151000}
INFO:transformers.trainer:{'loss': 3.0042829606533052, 'learning_rate': 3.1534499732180455e-05, 'epoch': 1.1079300160691727, 'step': 6151500}
INFO:transformers.trainer:{'loss': 2.9942652373313905, 'learning_rate': 3.153299883806782e-05, 'epoch': 1.1080200697159313, 'step': 6152000}
INFO:transformers.trainer:{'loss': 3.030457129478455, 'learning_rate': 3.153149794395517e-05, 'epoch': 1.1081101233626895, 'step': 6152500}
INFO:transformers.trainer:{'loss': 3.055095895767212, 'learning_rate': 3.152999704984254e-05, 'epoch': 1.108200177009448, 'step': 6153000}
INFO:transformers.trainer:{'loss': 3.055711378335953, 'learning_rate': 3.152849615572989e-05, 'epoch': 1.1082902306562066, 'step': 6153500}
INFO:transformers.trainer:{'loss': 3.0956287722587588, 'learning_rate': 3.152699526161726e-05, 'epoch': 1.1083802843029649, 'step': 6154000}
INFO:transformers.trainer:{'loss': 3.0309904925823212, 'learning_rate': 3.152549436750461e-05, 'epoch': 1.1084703379497234, 'step': 6154500}
INFO:transformers.trainer:{'loss': 3.113221913576126, 'learning_rate': 3.1523993473391975e-05, 'epoch': 1.108560391596482, 'step': 6155000}
INFO:transformers.trainer:{'loss': 3.072544861316681, 'learning_rate': 3.152249257927933e-05, 'epoch': 1.1086504452432404, 'step': 6155500}
INFO:transformers.trainer:{'loss': 3.0834870443344116, 'learning_rate': 3.1520991685166686e-05, 'epoch': 1.1087404988899987, 'step': 6156000}
INFO:transformers.trainer:{'loss': 3.1002826191186905, 'learning_rate': 3.1519490791054045e-05, 'epoch': 1.1088305525367572, 'step': 6156500}
INFO:transformers.trainer:{'loss': 3.0732685277462006, 'learning_rate': 3.1517989896941405e-05, 'epoch': 1.1089206061835157, 'step': 6157000}
INFO:transformers.trainer:{'loss': 3.0573509621620176, 'learning_rate': 3.1516489002828764e-05, 'epoch': 1.109010659830274, 'step': 6157500}
INFO:transformers.trainer:{'loss': 3.0403854978084563, 'learning_rate': 3.151498810871612e-05, 'epoch': 1.1091007134770325, 'step': 6158000}
INFO:transformers.trainer:{'loss': 3.1034401067495345, 'learning_rate': 3.151348721460349e-05, 'epoch': 1.109190767123791, 'step': 6158500}
INFO:transformers.trainer:{'loss': 3.08743566942215, 'learning_rate': 3.151198632049084e-05, 'epoch': 1.1092808207705493, 'step': 6159000}
INFO:transformers.trainer:{'loss': 3.044178969621658, 'learning_rate': 3.1510485426378207e-05, 'epoch': 1.1093708744173079, 'step': 6159500}
INFO:transformers.trainer:{'loss': 3.0621227011680605, 'learning_rate': 3.150898453226556e-05, 'epoch': 1.1094609280640664, 'step': 6160000}
INFO:transformers.trainer:{'loss': 3.0633660619258882, 'learning_rate': 3.1507483638152925e-05, 'epoch': 1.1095509817108247, 'step': 6160500}
INFO:transformers.trainer:{'loss': 3.0567773299217222, 'learning_rate': 3.150598274404028e-05, 'epoch': 1.1096410353575832, 'step': 6161000}
INFO:transformers.trainer:{'loss': 3.0734719638824464, 'learning_rate': 3.150448184992764e-05, 'epoch': 1.1097310890043417, 'step': 6161500}
INFO:transformers.trainer:{'loss': 3.0881003715991975, 'learning_rate': 3.1502980955814995e-05, 'epoch': 1.1098211426511002, 'step': 6162000}
INFO:transformers.trainer:{'loss': 3.0937084906101227, 'learning_rate': 3.150148006170236e-05, 'epoch': 1.1099111962978585, 'step': 6162500}
INFO:transformers.trainer:{'loss': 3.1086709368228913, 'learning_rate': 3.149997916758971e-05, 'epoch': 1.110001249944617, 'step': 6163000}
INFO:transformers.trainer:{'loss': 3.061978601336479, 'learning_rate': 3.149847827347708e-05, 'epoch': 1.1100913035913755, 'step': 6163500}
INFO:transformers.trainer:{'loss': 3.106503823161125, 'learning_rate': 3.149697737936443e-05, 'epoch': 1.1101813572381338, 'step': 6164000}
INFO:transformers.trainer:{'loss': 3.0669126160144806, 'learning_rate': 3.14954764852518e-05, 'epoch': 1.1102714108848923, 'step': 6164500}
INFO:transformers.trainer:{'loss': 3.106186866760254, 'learning_rate': 3.1493975591139156e-05, 'epoch': 1.1103614645316509, 'step': 6165000}
INFO:transformers.trainer:{'loss': 3.041969663977623, 'learning_rate': 3.1492474697026515e-05, 'epoch': 1.1104515181784091, 'step': 6165500}
INFO:transformers.trainer:{'loss': 3.1173096878528597, 'learning_rate': 3.1490973802913874e-05, 'epoch': 1.1105415718251677, 'step': 6166000}
INFO:transformers.trainer:{'loss': 3.096771360874176, 'learning_rate': 3.148947290880123e-05, 'epoch': 1.1106316254719262, 'step': 6166500}
INFO:transformers.trainer:{'loss': 3.1460930876731874, 'learning_rate': 3.148797201468859e-05, 'epoch': 1.1107216791186847, 'step': 6167000}
INFO:transformers.trainer:{'loss': 2.9850405151844024, 'learning_rate': 3.148647112057595e-05, 'epoch': 1.110811732765443, 'step': 6167500}
INFO:transformers.trainer:{'loss': 3.1434868805408476, 'learning_rate': 3.148497022646331e-05, 'epoch': 1.1109017864122015, 'step': 6168000}
INFO:transformers.trainer:{'loss': 3.073618016242981, 'learning_rate': 3.148346933235067e-05, 'epoch': 1.11099184005896, 'step': 6168500}
INFO:transformers.trainer:{'loss': 3.0496126902103424, 'learning_rate': 3.148196843823803e-05, 'epoch': 1.1110818937057183, 'step': 6169000}
INFO:transformers.trainer:{'loss': 3.101112027049065, 'learning_rate': 3.148046754412539e-05, 'epoch': 1.1111719473524768, 'step': 6169500}
INFO:transformers.trainer:{'loss': 3.1235753571987153, 'learning_rate': 3.1478966650012747e-05, 'epoch': 1.1112620009992353, 'step': 6170000}
INFO:transformers.trainer:{'loss': 2.990984779596329, 'learning_rate': 3.1477465755900106e-05, 'epoch': 1.1113520546459936, 'step': 6170500}
INFO:transformers.trainer:{'loss': 3.028699927687645, 'learning_rate': 3.1475964861787465e-05, 'epoch': 1.1114421082927521, 'step': 6171000}
INFO:transformers.trainer:{'loss': 3.1003602499961853, 'learning_rate': 3.1474463967674824e-05, 'epoch': 1.1115321619395107, 'step': 6171500}
INFO:transformers.trainer:{'loss': 3.1178363761901857, 'learning_rate': 3.147296307356218e-05, 'epoch': 1.111622215586269, 'step': 6172000}
INFO:transformers.trainer:{'loss': 3.0903436279296876, 'learning_rate': 3.147146217944955e-05, 'epoch': 1.1117122692330275, 'step': 6172500}
INFO:transformers.trainer:{'loss': 3.029947446465492, 'learning_rate': 3.14699612853369e-05, 'epoch': 1.111802322879786, 'step': 6173000}
INFO:transformers.trainer:{'loss': 3.057565475702286, 'learning_rate': 3.146846039122427e-05, 'epoch': 1.1118923765265445, 'step': 6173500}
INFO:transformers.trainer:{'loss': 3.077852062702179, 'learning_rate': 3.146695949711162e-05, 'epoch': 1.1119824301733028, 'step': 6174000}
INFO:transformers.trainer:{'loss': 3.1017608889341353, 'learning_rate': 3.1465458602998985e-05, 'epoch': 1.1120724838200613, 'step': 6174500}
INFO:transformers.trainer:{'loss': 3.067948235273361, 'learning_rate': 3.146395770888634e-05, 'epoch': 1.1121625374668198, 'step': 6175000}
INFO:transformers.trainer:{'loss': 3.0440991339683534, 'learning_rate': 3.14624568147737e-05, 'epoch': 1.112252591113578, 'step': 6175500}
INFO:transformers.trainer:{'loss': 3.1219700713157654, 'learning_rate': 3.1460955920661055e-05, 'epoch': 1.1123426447603366, 'step': 6176000}
INFO:transformers.trainer:{'loss': 3.0279767508506774, 'learning_rate': 3.145945502654842e-05, 'epoch': 1.1124326984070951, 'step': 6176500}
INFO:transformers.trainer:{'loss': 3.0658957823514936, 'learning_rate': 3.145795413243577e-05, 'epoch': 1.1125227520538534, 'step': 6177000}
INFO:transformers.trainer:{'loss': 3.041607183456421, 'learning_rate': 3.145645323832314e-05, 'epoch': 1.112612805700612, 'step': 6177500}
INFO:transformers.trainer:{'loss': 3.073164298295975, 'learning_rate': 3.145495234421049e-05, 'epoch': 1.1127028593473705, 'step': 6178000}
INFO:transformers.trainer:{'loss': 3.045218295097351, 'learning_rate': 3.145345145009786e-05, 'epoch': 1.112792912994129, 'step': 6178500}
INFO:transformers.trainer:{'loss': 3.1015876221656797, 'learning_rate': 3.1451950555985216e-05, 'epoch': 1.1128829666408873, 'step': 6179000}
INFO:transformers.trainer:{'loss': 3.035103808403015, 'learning_rate': 3.145044966187257e-05, 'epoch': 1.1129730202876458, 'step': 6179500}
INFO:transformers.trainer:{'loss': 2.986665709018707, 'learning_rate': 3.1448948767759934e-05, 'epoch': 1.1130630739344043, 'step': 6180000}
INFO:transformers.trainer:{'loss': 3.0952449991703035, 'learning_rate': 3.144744787364729e-05, 'epoch': 1.1131531275811626, 'step': 6180500}
INFO:transformers.trainer:{'loss': 3.0536808964014055, 'learning_rate': 3.144594697953465e-05, 'epoch': 1.113243181227921, 'step': 6181000}
INFO:transformers.trainer:{'loss': 3.0403163236379624, 'learning_rate': 3.1444446085422005e-05, 'epoch': 1.1133332348746796, 'step': 6181500}
INFO:transformers.trainer:{'loss': 3.082013083934784, 'learning_rate': 3.144294519130937e-05, 'epoch': 1.113423288521438, 'step': 6182000}
INFO:transformers.trainer:{'loss': 2.995632305145264, 'learning_rate': 3.144144429719672e-05, 'epoch': 1.1135133421681964, 'step': 6182500}
INFO:transformers.trainer:{'loss': 3.031342463731766, 'learning_rate': 3.143994340308409e-05, 'epoch': 1.113603395814955, 'step': 6183000}
INFO:transformers.trainer:{'loss': 3.0742058985233305, 'learning_rate': 3.143844250897144e-05, 'epoch': 1.1136934494617132, 'step': 6183500}
INFO:transformers.trainer:{'loss': 3.1141128199100496, 'learning_rate': 3.143694161485881e-05, 'epoch': 1.1137835031084717, 'step': 6184000}
INFO:transformers.trainer:{'loss': 3.0261610679626463, 'learning_rate': 3.143544072074616e-05, 'epoch': 1.1138735567552303, 'step': 6184500}
INFO:transformers.trainer:{'loss': 3.0672496210336684, 'learning_rate': 3.1433939826633525e-05, 'epoch': 1.1139636104019888, 'step': 6185000}
INFO:transformers.trainer:{'loss': 3.097999405384064, 'learning_rate': 3.143243893252088e-05, 'epoch': 1.114053664048747, 'step': 6185500}
INFO:transformers.trainer:{'loss': 3.074885701417923, 'learning_rate': 3.143093803840824e-05, 'epoch': 1.1141437176955056, 'step': 6186000}
INFO:transformers.trainer:{'loss': 3.071804785847664, 'learning_rate': 3.14294371442956e-05, 'epoch': 1.114233771342264, 'step': 6186500}
INFO:transformers.trainer:{'loss': 3.0871243433952333, 'learning_rate': 3.142793625018296e-05, 'epoch': 1.1143238249890224, 'step': 6187000}
INFO:transformers.trainer:{'loss': 3.0955549669265747, 'learning_rate': 3.142643535607032e-05, 'epoch': 1.114413878635781, 'step': 6187500}
INFO:transformers.trainer:{'loss': 3.0059825212955475, 'learning_rate': 3.142493446195768e-05, 'epoch': 1.1145039322825394, 'step': 6188000}
INFO:transformers.trainer:{'loss': 3.0377847740650177, 'learning_rate': 3.142343356784504e-05, 'epoch': 1.1145939859292977, 'step': 6188500}
INFO:transformers.trainer:{'loss': 3.076862887620926, 'learning_rate': 3.14219326737324e-05, 'epoch': 1.1146840395760562, 'step': 6189000}
INFO:transformers.trainer:{'loss': 3.03500426363945, 'learning_rate': 3.1420431779619756e-05, 'epoch': 1.1147740932228147, 'step': 6189500}
INFO:transformers.trainer:{'loss': 3.0697960809469222, 'learning_rate': 3.1418930885507115e-05, 'epoch': 1.1148641468695732, 'step': 6190000}
INFO:transformers.trainer:{'loss': 3.0607192100286484, 'learning_rate': 3.1417429991394474e-05, 'epoch': 1.1149542005163315, 'step': 6190500}
INFO:transformers.trainer:{'loss': 3.1692003325223923, 'learning_rate': 3.1415929097281833e-05, 'epoch': 1.11504425416309, 'step': 6191000}
INFO:transformers.trainer:{'loss': 3.0548671082258223, 'learning_rate': 3.141442820316919e-05, 'epoch': 1.1151343078098486, 'step': 6191500}
INFO:transformers.trainer:{'loss': 3.082296064734459, 'learning_rate': 3.141292730905655e-05, 'epoch': 1.1152243614566069, 'step': 6192000}
INFO:transformers.trainer:{'loss': 3.02508848798275, 'learning_rate': 3.141142641494391e-05, 'epoch': 1.1153144151033654, 'step': 6192500}
INFO:transformers.trainer:{'loss': 3.100892691850662, 'learning_rate': 3.1409925520831276e-05, 'epoch': 1.115404468750124, 'step': 6193000}
INFO:transformers.trainer:{'loss': 3.114008570432663, 'learning_rate': 3.140842462671863e-05, 'epoch': 1.1154945223968822, 'step': 6193500}
INFO:transformers.trainer:{'loss': 3.0823313105106354, 'learning_rate': 3.1406923732605995e-05, 'epoch': 1.1155845760436407, 'step': 6194000}
INFO:transformers.trainer:{'loss': 3.0320795023441316, 'learning_rate': 3.140542283849335e-05, 'epoch': 1.1156746296903992, 'step': 6194500}
INFO:transformers.trainer:{'loss': 3.0971482615470887, 'learning_rate': 3.140392194438071e-05, 'epoch': 1.1157646833371575, 'step': 6195000}
INFO:transformers.trainer:{'loss': 3.1029593262672424, 'learning_rate': 3.1402421050268065e-05, 'epoch': 1.115854736983916, 'step': 6195500}
INFO:transformers.trainer:{'loss': 3.0711641149520874, 'learning_rate': 3.140092015615543e-05, 'epoch': 1.1159447906306745, 'step': 6196000}
INFO:transformers.trainer:{'loss': 3.077215136528015, 'learning_rate': 3.139941926204278e-05, 'epoch': 1.116034844277433, 'step': 6196500}
INFO:transformers.trainer:{'loss': 3.0762777478694914, 'learning_rate': 3.139791836793015e-05, 'epoch': 1.1161248979241913, 'step': 6197000}
INFO:transformers.trainer:{'loss': 3.057900381565094, 'learning_rate': 3.13964174738175e-05, 'epoch': 1.1162149515709499, 'step': 6197500}
INFO:transformers.trainer:{'loss': 3.099382288813591, 'learning_rate': 3.139491657970487e-05, 'epoch': 1.1163050052177084, 'step': 6198000}
INFO:transformers.trainer:{'loss': 3.0851760931015013, 'learning_rate': 3.139341568559222e-05, 'epoch': 1.1163950588644667, 'step': 6198500}
INFO:transformers.trainer:{'loss': 3.1037967760562895, 'learning_rate': 3.1391914791479585e-05, 'epoch': 1.1164851125112252, 'step': 6199000}
INFO:transformers.trainer:{'loss': 3.008560920238495, 'learning_rate': 3.1390413897366944e-05, 'epoch': 1.1165751661579837, 'step': 6199500}
INFO:transformers.trainer:{'loss': 3.0868112230300904, 'learning_rate': 3.13889130032543e-05, 'epoch': 1.116665219804742, 'step': 6200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1030435450077056, 'learning_rate': 3.138741210914166e-05, 'epoch': 1.1167552734515005, 'step': 6200500}
INFO:transformers.trainer:{'loss': 2.997851825475693, 'learning_rate': 3.138591121502902e-05, 'epoch': 1.116845327098259, 'step': 6201000}
INFO:transformers.trainer:{'loss': 3.0485270516872407, 'learning_rate': 3.138441032091638e-05, 'epoch': 1.1169353807450175, 'step': 6201500}
INFO:transformers.trainer:{'loss': 3.0887216572761536, 'learning_rate': 3.138290942680374e-05, 'epoch': 1.1170254343917758, 'step': 6202000}
INFO:transformers.trainer:{'loss': 3.1138481198549273, 'learning_rate': 3.13814085326911e-05, 'epoch': 1.1171154880385343, 'step': 6202500}
INFO:transformers.trainer:{'loss': 3.0485823761224746, 'learning_rate': 3.137990763857846e-05, 'epoch': 1.1172055416852928, 'step': 6203000}
INFO:transformers.trainer:{'loss': 3.0560839693546296, 'learning_rate': 3.1378406744465816e-05, 'epoch': 1.1172955953320511, 'step': 6203500}
INFO:transformers.trainer:{'loss': 3.056817991018295, 'learning_rate': 3.137690585035317e-05, 'epoch': 1.1173856489788097, 'step': 6204000}
INFO:transformers.trainer:{'loss': 3.0780706914663316, 'learning_rate': 3.1375404956240535e-05, 'epoch': 1.1174757026255682, 'step': 6204500}
INFO:transformers.trainer:{'loss': 3.0993685263395307, 'learning_rate': 3.137390406212789e-05, 'epoch': 1.1175657562723265, 'step': 6205000}
INFO:transformers.trainer:{'loss': 3.0662324113845827, 'learning_rate': 3.137240316801525e-05, 'epoch': 1.117655809919085, 'step': 6205500}
INFO:transformers.trainer:{'loss': 3.098085997581482, 'learning_rate': 3.1370902273902605e-05, 'epoch': 1.1177458635658435, 'step': 6206000}
INFO:transformers.trainer:{'loss': 3.0845080163478853, 'learning_rate': 3.136940137978997e-05, 'epoch': 1.1178359172126018, 'step': 6206500}
INFO:transformers.trainer:{'loss': 3.0494429208040237, 'learning_rate': 3.136790048567733e-05, 'epoch': 1.1179259708593603, 'step': 6207000}
INFO:transformers.trainer:{'loss': 3.0392987943887713, 'learning_rate': 3.136639959156469e-05, 'epoch': 1.1180160245061188, 'step': 6207500}
INFO:transformers.trainer:{'loss': 3.075931083917618, 'learning_rate': 3.136489869745205e-05, 'epoch': 1.1181060781528773, 'step': 6208000}
INFO:transformers.trainer:{'loss': 3.074630749821663, 'learning_rate': 3.136339780333941e-05, 'epoch': 1.1181961317996356, 'step': 6208500}
INFO:transformers.trainer:{'loss': 3.0408179640769957, 'learning_rate': 3.1361896909226766e-05, 'epoch': 1.1182861854463941, 'step': 6209000}
INFO:transformers.trainer:{'loss': 3.116291391372681, 'learning_rate': 3.1360396015114125e-05, 'epoch': 1.1183762390931526, 'step': 6209500}
INFO:transformers.trainer:{'loss': 3.093108055830002, 'learning_rate': 3.1358895121001484e-05, 'epoch': 1.118466292739911, 'step': 6210000}
INFO:transformers.trainer:{'loss': 2.9989795792102814, 'learning_rate': 3.135739422688884e-05, 'epoch': 1.1185563463866695, 'step': 6210500}
INFO:transformers.trainer:{'loss': 3.0137769458293913, 'learning_rate': 3.13558933327762e-05, 'epoch': 1.118646400033428, 'step': 6211000}
INFO:transformers.trainer:{'loss': 3.029454090356827, 'learning_rate': 3.135439243866356e-05, 'epoch': 1.1187364536801863, 'step': 6211500}
INFO:transformers.trainer:{'loss': 3.04483799123764, 'learning_rate': 3.135289154455092e-05, 'epoch': 1.1188265073269448, 'step': 6212000}
INFO:transformers.trainer:{'loss': 3.018999507188797, 'learning_rate': 3.135139065043828e-05, 'epoch': 1.1189165609737033, 'step': 6212500}
INFO:transformers.trainer:{'loss': 3.0828113031387328, 'learning_rate': 3.134988975632564e-05, 'epoch': 1.1190066146204618, 'step': 6213000}
INFO:transformers.trainer:{'loss': 3.042135194301605, 'learning_rate': 3.1348388862213004e-05, 'epoch': 1.11909666826722, 'step': 6213500}
INFO:transformers.trainer:{'loss': 3.0403295460939406, 'learning_rate': 3.1346887968100357e-05, 'epoch': 1.1191867219139786, 'step': 6214000}
INFO:transformers.trainer:{'loss': 3.0154306490421297, 'learning_rate': 3.134538707398772e-05, 'epoch': 1.1192767755607371, 'step': 6214500}
INFO:transformers.trainer:{'loss': 3.04135320687294, 'learning_rate': 3.1343886179875075e-05, 'epoch': 1.1193668292074954, 'step': 6215000}
INFO:transformers.trainer:{'loss': 3.069870983123779, 'learning_rate': 3.134238528576244e-05, 'epoch': 1.119456882854254, 'step': 6215500}
INFO:transformers.trainer:{'loss': 3.064803505420685, 'learning_rate': 3.134088439164979e-05, 'epoch': 1.1195469365010124, 'step': 6216000}
INFO:transformers.trainer:{'loss': 3.0760840265750886, 'learning_rate': 3.133938349753716e-05, 'epoch': 1.1196369901477707, 'step': 6216500}
INFO:transformers.trainer:{'loss': 3.049657820701599, 'learning_rate': 3.133788260342451e-05, 'epoch': 1.1197270437945293, 'step': 6217000}
INFO:transformers.trainer:{'loss': 3.128969253063202, 'learning_rate': 3.133638170931188e-05, 'epoch': 1.1198170974412878, 'step': 6217500}
INFO:transformers.trainer:{'loss': 3.0861302897930147, 'learning_rate': 3.133488081519923e-05, 'epoch': 1.119907151088046, 'step': 6218000}
INFO:transformers.trainer:{'loss': 3.086428217768669, 'learning_rate': 3.1333379921086595e-05, 'epoch': 1.1199972047348046, 'step': 6218500}
INFO:transformers.trainer:{'loss': 2.954396634340286, 'learning_rate': 3.133187902697395e-05, 'epoch': 1.120087258381563, 'step': 6219000}
INFO:transformers.trainer:{'loss': 3.1250586898326875, 'learning_rate': 3.133037813286131e-05, 'epoch': 1.1201773120283216, 'step': 6219500}
INFO:transformers.trainer:{'loss': 3.0462432689666747, 'learning_rate': 3.1328877238748665e-05, 'epoch': 1.12026736567508, 'step': 6220000}
INFO:transformers.trainer:{'loss': 3.0941005256175993, 'learning_rate': 3.132737634463603e-05, 'epoch': 1.1203574193218384, 'step': 6220500}
INFO:transformers.trainer:{'loss': 3.095320313453674, 'learning_rate': 3.132587545052339e-05, 'epoch': 1.120447472968597, 'step': 6221000}
INFO:transformers.trainer:{'loss': 3.06512779712677, 'learning_rate': 3.132437455641075e-05, 'epoch': 1.1205375266153552, 'step': 6221500}
INFO:transformers.trainer:{'loss': 3.046489771604538, 'learning_rate': 3.132287366229811e-05, 'epoch': 1.1206275802621137, 'step': 6222000}
INFO:transformers.trainer:{'loss': 3.1140631251335145, 'learning_rate': 3.132137276818547e-05, 'epoch': 1.1207176339088722, 'step': 6222500}
INFO:transformers.trainer:{'loss': 3.1164681533575056, 'learning_rate': 3.1319871874072826e-05, 'epoch': 1.1208076875556305, 'step': 6223000}
INFO:transformers.trainer:{'loss': 3.073711899995804, 'learning_rate': 3.1318370979960185e-05, 'epoch': 1.120897741202389, 'step': 6223500}
INFO:transformers.trainer:{'loss': 3.06639097070694, 'learning_rate': 3.1316870085847544e-05, 'epoch': 1.1209877948491476, 'step': 6224000}
INFO:transformers.trainer:{'loss': 3.067509374141693, 'learning_rate': 3.13153691917349e-05, 'epoch': 1.121077848495906, 'step': 6224500}
INFO:transformers.trainer:{'loss': 3.074163551568985, 'learning_rate': 3.131386829762226e-05, 'epoch': 1.1211679021426644, 'step': 6225000}
INFO:transformers.trainer:{'loss': 3.082607746601105, 'learning_rate': 3.131236740350962e-05, 'epoch': 1.1212579557894229, 'step': 6225500}
INFO:transformers.trainer:{'loss': 3.058207921028137, 'learning_rate': 3.131086650939698e-05, 'epoch': 1.1213480094361814, 'step': 6226000}
INFO:transformers.trainer:{'loss': 3.0772301945686342, 'learning_rate': 3.130936561528434e-05, 'epoch': 1.1214380630829397, 'step': 6226500}
INFO:transformers.trainer:{'loss': 2.9912348212003708, 'learning_rate': 3.13078647211717e-05, 'epoch': 1.1215281167296982, 'step': 6227000}
INFO:transformers.trainer:{'loss': 3.1080364849567412, 'learning_rate': 3.130636382705906e-05, 'epoch': 1.1216181703764567, 'step': 6227500}
INFO:transformers.trainer:{'loss': 3.13374654173851, 'learning_rate': 3.130486293294642e-05, 'epoch': 1.121708224023215, 'step': 6228000}
INFO:transformers.trainer:{'loss': 3.0545422620773315, 'learning_rate': 3.1303362038833776e-05, 'epoch': 1.1217982776699735, 'step': 6228500}
INFO:transformers.trainer:{'loss': 3.0333042865991593, 'learning_rate': 3.1301861144721135e-05, 'epoch': 1.121888331316732, 'step': 6229000}
INFO:transformers.trainer:{'loss': 3.0140198590755465, 'learning_rate': 3.1300360250608494e-05, 'epoch': 1.1219783849634903, 'step': 6229500}
INFO:transformers.trainer:{'loss': 3.0723066341876986, 'learning_rate': 3.129885935649585e-05, 'epoch': 1.1220684386102489, 'step': 6230000}
INFO:transformers.trainer:{'loss': 3.048364947795868, 'learning_rate': 3.129735846238321e-05, 'epoch': 1.1221584922570074, 'step': 6230500}
INFO:transformers.trainer:{'loss': 2.9921688706874847, 'learning_rate': 3.129585756827057e-05, 'epoch': 1.1222485459037659, 'step': 6231000}
INFO:transformers.trainer:{'loss': 3.068854706287384, 'learning_rate': 3.129435667415793e-05, 'epoch': 1.1223385995505242, 'step': 6231500}
INFO:transformers.trainer:{'loss': 3.0945615820884704, 'learning_rate': 3.129285578004529e-05, 'epoch': 1.1224286531972827, 'step': 6232000}
INFO:transformers.trainer:{'loss': 2.999754658937454, 'learning_rate': 3.129135488593265e-05, 'epoch': 1.1225187068440412, 'step': 6232500}
INFO:transformers.trainer:{'loss': 3.125072494029999, 'learning_rate': 3.128985399182001e-05, 'epoch': 1.1226087604907995, 'step': 6233000}
INFO:transformers.trainer:{'loss': 3.0611978199481964, 'learning_rate': 3.1288353097707366e-05, 'epoch': 1.122698814137558, 'step': 6233500}
INFO:transformers.trainer:{'loss': 3.1019544469118117, 'learning_rate': 3.1286852203594725e-05, 'epoch': 1.1227888677843165, 'step': 6234000}
INFO:transformers.trainer:{'loss': 3.0238623905181883, 'learning_rate': 3.1285351309482084e-05, 'epoch': 1.1228789214310748, 'step': 6234500}
INFO:transformers.trainer:{'loss': 3.0644932153224946, 'learning_rate': 3.128385041536945e-05, 'epoch': 1.1229689750778333, 'step': 6235000}
INFO:transformers.trainer:{'loss': 3.0962679129838944, 'learning_rate': 3.12823495212568e-05, 'epoch': 1.1230590287245918, 'step': 6235500}
INFO:transformers.trainer:{'loss': 3.1427413328886034, 'learning_rate': 3.128084862714417e-05, 'epoch': 1.1231490823713504, 'step': 6236000}
INFO:transformers.trainer:{'loss': 3.0421465384960173, 'learning_rate': 3.127934773303152e-05, 'epoch': 1.1232391360181087, 'step': 6236500}
INFO:transformers.trainer:{'loss': 3.0354515662193298, 'learning_rate': 3.1277846838918886e-05, 'epoch': 1.1233291896648672, 'step': 6237000}
INFO:transformers.trainer:{'loss': 3.1052650949954987, 'learning_rate': 3.127634594480624e-05, 'epoch': 1.1234192433116257, 'step': 6237500}
INFO:transformers.trainer:{'loss': 3.095988768696785, 'learning_rate': 3.1274845050693604e-05, 'epoch': 1.123509296958384, 'step': 6238000}
INFO:transformers.trainer:{'loss': 3.0700862101316453, 'learning_rate': 3.127334415658096e-05, 'epoch': 1.1235993506051425, 'step': 6238500}
INFO:transformers.trainer:{'loss': 3.0489943251609803, 'learning_rate': 3.127184326246832e-05, 'epoch': 1.123689404251901, 'step': 6239000}
INFO:transformers.trainer:{'loss': 3.048430666923523, 'learning_rate': 3.1270342368355675e-05, 'epoch': 1.1237794578986593, 'step': 6239500}
INFO:transformers.trainer:{'loss': 3.1325332415103913, 'learning_rate': 3.126884147424304e-05, 'epoch': 1.1238695115454178, 'step': 6240000}
INFO:transformers.trainer:{'loss': 3.0640250561237337, 'learning_rate': 3.126734058013039e-05, 'epoch': 1.1239595651921763, 'step': 6240500}
INFO:transformers.trainer:{'loss': 3.0454019734859465, 'learning_rate': 3.126583968601776e-05, 'epoch': 1.1240496188389346, 'step': 6241000}
INFO:transformers.trainer:{'loss': 3.058610803127289, 'learning_rate': 3.126433879190512e-05, 'epoch': 1.1241396724856931, 'step': 6241500}
INFO:transformers.trainer:{'loss': 3.034404280424118, 'learning_rate': 3.126283789779248e-05, 'epoch': 1.1242297261324516, 'step': 6242000}
INFO:transformers.trainer:{'loss': 3.0336413106918334, 'learning_rate': 3.1261337003679836e-05, 'epoch': 1.1243197797792102, 'step': 6242500}
INFO:transformers.trainer:{'loss': 3.0650815534591676, 'learning_rate': 3.1259836109567195e-05, 'epoch': 1.1244098334259685, 'step': 6243000}
INFO:transformers.trainer:{'loss': 3.0279818605184556, 'learning_rate': 3.1258335215454554e-05, 'epoch': 1.124499887072727, 'step': 6243500}
INFO:transformers.trainer:{'loss': 3.041266350269318, 'learning_rate': 3.125683432134191e-05, 'epoch': 1.1245899407194855, 'step': 6244000}
INFO:transformers.trainer:{'loss': 3.0453782252073287, 'learning_rate': 3.125533342722927e-05, 'epoch': 1.1246799943662438, 'step': 6244500}
INFO:transformers.trainer:{'loss': 3.0622848477363585, 'learning_rate': 3.125383253311663e-05, 'epoch': 1.1247700480130023, 'step': 6245000}
INFO:transformers.trainer:{'loss': 3.1340067393779756, 'learning_rate': 3.125233163900399e-05, 'epoch': 1.1248601016597608, 'step': 6245500}
INFO:transformers.trainer:{'loss': 3.0824517951011656, 'learning_rate': 3.125083074489135e-05, 'epoch': 1.1249501553065193, 'step': 6246000}
INFO:transformers.trainer:{'loss': 3.058936295032501, 'learning_rate': 3.124932985077871e-05, 'epoch': 1.1250402089532776, 'step': 6246500}
INFO:transformers.trainer:{'loss': 3.051354900598526, 'learning_rate': 3.124782895666607e-05, 'epoch': 1.1251302626000361, 'step': 6247000}
INFO:transformers.trainer:{'loss': 3.07819935464859, 'learning_rate': 3.1246328062553426e-05, 'epoch': 1.1252203162467946, 'step': 6247500}
INFO:transformers.trainer:{'loss': 3.0433520641326903, 'learning_rate': 3.1244827168440785e-05, 'epoch': 1.125310369893553, 'step': 6248000}
INFO:transformers.trainer:{'loss': 3.042659075140953, 'learning_rate': 3.1243326274328145e-05, 'epoch': 1.1254004235403114, 'step': 6248500}
INFO:transformers.trainer:{'loss': 3.0841690607070924, 'learning_rate': 3.1241825380215504e-05, 'epoch': 1.12549047718707, 'step': 6249000}
INFO:transformers.trainer:{'loss': 3.0670926690101625, 'learning_rate': 3.124032448610286e-05, 'epoch': 1.1255805308338283, 'step': 6249500}
INFO:transformers.trainer:{'loss': 3.0384060711860656, 'learning_rate': 3.123882359199022e-05, 'epoch': 1.1256705844805868, 'step': 6250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0491612547636033, 'learning_rate': 3.123732269787758e-05, 'epoch': 1.1257606381273453, 'step': 6250500}
INFO:transformers.trainer:{'loss': 3.0969318742752074, 'learning_rate': 3.123582180376494e-05, 'epoch': 1.1258506917741036, 'step': 6251000}
INFO:transformers.trainer:{'loss': 3.028603147983551, 'learning_rate': 3.12343209096523e-05, 'epoch': 1.125940745420862, 'step': 6251500}
INFO:transformers.trainer:{'loss': 3.0475106348991394, 'learning_rate': 3.123282001553966e-05, 'epoch': 1.1260307990676206, 'step': 6252000}
INFO:transformers.trainer:{'loss': 3.0690231311321257, 'learning_rate': 3.123131912142702e-05, 'epoch': 1.126120852714379, 'step': 6252500}
INFO:transformers.trainer:{'loss': 3.055822287559509, 'learning_rate': 3.1229818227314376e-05, 'epoch': 1.1262109063611374, 'step': 6253000}
INFO:transformers.trainer:{'loss': 3.038806743502617, 'learning_rate': 3.1228317333201735e-05, 'epoch': 1.126300960007896, 'step': 6253500}
INFO:transformers.trainer:{'loss': 3.136496526479721, 'learning_rate': 3.1226816439089094e-05, 'epoch': 1.1263910136546544, 'step': 6254000}
INFO:transformers.trainer:{'loss': 3.0548846166133883, 'learning_rate': 3.122531554497645e-05, 'epoch': 1.1264810673014127, 'step': 6254500}
INFO:transformers.trainer:{'loss': 3.115373642206192, 'learning_rate': 3.122381465086381e-05, 'epoch': 1.1265711209481712, 'step': 6255000}
INFO:transformers.trainer:{'loss': 3.0904703743457795, 'learning_rate': 3.122231375675118e-05, 'epoch': 1.1266611745949298, 'step': 6255500}
INFO:transformers.trainer:{'loss': 3.055817944765091, 'learning_rate': 3.122081286263853e-05, 'epoch': 1.126751228241688, 'step': 6256000}
INFO:transformers.trainer:{'loss': 3.057463136434555, 'learning_rate': 3.1219311968525896e-05, 'epoch': 1.1268412818884466, 'step': 6256500}
INFO:transformers.trainer:{'loss': 3.0437168819904326, 'learning_rate': 3.121781107441325e-05, 'epoch': 1.126931335535205, 'step': 6257000}
INFO:transformers.trainer:{'loss': 3.052517431020737, 'learning_rate': 3.1216310180300614e-05, 'epoch': 1.1270213891819636, 'step': 6257500}
INFO:transformers.trainer:{'loss': 3.1354071118831635, 'learning_rate': 3.1214809286187966e-05, 'epoch': 1.1271114428287219, 'step': 6258000}
INFO:transformers.trainer:{'loss': 3.1176469750404356, 'learning_rate': 3.121330839207533e-05, 'epoch': 1.1272014964754804, 'step': 6258500}
INFO:transformers.trainer:{'loss': 3.037271859169006, 'learning_rate': 3.1211807497962685e-05, 'epoch': 1.127291550122239, 'step': 6259000}
INFO:transformers.trainer:{'loss': 3.0233039177656176, 'learning_rate': 3.121030660385005e-05, 'epoch': 1.1273816037689972, 'step': 6259500}
INFO:transformers.trainer:{'loss': 3.0421282660961153, 'learning_rate': 3.12088057097374e-05, 'epoch': 1.1274716574157557, 'step': 6260000}
INFO:transformers.trainer:{'loss': 3.1115514855384827, 'learning_rate': 3.120730481562477e-05, 'epoch': 1.1275617110625142, 'step': 6260500}
INFO:transformers.trainer:{'loss': 3.076351485490799, 'learning_rate': 3.120580392151212e-05, 'epoch': 1.1276517647092725, 'step': 6261000}
INFO:transformers.trainer:{'loss': 2.99332469189167, 'learning_rate': 3.120430302739949e-05, 'epoch': 1.127741818356031, 'step': 6261500}
INFO:transformers.trainer:{'loss': 3.0911162912845613, 'learning_rate': 3.1202802133286846e-05, 'epoch': 1.1278318720027896, 'step': 6262000}
INFO:transformers.trainer:{'loss': 3.0102967076301574, 'learning_rate': 3.1201301239174205e-05, 'epoch': 1.1279219256495479, 'step': 6262500}
INFO:transformers.trainer:{'loss': 3.0834530668258666, 'learning_rate': 3.1199800345061564e-05, 'epoch': 1.1280119792963064, 'step': 6263000}
INFO:transformers.trainer:{'loss': 3.0823524150848387, 'learning_rate': 3.119829945094892e-05, 'epoch': 1.1281020329430649, 'step': 6263500}
INFO:transformers.trainer:{'loss': 3.0621172403097154, 'learning_rate': 3.119679855683628e-05, 'epoch': 1.1281920865898232, 'step': 6264000}
INFO:transformers.trainer:{'loss': 3.0770052936077117, 'learning_rate': 3.119529766272364e-05, 'epoch': 1.1282821402365817, 'step': 6264500}
INFO:transformers.trainer:{'loss': 3.031023921728134, 'learning_rate': 3.1193796768611e-05, 'epoch': 1.1283721938833402, 'step': 6265000}
INFO:transformers.trainer:{'loss': 3.0633530402183533, 'learning_rate': 3.119229587449836e-05, 'epoch': 1.1284622475300987, 'step': 6265500}
INFO:transformers.trainer:{'loss': 3.0552392362356184, 'learning_rate': 3.119079498038572e-05, 'epoch': 1.128552301176857, 'step': 6266000}
INFO:transformers.trainer:{'loss': 3.11254778277874, 'learning_rate': 3.118929408627308e-05, 'epoch': 1.1286423548236155, 'step': 6266500}
INFO:transformers.trainer:{'loss': 3.1014937152862547, 'learning_rate': 3.1187793192160436e-05, 'epoch': 1.128732408470374, 'step': 6267000}
INFO:transformers.trainer:{'loss': 3.075927600622177, 'learning_rate': 3.1186292298047795e-05, 'epoch': 1.1288224621171323, 'step': 6267500}
INFO:transformers.trainer:{'loss': 3.1118861671686173, 'learning_rate': 3.1184791403935154e-05, 'epoch': 1.1289125157638908, 'step': 6268000}
INFO:transformers.trainer:{'loss': 3.0332368634939195, 'learning_rate': 3.118329050982251e-05, 'epoch': 1.1290025694106494, 'step': 6268500}
INFO:transformers.trainer:{'loss': 3.133731934785843, 'learning_rate': 3.118178961570987e-05, 'epoch': 1.1290926230574079, 'step': 6269000}
INFO:transformers.trainer:{'loss': 3.1147511723041537, 'learning_rate': 3.118028872159723e-05, 'epoch': 1.1291826767041662, 'step': 6269500}
INFO:transformers.trainer:{'loss': 3.0277714846134187, 'learning_rate': 3.117878782748459e-05, 'epoch': 1.1292727303509247, 'step': 6270000}
INFO:transformers.trainer:{'loss': 2.9858061006069185, 'learning_rate': 3.117728693337195e-05, 'epoch': 1.1293627839976832, 'step': 6270500}
INFO:transformers.trainer:{'loss': 3.067445184648037, 'learning_rate': 3.117578603925931e-05, 'epoch': 1.1294528376444415, 'step': 6271000}
INFO:transformers.trainer:{'loss': 3.069751435875893, 'learning_rate': 3.117428514514667e-05, 'epoch': 1.1295428912912, 'step': 6271500}
INFO:transformers.trainer:{'loss': 3.059120371580124, 'learning_rate': 3.117278425103403e-05, 'epoch': 1.1296329449379585, 'step': 6272000}
INFO:transformers.trainer:{'loss': 3.1168931362628935, 'learning_rate': 3.1171283356921386e-05, 'epoch': 1.1297229985847168, 'step': 6272500}
INFO:transformers.trainer:{'loss': 3.0593435118198395, 'learning_rate': 3.1169782462808745e-05, 'epoch': 1.1298130522314753, 'step': 6273000}
INFO:transformers.trainer:{'loss': 3.0228498129844668, 'learning_rate': 3.1168281568696104e-05, 'epoch': 1.1299031058782338, 'step': 6273500}
INFO:transformers.trainer:{'loss': 3.1065887149572373, 'learning_rate': 3.116678067458346e-05, 'epoch': 1.1299931595249921, 'step': 6274000}
INFO:transformers.trainer:{'loss': 3.098209084510803, 'learning_rate': 3.116527978047082e-05, 'epoch': 1.1300832131717506, 'step': 6274500}
INFO:transformers.trainer:{'loss': 3.002946489572525, 'learning_rate': 3.116377888635818e-05, 'epoch': 1.1301732668185092, 'step': 6275000}
INFO:transformers.trainer:{'loss': 3.0787650800943376, 'learning_rate': 3.116227799224554e-05, 'epoch': 1.1302633204652675, 'step': 6275500}
INFO:transformers.trainer:{'loss': 3.0956981756687165, 'learning_rate': 3.1160777098132906e-05, 'epoch': 1.130353374112026, 'step': 6276000}
INFO:transformers.trainer:{'loss': 3.07226431876421, 'learning_rate': 3.115927620402026e-05, 'epoch': 1.1304434277587845, 'step': 6276500}
INFO:transformers.trainer:{'loss': 3.0750898761749266, 'learning_rate': 3.1157775309907624e-05, 'epoch': 1.130533481405543, 'step': 6277000}
INFO:transformers.trainer:{'loss': 3.0292177722454072, 'learning_rate': 3.1156274415794976e-05, 'epoch': 1.1306235350523013, 'step': 6277500}
INFO:transformers.trainer:{'loss': 3.0732580723762513, 'learning_rate': 3.115477352168234e-05, 'epoch': 1.1307135886990598, 'step': 6278000}
INFO:transformers.trainer:{'loss': 3.0791249076128007, 'learning_rate': 3.1153272627569694e-05, 'epoch': 1.1308036423458183, 'step': 6278500}
INFO:transformers.trainer:{'loss': 3.037519690513611, 'learning_rate': 3.115177173345706e-05, 'epoch': 1.1308936959925766, 'step': 6279000}
INFO:transformers.trainer:{'loss': 3.034710035562515, 'learning_rate': 3.115027083934441e-05, 'epoch': 1.1309837496393351, 'step': 6279500}
INFO:transformers.trainer:{'loss': 3.05291100525856, 'learning_rate': 3.114876994523178e-05, 'epoch': 1.1310738032860936, 'step': 6280000}
INFO:transformers.trainer:{'loss': 3.0897658870220184, 'learning_rate': 3.114726905111913e-05, 'epoch': 1.1311638569328522, 'step': 6280500}
INFO:transformers.trainer:{'loss': 3.092380769729614, 'learning_rate': 3.1145768157006496e-05, 'epoch': 1.1312539105796104, 'step': 6281000}
INFO:transformers.trainer:{'loss': 3.0755230984687807, 'learning_rate': 3.114426726289385e-05, 'epoch': 1.131343964226369, 'step': 6281500}
INFO:transformers.trainer:{'loss': 3.053112253546715, 'learning_rate': 3.1142766368781214e-05, 'epoch': 1.1314340178731275, 'step': 6282000}
INFO:transformers.trainer:{'loss': 3.0075179468393327, 'learning_rate': 3.114126547466857e-05, 'epoch': 1.1315240715198858, 'step': 6282500}
INFO:transformers.trainer:{'loss': 3.067053128361702, 'learning_rate': 3.113976458055593e-05, 'epoch': 1.1316141251666443, 'step': 6283000}
INFO:transformers.trainer:{'loss': 3.084828038930893, 'learning_rate': 3.113826368644329e-05, 'epoch': 1.1317041788134028, 'step': 6283500}
INFO:transformers.trainer:{'loss': 3.061064311027527, 'learning_rate': 3.113676279233065e-05, 'epoch': 1.131794232460161, 'step': 6284000}
INFO:transformers.trainer:{'loss': 3.1426706628799437, 'learning_rate': 3.113526189821801e-05, 'epoch': 1.1318842861069196, 'step': 6284500}
INFO:transformers.trainer:{'loss': 3.050623384475708, 'learning_rate': 3.113376100410537e-05, 'epoch': 1.1319743397536781, 'step': 6285000}
INFO:transformers.trainer:{'loss': 3.045202143192291, 'learning_rate': 3.113226010999273e-05, 'epoch': 1.1320643934004364, 'step': 6285500}
INFO:transformers.trainer:{'loss': 3.073247643470764, 'learning_rate': 3.113075921588009e-05, 'epoch': 1.132154447047195, 'step': 6286000}
INFO:transformers.trainer:{'loss': 3.06299404668808, 'learning_rate': 3.1129258321767446e-05, 'epoch': 1.1322445006939534, 'step': 6286500}
INFO:transformers.trainer:{'loss': 3.0368137457370756, 'learning_rate': 3.1127757427654805e-05, 'epoch': 1.1323345543407117, 'step': 6287000}
INFO:transformers.trainer:{'loss': 2.9820278123617174, 'learning_rate': 3.1126256533542164e-05, 'epoch': 1.1324246079874702, 'step': 6287500}
INFO:transformers.trainer:{'loss': 3.0725462658405305, 'learning_rate': 3.112475563942952e-05, 'epoch': 1.1325146616342288, 'step': 6288000}
INFO:transformers.trainer:{'loss': 2.993265830993652, 'learning_rate': 3.112325474531688e-05, 'epoch': 1.1326047152809873, 'step': 6288500}
INFO:transformers.trainer:{'loss': 3.0229096989631654, 'learning_rate': 3.112175385120424e-05, 'epoch': 1.1326947689277456, 'step': 6289000}
INFO:transformers.trainer:{'loss': 3.078279608249664, 'learning_rate': 3.11202529570916e-05, 'epoch': 1.132784822574504, 'step': 6289500}
INFO:transformers.trainer:{'loss': 3.0603136825561523, 'learning_rate': 3.111875206297896e-05, 'epoch': 1.1328748762212626, 'step': 6290000}
INFO:transformers.trainer:{'loss': 3.065132025241852, 'learning_rate': 3.111725116886632e-05, 'epoch': 1.1329649298680209, 'step': 6290500}
INFO:transformers.trainer:{'loss': 3.038543032288551, 'learning_rate': 3.111575027475368e-05, 'epoch': 1.1330549835147794, 'step': 6291000}
INFO:transformers.trainer:{'loss': 3.0543943248987198, 'learning_rate': 3.1114249380641036e-05, 'epoch': 1.133145037161538, 'step': 6291500}
INFO:transformers.trainer:{'loss': 3.1191992869377136, 'learning_rate': 3.1112748486528395e-05, 'epoch': 1.1332350908082964, 'step': 6292000}
INFO:transformers.trainer:{'loss': 3.0445759527683256, 'learning_rate': 3.1111247592415754e-05, 'epoch': 1.1333251444550547, 'step': 6292500}
INFO:transformers.trainer:{'loss': 3.117928433895111, 'learning_rate': 3.1109746698303114e-05, 'epoch': 1.1334151981018132, 'step': 6293000}
INFO:transformers.trainer:{'loss': 3.06306303191185, 'learning_rate': 3.110824580419047e-05, 'epoch': 1.1335052517485718, 'step': 6293500}
INFO:transformers.trainer:{'loss': 3.0723586492538453, 'learning_rate': 3.110674491007783e-05, 'epoch': 1.13359530539533, 'step': 6294000}
INFO:transformers.trainer:{'loss': 3.064994310617447, 'learning_rate': 3.110524401596519e-05, 'epoch': 1.1336853590420886, 'step': 6294500}
INFO:transformers.trainer:{'loss': 3.044733690738678, 'learning_rate': 3.110374312185255e-05, 'epoch': 1.133775412688847, 'step': 6295000}
INFO:transformers.trainer:{'loss': 3.1099062938690185, 'learning_rate': 3.110224222773991e-05, 'epoch': 1.1338654663356054, 'step': 6295500}
INFO:transformers.trainer:{'loss': 3.1156011636257173, 'learning_rate': 3.110074133362727e-05, 'epoch': 1.1339555199823639, 'step': 6296000}
INFO:transformers.trainer:{'loss': 3.1155440487861634, 'learning_rate': 3.109924043951463e-05, 'epoch': 1.1340455736291224, 'step': 6296500}
INFO:transformers.trainer:{'loss': 3.0088952510356903, 'learning_rate': 3.1097739545401986e-05, 'epoch': 1.1341356272758807, 'step': 6297000}
INFO:transformers.trainer:{'loss': 3.1153303850889205, 'learning_rate': 3.109623865128935e-05, 'epoch': 1.1342256809226392, 'step': 6297500}
INFO:transformers.trainer:{'loss': 3.2003107433319093, 'learning_rate': 3.1094737757176704e-05, 'epoch': 1.1343157345693977, 'step': 6298000}
INFO:transformers.trainer:{'loss': 3.085743161559105, 'learning_rate': 3.109323686306407e-05, 'epoch': 1.134405788216156, 'step': 6298500}
INFO:transformers.trainer:{'loss': 3.043700236082077, 'learning_rate': 3.109173596895142e-05, 'epoch': 1.1344958418629145, 'step': 6299000}
INFO:transformers.trainer:{'loss': 3.0671218746900557, 'learning_rate': 3.109023507483879e-05, 'epoch': 1.134585895509673, 'step': 6299500}
INFO:transformers.trainer:{'loss': 3.0771059008836747, 'learning_rate': 3.108873418072614e-05, 'epoch': 1.1346759491564316, 'step': 6300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0997503905296324, 'learning_rate': 3.1087233286613506e-05, 'epoch': 1.1347660028031898, 'step': 6300500}
INFO:transformers.trainer:{'loss': 3.059195829629898, 'learning_rate': 3.108573239250086e-05, 'epoch': 1.1348560564499484, 'step': 6301000}
INFO:transformers.trainer:{'loss': 3.015876255393028, 'learning_rate': 3.1084231498388224e-05, 'epoch': 1.1349461100967069, 'step': 6301500}
INFO:transformers.trainer:{'loss': 3.100087465643883, 'learning_rate': 3.1082730604275576e-05, 'epoch': 1.1350361637434652, 'step': 6302000}
INFO:transformers.trainer:{'loss': 3.0773057397603987, 'learning_rate': 3.108122971016294e-05, 'epoch': 1.1351262173902237, 'step': 6302500}
INFO:transformers.trainer:{'loss': 3.098680196762085, 'learning_rate': 3.1079728816050295e-05, 'epoch': 1.1352162710369822, 'step': 6303000}
INFO:transformers.trainer:{'loss': 3.0453949954509736, 'learning_rate': 3.107822792193766e-05, 'epoch': 1.1353063246837407, 'step': 6303500}
INFO:transformers.trainer:{'loss': 3.0536013536453246, 'learning_rate': 3.107672702782502e-05, 'epoch': 1.135396378330499, 'step': 6304000}
INFO:transformers.trainer:{'loss': 3.0902391455173492, 'learning_rate': 3.107522613371238e-05, 'epoch': 1.1354864319772575, 'step': 6304500}
INFO:transformers.trainer:{'loss': 3.146069332242012, 'learning_rate': 3.107372523959974e-05, 'epoch': 1.135576485624016, 'step': 6305000}
INFO:transformers.trainer:{'loss': 3.027349626302719, 'learning_rate': 3.1072224345487097e-05, 'epoch': 1.1356665392707743, 'step': 6305500}
INFO:transformers.trainer:{'loss': 3.0316946074962616, 'learning_rate': 3.1070723451374456e-05, 'epoch': 1.1357565929175328, 'step': 6306000}
INFO:transformers.trainer:{'loss': 3.033678588628769, 'learning_rate': 3.1069222557261815e-05, 'epoch': 1.1358466465642914, 'step': 6306500}
INFO:transformers.trainer:{'loss': 3.0853421392440796, 'learning_rate': 3.1067721663149174e-05, 'epoch': 1.1359367002110496, 'step': 6307000}
INFO:transformers.trainer:{'loss': 3.088001962184906, 'learning_rate': 3.106622076903653e-05, 'epoch': 1.1360267538578082, 'step': 6307500}
INFO:transformers.trainer:{'loss': 3.0657017906904223, 'learning_rate': 3.106471987492389e-05, 'epoch': 1.1361168075045667, 'step': 6308000}
INFO:transformers.trainer:{'loss': 3.0738980810642245, 'learning_rate': 3.106321898081125e-05, 'epoch': 1.136206861151325, 'step': 6308500}
INFO:transformers.trainer:{'loss': 3.018578067779541, 'learning_rate': 3.106171808669861e-05, 'epoch': 1.1362969147980835, 'step': 6309000}
INFO:transformers.trainer:{'loss': 3.056647035598755, 'learning_rate': 3.106021719258597e-05, 'epoch': 1.136386968444842, 'step': 6309500}
INFO:transformers.trainer:{'loss': 3.0587111946344376, 'learning_rate': 3.105871629847333e-05, 'epoch': 1.1364770220916003, 'step': 6310000}
INFO:transformers.trainer:{'loss': 3.089468692779541, 'learning_rate': 3.105721540436069e-05, 'epoch': 1.1365670757383588, 'step': 6310500}
INFO:transformers.trainer:{'loss': 3.1064789835214617, 'learning_rate': 3.1055714510248046e-05, 'epoch': 1.1366571293851173, 'step': 6311000}
INFO:transformers.trainer:{'loss': 3.0826221609115603, 'learning_rate': 3.1054213616135405e-05, 'epoch': 1.1367471830318758, 'step': 6311500}
INFO:transformers.trainer:{'loss': 3.0817271894812586, 'learning_rate': 3.1052712722022764e-05, 'epoch': 1.1368372366786341, 'step': 6312000}
INFO:transformers.trainer:{'loss': 3.0847560403347014, 'learning_rate': 3.105121182791012e-05, 'epoch': 1.1369272903253926, 'step': 6312500}
INFO:transformers.trainer:{'loss': 3.082374090909958, 'learning_rate': 3.104971093379748e-05, 'epoch': 1.1370173439721512, 'step': 6313000}
INFO:transformers.trainer:{'loss': 3.130573073387146, 'learning_rate': 3.104821003968484e-05, 'epoch': 1.1371073976189094, 'step': 6313500}
INFO:transformers.trainer:{'loss': 3.038189330458641, 'learning_rate': 3.10467091455722e-05, 'epoch': 1.137197451265668, 'step': 6314000}
INFO:transformers.trainer:{'loss': 3.1411410570144653, 'learning_rate': 3.104520825145956e-05, 'epoch': 1.1372875049124265, 'step': 6314500}
INFO:transformers.trainer:{'loss': 3.107770327806473, 'learning_rate': 3.104370735734692e-05, 'epoch': 1.137377558559185, 'step': 6315000}
INFO:transformers.trainer:{'loss': 3.097045215129852, 'learning_rate': 3.104220646323428e-05, 'epoch': 1.1374676122059433, 'step': 6315500}
INFO:transformers.trainer:{'loss': 3.0920322270393372, 'learning_rate': 3.104070556912164e-05, 'epoch': 1.1375576658527018, 'step': 6316000}
INFO:transformers.trainer:{'loss': 3.1181966587305068, 'learning_rate': 3.1039204675008996e-05, 'epoch': 1.1376477194994603, 'step': 6316500}
INFO:transformers.trainer:{'loss': 3.0752798821926115, 'learning_rate': 3.1037703780896355e-05, 'epoch': 1.1377377731462186, 'step': 6317000}
INFO:transformers.trainer:{'loss': 3.058620437860489, 'learning_rate': 3.1036202886783714e-05, 'epoch': 1.1378278267929771, 'step': 6317500}
INFO:transformers.trainer:{'loss': 3.1177817842960356, 'learning_rate': 3.103470199267108e-05, 'epoch': 1.1379178804397356, 'step': 6318000}
INFO:transformers.trainer:{'loss': 3.036120489835739, 'learning_rate': 3.103320109855843e-05, 'epoch': 1.138007934086494, 'step': 6318500}
INFO:transformers.trainer:{'loss': 3.179615119457245, 'learning_rate': 3.10317002044458e-05, 'epoch': 1.1380979877332524, 'step': 6319000}
INFO:transformers.trainer:{'loss': 3.0122073316574096, 'learning_rate': 3.103019931033315e-05, 'epoch': 1.138188041380011, 'step': 6319500}
INFO:transformers.trainer:{'loss': 3.0916063911914824, 'learning_rate': 3.1028698416220516e-05, 'epoch': 1.1382780950267692, 'step': 6320000}
INFO:transformers.trainer:{'loss': 3.0654895329475402, 'learning_rate': 3.102719752210787e-05, 'epoch': 1.1383681486735278, 'step': 6320500}
INFO:transformers.trainer:{'loss': 2.9853454036712646, 'learning_rate': 3.1025696627995234e-05, 'epoch': 1.1384582023202863, 'step': 6321000}
INFO:transformers.trainer:{'loss': 3.089711835384369, 'learning_rate': 3.1024195733882586e-05, 'epoch': 1.1385482559670446, 'step': 6321500}
INFO:transformers.trainer:{'loss': 3.023731239795685, 'learning_rate': 3.102269483976995e-05, 'epoch': 1.138638309613803, 'step': 6322000}
INFO:transformers.trainer:{'loss': 3.039500512123108, 'learning_rate': 3.1021193945657304e-05, 'epoch': 1.1387283632605616, 'step': 6322500}
INFO:transformers.trainer:{'loss': 3.025498838424683, 'learning_rate': 3.101969305154467e-05, 'epoch': 1.13881841690732, 'step': 6323000}
INFO:transformers.trainer:{'loss': 3.129613342523575, 'learning_rate': 3.101819215743202e-05, 'epoch': 1.1389084705540784, 'step': 6323500}
INFO:transformers.trainer:{'loss': 3.0642804238796235, 'learning_rate': 3.101669126331939e-05, 'epoch': 1.138998524200837, 'step': 6324000}
INFO:transformers.trainer:{'loss': 3.0653333958387377, 'learning_rate': 3.101519036920675e-05, 'epoch': 1.1390885778475954, 'step': 6324500}
INFO:transformers.trainer:{'loss': 3.074928510904312, 'learning_rate': 3.1013689475094106e-05, 'epoch': 1.1391786314943537, 'step': 6325000}
INFO:transformers.trainer:{'loss': 3.0362987806797026, 'learning_rate': 3.1012188580981465e-05, 'epoch': 1.1392686851411122, 'step': 6325500}
INFO:transformers.trainer:{'loss': 3.0299124207496644, 'learning_rate': 3.1010687686868824e-05, 'epoch': 1.1393587387878708, 'step': 6326000}
INFO:transformers.trainer:{'loss': 3.089146817445755, 'learning_rate': 3.1009186792756183e-05, 'epoch': 1.1394487924346293, 'step': 6326500}
INFO:transformers.trainer:{'loss': 3.040650509595871, 'learning_rate': 3.100768589864354e-05, 'epoch': 1.1395388460813876, 'step': 6327000}
INFO:transformers.trainer:{'loss': 2.964033279657364, 'learning_rate': 3.10061850045309e-05, 'epoch': 1.139628899728146, 'step': 6327500}
INFO:transformers.trainer:{'loss': 3.030182771444321, 'learning_rate': 3.100468411041826e-05, 'epoch': 1.1397189533749046, 'step': 6328000}
INFO:transformers.trainer:{'loss': 3.1017827976942063, 'learning_rate': 3.100318321630562e-05, 'epoch': 1.1398090070216629, 'step': 6328500}
INFO:transformers.trainer:{'loss': 3.055664019584656, 'learning_rate': 3.100168232219298e-05, 'epoch': 1.1398990606684214, 'step': 6329000}
INFO:transformers.trainer:{'loss': 3.0630257976055146, 'learning_rate': 3.100018142808034e-05, 'epoch': 1.13998911431518, 'step': 6329500}
INFO:transformers.trainer:{'loss': 3.099904998064041, 'learning_rate': 3.09986805339677e-05, 'epoch': 1.1400791679619382, 'step': 6330000}
INFO:transformers.trainer:{'loss': 3.057481236219406, 'learning_rate': 3.0997179639855056e-05, 'epoch': 1.1401692216086967, 'step': 6330500}
INFO:transformers.trainer:{'loss': 3.085055626988411, 'learning_rate': 3.0995678745742415e-05, 'epoch': 1.1402592752554552, 'step': 6331000}
INFO:transformers.trainer:{'loss': 3.099058994293213, 'learning_rate': 3.0994177851629774e-05, 'epoch': 1.1403493289022135, 'step': 6331500}
INFO:transformers.trainer:{'loss': 3.017517791390419, 'learning_rate': 3.099267695751713e-05, 'epoch': 1.140439382548972, 'step': 6332000}
INFO:transformers.trainer:{'loss': 3.0261175743341444, 'learning_rate': 3.099117606340449e-05, 'epoch': 1.1405294361957306, 'step': 6332500}
INFO:transformers.trainer:{'loss': 3.081064081072807, 'learning_rate': 3.098967516929185e-05, 'epoch': 1.1406194898424888, 'step': 6333000}
INFO:transformers.trainer:{'loss': 3.0921058498620986, 'learning_rate': 3.098817427517921e-05, 'epoch': 1.1407095434892474, 'step': 6333500}
INFO:transformers.trainer:{'loss': 3.0289209229946135, 'learning_rate': 3.098667338106657e-05, 'epoch': 1.1407995971360059, 'step': 6334000}
INFO:transformers.trainer:{'loss': 3.005898050785065, 'learning_rate': 3.098517248695393e-05, 'epoch': 1.1408896507827644, 'step': 6334500}
INFO:transformers.trainer:{'loss': 2.983512078285217, 'learning_rate': 3.098367159284129e-05, 'epoch': 1.1409797044295227, 'step': 6335000}
INFO:transformers.trainer:{'loss': 3.0927011070251464, 'learning_rate': 3.0982170698728646e-05, 'epoch': 1.1410697580762812, 'step': 6335500}
INFO:transformers.trainer:{'loss': 3.0670253143310546, 'learning_rate': 3.0980669804616005e-05, 'epoch': 1.1411598117230397, 'step': 6336000}
INFO:transformers.trainer:{'loss': 3.030767420053482, 'learning_rate': 3.0979168910503364e-05, 'epoch': 1.141249865369798, 'step': 6336500}
INFO:transformers.trainer:{'loss': 3.053262007236481, 'learning_rate': 3.0977668016390724e-05, 'epoch': 1.1413399190165565, 'step': 6337000}
INFO:transformers.trainer:{'loss': 3.064585379600525, 'learning_rate': 3.097616712227808e-05, 'epoch': 1.141429972663315, 'step': 6337500}
INFO:transformers.trainer:{'loss': 3.0687378740310667, 'learning_rate': 3.097466622816544e-05, 'epoch': 1.1415200263100735, 'step': 6338000}
INFO:transformers.trainer:{'loss': 3.057168373823166, 'learning_rate': 3.097316533405281e-05, 'epoch': 1.1416100799568318, 'step': 6338500}
INFO:transformers.trainer:{'loss': 3.085128019094467, 'learning_rate': 3.097166443994016e-05, 'epoch': 1.1417001336035904, 'step': 6339000}
INFO:transformers.trainer:{'loss': 3.0680060150623323, 'learning_rate': 3.0970163545827526e-05, 'epoch': 1.1417901872503489, 'step': 6339500}
INFO:transformers.trainer:{'loss': 3.080077428817749, 'learning_rate': 3.096866265171488e-05, 'epoch': 1.1418802408971072, 'step': 6340000}
INFO:transformers.trainer:{'loss': 3.053597381949425, 'learning_rate': 3.0967161757602244e-05, 'epoch': 1.1419702945438657, 'step': 6340500}
INFO:transformers.trainer:{'loss': 2.973475834131241, 'learning_rate': 3.0965660863489596e-05, 'epoch': 1.1420603481906242, 'step': 6341000}
INFO:transformers.trainer:{'loss': 3.134986874103546, 'learning_rate': 3.096415996937696e-05, 'epoch': 1.1421504018373825, 'step': 6341500}
INFO:transformers.trainer:{'loss': 3.110683789730072, 'learning_rate': 3.0962659075264314e-05, 'epoch': 1.142240455484141, 'step': 6342000}
INFO:transformers.trainer:{'loss': 3.042112894654274, 'learning_rate': 3.096115818115168e-05, 'epoch': 1.1423305091308995, 'step': 6342500}
INFO:transformers.trainer:{'loss': 3.0563800060749053, 'learning_rate': 3.095965728703903e-05, 'epoch': 1.1424205627776578, 'step': 6343000}
INFO:transformers.trainer:{'loss': 3.103919189095497, 'learning_rate': 3.09581563929264e-05, 'epoch': 1.1425106164244163, 'step': 6343500}
INFO:transformers.trainer:{'loss': 3.09493901515007, 'learning_rate': 3.095665549881375e-05, 'epoch': 1.1426006700711748, 'step': 6344000}
INFO:transformers.trainer:{'loss': 3.023854628562927, 'learning_rate': 3.0955154604701116e-05, 'epoch': 1.1426907237179333, 'step': 6344500}
INFO:transformers.trainer:{'loss': 3.029276109933853, 'learning_rate': 3.095365371058847e-05, 'epoch': 1.1427807773646916, 'step': 6345000}
INFO:transformers.trainer:{'loss': 3.101886508703232, 'learning_rate': 3.0952152816475834e-05, 'epoch': 1.1428708310114502, 'step': 6345500}
INFO:transformers.trainer:{'loss': 3.002828050851822, 'learning_rate': 3.095065192236319e-05, 'epoch': 1.1429608846582087, 'step': 6346000}
INFO:transformers.trainer:{'loss': 3.068447600364685, 'learning_rate': 3.094915102825055e-05, 'epoch': 1.143050938304967, 'step': 6346500}
INFO:transformers.trainer:{'loss': 3.086963164806366, 'learning_rate': 3.094765013413791e-05, 'epoch': 1.1431409919517255, 'step': 6347000}
INFO:transformers.trainer:{'loss': 3.0073914234638215, 'learning_rate': 3.094614924002527e-05, 'epoch': 1.143231045598484, 'step': 6347500}
INFO:transformers.trainer:{'loss': 3.119557821035385, 'learning_rate': 3.094464834591263e-05, 'epoch': 1.1433210992452425, 'step': 6348000}
INFO:transformers.trainer:{'loss': 3.070582466840744, 'learning_rate': 3.094314745179999e-05, 'epoch': 1.1434111528920008, 'step': 6348500}
INFO:transformers.trainer:{'loss': 3.0500740175247194, 'learning_rate': 3.094164655768735e-05, 'epoch': 1.1435012065387593, 'step': 6349000}
INFO:transformers.trainer:{'loss': 2.993099599838257, 'learning_rate': 3.0940145663574707e-05, 'epoch': 1.1435912601855178, 'step': 6349500}
INFO:transformers.trainer:{'loss': 3.0470177335739135, 'learning_rate': 3.0938644769462066e-05, 'epoch': 1.1436813138322761, 'step': 6350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0877557215690614, 'learning_rate': 3.0937143875349425e-05, 'epoch': 1.1437713674790346, 'step': 6350500}
INFO:transformers.trainer:{'loss': 3.0862786972522738, 'learning_rate': 3.0935642981236784e-05, 'epoch': 1.1438614211257931, 'step': 6351000}
INFO:transformers.trainer:{'loss': 3.1174870246648787, 'learning_rate': 3.093414208712414e-05, 'epoch': 1.1439514747725514, 'step': 6351500}
INFO:transformers.trainer:{'loss': 3.129260925292969, 'learning_rate': 3.09326411930115e-05, 'epoch': 1.14404152841931, 'step': 6352000}
INFO:transformers.trainer:{'loss': 3.088313371181488, 'learning_rate': 3.093114029889886e-05, 'epoch': 1.1441315820660685, 'step': 6352500}
INFO:transformers.trainer:{'loss': 3.082382020711899, 'learning_rate': 3.092963940478622e-05, 'epoch': 1.1442216357128268, 'step': 6353000}
INFO:transformers.trainer:{'loss': 3.0611752042770384, 'learning_rate': 3.092813851067358e-05, 'epoch': 1.1443116893595853, 'step': 6353500}
INFO:transformers.trainer:{'loss': 3.049879200220108, 'learning_rate': 3.092663761656094e-05, 'epoch': 1.1444017430063438, 'step': 6354000}
INFO:transformers.trainer:{'loss': 3.0686818010807038, 'learning_rate': 3.09251367224483e-05, 'epoch': 1.144491796653102, 'step': 6354500}
INFO:transformers.trainer:{'loss': 3.073670368909836, 'learning_rate': 3.0923635828335656e-05, 'epoch': 1.1445818502998606, 'step': 6355000}
INFO:transformers.trainer:{'loss': 2.987821334004402, 'learning_rate': 3.0922134934223015e-05, 'epoch': 1.144671903946619, 'step': 6355500}
INFO:transformers.trainer:{'loss': 3.051513971328735, 'learning_rate': 3.0920634040110374e-05, 'epoch': 1.1447619575933776, 'step': 6356000}
INFO:transformers.trainer:{'loss': 3.0522770735025406, 'learning_rate': 3.091913314599773e-05, 'epoch': 1.144852011240136, 'step': 6356500}
INFO:transformers.trainer:{'loss': 3.04360641002655, 'learning_rate': 3.091763225188509e-05, 'epoch': 1.1449420648868944, 'step': 6357000}
INFO:transformers.trainer:{'loss': 3.051736367225647, 'learning_rate': 3.091613135777245e-05, 'epoch': 1.145032118533653, 'step': 6357500}
INFO:transformers.trainer:{'loss': 3.0810760172605516, 'learning_rate': 3.091463046365981e-05, 'epoch': 1.1451221721804112, 'step': 6358000}
INFO:transformers.trainer:{'loss': 3.092130352973938, 'learning_rate': 3.091312956954717e-05, 'epoch': 1.1452122258271697, 'step': 6358500}
INFO:transformers.trainer:{'loss': 3.0641109703183176, 'learning_rate': 3.0911628675434535e-05, 'epoch': 1.1453022794739283, 'step': 6359000}
INFO:transformers.trainer:{'loss': 3.070653843164444, 'learning_rate': 3.091012778132189e-05, 'epoch': 1.1453923331206868, 'step': 6359500}
INFO:transformers.trainer:{'loss': 3.111969331502914, 'learning_rate': 3.090862688720925e-05, 'epoch': 1.145482386767445, 'step': 6360000}
INFO:transformers.trainer:{'loss': 3.051005802869797, 'learning_rate': 3.0907125993096606e-05, 'epoch': 1.1455724404142036, 'step': 6360500}
INFO:transformers.trainer:{'loss': 3.076185522079468, 'learning_rate': 3.090562509898397e-05, 'epoch': 1.145662494060962, 'step': 6361000}
INFO:transformers.trainer:{'loss': 3.0755353038311006, 'learning_rate': 3.0904124204871324e-05, 'epoch': 1.1457525477077204, 'step': 6361500}
INFO:transformers.trainer:{'loss': 3.0405662076473234, 'learning_rate': 3.090262331075869e-05, 'epoch': 1.145842601354479, 'step': 6362000}
INFO:transformers.trainer:{'loss': 3.095490295410156, 'learning_rate': 3.090112241664604e-05, 'epoch': 1.1459326550012374, 'step': 6362500}
INFO:transformers.trainer:{'loss': 3.1237348058223726, 'learning_rate': 3.089962152253341e-05, 'epoch': 1.1460227086479957, 'step': 6363000}
INFO:transformers.trainer:{'loss': 3.049345960378647, 'learning_rate': 3.089812062842076e-05, 'epoch': 1.1461127622947542, 'step': 6363500}
INFO:transformers.trainer:{'loss': 3.1168339891433714, 'learning_rate': 3.0896619734308126e-05, 'epoch': 1.1462028159415127, 'step': 6364000}
INFO:transformers.trainer:{'loss': 3.011355266332626, 'learning_rate': 3.089511884019548e-05, 'epoch': 1.146292869588271, 'step': 6364500}
INFO:transformers.trainer:{'loss': 3.0892884223461152, 'learning_rate': 3.0893617946082844e-05, 'epoch': 1.1463829232350295, 'step': 6365000}
INFO:transformers.trainer:{'loss': 3.035302352666855, 'learning_rate': 3.0892117051970196e-05, 'epoch': 1.146472976881788, 'step': 6365500}
INFO:transformers.trainer:{'loss': 3.1224651086330413, 'learning_rate': 3.089061615785756e-05, 'epoch': 1.1465630305285464, 'step': 6366000}
INFO:transformers.trainer:{'loss': 3.032703274488449, 'learning_rate': 3.088911526374492e-05, 'epoch': 1.1466530841753049, 'step': 6366500}
INFO:transformers.trainer:{'loss': 3.06992321562767, 'learning_rate': 3.088761436963228e-05, 'epoch': 1.1467431378220634, 'step': 6367000}
INFO:transformers.trainer:{'loss': 3.066870239496231, 'learning_rate': 3.088611347551964e-05, 'epoch': 1.146833191468822, 'step': 6367500}
INFO:transformers.trainer:{'loss': 2.977804061412811, 'learning_rate': 3.0884612581407e-05, 'epoch': 1.1469232451155802, 'step': 6368000}
INFO:transformers.trainer:{'loss': 3.081471507191658, 'learning_rate': 3.088311168729436e-05, 'epoch': 1.1470132987623387, 'step': 6368500}
INFO:transformers.trainer:{'loss': 3.0173981482982635, 'learning_rate': 3.0881610793181716e-05, 'epoch': 1.1471033524090972, 'step': 6369000}
INFO:transformers.trainer:{'loss': 3.0992681136131286, 'learning_rate': 3.0880109899069075e-05, 'epoch': 1.1471934060558555, 'step': 6369500}
INFO:transformers.trainer:{'loss': 3.0749964727163315, 'learning_rate': 3.0878609004956434e-05, 'epoch': 1.147283459702614, 'step': 6370000}
INFO:transformers.trainer:{'loss': 3.080698156118393, 'learning_rate': 3.0877108110843793e-05, 'epoch': 1.1473735133493725, 'step': 6370500}
INFO:transformers.trainer:{'loss': 3.067288285255432, 'learning_rate': 3.087560721673115e-05, 'epoch': 1.147463566996131, 'step': 6371000}
INFO:transformers.trainer:{'loss': 3.0174480987787247, 'learning_rate': 3.087410632261851e-05, 'epoch': 1.1475536206428893, 'step': 6371500}
INFO:transformers.trainer:{'loss': 3.1149730789661407, 'learning_rate': 3.087260542850587e-05, 'epoch': 1.1476436742896479, 'step': 6372000}
INFO:transformers.trainer:{'loss': 3.0468717968463896, 'learning_rate': 3.087110453439323e-05, 'epoch': 1.1477337279364064, 'step': 6372500}
INFO:transformers.trainer:{'loss': 3.0712014900445936, 'learning_rate': 3.0869603640280595e-05, 'epoch': 1.1478237815831647, 'step': 6373000}
INFO:transformers.trainer:{'loss': 3.088933237552643, 'learning_rate': 3.086810274616795e-05, 'epoch': 1.1479138352299232, 'step': 6373500}
INFO:transformers.trainer:{'loss': 3.1058844010829927, 'learning_rate': 3.0866601852055314e-05, 'epoch': 1.1480038888766817, 'step': 6374000}
INFO:transformers.trainer:{'loss': 3.0419550787210463, 'learning_rate': 3.0865100957942666e-05, 'epoch': 1.14809394252344, 'step': 6374500}
INFO:transformers.trainer:{'loss': 3.069776219844818, 'learning_rate': 3.0863600063830025e-05, 'epoch': 1.1481839961701985, 'step': 6375000}
INFO:transformers.trainer:{'loss': 2.9940036525726317, 'learning_rate': 3.0862099169717384e-05, 'epoch': 1.148274049816957, 'step': 6375500}
INFO:transformers.trainer:{'loss': 3.0237433948516848, 'learning_rate': 3.086059827560474e-05, 'epoch': 1.1483641034637153, 'step': 6376000}
INFO:transformers.trainer:{'loss': 3.0543070113658906, 'learning_rate': 3.08590973814921e-05, 'epoch': 1.1484541571104738, 'step': 6376500}
INFO:transformers.trainer:{'loss': 3.077321214199066, 'learning_rate': 3.085759648737946e-05, 'epoch': 1.1485442107572323, 'step': 6377000}
INFO:transformers.trainer:{'loss': 3.0285999729633333, 'learning_rate': 3.085609559326682e-05, 'epoch': 1.1486342644039906, 'step': 6377500}
INFO:transformers.trainer:{'loss': 3.066911616563797, 'learning_rate': 3.085459469915418e-05, 'epoch': 1.1487243180507491, 'step': 6378000}
INFO:transformers.trainer:{'loss': 3.0429819769859314, 'learning_rate': 3.085309380504154e-05, 'epoch': 1.1488143716975077, 'step': 6378500}
INFO:transformers.trainer:{'loss': 3.1005457994937897, 'learning_rate': 3.08515929109289e-05, 'epoch': 1.1489044253442662, 'step': 6379000}
INFO:transformers.trainer:{'loss': 3.058242010474205, 'learning_rate': 3.0850092016816256e-05, 'epoch': 1.1489944789910245, 'step': 6379500}
INFO:transformers.trainer:{'loss': 3.0261994183063505, 'learning_rate': 3.0848591122703615e-05, 'epoch': 1.149084532637783, 'step': 6380000}
INFO:transformers.trainer:{'loss': 3.072035660505295, 'learning_rate': 3.084709022859098e-05, 'epoch': 1.1491745862845415, 'step': 6380500}
INFO:transformers.trainer:{'loss': 3.0567420500516893, 'learning_rate': 3.0845589334478333e-05, 'epoch': 1.1492646399312998, 'step': 6381000}
INFO:transformers.trainer:{'loss': 3.1101018123626707, 'learning_rate': 3.08440884403657e-05, 'epoch': 1.1493546935780583, 'step': 6381500}
INFO:transformers.trainer:{'loss': 2.992099501132965, 'learning_rate': 3.084258754625305e-05, 'epoch': 1.1494447472248168, 'step': 6382000}
INFO:transformers.trainer:{'loss': 3.08464328789711, 'learning_rate': 3.084108665214042e-05, 'epoch': 1.1495348008715753, 'step': 6382500}
INFO:transformers.trainer:{'loss': 3.0733058713674546, 'learning_rate': 3.083958575802777e-05, 'epoch': 1.1496248545183336, 'step': 6383000}
INFO:transformers.trainer:{'loss': 3.082677367448807, 'learning_rate': 3.0838084863915135e-05, 'epoch': 1.1497149081650921, 'step': 6383500}
INFO:transformers.trainer:{'loss': 3.0798361381292345, 'learning_rate': 3.083658396980249e-05, 'epoch': 1.1498049618118507, 'step': 6384000}
INFO:transformers.trainer:{'loss': 3.0062284395694734, 'learning_rate': 3.0835083075689854e-05, 'epoch': 1.149895015458609, 'step': 6384500}
INFO:transformers.trainer:{'loss': 3.0802830410003663, 'learning_rate': 3.0833582181577206e-05, 'epoch': 1.1499850691053675, 'step': 6385000}
INFO:transformers.trainer:{'loss': 3.0858244547843934, 'learning_rate': 3.083208128746457e-05, 'epoch': 1.150075122752126, 'step': 6385500}
INFO:transformers.trainer:{'loss': 3.0816598312854766, 'learning_rate': 3.0830580393351924e-05, 'epoch': 1.1501651763988843, 'step': 6386000}
INFO:transformers.trainer:{'loss': 3.0761114358901978, 'learning_rate': 3.082907949923929e-05, 'epoch': 1.1502552300456428, 'step': 6386500}
INFO:transformers.trainer:{'loss': 3.0538330247402192, 'learning_rate': 3.082757860512665e-05, 'epoch': 1.1503452836924013, 'step': 6387000}
INFO:transformers.trainer:{'loss': 3.04276353931427, 'learning_rate': 3.082607771101401e-05, 'epoch': 1.1504353373391596, 'step': 6387500}
INFO:transformers.trainer:{'loss': 3.0563344377279282, 'learning_rate': 3.082457681690137e-05, 'epoch': 1.150525390985918, 'step': 6388000}
INFO:transformers.trainer:{'loss': 3.089028012752533, 'learning_rate': 3.0823075922788726e-05, 'epoch': 1.1506154446326766, 'step': 6388500}
INFO:transformers.trainer:{'loss': 3.1059841833114623, 'learning_rate': 3.0821575028676085e-05, 'epoch': 1.150705498279435, 'step': 6389000}
INFO:transformers.trainer:{'loss': 3.1099473042488097, 'learning_rate': 3.0820074134563444e-05, 'epoch': 1.1507955519261934, 'step': 6389500}
INFO:transformers.trainer:{'loss': 3.0471479011774063, 'learning_rate': 3.08185732404508e-05, 'epoch': 1.150885605572952, 'step': 6390000}
INFO:transformers.trainer:{'loss': 3.081306305170059, 'learning_rate': 3.081707234633816e-05, 'epoch': 1.1509756592197105, 'step': 6390500}
INFO:transformers.trainer:{'loss': 3.0618691046237947, 'learning_rate': 3.081557145222552e-05, 'epoch': 1.1510657128664687, 'step': 6391000}
INFO:transformers.trainer:{'loss': 3.0244465434551238, 'learning_rate': 3.081407055811288e-05, 'epoch': 1.1511557665132273, 'step': 6391500}
INFO:transformers.trainer:{'loss': 3.0782861444950105, 'learning_rate': 3.081256966400024e-05, 'epoch': 1.1512458201599858, 'step': 6392000}
INFO:transformers.trainer:{'loss': 3.0504849367141724, 'learning_rate': 3.08110687698876e-05, 'epoch': 1.151335873806744, 'step': 6392500}
INFO:transformers.trainer:{'loss': 3.021632649898529, 'learning_rate': 3.080956787577496e-05, 'epoch': 1.1514259274535026, 'step': 6393000}
INFO:transformers.trainer:{'loss': 3.09788900411129, 'learning_rate': 3.0808066981662316e-05, 'epoch': 1.151515981100261, 'step': 6393500}
INFO:transformers.trainer:{'loss': 3.0210918259620665, 'learning_rate': 3.0806566087549676e-05, 'epoch': 1.1516060347470196, 'step': 6394000}
INFO:transformers.trainer:{'loss': 3.0714700417518617, 'learning_rate': 3.080506519343704e-05, 'epoch': 1.151696088393778, 'step': 6394500}
INFO:transformers.trainer:{'loss': 3.086092267036438, 'learning_rate': 3.0803564299324394e-05, 'epoch': 1.1517861420405364, 'step': 6395000}
INFO:transformers.trainer:{'loss': 3.048416657924652, 'learning_rate': 3.080206340521176e-05, 'epoch': 1.151876195687295, 'step': 6395500}
INFO:transformers.trainer:{'loss': 3.1016026256084444, 'learning_rate': 3.080056251109911e-05, 'epoch': 1.1519662493340532, 'step': 6396000}
INFO:transformers.trainer:{'loss': 3.036834230422974, 'learning_rate': 3.079906161698648e-05, 'epoch': 1.1520563029808117, 'step': 6396500}
INFO:transformers.trainer:{'loss': 3.0016433874368667, 'learning_rate': 3.079756072287383e-05, 'epoch': 1.1521463566275703, 'step': 6397000}
INFO:transformers.trainer:{'loss': 3.067749236345291, 'learning_rate': 3.0796059828761196e-05, 'epoch': 1.1522364102743285, 'step': 6397500}
INFO:transformers.trainer:{'loss': 3.0696376980543136, 'learning_rate': 3.079455893464855e-05, 'epoch': 1.152326463921087, 'step': 6398000}
INFO:transformers.trainer:{'loss': 3.0384942692518235, 'learning_rate': 3.079305804053591e-05, 'epoch': 1.1524165175678456, 'step': 6398500}
INFO:transformers.trainer:{'loss': 3.052690168142319, 'learning_rate': 3.0791557146423266e-05, 'epoch': 1.1525065712146039, 'step': 6399000}
INFO:transformers.trainer:{'loss': 3.0644117875099184, 'learning_rate': 3.0790056252310625e-05, 'epoch': 1.1525966248613624, 'step': 6399500}
INFO:transformers.trainer:{'loss': 3.0795025688409807, 'learning_rate': 3.0788555358197984e-05, 'epoch': 1.152686678508121, 'step': 6400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0876680154800416, 'learning_rate': 3.078705446408534e-05, 'epoch': 1.1527767321548792, 'step': 6400500}
INFO:transformers.trainer:{'loss': 3.098690509557724, 'learning_rate': 3.078555356997271e-05, 'epoch': 1.1528667858016377, 'step': 6401000}
INFO:transformers.trainer:{'loss': 3.0576531081199647, 'learning_rate': 3.078405267586006e-05, 'epoch': 1.1529568394483962, 'step': 6401500}
INFO:transformers.trainer:{'loss': 3.080080167889595, 'learning_rate': 3.078255178174743e-05, 'epoch': 1.1530468930951547, 'step': 6402000}
INFO:transformers.trainer:{'loss': 3.0208810309171676, 'learning_rate': 3.078105088763478e-05, 'epoch': 1.153136946741913, 'step': 6402500}
INFO:transformers.trainer:{'loss': 3.1128408691883087, 'learning_rate': 3.0779549993522145e-05, 'epoch': 1.1532270003886715, 'step': 6403000}
INFO:transformers.trainer:{'loss': 3.0781444981098174, 'learning_rate': 3.07780490994095e-05, 'epoch': 1.15331705403543, 'step': 6403500}
INFO:transformers.trainer:{'loss': 3.056810524702072, 'learning_rate': 3.077654820529686e-05, 'epoch': 1.1534071076821883, 'step': 6404000}
INFO:transformers.trainer:{'loss': 3.0500105345249175, 'learning_rate': 3.0775047311184216e-05, 'epoch': 1.1534971613289469, 'step': 6404500}
INFO:transformers.trainer:{'loss': 3.0401587510108947, 'learning_rate': 3.077354641707158e-05, 'epoch': 1.1535872149757054, 'step': 6405000}
INFO:transformers.trainer:{'loss': 3.027631112098694, 'learning_rate': 3.0772045522958934e-05, 'epoch': 1.153677268622464, 'step': 6405500}
INFO:transformers.trainer:{'loss': 3.065472421884537, 'learning_rate': 3.07705446288463e-05, 'epoch': 1.1537673222692222, 'step': 6406000}
INFO:transformers.trainer:{'loss': 3.020754157781601, 'learning_rate': 3.076904373473365e-05, 'epoch': 1.1538573759159807, 'step': 6406500}
INFO:transformers.trainer:{'loss': 3.066238356590271, 'learning_rate': 3.076754284062102e-05, 'epoch': 1.1539474295627392, 'step': 6407000}
INFO:transformers.trainer:{'loss': 3.0549679610729217, 'learning_rate': 3.076604194650837e-05, 'epoch': 1.1540374832094975, 'step': 6407500}
INFO:transformers.trainer:{'loss': 3.0399366283416747, 'learning_rate': 3.0764541052395736e-05, 'epoch': 1.154127536856256, 'step': 6408000}
INFO:transformers.trainer:{'loss': 3.069692966938019, 'learning_rate': 3.0763040158283095e-05, 'epoch': 1.1542175905030145, 'step': 6408500}
INFO:transformers.trainer:{'loss': 3.0338351858854296, 'learning_rate': 3.0761539264170454e-05, 'epoch': 1.1543076441497728, 'step': 6409000}
INFO:transformers.trainer:{'loss': 3.0063180627822876, 'learning_rate': 3.076003837005781e-05, 'epoch': 1.1543976977965313, 'step': 6409500}
INFO:transformers.trainer:{'loss': 3.075829196691513, 'learning_rate': 3.075853747594517e-05, 'epoch': 1.1544877514432899, 'step': 6410000}
INFO:transformers.trainer:{'loss': 3.1246346848011015, 'learning_rate': 3.075703658183253e-05, 'epoch': 1.1545778050900481, 'step': 6410500}
INFO:transformers.trainer:{'loss': 3.072477324485779, 'learning_rate': 3.075553568771989e-05, 'epoch': 1.1546678587368067, 'step': 6411000}
INFO:transformers.trainer:{'loss': 3.05544080889225, 'learning_rate': 3.075403479360725e-05, 'epoch': 1.1547579123835652, 'step': 6411500}
INFO:transformers.trainer:{'loss': 3.050349946498871, 'learning_rate': 3.075253389949461e-05, 'epoch': 1.1548479660303235, 'step': 6412000}
INFO:transformers.trainer:{'loss': 3.0058928176164628, 'learning_rate': 3.075103300538197e-05, 'epoch': 1.154938019677082, 'step': 6412500}
INFO:transformers.trainer:{'loss': 3.0775709083080294, 'learning_rate': 3.0749532111269326e-05, 'epoch': 1.1550280733238405, 'step': 6413000}
INFO:transformers.trainer:{'loss': 3.0740795094966886, 'learning_rate': 3.0748031217156685e-05, 'epoch': 1.155118126970599, 'step': 6413500}
INFO:transformers.trainer:{'loss': 3.102111653804779, 'learning_rate': 3.0746530323044044e-05, 'epoch': 1.1552081806173573, 'step': 6414000}
INFO:transformers.trainer:{'loss': 3.0065414590835573, 'learning_rate': 3.07450294289314e-05, 'epoch': 1.1552982342641158, 'step': 6414500}
INFO:transformers.trainer:{'loss': 3.0576852544546127, 'learning_rate': 3.074352853481877e-05, 'epoch': 1.1553882879108743, 'step': 6415000}
INFO:transformers.trainer:{'loss': 3.007482427954674, 'learning_rate': 3.074202764070612e-05, 'epoch': 1.1554783415576326, 'step': 6415500}
INFO:transformers.trainer:{'loss': 3.098193480730057, 'learning_rate': 3.074052674659349e-05, 'epoch': 1.1555683952043911, 'step': 6416000}
INFO:transformers.trainer:{'loss': 3.0982912232875823, 'learning_rate': 3.073902585248084e-05, 'epoch': 1.1556584488511497, 'step': 6416500}
INFO:transformers.trainer:{'loss': 3.119519677758217, 'learning_rate': 3.0737524958368205e-05, 'epoch': 1.1557485024979082, 'step': 6417000}
INFO:transformers.trainer:{'loss': 3.0857224750518797, 'learning_rate': 3.073602406425556e-05, 'epoch': 1.1558385561446665, 'step': 6417500}
INFO:transformers.trainer:{'loss': 3.066210056185722, 'learning_rate': 3.0734523170142923e-05, 'epoch': 1.155928609791425, 'step': 6418000}
INFO:transformers.trainer:{'loss': 3.099973421216011, 'learning_rate': 3.0733022276030276e-05, 'epoch': 1.1560186634381835, 'step': 6418500}
INFO:transformers.trainer:{'loss': 3.0540773849487306, 'learning_rate': 3.073152138191764e-05, 'epoch': 1.1561087170849418, 'step': 6419000}
INFO:transformers.trainer:{'loss': 3.0366375806331636, 'learning_rate': 3.0730020487804994e-05, 'epoch': 1.1561987707317003, 'step': 6419500}
INFO:transformers.trainer:{'loss': 3.0878255157470704, 'learning_rate': 3.072851959369236e-05, 'epoch': 1.1562888243784588, 'step': 6420000}
INFO:transformers.trainer:{'loss': 3.050437507390976, 'learning_rate': 3.072701869957971e-05, 'epoch': 1.156378878025217, 'step': 6420500}
INFO:transformers.trainer:{'loss': 2.9759225507974625, 'learning_rate': 3.072551780546708e-05, 'epoch': 1.1564689316719756, 'step': 6421000}
INFO:transformers.trainer:{'loss': 3.0669741312265395, 'learning_rate': 3.072401691135444e-05, 'epoch': 1.1565589853187341, 'step': 6421500}
INFO:transformers.trainer:{'loss': 3.0811331086158753, 'learning_rate': 3.0722516017241796e-05, 'epoch': 1.1566490389654924, 'step': 6422000}
INFO:transformers.trainer:{'loss': 3.001862541079521, 'learning_rate': 3.0721015123129155e-05, 'epoch': 1.156739092612251, 'step': 6422500}
INFO:transformers.trainer:{'loss': 3.080571928739548, 'learning_rate': 3.071951422901651e-05, 'epoch': 1.1568291462590095, 'step': 6423000}
INFO:transformers.trainer:{'loss': 3.0840073618888857, 'learning_rate': 3.071801333490387e-05, 'epoch': 1.1569191999057677, 'step': 6423500}
INFO:transformers.trainer:{'loss': 3.0840379633903505, 'learning_rate': 3.0716512440791225e-05, 'epoch': 1.1570092535525263, 'step': 6424000}
INFO:transformers.trainer:{'loss': 3.0586432826519014, 'learning_rate': 3.071501154667859e-05, 'epoch': 1.1570993071992848, 'step': 6424500}
INFO:transformers.trainer:{'loss': 3.0221627306938172, 'learning_rate': 3.0713510652565943e-05, 'epoch': 1.1571893608460433, 'step': 6425000}
INFO:transformers.trainer:{'loss': 3.124259996652603, 'learning_rate': 3.071200975845331e-05, 'epoch': 1.1572794144928016, 'step': 6425500}
INFO:transformers.trainer:{'loss': 3.018683372735977, 'learning_rate': 3.071050886434066e-05, 'epoch': 1.15736946813956, 'step': 6426000}
INFO:transformers.trainer:{'loss': 3.040743126869202, 'learning_rate': 3.070900797022803e-05, 'epoch': 1.1574595217863186, 'step': 6426500}
INFO:transformers.trainer:{'loss': 3.0638642172813415, 'learning_rate': 3.070750707611538e-05, 'epoch': 1.157549575433077, 'step': 6427000}
INFO:transformers.trainer:{'loss': 3.1049068603515626, 'learning_rate': 3.0706006182002745e-05, 'epoch': 1.1576396290798354, 'step': 6427500}
INFO:transformers.trainer:{'loss': 3.0437941961288453, 'learning_rate': 3.07045052878901e-05, 'epoch': 1.157729682726594, 'step': 6428000}
INFO:transformers.trainer:{'loss': 3.0623259720802305, 'learning_rate': 3.0703004393777464e-05, 'epoch': 1.1578197363733524, 'step': 6428500}
INFO:transformers.trainer:{'loss': 3.064448395252228, 'learning_rate': 3.070150349966482e-05, 'epoch': 1.1579097900201107, 'step': 6429000}
INFO:transformers.trainer:{'loss': 3.08032084274292, 'learning_rate': 3.070000260555218e-05, 'epoch': 1.1579998436668693, 'step': 6429500}
INFO:transformers.trainer:{'loss': 3.0479510653018953, 'learning_rate': 3.069850171143954e-05, 'epoch': 1.1580898973136278, 'step': 6430000}
INFO:transformers.trainer:{'loss': 3.0505048589706423, 'learning_rate': 3.06970008173269e-05, 'epoch': 1.158179950960386, 'step': 6430500}
INFO:transformers.trainer:{'loss': 3.046656291246414, 'learning_rate': 3.069549992321426e-05, 'epoch': 1.1582700046071446, 'step': 6431000}
INFO:transformers.trainer:{'loss': 3.043866162776947, 'learning_rate': 3.069399902910162e-05, 'epoch': 1.158360058253903, 'step': 6431500}
INFO:transformers.trainer:{'loss': 3.141565993309021, 'learning_rate': 3.069249813498898e-05, 'epoch': 1.1584501119006614, 'step': 6432000}
INFO:transformers.trainer:{'loss': 3.0643563582897184, 'learning_rate': 3.0690997240876336e-05, 'epoch': 1.15854016554742, 'step': 6432500}
INFO:transformers.trainer:{'loss': 3.098984017133713, 'learning_rate': 3.0689496346763695e-05, 'epoch': 1.1586302191941784, 'step': 6433000}
INFO:transformers.trainer:{'loss': 3.029099427700043, 'learning_rate': 3.0687995452651054e-05, 'epoch': 1.1587202728409367, 'step': 6433500}
INFO:transformers.trainer:{'loss': 3.089414671421051, 'learning_rate': 3.068649455853841e-05, 'epoch': 1.1588103264876952, 'step': 6434000}
INFO:transformers.trainer:{'loss': 3.047852866649628, 'learning_rate': 3.068499366442577e-05, 'epoch': 1.1589003801344537, 'step': 6434500}
INFO:transformers.trainer:{'loss': 3.085218507409096, 'learning_rate': 3.068349277031313e-05, 'epoch': 1.158990433781212, 'step': 6435000}
INFO:transformers.trainer:{'loss': 3.079227945804596, 'learning_rate': 3.06819918762005e-05, 'epoch': 1.1590804874279705, 'step': 6435500}
INFO:transformers.trainer:{'loss': 3.0426987850666047, 'learning_rate': 3.068049098208785e-05, 'epoch': 1.159170541074729, 'step': 6436000}
INFO:transformers.trainer:{'loss': 3.038825167417526, 'learning_rate': 3.0678990087975215e-05, 'epoch': 1.1592605947214876, 'step': 6436500}
INFO:transformers.trainer:{'loss': 3.0316084928512574, 'learning_rate': 3.067748919386257e-05, 'epoch': 1.1593506483682459, 'step': 6437000}
INFO:transformers.trainer:{'loss': 3.0565627676248552, 'learning_rate': 3.067598829974993e-05, 'epoch': 1.1594407020150044, 'step': 6437500}
INFO:transformers.trainer:{'loss': 3.067082786798477, 'learning_rate': 3.0674487405637285e-05, 'epoch': 1.159530755661763, 'step': 6438000}
INFO:transformers.trainer:{'loss': 3.088448830842972, 'learning_rate': 3.067298651152465e-05, 'epoch': 1.1596208093085212, 'step': 6438500}
INFO:transformers.trainer:{'loss': 3.0487261900901794, 'learning_rate': 3.0671485617412004e-05, 'epoch': 1.1597108629552797, 'step': 6439000}
INFO:transformers.trainer:{'loss': 3.066550792217255, 'learning_rate': 3.066998472329937e-05, 'epoch': 1.1598009166020382, 'step': 6439500}
INFO:transformers.trainer:{'loss': 3.0212447494268417, 'learning_rate': 3.066848382918672e-05, 'epoch': 1.1598909702487967, 'step': 6440000}
INFO:transformers.trainer:{'loss': 3.0545545777082443, 'learning_rate': 3.066698293507409e-05, 'epoch': 1.159981023895555, 'step': 6440500}
INFO:transformers.trainer:{'loss': 3.128785796880722, 'learning_rate': 3.066548204096144e-05, 'epoch': 1.1600710775423135, 'step': 6441000}
INFO:transformers.trainer:{'loss': 3.0031694687604906, 'learning_rate': 3.0663981146848806e-05, 'epoch': 1.160161131189072, 'step': 6441500}
INFO:transformers.trainer:{'loss': 3.0805770219564437, 'learning_rate': 3.066248025273616e-05, 'epoch': 1.1602511848358303, 'step': 6442000}
INFO:transformers.trainer:{'loss': 3.1355948705673216, 'learning_rate': 3.0660979358623524e-05, 'epoch': 1.1603412384825889, 'step': 6442500}
INFO:transformers.trainer:{'loss': 3.1026312239170073, 'learning_rate': 3.065947846451088e-05, 'epoch': 1.1604312921293474, 'step': 6443000}
INFO:transformers.trainer:{'loss': 3.0507089762687682, 'learning_rate': 3.065797757039824e-05, 'epoch': 1.1605213457761057, 'step': 6443500}
INFO:transformers.trainer:{'loss': 2.9943626880645753, 'learning_rate': 3.06564766762856e-05, 'epoch': 1.1606113994228642, 'step': 6444000}
INFO:transformers.trainer:{'loss': 3.078632367134094, 'learning_rate': 3.065497578217296e-05, 'epoch': 1.1607014530696227, 'step': 6444500}
INFO:transformers.trainer:{'loss': 3.0204444448947907, 'learning_rate': 3.065347488806032e-05, 'epoch': 1.160791506716381, 'step': 6445000}
INFO:transformers.trainer:{'loss': 3.044538465976715, 'learning_rate': 3.065197399394768e-05, 'epoch': 1.1608815603631395, 'step': 6445500}
INFO:transformers.trainer:{'loss': 3.075207422733307, 'learning_rate': 3.065047309983504e-05, 'epoch': 1.160971614009898, 'step': 6446000}
INFO:transformers.trainer:{'loss': 3.006234235525131, 'learning_rate': 3.064897220572239e-05, 'epoch': 1.1610616676566563, 'step': 6446500}
INFO:transformers.trainer:{'loss': 3.031122615814209, 'learning_rate': 3.0647471311609755e-05, 'epoch': 1.1611517213034148, 'step': 6447000}
INFO:transformers.trainer:{'loss': 2.9999326913356783, 'learning_rate': 3.064597041749711e-05, 'epoch': 1.1612417749501733, 'step': 6447500}
INFO:transformers.trainer:{'loss': 3.059769447803497, 'learning_rate': 3.064446952338447e-05, 'epoch': 1.1613318285969318, 'step': 6448000}
INFO:transformers.trainer:{'loss': 3.0401739373207093, 'learning_rate': 3.0642968629271826e-05, 'epoch': 1.1614218822436901, 'step': 6448500}
INFO:transformers.trainer:{'loss': 3.094321526885033, 'learning_rate': 3.064146773515919e-05, 'epoch': 1.1615119358904487, 'step': 6449000}
INFO:transformers.trainer:{'loss': 3.05409855902195, 'learning_rate': 3.063996684104655e-05, 'epoch': 1.1616019895372072, 'step': 6449500}
INFO:transformers.trainer:{'loss': 3.106425949692726, 'learning_rate': 3.063846594693391e-05, 'epoch': 1.1616920431839655, 'step': 6450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0406201729774476, 'learning_rate': 3.063696505282127e-05, 'epoch': 1.161782096830724, 'step': 6450500}
INFO:transformers.trainer:{'loss': 3.059430766582489, 'learning_rate': 3.063546415870863e-05, 'epoch': 1.1618721504774825, 'step': 6451000}
INFO:transformers.trainer:{'loss': 3.026564776659012, 'learning_rate': 3.063396326459599e-05, 'epoch': 1.161962204124241, 'step': 6451500}
INFO:transformers.trainer:{'loss': 3.06026097548008, 'learning_rate': 3.0632462370483346e-05, 'epoch': 1.1620522577709993, 'step': 6452000}
INFO:transformers.trainer:{'loss': 3.106715081691742, 'learning_rate': 3.0630961476370705e-05, 'epoch': 1.1621423114177578, 'step': 6452500}
INFO:transformers.trainer:{'loss': 3.0631242288351057, 'learning_rate': 3.0629460582258064e-05, 'epoch': 1.1622323650645163, 'step': 6453000}
INFO:transformers.trainer:{'loss': 3.0544180989265444, 'learning_rate': 3.062795968814542e-05, 'epoch': 1.1623224187112746, 'step': 6453500}
INFO:transformers.trainer:{'loss': 3.1077463395595553, 'learning_rate': 3.062645879403278e-05, 'epoch': 1.1624124723580331, 'step': 6454000}
INFO:transformers.trainer:{'loss': 3.0570041656494142, 'learning_rate': 3.062495789992014e-05, 'epoch': 1.1625025260047916, 'step': 6454500}
INFO:transformers.trainer:{'loss': 3.0288430502414703, 'learning_rate': 3.06234570058075e-05, 'epoch': 1.16259257965155, 'step': 6455000}
INFO:transformers.trainer:{'loss': 3.051474024295807, 'learning_rate': 3.062195611169486e-05, 'epoch': 1.1626826332983085, 'step': 6455500}
INFO:transformers.trainer:{'loss': 3.0074414039850237, 'learning_rate': 3.062045521758222e-05, 'epoch': 1.162772686945067, 'step': 6456000}
INFO:transformers.trainer:{'loss': 3.0907917931079862, 'learning_rate': 3.061895432346958e-05, 'epoch': 1.1628627405918253, 'step': 6456500}
INFO:transformers.trainer:{'loss': 2.9886311144828794, 'learning_rate': 3.061745342935694e-05, 'epoch': 1.1629527942385838, 'step': 6457000}
INFO:transformers.trainer:{'loss': 2.972161156177521, 'learning_rate': 3.0615952535244295e-05, 'epoch': 1.1630428478853423, 'step': 6457500}
INFO:transformers.trainer:{'loss': 3.0408779405355455, 'learning_rate': 3.061445164113166e-05, 'epoch': 1.1631329015321006, 'step': 6458000}
INFO:transformers.trainer:{'loss': 3.0674904326200485, 'learning_rate': 3.061295074701901e-05, 'epoch': 1.163222955178859, 'step': 6458500}
INFO:transformers.trainer:{'loss': 3.038713219165802, 'learning_rate': 3.061144985290638e-05, 'epoch': 1.1633130088256176, 'step': 6459000}
INFO:transformers.trainer:{'loss': 3.1270976259708405, 'learning_rate': 3.060994895879373e-05, 'epoch': 1.1634030624723761, 'step': 6459500}
INFO:transformers.trainer:{'loss': 3.0803863669633866, 'learning_rate': 3.06084480646811e-05, 'epoch': 1.1634931161191344, 'step': 6460000}
INFO:transformers.trainer:{'loss': 3.082909462928772, 'learning_rate': 3.060694717056845e-05, 'epoch': 1.163583169765893, 'step': 6460500}
INFO:transformers.trainer:{'loss': 3.059739905834198, 'learning_rate': 3.0605446276455815e-05, 'epoch': 1.1636732234126514, 'step': 6461000}
INFO:transformers.trainer:{'loss': 3.0478702313899992, 'learning_rate': 3.060394538234317e-05, 'epoch': 1.1637632770594097, 'step': 6461500}
INFO:transformers.trainer:{'loss': 3.128224020242691, 'learning_rate': 3.0602444488230533e-05, 'epoch': 1.1638533307061683, 'step': 6462000}
INFO:transformers.trainer:{'loss': 3.032145181059837, 'learning_rate': 3.0600943594117886e-05, 'epoch': 1.1639433843529268, 'step': 6462500}
INFO:transformers.trainer:{'loss': 3.0756168875694274, 'learning_rate': 3.059944270000525e-05, 'epoch': 1.1640334379996853, 'step': 6463000}
INFO:transformers.trainer:{'loss': 3.0166385102272035, 'learning_rate': 3.059794180589261e-05, 'epoch': 1.1641234916464436, 'step': 6463500}
INFO:transformers.trainer:{'loss': 3.03832963180542, 'learning_rate': 3.059644091177997e-05, 'epoch': 1.164213545293202, 'step': 6464000}
INFO:transformers.trainer:{'loss': 3.104898272275925, 'learning_rate': 3.059494001766733e-05, 'epoch': 1.1643035989399606, 'step': 6464500}
INFO:transformers.trainer:{'loss': 3.072719322681427, 'learning_rate': 3.059343912355469e-05, 'epoch': 1.164393652586719, 'step': 6465000}
INFO:transformers.trainer:{'loss': 3.0285243200063707, 'learning_rate': 3.059193822944205e-05, 'epoch': 1.1644837062334774, 'step': 6465500}
INFO:transformers.trainer:{'loss': 2.978908224105835, 'learning_rate': 3.0590437335329406e-05, 'epoch': 1.164573759880236, 'step': 6466000}
INFO:transformers.trainer:{'loss': 3.0929093039035798, 'learning_rate': 3.0588936441216765e-05, 'epoch': 1.1646638135269942, 'step': 6466500}
INFO:transformers.trainer:{'loss': 3.0519409157037733, 'learning_rate': 3.0587435547104124e-05, 'epoch': 1.1647538671737527, 'step': 6467000}
INFO:transformers.trainer:{'loss': 3.013340710878372, 'learning_rate': 3.058593465299148e-05, 'epoch': 1.1648439208205112, 'step': 6467500}
INFO:transformers.trainer:{'loss': 3.0737102346420286, 'learning_rate': 3.058443375887884e-05, 'epoch': 1.1649339744672695, 'step': 6468000}
INFO:transformers.trainer:{'loss': 3.0494525554180147, 'learning_rate': 3.05829328647662e-05, 'epoch': 1.165024028114028, 'step': 6468500}
INFO:transformers.trainer:{'loss': 2.972209468364716, 'learning_rate': 3.058143197065356e-05, 'epoch': 1.1651140817607866, 'step': 6469000}
INFO:transformers.trainer:{'loss': 3.069041190862656, 'learning_rate': 3.057993107654092e-05, 'epoch': 1.1652041354075449, 'step': 6469500}
INFO:transformers.trainer:{'loss': 3.052597597837448, 'learning_rate': 3.057843018242828e-05, 'epoch': 1.1652941890543034, 'step': 6470000}
INFO:transformers.trainer:{'loss': 3.0576379120349886, 'learning_rate': 3.057692928831564e-05, 'epoch': 1.165384242701062, 'step': 6470500}
INFO:transformers.trainer:{'loss': 3.0916659293174744, 'learning_rate': 3.0575428394202996e-05, 'epoch': 1.1654742963478204, 'step': 6471000}
INFO:transformers.trainer:{'loss': 2.999897579193115, 'learning_rate': 3.0573927500090355e-05, 'epoch': 1.1655643499945787, 'step': 6471500}
INFO:transformers.trainer:{'loss': 3.0626873543262483, 'learning_rate': 3.0572426605977714e-05, 'epoch': 1.1656544036413372, 'step': 6472000}
INFO:transformers.trainer:{'loss': 3.1436210098266604, 'learning_rate': 3.0570925711865073e-05, 'epoch': 1.1657444572880957, 'step': 6472500}
INFO:transformers.trainer:{'loss': 3.0197337445020676, 'learning_rate': 3.056942481775243e-05, 'epoch': 1.165834510934854, 'step': 6473000}
INFO:transformers.trainer:{'loss': 3.094274038434029, 'learning_rate': 3.056792392363979e-05, 'epoch': 1.1659245645816125, 'step': 6473500}
INFO:transformers.trainer:{'loss': 3.1269538385868074, 'learning_rate': 3.056642302952715e-05, 'epoch': 1.166014618228371, 'step': 6474000}
INFO:transformers.trainer:{'loss': 3.0922973310947417, 'learning_rate': 3.056492213541451e-05, 'epoch': 1.1661046718751296, 'step': 6474500}
INFO:transformers.trainer:{'loss': 3.101427348613739, 'learning_rate': 3.056342124130187e-05, 'epoch': 1.1661947255218879, 'step': 6475000}
INFO:transformers.trainer:{'loss': 3.152274685740471, 'learning_rate': 3.056192034718923e-05, 'epoch': 1.1662847791686464, 'step': 6475500}
INFO:transformers.trainer:{'loss': 3.111534087598324, 'learning_rate': 3.056041945307659e-05, 'epoch': 1.1663748328154049, 'step': 6476000}
INFO:transformers.trainer:{'loss': 3.081406298279762, 'learning_rate': 3.0558918558963946e-05, 'epoch': 1.1664648864621632, 'step': 6476500}
INFO:transformers.trainer:{'loss': 3.071635801553726, 'learning_rate': 3.0557417664851305e-05, 'epoch': 1.1665549401089217, 'step': 6477000}
INFO:transformers.trainer:{'loss': 3.067469979763031, 'learning_rate': 3.055591677073867e-05, 'epoch': 1.1666449937556802, 'step': 6477500}
INFO:transformers.trainer:{'loss': 3.064062137365341, 'learning_rate': 3.055441587662602e-05, 'epoch': 1.1667350474024385, 'step': 6478000}
INFO:transformers.trainer:{'loss': 3.0579787220954895, 'learning_rate': 3.055291498251339e-05, 'epoch': 1.166825101049197, 'step': 6478500}
INFO:transformers.trainer:{'loss': 3.066449640393257, 'learning_rate': 3.055141408840074e-05, 'epoch': 1.1669151546959555, 'step': 6479000}
INFO:transformers.trainer:{'loss': 3.080058430433273, 'learning_rate': 3.054991319428811e-05, 'epoch': 1.1670052083427138, 'step': 6479500}
INFO:transformers.trainer:{'loss': 3.081432014465332, 'learning_rate': 3.054841230017546e-05, 'epoch': 1.1670952619894723, 'step': 6480000}
INFO:transformers.trainer:{'loss': 3.0364630246162414, 'learning_rate': 3.0546911406062825e-05, 'epoch': 1.1671853156362308, 'step': 6480500}
INFO:transformers.trainer:{'loss': 3.043274915456772, 'learning_rate': 3.054541051195018e-05, 'epoch': 1.1672753692829891, 'step': 6481000}
INFO:transformers.trainer:{'loss': 3.0308739401102067, 'learning_rate': 3.054390961783754e-05, 'epoch': 1.1673654229297477, 'step': 6481500}
INFO:transformers.trainer:{'loss': 3.062071106672287, 'learning_rate': 3.0542408723724895e-05, 'epoch': 1.1674554765765062, 'step': 6482000}
INFO:transformers.trainer:{'loss': 3.0798935998678205, 'learning_rate': 3.054090782961226e-05, 'epoch': 1.1675455302232647, 'step': 6482500}
INFO:transformers.trainer:{'loss': 3.0390879759788514, 'learning_rate': 3.0539406935499614e-05, 'epoch': 1.167635583870023, 'step': 6483000}
INFO:transformers.trainer:{'loss': 3.0066189068853855, 'learning_rate': 3.053790604138698e-05, 'epoch': 1.1677256375167815, 'step': 6483500}
INFO:transformers.trainer:{'loss': 3.036547464966774, 'learning_rate': 3.053640514727434e-05, 'epoch': 1.16781569116354, 'step': 6484000}
INFO:transformers.trainer:{'loss': 3.0512723100185393, 'learning_rate': 3.05349042531617e-05, 'epoch': 1.1679057448102983, 'step': 6484500}
INFO:transformers.trainer:{'loss': 3.0367509973049165, 'learning_rate': 3.0533403359049057e-05, 'epoch': 1.1679957984570568, 'step': 6485000}
INFO:transformers.trainer:{'loss': 3.045851271390915, 'learning_rate': 3.0531902464936416e-05, 'epoch': 1.1680858521038153, 'step': 6485500}
INFO:transformers.trainer:{'loss': 3.0672112538814544, 'learning_rate': 3.0530401570823775e-05, 'epoch': 1.1681759057505738, 'step': 6486000}
INFO:transformers.trainer:{'loss': 3.063597939491272, 'learning_rate': 3.0528900676711134e-05, 'epoch': 1.1682659593973321, 'step': 6486500}
INFO:transformers.trainer:{'loss': 3.0609264842271804, 'learning_rate': 3.052739978259849e-05, 'epoch': 1.1683560130440906, 'step': 6487000}
INFO:transformers.trainer:{'loss': 2.9877702174186704, 'learning_rate': 3.052589888848585e-05, 'epoch': 1.1684460666908492, 'step': 6487500}
INFO:transformers.trainer:{'loss': 3.1070104739665987, 'learning_rate': 3.052439799437321e-05, 'epoch': 1.1685361203376075, 'step': 6488000}
INFO:transformers.trainer:{'loss': 3.025451280593872, 'learning_rate': 3.052289710026057e-05, 'epoch': 1.168626173984366, 'step': 6488500}
INFO:transformers.trainer:{'loss': 3.0811700283288954, 'learning_rate': 3.052139620614793e-05, 'epoch': 1.1687162276311245, 'step': 6489000}
INFO:transformers.trainer:{'loss': 3.0443960003852846, 'learning_rate': 3.051989531203529e-05, 'epoch': 1.1688062812778828, 'step': 6489500}
INFO:transformers.trainer:{'loss': 3.0131908910274507, 'learning_rate': 3.051839441792265e-05, 'epoch': 1.1688963349246413, 'step': 6490000}
INFO:transformers.trainer:{'loss': 3.0591987777948377, 'learning_rate': 3.0516893523810003e-05, 'epoch': 1.1689863885713998, 'step': 6490500}
INFO:transformers.trainer:{'loss': 3.11443160033226, 'learning_rate': 3.0515392629697365e-05, 'epoch': 1.169076442218158, 'step': 6491000}
INFO:transformers.trainer:{'loss': 3.0393939707279207, 'learning_rate': 3.0513891735584728e-05, 'epoch': 1.1691664958649166, 'step': 6491500}
INFO:transformers.trainer:{'loss': 3.0105529934167863, 'learning_rate': 3.0512390841472083e-05, 'epoch': 1.1692565495116751, 'step': 6492000}
INFO:transformers.trainer:{'loss': 3.019818761587143, 'learning_rate': 3.0510889947359446e-05, 'epoch': 1.1693466031584334, 'step': 6492500}
INFO:transformers.trainer:{'loss': 3.0486272327899933, 'learning_rate': 3.05093890532468e-05, 'epoch': 1.169436656805192, 'step': 6493000}
INFO:transformers.trainer:{'loss': 2.9536969006061553, 'learning_rate': 3.0507888159134164e-05, 'epoch': 1.1695267104519504, 'step': 6493500}
INFO:transformers.trainer:{'loss': 3.015604493021965, 'learning_rate': 3.050638726502152e-05, 'epoch': 1.169616764098709, 'step': 6494000}
INFO:transformers.trainer:{'loss': 3.027883357048035, 'learning_rate': 3.0504886370908882e-05, 'epoch': 1.1697068177454673, 'step': 6494500}
INFO:transformers.trainer:{'loss': 3.0143380668163298, 'learning_rate': 3.0503385476796238e-05, 'epoch': 1.1697968713922258, 'step': 6495000}
INFO:transformers.trainer:{'loss': 3.0637601761817934, 'learning_rate': 3.05018845826836e-05, 'epoch': 1.1698869250389843, 'step': 6495500}
INFO:transformers.trainer:{'loss': 3.0473562376499177, 'learning_rate': 3.0500383688570956e-05, 'epoch': 1.1699769786857426, 'step': 6496000}
INFO:transformers.trainer:{'loss': 3.0766554205417633, 'learning_rate': 3.0498882794458318e-05, 'epoch': 1.170067032332501, 'step': 6496500}
INFO:transformers.trainer:{'loss': 3.0530472044944763, 'learning_rate': 3.0497381900345674e-05, 'epoch': 1.1701570859792596, 'step': 6497000}
INFO:transformers.trainer:{'loss': 3.030511247873306, 'learning_rate': 3.0495881006233036e-05, 'epoch': 1.1702471396260181, 'step': 6497500}
INFO:transformers.trainer:{'loss': 3.041973474264145, 'learning_rate': 3.0494380112120395e-05, 'epoch': 1.1703371932727764, 'step': 6498000}
INFO:transformers.trainer:{'loss': 3.0343325392007827, 'learning_rate': 3.0492879218007754e-05, 'epoch': 1.170427246919535, 'step': 6498500}
INFO:transformers.trainer:{'loss': 3.063820620059967, 'learning_rate': 3.0491378323895113e-05, 'epoch': 1.1705173005662934, 'step': 6499000}
INFO:transformers.trainer:{'loss': 3.02181702375412, 'learning_rate': 3.0489877429782472e-05, 'epoch': 1.1706073542130517, 'step': 6499500}
INFO:transformers.trainer:{'loss': 3.0323251020908355, 'learning_rate': 3.048837653566983e-05, 'epoch': 1.1706974078598102, 'step': 6500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.142205436706543, 'learning_rate': 3.048687564155719e-05, 'epoch': 1.1707874615065688, 'step': 6500500}
INFO:transformers.trainer:{'loss': 3.024239398956299, 'learning_rate': 3.048537474744455e-05, 'epoch': 1.170877515153327, 'step': 6501000}
INFO:transformers.trainer:{'loss': 3.0334266068935394, 'learning_rate': 3.0483873853331905e-05, 'epoch': 1.1709675688000856, 'step': 6501500}
INFO:transformers.trainer:{'loss': 3.0831022417545317, 'learning_rate': 3.0482372959219268e-05, 'epoch': 1.171057622446844, 'step': 6502000}
INFO:transformers.trainer:{'loss': 3.0390343054533004, 'learning_rate': 3.0480872065106623e-05, 'epoch': 1.1711476760936024, 'step': 6502500}
INFO:transformers.trainer:{'loss': 3.0284305367469786, 'learning_rate': 3.0479371170993986e-05, 'epoch': 1.1712377297403609, 'step': 6503000}
INFO:transformers.trainer:{'loss': 3.064936646938324, 'learning_rate': 3.047787027688134e-05, 'epoch': 1.1713277833871194, 'step': 6503500}
INFO:transformers.trainer:{'loss': 3.041834352850914, 'learning_rate': 3.0476369382768704e-05, 'epoch': 1.171417837033878, 'step': 6504000}
INFO:transformers.trainer:{'loss': 3.0181264679431914, 'learning_rate': 3.047486848865606e-05, 'epoch': 1.1715078906806362, 'step': 6504500}
INFO:transformers.trainer:{'loss': 3.0727277828454973, 'learning_rate': 3.0473367594543422e-05, 'epoch': 1.1715979443273947, 'step': 6505000}
INFO:transformers.trainer:{'loss': 3.09401247382164, 'learning_rate': 3.0471866700430784e-05, 'epoch': 1.1716879979741532, 'step': 6505500}
INFO:transformers.trainer:{'loss': 3.069144568681717, 'learning_rate': 3.047036580631814e-05, 'epoch': 1.1717780516209115, 'step': 6506000}
INFO:transformers.trainer:{'loss': 3.0719862813949583, 'learning_rate': 3.0468864912205502e-05, 'epoch': 1.17186810526767, 'step': 6506500}
INFO:transformers.trainer:{'loss': 3.1449691268205644, 'learning_rate': 3.0467364018092858e-05, 'epoch': 1.1719581589144286, 'step': 6507000}
INFO:transformers.trainer:{'loss': 3.060192207098007, 'learning_rate': 3.046586312398022e-05, 'epoch': 1.172048212561187, 'step': 6507500}
INFO:transformers.trainer:{'loss': 3.066966913819313, 'learning_rate': 3.0464362229867576e-05, 'epoch': 1.1721382662079454, 'step': 6508000}
INFO:transformers.trainer:{'loss': 3.1145191385746003, 'learning_rate': 3.046286133575494e-05, 'epoch': 1.1722283198547039, 'step': 6508500}
INFO:transformers.trainer:{'loss': 3.0548844856843353, 'learning_rate': 3.0461360441642294e-05, 'epoch': 1.1723183735014624, 'step': 6509000}
INFO:transformers.trainer:{'loss': 3.049705696940422, 'learning_rate': 3.0459859547529657e-05, 'epoch': 1.1724084271482207, 'step': 6509500}
INFO:transformers.trainer:{'loss': 3.127502074718475, 'learning_rate': 3.0458358653417012e-05, 'epoch': 1.1724984807949792, 'step': 6510000}
INFO:transformers.trainer:{'loss': 3.0604304735660555, 'learning_rate': 3.0456857759304375e-05, 'epoch': 1.1725885344417377, 'step': 6510500}
INFO:transformers.trainer:{'loss': 3.016350145339966, 'learning_rate': 3.045535686519173e-05, 'epoch': 1.172678588088496, 'step': 6511000}
INFO:transformers.trainer:{'loss': 3.078451975822449, 'learning_rate': 3.0453855971079093e-05, 'epoch': 1.1727686417352545, 'step': 6511500}
INFO:transformers.trainer:{'loss': 3.0536507556438446, 'learning_rate': 3.0452355076966455e-05, 'epoch': 1.172858695382013, 'step': 6512000}
INFO:transformers.trainer:{'loss': 3.0732799990177155, 'learning_rate': 3.045085418285381e-05, 'epoch': 1.1729487490287713, 'step': 6512500}
INFO:transformers.trainer:{'loss': 2.993228324890137, 'learning_rate': 3.0449353288741173e-05, 'epoch': 1.1730388026755298, 'step': 6513000}
INFO:transformers.trainer:{'loss': 3.066436285018921, 'learning_rate': 3.044785239462853e-05, 'epoch': 1.1731288563222884, 'step': 6513500}
INFO:transformers.trainer:{'loss': 3.07072763299942, 'learning_rate': 3.044635150051589e-05, 'epoch': 1.1732189099690467, 'step': 6514000}
INFO:transformers.trainer:{'loss': 3.08146053981781, 'learning_rate': 3.0444850606403247e-05, 'epoch': 1.1733089636158052, 'step': 6514500}
INFO:transformers.trainer:{'loss': 3.124194492459297, 'learning_rate': 3.044334971229061e-05, 'epoch': 1.1733990172625637, 'step': 6515000}
INFO:transformers.trainer:{'loss': 3.017671131849289, 'learning_rate': 3.0441848818177965e-05, 'epoch': 1.1734890709093222, 'step': 6515500}
INFO:transformers.trainer:{'loss': 3.086508594751358, 'learning_rate': 3.0440347924065328e-05, 'epoch': 1.1735791245560805, 'step': 6516000}
INFO:transformers.trainer:{'loss': 3.05547955930233, 'learning_rate': 3.0438847029952683e-05, 'epoch': 1.173669178202839, 'step': 6516500}
INFO:transformers.trainer:{'loss': 3.036568108558655, 'learning_rate': 3.0437346135840046e-05, 'epoch': 1.1737592318495975, 'step': 6517000}
INFO:transformers.trainer:{'loss': 3.0662235876321793, 'learning_rate': 3.04358452417274e-05, 'epoch': 1.1738492854963558, 'step': 6517500}
INFO:transformers.trainer:{'loss': 3.1005466377735136, 'learning_rate': 3.0434344347614764e-05, 'epoch': 1.1739393391431143, 'step': 6518000}
INFO:transformers.trainer:{'loss': 3.0691874064207076, 'learning_rate': 3.0432843453502123e-05, 'epoch': 1.1740293927898728, 'step': 6518500}
INFO:transformers.trainer:{'loss': 3.037189810037613, 'learning_rate': 3.0431342559389482e-05, 'epoch': 1.1741194464366314, 'step': 6519000}
INFO:transformers.trainer:{'loss': 3.024150898218155, 'learning_rate': 3.042984166527684e-05, 'epoch': 1.1742095000833896, 'step': 6519500}
INFO:transformers.trainer:{'loss': 3.0474507575035097, 'learning_rate': 3.04283407711642e-05, 'epoch': 1.1742995537301482, 'step': 6520000}
INFO:transformers.trainer:{'loss': 3.073048166036606, 'learning_rate': 3.042683987705156e-05, 'epoch': 1.1743896073769067, 'step': 6520500}
INFO:transformers.trainer:{'loss': 3.057283038377762, 'learning_rate': 3.0425338982938918e-05, 'epoch': 1.174479661023665, 'step': 6521000}
INFO:transformers.trainer:{'loss': 3.009134306907654, 'learning_rate': 3.0423838088826277e-05, 'epoch': 1.1745697146704235, 'step': 6521500}
INFO:transformers.trainer:{'loss': 3.126181749343872, 'learning_rate': 3.0422337194713636e-05, 'epoch': 1.174659768317182, 'step': 6522000}
INFO:transformers.trainer:{'loss': 3.021494300842285, 'learning_rate': 3.0420836300600995e-05, 'epoch': 1.1747498219639403, 'step': 6522500}
INFO:transformers.trainer:{'loss': 3.045076722383499, 'learning_rate': 3.0419335406488354e-05, 'epoch': 1.1748398756106988, 'step': 6523000}
INFO:transformers.trainer:{'loss': 3.066816320180893, 'learning_rate': 3.0417834512375714e-05, 'epoch': 1.1749299292574573, 'step': 6523500}
INFO:transformers.trainer:{'loss': 3.0537192804813387, 'learning_rate': 3.0416333618263073e-05, 'epoch': 1.1750199829042156, 'step': 6524000}
INFO:transformers.trainer:{'loss': 3.115820081114769, 'learning_rate': 3.041483272415043e-05, 'epoch': 1.1751100365509741, 'step': 6524500}
INFO:transformers.trainer:{'loss': 2.996882502436638, 'learning_rate': 3.0413331830037787e-05, 'epoch': 1.1752000901977326, 'step': 6525000}
INFO:transformers.trainer:{'loss': 3.051264483451843, 'learning_rate': 3.041183093592515e-05, 'epoch': 1.175290143844491, 'step': 6525500}
INFO:transformers.trainer:{'loss': 3.042516724348068, 'learning_rate': 3.0410330041812512e-05, 'epoch': 1.1753801974912494, 'step': 6526000}
INFO:transformers.trainer:{'loss': 3.0023793267011643, 'learning_rate': 3.0408829147699868e-05, 'epoch': 1.175470251138008, 'step': 6526500}
INFO:transformers.trainer:{'loss': 3.0998222970962526, 'learning_rate': 3.040732825358723e-05, 'epoch': 1.1755603047847665, 'step': 6527000}
INFO:transformers.trainer:{'loss': 3.0637453105449675, 'learning_rate': 3.0405827359474586e-05, 'epoch': 1.1756503584315248, 'step': 6527500}
INFO:transformers.trainer:{'loss': 3.0697721843719483, 'learning_rate': 3.040432646536195e-05, 'epoch': 1.1757404120782833, 'step': 6528000}
INFO:transformers.trainer:{'loss': 3.036370764493942, 'learning_rate': 3.0402825571249304e-05, 'epoch': 1.1758304657250418, 'step': 6528500}
INFO:transformers.trainer:{'loss': 3.053089845061302, 'learning_rate': 3.0401324677136666e-05, 'epoch': 1.1759205193718, 'step': 6529000}
INFO:transformers.trainer:{'loss': 3.050389578342438, 'learning_rate': 3.0399823783024022e-05, 'epoch': 1.1760105730185586, 'step': 6529500}
INFO:transformers.trainer:{'loss': 3.0172074074745177, 'learning_rate': 3.0398322888911385e-05, 'epoch': 1.1761006266653171, 'step': 6530000}
INFO:transformers.trainer:{'loss': 3.0580466042757033, 'learning_rate': 3.039682199479874e-05, 'epoch': 1.1761906803120756, 'step': 6530500}
INFO:transformers.trainer:{'loss': 2.993201197862625, 'learning_rate': 3.0395321100686103e-05, 'epoch': 1.176280733958834, 'step': 6531000}
INFO:transformers.trainer:{'loss': 3.076716310739517, 'learning_rate': 3.039382020657346e-05, 'epoch': 1.1763707876055924, 'step': 6531500}
INFO:transformers.trainer:{'loss': 3.070719382047653, 'learning_rate': 3.039231931246082e-05, 'epoch': 1.176460841252351, 'step': 6532000}
INFO:transformers.trainer:{'loss': 3.037868391752243, 'learning_rate': 3.0390818418348183e-05, 'epoch': 1.1765508948991092, 'step': 6532500}
INFO:transformers.trainer:{'loss': 3.078471791267395, 'learning_rate': 3.038931752423554e-05, 'epoch': 1.1766409485458678, 'step': 6533000}
INFO:transformers.trainer:{'loss': 3.0180883519649506, 'learning_rate': 3.03878166301229e-05, 'epoch': 1.1767310021926263, 'step': 6533500}
INFO:transformers.trainer:{'loss': 3.036225456237793, 'learning_rate': 3.0386315736010257e-05, 'epoch': 1.1768210558393846, 'step': 6534000}
INFO:transformers.trainer:{'loss': 3.021861129462719, 'learning_rate': 3.038481484189762e-05, 'epoch': 1.176911109486143, 'step': 6534500}
INFO:transformers.trainer:{'loss': 2.994990495681763, 'learning_rate': 3.0383313947784975e-05, 'epoch': 1.1770011631329016, 'step': 6535000}
INFO:transformers.trainer:{'loss': 3.159029679775238, 'learning_rate': 3.0381813053672338e-05, 'epoch': 1.1770912167796599, 'step': 6535500}
INFO:transformers.trainer:{'loss': 3.0039855757951734, 'learning_rate': 3.0380312159559693e-05, 'epoch': 1.1771812704264184, 'step': 6536000}
INFO:transformers.trainer:{'loss': 3.0445222103595735, 'learning_rate': 3.0378811265447056e-05, 'epoch': 1.177271324073177, 'step': 6536500}
INFO:transformers.trainer:{'loss': 3.0656946623325347, 'learning_rate': 3.037731037133441e-05, 'epoch': 1.1773613777199352, 'step': 6537000}
INFO:transformers.trainer:{'loss': 3.077551302909851, 'learning_rate': 3.0375809477221774e-05, 'epoch': 1.1774514313666937, 'step': 6537500}
INFO:transformers.trainer:{'loss': 3.03974459528923, 'learning_rate': 3.037430858310913e-05, 'epoch': 1.1775414850134522, 'step': 6538000}
INFO:transformers.trainer:{'loss': 3.0354912679195403, 'learning_rate': 3.0372807688996492e-05, 'epoch': 1.1776315386602108, 'step': 6538500}
INFO:transformers.trainer:{'loss': 3.060909802913666, 'learning_rate': 3.0371306794883847e-05, 'epoch': 1.177721592306969, 'step': 6539000}
INFO:transformers.trainer:{'loss': 3.0539300928115845, 'learning_rate': 3.036980590077121e-05, 'epoch': 1.1778116459537276, 'step': 6539500}
INFO:transformers.trainer:{'loss': 3.0904893317222597, 'learning_rate': 3.036830500665857e-05, 'epoch': 1.177901699600486, 'step': 6540000}
INFO:transformers.trainer:{'loss': 3.071846981048584, 'learning_rate': 3.0366804112545928e-05, 'epoch': 1.1779917532472444, 'step': 6540500}
INFO:transformers.trainer:{'loss': 3.1162663235664367, 'learning_rate': 3.0365303218433287e-05, 'epoch': 1.1780818068940029, 'step': 6541000}
INFO:transformers.trainer:{'loss': 3.0593167408704756, 'learning_rate': 3.0363802324320646e-05, 'epoch': 1.1781718605407614, 'step': 6541500}
INFO:transformers.trainer:{'loss': 3.0708434329032896, 'learning_rate': 3.0362301430208005e-05, 'epoch': 1.17826191418752, 'step': 6542000}
INFO:transformers.trainer:{'loss': 3.071390603303909, 'learning_rate': 3.0360800536095364e-05, 'epoch': 1.1783519678342782, 'step': 6542500}
INFO:transformers.trainer:{'loss': 3.1197811892032625, 'learning_rate': 3.0359299641982723e-05, 'epoch': 1.1784420214810367, 'step': 6543000}
INFO:transformers.trainer:{'loss': 3.0540060896873475, 'learning_rate': 3.0357798747870082e-05, 'epoch': 1.1785320751277952, 'step': 6543500}
INFO:transformers.trainer:{'loss': 3.0385629551410673, 'learning_rate': 3.035629785375744e-05, 'epoch': 1.1786221287745535, 'step': 6544000}
INFO:transformers.trainer:{'loss': 2.992677898168564, 'learning_rate': 3.03547969596448e-05, 'epoch': 1.178712182421312, 'step': 6544500}
INFO:transformers.trainer:{'loss': 3.0793080834150315, 'learning_rate': 3.035329606553216e-05, 'epoch': 1.1788022360680706, 'step': 6545000}
INFO:transformers.trainer:{'loss': 3.0576535596847534, 'learning_rate': 3.035179517141952e-05, 'epoch': 1.1788922897148288, 'step': 6545500}
INFO:transformers.trainer:{'loss': 3.077737840414047, 'learning_rate': 3.0350294277306878e-05, 'epoch': 1.1789823433615874, 'step': 6546000}
INFO:transformers.trainer:{'loss': 3.0461228630542756, 'learning_rate': 3.034879338319424e-05, 'epoch': 1.1790723970083459, 'step': 6546500}
INFO:transformers.trainer:{'loss': 3.0224783403873445, 'learning_rate': 3.0347292489081596e-05, 'epoch': 1.1791624506551042, 'step': 6547000}
INFO:transformers.trainer:{'loss': 3.046670951485634, 'learning_rate': 3.0345791594968958e-05, 'epoch': 1.1792525043018627, 'step': 6547500}
INFO:transformers.trainer:{'loss': 3.084625968694687, 'learning_rate': 3.0344290700856314e-05, 'epoch': 1.1793425579486212, 'step': 6548000}
INFO:transformers.trainer:{'loss': 3.1086929380893706, 'learning_rate': 3.0342789806743676e-05, 'epoch': 1.1794326115953795, 'step': 6548500}
INFO:transformers.trainer:{'loss': 3.1305538799762727, 'learning_rate': 3.0341288912631032e-05, 'epoch': 1.179522665242138, 'step': 6549000}
INFO:transformers.trainer:{'loss': 3.030480660676956, 'learning_rate': 3.0339788018518394e-05, 'epoch': 1.1796127188888965, 'step': 6549500}
INFO:transformers.trainer:{'loss': 2.9821001505851745, 'learning_rate': 3.033828712440575e-05, 'epoch': 1.179702772535655, 'step': 6550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0085898480415345, 'learning_rate': 3.0336786230293112e-05, 'epoch': 1.1797928261824133, 'step': 6550500}
INFO:transformers.trainer:{'loss': 2.988694676399231, 'learning_rate': 3.0335285336180468e-05, 'epoch': 1.1798828798291718, 'step': 6551000}
INFO:transformers.trainer:{'loss': 3.005719294548035, 'learning_rate': 3.033378444206783e-05, 'epoch': 1.1799729334759304, 'step': 6551500}
INFO:transformers.trainer:{'loss': 3.03050705242157, 'learning_rate': 3.0332283547955186e-05, 'epoch': 1.1800629871226886, 'step': 6552000}
INFO:transformers.trainer:{'loss': 3.108073991239071, 'learning_rate': 3.033078265384255e-05, 'epoch': 1.1801530407694472, 'step': 6552500}
INFO:transformers.trainer:{'loss': 3.0687281116247176, 'learning_rate': 3.0329281759729904e-05, 'epoch': 1.1802430944162057, 'step': 6553000}
INFO:transformers.trainer:{'loss': 3.04693691945076, 'learning_rate': 3.0327780865617267e-05, 'epoch': 1.1803331480629642, 'step': 6553500}
INFO:transformers.trainer:{'loss': 3.073797178268433, 'learning_rate': 3.032627997150463e-05, 'epoch': 1.1804232017097225, 'step': 6554000}
INFO:transformers.trainer:{'loss': 3.1029652967453, 'learning_rate': 3.0324779077391985e-05, 'epoch': 1.180513255356481, 'step': 6554500}
INFO:transformers.trainer:{'loss': 3.0471566429138184, 'learning_rate': 3.0323278183279347e-05, 'epoch': 1.1806033090032395, 'step': 6555000}
INFO:transformers.trainer:{'loss': 2.9978908874988557, 'learning_rate': 3.0321777289166703e-05, 'epoch': 1.1806933626499978, 'step': 6555500}
INFO:transformers.trainer:{'loss': 3.060371729969978, 'learning_rate': 3.0320276395054065e-05, 'epoch': 1.1807834162967563, 'step': 6556000}
INFO:transformers.trainer:{'loss': 2.990948703289032, 'learning_rate': 3.031877550094142e-05, 'epoch': 1.1808734699435148, 'step': 6556500}
INFO:transformers.trainer:{'loss': 3.08797056889534, 'learning_rate': 3.0317274606828783e-05, 'epoch': 1.1809635235902731, 'step': 6557000}
INFO:transformers.trainer:{'loss': 2.989187298297882, 'learning_rate': 3.031577371271614e-05, 'epoch': 1.1810535772370316, 'step': 6557500}
INFO:transformers.trainer:{'loss': 3.095620628118515, 'learning_rate': 3.03142728186035e-05, 'epoch': 1.1811436308837902, 'step': 6558000}
INFO:transformers.trainer:{'loss': 3.0510378031730654, 'learning_rate': 3.0312771924490857e-05, 'epoch': 1.1812336845305484, 'step': 6558500}
INFO:transformers.trainer:{'loss': 3.070180047750473, 'learning_rate': 3.031127103037822e-05, 'epoch': 1.181323738177307, 'step': 6559000}
INFO:transformers.trainer:{'loss': 3.0537661793231963, 'learning_rate': 3.0309770136265575e-05, 'epoch': 1.1814137918240655, 'step': 6559500}
INFO:transformers.trainer:{'loss': 3.0908088891506194, 'learning_rate': 3.0308269242152938e-05, 'epoch': 1.1815038454708238, 'step': 6560000}
INFO:transformers.trainer:{'loss': 3.0919683994054794, 'learning_rate': 3.03067683480403e-05, 'epoch': 1.1815938991175823, 'step': 6560500}
INFO:transformers.trainer:{'loss': 3.103231465816498, 'learning_rate': 3.0305267453927656e-05, 'epoch': 1.1816839527643408, 'step': 6561000}
INFO:transformers.trainer:{'loss': 3.0835436446666717, 'learning_rate': 3.0303766559815018e-05, 'epoch': 1.1817740064110993, 'step': 6561500}
INFO:transformers.trainer:{'loss': 3.054237523674965, 'learning_rate': 3.0302265665702374e-05, 'epoch': 1.1818640600578576, 'step': 6562000}
INFO:transformers.trainer:{'loss': 3.0605556077957154, 'learning_rate': 3.0300764771589736e-05, 'epoch': 1.1819541137046161, 'step': 6562500}
INFO:transformers.trainer:{'loss': 3.0260495269298553, 'learning_rate': 3.0299263877477092e-05, 'epoch': 1.1820441673513746, 'step': 6563000}
INFO:transformers.trainer:{'loss': 3.078589655637741, 'learning_rate': 3.029776298336445e-05, 'epoch': 1.182134220998133, 'step': 6563500}
INFO:transformers.trainer:{'loss': 3.086438197851181, 'learning_rate': 3.029626208925181e-05, 'epoch': 1.1822242746448914, 'step': 6564000}
INFO:transformers.trainer:{'loss': 3.0750886080265043, 'learning_rate': 3.029476119513917e-05, 'epoch': 1.18231432829165, 'step': 6564500}
INFO:transformers.trainer:{'loss': 3.0671952518224717, 'learning_rate': 3.0293260301026528e-05, 'epoch': 1.1824043819384085, 'step': 6565000}
INFO:transformers.trainer:{'loss': 3.0327692394256593, 'learning_rate': 3.0291759406913887e-05, 'epoch': 1.1824944355851668, 'step': 6565500}
INFO:transformers.trainer:{'loss': 3.115447997331619, 'learning_rate': 3.0290258512801246e-05, 'epoch': 1.1825844892319253, 'step': 6566000}
INFO:transformers.trainer:{'loss': 3.0879825654029847, 'learning_rate': 3.0288757618688605e-05, 'epoch': 1.1826745428786838, 'step': 6566500}
INFO:transformers.trainer:{'loss': 3.0341525335311887, 'learning_rate': 3.0287256724575964e-05, 'epoch': 1.182764596525442, 'step': 6567000}
INFO:transformers.trainer:{'loss': 3.059841222167015, 'learning_rate': 3.0285755830463323e-05, 'epoch': 1.1828546501722006, 'step': 6567500}
INFO:transformers.trainer:{'loss': 3.0699187960624696, 'learning_rate': 3.0284254936350686e-05, 'epoch': 1.182944703818959, 'step': 6568000}
INFO:transformers.trainer:{'loss': 3.0355500102043154, 'learning_rate': 3.028275404223804e-05, 'epoch': 1.1830347574657174, 'step': 6568500}
INFO:transformers.trainer:{'loss': 3.0490470461845396, 'learning_rate': 3.0281253148125404e-05, 'epoch': 1.183124811112476, 'step': 6569000}
INFO:transformers.trainer:{'loss': 3.0528270539045335, 'learning_rate': 3.027975225401276e-05, 'epoch': 1.1832148647592344, 'step': 6569500}
INFO:transformers.trainer:{'loss': 3.0736706235408784, 'learning_rate': 3.0278251359900122e-05, 'epoch': 1.1833049184059927, 'step': 6570000}
INFO:transformers.trainer:{'loss': 3.076408843755722, 'learning_rate': 3.0276750465787478e-05, 'epoch': 1.1833949720527512, 'step': 6570500}
INFO:transformers.trainer:{'loss': 3.0493851413726807, 'learning_rate': 3.027524957167484e-05, 'epoch': 1.1834850256995098, 'step': 6571000}
INFO:transformers.trainer:{'loss': 3.012739421367645, 'learning_rate': 3.0273748677562196e-05, 'epoch': 1.183575079346268, 'step': 6571500}
INFO:transformers.trainer:{'loss': 3.0460877138376237, 'learning_rate': 3.027224778344956e-05, 'epoch': 1.1836651329930266, 'step': 6572000}
INFO:transformers.trainer:{'loss': 3.058942096233368, 'learning_rate': 3.0270746889336914e-05, 'epoch': 1.183755186639785, 'step': 6572500}
INFO:transformers.trainer:{'loss': 3.024202491283417, 'learning_rate': 3.0269245995224276e-05, 'epoch': 1.1838452402865436, 'step': 6573000}
INFO:transformers.trainer:{'loss': 3.0240858886241915, 'learning_rate': 3.0267745101111632e-05, 'epoch': 1.1839352939333019, 'step': 6573500}
INFO:transformers.trainer:{'loss': 3.010512969970703, 'learning_rate': 3.0266244206998995e-05, 'epoch': 1.1840253475800604, 'step': 6574000}
INFO:transformers.trainer:{'loss': 3.024320261001587, 'learning_rate': 3.0264743312886357e-05, 'epoch': 1.184115401226819, 'step': 6574500}
INFO:transformers.trainer:{'loss': 3.117613356590271, 'learning_rate': 3.0263242418773713e-05, 'epoch': 1.1842054548735772, 'step': 6575000}
INFO:transformers.trainer:{'loss': 3.0267865464687347, 'learning_rate': 3.0261741524661075e-05, 'epoch': 1.1842955085203357, 'step': 6575500}
INFO:transformers.trainer:{'loss': 3.058131819486618, 'learning_rate': 3.026024063054843e-05, 'epoch': 1.1843855621670942, 'step': 6576000}
INFO:transformers.trainer:{'loss': 3.050894839167595, 'learning_rate': 3.0258739736435793e-05, 'epoch': 1.1844756158138527, 'step': 6576500}
INFO:transformers.trainer:{'loss': 3.0363263897895814, 'learning_rate': 3.025723884232315e-05, 'epoch': 1.184565669460611, 'step': 6577000}
INFO:transformers.trainer:{'loss': 3.0569144891500475, 'learning_rate': 3.025573794821051e-05, 'epoch': 1.1846557231073696, 'step': 6577500}
INFO:transformers.trainer:{'loss': 3.0328747889995573, 'learning_rate': 3.0254237054097867e-05, 'epoch': 1.184745776754128, 'step': 6578000}
INFO:transformers.trainer:{'loss': 3.0451115794181822, 'learning_rate': 3.025273615998523e-05, 'epoch': 1.1848358304008864, 'step': 6578500}
INFO:transformers.trainer:{'loss': 3.0518513865470887, 'learning_rate': 3.0251235265872585e-05, 'epoch': 1.1849258840476449, 'step': 6579000}
INFO:transformers.trainer:{'loss': 3.043843151330948, 'learning_rate': 3.0249734371759947e-05, 'epoch': 1.1850159376944034, 'step': 6579500}
INFO:transformers.trainer:{'loss': 3.040148012161255, 'learning_rate': 3.0248233477647303e-05, 'epoch': 1.1851059913411617, 'step': 6580000}
INFO:transformers.trainer:{'loss': 3.07224524641037, 'learning_rate': 3.0246732583534666e-05, 'epoch': 1.1851960449879202, 'step': 6580500}
INFO:transformers.trainer:{'loss': 3.11245472073555, 'learning_rate': 3.0245231689422028e-05, 'epoch': 1.1852860986346787, 'step': 6581000}
INFO:transformers.trainer:{'loss': 3.102206549882889, 'learning_rate': 3.0243730795309384e-05, 'epoch': 1.185376152281437, 'step': 6581500}
INFO:transformers.trainer:{'loss': 3.0529926843643187, 'learning_rate': 3.0242229901196746e-05, 'epoch': 1.1854662059281955, 'step': 6582000}
INFO:transformers.trainer:{'loss': 3.019860188484192, 'learning_rate': 3.0240729007084102e-05, 'epoch': 1.185556259574954, 'step': 6582500}
INFO:transformers.trainer:{'loss': 3.0771573102474212, 'learning_rate': 3.0239228112971464e-05, 'epoch': 1.1856463132217123, 'step': 6583000}
INFO:transformers.trainer:{'loss': 3.0579322928190233, 'learning_rate': 3.023772721885882e-05, 'epoch': 1.1857363668684708, 'step': 6583500}
INFO:transformers.trainer:{'loss': 3.0748467140197753, 'learning_rate': 3.0236226324746182e-05, 'epoch': 1.1858264205152294, 'step': 6584000}
INFO:transformers.trainer:{'loss': 3.0444991390705107, 'learning_rate': 3.0234725430633538e-05, 'epoch': 1.1859164741619879, 'step': 6584500}
INFO:transformers.trainer:{'loss': 3.057186318874359, 'learning_rate': 3.02332245365209e-05, 'epoch': 1.1860065278087462, 'step': 6585000}
INFO:transformers.trainer:{'loss': 3.0491943994760513, 'learning_rate': 3.0231723642408256e-05, 'epoch': 1.1860965814555047, 'step': 6585500}
INFO:transformers.trainer:{'loss': 3.021879630327225, 'learning_rate': 3.023022274829562e-05, 'epoch': 1.1861866351022632, 'step': 6586000}
INFO:transformers.trainer:{'loss': 3.049196943283081, 'learning_rate': 3.0228721854182974e-05, 'epoch': 1.1862766887490215, 'step': 6586500}
INFO:transformers.trainer:{'loss': 3.0314417078495026, 'learning_rate': 3.0227220960070333e-05, 'epoch': 1.18636674239578, 'step': 6587000}
INFO:transformers.trainer:{'loss': 3.085306930422783, 'learning_rate': 3.0225720065957692e-05, 'epoch': 1.1864567960425385, 'step': 6587500}
INFO:transformers.trainer:{'loss': 3.067276962518692, 'learning_rate': 3.022421917184505e-05, 'epoch': 1.186546849689297, 'step': 6588000}
INFO:transformers.trainer:{'loss': 3.080816017627716, 'learning_rate': 3.0222718277732414e-05, 'epoch': 1.1866369033360553, 'step': 6588500}
INFO:transformers.trainer:{'loss': 3.0719003977775574, 'learning_rate': 3.022121738361977e-05, 'epoch': 1.1867269569828138, 'step': 6589000}
INFO:transformers.trainer:{'loss': 3.0524061255455015, 'learning_rate': 3.0219716489507132e-05, 'epoch': 1.1868170106295723, 'step': 6589500}
INFO:transformers.trainer:{'loss': 3.038075150966644, 'learning_rate': 3.0218215595394488e-05, 'epoch': 1.1869070642763306, 'step': 6590000}
INFO:transformers.trainer:{'loss': 3.0550388231277466, 'learning_rate': 3.021671470128185e-05, 'epoch': 1.1869971179230892, 'step': 6590500}
INFO:transformers.trainer:{'loss': 3.05884604370594, 'learning_rate': 3.0215213807169206e-05, 'epoch': 1.1870871715698477, 'step': 6591000}
INFO:transformers.trainer:{'loss': 3.059464810490608, 'learning_rate': 3.0213712913056568e-05, 'epoch': 1.187177225216606, 'step': 6591500}
INFO:transformers.trainer:{'loss': 3.024673574566841, 'learning_rate': 3.0212212018943924e-05, 'epoch': 1.1872672788633645, 'step': 6592000}
INFO:transformers.trainer:{'loss': 2.9885257490873336, 'learning_rate': 3.0210711124831286e-05, 'epoch': 1.187357332510123, 'step': 6592500}
INFO:transformers.trainer:{'loss': 3.1102971410751343, 'learning_rate': 3.0209210230718642e-05, 'epoch': 1.1874473861568813, 'step': 6593000}
INFO:transformers.trainer:{'loss': 3.0558332591056825, 'learning_rate': 3.0207709336606004e-05, 'epoch': 1.1875374398036398, 'step': 6593500}
INFO:transformers.trainer:{'loss': 3.0161372656822203, 'learning_rate': 3.020620844249336e-05, 'epoch': 1.1876274934503983, 'step': 6594000}
INFO:transformers.trainer:{'loss': 3.066398512840271, 'learning_rate': 3.0204707548380722e-05, 'epoch': 1.1877175470971566, 'step': 6594500}
INFO:transformers.trainer:{'loss': 3.1034251389503478, 'learning_rate': 3.0203206654268085e-05, 'epoch': 1.1878076007439151, 'step': 6595000}
INFO:transformers.trainer:{'loss': 3.0196423552036284, 'learning_rate': 3.020170576015544e-05, 'epoch': 1.1878976543906736, 'step': 6595500}
INFO:transformers.trainer:{'loss': 3.015319795370102, 'learning_rate': 3.0200204866042803e-05, 'epoch': 1.1879877080374321, 'step': 6596000}
INFO:transformers.trainer:{'loss': 3.015938688516617, 'learning_rate': 3.019870397193016e-05, 'epoch': 1.1880777616841904, 'step': 6596500}
INFO:transformers.trainer:{'loss': 3.0851482410430906, 'learning_rate': 3.019720307781752e-05, 'epoch': 1.188167815330949, 'step': 6597000}
INFO:transformers.trainer:{'loss': 3.0260960576534273, 'learning_rate': 3.0195702183704877e-05, 'epoch': 1.1882578689777075, 'step': 6597500}
INFO:transformers.trainer:{'loss': 3.044344424724579, 'learning_rate': 3.019420128959224e-05, 'epoch': 1.1883479226244658, 'step': 6598000}
INFO:transformers.trainer:{'loss': 3.045579302549362, 'learning_rate': 3.0192700395479595e-05, 'epoch': 1.1884379762712243, 'step': 6598500}
INFO:transformers.trainer:{'loss': 3.066985320687294, 'learning_rate': 3.0191199501366957e-05, 'epoch': 1.1885280299179828, 'step': 6599000}
INFO:transformers.trainer:{'loss': 3.0833399918079376, 'learning_rate': 3.0189698607254313e-05, 'epoch': 1.1886180835647413, 'step': 6599500}
INFO:transformers.trainer:{'loss': 2.9976661376953126, 'learning_rate': 3.0188197713141675e-05, 'epoch': 1.1887081372114996, 'step': 6600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.02105174946785, 'learning_rate': 3.018669681902903e-05, 'epoch': 1.188798190858258, 'step': 6600500}
INFO:transformers.trainer:{'loss': 3.0984311037063597, 'learning_rate': 3.0185195924916393e-05, 'epoch': 1.1888882445050166, 'step': 6601000}
INFO:transformers.trainer:{'loss': 3.088754529476166, 'learning_rate': 3.018369503080375e-05, 'epoch': 1.188978298151775, 'step': 6601500}
INFO:transformers.trainer:{'loss': 3.067636628270149, 'learning_rate': 3.018219413669111e-05, 'epoch': 1.1890683517985334, 'step': 6602000}
INFO:transformers.trainer:{'loss': 3.0261694502830507, 'learning_rate': 3.0180693242578474e-05, 'epoch': 1.189158405445292, 'step': 6602500}
INFO:transformers.trainer:{'loss': 3.0625138742923737, 'learning_rate': 3.017919234846583e-05, 'epoch': 1.1892484590920502, 'step': 6603000}
INFO:transformers.trainer:{'loss': 2.9532247169017793, 'learning_rate': 3.0177691454353192e-05, 'epoch': 1.1893385127388088, 'step': 6603500}
INFO:transformers.trainer:{'loss': 3.001197427511215, 'learning_rate': 3.0176190560240548e-05, 'epoch': 1.1894285663855673, 'step': 6604000}
INFO:transformers.trainer:{'loss': 3.0638132817745207, 'learning_rate': 3.017468966612791e-05, 'epoch': 1.1895186200323256, 'step': 6604500}
INFO:transformers.trainer:{'loss': 3.012727328419685, 'learning_rate': 3.0173188772015266e-05, 'epoch': 1.189608673679084, 'step': 6605000}
INFO:transformers.trainer:{'loss': 3.023064348936081, 'learning_rate': 3.0171687877902628e-05, 'epoch': 1.1896987273258426, 'step': 6605500}
INFO:transformers.trainer:{'loss': 3.0309817321300505, 'learning_rate': 3.0170186983789984e-05, 'epoch': 1.1897887809726009, 'step': 6606000}
INFO:transformers.trainer:{'loss': 3.0231458711624146, 'learning_rate': 3.0168686089677346e-05, 'epoch': 1.1898788346193594, 'step': 6606500}
INFO:transformers.trainer:{'loss': 3.003293491125107, 'learning_rate': 3.0167185195564702e-05, 'epoch': 1.189968888266118, 'step': 6607000}
INFO:transformers.trainer:{'loss': 3.0465122479200364, 'learning_rate': 3.0165684301452064e-05, 'epoch': 1.1900589419128764, 'step': 6607500}
INFO:transformers.trainer:{'loss': 3.11903738117218, 'learning_rate': 3.016418340733942e-05, 'epoch': 1.1901489955596347, 'step': 6608000}
INFO:transformers.trainer:{'loss': 3.1116037561893464, 'learning_rate': 3.0162682513226783e-05, 'epoch': 1.1902390492063932, 'step': 6608500}
INFO:transformers.trainer:{'loss': 3.0855144736766813, 'learning_rate': 3.016118161911414e-05, 'epoch': 1.1903291028531517, 'step': 6609000}
INFO:transformers.trainer:{'loss': 3.105985790014267, 'learning_rate': 3.01596807250015e-05, 'epoch': 1.19041915649991, 'step': 6609500}
INFO:transformers.trainer:{'loss': 2.9987230855226517, 'learning_rate': 3.015817983088886e-05, 'epoch': 1.1905092101466686, 'step': 6610000}
INFO:transformers.trainer:{'loss': 3.012781725883484, 'learning_rate': 3.0156678936776215e-05, 'epoch': 1.190599263793427, 'step': 6610500}
INFO:transformers.trainer:{'loss': 3.0787873764038087, 'learning_rate': 3.0155178042663578e-05, 'epoch': 1.1906893174401856, 'step': 6611000}
INFO:transformers.trainer:{'loss': 3.0389001085758207, 'learning_rate': 3.0153677148550933e-05, 'epoch': 1.1907793710869439, 'step': 6611500}
INFO:transformers.trainer:{'loss': 3.094780863404274, 'learning_rate': 3.0152176254438296e-05, 'epoch': 1.1908694247337024, 'step': 6612000}
INFO:transformers.trainer:{'loss': 3.074125980377197, 'learning_rate': 3.015067536032565e-05, 'epoch': 1.190959478380461, 'step': 6612500}
INFO:transformers.trainer:{'loss': 3.034948579788208, 'learning_rate': 3.0149174466213014e-05, 'epoch': 1.1910495320272192, 'step': 6613000}
INFO:transformers.trainer:{'loss': 3.0019687941074373, 'learning_rate': 3.014767357210037e-05, 'epoch': 1.1911395856739777, 'step': 6613500}
INFO:transformers.trainer:{'loss': 3.0723120982646943, 'learning_rate': 3.0146172677987732e-05, 'epoch': 1.1912296393207362, 'step': 6614000}
INFO:transformers.trainer:{'loss': 3.0905797876119614, 'learning_rate': 3.0144671783875088e-05, 'epoch': 1.1913196929674945, 'step': 6614500}
INFO:transformers.trainer:{'loss': 2.9787402737140654, 'learning_rate': 3.014317088976245e-05, 'epoch': 1.191409746614253, 'step': 6615000}
INFO:transformers.trainer:{'loss': 2.998924994468689, 'learning_rate': 3.0141669995649806e-05, 'epoch': 1.1914998002610115, 'step': 6615500}
INFO:transformers.trainer:{'loss': 3.082138821005821, 'learning_rate': 3.0140169101537168e-05, 'epoch': 1.1915898539077698, 'step': 6616000}
INFO:transformers.trainer:{'loss': 3.0426941645145416, 'learning_rate': 3.013866820742453e-05, 'epoch': 1.1916799075545284, 'step': 6616500}
INFO:transformers.trainer:{'loss': 3.0437418628931043, 'learning_rate': 3.0137167313311886e-05, 'epoch': 1.1917699612012869, 'step': 6617000}
INFO:transformers.trainer:{'loss': 3.055671544790268, 'learning_rate': 3.013566641919925e-05, 'epoch': 1.1918600148480452, 'step': 6617500}
INFO:transformers.trainer:{'loss': 3.0511483192443847, 'learning_rate': 3.0134165525086604e-05, 'epoch': 1.1919500684948037, 'step': 6618000}
INFO:transformers.trainer:{'loss': 3.047066499710083, 'learning_rate': 3.0132664630973967e-05, 'epoch': 1.1920401221415622, 'step': 6618500}
INFO:transformers.trainer:{'loss': 3.0218800030946733, 'learning_rate': 3.0131163736861323e-05, 'epoch': 1.1921301757883207, 'step': 6619000}
INFO:transformers.trainer:{'loss': 3.045479789018631, 'learning_rate': 3.0129662842748685e-05, 'epoch': 1.192220229435079, 'step': 6619500}
INFO:transformers.trainer:{'loss': 3.026809073209763, 'learning_rate': 3.012816194863604e-05, 'epoch': 1.1923102830818375, 'step': 6620000}
INFO:transformers.trainer:{'loss': 3.065960019111633, 'learning_rate': 3.0126661054523403e-05, 'epoch': 1.192400336728596, 'step': 6620500}
INFO:transformers.trainer:{'loss': 3.0998105149269106, 'learning_rate': 3.012516016041076e-05, 'epoch': 1.1924903903753543, 'step': 6621000}
INFO:transformers.trainer:{'loss': 2.9877100150585174, 'learning_rate': 3.012365926629812e-05, 'epoch': 1.1925804440221128, 'step': 6621500}
INFO:transformers.trainer:{'loss': 3.1077709465026855, 'learning_rate': 3.0122158372185477e-05, 'epoch': 1.1926704976688713, 'step': 6622000}
INFO:transformers.trainer:{'loss': 2.9906514337062835, 'learning_rate': 3.012065747807284e-05, 'epoch': 1.1927605513156299, 'step': 6622500}
INFO:transformers.trainer:{'loss': 2.9947264895439147, 'learning_rate': 3.0119156583960202e-05, 'epoch': 1.1928506049623882, 'step': 6623000}
INFO:transformers.trainer:{'loss': 3.0762055084705353, 'learning_rate': 3.0117655689847557e-05, 'epoch': 1.1929406586091467, 'step': 6623500}
INFO:transformers.trainer:{'loss': 3.041710212945938, 'learning_rate': 3.011615479573492e-05, 'epoch': 1.1930307122559052, 'step': 6624000}
INFO:transformers.trainer:{'loss': 3.0551505402326584, 'learning_rate': 3.0114653901622276e-05, 'epoch': 1.1931207659026635, 'step': 6624500}
INFO:transformers.trainer:{'loss': 3.005634912490845, 'learning_rate': 3.0113153007509638e-05, 'epoch': 1.193210819549422, 'step': 6625000}
INFO:transformers.trainer:{'loss': 3.044704046010971, 'learning_rate': 3.0111652113396994e-05, 'epoch': 1.1933008731961805, 'step': 6625500}
INFO:transformers.trainer:{'loss': 3.026902761220932, 'learning_rate': 3.0110151219284356e-05, 'epoch': 1.1933909268429388, 'step': 6626000}
INFO:transformers.trainer:{'loss': 3.0793324882984163, 'learning_rate': 3.0108650325171712e-05, 'epoch': 1.1934809804896973, 'step': 6626500}
INFO:transformers.trainer:{'loss': 3.025740858912468, 'learning_rate': 3.0107149431059074e-05, 'epoch': 1.1935710341364558, 'step': 6627000}
INFO:transformers.trainer:{'loss': 3.0979608150720597, 'learning_rate': 3.010564853694643e-05, 'epoch': 1.1936610877832141, 'step': 6627500}
INFO:transformers.trainer:{'loss': 3.059140099167824, 'learning_rate': 3.0104147642833792e-05, 'epoch': 1.1937511414299726, 'step': 6628000}
INFO:transformers.trainer:{'loss': 3.0376020402908326, 'learning_rate': 3.0102646748721148e-05, 'epoch': 1.1938411950767311, 'step': 6628500}
INFO:transformers.trainer:{'loss': 3.052725176334381, 'learning_rate': 3.010114585460851e-05, 'epoch': 1.1939312487234894, 'step': 6629000}
INFO:transformers.trainer:{'loss': 3.0694981985092165, 'learning_rate': 3.009964496049587e-05, 'epoch': 1.194021302370248, 'step': 6629500}
INFO:transformers.trainer:{'loss': 3.0855231133699417, 'learning_rate': 3.009814406638323e-05, 'epoch': 1.1941113560170065, 'step': 6630000}
INFO:transformers.trainer:{'loss': 3.0071833581924436, 'learning_rate': 3.0096643172270588e-05, 'epoch': 1.194201409663765, 'step': 6630500}
INFO:transformers.trainer:{'loss': 3.042603381037712, 'learning_rate': 3.0095142278157947e-05, 'epoch': 1.1942914633105233, 'step': 6631000}
INFO:transformers.trainer:{'loss': 3.0677525875568388, 'learning_rate': 3.0093641384045306e-05, 'epoch': 1.1943815169572818, 'step': 6631500}
INFO:transformers.trainer:{'loss': 3.095838151931763, 'learning_rate': 3.0092140489932665e-05, 'epoch': 1.1944715706040403, 'step': 6632000}
INFO:transformers.trainer:{'loss': 3.0837444995641707, 'learning_rate': 3.0090639595820024e-05, 'epoch': 1.1945616242507986, 'step': 6632500}
INFO:transformers.trainer:{'loss': 3.102090812444687, 'learning_rate': 3.0089138701707383e-05, 'epoch': 1.194651677897557, 'step': 6633000}
INFO:transformers.trainer:{'loss': 3.0369939925670626, 'learning_rate': 3.0087637807594742e-05, 'epoch': 1.1947417315443156, 'step': 6633500}
INFO:transformers.trainer:{'loss': 3.0400817413330077, 'learning_rate': 3.00861369134821e-05, 'epoch': 1.1948317851910741, 'step': 6634000}
INFO:transformers.trainer:{'loss': 3.081196438074112, 'learning_rate': 3.008463601936946e-05, 'epoch': 1.1949218388378324, 'step': 6634500}
INFO:transformers.trainer:{'loss': 3.083304769873619, 'learning_rate': 3.0083135125256816e-05, 'epoch': 1.195011892484591, 'step': 6635000}
INFO:transformers.trainer:{'loss': 3.03999294257164, 'learning_rate': 3.0081634231144178e-05, 'epoch': 1.1951019461313495, 'step': 6635500}
INFO:transformers.trainer:{'loss': 3.0011024951934813, 'learning_rate': 3.0080133337031534e-05, 'epoch': 1.1951919997781077, 'step': 6636000}
INFO:transformers.trainer:{'loss': 2.999477612257004, 'learning_rate': 3.0078632442918896e-05, 'epoch': 1.1952820534248663, 'step': 6636500}
INFO:transformers.trainer:{'loss': 3.119411665201187, 'learning_rate': 3.007713154880626e-05, 'epoch': 1.1953721070716248, 'step': 6637000}
INFO:transformers.trainer:{'loss': 3.0342634909152983, 'learning_rate': 3.0075630654693614e-05, 'epoch': 1.195462160718383, 'step': 6637500}
INFO:transformers.trainer:{'loss': 3.0288914197683336, 'learning_rate': 3.0074129760580977e-05, 'epoch': 1.1955522143651416, 'step': 6638000}
INFO:transformers.trainer:{'loss': 3.066965900540352, 'learning_rate': 3.0072628866468332e-05, 'epoch': 1.1956422680119, 'step': 6638500}
INFO:transformers.trainer:{'loss': 3.015560762047768, 'learning_rate': 3.0071127972355695e-05, 'epoch': 1.1957323216586584, 'step': 6639000}
INFO:transformers.trainer:{'loss': 3.044150892138481, 'learning_rate': 3.006962707824305e-05, 'epoch': 1.195822375305417, 'step': 6639500}
INFO:transformers.trainer:{'loss': 2.990881050467491, 'learning_rate': 3.0068126184130413e-05, 'epoch': 1.1959124289521754, 'step': 6640000}
INFO:transformers.trainer:{'loss': 3.0613751788139343, 'learning_rate': 3.006662529001777e-05, 'epoch': 1.1960024825989337, 'step': 6640500}
INFO:transformers.trainer:{'loss': 3.0354153006076814, 'learning_rate': 3.006512439590513e-05, 'epoch': 1.1960925362456922, 'step': 6641000}
INFO:transformers.trainer:{'loss': 3.0010272790193557, 'learning_rate': 3.0063623501792487e-05, 'epoch': 1.1961825898924507, 'step': 6641500}
INFO:transformers.trainer:{'loss': 3.077089397549629, 'learning_rate': 3.006212260767985e-05, 'epoch': 1.1962726435392093, 'step': 6642000}
INFO:transformers.trainer:{'loss': 3.0468203241825105, 'learning_rate': 3.0060621713567205e-05, 'epoch': 1.1963626971859675, 'step': 6642500}
INFO:transformers.trainer:{'loss': 3.025005346059799, 'learning_rate': 3.0059120819454567e-05, 'epoch': 1.196452750832726, 'step': 6643000}
INFO:transformers.trainer:{'loss': 3.047357669353485, 'learning_rate': 3.005761992534193e-05, 'epoch': 1.1965428044794846, 'step': 6643500}
INFO:transformers.trainer:{'loss': 3.027288019120693, 'learning_rate': 3.0056119031229285e-05, 'epoch': 1.1966328581262429, 'step': 6644000}
INFO:transformers.trainer:{'loss': 3.02941539144516, 'learning_rate': 3.0054618137116648e-05, 'epoch': 1.1967229117730014, 'step': 6644500}
INFO:transformers.trainer:{'loss': 3.1011914241313936, 'learning_rate': 3.0053117243004003e-05, 'epoch': 1.19681296541976, 'step': 6645000}
INFO:transformers.trainer:{'loss': 3.1639132709503173, 'learning_rate': 3.0051616348891366e-05, 'epoch': 1.1969030190665184, 'step': 6645500}
INFO:transformers.trainer:{'loss': 3.0013916300535204, 'learning_rate': 3.005011545477872e-05, 'epoch': 1.1969930727132767, 'step': 6646000}
INFO:transformers.trainer:{'loss': 3.0918865888118745, 'learning_rate': 3.0048614560666084e-05, 'epoch': 1.1970831263600352, 'step': 6646500}
INFO:transformers.trainer:{'loss': 3.0607193278074263, 'learning_rate': 3.004711366655344e-05, 'epoch': 1.1971731800067937, 'step': 6647000}
INFO:transformers.trainer:{'loss': 3.1581660912036895, 'learning_rate': 3.0045612772440802e-05, 'epoch': 1.197263233653552, 'step': 6647500}
INFO:transformers.trainer:{'loss': 3.0592481914758682, 'learning_rate': 3.0044111878328158e-05, 'epoch': 1.1973532873003105, 'step': 6648000}
INFO:transformers.trainer:{'loss': 3.0446821212768556, 'learning_rate': 3.004261098421552e-05, 'epoch': 1.197443340947069, 'step': 6648500}
INFO:transformers.trainer:{'loss': 3.0921345705986023, 'learning_rate': 3.0041110090102876e-05, 'epoch': 1.1975333945938273, 'step': 6649000}
INFO:transformers.trainer:{'loss': 3.083071479797363, 'learning_rate': 3.0039609195990238e-05, 'epoch': 1.1976234482405859, 'step': 6649500}
INFO:transformers.trainer:{'loss': 3.0724615132808686, 'learning_rate': 3.0038108301877594e-05, 'epoch': 1.1977135018873444, 'step': 6650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.1022351627349853, 'learning_rate': 3.0036607407764956e-05, 'epoch': 1.1978035555341027, 'step': 6650500}
INFO:transformers.trainer:{'loss': 3.0860296239852905, 'learning_rate': 3.0035106513652315e-05, 'epoch': 1.1978936091808612, 'step': 6651000}
INFO:transformers.trainer:{'loss': 3.0658652530908586, 'learning_rate': 3.0033605619539674e-05, 'epoch': 1.1979836628276197, 'step': 6651500}
INFO:transformers.trainer:{'loss': 3.043635736346245, 'learning_rate': 3.0032104725427033e-05, 'epoch': 1.198073716474378, 'step': 6652000}
INFO:transformers.trainer:{'loss': 2.9543454637527464, 'learning_rate': 3.0030603831314392e-05, 'epoch': 1.1981637701211365, 'step': 6652500}
INFO:transformers.trainer:{'loss': 3.0056053491830825, 'learning_rate': 3.002910293720175e-05, 'epoch': 1.198253823767895, 'step': 6653000}
INFO:transformers.trainer:{'loss': 3.0376228679418564, 'learning_rate': 3.002760204308911e-05, 'epoch': 1.1983438774146535, 'step': 6653500}
INFO:transformers.trainer:{'loss': 3.0728470737934113, 'learning_rate': 3.002610114897647e-05, 'epoch': 1.1984339310614118, 'step': 6654000}
INFO:transformers.trainer:{'loss': 2.9903901867866516, 'learning_rate': 3.002460025486383e-05, 'epoch': 1.1985239847081703, 'step': 6654500}
INFO:transformers.trainer:{'loss': 3.0101540184020994, 'learning_rate': 3.0023099360751188e-05, 'epoch': 1.1986140383549289, 'step': 6655000}
INFO:transformers.trainer:{'loss': 3.1165554962158204, 'learning_rate': 3.0021598466638547e-05, 'epoch': 1.1987040920016871, 'step': 6655500}
INFO:transformers.trainer:{'loss': 3.0276383897066115, 'learning_rate': 3.0020097572525906e-05, 'epoch': 1.1987941456484457, 'step': 6656000}
INFO:transformers.trainer:{'loss': 2.992231914281845, 'learning_rate': 3.0018596678413265e-05, 'epoch': 1.1988841992952042, 'step': 6656500}
INFO:transformers.trainer:{'loss': 3.056240322828293, 'learning_rate': 3.0017095784300624e-05, 'epoch': 1.1989742529419627, 'step': 6657000}
INFO:transformers.trainer:{'loss': 3.0899197952747346, 'learning_rate': 3.0015594890187986e-05, 'epoch': 1.199064306588721, 'step': 6657500}
INFO:transformers.trainer:{'loss': 3.026270204663277, 'learning_rate': 3.0014093996075342e-05, 'epoch': 1.1991543602354795, 'step': 6658000}
INFO:transformers.trainer:{'loss': 2.999458687067032, 'learning_rate': 3.0012593101962704e-05, 'epoch': 1.199244413882238, 'step': 6658500}
INFO:transformers.trainer:{'loss': 3.0655320973396303, 'learning_rate': 3.001109220785006e-05, 'epoch': 1.1993344675289963, 'step': 6659000}
INFO:transformers.trainer:{'loss': 3.0646931049823762, 'learning_rate': 3.0009591313737423e-05, 'epoch': 1.1994245211757548, 'step': 6659500}
INFO:transformers.trainer:{'loss': 3.1242683742046355, 'learning_rate': 3.0008090419624778e-05, 'epoch': 1.1995145748225133, 'step': 6660000}
INFO:transformers.trainer:{'loss': 3.08575475358963, 'learning_rate': 3.000658952551214e-05, 'epoch': 1.1996046284692716, 'step': 6660500}
INFO:transformers.trainer:{'loss': 3.0144869475364686, 'learning_rate': 3.0005088631399496e-05, 'epoch': 1.1996946821160301, 'step': 6661000}
INFO:transformers.trainer:{'loss': 3.070298926591873, 'learning_rate': 3.000358773728686e-05, 'epoch': 1.1997847357627887, 'step': 6661500}
INFO:transformers.trainer:{'loss': 3.030249544620514, 'learning_rate': 3.0002086843174214e-05, 'epoch': 1.199874789409547, 'step': 6662000}
INFO:transformers.trainer:{'loss': 3.0944361428022384, 'learning_rate': 3.0000585949061577e-05, 'epoch': 1.1999648430563055, 'step': 6662500}
INFO:transformers.trainer:{'loss': 3.0194958618879317, 'learning_rate': 2.9999085054948933e-05, 'epoch': 1.200054896703064, 'step': 6663000}
INFO:transformers.trainer:{'loss': 3.0566709308624267, 'learning_rate': 2.9997584160836295e-05, 'epoch': 1.2001449503498225, 'step': 6663500}
INFO:transformers.trainer:{'loss': 3.0846182422637938, 'learning_rate': 2.999608326672365e-05, 'epoch': 1.2002350039965808, 'step': 6664000}
INFO:transformers.trainer:{'loss': 3.0649757936000825, 'learning_rate': 2.9994582372611013e-05, 'epoch': 1.2003250576433393, 'step': 6664500}
INFO:transformers.trainer:{'loss': 3.1009432649612427, 'learning_rate': 2.9993081478498376e-05, 'epoch': 1.2004151112900978, 'step': 6665000}
INFO:transformers.trainer:{'loss': 3.0722841963768004, 'learning_rate': 2.999158058438573e-05, 'epoch': 1.200505164936856, 'step': 6665500}
INFO:transformers.trainer:{'loss': 3.0281374937295915, 'learning_rate': 2.9990079690273094e-05, 'epoch': 1.2005952185836146, 'step': 6666000}
INFO:transformers.trainer:{'loss': 3.019618725538254, 'learning_rate': 2.998857879616045e-05, 'epoch': 1.2006852722303731, 'step': 6666500}
INFO:transformers.trainer:{'loss': 3.0427490842342375, 'learning_rate': 2.9987077902047812e-05, 'epoch': 1.2007753258771316, 'step': 6667000}
INFO:transformers.trainer:{'loss': 3.0892071089744566, 'learning_rate': 2.9985577007935167e-05, 'epoch': 1.20086537952389, 'step': 6667500}
INFO:transformers.trainer:{'loss': 3.015934671282768, 'learning_rate': 2.998407611382253e-05, 'epoch': 1.2009554331706485, 'step': 6668000}
INFO:transformers.trainer:{'loss': 3.01879594373703, 'learning_rate': 2.9982575219709885e-05, 'epoch': 1.201045486817407, 'step': 6668500}
INFO:transformers.trainer:{'loss': 3.085085513830185, 'learning_rate': 2.9981074325597248e-05, 'epoch': 1.2011355404641653, 'step': 6669000}
INFO:transformers.trainer:{'loss': 3.0013938810825347, 'learning_rate': 2.9979573431484604e-05, 'epoch': 1.2012255941109238, 'step': 6669500}
INFO:transformers.trainer:{'loss': 2.9944526500701905, 'learning_rate': 2.9978072537371966e-05, 'epoch': 1.2013156477576823, 'step': 6670000}
INFO:transformers.trainer:{'loss': 3.0811301900148393, 'learning_rate': 2.997657164325932e-05, 'epoch': 1.2014057014044406, 'step': 6670500}
INFO:transformers.trainer:{'loss': 2.9914455494880676, 'learning_rate': 2.9975070749146684e-05, 'epoch': 1.201495755051199, 'step': 6671000}
INFO:transformers.trainer:{'loss': 3.0660794994831084, 'learning_rate': 2.9973569855034047e-05, 'epoch': 1.2015858086979576, 'step': 6671500}
INFO:transformers.trainer:{'loss': 3.0347601647377016, 'learning_rate': 2.9972068960921402e-05, 'epoch': 1.201675862344716, 'step': 6672000}
INFO:transformers.trainer:{'loss': 3.080607433319092, 'learning_rate': 2.997056806680876e-05, 'epoch': 1.2017659159914744, 'step': 6672500}
INFO:transformers.trainer:{'loss': 3.043797923564911, 'learning_rate': 2.996906717269612e-05, 'epoch': 1.201855969638233, 'step': 6673000}
INFO:transformers.trainer:{'loss': 3.072658460378647, 'learning_rate': 2.996756627858348e-05, 'epoch': 1.2019460232849912, 'step': 6673500}
INFO:transformers.trainer:{'loss': 3.024449119567871, 'learning_rate': 2.996606538447084e-05, 'epoch': 1.2020360769317497, 'step': 6674000}
INFO:transformers.trainer:{'loss': 3.042647885799408, 'learning_rate': 2.9964564490358197e-05, 'epoch': 1.2021261305785083, 'step': 6674500}
INFO:transformers.trainer:{'loss': 3.050686077594757, 'learning_rate': 2.9963063596245557e-05, 'epoch': 1.2022161842252668, 'step': 6675000}
INFO:transformers.trainer:{'loss': 3.0631842873096464, 'learning_rate': 2.9961562702132916e-05, 'epoch': 1.202306237872025, 'step': 6675500}
INFO:transformers.trainer:{'loss': 3.027858652830124, 'learning_rate': 2.9960061808020275e-05, 'epoch': 1.2023962915187836, 'step': 6676000}
INFO:transformers.trainer:{'loss': 3.023032296895981, 'learning_rate': 2.9958560913907634e-05, 'epoch': 1.202486345165542, 'step': 6676500}
INFO:transformers.trainer:{'loss': 3.1257197184562684, 'learning_rate': 2.9957060019794993e-05, 'epoch': 1.2025763988123004, 'step': 6677000}
INFO:transformers.trainer:{'loss': 3.083539563179016, 'learning_rate': 2.9955559125682352e-05, 'epoch': 1.202666452459059, 'step': 6677500}
INFO:transformers.trainer:{'loss': 3.0501930696964266, 'learning_rate': 2.9954058231569714e-05, 'epoch': 1.2027565061058174, 'step': 6678000}
INFO:transformers.trainer:{'loss': 2.999393829345703, 'learning_rate': 2.995255733745707e-05, 'epoch': 1.202846559752576, 'step': 6678500}
INFO:transformers.trainer:{'loss': 3.0826733735799787, 'learning_rate': 2.9951056443344432e-05, 'epoch': 1.2029366133993342, 'step': 6679000}
INFO:transformers.trainer:{'loss': 3.0877452716827394, 'learning_rate': 2.9949555549231788e-05, 'epoch': 1.2030266670460927, 'step': 6679500}
INFO:transformers.trainer:{'loss': 3.0154593551158904, 'learning_rate': 2.994805465511915e-05, 'epoch': 1.2031167206928512, 'step': 6680000}
INFO:transformers.trainer:{'loss': 3.006809609889984, 'learning_rate': 2.9946553761006506e-05, 'epoch': 1.2032067743396095, 'step': 6680500}
INFO:transformers.trainer:{'loss': 3.001729946374893, 'learning_rate': 2.994505286689387e-05, 'epoch': 1.203296827986368, 'step': 6681000}
INFO:transformers.trainer:{'loss': 3.07810434794426, 'learning_rate': 2.9943551972781224e-05, 'epoch': 1.2033868816331266, 'step': 6681500}
INFO:transformers.trainer:{'loss': 3.122936871767044, 'learning_rate': 2.9942051078668587e-05, 'epoch': 1.2034769352798849, 'step': 6682000}
INFO:transformers.trainer:{'loss': 3.028080646276474, 'learning_rate': 2.9940550184555942e-05, 'epoch': 1.2035669889266434, 'step': 6682500}
INFO:transformers.trainer:{'loss': 3.0469669947624207, 'learning_rate': 2.9939049290443305e-05, 'epoch': 1.203657042573402, 'step': 6683000}
INFO:transformers.trainer:{'loss': 3.036386674642563, 'learning_rate': 2.993754839633066e-05, 'epoch': 1.2037470962201602, 'step': 6683500}
INFO:transformers.trainer:{'loss': 3.0181000424623488, 'learning_rate': 2.9936047502218023e-05, 'epoch': 1.2038371498669187, 'step': 6684000}
INFO:transformers.trainer:{'loss': 3.034564825296402, 'learning_rate': 2.993454660810538e-05, 'epoch': 1.2039272035136772, 'step': 6684500}
INFO:transformers.trainer:{'loss': 3.016778016090393, 'learning_rate': 2.993304571399274e-05, 'epoch': 1.2040172571604355, 'step': 6685000}
INFO:transformers.trainer:{'loss': 2.92101487159729, 'learning_rate': 2.9931544819880103e-05, 'epoch': 1.204107310807194, 'step': 6685500}
INFO:transformers.trainer:{'loss': 2.9927930105924605, 'learning_rate': 2.993004392576746e-05, 'epoch': 1.2041973644539525, 'step': 6686000}
INFO:transformers.trainer:{'loss': 3.0755446186065676, 'learning_rate': 2.992854303165482e-05, 'epoch': 1.204287418100711, 'step': 6686500}
INFO:transformers.trainer:{'loss': 3.0693449959754946, 'learning_rate': 2.9927042137542177e-05, 'epoch': 1.2043774717474693, 'step': 6687000}
INFO:transformers.trainer:{'loss': 3.0850484555959703, 'learning_rate': 2.992554124342954e-05, 'epoch': 1.2044675253942279, 'step': 6687500}
INFO:transformers.trainer:{'loss': 3.0401539628505705, 'learning_rate': 2.9924040349316895e-05, 'epoch': 1.2045575790409864, 'step': 6688000}
INFO:transformers.trainer:{'loss': 3.014282296895981, 'learning_rate': 2.9922539455204258e-05, 'epoch': 1.2046476326877447, 'step': 6688500}
INFO:transformers.trainer:{'loss': 3.0512643243074415, 'learning_rate': 2.9921038561091613e-05, 'epoch': 1.2047376863345032, 'step': 6689000}
INFO:transformers.trainer:{'loss': 3.075835277557373, 'learning_rate': 2.9919537666978976e-05, 'epoch': 1.2048277399812617, 'step': 6689500}
INFO:transformers.trainer:{'loss': 3.000585558652878, 'learning_rate': 2.991803677286633e-05, 'epoch': 1.2049177936280202, 'step': 6690000}
INFO:transformers.trainer:{'loss': 3.108377406358719, 'learning_rate': 2.9916535878753694e-05, 'epoch': 1.2050078472747785, 'step': 6690500}
INFO:transformers.trainer:{'loss': 3.0275728145837784, 'learning_rate': 2.991503498464105e-05, 'epoch': 1.205097900921537, 'step': 6691000}
INFO:transformers.trainer:{'loss': 3.123957844495773, 'learning_rate': 2.9913534090528412e-05, 'epoch': 1.2051879545682955, 'step': 6691500}
INFO:transformers.trainer:{'loss': 3.1099348927736283, 'learning_rate': 2.9912033196415774e-05, 'epoch': 1.2052780082150538, 'step': 6692000}
INFO:transformers.trainer:{'loss': 2.9746864047050474, 'learning_rate': 2.991053230230313e-05, 'epoch': 1.2053680618618123, 'step': 6692500}
INFO:transformers.trainer:{'loss': 3.00338108253479, 'learning_rate': 2.9909031408190492e-05, 'epoch': 1.2054581155085708, 'step': 6693000}
INFO:transformers.trainer:{'loss': 3.0570776624679565, 'learning_rate': 2.9907530514077848e-05, 'epoch': 1.2055481691553291, 'step': 6693500}
INFO:transformers.trainer:{'loss': 3.1286186656951904, 'learning_rate': 2.990602961996521e-05, 'epoch': 1.2056382228020877, 'step': 6694000}
INFO:transformers.trainer:{'loss': 3.0478249385356904, 'learning_rate': 2.9904528725852566e-05, 'epoch': 1.2057282764488462, 'step': 6694500}
INFO:transformers.trainer:{'loss': 3.0704614284038545, 'learning_rate': 2.990302783173993e-05, 'epoch': 1.2058183300956045, 'step': 6695000}
INFO:transformers.trainer:{'loss': 3.028923179149628, 'learning_rate': 2.9901526937627284e-05, 'epoch': 1.205908383742363, 'step': 6695500}
INFO:transformers.trainer:{'loss': 3.0197624604702, 'learning_rate': 2.9900026043514643e-05, 'epoch': 1.2059984373891215, 'step': 6696000}
INFO:transformers.trainer:{'loss': 3.0687430384159087, 'learning_rate': 2.9898525149402002e-05, 'epoch': 1.2060884910358798, 'step': 6696500}
INFO:transformers.trainer:{'loss': 3.0432094881534577, 'learning_rate': 2.989702425528936e-05, 'epoch': 1.2061785446826383, 'step': 6697000}
INFO:transformers.trainer:{'loss': 3.06083021068573, 'learning_rate': 2.989552336117672e-05, 'epoch': 1.2062685983293968, 'step': 6697500}
INFO:transformers.trainer:{'loss': 3.0664533097743987, 'learning_rate': 2.989402246706408e-05, 'epoch': 1.2063586519761553, 'step': 6698000}
INFO:transformers.trainer:{'loss': 3.063053688645363, 'learning_rate': 2.989252157295144e-05, 'epoch': 1.2064487056229136, 'step': 6698500}
INFO:transformers.trainer:{'loss': 3.0257965943813323, 'learning_rate': 2.9891020678838798e-05, 'epoch': 1.2065387592696721, 'step': 6699000}
INFO:transformers.trainer:{'loss': 3.0479049081802367, 'learning_rate': 2.988951978472616e-05, 'epoch': 1.2066288129164306, 'step': 6699500}
INFO:transformers.trainer:{'loss': 3.0791301555633543, 'learning_rate': 2.9888018890613516e-05, 'epoch': 1.206718866563189, 'step': 6700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.031133458852768, 'learning_rate': 2.9886517996500878e-05, 'epoch': 1.2068089202099475, 'step': 6700500}
INFO:transformers.trainer:{'loss': 3.0194209513664245, 'learning_rate': 2.9885017102388234e-05, 'epoch': 1.206898973856706, 'step': 6701000}
INFO:transformers.trainer:{'loss': 3.0060179905891418, 'learning_rate': 2.9883516208275596e-05, 'epoch': 1.2069890275034645, 'step': 6701500}
INFO:transformers.trainer:{'loss': 3.0263435678482056, 'learning_rate': 2.9882015314162952e-05, 'epoch': 1.2070790811502228, 'step': 6702000}
INFO:transformers.trainer:{'loss': 3.0723258810043337, 'learning_rate': 2.9880514420050314e-05, 'epoch': 1.2071691347969813, 'step': 6702500}
INFO:transformers.trainer:{'loss': 3.015798723936081, 'learning_rate': 2.987901352593767e-05, 'epoch': 1.2072591884437398, 'step': 6703000}
INFO:transformers.trainer:{'loss': 3.0764662704467773, 'learning_rate': 2.9877512631825033e-05, 'epoch': 1.207349242090498, 'step': 6703500}
INFO:transformers.trainer:{'loss': 3.090480115175247, 'learning_rate': 2.9876011737712388e-05, 'epoch': 1.2074392957372566, 'step': 6704000}
INFO:transformers.trainer:{'loss': 3.0406807491779326, 'learning_rate': 2.987451084359975e-05, 'epoch': 1.2075293493840151, 'step': 6704500}
INFO:transformers.trainer:{'loss': 2.9905144177675247, 'learning_rate': 2.9873009949487106e-05, 'epoch': 1.2076194030307734, 'step': 6705000}
INFO:transformers.trainer:{'loss': 3.003952258348465, 'learning_rate': 2.987150905537447e-05, 'epoch': 1.207709456677532, 'step': 6705500}
INFO:transformers.trainer:{'loss': 3.0746316459178926, 'learning_rate': 2.987000816126183e-05, 'epoch': 1.2077995103242904, 'step': 6706000}
INFO:transformers.trainer:{'loss': 3.088950930953026, 'learning_rate': 2.9868507267149187e-05, 'epoch': 1.2078895639710487, 'step': 6706500}
INFO:transformers.trainer:{'loss': 3.0615986944437026, 'learning_rate': 2.986700637303655e-05, 'epoch': 1.2079796176178073, 'step': 6707000}
INFO:transformers.trainer:{'loss': 3.0574322159290315, 'learning_rate': 2.9865505478923905e-05, 'epoch': 1.2080696712645658, 'step': 6707500}
INFO:transformers.trainer:{'loss': 3.0055868752002715, 'learning_rate': 2.9864004584811267e-05, 'epoch': 1.208159724911324, 'step': 6708000}
INFO:transformers.trainer:{'loss': 3.0339487774372103, 'learning_rate': 2.9862503690698623e-05, 'epoch': 1.2082497785580826, 'step': 6708500}
INFO:transformers.trainer:{'loss': 3.074221386909485, 'learning_rate': 2.9861002796585985e-05, 'epoch': 1.208339832204841, 'step': 6709000}
INFO:transformers.trainer:{'loss': 3.078229061126709, 'learning_rate': 2.985950190247334e-05, 'epoch': 1.2084298858515996, 'step': 6709500}
INFO:transformers.trainer:{'loss': 3.0591952664852142, 'learning_rate': 2.9858001008360704e-05, 'epoch': 1.208519939498358, 'step': 6710000}
INFO:transformers.trainer:{'loss': 3.002112629890442, 'learning_rate': 2.985650011424806e-05, 'epoch': 1.2086099931451164, 'step': 6710500}
INFO:transformers.trainer:{'loss': 3.083474579453468, 'learning_rate': 2.985499922013542e-05, 'epoch': 1.208700046791875, 'step': 6711000}
INFO:transformers.trainer:{'loss': 3.0667245037555695, 'learning_rate': 2.9853498326022777e-05, 'epoch': 1.2087901004386332, 'step': 6711500}
INFO:transformers.trainer:{'loss': 3.0642442126274108, 'learning_rate': 2.985199743191014e-05, 'epoch': 1.2088801540853917, 'step': 6712000}
INFO:transformers.trainer:{'loss': 3.0066945791244506, 'learning_rate': 2.9850496537797495e-05, 'epoch': 1.2089702077321502, 'step': 6712500}
INFO:transformers.trainer:{'loss': 3.005848269820213, 'learning_rate': 2.9848995643684858e-05, 'epoch': 1.2090602613789088, 'step': 6713000}
INFO:transformers.trainer:{'loss': 3.049700487613678, 'learning_rate': 2.984749474957222e-05, 'epoch': 1.209150315025667, 'step': 6713500}
INFO:transformers.trainer:{'loss': 3.102741787791252, 'learning_rate': 2.9845993855459576e-05, 'epoch': 1.2092403686724256, 'step': 6714000}
INFO:transformers.trainer:{'loss': 3.081399337053299, 'learning_rate': 2.984449296134694e-05, 'epoch': 1.209330422319184, 'step': 6714500}
INFO:transformers.trainer:{'loss': 3.008062845826149, 'learning_rate': 2.9842992067234294e-05, 'epoch': 1.2094204759659424, 'step': 6715000}
INFO:transformers.trainer:{'loss': 3.07305823469162, 'learning_rate': 2.9841491173121657e-05, 'epoch': 1.209510529612701, 'step': 6715500}
INFO:transformers.trainer:{'loss': 3.019086662769318, 'learning_rate': 2.9839990279009012e-05, 'epoch': 1.2096005832594594, 'step': 6716000}
INFO:transformers.trainer:{'loss': 3.01388250875473, 'learning_rate': 2.9838489384896375e-05, 'epoch': 1.2096906369062177, 'step': 6716500}
INFO:transformers.trainer:{'loss': 3.0520323607921602, 'learning_rate': 2.983698849078373e-05, 'epoch': 1.2097806905529762, 'step': 6717000}
INFO:transformers.trainer:{'loss': 3.023510925292969, 'learning_rate': 2.9835487596671093e-05, 'epoch': 1.2098707441997347, 'step': 6717500}
INFO:transformers.trainer:{'loss': 3.080085668563843, 'learning_rate': 2.983398670255845e-05, 'epoch': 1.209960797846493, 'step': 6718000}
INFO:transformers.trainer:{'loss': 3.0217020144462587, 'learning_rate': 2.983248580844581e-05, 'epoch': 1.2100508514932515, 'step': 6718500}
INFO:transformers.trainer:{'loss': 3.092859524011612, 'learning_rate': 2.9830984914333166e-05, 'epoch': 1.21014090514001, 'step': 6719000}
INFO:transformers.trainer:{'loss': 3.0370869579315185, 'learning_rate': 2.982948402022053e-05, 'epoch': 1.2102309587867683, 'step': 6719500}
INFO:transformers.trainer:{'loss': 3.017634136199951, 'learning_rate': 2.9827983126107888e-05, 'epoch': 1.2103210124335269, 'step': 6720000}
INFO:transformers.trainer:{'loss': 3.0065264127254485, 'learning_rate': 2.9826482231995244e-05, 'epoch': 1.2104110660802854, 'step': 6720500}
INFO:transformers.trainer:{'loss': 3.0161692739725114, 'learning_rate': 2.9824981337882606e-05, 'epoch': 1.2105011197270439, 'step': 6721000}
INFO:transformers.trainer:{'loss': 3.086988842725754, 'learning_rate': 2.9823480443769962e-05, 'epoch': 1.2105911733738022, 'step': 6721500}
INFO:transformers.trainer:{'loss': 3.0665420577526095, 'learning_rate': 2.9821979549657324e-05, 'epoch': 1.2106812270205607, 'step': 6722000}
INFO:transformers.trainer:{'loss': 3.0542143055200577, 'learning_rate': 2.982047865554468e-05, 'epoch': 1.2107712806673192, 'step': 6722500}
INFO:transformers.trainer:{'loss': 3.0110090985298155, 'learning_rate': 2.9818977761432042e-05, 'epoch': 1.2108613343140775, 'step': 6723000}
INFO:transformers.trainer:{'loss': 3.0656917746067047, 'learning_rate': 2.9817476867319398e-05, 'epoch': 1.210951387960836, 'step': 6723500}
INFO:transformers.trainer:{'loss': 3.0587132538557054, 'learning_rate': 2.981597597320676e-05, 'epoch': 1.2110414416075945, 'step': 6724000}
INFO:transformers.trainer:{'loss': 3.0594634506702425, 'learning_rate': 2.9814475079094116e-05, 'epoch': 1.211131495254353, 'step': 6724500}
INFO:transformers.trainer:{'loss': 3.000045344829559, 'learning_rate': 2.981297418498148e-05, 'epoch': 1.2112215489011113, 'step': 6725000}
INFO:transformers.trainer:{'loss': 3.0700391070842743, 'learning_rate': 2.9811473290868834e-05, 'epoch': 1.2113116025478698, 'step': 6725500}
INFO:transformers.trainer:{'loss': 3.0669169890880585, 'learning_rate': 2.9809972396756197e-05, 'epoch': 1.2114016561946284, 'step': 6726000}
INFO:transformers.trainer:{'loss': 3.042933265686035, 'learning_rate': 2.9808471502643552e-05, 'epoch': 1.2114917098413867, 'step': 6726500}
INFO:transformers.trainer:{'loss': 3.0393140530586242, 'learning_rate': 2.9806970608530915e-05, 'epoch': 1.2115817634881452, 'step': 6727000}
INFO:transformers.trainer:{'loss': 3.071882250070572, 'learning_rate': 2.9805469714418277e-05, 'epoch': 1.2116718171349037, 'step': 6727500}
INFO:transformers.trainer:{'loss': 3.05626948928833, 'learning_rate': 2.9803968820305633e-05, 'epoch': 1.211761870781662, 'step': 6728000}
INFO:transformers.trainer:{'loss': 3.050429490327835, 'learning_rate': 2.9802467926192995e-05, 'epoch': 1.2118519244284205, 'step': 6728500}
INFO:transformers.trainer:{'loss': 3.08383984375, 'learning_rate': 2.980096703208035e-05, 'epoch': 1.211941978075179, 'step': 6729000}
INFO:transformers.trainer:{'loss': 3.0310987411737442, 'learning_rate': 2.9799466137967713e-05, 'epoch': 1.2120320317219373, 'step': 6729500}
INFO:transformers.trainer:{'loss': 3.100419712662697, 'learning_rate': 2.979796524385507e-05, 'epoch': 1.2121220853686958, 'step': 6730000}
INFO:transformers.trainer:{'loss': 3.047597539782524, 'learning_rate': 2.979646434974243e-05, 'epoch': 1.2122121390154543, 'step': 6730500}
INFO:transformers.trainer:{'loss': 3.08564248251915, 'learning_rate': 2.9794963455629787e-05, 'epoch': 1.2123021926622126, 'step': 6731000}
INFO:transformers.trainer:{'loss': 3.124110452413559, 'learning_rate': 2.979346256151715e-05, 'epoch': 1.2123922463089711, 'step': 6731500}
INFO:transformers.trainer:{'loss': 3.0285672717094423, 'learning_rate': 2.9791961667404505e-05, 'epoch': 1.2124822999557296, 'step': 6732000}
INFO:transformers.trainer:{'loss': 3.070742027044296, 'learning_rate': 2.9790460773291868e-05, 'epoch': 1.2125723536024882, 'step': 6732500}
INFO:transformers.trainer:{'loss': 3.0192060463428496, 'learning_rate': 2.9788959879179223e-05, 'epoch': 1.2126624072492465, 'step': 6733000}
INFO:transformers.trainer:{'loss': 3.0613978967666626, 'learning_rate': 2.9787458985066586e-05, 'epoch': 1.212752460896005, 'step': 6733500}
INFO:transformers.trainer:{'loss': 3.017556213140488, 'learning_rate': 2.9785958090953948e-05, 'epoch': 1.2128425145427635, 'step': 6734000}
INFO:transformers.trainer:{'loss': 3.0702614175081253, 'learning_rate': 2.9784457196841304e-05, 'epoch': 1.2129325681895218, 'step': 6734500}
INFO:transformers.trainer:{'loss': 3.046551683664322, 'learning_rate': 2.9782956302728666e-05, 'epoch': 1.2130226218362803, 'step': 6735000}
INFO:transformers.trainer:{'loss': 3.024116727590561, 'learning_rate': 2.9781455408616022e-05, 'epoch': 1.2131126754830388, 'step': 6735500}
INFO:transformers.trainer:{'loss': 3.037216992497444, 'learning_rate': 2.9779954514503384e-05, 'epoch': 1.2132027291297973, 'step': 6736000}
INFO:transformers.trainer:{'loss': 3.001308935523033, 'learning_rate': 2.977845362039074e-05, 'epoch': 1.2132927827765556, 'step': 6736500}
INFO:transformers.trainer:{'loss': 3.0255613107681274, 'learning_rate': 2.9776952726278102e-05, 'epoch': 1.2133828364233141, 'step': 6737000}
INFO:transformers.trainer:{'loss': 3.0927483999729155, 'learning_rate': 2.9775451832165458e-05, 'epoch': 1.2134728900700726, 'step': 6737500}
INFO:transformers.trainer:{'loss': 3.0473647208213808, 'learning_rate': 2.977395093805282e-05, 'epoch': 1.213562943716831, 'step': 6738000}
INFO:transformers.trainer:{'loss': 3.00358879506588, 'learning_rate': 2.9772450043940176e-05, 'epoch': 1.2136529973635894, 'step': 6738500}
INFO:transformers.trainer:{'loss': 3.064895541191101, 'learning_rate': 2.977094914982754e-05, 'epoch': 1.213743051010348, 'step': 6739000}
INFO:transformers.trainer:{'loss': 3.0434752063751223, 'learning_rate': 2.9769448255714894e-05, 'epoch': 1.2138331046571063, 'step': 6739500}
INFO:transformers.trainer:{'loss': 3.0794913257360457, 'learning_rate': 2.9767947361602257e-05, 'epoch': 1.2139231583038648, 'step': 6740000}
INFO:transformers.trainer:{'loss': 3.029086970329285, 'learning_rate': 2.9766446467489616e-05, 'epoch': 1.2140132119506233, 'step': 6740500}
INFO:transformers.trainer:{'loss': 3.0200280427932737, 'learning_rate': 2.9764945573376975e-05, 'epoch': 1.2141032655973816, 'step': 6741000}
INFO:transformers.trainer:{'loss': 3.0979020644426347, 'learning_rate': 2.9763444679264334e-05, 'epoch': 1.21419331924414, 'step': 6741500}
INFO:transformers.trainer:{'loss': 3.0453391792774203, 'learning_rate': 2.9761943785151693e-05, 'epoch': 1.2142833728908986, 'step': 6742000}
INFO:transformers.trainer:{'loss': 3.0905554758310316, 'learning_rate': 2.9760442891039052e-05, 'epoch': 1.214373426537657, 'step': 6742500}
INFO:transformers.trainer:{'loss': 3.0489898002147675, 'learning_rate': 2.975894199692641e-05, 'epoch': 1.2144634801844154, 'step': 6743000}
INFO:transformers.trainer:{'loss': 3.0367700362205508, 'learning_rate': 2.975744110281377e-05, 'epoch': 1.214553533831174, 'step': 6743500}
INFO:transformers.trainer:{'loss': 3.142602553606033, 'learning_rate': 2.9755940208701126e-05, 'epoch': 1.2146435874779324, 'step': 6744000}
INFO:transformers.trainer:{'loss': 3.0843734788894652, 'learning_rate': 2.9754439314588488e-05, 'epoch': 1.2147336411246907, 'step': 6744500}
INFO:transformers.trainer:{'loss': 3.0813486602306366, 'learning_rate': 2.9752938420475844e-05, 'epoch': 1.2148236947714492, 'step': 6745000}
INFO:transformers.trainer:{'loss': 3.0048421845436097, 'learning_rate': 2.9751437526363206e-05, 'epoch': 1.2149137484182078, 'step': 6745500}
INFO:transformers.trainer:{'loss': 3.0894675810337064, 'learning_rate': 2.9749936632250562e-05, 'epoch': 1.215003802064966, 'step': 6746000}
INFO:transformers.trainer:{'loss': 2.982652757406235, 'learning_rate': 2.9748435738137924e-05, 'epoch': 1.2150938557117246, 'step': 6746500}
INFO:transformers.trainer:{'loss': 3.068809653520584, 'learning_rate': 2.974693484402528e-05, 'epoch': 1.215183909358483, 'step': 6747000}
INFO:transformers.trainer:{'loss': 3.031677993774414, 'learning_rate': 2.9745433949912642e-05, 'epoch': 1.2152739630052416, 'step': 6747500}
INFO:transformers.trainer:{'loss': 3.03464121055603, 'learning_rate': 2.9743933055800005e-05, 'epoch': 1.215364016652, 'step': 6748000}
INFO:transformers.trainer:{'loss': 3.03406899023056, 'learning_rate': 2.974243216168736e-05, 'epoch': 1.2154540702987584, 'step': 6748500}
INFO:transformers.trainer:{'loss': 3.069810084104538, 'learning_rate': 2.9740931267574723e-05, 'epoch': 1.215544123945517, 'step': 6749000}
INFO:transformers.trainer:{'loss': 3.1019573740959165, 'learning_rate': 2.973943037346208e-05, 'epoch': 1.2156341775922752, 'step': 6749500}
INFO:transformers.trainer:{'loss': 3.0608187963962554, 'learning_rate': 2.973792947934944e-05, 'epoch': 1.2157242312390337, 'step': 6750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 2.987296214222908, 'learning_rate': 2.9736428585236797e-05, 'epoch': 1.2158142848857922, 'step': 6750500}
INFO:transformers.trainer:{'loss': 3.020163358449936, 'learning_rate': 2.973492769112416e-05, 'epoch': 1.2159043385325505, 'step': 6751000}
INFO:transformers.trainer:{'loss': 3.0309681109189985, 'learning_rate': 2.9733426797011515e-05, 'epoch': 1.215994392179309, 'step': 6751500}
INFO:transformers.trainer:{'loss': 3.0779666080474852, 'learning_rate': 2.9731925902898877e-05, 'epoch': 1.2160844458260676, 'step': 6752000}
INFO:transformers.trainer:{'loss': 3.020790546655655, 'learning_rate': 2.9730425008786233e-05, 'epoch': 1.2161744994728259, 'step': 6752500}
INFO:transformers.trainer:{'loss': 2.970763494729996, 'learning_rate': 2.9728924114673595e-05, 'epoch': 1.2162645531195844, 'step': 6753000}
INFO:transformers.trainer:{'loss': 3.0838971750736235, 'learning_rate': 2.972742322056095e-05, 'epoch': 1.2163546067663429, 'step': 6753500}
INFO:transformers.trainer:{'loss': 3.0517255222797393, 'learning_rate': 2.9725922326448314e-05, 'epoch': 1.2164446604131012, 'step': 6754000}
INFO:transformers.trainer:{'loss': 3.077809064388275, 'learning_rate': 2.9724421432335676e-05, 'epoch': 1.2165347140598597, 'step': 6754500}
INFO:transformers.trainer:{'loss': 3.0014356149435044, 'learning_rate': 2.972292053822303e-05, 'epoch': 1.2166247677066182, 'step': 6755000}
INFO:transformers.trainer:{'loss': 3.0770483059883116, 'learning_rate': 2.9721419644110394e-05, 'epoch': 1.2167148213533767, 'step': 6755500}
INFO:transformers.trainer:{'loss': 3.053946713924408, 'learning_rate': 2.971991874999775e-05, 'epoch': 1.216804875000135, 'step': 6756000}
INFO:transformers.trainer:{'loss': 3.072909629583359, 'learning_rate': 2.9718417855885112e-05, 'epoch': 1.2168949286468935, 'step': 6756500}
INFO:transformers.trainer:{'loss': 3.045199947118759, 'learning_rate': 2.9716916961772468e-05, 'epoch': 1.216984982293652, 'step': 6757000}
INFO:transformers.trainer:{'loss': 3.0730401492118835, 'learning_rate': 2.971541606765983e-05, 'epoch': 1.2170750359404103, 'step': 6757500}
INFO:transformers.trainer:{'loss': 2.997241425037384, 'learning_rate': 2.9713915173547186e-05, 'epoch': 1.2171650895871688, 'step': 6758000}
INFO:transformers.trainer:{'loss': 2.9808461754322053, 'learning_rate': 2.971241427943455e-05, 'epoch': 1.2172551432339274, 'step': 6758500}
INFO:transformers.trainer:{'loss': 3.1140857372283937, 'learning_rate': 2.9710913385321904e-05, 'epoch': 1.2173451968806859, 'step': 6759000}
INFO:transformers.trainer:{'loss': 3.0432966487407684, 'learning_rate': 2.9709412491209266e-05, 'epoch': 1.2174352505274442, 'step': 6759500}
INFO:transformers.trainer:{'loss': 3.019708018064499, 'learning_rate': 2.9707911597096622e-05, 'epoch': 1.2175253041742027, 'step': 6760000}
INFO:transformers.trainer:{'loss': 3.0694439537525176, 'learning_rate': 2.9706410702983985e-05, 'epoch': 1.2176153578209612, 'step': 6760500}
INFO:transformers.trainer:{'loss': 3.0266666123867036, 'learning_rate': 2.970490980887134e-05, 'epoch': 1.2177054114677195, 'step': 6761000}
INFO:transformers.trainer:{'loss': 3.049245250463486, 'learning_rate': 2.9703408914758703e-05, 'epoch': 1.217795465114478, 'step': 6761500}
INFO:transformers.trainer:{'loss': 2.964417366027832, 'learning_rate': 2.9701908020646062e-05, 'epoch': 1.2178855187612365, 'step': 6762000}
INFO:transformers.trainer:{'loss': 3.131412115454674, 'learning_rate': 2.970040712653342e-05, 'epoch': 1.2179755724079948, 'step': 6762500}
INFO:transformers.trainer:{'loss': 3.002768813967705, 'learning_rate': 2.969890623242078e-05, 'epoch': 1.2180656260547533, 'step': 6763000}
INFO:transformers.trainer:{'loss': 3.0346689302921295, 'learning_rate': 2.969740533830814e-05, 'epoch': 1.2181556797015118, 'step': 6763500}
INFO:transformers.trainer:{'loss': 3.0098547320365907, 'learning_rate': 2.9695904444195498e-05, 'epoch': 1.2182457333482701, 'step': 6764000}
INFO:transformers.trainer:{'loss': 3.0331635831594466, 'learning_rate': 2.9694403550082857e-05, 'epoch': 1.2183357869950286, 'step': 6764500}
INFO:transformers.trainer:{'loss': 3.0222798206806183, 'learning_rate': 2.9692902655970216e-05, 'epoch': 1.2184258406417872, 'step': 6765000}
INFO:transformers.trainer:{'loss': 3.0643631854057314, 'learning_rate': 2.9691401761857575e-05, 'epoch': 1.2185158942885455, 'step': 6765500}
INFO:transformers.trainer:{'loss': 3.0037017049789427, 'learning_rate': 2.9689900867744934e-05, 'epoch': 1.218605947935304, 'step': 6766000}
INFO:transformers.trainer:{'loss': 3.0574668679237367, 'learning_rate': 2.9688399973632293e-05, 'epoch': 1.2186960015820625, 'step': 6766500}
INFO:transformers.trainer:{'loss': 2.9799083156585695, 'learning_rate': 2.9686899079519652e-05, 'epoch': 1.218786055228821, 'step': 6767000}
INFO:transformers.trainer:{'loss': 3.0592391167879103, 'learning_rate': 2.9685398185407008e-05, 'epoch': 1.2188761088755793, 'step': 6767500}
INFO:transformers.trainer:{'loss': 3.046821063041687, 'learning_rate': 2.968389729129437e-05, 'epoch': 1.2189661625223378, 'step': 6768000}
INFO:transformers.trainer:{'loss': 3.1085117656588555, 'learning_rate': 2.9682396397181733e-05, 'epoch': 1.2190562161690963, 'step': 6768500}
INFO:transformers.trainer:{'loss': 3.099951012611389, 'learning_rate': 2.968089550306909e-05, 'epoch': 1.2191462698158546, 'step': 6769000}
INFO:transformers.trainer:{'loss': 3.08922696018219, 'learning_rate': 2.967939460895645e-05, 'epoch': 1.2192363234626131, 'step': 6769500}
INFO:transformers.trainer:{'loss': 3.0451051621437073, 'learning_rate': 2.9677893714843807e-05, 'epoch': 1.2193263771093716, 'step': 6770000}
INFO:transformers.trainer:{'loss': 3.0534552582502363, 'learning_rate': 2.967639282073117e-05, 'epoch': 1.2194164307561302, 'step': 6770500}
INFO:transformers.trainer:{'loss': 3.130938838481903, 'learning_rate': 2.9674891926618525e-05, 'epoch': 1.2195064844028884, 'step': 6771000}
INFO:transformers.trainer:{'loss': 2.9839895590543746, 'learning_rate': 2.9673391032505887e-05, 'epoch': 1.219596538049647, 'step': 6771500}
INFO:transformers.trainer:{'loss': 3.094165864467621, 'learning_rate': 2.9671890138393243e-05, 'epoch': 1.2196865916964055, 'step': 6772000}
INFO:transformers.trainer:{'loss': 3.016792339205742, 'learning_rate': 2.9670389244280605e-05, 'epoch': 1.2197766453431638, 'step': 6772500}
INFO:transformers.trainer:{'loss': 3.0660157039165497, 'learning_rate': 2.966888835016796e-05, 'epoch': 1.2198666989899223, 'step': 6773000}
INFO:transformers.trainer:{'loss': 3.0427776832580564, 'learning_rate': 2.9667387456055323e-05, 'epoch': 1.2199567526366808, 'step': 6773500}
INFO:transformers.trainer:{'loss': 3.0413170297145844, 'learning_rate': 2.966588656194268e-05, 'epoch': 1.220046806283439, 'step': 6774000}
INFO:transformers.trainer:{'loss': 3.0459190492630004, 'learning_rate': 2.966438566783004e-05, 'epoch': 1.2201368599301976, 'step': 6774500}
INFO:transformers.trainer:{'loss': 3.096818888425827, 'learning_rate': 2.9662884773717397e-05, 'epoch': 1.2202269135769561, 'step': 6775000}
INFO:transformers.trainer:{'loss': 3.101348532438278, 'learning_rate': 2.966138387960476e-05, 'epoch': 1.2203169672237144, 'step': 6775500}
INFO:transformers.trainer:{'loss': 3.0479294905662537, 'learning_rate': 2.9659882985492122e-05, 'epoch': 1.220407020870473, 'step': 6776000}
INFO:transformers.trainer:{'loss': 3.052142415881157, 'learning_rate': 2.9658382091379478e-05, 'epoch': 1.2204970745172314, 'step': 6776500}
INFO:transformers.trainer:{'loss': 3.0471794147491456, 'learning_rate': 2.965688119726684e-05, 'epoch': 1.2205871281639897, 'step': 6777000}
INFO:transformers.trainer:{'loss': 3.069808346748352, 'learning_rate': 2.9655380303154196e-05, 'epoch': 1.2206771818107482, 'step': 6777500}
INFO:transformers.trainer:{'loss': 2.997529175460339, 'learning_rate': 2.9653879409041558e-05, 'epoch': 1.2207672354575068, 'step': 6778000}
INFO:transformers.trainer:{'loss': 3.0571684768199923, 'learning_rate': 2.9652378514928914e-05, 'epoch': 1.2208572891042653, 'step': 6778500}
INFO:transformers.trainer:{'loss': 3.053485028028488, 'learning_rate': 2.9650877620816276e-05, 'epoch': 1.2209473427510236, 'step': 6779000}
INFO:transformers.trainer:{'loss': 3.0445090098381042, 'learning_rate': 2.9649376726703632e-05, 'epoch': 1.221037396397782, 'step': 6779500}
INFO:transformers.trainer:{'loss': 3.027135265827179, 'learning_rate': 2.9647875832590994e-05, 'epoch': 1.2211274500445406, 'step': 6780000}
INFO:transformers.trainer:{'loss': 3.076096889138222, 'learning_rate': 2.964637493847835e-05, 'epoch': 1.221217503691299, 'step': 6780500}
INFO:transformers.trainer:{'loss': 3.0339795985221865, 'learning_rate': 2.9644874044365712e-05, 'epoch': 1.2213075573380574, 'step': 6781000}
INFO:transformers.trainer:{'loss': 2.996064229488373, 'learning_rate': 2.9643373150253068e-05, 'epoch': 1.221397610984816, 'step': 6781500}
INFO:transformers.trainer:{'loss': 3.0145207475423814, 'learning_rate': 2.964187225614043e-05, 'epoch': 1.2214876646315744, 'step': 6782000}
INFO:transformers.trainer:{'loss': 2.911240000486374, 'learning_rate': 2.964037136202779e-05, 'epoch': 1.2215777182783327, 'step': 6782500}
INFO:transformers.trainer:{'loss': 3.026463793039322, 'learning_rate': 2.963887046791515e-05, 'epoch': 1.2216677719250912, 'step': 6783000}
INFO:transformers.trainer:{'loss': 3.090605445384979, 'learning_rate': 2.9637369573802508e-05, 'epoch': 1.2217578255718498, 'step': 6783500}
INFO:transformers.trainer:{'loss': 3.02454496216774, 'learning_rate': 2.9635868679689867e-05, 'epoch': 1.221847879218608, 'step': 6784000}
INFO:transformers.trainer:{'loss': 2.988080493986607, 'learning_rate': 2.9634367785577226e-05, 'epoch': 1.2219379328653666, 'step': 6784500}
INFO:transformers.trainer:{'loss': 3.0526604356765747, 'learning_rate': 2.9632866891464585e-05, 'epoch': 1.222027986512125, 'step': 6785000}
INFO:transformers.trainer:{'loss': 3.017969232738018, 'learning_rate': 2.9631365997351944e-05, 'epoch': 1.2221180401588834, 'step': 6785500}
INFO:transformers.trainer:{'loss': 3.0816236312389376, 'learning_rate': 2.9629865103239303e-05, 'epoch': 1.2222080938056419, 'step': 6786000}
INFO:transformers.trainer:{'loss': 3.0519847531318662, 'learning_rate': 2.9628364209126662e-05, 'epoch': 1.2222981474524004, 'step': 6786500}
INFO:transformers.trainer:{'loss': 3.0257064545154573, 'learning_rate': 2.962686331501402e-05, 'epoch': 1.2223882010991587, 'step': 6787000}
INFO:transformers.trainer:{'loss': 3.12839864385128, 'learning_rate': 2.962536242090138e-05, 'epoch': 1.2224782547459172, 'step': 6787500}
INFO:transformers.trainer:{'loss': 3.0375793508291244, 'learning_rate': 2.962386152678874e-05, 'epoch': 1.2225683083926757, 'step': 6788000}
INFO:transformers.trainer:{'loss': 3.0454649797677993, 'learning_rate': 2.9622360632676098e-05, 'epoch': 1.222658362039434, 'step': 6788500}
INFO:transformers.trainer:{'loss': 3.0508973842859266, 'learning_rate': 2.962085973856346e-05, 'epoch': 1.2227484156861925, 'step': 6789000}
INFO:transformers.trainer:{'loss': 3.022373745918274, 'learning_rate': 2.9619358844450816e-05, 'epoch': 1.222838469332951, 'step': 6789500}
INFO:transformers.trainer:{'loss': 3.02709298825264, 'learning_rate': 2.961785795033818e-05, 'epoch': 1.2229285229797096, 'step': 6790000}
INFO:transformers.trainer:{'loss': 3.0554341465234756, 'learning_rate': 2.9616357056225534e-05, 'epoch': 1.2230185766264678, 'step': 6790500}
INFO:transformers.trainer:{'loss': 2.9762947154045105, 'learning_rate': 2.9614856162112897e-05, 'epoch': 1.2231086302732264, 'step': 6791000}
INFO:transformers.trainer:{'loss': 2.9729803668260573, 'learning_rate': 2.9613355268000252e-05, 'epoch': 1.2231986839199849, 'step': 6791500}
INFO:transformers.trainer:{'loss': 3.1484802303314208, 'learning_rate': 2.9611854373887615e-05, 'epoch': 1.2232887375667432, 'step': 6792000}
INFO:transformers.trainer:{'loss': 3.0359704424142837, 'learning_rate': 2.961035347977497e-05, 'epoch': 1.2233787912135017, 'step': 6792500}
INFO:transformers.trainer:{'loss': 3.076074205875397, 'learning_rate': 2.9608852585662333e-05, 'epoch': 1.2234688448602602, 'step': 6793000}
INFO:transformers.trainer:{'loss': 3.1256168134212494, 'learning_rate': 2.960735169154969e-05, 'epoch': 1.2235588985070187, 'step': 6793500}
INFO:transformers.trainer:{'loss': 3.067032492876053, 'learning_rate': 2.960585079743705e-05, 'epoch': 1.223648952153777, 'step': 6794000}
INFO:transformers.trainer:{'loss': 3.0820371487140656, 'learning_rate': 2.9604349903324407e-05, 'epoch': 1.2237390058005355, 'step': 6794500}
INFO:transformers.trainer:{'loss': 3.037448040485382, 'learning_rate': 2.960284900921177e-05, 'epoch': 1.223829059447294, 'step': 6795000}
INFO:transformers.trainer:{'loss': 3.05453536760807, 'learning_rate': 2.9601348115099125e-05, 'epoch': 1.2239191130940523, 'step': 6795500}
INFO:transformers.trainer:{'loss': 3.1216200354099275, 'learning_rate': 2.9599847220986487e-05, 'epoch': 1.2240091667408108, 'step': 6796000}
INFO:transformers.trainer:{'loss': 2.9651435976028444, 'learning_rate': 2.959834632687385e-05, 'epoch': 1.2240992203875694, 'step': 6796500}
INFO:transformers.trainer:{'loss': 3.056306561946869, 'learning_rate': 2.9596845432761205e-05, 'epoch': 1.2241892740343276, 'step': 6797000}
INFO:transformers.trainer:{'loss': 3.065734360456467, 'learning_rate': 2.9595344538648568e-05, 'epoch': 1.2242793276810862, 'step': 6797500}
INFO:transformers.trainer:{'loss': 3.023864782333374, 'learning_rate': 2.9593843644535923e-05, 'epoch': 1.2243693813278447, 'step': 6798000}
INFO:transformers.trainer:{'loss': 3.058050894975662, 'learning_rate': 2.9592342750423286e-05, 'epoch': 1.224459434974603, 'step': 6798500}
INFO:transformers.trainer:{'loss': 3.0659709565639495, 'learning_rate': 2.959084185631064e-05, 'epoch': 1.2245494886213615, 'step': 6799000}
INFO:transformers.trainer:{'loss': 3.0331726243495942, 'learning_rate': 2.9589340962198004e-05, 'epoch': 1.22463954226812, 'step': 6799500}
INFO:transformers.trainer:{'loss': 3.0451895825862882, 'learning_rate': 2.958784006808536e-05, 'epoch': 1.2247295959148783, 'step': 6800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0173128793239594, 'learning_rate': 2.9586339173972722e-05, 'epoch': 1.2248196495616368, 'step': 6800500}
INFO:transformers.trainer:{'loss': 3.1136614339351656, 'learning_rate': 2.9584838279860078e-05, 'epoch': 1.2249097032083953, 'step': 6801000}
INFO:transformers.trainer:{'loss': 3.03898383808136, 'learning_rate': 2.958333738574744e-05, 'epoch': 1.2249997568551538, 'step': 6801500}
INFO:transformers.trainer:{'loss': 3.0338676810264587, 'learning_rate': 2.9581836491634796e-05, 'epoch': 1.2250898105019121, 'step': 6802000}
INFO:transformers.trainer:{'loss': 3.0443688826560975, 'learning_rate': 2.958033559752216e-05, 'epoch': 1.2251798641486706, 'step': 6802500}
INFO:transformers.trainer:{'loss': 2.984929584980011, 'learning_rate': 2.957883470340952e-05, 'epoch': 1.2252699177954292, 'step': 6803000}
INFO:transformers.trainer:{'loss': 3.065612553358078, 'learning_rate': 2.9577333809296876e-05, 'epoch': 1.2253599714421874, 'step': 6803500}
INFO:transformers.trainer:{'loss': 3.0581168394088745, 'learning_rate': 2.957583291518424e-05, 'epoch': 1.225450025088946, 'step': 6804000}
INFO:transformers.trainer:{'loss': 3.06152822971344, 'learning_rate': 2.9574332021071595e-05, 'epoch': 1.2255400787357045, 'step': 6804500}
INFO:transformers.trainer:{'loss': 3.1094033162593844, 'learning_rate': 2.9572831126958957e-05, 'epoch': 1.225630132382463, 'step': 6805000}
INFO:transformers.trainer:{'loss': 3.030658826828003, 'learning_rate': 2.9571330232846313e-05, 'epoch': 1.2257201860292213, 'step': 6805500}
INFO:transformers.trainer:{'loss': 3.0087833800315855, 'learning_rate': 2.956982933873367e-05, 'epoch': 1.2258102396759798, 'step': 6806000}
INFO:transformers.trainer:{'loss': 3.0929963430166243, 'learning_rate': 2.956832844462103e-05, 'epoch': 1.2259002933227383, 'step': 6806500}
INFO:transformers.trainer:{'loss': 3.0333702461719514, 'learning_rate': 2.956682755050839e-05, 'epoch': 1.2259903469694966, 'step': 6807000}
INFO:transformers.trainer:{'loss': 3.0371771111488344, 'learning_rate': 2.956532665639575e-05, 'epoch': 1.2260804006162551, 'step': 6807500}
INFO:transformers.trainer:{'loss': 2.9720930898189546, 'learning_rate': 2.9563825762283108e-05, 'epoch': 1.2261704542630136, 'step': 6808000}
INFO:transformers.trainer:{'loss': 3.0278377816677096, 'learning_rate': 2.9562324868170467e-05, 'epoch': 1.226260507909772, 'step': 6808500}
INFO:transformers.trainer:{'loss': 3.0448514552116395, 'learning_rate': 2.9560823974057826e-05, 'epoch': 1.2263505615565304, 'step': 6809000}
INFO:transformers.trainer:{'loss': 2.995806376576424, 'learning_rate': 2.9559323079945185e-05, 'epoch': 1.226440615203289, 'step': 6809500}
INFO:transformers.trainer:{'loss': 3.043143701553345, 'learning_rate': 2.9557822185832544e-05, 'epoch': 1.2265306688500472, 'step': 6810000}
INFO:transformers.trainer:{'loss': 3.060750927567482, 'learning_rate': 2.9556321291719907e-05, 'epoch': 1.2266207224968058, 'step': 6810500}
INFO:transformers.trainer:{'loss': 3.046816332578659, 'learning_rate': 2.9554820397607262e-05, 'epoch': 1.2267107761435643, 'step': 6811000}
INFO:transformers.trainer:{'loss': 3.047012271642685, 'learning_rate': 2.9553319503494625e-05, 'epoch': 1.2268008297903226, 'step': 6811500}
INFO:transformers.trainer:{'loss': 2.9467527751922606, 'learning_rate': 2.955181860938198e-05, 'epoch': 1.226890883437081, 'step': 6812000}
INFO:transformers.trainer:{'loss': 3.015223242521286, 'learning_rate': 2.9550317715269343e-05, 'epoch': 1.2269809370838396, 'step': 6812500}
INFO:transformers.trainer:{'loss': 3.0765415575504305, 'learning_rate': 2.95488168211567e-05, 'epoch': 1.227070990730598, 'step': 6813000}
INFO:transformers.trainer:{'loss': 3.055619938850403, 'learning_rate': 2.954731592704406e-05, 'epoch': 1.2271610443773564, 'step': 6813500}
INFO:transformers.trainer:{'loss': 3.074585735917091, 'learning_rate': 2.9545815032931416e-05, 'epoch': 1.227251098024115, 'step': 6814000}
INFO:transformers.trainer:{'loss': 3.0669443790912627, 'learning_rate': 2.954431413881878e-05, 'epoch': 1.2273411516708734, 'step': 6814500}
INFO:transformers.trainer:{'loss': 3.064233645439148, 'learning_rate': 2.9542813244706135e-05, 'epoch': 1.2274312053176317, 'step': 6815000}
INFO:transformers.trainer:{'loss': 3.043896430373192, 'learning_rate': 2.9541312350593497e-05, 'epoch': 1.2275212589643902, 'step': 6815500}
INFO:transformers.trainer:{'loss': 3.0221300041675567, 'learning_rate': 2.9539811456480853e-05, 'epoch': 1.2276113126111488, 'step': 6816000}
INFO:transformers.trainer:{'loss': 3.0274566385746002, 'learning_rate': 2.9538310562368215e-05, 'epoch': 1.2277013662579073, 'step': 6816500}
INFO:transformers.trainer:{'loss': 3.0288448300361632, 'learning_rate': 2.9536809668255578e-05, 'epoch': 1.2277914199046656, 'step': 6817000}
INFO:transformers.trainer:{'loss': 3.0528667135238647, 'learning_rate': 2.9535308774142933e-05, 'epoch': 1.227881473551424, 'step': 6817500}
INFO:transformers.trainer:{'loss': 3.088990919828415, 'learning_rate': 2.9533807880030296e-05, 'epoch': 1.2279715271981826, 'step': 6818000}
INFO:transformers.trainer:{'loss': 3.0942981573343276, 'learning_rate': 2.953230698591765e-05, 'epoch': 1.2280615808449409, 'step': 6818500}
INFO:transformers.trainer:{'loss': 3.0205831302404405, 'learning_rate': 2.9530806091805014e-05, 'epoch': 1.2281516344916994, 'step': 6819000}
INFO:transformers.trainer:{'loss': 3.0550339732170104, 'learning_rate': 2.952930519769237e-05, 'epoch': 1.228241688138458, 'step': 6819500}
INFO:transformers.trainer:{'loss': 3.0869669061899185, 'learning_rate': 2.9527804303579732e-05, 'epoch': 1.2283317417852162, 'step': 6820000}
INFO:transformers.trainer:{'loss': 2.994300460100174, 'learning_rate': 2.9526303409467088e-05, 'epoch': 1.2284217954319747, 'step': 6820500}
INFO:transformers.trainer:{'loss': 3.077456293106079, 'learning_rate': 2.952480251535445e-05, 'epoch': 1.2285118490787332, 'step': 6821000}
INFO:transformers.trainer:{'loss': 3.0900343528985976, 'learning_rate': 2.9523301621241806e-05, 'epoch': 1.2286019027254915, 'step': 6821500}
INFO:transformers.trainer:{'loss': 3.0398095536231993, 'learning_rate': 2.9521800727129168e-05, 'epoch': 1.22869195637225, 'step': 6822000}
INFO:transformers.trainer:{'loss': 3.0429325890541077, 'learning_rate': 2.9520299833016524e-05, 'epoch': 1.2287820100190086, 'step': 6822500}
INFO:transformers.trainer:{'loss': 3.113638612270355, 'learning_rate': 2.9518798938903886e-05, 'epoch': 1.228872063665767, 'step': 6823000}
INFO:transformers.trainer:{'loss': 3.082889472603798, 'learning_rate': 2.9517298044791242e-05, 'epoch': 1.2289621173125254, 'step': 6823500}
INFO:transformers.trainer:{'loss': 3.070890191078186, 'learning_rate': 2.9515797150678604e-05, 'epoch': 1.2290521709592839, 'step': 6824000}
INFO:transformers.trainer:{'loss': 3.0634311242103576, 'learning_rate': 2.9514296256565967e-05, 'epoch': 1.2291422246060424, 'step': 6824500}
INFO:transformers.trainer:{'loss': 3.0718047049045563, 'learning_rate': 2.9512795362453322e-05, 'epoch': 1.2292322782528007, 'step': 6825000}
INFO:transformers.trainer:{'loss': 3.0203536882400512, 'learning_rate': 2.9511294468340685e-05, 'epoch': 1.2293223318995592, 'step': 6825500}
INFO:transformers.trainer:{'loss': 3.051195846796036, 'learning_rate': 2.950979357422804e-05, 'epoch': 1.2294123855463177, 'step': 6826000}
INFO:transformers.trainer:{'loss': 3.021915408372879, 'learning_rate': 2.9508292680115403e-05, 'epoch': 1.229502439193076, 'step': 6826500}
INFO:transformers.trainer:{'loss': 3.0346358530521393, 'learning_rate': 2.950679178600276e-05, 'epoch': 1.2295924928398345, 'step': 6827000}
INFO:transformers.trainer:{'loss': 3.00300683760643, 'learning_rate': 2.950529089189012e-05, 'epoch': 1.229682546486593, 'step': 6827500}
INFO:transformers.trainer:{'loss': 3.058109517931938, 'learning_rate': 2.9503789997777477e-05, 'epoch': 1.2297726001333515, 'step': 6828000}
INFO:transformers.trainer:{'loss': 3.023995887041092, 'learning_rate': 2.950228910366484e-05, 'epoch': 1.2298626537801098, 'step': 6828500}
INFO:transformers.trainer:{'loss': 3.1228737231493, 'learning_rate': 2.9500788209552195e-05, 'epoch': 1.2299527074268684, 'step': 6829000}
INFO:transformers.trainer:{'loss': 3.0877978212833406, 'learning_rate': 2.9499287315439554e-05, 'epoch': 1.2300427610736269, 'step': 6829500}
INFO:transformers.trainer:{'loss': 3.0557819092273713, 'learning_rate': 2.9497786421326913e-05, 'epoch': 1.2301328147203852, 'step': 6830000}
INFO:transformers.trainer:{'loss': 3.014363347530365, 'learning_rate': 2.9496285527214272e-05, 'epoch': 1.2302228683671437, 'step': 6830500}
INFO:transformers.trainer:{'loss': 3.0366354595422744, 'learning_rate': 2.9494784633101634e-05, 'epoch': 1.2303129220139022, 'step': 6831000}
INFO:transformers.trainer:{'loss': 3.1008410165309908, 'learning_rate': 2.949328373898899e-05, 'epoch': 1.2304029756606605, 'step': 6831500}
INFO:transformers.trainer:{'loss': 3.1249734196662904, 'learning_rate': 2.9491782844876352e-05, 'epoch': 1.230493029307419, 'step': 6832000}
INFO:transformers.trainer:{'loss': 3.129819700717926, 'learning_rate': 2.9490281950763708e-05, 'epoch': 1.2305830829541775, 'step': 6832500}
INFO:transformers.trainer:{'loss': 3.0681565803289415, 'learning_rate': 2.948878105665107e-05, 'epoch': 1.2306731366009358, 'step': 6833000}
INFO:transformers.trainer:{'loss': 3.0258601608276368, 'learning_rate': 2.9487280162538426e-05, 'epoch': 1.2307631902476943, 'step': 6833500}
INFO:transformers.trainer:{'loss': 3.089989143371582, 'learning_rate': 2.948577926842579e-05, 'epoch': 1.2308532438944528, 'step': 6834000}
INFO:transformers.trainer:{'loss': 3.090319866657257, 'learning_rate': 2.9484278374313144e-05, 'epoch': 1.2309432975412113, 'step': 6834500}
INFO:transformers.trainer:{'loss': 3.0084433817863463, 'learning_rate': 2.9482777480200507e-05, 'epoch': 1.2310333511879696, 'step': 6835000}
INFO:transformers.trainer:{'loss': 3.0757936658859255, 'learning_rate': 2.9481276586087862e-05, 'epoch': 1.2311234048347282, 'step': 6835500}
INFO:transformers.trainer:{'loss': 3.060519775211811, 'learning_rate': 2.9479775691975225e-05, 'epoch': 1.2312134584814867, 'step': 6836000}
INFO:transformers.trainer:{'loss': 2.9901085407733916, 'learning_rate': 2.947827479786258e-05, 'epoch': 1.231303512128245, 'step': 6836500}
INFO:transformers.trainer:{'loss': 3.031905244588852, 'learning_rate': 2.9476773903749943e-05, 'epoch': 1.2313935657750035, 'step': 6837000}
INFO:transformers.trainer:{'loss': 3.082991753578186, 'learning_rate': 2.9475273009637305e-05, 'epoch': 1.231483619421762, 'step': 6837500}
INFO:transformers.trainer:{'loss': 3.0639112861156463, 'learning_rate': 2.947377211552466e-05, 'epoch': 1.2315736730685205, 'step': 6838000}
INFO:transformers.trainer:{'loss': 3.018281693696976, 'learning_rate': 2.9472271221412023e-05, 'epoch': 1.2316637267152788, 'step': 6838500}
INFO:transformers.trainer:{'loss': 3.033694135427475, 'learning_rate': 2.947077032729938e-05, 'epoch': 1.2317537803620373, 'step': 6839000}
INFO:transformers.trainer:{'loss': 3.0936435202360153, 'learning_rate': 2.946926943318674e-05, 'epoch': 1.2318438340087958, 'step': 6839500}
INFO:transformers.trainer:{'loss': 3.0187847473621368, 'learning_rate': 2.9467768539074097e-05, 'epoch': 1.2319338876555541, 'step': 6840000}
INFO:transformers.trainer:{'loss': 3.103034625172615, 'learning_rate': 2.946626764496146e-05, 'epoch': 1.2320239413023126, 'step': 6840500}
INFO:transformers.trainer:{'loss': 3.0432803868055345, 'learning_rate': 2.9464766750848815e-05, 'epoch': 1.2321139949490711, 'step': 6841000}
INFO:transformers.trainer:{'loss': 2.9834600479602815, 'learning_rate': 2.9463265856736178e-05, 'epoch': 1.2322040485958294, 'step': 6841500}
INFO:transformers.trainer:{'loss': 3.075299549460411, 'learning_rate': 2.9461764962623533e-05, 'epoch': 1.232294102242588, 'step': 6842000}
INFO:transformers.trainer:{'loss': 3.011458563685417, 'learning_rate': 2.9460264068510896e-05, 'epoch': 1.2323841558893465, 'step': 6842500}
INFO:transformers.trainer:{'loss': 3.027280366539955, 'learning_rate': 2.945876317439825e-05, 'epoch': 1.2324742095361048, 'step': 6843000}
INFO:transformers.trainer:{'loss': 3.051476632595062, 'learning_rate': 2.9457262280285614e-05, 'epoch': 1.2325642631828633, 'step': 6843500}
INFO:transformers.trainer:{'loss': 3.0885756568908693, 'learning_rate': 2.945576138617297e-05, 'epoch': 1.2326543168296218, 'step': 6844000}
INFO:transformers.trainer:{'loss': 3.05377622961998, 'learning_rate': 2.9454260492060332e-05, 'epoch': 1.23274437047638, 'step': 6844500}
INFO:transformers.trainer:{'loss': 3.0651286301612855, 'learning_rate': 2.9452759597947695e-05, 'epoch': 1.2328344241231386, 'step': 6845000}
INFO:transformers.trainer:{'loss': 3.052383796453476, 'learning_rate': 2.945125870383505e-05, 'epoch': 1.232924477769897, 'step': 6845500}
INFO:transformers.trainer:{'loss': 3.054107329368591, 'learning_rate': 2.9449757809722413e-05, 'epoch': 1.2330145314166556, 'step': 6846000}
INFO:transformers.trainer:{'loss': 3.0523221986293794, 'learning_rate': 2.9448256915609768e-05, 'epoch': 1.233104585063414, 'step': 6846500}
INFO:transformers.trainer:{'loss': 3.009170465230942, 'learning_rate': 2.944675602149713e-05, 'epoch': 1.2331946387101724, 'step': 6847000}
INFO:transformers.trainer:{'loss': 3.0983394844532013, 'learning_rate': 2.9445255127384486e-05, 'epoch': 1.233284692356931, 'step': 6847500}
INFO:transformers.trainer:{'loss': 3.096294480085373, 'learning_rate': 2.944375423327185e-05, 'epoch': 1.2333747460036892, 'step': 6848000}
INFO:transformers.trainer:{'loss': 3.020447517156601, 'learning_rate': 2.9442253339159204e-05, 'epoch': 1.2334647996504478, 'step': 6848500}
INFO:transformers.trainer:{'loss': 3.0552763924598696, 'learning_rate': 2.9440752445046567e-05, 'epoch': 1.2335548532972063, 'step': 6849000}
INFO:transformers.trainer:{'loss': 3.08307901763916, 'learning_rate': 2.9439251550933923e-05, 'epoch': 1.2336449069439648, 'step': 6849500}
INFO:transformers.trainer:{'loss': 3.025413094043732, 'learning_rate': 2.9437750656821285e-05, 'epoch': 1.233734960590723, 'step': 6850000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6850000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6850000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6850000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6750000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0121907118558884, 'learning_rate': 2.943624976270864e-05, 'epoch': 1.2338250142374816, 'step': 6850500}
INFO:transformers.trainer:{'loss': 3.047113593816757, 'learning_rate': 2.9434748868596003e-05, 'epoch': 1.23391506788424, 'step': 6851000}
INFO:transformers.trainer:{'loss': 3.016676371335983, 'learning_rate': 2.9433247974483362e-05, 'epoch': 1.2340051215309984, 'step': 6851500}
INFO:transformers.trainer:{'loss': 3.072896423816681, 'learning_rate': 2.943174708037072e-05, 'epoch': 1.234095175177757, 'step': 6852000}
INFO:transformers.trainer:{'loss': 3.1257736327648162, 'learning_rate': 2.943024618625808e-05, 'epoch': 1.2341852288245154, 'step': 6852500}
INFO:transformers.trainer:{'loss': 3.0911985030174254, 'learning_rate': 2.942874529214544e-05, 'epoch': 1.2342752824712737, 'step': 6853000}
INFO:transformers.trainer:{'loss': 3.051294289112091, 'learning_rate': 2.94272443980328e-05, 'epoch': 1.2343653361180322, 'step': 6853500}
INFO:transformers.trainer:{'loss': 3.075839094877243, 'learning_rate': 2.9425743503920154e-05, 'epoch': 1.2344553897647907, 'step': 6854000}
INFO:transformers.trainer:{'loss': 3.0662102744579314, 'learning_rate': 2.9424242609807516e-05, 'epoch': 1.234545443411549, 'step': 6854500}
INFO:transformers.trainer:{'loss': 3.0310140351057053, 'learning_rate': 2.9422741715694872e-05, 'epoch': 1.2346354970583076, 'step': 6855000}
INFO:transformers.trainer:{'loss': 3.0751258533000945, 'learning_rate': 2.9421240821582235e-05, 'epoch': 1.234725550705066, 'step': 6855500}
INFO:transformers.trainer:{'loss': 3.023355549812317, 'learning_rate': 2.941973992746959e-05, 'epoch': 1.2348156043518244, 'step': 6856000}
INFO:transformers.trainer:{'loss': 3.011616996526718, 'learning_rate': 2.9418239033356953e-05, 'epoch': 1.2349056579985829, 'step': 6856500}
INFO:transformers.trainer:{'loss': 3.0449911932945253, 'learning_rate': 2.941673813924431e-05, 'epoch': 1.2349957116453414, 'step': 6857000}
INFO:transformers.trainer:{'loss': 3.084716908454895, 'learning_rate': 2.941523724513167e-05, 'epoch': 1.2350857652921, 'step': 6857500}
INFO:transformers.trainer:{'loss': 3.080547705888748, 'learning_rate': 2.9413736351019026e-05, 'epoch': 1.2351758189388582, 'step': 6858000}
INFO:transformers.trainer:{'loss': 3.1067541627883912, 'learning_rate': 2.941223545690639e-05, 'epoch': 1.2352658725856167, 'step': 6858500}
INFO:transformers.trainer:{'loss': 3.05668022441864, 'learning_rate': 2.941073456279375e-05, 'epoch': 1.2353559262323752, 'step': 6859000}
INFO:transformers.trainer:{'loss': 3.01445823097229, 'learning_rate': 2.9409233668681107e-05, 'epoch': 1.2354459798791335, 'step': 6859500}
INFO:transformers.trainer:{'loss': 3.0188687098026277, 'learning_rate': 2.940773277456847e-05, 'epoch': 1.235536033525892, 'step': 6860000}
INFO:transformers.trainer:{'loss': 3.1060879374742507, 'learning_rate': 2.9406231880455825e-05, 'epoch': 1.2356260871726505, 'step': 6860500}
INFO:transformers.trainer:{'loss': 3.0563792979717253, 'learning_rate': 2.9404730986343188e-05, 'epoch': 1.235716140819409, 'step': 6861000}
INFO:transformers.trainer:{'loss': 3.0450007581710814, 'learning_rate': 2.9403230092230543e-05, 'epoch': 1.2358061944661674, 'step': 6861500}
INFO:transformers.trainer:{'loss': 2.9820117955207825, 'learning_rate': 2.9401729198117906e-05, 'epoch': 1.2358962481129259, 'step': 6862000}
INFO:transformers.trainer:{'loss': 3.082827695131302, 'learning_rate': 2.940022830400526e-05, 'epoch': 1.2359863017596844, 'step': 6862500}
INFO:transformers.trainer:{'loss': 3.034183759689331, 'learning_rate': 2.9398727409892624e-05, 'epoch': 1.2360763554064427, 'step': 6863000}
INFO:transformers.trainer:{'loss': 3.038008535861969, 'learning_rate': 2.939722651577998e-05, 'epoch': 1.2361664090532012, 'step': 6863500}
INFO:transformers.trainer:{'loss': 3.0579944578409193, 'learning_rate': 2.9395725621667342e-05, 'epoch': 1.2362564626999597, 'step': 6864000}
INFO:transformers.trainer:{'loss': 3.0325591781139374, 'learning_rate': 2.9394224727554697e-05, 'epoch': 1.236346516346718, 'step': 6864500}
INFO:transformers.trainer:{'loss': 3.0841496040821075, 'learning_rate': 2.939272383344206e-05, 'epoch': 1.2364365699934765, 'step': 6865000}
INFO:transformers.trainer:{'loss': 3.071872885465622, 'learning_rate': 2.9391222939329422e-05, 'epoch': 1.236526623640235, 'step': 6865500}
INFO:transformers.trainer:{'loss': 3.0046239038705824, 'learning_rate': 2.9389722045216778e-05, 'epoch': 1.2366166772869933, 'step': 6866000}
INFO:transformers.trainer:{'loss': 2.9705249316692353, 'learning_rate': 2.938822115110414e-05, 'epoch': 1.2367067309337518, 'step': 6866500}
INFO:transformers.trainer:{'loss': 3.079358315229416, 'learning_rate': 2.9386720256991496e-05, 'epoch': 1.2367967845805103, 'step': 6867000}
INFO:transformers.trainer:{'loss': 3.037006670475006, 'learning_rate': 2.938521936287886e-05, 'epoch': 1.2368868382272686, 'step': 6867500}
INFO:transformers.trainer:{'loss': 3.048601238012314, 'learning_rate': 2.9383718468766214e-05, 'epoch': 1.2369768918740272, 'step': 6868000}
INFO:transformers.trainer:{'loss': 3.001995204925537, 'learning_rate': 2.9382217574653577e-05, 'epoch': 1.2370669455207857, 'step': 6868500}
INFO:transformers.trainer:{'loss': 3.0581502079963685, 'learning_rate': 2.9380716680540932e-05, 'epoch': 1.2371569991675442, 'step': 6869000}
INFO:transformers.trainer:{'loss': 3.075693280220032, 'learning_rate': 2.9379215786428295e-05, 'epoch': 1.2372470528143025, 'step': 6869500}
INFO:transformers.trainer:{'loss': 3.0856811845302583, 'learning_rate': 2.937771489231565e-05, 'epoch': 1.237337106461061, 'step': 6870000}
INFO:transformers.trainer:{'loss': 3.0137715039253234, 'learning_rate': 2.9376213998203013e-05, 'epoch': 1.2374271601078195, 'step': 6870500}
INFO:transformers.trainer:{'loss': 3.0717452285289766, 'learning_rate': 2.937471310409037e-05, 'epoch': 1.2375172137545778, 'step': 6871000}
INFO:transformers.trainer:{'loss': 3.0045425288677214, 'learning_rate': 2.937321220997773e-05, 'epoch': 1.2376072674013363, 'step': 6871500}
INFO:transformers.trainer:{'loss': 3.0798146966695787, 'learning_rate': 2.9371711315865087e-05, 'epoch': 1.2376973210480948, 'step': 6872000}
INFO:transformers.trainer:{'loss': 3.075196531534195, 'learning_rate': 2.937021042175245e-05, 'epoch': 1.2377873746948533, 'step': 6872500}
INFO:transformers.trainer:{'loss': 3.062232235908508, 'learning_rate': 2.9368709527639808e-05, 'epoch': 1.2378774283416116, 'step': 6873000}
INFO:transformers.trainer:{'loss': 3.034116447925568, 'learning_rate': 2.9367208633527167e-05, 'epoch': 1.2379674819883701, 'step': 6873500}
INFO:transformers.trainer:{'loss': 3.058986197710037, 'learning_rate': 2.9365707739414526e-05, 'epoch': 1.2380575356351287, 'step': 6874000}
INFO:transformers.trainer:{'loss': 3.019479239463806, 'learning_rate': 2.9364206845301885e-05, 'epoch': 1.238147589281887, 'step': 6874500}
INFO:transformers.trainer:{'loss': 3.0617499088048934, 'learning_rate': 2.9362705951189244e-05, 'epoch': 1.2382376429286455, 'step': 6875000}
INFO:transformers.trainer:{'loss': 3.058170588493347, 'learning_rate': 2.9361205057076603e-05, 'epoch': 1.238327696575404, 'step': 6875500}
INFO:transformers.trainer:{'loss': 3.023232063293457, 'learning_rate': 2.9359704162963962e-05, 'epoch': 1.2384177502221623, 'step': 6876000}
INFO:transformers.trainer:{'loss': 3.021483279943466, 'learning_rate': 2.935820326885132e-05, 'epoch': 1.2385078038689208, 'step': 6876500}
INFO:transformers.trainer:{'loss': 3.0575592788457873, 'learning_rate': 2.935670237473868e-05, 'epoch': 1.2385978575156793, 'step': 6877000}
INFO:transformers.trainer:{'loss': 2.9951660994291305, 'learning_rate': 2.9355201480626036e-05, 'epoch': 1.2386879111624376, 'step': 6877500}
INFO:transformers.trainer:{'loss': 3.0430335634946823, 'learning_rate': 2.93537005865134e-05, 'epoch': 1.238777964809196, 'step': 6878000}
INFO:transformers.trainer:{'loss': 3.094443196892738, 'learning_rate': 2.9352199692400754e-05, 'epoch': 1.2388680184559546, 'step': 6878500}
INFO:transformers.trainer:{'loss': 3.0604041628837586, 'learning_rate': 2.9350698798288117e-05, 'epoch': 1.238958072102713, 'step': 6879000}
INFO:transformers.trainer:{'loss': 3.093150676250458, 'learning_rate': 2.934919790417548e-05, 'epoch': 1.2390481257494714, 'step': 6879500}
INFO:transformers.trainer:{'loss': 3.0092418932914735, 'learning_rate': 2.9347697010062835e-05, 'epoch': 1.23913817939623, 'step': 6880000}
INFO:transformers.trainer:{'loss': 2.9844023466110228, 'learning_rate': 2.9346196115950197e-05, 'epoch': 1.2392282330429885, 'step': 6880500}
INFO:transformers.trainer:{'loss': 3.029600672006607, 'learning_rate': 2.9344695221837553e-05, 'epoch': 1.2393182866897468, 'step': 6881000}
INFO:transformers.trainer:{'loss': 3.058413959026337, 'learning_rate': 2.9343194327724915e-05, 'epoch': 1.2394083403365053, 'step': 6881500}
INFO:transformers.trainer:{'loss': 3.0569605059623717, 'learning_rate': 2.934169343361227e-05, 'epoch': 1.2394983939832638, 'step': 6882000}
INFO:transformers.trainer:{'loss': 3.0457564396858214, 'learning_rate': 2.9340192539499633e-05, 'epoch': 1.239588447630022, 'step': 6882500}
INFO:transformers.trainer:{'loss': 3.0490485022068023, 'learning_rate': 2.933869164538699e-05, 'epoch': 1.2396785012767806, 'step': 6883000}
INFO:transformers.trainer:{'loss': 3.08384220123291, 'learning_rate': 2.933719075127435e-05, 'epoch': 1.239768554923539, 'step': 6883500}
INFO:transformers.trainer:{'loss': 3.0773011920452116, 'learning_rate': 2.9335689857161707e-05, 'epoch': 1.2398586085702976, 'step': 6884000}
INFO:transformers.trainer:{'loss': 3.0591729776859284, 'learning_rate': 2.933418896304907e-05, 'epoch': 1.239948662217056, 'step': 6884500}
INFO:transformers.trainer:{'loss': 2.991304010629654, 'learning_rate': 2.9332688068936425e-05, 'epoch': 1.2400387158638144, 'step': 6885000}
INFO:transformers.trainer:{'loss': 3.077305592536926, 'learning_rate': 2.9331187174823788e-05, 'epoch': 1.240128769510573, 'step': 6885500}
INFO:transformers.trainer:{'loss': 3.0235593019723894, 'learning_rate': 2.9329686280711143e-05, 'epoch': 1.2402188231573312, 'step': 6886000}
INFO:transformers.trainer:{'loss': 3.0601746447086335, 'learning_rate': 2.9328185386598506e-05, 'epoch': 1.2403088768040897, 'step': 6886500}
INFO:transformers.trainer:{'loss': 3.058804498076439, 'learning_rate': 2.9326684492485868e-05, 'epoch': 1.2403989304508483, 'step': 6887000}
INFO:transformers.trainer:{'loss': 3.0525521202087402, 'learning_rate': 2.9325183598373224e-05, 'epoch': 1.2404889840976066, 'step': 6887500}
INFO:transformers.trainer:{'loss': 3.0413445620536805, 'learning_rate': 2.9323682704260586e-05, 'epoch': 1.240579037744365, 'step': 6888000}
INFO:transformers.trainer:{'loss': 3.0496951888799666, 'learning_rate': 2.9322181810147942e-05, 'epoch': 1.2406690913911236, 'step': 6888500}
INFO:transformers.trainer:{'loss': 3.0139020332098005, 'learning_rate': 2.9320680916035304e-05, 'epoch': 1.2407591450378819, 'step': 6889000}
INFO:transformers.trainer:{'loss': 3.0867518844604493, 'learning_rate': 2.931918002192266e-05, 'epoch': 1.2408491986846404, 'step': 6889500}
INFO:transformers.trainer:{'loss': 3.0432724068164827, 'learning_rate': 2.9317679127810023e-05, 'epoch': 1.240939252331399, 'step': 6890000}
INFO:transformers.trainer:{'loss': 3.0498873813152314, 'learning_rate': 2.9316178233697378e-05, 'epoch': 1.2410293059781572, 'step': 6890500}
INFO:transformers.trainer:{'loss': 3.0686767013072966, 'learning_rate': 2.931467733958474e-05, 'epoch': 1.2411193596249157, 'step': 6891000}
INFO:transformers.trainer:{'loss': 2.970881965637207, 'learning_rate': 2.9313176445472096e-05, 'epoch': 1.2412094132716742, 'step': 6891500}
INFO:transformers.trainer:{'loss': 3.046632546901703, 'learning_rate': 2.931167555135946e-05, 'epoch': 1.2412994669184327, 'step': 6892000}
INFO:transformers.trainer:{'loss': 3.067672169685364, 'learning_rate': 2.9310174657246814e-05, 'epoch': 1.241389520565191, 'step': 6892500}
INFO:transformers.trainer:{'loss': 3.0029689114093783, 'learning_rate': 2.9308673763134177e-05, 'epoch': 1.2414795742119495, 'step': 6893000}
INFO:transformers.trainer:{'loss': 3.05555532181263, 'learning_rate': 2.9307172869021536e-05, 'epoch': 1.241569627858708, 'step': 6893500}
INFO:transformers.trainer:{'loss': 3.0623620979785917, 'learning_rate': 2.9305671974908895e-05, 'epoch': 1.2416596815054664, 'step': 6894000}
INFO:transformers.trainer:{'loss': 3.041614289164543, 'learning_rate': 2.9304171080796254e-05, 'epoch': 1.2417497351522249, 'step': 6894500}
INFO:transformers.trainer:{'loss': 2.939566865324974, 'learning_rate': 2.9302670186683613e-05, 'epoch': 1.2418397887989834, 'step': 6895000}
INFO:transformers.trainer:{'loss': 3.024907120704651, 'learning_rate': 2.9301169292570972e-05, 'epoch': 1.241929842445742, 'step': 6895500}
INFO:transformers.trainer:{'loss': 3.066190102458, 'learning_rate': 2.929966839845833e-05, 'epoch': 1.2420198960925002, 'step': 6896000}
INFO:transformers.trainer:{'loss': 2.9889723294973374, 'learning_rate': 2.929816750434569e-05, 'epoch': 1.2421099497392587, 'step': 6896500}
INFO:transformers.trainer:{'loss': 3.033532791733742, 'learning_rate': 2.929666661023305e-05, 'epoch': 1.2422000033860172, 'step': 6897000}
INFO:transformers.trainer:{'loss': 2.967021789550781, 'learning_rate': 2.929516571612041e-05, 'epoch': 1.2422900570327755, 'step': 6897500}
INFO:transformers.trainer:{'loss': 3.0351399168968203, 'learning_rate': 2.9293664822007767e-05, 'epoch': 1.242380110679534, 'step': 6898000}
INFO:transformers.trainer:{'loss': 3.0361912010908125, 'learning_rate': 2.9292163927895126e-05, 'epoch': 1.2424701643262925, 'step': 6898500}
INFO:transformers.trainer:{'loss': 3.056505705475807, 'learning_rate': 2.9290663033782485e-05, 'epoch': 1.2425602179730508, 'step': 6899000}
INFO:transformers.trainer:{'loss': 3.085898585319519, 'learning_rate': 2.9289162139669845e-05, 'epoch': 1.2426502716198093, 'step': 6899500}
INFO:transformers.trainer:{'loss': 3.020575245141983, 'learning_rate': 2.9287661245557207e-05, 'epoch': 1.2427403252665679, 'step': 6900000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6900000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6900000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6900000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6800000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.059440802335739, 'learning_rate': 2.9286160351444563e-05, 'epoch': 1.2428303789133262, 'step': 6900500}
INFO:transformers.trainer:{'loss': 3.0105090074539183, 'learning_rate': 2.9284659457331925e-05, 'epoch': 1.2429204325600847, 'step': 6901000}
INFO:transformers.trainer:{'loss': 3.081829847574234, 'learning_rate': 2.928315856321928e-05, 'epoch': 1.2430104862068432, 'step': 6901500}
INFO:transformers.trainer:{'loss': 3.0810291941165926, 'learning_rate': 2.9281657669106643e-05, 'epoch': 1.2431005398536015, 'step': 6902000}
INFO:transformers.trainer:{'loss': 3.0000774449110033, 'learning_rate': 2.9280156774994e-05, 'epoch': 1.24319059350036, 'step': 6902500}
INFO:transformers.trainer:{'loss': 3.0494859389066695, 'learning_rate': 2.927865588088136e-05, 'epoch': 1.2432806471471185, 'step': 6903000}
INFO:transformers.trainer:{'loss': 3.0401701793670655, 'learning_rate': 2.9277154986768717e-05, 'epoch': 1.243370700793877, 'step': 6903500}
INFO:transformers.trainer:{'loss': 3.0412016776800157, 'learning_rate': 2.927565409265608e-05, 'epoch': 1.2434607544406353, 'step': 6904000}
INFO:transformers.trainer:{'loss': 3.0923808338642123, 'learning_rate': 2.9274153198543435e-05, 'epoch': 1.2435508080873938, 'step': 6904500}
INFO:transformers.trainer:{'loss': 3.014983896493912, 'learning_rate': 2.9272652304430797e-05, 'epoch': 1.2436408617341523, 'step': 6905000}
INFO:transformers.trainer:{'loss': 3.0356990826129913, 'learning_rate': 2.9271151410318153e-05, 'epoch': 1.2437309153809106, 'step': 6905500}
INFO:transformers.trainer:{'loss': 3.035728104233742, 'learning_rate': 2.9269650516205516e-05, 'epoch': 1.2438209690276691, 'step': 6906000}
INFO:transformers.trainer:{'loss': 3.0287596504688263, 'learning_rate': 2.926814962209287e-05, 'epoch': 1.2439110226744277, 'step': 6906500}
INFO:transformers.trainer:{'loss': 3.0257600786685943, 'learning_rate': 2.9266648727980234e-05, 'epoch': 1.2440010763211862, 'step': 6907000}
INFO:transformers.trainer:{'loss': 3.088311365365982, 'learning_rate': 2.9265147833867596e-05, 'epoch': 1.2440911299679445, 'step': 6907500}
INFO:transformers.trainer:{'loss': 3.0890434238910673, 'learning_rate': 2.9263646939754952e-05, 'epoch': 1.244181183614703, 'step': 6908000}
INFO:transformers.trainer:{'loss': 3.04493608045578, 'learning_rate': 2.9262146045642314e-05, 'epoch': 1.2442712372614615, 'step': 6908500}
INFO:transformers.trainer:{'loss': 3.053406986474991, 'learning_rate': 2.926064515152967e-05, 'epoch': 1.2443612909082198, 'step': 6909000}
INFO:transformers.trainer:{'loss': 3.0236032310724257, 'learning_rate': 2.9259144257417032e-05, 'epoch': 1.2444513445549783, 'step': 6909500}
INFO:transformers.trainer:{'loss': 3.089597469329834, 'learning_rate': 2.9257643363304388e-05, 'epoch': 1.2445413982017368, 'step': 6910000}
INFO:transformers.trainer:{'loss': 3.034988574385643, 'learning_rate': 2.925614246919175e-05, 'epoch': 1.244631451848495, 'step': 6910500}
INFO:transformers.trainer:{'loss': 3.020801486134529, 'learning_rate': 2.9254641575079106e-05, 'epoch': 1.2447215054952536, 'step': 6911000}
INFO:transformers.trainer:{'loss': 3.066287458896637, 'learning_rate': 2.925314068096647e-05, 'epoch': 1.2448115591420121, 'step': 6911500}
INFO:transformers.trainer:{'loss': 3.061050036430359, 'learning_rate': 2.9251639786853824e-05, 'epoch': 1.2449016127887704, 'step': 6912000}
INFO:transformers.trainer:{'loss': 3.116756744623184, 'learning_rate': 2.9250138892741187e-05, 'epoch': 1.244991666435529, 'step': 6912500}
INFO:transformers.trainer:{'loss': 3.0351534937620164, 'learning_rate': 2.9248637998628542e-05, 'epoch': 1.2450817200822875, 'step': 6913000}
INFO:transformers.trainer:{'loss': 3.0582075347900393, 'learning_rate': 2.9247137104515905e-05, 'epoch': 1.2451717737290457, 'step': 6913500}
INFO:transformers.trainer:{'loss': 3.0600420936346056, 'learning_rate': 2.9245636210403267e-05, 'epoch': 1.2452618273758043, 'step': 6914000}
INFO:transformers.trainer:{'loss': 3.064401438951492, 'learning_rate': 2.9244135316290623e-05, 'epoch': 1.2453518810225628, 'step': 6914500}
INFO:transformers.trainer:{'loss': 3.046724468231201, 'learning_rate': 2.9242634422177985e-05, 'epoch': 1.2454419346693213, 'step': 6915000}
INFO:transformers.trainer:{'loss': 3.0585764472484587, 'learning_rate': 2.924113352806534e-05, 'epoch': 1.2455319883160796, 'step': 6915500}
INFO:transformers.trainer:{'loss': 3.0373498030900956, 'learning_rate': 2.92396326339527e-05, 'epoch': 1.245622041962838, 'step': 6916000}
INFO:transformers.trainer:{'loss': 3.0037847940921782, 'learning_rate': 2.923813173984006e-05, 'epoch': 1.2457120956095966, 'step': 6916500}
INFO:transformers.trainer:{'loss': 3.0509708161354063, 'learning_rate': 2.9236630845727418e-05, 'epoch': 1.245802149256355, 'step': 6917000}
INFO:transformers.trainer:{'loss': 3.0218957163095475, 'learning_rate': 2.9235129951614777e-05, 'epoch': 1.2458922029031134, 'step': 6917500}
INFO:transformers.trainer:{'loss': 3.0320178982019423, 'learning_rate': 2.9233629057502136e-05, 'epoch': 1.245982256549872, 'step': 6918000}
INFO:transformers.trainer:{'loss': 3.0032517836093904, 'learning_rate': 2.9232128163389495e-05, 'epoch': 1.2460723101966305, 'step': 6918500}
INFO:transformers.trainer:{'loss': 3.0171232063770295, 'learning_rate': 2.9230627269276854e-05, 'epoch': 1.2461623638433887, 'step': 6919000}
INFO:transformers.trainer:{'loss': 3.011308558344841, 'learning_rate': 2.9229126375164213e-05, 'epoch': 1.2462524174901473, 'step': 6919500}
INFO:transformers.trainer:{'loss': 3.0921554594039917, 'learning_rate': 2.9227625481051572e-05, 'epoch': 1.2463424711369058, 'step': 6920000}
INFO:transformers.trainer:{'loss': 3.0913548662662507, 'learning_rate': 2.922612458693893e-05, 'epoch': 1.246432524783664, 'step': 6920500}
INFO:transformers.trainer:{'loss': 3.0023101279735567, 'learning_rate': 2.922462369282629e-05, 'epoch': 1.2465225784304226, 'step': 6921000}
INFO:transformers.trainer:{'loss': 3.045049700498581, 'learning_rate': 2.9223122798713653e-05, 'epoch': 1.246612632077181, 'step': 6921500}
INFO:transformers.trainer:{'loss': 3.0587827463150026, 'learning_rate': 2.922162190460101e-05, 'epoch': 1.2467026857239394, 'step': 6922000}
INFO:transformers.trainer:{'loss': 3.0271250338554383, 'learning_rate': 2.922012101048837e-05, 'epoch': 1.246792739370698, 'step': 6922500}
INFO:transformers.trainer:{'loss': 3.027804023146629, 'learning_rate': 2.9218620116375727e-05, 'epoch': 1.2468827930174564, 'step': 6923000}
INFO:transformers.trainer:{'loss': 3.076543528318405, 'learning_rate': 2.921711922226309e-05, 'epoch': 1.2469728466642147, 'step': 6923500}
INFO:transformers.trainer:{'loss': 3.0504436167478564, 'learning_rate': 2.9215618328150445e-05, 'epoch': 1.2470629003109732, 'step': 6924000}
INFO:transformers.trainer:{'loss': 3.1383404083251953, 'learning_rate': 2.9214117434037807e-05, 'epoch': 1.2471529539577317, 'step': 6924500}
INFO:transformers.trainer:{'loss': 3.0868919900655745, 'learning_rate': 2.9212616539925163e-05, 'epoch': 1.24724300760449, 'step': 6925000}
INFO:transformers.trainer:{'loss': 3.067382952213287, 'learning_rate': 2.9211115645812525e-05, 'epoch': 1.2473330612512485, 'step': 6925500}
INFO:transformers.trainer:{'loss': 3.024560914516449, 'learning_rate': 2.920961475169988e-05, 'epoch': 1.247423114898007, 'step': 6926000}
INFO:transformers.trainer:{'loss': 3.0710187101364137, 'learning_rate': 2.9208113857587243e-05, 'epoch': 1.2475131685447656, 'step': 6926500}
INFO:transformers.trainer:{'loss': 3.0011331902742384, 'learning_rate': 2.92066129634746e-05, 'epoch': 1.2476032221915239, 'step': 6927000}
INFO:transformers.trainer:{'loss': 3.037704710483551, 'learning_rate': 2.920511206936196e-05, 'epoch': 1.2476932758382824, 'step': 6927500}
INFO:transformers.trainer:{'loss': 3.0191123831272124, 'learning_rate': 2.9203611175249324e-05, 'epoch': 1.247783329485041, 'step': 6928000}
INFO:transformers.trainer:{'loss': 3.0326576261520386, 'learning_rate': 2.920211028113668e-05, 'epoch': 1.2478733831317992, 'step': 6928500}
INFO:transformers.trainer:{'loss': 3.0581653678417204, 'learning_rate': 2.9200609387024042e-05, 'epoch': 1.2479634367785577, 'step': 6929000}
INFO:transformers.trainer:{'loss': 3.044482684493065, 'learning_rate': 2.9199108492911398e-05, 'epoch': 1.2480534904253162, 'step': 6929500}
INFO:transformers.trainer:{'loss': 3.070756118893623, 'learning_rate': 2.919760759879876e-05, 'epoch': 1.2481435440720747, 'step': 6930000}
INFO:transformers.trainer:{'loss': 3.055199969649315, 'learning_rate': 2.9196106704686116e-05, 'epoch': 1.248233597718833, 'step': 6930500}
INFO:transformers.trainer:{'loss': 3.082427501678467, 'learning_rate': 2.9194605810573478e-05, 'epoch': 1.2483236513655915, 'step': 6931000}
INFO:transformers.trainer:{'loss': 3.0021252789497375, 'learning_rate': 2.9193104916460834e-05, 'epoch': 1.24841370501235, 'step': 6931500}
INFO:transformers.trainer:{'loss': 3.024183674812317, 'learning_rate': 2.9191604022348196e-05, 'epoch': 1.2485037586591083, 'step': 6932000}
INFO:transformers.trainer:{'loss': 3.0505405979156492, 'learning_rate': 2.9190103128235552e-05, 'epoch': 1.2485938123058669, 'step': 6932500}
INFO:transformers.trainer:{'loss': 3.02358811044693, 'learning_rate': 2.9188602234122914e-05, 'epoch': 1.2486838659526254, 'step': 6933000}
INFO:transformers.trainer:{'loss': 3.020127811193466, 'learning_rate': 2.918710134001027e-05, 'epoch': 1.2487739195993837, 'step': 6933500}
INFO:transformers.trainer:{'loss': 3.0023669344186783, 'learning_rate': 2.9185600445897633e-05, 'epoch': 1.2488639732461422, 'step': 6934000}
INFO:transformers.trainer:{'loss': 3.060489642381668, 'learning_rate': 2.9184099551784988e-05, 'epoch': 1.2489540268929007, 'step': 6934500}
INFO:transformers.trainer:{'loss': 3.001213910102844, 'learning_rate': 2.918259865767235e-05, 'epoch': 1.249044080539659, 'step': 6935000}
INFO:transformers.trainer:{'loss': 3.0180069732666017, 'learning_rate': 2.9181097763559713e-05, 'epoch': 1.2491341341864175, 'step': 6935500}
INFO:transformers.trainer:{'loss': 3.032801890850067, 'learning_rate': 2.917959686944707e-05, 'epoch': 1.249224187833176, 'step': 6936000}
INFO:transformers.trainer:{'loss': 3.0387998785972594, 'learning_rate': 2.917809597533443e-05, 'epoch': 1.2493142414799343, 'step': 6936500}
INFO:transformers.trainer:{'loss': 3.103863545894623, 'learning_rate': 2.9176595081221787e-05, 'epoch': 1.2494042951266928, 'step': 6937000}
INFO:transformers.trainer:{'loss': 3.0719058163166046, 'learning_rate': 2.917509418710915e-05, 'epoch': 1.2494943487734513, 'step': 6937500}
INFO:transformers.trainer:{'loss': 3.010677513360977, 'learning_rate': 2.9173593292996505e-05, 'epoch': 1.2495844024202098, 'step': 6938000}
INFO:transformers.trainer:{'loss': 3.0675525790452958, 'learning_rate': 2.9172092398883867e-05, 'epoch': 1.2496744560669681, 'step': 6938500}
INFO:transformers.trainer:{'loss': 3.0710851364135743, 'learning_rate': 2.9170591504771223e-05, 'epoch': 1.2497645097137267, 'step': 6939000}
INFO:transformers.trainer:{'loss': 3.049682456970215, 'learning_rate': 2.9169090610658582e-05, 'epoch': 1.2498545633604852, 'step': 6939500}
INFO:transformers.trainer:{'loss': 3.042244280576706, 'learning_rate': 2.916758971654594e-05, 'epoch': 1.2499446170072435, 'step': 6940000}
INFO:transformers.trainer:{'loss': 3.0512812879085542, 'learning_rate': 2.91660888224333e-05, 'epoch': 1.250034670654002, 'step': 6940500}
INFO:transformers.trainer:{'loss': 3.043414760828018, 'learning_rate': 2.916458792832066e-05, 'epoch': 1.2501247243007605, 'step': 6941000}
INFO:transformers.trainer:{'loss': 3.0805311299562455, 'learning_rate': 2.9163087034208018e-05, 'epoch': 1.250214777947519, 'step': 6941500}
INFO:transformers.trainer:{'loss': 3.063280834197998, 'learning_rate': 2.916158614009538e-05, 'epoch': 1.2503048315942773, 'step': 6942000}
INFO:transformers.trainer:{'loss': 3.090771581411362, 'learning_rate': 2.9160085245982736e-05, 'epoch': 1.2503948852410358, 'step': 6942500}
INFO:transformers.trainer:{'loss': 3.0399721970558167, 'learning_rate': 2.91585843518701e-05, 'epoch': 1.2504849388877943, 'step': 6943000}
INFO:transformers.trainer:{'loss': 3.0556753106117247, 'learning_rate': 2.9157083457757454e-05, 'epoch': 1.2505749925345526, 'step': 6943500}
INFO:transformers.trainer:{'loss': 2.9947987232208253, 'learning_rate': 2.9155582563644817e-05, 'epoch': 1.2506650461813111, 'step': 6944000}
INFO:transformers.trainer:{'loss': 3.055453383684158, 'learning_rate': 2.9154081669532173e-05, 'epoch': 1.2507550998280696, 'step': 6944500}
INFO:transformers.trainer:{'loss': 3.038162707924843, 'learning_rate': 2.9152580775419535e-05, 'epoch': 1.250845153474828, 'step': 6945000}
INFO:transformers.trainer:{'loss': 3.0771116508245466, 'learning_rate': 2.915107988130689e-05, 'epoch': 1.2509352071215865, 'step': 6945500}
INFO:transformers.trainer:{'loss': 3.0320552785396577, 'learning_rate': 2.9149578987194253e-05, 'epoch': 1.251025260768345, 'step': 6946000}
INFO:transformers.trainer:{'loss': 3.061222795963287, 'learning_rate': 2.914807809308161e-05, 'epoch': 1.2511153144151033, 'step': 6946500}
INFO:transformers.trainer:{'loss': 3.032956736087799, 'learning_rate': 2.914657719896897e-05, 'epoch': 1.2512053680618618, 'step': 6947000}
INFO:transformers.trainer:{'loss': 3.0279854164123536, 'learning_rate': 2.9145076304856327e-05, 'epoch': 1.2512954217086203, 'step': 6947500}
INFO:transformers.trainer:{'loss': 3.0618885623216627, 'learning_rate': 2.914357541074369e-05, 'epoch': 1.2513854753553786, 'step': 6948000}
INFO:transformers.trainer:{'loss': 3.0160543125867845, 'learning_rate': 2.9142074516631052e-05, 'epoch': 1.251475529002137, 'step': 6948500}
INFO:transformers.trainer:{'loss': 3.0609003639221193, 'learning_rate': 2.9140573622518407e-05, 'epoch': 1.2515655826488956, 'step': 6949000}
INFO:transformers.trainer:{'loss': 3.030883427143097, 'learning_rate': 2.913907272840577e-05, 'epoch': 1.2516556362956541, 'step': 6949500}
INFO:transformers.trainer:{'loss': 3.0776478604078292, 'learning_rate': 2.9137571834293126e-05, 'epoch': 1.2517456899424124, 'step': 6950000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-6950000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6950000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-6950000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6850000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0614120423793794, 'learning_rate': 2.9136070940180488e-05, 'epoch': 1.251835743589171, 'step': 6950500}
INFO:transformers.trainer:{'loss': 2.9456217238903046, 'learning_rate': 2.9134570046067844e-05, 'epoch': 1.2519257972359294, 'step': 6951000}
INFO:transformers.trainer:{'loss': 3.016993129372597, 'learning_rate': 2.9133069151955206e-05, 'epoch': 1.252015850882688, 'step': 6951500}
INFO:transformers.trainer:{'loss': 3.077910710334778, 'learning_rate': 2.9131568257842562e-05, 'epoch': 1.2521059045294463, 'step': 6952000}
INFO:transformers.trainer:{'loss': 2.9638471646308897, 'learning_rate': 2.9130067363729924e-05, 'epoch': 1.2521959581762048, 'step': 6952500}
INFO:transformers.trainer:{'loss': 3.015389072418213, 'learning_rate': 2.912856646961728e-05, 'epoch': 1.2522860118229633, 'step': 6953000}
INFO:transformers.trainer:{'loss': 3.056350347995758, 'learning_rate': 2.9127065575504642e-05, 'epoch': 1.2523760654697216, 'step': 6953500}
INFO:transformers.trainer:{'loss': 3.02910728430748, 'learning_rate': 2.9125564681391998e-05, 'epoch': 1.25246611911648, 'step': 6954000}
INFO:transformers.trainer:{'loss': 3.037947476506233, 'learning_rate': 2.912406378727936e-05, 'epoch': 1.2525561727632386, 'step': 6954500}
INFO:transformers.trainer:{'loss': 3.0125601694583892, 'learning_rate': 2.9122562893166716e-05, 'epoch': 1.252646226409997, 'step': 6955000}
INFO:transformers.trainer:{'loss': 3.0147036899328232, 'learning_rate': 2.912106199905408e-05, 'epoch': 1.2527362800567554, 'step': 6955500}
INFO:transformers.trainer:{'loss': 3.071437130689621, 'learning_rate': 2.911956110494144e-05, 'epoch': 1.252826333703514, 'step': 6956000}
INFO:transformers.trainer:{'loss': 3.0880254632234574, 'learning_rate': 2.9118060210828797e-05, 'epoch': 1.2529163873502722, 'step': 6956500}
INFO:transformers.trainer:{'loss': 3.0301258130073547, 'learning_rate': 2.911655931671616e-05, 'epoch': 1.2530064409970307, 'step': 6957000}
INFO:transformers.trainer:{'loss': 2.99575513446331, 'learning_rate': 2.9115058422603515e-05, 'epoch': 1.2530964946437892, 'step': 6957500}
INFO:transformers.trainer:{'loss': 3.0728157753944396, 'learning_rate': 2.9113557528490877e-05, 'epoch': 1.2531865482905475, 'step': 6958000}
INFO:transformers.trainer:{'loss': 3.0522522842884063, 'learning_rate': 2.9112056634378233e-05, 'epoch': 1.253276601937306, 'step': 6958500}
INFO:transformers.trainer:{'loss': 3.064993077874184, 'learning_rate': 2.9110555740265595e-05, 'epoch': 1.2533666555840646, 'step': 6959000}
INFO:transformers.trainer:{'loss': 3.0203924473524095, 'learning_rate': 2.910905484615295e-05, 'epoch': 1.2534567092308229, 'step': 6959500}
INFO:transformers.trainer:{'loss': 3.048993166208267, 'learning_rate': 2.9107553952040313e-05, 'epoch': 1.2535467628775814, 'step': 6960000}
INFO:transformers.trainer:{'loss': 3.128322319149971, 'learning_rate': 2.910605305792767e-05, 'epoch': 1.25363681652434, 'step': 6960500}
INFO:transformers.trainer:{'loss': 2.9912016409635545, 'learning_rate': 2.910455216381503e-05, 'epoch': 1.2537268701710984, 'step': 6961000}
INFO:transformers.trainer:{'loss': 3.0522592175006866, 'learning_rate': 2.9103051269702387e-05, 'epoch': 1.2538169238178567, 'step': 6961500}
INFO:transformers.trainer:{'loss': 3.061221429347992, 'learning_rate': 2.910155037558975e-05, 'epoch': 1.2539069774646152, 'step': 6962000}
INFO:transformers.trainer:{'loss': 3.0688585863113405, 'learning_rate': 2.910004948147711e-05, 'epoch': 1.2539970311113737, 'step': 6962500}
INFO:transformers.trainer:{'loss': 3.042846719264984, 'learning_rate': 2.9098548587364464e-05, 'epoch': 1.2540870847581322, 'step': 6963000}
INFO:transformers.trainer:{'loss': 3.020850260972977, 'learning_rate': 2.9097047693251827e-05, 'epoch': 1.2541771384048905, 'step': 6963500}
INFO:transformers.trainer:{'loss': 3.0747479066848755, 'learning_rate': 2.9095546799139182e-05, 'epoch': 1.254267192051649, 'step': 6964000}
INFO:transformers.trainer:{'loss': 3.029433718919754, 'learning_rate': 2.9094045905026545e-05, 'epoch': 1.2543572456984076, 'step': 6964500}
INFO:transformers.trainer:{'loss': 3.0515547132492067, 'learning_rate': 2.90925450109139e-05, 'epoch': 1.2544472993451659, 'step': 6965000}
INFO:transformers.trainer:{'loss': 2.9840395715236663, 'learning_rate': 2.9091044116801263e-05, 'epoch': 1.2545373529919244, 'step': 6965500}
INFO:transformers.trainer:{'loss': 2.9914355231523513, 'learning_rate': 2.908954322268862e-05, 'epoch': 1.2546274066386829, 'step': 6966000}
INFO:transformers.trainer:{'loss': 3.03771771466732, 'learning_rate': 2.908804232857598e-05, 'epoch': 1.2547174602854412, 'step': 6966500}
INFO:transformers.trainer:{'loss': 3.0913486070632934, 'learning_rate': 2.9086541434463337e-05, 'epoch': 1.2548075139321997, 'step': 6967000}
INFO:transformers.trainer:{'loss': 3.028761230587959, 'learning_rate': 2.90850405403507e-05, 'epoch': 1.2548975675789582, 'step': 6967500}
INFO:transformers.trainer:{'loss': 3.080300439119339, 'learning_rate': 2.9083539646238055e-05, 'epoch': 1.2549876212257165, 'step': 6968000}
INFO:transformers.trainer:{'loss': 3.0509589709043503, 'learning_rate': 2.9082038752125417e-05, 'epoch': 1.255077674872475, 'step': 6968500}
INFO:transformers.trainer:{'loss': 3.042727953910828, 'learning_rate': 2.9080537858012773e-05, 'epoch': 1.2551677285192335, 'step': 6969000}
INFO:transformers.trainer:{'loss': 3.0711291618347167, 'learning_rate': 2.9079036963900135e-05, 'epoch': 1.2552577821659918, 'step': 6969500}
INFO:transformers.trainer:{'loss': 3.0454137403964996, 'learning_rate': 2.9077536069787498e-05, 'epoch': 1.2553478358127503, 'step': 6970000}
INFO:transformers.trainer:{'loss': 3.036998872756958, 'learning_rate': 2.9076035175674853e-05, 'epoch': 1.2554378894595088, 'step': 6970500}
INFO:transformers.trainer:{'loss': 3.0941435170173643, 'learning_rate': 2.9074534281562216e-05, 'epoch': 1.2555279431062671, 'step': 6971000}
INFO:transformers.trainer:{'loss': 3.0238134171962736, 'learning_rate': 2.907303338744957e-05, 'epoch': 1.2556179967530257, 'step': 6971500}
INFO:transformers.trainer:{'loss': 2.9848086627721786, 'learning_rate': 2.9071532493336934e-05, 'epoch': 1.2557080503997842, 'step': 6972000}
INFO:transformers.trainer:{'loss': 3.0167091231346133, 'learning_rate': 2.907003159922429e-05, 'epoch': 1.2557981040465427, 'step': 6972500}
INFO:transformers.trainer:{'loss': 3.085470647215843, 'learning_rate': 2.9068530705111652e-05, 'epoch': 1.255888157693301, 'step': 6973000}
INFO:transformers.trainer:{'loss': 3.0275262155532836, 'learning_rate': 2.9067029810999008e-05, 'epoch': 1.2559782113400595, 'step': 6973500}
INFO:transformers.trainer:{'loss': 3.053679529428482, 'learning_rate': 2.906552891688637e-05, 'epoch': 1.256068264986818, 'step': 6974000}
INFO:transformers.trainer:{'loss': 3.075414013147354, 'learning_rate': 2.9064028022773726e-05, 'epoch': 1.2561583186335765, 'step': 6974500}
INFO:transformers.trainer:{'loss': 3.1036886489391327, 'learning_rate': 2.9062527128661088e-05, 'epoch': 1.2562483722803348, 'step': 6975000}
INFO:transformers.trainer:{'loss': 3.0347602021694184, 'learning_rate': 2.9061026234548444e-05, 'epoch': 1.2563384259270933, 'step': 6975500}
INFO:transformers.trainer:{'loss': 3.063286607503891, 'learning_rate': 2.9059525340435806e-05, 'epoch': 1.2564284795738518, 'step': 6976000}
INFO:transformers.trainer:{'loss': 3.0114566826820375, 'learning_rate': 2.905802444632317e-05, 'epoch': 1.2565185332206101, 'step': 6976500}
INFO:transformers.trainer:{'loss': 3.0358381731510162, 'learning_rate': 2.9056523552210524e-05, 'epoch': 1.2566085868673686, 'step': 6977000}
INFO:transformers.trainer:{'loss': 3.090569312214851, 'learning_rate': 2.9055022658097887e-05, 'epoch': 1.2566986405141272, 'step': 6977500}
INFO:transformers.trainer:{'loss': 3.0459503149986267, 'learning_rate': 2.9053521763985242e-05, 'epoch': 1.2567886941608855, 'step': 6978000}
INFO:transformers.trainer:{'loss': 2.9853353946208956, 'learning_rate': 2.9052020869872605e-05, 'epoch': 1.256878747807644, 'step': 6978500}
INFO:transformers.trainer:{'loss': 3.0150107955932617, 'learning_rate': 2.905051997575996e-05, 'epoch': 1.2569688014544025, 'step': 6979000}
INFO:transformers.trainer:{'loss': 3.0967092595100403, 'learning_rate': 2.9049019081647323e-05, 'epoch': 1.2570588551011608, 'step': 6979500}
INFO:transformers.trainer:{'loss': 2.998619342327118, 'learning_rate': 2.904751818753468e-05, 'epoch': 1.2571489087479193, 'step': 6980000}
INFO:transformers.trainer:{'loss': 3.0453682129383086, 'learning_rate': 2.904601729342204e-05, 'epoch': 1.2572389623946778, 'step': 6980500}
INFO:transformers.trainer:{'loss': 3.0180929641723635, 'learning_rate': 2.9044516399309397e-05, 'epoch': 1.257329016041436, 'step': 6981000}
INFO:transformers.trainer:{'loss': 3.0196254694461824, 'learning_rate': 2.904301550519676e-05, 'epoch': 1.2574190696881946, 'step': 6981500}
INFO:transformers.trainer:{'loss': 2.991525342822075, 'learning_rate': 2.9041514611084115e-05, 'epoch': 1.2575091233349531, 'step': 6982000}
INFO:transformers.trainer:{'loss': 3.0308462682962416, 'learning_rate': 2.9040013716971477e-05, 'epoch': 1.2575991769817114, 'step': 6982500}
INFO:transformers.trainer:{'loss': 3.047728004574776, 'learning_rate': 2.9038512822858833e-05, 'epoch': 1.25768923062847, 'step': 6983000}
INFO:transformers.trainer:{'loss': 3.0441573631763457, 'learning_rate': 2.9037011928746195e-05, 'epoch': 1.2577792842752284, 'step': 6983500}
INFO:transformers.trainer:{'loss': 3.06936700630188, 'learning_rate': 2.9035511034633554e-05, 'epoch': 1.257869337921987, 'step': 6984000}
INFO:transformers.trainer:{'loss': 3.019923223018646, 'learning_rate': 2.9034010140520914e-05, 'epoch': 1.2579593915687453, 'step': 6984500}
INFO:transformers.trainer:{'loss': 3.014818386435509, 'learning_rate': 2.9032509246408273e-05, 'epoch': 1.2580494452155038, 'step': 6985000}
INFO:transformers.trainer:{'loss': 3.0816288573741915, 'learning_rate': 2.903100835229563e-05, 'epoch': 1.2581394988622623, 'step': 6985500}
INFO:transformers.trainer:{'loss': 3.0289631853103636, 'learning_rate': 2.902950745818299e-05, 'epoch': 1.2582295525090208, 'step': 6986000}
INFO:transformers.trainer:{'loss': 3.074653344869614, 'learning_rate': 2.9028006564070346e-05, 'epoch': 1.258319606155779, 'step': 6986500}
INFO:transformers.trainer:{'loss': 3.044147075176239, 'learning_rate': 2.902650566995771e-05, 'epoch': 1.2584096598025376, 'step': 6987000}
INFO:transformers.trainer:{'loss': 3.0533078627586363, 'learning_rate': 2.9025004775845064e-05, 'epoch': 1.2584997134492961, 'step': 6987500}
INFO:transformers.trainer:{'loss': 3.0390737372636796, 'learning_rate': 2.9023503881732427e-05, 'epoch': 1.2585897670960544, 'step': 6988000}
INFO:transformers.trainer:{'loss': 3.0840468130111693, 'learning_rate': 2.9022002987619783e-05, 'epoch': 1.258679820742813, 'step': 6988500}
INFO:transformers.trainer:{'loss': 3.074770026683807, 'learning_rate': 2.9020502093507145e-05, 'epoch': 1.2587698743895714, 'step': 6989000}
INFO:transformers.trainer:{'loss': 3.002379874944687, 'learning_rate': 2.90190011993945e-05, 'epoch': 1.2588599280363297, 'step': 6989500}
INFO:transformers.trainer:{'loss': 2.9980924279689787, 'learning_rate': 2.9017500305281863e-05, 'epoch': 1.2589499816830882, 'step': 6990000}
INFO:transformers.trainer:{'loss': 3.0612216662168503, 'learning_rate': 2.9015999411169226e-05, 'epoch': 1.2590400353298468, 'step': 6990500}
INFO:transformers.trainer:{'loss': 3.030334092617035, 'learning_rate': 2.901449851705658e-05, 'epoch': 1.259130088976605, 'step': 6991000}
INFO:transformers.trainer:{'loss': 3.0724123162031174, 'learning_rate': 2.9012997622943944e-05, 'epoch': 1.2592201426233636, 'step': 6991500}
INFO:transformers.trainer:{'loss': 3.0397327880859377, 'learning_rate': 2.90114967288313e-05, 'epoch': 1.259310196270122, 'step': 6992000}
INFO:transformers.trainer:{'loss': 3.0354328389167784, 'learning_rate': 2.9009995834718662e-05, 'epoch': 1.2594002499168804, 'step': 6992500}
INFO:transformers.trainer:{'loss': 3.0268046145439147, 'learning_rate': 2.9008494940606017e-05, 'epoch': 1.259490303563639, 'step': 6993000}
INFO:transformers.trainer:{'loss': 3.049386984586716, 'learning_rate': 2.900699404649338e-05, 'epoch': 1.2595803572103974, 'step': 6993500}
INFO:transformers.trainer:{'loss': 3.062809394240379, 'learning_rate': 2.9005493152380735e-05, 'epoch': 1.2596704108571557, 'step': 6994000}
INFO:transformers.trainer:{'loss': 3.055864893913269, 'learning_rate': 2.9003992258268098e-05, 'epoch': 1.2597604645039142, 'step': 6994500}
INFO:transformers.trainer:{'loss': 3.036928957939148, 'learning_rate': 2.9002491364155454e-05, 'epoch': 1.2598505181506727, 'step': 6995000}
INFO:transformers.trainer:{'loss': 3.0598944737911222, 'learning_rate': 2.9000990470042816e-05, 'epoch': 1.2599405717974312, 'step': 6995500}
INFO:transformers.trainer:{'loss': 2.9793375339508055, 'learning_rate': 2.899948957593017e-05, 'epoch': 1.2600306254441895, 'step': 6996000}
INFO:transformers.trainer:{'loss': 3.0935352687835693, 'learning_rate': 2.8997988681817534e-05, 'epoch': 1.260120679090948, 'step': 6996500}
INFO:transformers.trainer:{'loss': 3.0873981914520265, 'learning_rate': 2.8996487787704897e-05, 'epoch': 1.2602107327377066, 'step': 6997000}
INFO:transformers.trainer:{'loss': 3.049941030025482, 'learning_rate': 2.8994986893592252e-05, 'epoch': 1.260300786384465, 'step': 6997500}
INFO:transformers.trainer:{'loss': 3.0951085988283156, 'learning_rate': 2.8993485999479615e-05, 'epoch': 1.2603908400312234, 'step': 6998000}
INFO:transformers.trainer:{'loss': 3.0381707212924955, 'learning_rate': 2.899198510536697e-05, 'epoch': 1.2604808936779819, 'step': 6998500}
INFO:transformers.trainer:{'loss': 3.109583621740341, 'learning_rate': 2.8990484211254333e-05, 'epoch': 1.2605709473247404, 'step': 6999000}
INFO:transformers.trainer:{'loss': 3.0395987621545792, 'learning_rate': 2.898898331714169e-05, 'epoch': 1.2606610009714987, 'step': 6999500}
INFO:transformers.trainer:{'loss': 3.0729031307697294, 'learning_rate': 2.898748242302905e-05, 'epoch': 1.2607510546182572, 'step': 7000000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7000000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7000000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7000000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6900000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.048398321390152, 'learning_rate': 2.8985981528916407e-05, 'epoch': 1.2608411082650157, 'step': 7000500}
INFO:transformers.trainer:{'loss': 2.9801912984848022, 'learning_rate': 2.898448063480377e-05, 'epoch': 1.260931161911774, 'step': 7001000}
INFO:transformers.trainer:{'loss': 3.0316132229566572, 'learning_rate': 2.8982979740691125e-05, 'epoch': 1.2610212155585325, 'step': 7001500}
INFO:transformers.trainer:{'loss': 3.0048849118947984, 'learning_rate': 2.8981478846578487e-05, 'epoch': 1.261111269205291, 'step': 7002000}
INFO:transformers.trainer:{'loss': 3.0894464617967605, 'learning_rate': 2.8979977952465843e-05, 'epoch': 1.2612013228520493, 'step': 7002500}
INFO:transformers.trainer:{'loss': 3.0086815133094786, 'learning_rate': 2.8978477058353205e-05, 'epoch': 1.2612913764988078, 'step': 7003000}
INFO:transformers.trainer:{'loss': 3.018564286708832, 'learning_rate': 2.897697616424056e-05, 'epoch': 1.2613814301455664, 'step': 7003500}
INFO:transformers.trainer:{'loss': 3.038419000864029, 'learning_rate': 2.8975475270127923e-05, 'epoch': 1.2614714837923247, 'step': 7004000}
INFO:transformers.trainer:{'loss': 3.0140856063365935, 'learning_rate': 2.8973974376015282e-05, 'epoch': 1.2615615374390832, 'step': 7004500}
INFO:transformers.trainer:{'loss': 3.06918097782135, 'learning_rate': 2.897247348190264e-05, 'epoch': 1.2616515910858417, 'step': 7005000}
INFO:transformers.trainer:{'loss': 3.0532157304286955, 'learning_rate': 2.897097258779e-05, 'epoch': 1.2617416447326, 'step': 7005500}
INFO:transformers.trainer:{'loss': 3.075586213469505, 'learning_rate': 2.896947169367736e-05, 'epoch': 1.2618316983793585, 'step': 7006000}
INFO:transformers.trainer:{'loss': 2.9999990019798277, 'learning_rate': 2.896797079956472e-05, 'epoch': 1.261921752026117, 'step': 7006500}
INFO:transformers.trainer:{'loss': 3.0680045466423036, 'learning_rate': 2.8966469905452078e-05, 'epoch': 1.2620118056728755, 'step': 7007000}
INFO:transformers.trainer:{'loss': 3.0328683822155, 'learning_rate': 2.8964969011339437e-05, 'epoch': 1.2621018593196338, 'step': 7007500}
INFO:transformers.trainer:{'loss': 3.0021272567510606, 'learning_rate': 2.8963468117226796e-05, 'epoch': 1.2621919129663923, 'step': 7008000}
INFO:transformers.trainer:{'loss': 3.0060223009586333, 'learning_rate': 2.8961967223114155e-05, 'epoch': 1.2622819666131508, 'step': 7008500}
INFO:transformers.trainer:{'loss': 3.062219463467598, 'learning_rate': 2.8960466329001514e-05, 'epoch': 1.2623720202599094, 'step': 7009000}
INFO:transformers.trainer:{'loss': 3.0263629120588305, 'learning_rate': 2.8958965434888873e-05, 'epoch': 1.2624620739066676, 'step': 7009500}
INFO:transformers.trainer:{'loss': 3.0382762296199797, 'learning_rate': 2.8957464540776232e-05, 'epoch': 1.2625521275534262, 'step': 7010000}
INFO:transformers.trainer:{'loss': 3.0903805360794068, 'learning_rate': 2.895596364666359e-05, 'epoch': 1.2626421812001847, 'step': 7010500}
INFO:transformers.trainer:{'loss': 3.042627874493599, 'learning_rate': 2.8954462752550953e-05, 'epoch': 1.262732234846943, 'step': 7011000}
INFO:transformers.trainer:{'loss': 3.03745257127285, 'learning_rate': 2.895296185843831e-05, 'epoch': 1.2628222884937015, 'step': 7011500}
INFO:transformers.trainer:{'loss': 3.0802714121341705, 'learning_rate': 2.895146096432567e-05, 'epoch': 1.26291234214046, 'step': 7012000}
INFO:transformers.trainer:{'loss': 3.0346405792236326, 'learning_rate': 2.8949960070213027e-05, 'epoch': 1.2630023957872183, 'step': 7012500}
INFO:transformers.trainer:{'loss': 2.9710017249584197, 'learning_rate': 2.894845917610039e-05, 'epoch': 1.2630924494339768, 'step': 7013000}
INFO:transformers.trainer:{'loss': 3.0281673406362533, 'learning_rate': 2.8946958281987745e-05, 'epoch': 1.2631825030807353, 'step': 7013500}
INFO:transformers.trainer:{'loss': 3.0540005974769593, 'learning_rate': 2.8945457387875108e-05, 'epoch': 1.2632725567274936, 'step': 7014000}
INFO:transformers.trainer:{'loss': 3.0510067138671877, 'learning_rate': 2.8943956493762463e-05, 'epoch': 1.2633626103742521, 'step': 7014500}
INFO:transformers.trainer:{'loss': 3.0075536433458328, 'learning_rate': 2.8942455599649826e-05, 'epoch': 1.2634526640210106, 'step': 7015000}
INFO:transformers.trainer:{'loss': 3.0276099902391436, 'learning_rate': 2.894095470553718e-05, 'epoch': 1.263542717667769, 'step': 7015500}
INFO:transformers.trainer:{'loss': 3.0663269827365873, 'learning_rate': 2.8939453811424544e-05, 'epoch': 1.2636327713145274, 'step': 7016000}
INFO:transformers.trainer:{'loss': 3.0742675511837008, 'learning_rate': 2.89379529173119e-05, 'epoch': 1.263722824961286, 'step': 7016500}
INFO:transformers.trainer:{'loss': 3.074556054830551, 'learning_rate': 2.8936452023199262e-05, 'epoch': 1.2638128786080443, 'step': 7017000}
INFO:transformers.trainer:{'loss': 3.0176460041999817, 'learning_rate': 2.8934951129086618e-05, 'epoch': 1.2639029322548028, 'step': 7017500}
INFO:transformers.trainer:{'loss': 3.0264468517303467, 'learning_rate': 2.893345023497398e-05, 'epoch': 1.2639929859015613, 'step': 7018000}
INFO:transformers.trainer:{'loss': 3.0967558903694155, 'learning_rate': 2.8931949340861342e-05, 'epoch': 1.2640830395483198, 'step': 7018500}
INFO:transformers.trainer:{'loss': 3.0484168429374696, 'learning_rate': 2.8930448446748698e-05, 'epoch': 1.264173093195078, 'step': 7019000}
INFO:transformers.trainer:{'loss': 3.046940895795822, 'learning_rate': 2.892894755263606e-05, 'epoch': 1.2642631468418366, 'step': 7019500}
INFO:transformers.trainer:{'loss': 3.1065471076965334, 'learning_rate': 2.8927446658523416e-05, 'epoch': 1.2643532004885951, 'step': 7020000}
INFO:transformers.trainer:{'loss': 3.063096222758293, 'learning_rate': 2.892594576441078e-05, 'epoch': 1.2644432541353536, 'step': 7020500}
INFO:transformers.trainer:{'loss': 3.0544795336723327, 'learning_rate': 2.8924444870298134e-05, 'epoch': 1.264533307782112, 'step': 7021000}
INFO:transformers.trainer:{'loss': 3.0402170186042787, 'learning_rate': 2.8922943976185497e-05, 'epoch': 1.2646233614288704, 'step': 7021500}
INFO:transformers.trainer:{'loss': 3.0894281113147737, 'learning_rate': 2.8921443082072852e-05, 'epoch': 1.264713415075629, 'step': 7022000}
INFO:transformers.trainer:{'loss': 3.0352914605140686, 'learning_rate': 2.8919942187960215e-05, 'epoch': 1.2648034687223872, 'step': 7022500}
INFO:transformers.trainer:{'loss': 2.9649768757820127, 'learning_rate': 2.891844129384757e-05, 'epoch': 1.2648935223691458, 'step': 7023000}
INFO:transformers.trainer:{'loss': 3.0763481624126436, 'learning_rate': 2.8916940399734933e-05, 'epoch': 1.2649835760159043, 'step': 7023500}
INFO:transformers.trainer:{'loss': 3.06143825340271, 'learning_rate': 2.891543950562229e-05, 'epoch': 1.2650736296626626, 'step': 7024000}
INFO:transformers.trainer:{'loss': 3.007547855615616, 'learning_rate': 2.891393861150965e-05, 'epoch': 1.265163683309421, 'step': 7024500}
INFO:transformers.trainer:{'loss': 3.062412565588951, 'learning_rate': 2.891243771739701e-05, 'epoch': 1.2652537369561796, 'step': 7025000}
INFO:transformers.trainer:{'loss': 3.002671738743782, 'learning_rate': 2.891093682328437e-05, 'epoch': 1.265343790602938, 'step': 7025500}
INFO:transformers.trainer:{'loss': 3.0297095655202866, 'learning_rate': 2.8909435929171728e-05, 'epoch': 1.2654338442496964, 'step': 7026000}
INFO:transformers.trainer:{'loss': 3.0915185021162035, 'learning_rate': 2.8907935035059087e-05, 'epoch': 1.265523897896455, 'step': 7026500}
INFO:transformers.trainer:{'loss': 3.01065726017952, 'learning_rate': 2.8906434140946446e-05, 'epoch': 1.2656139515432132, 'step': 7027000}
INFO:transformers.trainer:{'loss': 3.0158961462974547, 'learning_rate': 2.8904933246833805e-05, 'epoch': 1.2657040051899717, 'step': 7027500}
INFO:transformers.trainer:{'loss': 3.035407309055328, 'learning_rate': 2.8903432352721164e-05, 'epoch': 1.2657940588367302, 'step': 7028000}
INFO:transformers.trainer:{'loss': 3.0017887296676635, 'learning_rate': 2.8901931458608523e-05, 'epoch': 1.2658841124834885, 'step': 7028500}
INFO:transformers.trainer:{'loss': 3.051650451540947, 'learning_rate': 2.8900430564495883e-05, 'epoch': 1.265974166130247, 'step': 7029000}
INFO:transformers.trainer:{'loss': 3.042290701150894, 'learning_rate': 2.889892967038324e-05, 'epoch': 1.2660642197770056, 'step': 7029500}
INFO:transformers.trainer:{'loss': 3.0611874973773956, 'learning_rate': 2.88974287762706e-05, 'epoch': 1.266154273423764, 'step': 7030000}
INFO:transformers.trainer:{'loss': 3.0954293694496156, 'learning_rate': 2.889592788215796e-05, 'epoch': 1.2662443270705224, 'step': 7030500}
INFO:transformers.trainer:{'loss': 3.065041245222092, 'learning_rate': 2.889442698804532e-05, 'epoch': 1.2663343807172809, 'step': 7031000}
INFO:transformers.trainer:{'loss': 3.0642562804222107, 'learning_rate': 2.8892926093932678e-05, 'epoch': 1.2664244343640394, 'step': 7031500}
INFO:transformers.trainer:{'loss': 3.0915596567392347, 'learning_rate': 2.8891425199820037e-05, 'epoch': 1.266514488010798, 'step': 7032000}
INFO:transformers.trainer:{'loss': 3.0708266941308975, 'learning_rate': 2.88899243057074e-05, 'epoch': 1.2666045416575562, 'step': 7032500}
INFO:transformers.trainer:{'loss': 3.045249109506607, 'learning_rate': 2.8888423411594755e-05, 'epoch': 1.2666945953043147, 'step': 7033000}
INFO:transformers.trainer:{'loss': 3.016406418442726, 'learning_rate': 2.8886922517482117e-05, 'epoch': 1.2667846489510732, 'step': 7033500}
INFO:transformers.trainer:{'loss': 3.069669848203659, 'learning_rate': 2.8885421623369473e-05, 'epoch': 1.2668747025978315, 'step': 7034000}
INFO:transformers.trainer:{'loss': 3.0065688531398775, 'learning_rate': 2.8883920729256835e-05, 'epoch': 1.26696475624459, 'step': 7034500}
INFO:transformers.trainer:{'loss': 3.060927615404129, 'learning_rate': 2.888241983514419e-05, 'epoch': 1.2670548098913486, 'step': 7035000}
INFO:transformers.trainer:{'loss': 3.0582632191181185, 'learning_rate': 2.8880918941031554e-05, 'epoch': 1.2671448635381068, 'step': 7035500}
INFO:transformers.trainer:{'loss': 3.004346005678177, 'learning_rate': 2.887941804691891e-05, 'epoch': 1.2672349171848654, 'step': 7036000}
INFO:transformers.trainer:{'loss': 3.0298607133626936, 'learning_rate': 2.887791715280627e-05, 'epoch': 1.2673249708316239, 'step': 7036500}
INFO:transformers.trainer:{'loss': 3.0165160158872606, 'learning_rate': 2.8876416258693627e-05, 'epoch': 1.2674150244783822, 'step': 7037000}
INFO:transformers.trainer:{'loss': 2.9941661684513092, 'learning_rate': 2.887491536458099e-05, 'epoch': 1.2675050781251407, 'step': 7037500}
INFO:transformers.trainer:{'loss': 3.0352508062124253, 'learning_rate': 2.8873414470468345e-05, 'epoch': 1.2675951317718992, 'step': 7038000}
INFO:transformers.trainer:{'loss': 3.0452269880771636, 'learning_rate': 2.8871913576355708e-05, 'epoch': 1.2676851854186575, 'step': 7038500}
INFO:transformers.trainer:{'loss': 3.095347870230675, 'learning_rate': 2.887041268224307e-05, 'epoch': 1.267775239065416, 'step': 7039000}
INFO:transformers.trainer:{'loss': 3.0238980193138123, 'learning_rate': 2.8868911788130426e-05, 'epoch': 1.2678652927121745, 'step': 7039500}
INFO:transformers.trainer:{'loss': 3.095794855117798, 'learning_rate': 2.886741089401779e-05, 'epoch': 1.2679553463589328, 'step': 7040000}
INFO:transformers.trainer:{'loss': 3.0137666680812836, 'learning_rate': 2.8865909999905144e-05, 'epoch': 1.2680454000056913, 'step': 7040500}
INFO:transformers.trainer:{'loss': 3.0229553322792055, 'learning_rate': 2.8864409105792507e-05, 'epoch': 1.2681354536524498, 'step': 7041000}
INFO:transformers.trainer:{'loss': 3.0206853498220445, 'learning_rate': 2.8862908211679862e-05, 'epoch': 1.2682255072992084, 'step': 7041500}
INFO:transformers.trainer:{'loss': 3.035857377052307, 'learning_rate': 2.8861407317567225e-05, 'epoch': 1.2683155609459669, 'step': 7042000}
INFO:transformers.trainer:{'loss': 3.0483204255104064, 'learning_rate': 2.885990642345458e-05, 'epoch': 1.2684056145927252, 'step': 7042500}
INFO:transformers.trainer:{'loss': 3.0343611845970155, 'learning_rate': 2.8858405529341943e-05, 'epoch': 1.2684956682394837, 'step': 7043000}
INFO:transformers.trainer:{'loss': 3.088200593471527, 'learning_rate': 2.88569046352293e-05, 'epoch': 1.2685857218862422, 'step': 7043500}
INFO:transformers.trainer:{'loss': 3.0583432552814482, 'learning_rate': 2.885540374111666e-05, 'epoch': 1.2686757755330005, 'step': 7044000}
INFO:transformers.trainer:{'loss': 3.0530653624534607, 'learning_rate': 2.8853902847004016e-05, 'epoch': 1.268765829179759, 'step': 7044500}
INFO:transformers.trainer:{'loss': 3.0625486869812013, 'learning_rate': 2.885240195289138e-05, 'epoch': 1.2688558828265175, 'step': 7045000}
INFO:transformers.trainer:{'loss': 3.0269602382183076, 'learning_rate': 2.8850901058778735e-05, 'epoch': 1.2689459364732758, 'step': 7045500}
INFO:transformers.trainer:{'loss': 3.0072604975700377, 'learning_rate': 2.8849400164666097e-05, 'epoch': 1.2690359901200343, 'step': 7046000}
INFO:transformers.trainer:{'loss': 3.061613454222679, 'learning_rate': 2.884789927055346e-05, 'epoch': 1.2691260437667928, 'step': 7046500}
INFO:transformers.trainer:{'loss': 3.0145833349227904, 'learning_rate': 2.8846398376440815e-05, 'epoch': 1.2692160974135511, 'step': 7047000}
INFO:transformers.trainer:{'loss': 3.0202676784992217, 'learning_rate': 2.8844897482328178e-05, 'epoch': 1.2693061510603096, 'step': 7047500}
INFO:transformers.trainer:{'loss': 3.0513837270736692, 'learning_rate': 2.8843396588215533e-05, 'epoch': 1.2693962047070682, 'step': 7048000}
INFO:transformers.trainer:{'loss': 3.028173626661301, 'learning_rate': 2.8841895694102892e-05, 'epoch': 1.2694862583538264, 'step': 7048500}
INFO:transformers.trainer:{'loss': 3.07355033659935, 'learning_rate': 2.884039479999025e-05, 'epoch': 1.269576312000585, 'step': 7049000}
INFO:transformers.trainer:{'loss': 3.034667750239372, 'learning_rate': 2.883889390587761e-05, 'epoch': 1.2696663656473435, 'step': 7049500}
INFO:transformers.trainer:{'loss': 3.0673415138721465, 'learning_rate': 2.883739301176497e-05, 'epoch': 1.2697564192941018, 'step': 7050000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7050000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7050000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7050000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-6950000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0019091513156893, 'learning_rate': 2.883589211765233e-05, 'epoch': 1.2698464729408603, 'step': 7050500}
INFO:transformers.trainer:{'loss': 2.9977953414916994, 'learning_rate': 2.8834391223539688e-05, 'epoch': 1.2699365265876188, 'step': 7051000}
INFO:transformers.trainer:{'loss': 3.0018864517211914, 'learning_rate': 2.8832890329427047e-05, 'epoch': 1.270026580234377, 'step': 7051500}
INFO:transformers.trainer:{'loss': 3.0293189532756806, 'learning_rate': 2.8831389435314406e-05, 'epoch': 1.2701166338811356, 'step': 7052000}
INFO:transformers.trainer:{'loss': 3.0397989773750305, 'learning_rate': 2.8829888541201765e-05, 'epoch': 1.2702066875278941, 'step': 7052500}
INFO:transformers.trainer:{'loss': 2.994155957698822, 'learning_rate': 2.8828387647089127e-05, 'epoch': 1.2702967411746526, 'step': 7053000}
INFO:transformers.trainer:{'loss': 3.082916482448578, 'learning_rate': 2.8826886752976483e-05, 'epoch': 1.2703867948214111, 'step': 7053500}
INFO:transformers.trainer:{'loss': 2.969561614871025, 'learning_rate': 2.8825385858863845e-05, 'epoch': 1.2704768484681694, 'step': 7054000}
INFO:transformers.trainer:{'loss': 2.986348264217377, 'learning_rate': 2.88238849647512e-05, 'epoch': 1.270566902114928, 'step': 7054500}
INFO:transformers.trainer:{'loss': 3.041997554063797, 'learning_rate': 2.8822384070638563e-05, 'epoch': 1.2706569557616865, 'step': 7055000}
INFO:transformers.trainer:{'loss': 3.054723354101181, 'learning_rate': 2.882088317652592e-05, 'epoch': 1.2707470094084448, 'step': 7055500}
INFO:transformers.trainer:{'loss': 3.070831575155258, 'learning_rate': 2.881938228241328e-05, 'epoch': 1.2708370630552033, 'step': 7056000}
INFO:transformers.trainer:{'loss': 2.9987380373477937, 'learning_rate': 2.8817881388300637e-05, 'epoch': 1.2709271167019618, 'step': 7056500}
INFO:transformers.trainer:{'loss': 3.0926923677921296, 'learning_rate': 2.8816380494188e-05, 'epoch': 1.27101717034872, 'step': 7057000}
INFO:transformers.trainer:{'loss': 3.05531509244442, 'learning_rate': 2.8814879600075355e-05, 'epoch': 1.2711072239954786, 'step': 7057500}
INFO:transformers.trainer:{'loss': 3.0292564029693603, 'learning_rate': 2.8813378705962718e-05, 'epoch': 1.2711972776422371, 'step': 7058000}
INFO:transformers.trainer:{'loss': 3.020894899606705, 'learning_rate': 2.8811877811850073e-05, 'epoch': 1.2712873312889954, 'step': 7058500}
INFO:transformers.trainer:{'loss': 2.995435800075531, 'learning_rate': 2.8810376917737436e-05, 'epoch': 1.271377384935754, 'step': 7059000}
INFO:transformers.trainer:{'loss': 3.0435437037944792, 'learning_rate': 2.8808876023624798e-05, 'epoch': 1.2714674385825124, 'step': 7059500}
INFO:transformers.trainer:{'loss': 3.0483738610744475, 'learning_rate': 2.8807375129512154e-05, 'epoch': 1.2715574922292707, 'step': 7060000}
INFO:transformers.trainer:{'loss': 3.03810813498497, 'learning_rate': 2.8805874235399516e-05, 'epoch': 1.2716475458760292, 'step': 7060500}
INFO:transformers.trainer:{'loss': 3.024309759378433, 'learning_rate': 2.8804373341286872e-05, 'epoch': 1.2717375995227878, 'step': 7061000}
INFO:transformers.trainer:{'loss': 3.0276242674589158, 'learning_rate': 2.8802872447174234e-05, 'epoch': 1.271827653169546, 'step': 7061500}
INFO:transformers.trainer:{'loss': 3.0342555360794066, 'learning_rate': 2.880137155306159e-05, 'epoch': 1.2719177068163046, 'step': 7062000}
INFO:transformers.trainer:{'loss': 3.0617881331443786, 'learning_rate': 2.8799870658948952e-05, 'epoch': 1.272007760463063, 'step': 7062500}
INFO:transformers.trainer:{'loss': 3.093863832592964, 'learning_rate': 2.8798369764836308e-05, 'epoch': 1.2720978141098214, 'step': 7063000}
INFO:transformers.trainer:{'loss': 2.9774040939807893, 'learning_rate': 2.879686887072367e-05, 'epoch': 1.2721878677565799, 'step': 7063500}
INFO:transformers.trainer:{'loss': 3.0277283444404604, 'learning_rate': 2.8795367976611026e-05, 'epoch': 1.2722779214033384, 'step': 7064000}
INFO:transformers.trainer:{'loss': 3.096054660439491, 'learning_rate': 2.879386708249839e-05, 'epoch': 1.272367975050097, 'step': 7064500}
INFO:transformers.trainer:{'loss': 3.0043243908882142, 'learning_rate': 2.8792366188385744e-05, 'epoch': 1.2724580286968554, 'step': 7065000}
INFO:transformers.trainer:{'loss': 2.9908356630802153, 'learning_rate': 2.8790865294273107e-05, 'epoch': 1.2725480823436137, 'step': 7065500}
INFO:transformers.trainer:{'loss': 3.0692697999477385, 'learning_rate': 2.8789364400160462e-05, 'epoch': 1.2726381359903722, 'step': 7066000}
INFO:transformers.trainer:{'loss': 3.047333518624306, 'learning_rate': 2.8787863506047825e-05, 'epoch': 1.2727281896371307, 'step': 7066500}
INFO:transformers.trainer:{'loss': 2.9980981625318526, 'learning_rate': 2.8786362611935187e-05, 'epoch': 1.272818243283889, 'step': 7067000}
INFO:transformers.trainer:{'loss': 3.0811984001398085, 'learning_rate': 2.8784861717822543e-05, 'epoch': 1.2729082969306476, 'step': 7067500}
INFO:transformers.trainer:{'loss': 3.0254961788654327, 'learning_rate': 2.8783360823709905e-05, 'epoch': 1.272998350577406, 'step': 7068000}
INFO:transformers.trainer:{'loss': 3.029135939955711, 'learning_rate': 2.878185992959726e-05, 'epoch': 1.2730884042241644, 'step': 7068500}
INFO:transformers.trainer:{'loss': 3.0994944598674774, 'learning_rate': 2.8780359035484623e-05, 'epoch': 1.2731784578709229, 'step': 7069000}
INFO:transformers.trainer:{'loss': 3.109186760187149, 'learning_rate': 2.877885814137198e-05, 'epoch': 1.2732685115176814, 'step': 7069500}
INFO:transformers.trainer:{'loss': 3.0324351402521135, 'learning_rate': 2.877735724725934e-05, 'epoch': 1.2733585651644397, 'step': 7070000}
INFO:transformers.trainer:{'loss': 3.0230620489120485, 'learning_rate': 2.8775856353146697e-05, 'epoch': 1.2734486188111982, 'step': 7070500}
INFO:transformers.trainer:{'loss': 3.018129893660545, 'learning_rate': 2.877435545903406e-05, 'epoch': 1.2735386724579567, 'step': 7071000}
INFO:transformers.trainer:{'loss': 3.1288169794082643, 'learning_rate': 2.8772854564921415e-05, 'epoch': 1.273628726104715, 'step': 7071500}
INFO:transformers.trainer:{'loss': 2.995032049536705, 'learning_rate': 2.8771353670808778e-05, 'epoch': 1.2737187797514735, 'step': 7072000}
INFO:transformers.trainer:{'loss': 3.0677418045997618, 'learning_rate': 2.8769852776696133e-05, 'epoch': 1.273808833398232, 'step': 7072500}
INFO:transformers.trainer:{'loss': 3.093269129753113, 'learning_rate': 2.8768351882583492e-05, 'epoch': 1.2738988870449903, 'step': 7073000}
INFO:transformers.trainer:{'loss': 3.019930235147476, 'learning_rate': 2.8766850988470855e-05, 'epoch': 1.2739889406917488, 'step': 7073500}
INFO:transformers.trainer:{'loss': 3.0578371342420576, 'learning_rate': 2.876535009435821e-05, 'epoch': 1.2740789943385074, 'step': 7074000}
INFO:transformers.trainer:{'loss': 3.00938685297966, 'learning_rate': 2.8763849200245573e-05, 'epoch': 1.2741690479852656, 'step': 7074500}
INFO:transformers.trainer:{'loss': 3.080666489601135, 'learning_rate': 2.876234830613293e-05, 'epoch': 1.2742591016320242, 'step': 7075000}
INFO:transformers.trainer:{'loss': 3.103207896590233, 'learning_rate': 2.876084741202029e-05, 'epoch': 1.2743491552787827, 'step': 7075500}
INFO:transformers.trainer:{'loss': 2.9961236641407014, 'learning_rate': 2.8759346517907647e-05, 'epoch': 1.2744392089255412, 'step': 7076000}
INFO:transformers.trainer:{'loss': 3.0362282779216767, 'learning_rate': 2.875784562379501e-05, 'epoch': 1.2745292625722997, 'step': 7076500}
INFO:transformers.trainer:{'loss': 3.040566596150398, 'learning_rate': 2.8756344729682365e-05, 'epoch': 1.274619316219058, 'step': 7077000}
INFO:transformers.trainer:{'loss': 3.044259465456009, 'learning_rate': 2.8754843835569727e-05, 'epoch': 1.2747093698658165, 'step': 7077500}
INFO:transformers.trainer:{'loss': 3.059440031051636, 'learning_rate': 2.8753342941457083e-05, 'epoch': 1.274799423512575, 'step': 7078000}
INFO:transformers.trainer:{'loss': 2.9980381815433503, 'learning_rate': 2.8751842047344445e-05, 'epoch': 1.2748894771593333, 'step': 7078500}
INFO:transformers.trainer:{'loss': 3.0017480041980744, 'learning_rate': 2.87503411532318e-05, 'epoch': 1.2749795308060918, 'step': 7079000}
INFO:transformers.trainer:{'loss': 2.9599612842798235, 'learning_rate': 2.8748840259119164e-05, 'epoch': 1.2750695844528503, 'step': 7079500}
INFO:transformers.trainer:{'loss': 3.0674779703617094, 'learning_rate': 2.874733936500652e-05, 'epoch': 1.2751596380996086, 'step': 7080000}
INFO:transformers.trainer:{'loss': 3.0114932354688646, 'learning_rate': 2.874583847089388e-05, 'epoch': 1.2752496917463672, 'step': 7080500}
INFO:transformers.trainer:{'loss': 3.0619969618320466, 'learning_rate': 2.8744337576781244e-05, 'epoch': 1.2753397453931257, 'step': 7081000}
INFO:transformers.trainer:{'loss': 3.041809783220291, 'learning_rate': 2.87428366826686e-05, 'epoch': 1.275429799039884, 'step': 7081500}
INFO:transformers.trainer:{'loss': 3.002120053052902, 'learning_rate': 2.8741335788555962e-05, 'epoch': 1.2755198526866425, 'step': 7082000}
INFO:transformers.trainer:{'loss': 3.0302044208049774, 'learning_rate': 2.8739834894443318e-05, 'epoch': 1.275609906333401, 'step': 7082500}
INFO:transformers.trainer:{'loss': 3.0307930538654326, 'learning_rate': 2.873833400033068e-05, 'epoch': 1.2756999599801593, 'step': 7083000}
INFO:transformers.trainer:{'loss': 3.0187388257980348, 'learning_rate': 2.8736833106218036e-05, 'epoch': 1.2757900136269178, 'step': 7083500}
INFO:transformers.trainer:{'loss': 3.062218670606613, 'learning_rate': 2.87353322121054e-05, 'epoch': 1.2758800672736763, 'step': 7084000}
INFO:transformers.trainer:{'loss': 3.0570504982471465, 'learning_rate': 2.8733831317992754e-05, 'epoch': 1.2759701209204346, 'step': 7084500}
INFO:transformers.trainer:{'loss': 3.0226212484836577, 'learning_rate': 2.8732330423880116e-05, 'epoch': 1.2760601745671931, 'step': 7085000}
INFO:transformers.trainer:{'loss': 3.070356244325638, 'learning_rate': 2.8730829529767472e-05, 'epoch': 1.2761502282139516, 'step': 7085500}
INFO:transformers.trainer:{'loss': 3.012748356580734, 'learning_rate': 2.8729328635654835e-05, 'epoch': 1.27624028186071, 'step': 7086000}
INFO:transformers.trainer:{'loss': 3.0224039256572723, 'learning_rate': 2.872782774154219e-05, 'epoch': 1.2763303355074684, 'step': 7086500}
INFO:transformers.trainer:{'loss': 3.0449635992050172, 'learning_rate': 2.8726326847429553e-05, 'epoch': 1.276420389154227, 'step': 7087000}
INFO:transformers.trainer:{'loss': 3.0537677332162856, 'learning_rate': 2.8724825953316915e-05, 'epoch': 1.2765104428009855, 'step': 7087500}
INFO:transformers.trainer:{'loss': 3.118004873275757, 'learning_rate': 2.872332505920427e-05, 'epoch': 1.276600496447744, 'step': 7088000}
INFO:transformers.trainer:{'loss': 3.011505603313446, 'learning_rate': 2.8721824165091633e-05, 'epoch': 1.2766905500945023, 'step': 7088500}
INFO:transformers.trainer:{'loss': 3.105943682074547, 'learning_rate': 2.872032327097899e-05, 'epoch': 1.2767806037412608, 'step': 7089000}
INFO:transformers.trainer:{'loss': 3.0573771262168883, 'learning_rate': 2.871882237686635e-05, 'epoch': 1.2768706573880193, 'step': 7089500}
INFO:transformers.trainer:{'loss': 3.037510483264923, 'learning_rate': 2.8717321482753707e-05, 'epoch': 1.2769607110347776, 'step': 7090000}
INFO:transformers.trainer:{'loss': 3.023584520101547, 'learning_rate': 2.871582058864107e-05, 'epoch': 1.277050764681536, 'step': 7090500}
INFO:transformers.trainer:{'loss': 3.0368997530937194, 'learning_rate': 2.8714319694528425e-05, 'epoch': 1.2771408183282946, 'step': 7091000}
INFO:transformers.trainer:{'loss': 3.0585054993629455, 'learning_rate': 2.8712818800415788e-05, 'epoch': 1.277230871975053, 'step': 7091500}
INFO:transformers.trainer:{'loss': 3.05015981400013, 'learning_rate': 2.8711317906303143e-05, 'epoch': 1.2773209256218114, 'step': 7092000}
INFO:transformers.trainer:{'loss': 3.0418487569093706, 'learning_rate': 2.8709817012190506e-05, 'epoch': 1.27741097926857, 'step': 7092500}
INFO:transformers.trainer:{'loss': 3.0111499987840653, 'learning_rate': 2.870831611807786e-05, 'epoch': 1.2775010329153282, 'step': 7093000}
INFO:transformers.trainer:{'loss': 3.06454954123497, 'learning_rate': 2.8706815223965224e-05, 'epoch': 1.2775910865620868, 'step': 7093500}
INFO:transformers.trainer:{'loss': 3.0922598819732667, 'learning_rate': 2.870531432985258e-05, 'epoch': 1.2776811402088453, 'step': 7094000}
INFO:transformers.trainer:{'loss': 3.0524182250499727, 'learning_rate': 2.8703813435739942e-05, 'epoch': 1.2777711938556036, 'step': 7094500}
INFO:transformers.trainer:{'loss': 3.0883853645324706, 'learning_rate': 2.87023125416273e-05, 'epoch': 1.277861247502362, 'step': 7095000}
INFO:transformers.trainer:{'loss': 2.992029005765915, 'learning_rate': 2.870081164751466e-05, 'epoch': 1.2779513011491206, 'step': 7095500}
INFO:transformers.trainer:{'loss': 3.0385555045604704, 'learning_rate': 2.869931075340202e-05, 'epoch': 1.2780413547958789, 'step': 7096000}
INFO:transformers.trainer:{'loss': 3.0649295033216477, 'learning_rate': 2.8697809859289375e-05, 'epoch': 1.2781314084426374, 'step': 7096500}
INFO:transformers.trainer:{'loss': 3.041654904842377, 'learning_rate': 2.8696308965176737e-05, 'epoch': 1.278221462089396, 'step': 7097000}
INFO:transformers.trainer:{'loss': 3.024331202983856, 'learning_rate': 2.8694808071064093e-05, 'epoch': 1.2783115157361544, 'step': 7097500}
INFO:transformers.trainer:{'loss': 3.0669150110483168, 'learning_rate': 2.8693307176951455e-05, 'epoch': 1.2784015693829127, 'step': 7098000}
INFO:transformers.trainer:{'loss': 2.9912231475114823, 'learning_rate': 2.869180628283881e-05, 'epoch': 1.2784916230296712, 'step': 7098500}
INFO:transformers.trainer:{'loss': 3.021012466788292, 'learning_rate': 2.8690305388726173e-05, 'epoch': 1.2785816766764297, 'step': 7099000}
INFO:transformers.trainer:{'loss': 3.0145655801296236, 'learning_rate': 2.868880449461353e-05, 'epoch': 1.2786717303231883, 'step': 7099500}
INFO:transformers.trainer:{'loss': 2.9950846325159075, 'learning_rate': 2.868730360050089e-05, 'epoch': 1.2787617839699466, 'step': 7100000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7100000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7100000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7100000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7000000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0747196221351625, 'learning_rate': 2.8685802706388247e-05, 'epoch': 1.278851837616705, 'step': 7100500}
INFO:transformers.trainer:{'loss': 3.061763005375862, 'learning_rate': 2.868430181227561e-05, 'epoch': 1.2789418912634636, 'step': 7101000}
INFO:transformers.trainer:{'loss': 2.939798671603203, 'learning_rate': 2.8682800918162972e-05, 'epoch': 1.2790319449102219, 'step': 7101500}
INFO:transformers.trainer:{'loss': 3.0767049164772033, 'learning_rate': 2.8681300024050328e-05, 'epoch': 1.2791219985569804, 'step': 7102000}
INFO:transformers.trainer:{'loss': 2.9954200801849367, 'learning_rate': 2.867979912993769e-05, 'epoch': 1.279212052203739, 'step': 7102500}
INFO:transformers.trainer:{'loss': 3.011147134304047, 'learning_rate': 2.8678298235825046e-05, 'epoch': 1.2793021058504972, 'step': 7103000}
INFO:transformers.trainer:{'loss': 3.017455160856247, 'learning_rate': 2.8676797341712408e-05, 'epoch': 1.2793921594972557, 'step': 7103500}
INFO:transformers.trainer:{'loss': 3.0852957911491394, 'learning_rate': 2.8675296447599764e-05, 'epoch': 1.2794822131440142, 'step': 7104000}
INFO:transformers.trainer:{'loss': 3.0026912405490873, 'learning_rate': 2.8673795553487126e-05, 'epoch': 1.2795722667907725, 'step': 7104500}
INFO:transformers.trainer:{'loss': 3.045083080768585, 'learning_rate': 2.8672294659374482e-05, 'epoch': 1.279662320437531, 'step': 7105000}
INFO:transformers.trainer:{'loss': 3.006441389799118, 'learning_rate': 2.8670793765261844e-05, 'epoch': 1.2797523740842895, 'step': 7105500}
INFO:transformers.trainer:{'loss': 2.997970998466015, 'learning_rate': 2.86692928711492e-05, 'epoch': 1.2798424277310478, 'step': 7106000}
INFO:transformers.trainer:{'loss': 3.0667250595092774, 'learning_rate': 2.8667791977036562e-05, 'epoch': 1.2799324813778064, 'step': 7106500}
INFO:transformers.trainer:{'loss': 3.0774831352233885, 'learning_rate': 2.8666291082923918e-05, 'epoch': 1.2800225350245649, 'step': 7107000}
INFO:transformers.trainer:{'loss': 3.026062355399132, 'learning_rate': 2.866479018881128e-05, 'epoch': 1.2801125886713232, 'step': 7107500}
INFO:transformers.trainer:{'loss': 2.9927452598810196, 'learning_rate': 2.8663289294698643e-05, 'epoch': 1.2802026423180817, 'step': 7108000}
INFO:transformers.trainer:{'loss': 2.9884277574121954, 'learning_rate': 2.8661788400586e-05, 'epoch': 1.2802926959648402, 'step': 7108500}
INFO:transformers.trainer:{'loss': 3.03107416677475, 'learning_rate': 2.866028750647336e-05, 'epoch': 1.2803827496115987, 'step': 7109000}
INFO:transformers.trainer:{'loss': 3.070075976729393, 'learning_rate': 2.8658786612360717e-05, 'epoch': 1.280472803258357, 'step': 7109500}
INFO:transformers.trainer:{'loss': 3.0910600419044494, 'learning_rate': 2.865728571824808e-05, 'epoch': 1.2805628569051155, 'step': 7110000}
INFO:transformers.trainer:{'loss': 2.98634445130825, 'learning_rate': 2.8655784824135435e-05, 'epoch': 1.280652910551874, 'step': 7110500}
INFO:transformers.trainer:{'loss': 3.011174507141113, 'learning_rate': 2.8654283930022797e-05, 'epoch': 1.2807429641986325, 'step': 7111000}
INFO:transformers.trainer:{'loss': 3.038941430091858, 'learning_rate': 2.8652783035910153e-05, 'epoch': 1.2808330178453908, 'step': 7111500}
INFO:transformers.trainer:{'loss': 3.097545404314995, 'learning_rate': 2.8651282141797515e-05, 'epoch': 1.2809230714921493, 'step': 7112000}
INFO:transformers.trainer:{'loss': 3.04126611495018, 'learning_rate': 2.864978124768487e-05, 'epoch': 1.2810131251389079, 'step': 7112500}
INFO:transformers.trainer:{'loss': 3.072389489412308, 'learning_rate': 2.8648280353572233e-05, 'epoch': 1.2811031787856662, 'step': 7113000}
INFO:transformers.trainer:{'loss': 3.0638004566431047, 'learning_rate': 2.864677945945959e-05, 'epoch': 1.2811932324324247, 'step': 7113500}
INFO:transformers.trainer:{'loss': 3.043273130774498, 'learning_rate': 2.864527856534695e-05, 'epoch': 1.2812832860791832, 'step': 7114000}
INFO:transformers.trainer:{'loss': 3.0539036988019945, 'learning_rate': 2.8643777671234307e-05, 'epoch': 1.2813733397259415, 'step': 7114500}
INFO:transformers.trainer:{'loss': 3.02511163020134, 'learning_rate': 2.864227677712167e-05, 'epoch': 1.2814633933727, 'step': 7115000}
INFO:transformers.trainer:{'loss': 3.00797674536705, 'learning_rate': 2.864077588300903e-05, 'epoch': 1.2815534470194585, 'step': 7115500}
INFO:transformers.trainer:{'loss': 3.0348657228946685, 'learning_rate': 2.8639274988896388e-05, 'epoch': 1.2816435006662168, 'step': 7116000}
INFO:transformers.trainer:{'loss': 3.0973113803863526, 'learning_rate': 2.8637774094783747e-05, 'epoch': 1.2817335543129753, 'step': 7116500}
INFO:transformers.trainer:{'loss': 3.0594902262687684, 'learning_rate': 2.8636273200671106e-05, 'epoch': 1.2818236079597338, 'step': 7117000}
INFO:transformers.trainer:{'loss': 3.1044449130296705, 'learning_rate': 2.8634772306558465e-05, 'epoch': 1.2819136616064921, 'step': 7117500}
INFO:transformers.trainer:{'loss': 3.032034024119377, 'learning_rate': 2.8633271412445824e-05, 'epoch': 1.2820037152532506, 'step': 7118000}
INFO:transformers.trainer:{'loss': 3.0200526000261307, 'learning_rate': 2.8631770518333183e-05, 'epoch': 1.2820937689000091, 'step': 7118500}
INFO:transformers.trainer:{'loss': 3.044525959968567, 'learning_rate': 2.8630269624220542e-05, 'epoch': 1.2821838225467674, 'step': 7119000}
INFO:transformers.trainer:{'loss': 3.0874178490638733, 'learning_rate': 2.86287687301079e-05, 'epoch': 1.282273876193526, 'step': 7119500}
INFO:transformers.trainer:{'loss': 3.0538867927193643, 'learning_rate': 2.8627267835995257e-05, 'epoch': 1.2823639298402845, 'step': 7120000}
INFO:transformers.trainer:{'loss': 3.0820403983592985, 'learning_rate': 2.862576694188262e-05, 'epoch': 1.282453983487043, 'step': 7120500}
INFO:transformers.trainer:{'loss': 3.0850363161563874, 'learning_rate': 2.8624266047769975e-05, 'epoch': 1.2825440371338013, 'step': 7121000}
INFO:transformers.trainer:{'loss': 3.0184683022499086, 'learning_rate': 2.8622765153657337e-05, 'epoch': 1.2826340907805598, 'step': 7121500}
INFO:transformers.trainer:{'loss': 3.0616033668518066, 'learning_rate': 2.86212642595447e-05, 'epoch': 1.2827241444273183, 'step': 7122000}
INFO:transformers.trainer:{'loss': 3.058623630642891, 'learning_rate': 2.8619763365432055e-05, 'epoch': 1.2828141980740768, 'step': 7122500}
INFO:transformers.trainer:{'loss': 3.0507263622283936, 'learning_rate': 2.8618262471319418e-05, 'epoch': 1.282904251720835, 'step': 7123000}
INFO:transformers.trainer:{'loss': 3.015725091814995, 'learning_rate': 2.8616761577206773e-05, 'epoch': 1.2829943053675936, 'step': 7123500}
INFO:transformers.trainer:{'loss': 3.0100360321998596, 'learning_rate': 2.8615260683094136e-05, 'epoch': 1.2830843590143521, 'step': 7124000}
INFO:transformers.trainer:{'loss': 3.0841007936000824, 'learning_rate': 2.861375978898149e-05, 'epoch': 1.2831744126611104, 'step': 7124500}
INFO:transformers.trainer:{'loss': 2.982454450726509, 'learning_rate': 2.8612258894868854e-05, 'epoch': 1.283264466307869, 'step': 7125000}
INFO:transformers.trainer:{'loss': 3.041478021621704, 'learning_rate': 2.861075800075621e-05, 'epoch': 1.2833545199546275, 'step': 7125500}
INFO:transformers.trainer:{'loss': 3.0351402015686033, 'learning_rate': 2.8609257106643572e-05, 'epoch': 1.2834445736013858, 'step': 7126000}
INFO:transformers.trainer:{'loss': 3.032384000301361, 'learning_rate': 2.8607756212530928e-05, 'epoch': 1.2835346272481443, 'step': 7126500}
INFO:transformers.trainer:{'loss': 3.095646040916443, 'learning_rate': 2.860625531841829e-05, 'epoch': 1.2836246808949028, 'step': 7127000}
INFO:transformers.trainer:{'loss': 3.0684635466337205, 'learning_rate': 2.8604754424305646e-05, 'epoch': 1.283714734541661, 'step': 7127500}
INFO:transformers.trainer:{'loss': 2.9825653373003007, 'learning_rate': 2.860325353019301e-05, 'epoch': 1.2838047881884196, 'step': 7128000}
INFO:transformers.trainer:{'loss': 3.0838544484376906, 'learning_rate': 2.8601752636080364e-05, 'epoch': 1.283894841835178, 'step': 7128500}
INFO:transformers.trainer:{'loss': 3.007857859015465, 'learning_rate': 2.8600251741967726e-05, 'epoch': 1.2839848954819364, 'step': 7129000}
INFO:transformers.trainer:{'loss': 3.0752883381843565, 'learning_rate': 2.859875084785509e-05, 'epoch': 1.284074949128695, 'step': 7129500}
INFO:transformers.trainer:{'loss': 3.0088633658885957, 'learning_rate': 2.8597249953742445e-05, 'epoch': 1.2841650027754534, 'step': 7130000}
INFO:transformers.trainer:{'loss': 2.984403194189072, 'learning_rate': 2.8595749059629807e-05, 'epoch': 1.2842550564222117, 'step': 7130500}
INFO:transformers.trainer:{'loss': 3.0208929002285005, 'learning_rate': 2.8594248165517163e-05, 'epoch': 1.2843451100689702, 'step': 7131000}
INFO:transformers.trainer:{'loss': 3.0839575259685517, 'learning_rate': 2.8592747271404525e-05, 'epoch': 1.2844351637157287, 'step': 7131500}
INFO:transformers.trainer:{'loss': 3.0612692320346833, 'learning_rate': 2.859124637729188e-05, 'epoch': 1.2845252173624873, 'step': 7132000}
INFO:transformers.trainer:{'loss': 3.0270760526657106, 'learning_rate': 2.8589745483179243e-05, 'epoch': 1.2846152710092456, 'step': 7132500}
INFO:transformers.trainer:{'loss': 3.0027578587532044, 'learning_rate': 2.85882445890666e-05, 'epoch': 1.284705324656004, 'step': 7133000}
INFO:transformers.trainer:{'loss': 3.0540276705026628, 'learning_rate': 2.858674369495396e-05, 'epoch': 1.2847953783027626, 'step': 7133500}
INFO:transformers.trainer:{'loss': 3.0127458958625795, 'learning_rate': 2.8585242800841317e-05, 'epoch': 1.284885431949521, 'step': 7134000}
INFO:transformers.trainer:{'loss': 3.014819002866745, 'learning_rate': 2.858374190672868e-05, 'epoch': 1.2849754855962794, 'step': 7134500}
INFO:transformers.trainer:{'loss': 3.0637308526039124, 'learning_rate': 2.8582241012616035e-05, 'epoch': 1.285065539243038, 'step': 7135000}
INFO:transformers.trainer:{'loss': 3.06130426132679, 'learning_rate': 2.8580740118503397e-05, 'epoch': 1.2851555928897964, 'step': 7135500}
INFO:transformers.trainer:{'loss': 3.048709106206894, 'learning_rate': 2.8579239224390757e-05, 'epoch': 1.2852456465365547, 'step': 7136000}
INFO:transformers.trainer:{'loss': 3.0540088950395585, 'learning_rate': 2.8577738330278116e-05, 'epoch': 1.2853357001833132, 'step': 7136500}
INFO:transformers.trainer:{'loss': 3.0187720264196396, 'learning_rate': 2.8576237436165475e-05, 'epoch': 1.2854257538300717, 'step': 7137000}
INFO:transformers.trainer:{'loss': 3.066758308470249, 'learning_rate': 2.8574736542052834e-05, 'epoch': 1.28551580747683, 'step': 7137500}
INFO:transformers.trainer:{'loss': 3.0248945410251618, 'learning_rate': 2.8573235647940193e-05, 'epoch': 1.2856058611235885, 'step': 7138000}
INFO:transformers.trainer:{'loss': 2.9750803091526032, 'learning_rate': 2.8571734753827552e-05, 'epoch': 1.285695914770347, 'step': 7138500}
INFO:transformers.trainer:{'loss': 2.987807245016098, 'learning_rate': 2.857023385971491e-05, 'epoch': 1.2857859684171054, 'step': 7139000}
INFO:transformers.trainer:{'loss': 3.038462287068367, 'learning_rate': 2.856873296560227e-05, 'epoch': 1.2858760220638639, 'step': 7139500}
INFO:transformers.trainer:{'loss': 3.0506486600637435, 'learning_rate': 2.856723207148963e-05, 'epoch': 1.2859660757106224, 'step': 7140000}
INFO:transformers.trainer:{'loss': 2.9886031963825226, 'learning_rate': 2.8565731177376988e-05, 'epoch': 1.2860561293573807, 'step': 7140500}
INFO:transformers.trainer:{'loss': 2.9988627126216887, 'learning_rate': 2.8564230283264347e-05, 'epoch': 1.2861461830041392, 'step': 7141000}
INFO:transformers.trainer:{'loss': 3.001585732936859, 'learning_rate': 2.8562729389151706e-05, 'epoch': 1.2862362366508977, 'step': 7141500}
INFO:transformers.trainer:{'loss': 3.1195213928222656, 'learning_rate': 2.8561228495039065e-05, 'epoch': 1.286326290297656, 'step': 7142000}
INFO:transformers.trainer:{'loss': 3.053679948568344, 'learning_rate': 2.8559727600926424e-05, 'epoch': 1.2864163439444145, 'step': 7142500}
INFO:transformers.trainer:{'loss': 3.0234980635643005, 'learning_rate': 2.8558226706813783e-05, 'epoch': 1.286506397591173, 'step': 7143000}
INFO:transformers.trainer:{'loss': 3.038426511764526, 'learning_rate': 2.8556725812701146e-05, 'epoch': 1.2865964512379315, 'step': 7143500}
INFO:transformers.trainer:{'loss': 3.075576054096222, 'learning_rate': 2.85552249185885e-05, 'epoch': 1.2866865048846898, 'step': 7144000}
INFO:transformers.trainer:{'loss': 3.1086730909347535, 'learning_rate': 2.8553724024475864e-05, 'epoch': 1.2867765585314483, 'step': 7144500}
INFO:transformers.trainer:{'loss': 3.0616436319351195, 'learning_rate': 2.855222313036322e-05, 'epoch': 1.2868666121782069, 'step': 7145000}
INFO:transformers.trainer:{'loss': 3.0123785512447356, 'learning_rate': 2.8550722236250582e-05, 'epoch': 1.2869566658249654, 'step': 7145500}
INFO:transformers.trainer:{'loss': 3.0458360562324525, 'learning_rate': 2.8549221342137938e-05, 'epoch': 1.2870467194717237, 'step': 7146000}
INFO:transformers.trainer:{'loss': 2.9454434149265287, 'learning_rate': 2.85477204480253e-05, 'epoch': 1.2871367731184822, 'step': 7146500}
INFO:transformers.trainer:{'loss': 3.054679444313049, 'learning_rate': 2.8546219553912656e-05, 'epoch': 1.2872268267652407, 'step': 7147000}
INFO:transformers.trainer:{'loss': 2.947417283177376, 'learning_rate': 2.8544718659800018e-05, 'epoch': 1.287316880411999, 'step': 7147500}
INFO:transformers.trainer:{'loss': 3.0065395810604096, 'learning_rate': 2.8543217765687374e-05, 'epoch': 1.2874069340587575, 'step': 7148000}
INFO:transformers.trainer:{'loss': 3.0207615711688995, 'learning_rate': 2.8541716871574736e-05, 'epoch': 1.287496987705516, 'step': 7148500}
INFO:transformers.trainer:{'loss': 3.05333491897583, 'learning_rate': 2.8540215977462092e-05, 'epoch': 1.2875870413522743, 'step': 7149000}
INFO:transformers.trainer:{'loss': 3.068966578364372, 'learning_rate': 2.8538715083349454e-05, 'epoch': 1.2876770949990328, 'step': 7149500}
INFO:transformers.trainer:{'loss': 3.0143287370204925, 'learning_rate': 2.8537214189236817e-05, 'epoch': 1.2877671486457913, 'step': 7150000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7150000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7150000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7150000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7050000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.036475863456726, 'learning_rate': 2.8535713295124172e-05, 'epoch': 1.2878572022925496, 'step': 7150500}
INFO:transformers.trainer:{'loss': 3.0311647741794587, 'learning_rate': 2.8534212401011535e-05, 'epoch': 1.2879472559393081, 'step': 7151000}
INFO:transformers.trainer:{'loss': 3.034992138624191, 'learning_rate': 2.853271150689889e-05, 'epoch': 1.2880373095860667, 'step': 7151500}
INFO:transformers.trainer:{'loss': 3.0514027955532073, 'learning_rate': 2.8531210612786253e-05, 'epoch': 1.288127363232825, 'step': 7152000}
INFO:transformers.trainer:{'loss': 3.0109091906547545, 'learning_rate': 2.852970971867361e-05, 'epoch': 1.2882174168795835, 'step': 7152500}
INFO:transformers.trainer:{'loss': 3.0027903473377227, 'learning_rate': 2.852820882456097e-05, 'epoch': 1.288307470526342, 'step': 7153000}
INFO:transformers.trainer:{'loss': 3.049880837917328, 'learning_rate': 2.8526707930448327e-05, 'epoch': 1.2883975241731003, 'step': 7153500}
INFO:transformers.trainer:{'loss': 3.0159687272310256, 'learning_rate': 2.852520703633569e-05, 'epoch': 1.2884875778198588, 'step': 7154000}
INFO:transformers.trainer:{'loss': 3.040847359657288, 'learning_rate': 2.8523706142223045e-05, 'epoch': 1.2885776314666173, 'step': 7154500}
INFO:transformers.trainer:{'loss': 3.085644695043564, 'learning_rate': 2.8522205248110407e-05, 'epoch': 1.2886676851133758, 'step': 7155000}
INFO:transformers.trainer:{'loss': 3.073143369674683, 'learning_rate': 2.8520704353997763e-05, 'epoch': 1.288757738760134, 'step': 7155500}
INFO:transformers.trainer:{'loss': 3.0507183343172075, 'learning_rate': 2.8519203459885125e-05, 'epoch': 1.2888477924068926, 'step': 7156000}
INFO:transformers.trainer:{'loss': 3.003833978652954, 'learning_rate': 2.8517702565772488e-05, 'epoch': 1.2889378460536511, 'step': 7156500}
INFO:transformers.trainer:{'loss': 3.0728857526779176, 'learning_rate': 2.8516201671659843e-05, 'epoch': 1.2890278997004097, 'step': 7157000}
INFO:transformers.trainer:{'loss': 3.063766704916954, 'learning_rate': 2.8514700777547206e-05, 'epoch': 1.289117953347168, 'step': 7157500}
INFO:transformers.trainer:{'loss': 3.0039846855401993, 'learning_rate': 2.851319988343456e-05, 'epoch': 1.2892080069939265, 'step': 7158000}
INFO:transformers.trainer:{'loss': 3.0855348089933394, 'learning_rate': 2.851169898932192e-05, 'epoch': 1.289298060640685, 'step': 7158500}
INFO:transformers.trainer:{'loss': 3.09407390332222, 'learning_rate': 2.851019809520928e-05, 'epoch': 1.2893881142874433, 'step': 7159000}
INFO:transformers.trainer:{'loss': 3.000688876271248, 'learning_rate': 2.850869720109664e-05, 'epoch': 1.2894781679342018, 'step': 7159500}
INFO:transformers.trainer:{'loss': 3.0109503482580187, 'learning_rate': 2.8507196306983998e-05, 'epoch': 1.2895682215809603, 'step': 7160000}
INFO:transformers.trainer:{'loss': 3.0062382036447524, 'learning_rate': 2.8505695412871357e-05, 'epoch': 1.2896582752277186, 'step': 7160500}
INFO:transformers.trainer:{'loss': 3.031354351758957, 'learning_rate': 2.8504194518758716e-05, 'epoch': 1.289748328874477, 'step': 7161000}
INFO:transformers.trainer:{'loss': 3.0630411632061003, 'learning_rate': 2.8502693624646075e-05, 'epoch': 1.2898383825212356, 'step': 7161500}
INFO:transformers.trainer:{'loss': 3.0345945987701417, 'learning_rate': 2.8501192730533434e-05, 'epoch': 1.289928436167994, 'step': 7162000}
INFO:transformers.trainer:{'loss': 3.0069104716777804, 'learning_rate': 2.8499691836420793e-05, 'epoch': 1.2900184898147524, 'step': 7162500}
INFO:transformers.trainer:{'loss': 3.099693269252777, 'learning_rate': 2.8498190942308152e-05, 'epoch': 1.290108543461511, 'step': 7163000}
INFO:transformers.trainer:{'loss': 3.074190368652344, 'learning_rate': 2.849669004819551e-05, 'epoch': 1.2901985971082692, 'step': 7163500}
INFO:transformers.trainer:{'loss': 3.02973313498497, 'learning_rate': 2.8495189154082873e-05, 'epoch': 1.2902886507550277, 'step': 7164000}
INFO:transformers.trainer:{'loss': 2.971926071047783, 'learning_rate': 2.849368825997023e-05, 'epoch': 1.2903787044017863, 'step': 7164500}
INFO:transformers.trainer:{'loss': 3.0157153812646866, 'learning_rate': 2.849218736585759e-05, 'epoch': 1.2904687580485446, 'step': 7165000}
INFO:transformers.trainer:{'loss': 2.972655315518379, 'learning_rate': 2.8490686471744947e-05, 'epoch': 1.290558811695303, 'step': 7165500}
INFO:transformers.trainer:{'loss': 3.005113231897354, 'learning_rate': 2.848918557763231e-05, 'epoch': 1.2906488653420616, 'step': 7166000}
INFO:transformers.trainer:{'loss': 2.99426247215271, 'learning_rate': 2.8487684683519665e-05, 'epoch': 1.29073891898882, 'step': 7166500}
INFO:transformers.trainer:{'loss': 3.0235938582420347, 'learning_rate': 2.8486183789407028e-05, 'epoch': 1.2908289726355784, 'step': 7167000}
INFO:transformers.trainer:{'loss': 3.065323281049728, 'learning_rate': 2.8484682895294383e-05, 'epoch': 1.290919026282337, 'step': 7167500}
INFO:transformers.trainer:{'loss': 3.052865394115448, 'learning_rate': 2.8483182001181746e-05, 'epoch': 1.2910090799290954, 'step': 7168000}
INFO:transformers.trainer:{'loss': 3.01487641453743, 'learning_rate': 2.84816811070691e-05, 'epoch': 1.291099133575854, 'step': 7168500}
INFO:transformers.trainer:{'loss': 3.015098219156265, 'learning_rate': 2.8480180212956464e-05, 'epoch': 1.2911891872226122, 'step': 7169000}
INFO:transformers.trainer:{'loss': 3.0555152921676636, 'learning_rate': 2.847867931884382e-05, 'epoch': 1.2912792408693707, 'step': 7169500}
INFO:transformers.trainer:{'loss': 3.0342125008106233, 'learning_rate': 2.8477178424731182e-05, 'epoch': 1.2913692945161293, 'step': 7170000}
INFO:transformers.trainer:{'loss': 3.0426516296863557, 'learning_rate': 2.8475677530618545e-05, 'epoch': 1.2914593481628875, 'step': 7170500}
INFO:transformers.trainer:{'loss': 3.0162155678272247, 'learning_rate': 2.84741766365059e-05, 'epoch': 1.291549401809646, 'step': 7171000}
INFO:transformers.trainer:{'loss': 3.103218978404999, 'learning_rate': 2.8472675742393263e-05, 'epoch': 1.2916394554564046, 'step': 7171500}
INFO:transformers.trainer:{'loss': 3.0250228760242464, 'learning_rate': 2.8471174848280618e-05, 'epoch': 1.2917295091031629, 'step': 7172000}
INFO:transformers.trainer:{'loss': 2.992028981566429, 'learning_rate': 2.846967395416798e-05, 'epoch': 1.2918195627499214, 'step': 7172500}
INFO:transformers.trainer:{'loss': 2.9790406529903413, 'learning_rate': 2.8468173060055336e-05, 'epoch': 1.29190961639668, 'step': 7173000}
INFO:transformers.trainer:{'loss': 3.0222886979579924, 'learning_rate': 2.84666721659427e-05, 'epoch': 1.2919996700434382, 'step': 7173500}
INFO:transformers.trainer:{'loss': 3.0401483212709426, 'learning_rate': 2.8465171271830054e-05, 'epoch': 1.2920897236901967, 'step': 7174000}
INFO:transformers.trainer:{'loss': 3.030675192832947, 'learning_rate': 2.8463670377717417e-05, 'epoch': 1.2921797773369552, 'step': 7174500}
INFO:transformers.trainer:{'loss': 3.1001188013553618, 'learning_rate': 2.8462169483604773e-05, 'epoch': 1.2922698309837135, 'step': 7175000}
INFO:transformers.trainer:{'loss': 3.066016991972923, 'learning_rate': 2.8460668589492135e-05, 'epoch': 1.292359884630472, 'step': 7175500}
INFO:transformers.trainer:{'loss': 3.065491686582565, 'learning_rate': 2.845916769537949e-05, 'epoch': 1.2924499382772305, 'step': 7176000}
INFO:transformers.trainer:{'loss': 3.0633329164981844, 'learning_rate': 2.8457666801266853e-05, 'epoch': 1.2925399919239888, 'step': 7176500}
INFO:transformers.trainer:{'loss': 3.105624869346619, 'learning_rate': 2.845616590715421e-05, 'epoch': 1.2926300455707473, 'step': 7177000}
INFO:transformers.trainer:{'loss': 2.987892792224884, 'learning_rate': 2.845466501304157e-05, 'epoch': 1.2927200992175059, 'step': 7177500}
INFO:transformers.trainer:{'loss': 3.07499268078804, 'learning_rate': 2.8453164118928934e-05, 'epoch': 1.2928101528642644, 'step': 7178000}
INFO:transformers.trainer:{'loss': 2.9797667509317396, 'learning_rate': 2.845166322481629e-05, 'epoch': 1.2929002065110227, 'step': 7178500}
INFO:transformers.trainer:{'loss': 3.043060291290283, 'learning_rate': 2.8450162330703652e-05, 'epoch': 1.2929902601577812, 'step': 7179000}
INFO:transformers.trainer:{'loss': 3.068951969385147, 'learning_rate': 2.8448661436591007e-05, 'epoch': 1.2930803138045397, 'step': 7179500}
INFO:transformers.trainer:{'loss': 3.000589963912964, 'learning_rate': 2.844716054247837e-05, 'epoch': 1.2931703674512982, 'step': 7180000}
INFO:transformers.trainer:{'loss': 3.008076432585716, 'learning_rate': 2.8445659648365726e-05, 'epoch': 1.2932604210980565, 'step': 7180500}
INFO:transformers.trainer:{'loss': 3.008743795633316, 'learning_rate': 2.8444158754253088e-05, 'epoch': 1.293350474744815, 'step': 7181000}
INFO:transformers.trainer:{'loss': 3.0255810000896455, 'learning_rate': 2.8442657860140444e-05, 'epoch': 1.2934405283915735, 'step': 7181500}
INFO:transformers.trainer:{'loss': 3.116998225927353, 'learning_rate': 2.8441156966027803e-05, 'epoch': 1.2935305820383318, 'step': 7182000}
INFO:transformers.trainer:{'loss': 3.0483086726665496, 'learning_rate': 2.8439656071915162e-05, 'epoch': 1.2936206356850903, 'step': 7182500}
INFO:transformers.trainer:{'loss': 2.9762061908245085, 'learning_rate': 2.843815517780252e-05, 'epoch': 1.2937106893318489, 'step': 7183000}
INFO:transformers.trainer:{'loss': 3.0112992302179338, 'learning_rate': 2.843665428368988e-05, 'epoch': 1.2938007429786071, 'step': 7183500}
INFO:transformers.trainer:{'loss': 3.021117994427681, 'learning_rate': 2.843515338957724e-05, 'epoch': 1.2938907966253657, 'step': 7184000}
INFO:transformers.trainer:{'loss': 3.0421956117153166, 'learning_rate': 2.84336524954646e-05, 'epoch': 1.2939808502721242, 'step': 7184500}
INFO:transformers.trainer:{'loss': 3.005546192407608, 'learning_rate': 2.8432151601351957e-05, 'epoch': 1.2940709039188825, 'step': 7185000}
INFO:transformers.trainer:{'loss': 3.0846613787412642, 'learning_rate': 2.843065070723932e-05, 'epoch': 1.294160957565641, 'step': 7185500}
INFO:transformers.trainer:{'loss': 3.084532932281494, 'learning_rate': 2.8429149813126675e-05, 'epoch': 1.2942510112123995, 'step': 7186000}
INFO:transformers.trainer:{'loss': 3.0638154010772705, 'learning_rate': 2.8427648919014038e-05, 'epoch': 1.2943410648591578, 'step': 7186500}
INFO:transformers.trainer:{'loss': 3.007834238529205, 'learning_rate': 2.8426148024901393e-05, 'epoch': 1.2944311185059163, 'step': 7187000}
INFO:transformers.trainer:{'loss': 3.0184103827476503, 'learning_rate': 2.8424647130788756e-05, 'epoch': 1.2945211721526748, 'step': 7187500}
INFO:transformers.trainer:{'loss': 2.9268293755054473, 'learning_rate': 2.842314623667611e-05, 'epoch': 1.294611225799433, 'step': 7188000}
INFO:transformers.trainer:{'loss': 3.0418062527179717, 'learning_rate': 2.8421645342563474e-05, 'epoch': 1.2947012794461916, 'step': 7188500}
INFO:transformers.trainer:{'loss': 3.037706448197365, 'learning_rate': 2.842014444845083e-05, 'epoch': 1.2947913330929501, 'step': 7189000}
INFO:transformers.trainer:{'loss': 2.998751541018486, 'learning_rate': 2.8418643554338192e-05, 'epoch': 1.2948813867397087, 'step': 7189500}
INFO:transformers.trainer:{'loss': 3.034583682179451, 'learning_rate': 2.8417142660225547e-05, 'epoch': 1.294971440386467, 'step': 7190000}
INFO:transformers.trainer:{'loss': 2.997121735572815, 'learning_rate': 2.841564176611291e-05, 'epoch': 1.2950614940332255, 'step': 7190500}
INFO:transformers.trainer:{'loss': 3.0461799392700195, 'learning_rate': 2.8414140872000266e-05, 'epoch': 1.295151547679984, 'step': 7191000}
INFO:transformers.trainer:{'loss': 3.042585849881172, 'learning_rate': 2.8412639977887628e-05, 'epoch': 1.2952416013267425, 'step': 7191500}
INFO:transformers.trainer:{'loss': 3.0141068643331526, 'learning_rate': 2.841113908377499e-05, 'epoch': 1.2953316549735008, 'step': 7192000}
INFO:transformers.trainer:{'loss': 3.032926248550415, 'learning_rate': 2.8409638189662346e-05, 'epoch': 1.2954217086202593, 'step': 7192500}
INFO:transformers.trainer:{'loss': 3.0883561775684356, 'learning_rate': 2.840813729554971e-05, 'epoch': 1.2955117622670178, 'step': 7193000}
INFO:transformers.trainer:{'loss': 3.0200827922821043, 'learning_rate': 2.8406636401437064e-05, 'epoch': 1.295601815913776, 'step': 7193500}
INFO:transformers.trainer:{'loss': 3.043727254152298, 'learning_rate': 2.8405135507324427e-05, 'epoch': 1.2956918695605346, 'step': 7194000}
INFO:transformers.trainer:{'loss': 3.023064712047577, 'learning_rate': 2.8403634613211782e-05, 'epoch': 1.2957819232072931, 'step': 7194500}
INFO:transformers.trainer:{'loss': 3.046547719180584, 'learning_rate': 2.8402133719099145e-05, 'epoch': 1.2958719768540514, 'step': 7195000}
INFO:transformers.trainer:{'loss': 3.0388400156497957, 'learning_rate': 2.84006328249865e-05, 'epoch': 1.29596203050081, 'step': 7195500}
INFO:transformers.trainer:{'loss': 3.0038164358139037, 'learning_rate': 2.8399131930873863e-05, 'epoch': 1.2960520841475685, 'step': 7196000}
INFO:transformers.trainer:{'loss': 3.004533768415451, 'learning_rate': 2.839763103676122e-05, 'epoch': 1.2961421377943267, 'step': 7196500}
INFO:transformers.trainer:{'loss': 3.0709779462814333, 'learning_rate': 2.839613014264858e-05, 'epoch': 1.2962321914410853, 'step': 7197000}
INFO:transformers.trainer:{'loss': 3.0128705312013624, 'learning_rate': 2.8394629248535937e-05, 'epoch': 1.2963222450878438, 'step': 7197500}
INFO:transformers.trainer:{'loss': 3.031584156513214, 'learning_rate': 2.83931283544233e-05, 'epoch': 1.296412298734602, 'step': 7198000}
INFO:transformers.trainer:{'loss': 3.020651428699493, 'learning_rate': 2.839162746031066e-05, 'epoch': 1.2965023523813606, 'step': 7198500}
INFO:transformers.trainer:{'loss': 3.0625623483657836, 'learning_rate': 2.8390126566198017e-05, 'epoch': 1.296592406028119, 'step': 7199000}
INFO:transformers.trainer:{'loss': 3.0892544724941255, 'learning_rate': 2.838862567208538e-05, 'epoch': 1.2966824596748774, 'step': 7199500}
INFO:transformers.trainer:{'loss': 3.0160024412870405, 'learning_rate': 2.8387124777972735e-05, 'epoch': 1.296772513321636, 'step': 7200000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7200000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7200000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7200000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7100000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 2.9737337197065354, 'learning_rate': 2.8385623883860098e-05, 'epoch': 1.2968625669683944, 'step': 7200500}
INFO:transformers.trainer:{'loss': 3.027187597155571, 'learning_rate': 2.8384122989747453e-05, 'epoch': 1.296952620615153, 'step': 7201000}
INFO:transformers.trainer:{'loss': 3.031738818407059, 'learning_rate': 2.8382622095634816e-05, 'epoch': 1.2970426742619114, 'step': 7201500}
INFO:transformers.trainer:{'loss': 2.9711865804195403, 'learning_rate': 2.838112120152217e-05, 'epoch': 1.2971327279086697, 'step': 7202000}
INFO:transformers.trainer:{'loss': 3.0039686433076858, 'learning_rate': 2.8379620307409534e-05, 'epoch': 1.2972227815554283, 'step': 7202500}
INFO:transformers.trainer:{'loss': 3.060938935995102, 'learning_rate': 2.837811941329689e-05, 'epoch': 1.2973128352021868, 'step': 7203000}
INFO:transformers.trainer:{'loss': 2.9862401170730593, 'learning_rate': 2.8376618519184252e-05, 'epoch': 1.297402888848945, 'step': 7203500}
INFO:transformers.trainer:{'loss': 3.1093493850827216, 'learning_rate': 2.8375117625071608e-05, 'epoch': 1.2974929424957036, 'step': 7204000}
INFO:transformers.trainer:{'loss': 3.0014620332717894, 'learning_rate': 2.837361673095897e-05, 'epoch': 1.297582996142462, 'step': 7204500}
INFO:transformers.trainer:{'loss': 2.986284472465515, 'learning_rate': 2.8372115836846326e-05, 'epoch': 1.2976730497892204, 'step': 7205000}
INFO:transformers.trainer:{'loss': 3.0018723962306977, 'learning_rate': 2.8370614942733685e-05, 'epoch': 1.297763103435979, 'step': 7205500}
INFO:transformers.trainer:{'loss': 3.034729169368744, 'learning_rate': 2.8369114048621047e-05, 'epoch': 1.2978531570827374, 'step': 7206000}
INFO:transformers.trainer:{'loss': 3.0285265769958496, 'learning_rate': 2.8367613154508403e-05, 'epoch': 1.2979432107294957, 'step': 7206500}
INFO:transformers.trainer:{'loss': 3.0935909881591797, 'learning_rate': 2.8366112260395765e-05, 'epoch': 1.2980332643762542, 'step': 7207000}
INFO:transformers.trainer:{'loss': 3.034054449915886, 'learning_rate': 2.836461136628312e-05, 'epoch': 1.2981233180230127, 'step': 7207500}
INFO:transformers.trainer:{'loss': 3.016048368573189, 'learning_rate': 2.8363110472170483e-05, 'epoch': 1.298213371669771, 'step': 7208000}
INFO:transformers.trainer:{'loss': 3.0581341941356657, 'learning_rate': 2.836160957805784e-05, 'epoch': 1.2983034253165295, 'step': 7208500}
INFO:transformers.trainer:{'loss': 3.0325583708286286, 'learning_rate': 2.83601086839452e-05, 'epoch': 1.298393478963288, 'step': 7209000}
INFO:transformers.trainer:{'loss': 2.9994176468849183, 'learning_rate': 2.8358607789832557e-05, 'epoch': 1.2984835326100463, 'step': 7209500}
INFO:transformers.trainer:{'loss': 3.0308909590244295, 'learning_rate': 2.835710689571992e-05, 'epoch': 1.2985735862568049, 'step': 7210000}
INFO:transformers.trainer:{'loss': 3.027983141541481, 'learning_rate': 2.8355606001607275e-05, 'epoch': 1.2986636399035634, 'step': 7210500}
INFO:transformers.trainer:{'loss': 3.056545828580856, 'learning_rate': 2.8354105107494638e-05, 'epoch': 1.2987536935503217, 'step': 7211000}
INFO:transformers.trainer:{'loss': 3.1081034041643143, 'learning_rate': 2.8352604213381993e-05, 'epoch': 1.2988437471970802, 'step': 7211500}
INFO:transformers.trainer:{'loss': 3.0127767107486725, 'learning_rate': 2.8351103319269356e-05, 'epoch': 1.2989338008438387, 'step': 7212000}
INFO:transformers.trainer:{'loss': 3.0721092224121094, 'learning_rate': 2.8349602425156718e-05, 'epoch': 1.2990238544905972, 'step': 7212500}
INFO:transformers.trainer:{'loss': 3.022821008682251, 'learning_rate': 2.8348101531044074e-05, 'epoch': 1.2991139081373557, 'step': 7213000}
INFO:transformers.trainer:{'loss': 3.1053980712890623, 'learning_rate': 2.8346600636931436e-05, 'epoch': 1.299203961784114, 'step': 7213500}
INFO:transformers.trainer:{'loss': 3.0108824949264528, 'learning_rate': 2.8345099742818792e-05, 'epoch': 1.2992940154308725, 'step': 7214000}
INFO:transformers.trainer:{'loss': 3.068477434515953, 'learning_rate': 2.8343598848706154e-05, 'epoch': 1.299384069077631, 'step': 7214500}
INFO:transformers.trainer:{'loss': 3.018132697701454, 'learning_rate': 2.834209795459351e-05, 'epoch': 1.2994741227243893, 'step': 7215000}
INFO:transformers.trainer:{'loss': 3.049880378007889, 'learning_rate': 2.8340597060480873e-05, 'epoch': 1.2995641763711479, 'step': 7215500}
INFO:transformers.trainer:{'loss': 3.0563369643688203, 'learning_rate': 2.8339096166368228e-05, 'epoch': 1.2996542300179064, 'step': 7216000}
INFO:transformers.trainer:{'loss': 3.0003726618289948, 'learning_rate': 2.833759527225559e-05, 'epoch': 1.2997442836646647, 'step': 7216500}
INFO:transformers.trainer:{'loss': 3.0341246984004973, 'learning_rate': 2.8336094378142946e-05, 'epoch': 1.2998343373114232, 'step': 7217000}
INFO:transformers.trainer:{'loss': 3.075142311692238, 'learning_rate': 2.833459348403031e-05, 'epoch': 1.2999243909581817, 'step': 7217500}
INFO:transformers.trainer:{'loss': 3.0067416454553606, 'learning_rate': 2.8333092589917664e-05, 'epoch': 1.30001444460494, 'step': 7218000}
INFO:transformers.trainer:{'loss': 3.020960159063339, 'learning_rate': 2.8331591695805027e-05, 'epoch': 1.3001044982516985, 'step': 7218500}
INFO:transformers.trainer:{'loss': 3.029536904811859, 'learning_rate': 2.833009080169239e-05, 'epoch': 1.300194551898457, 'step': 7219000}
INFO:transformers.trainer:{'loss': 3.026799204826355, 'learning_rate': 2.8328589907579745e-05, 'epoch': 1.3002846055452153, 'step': 7219500}
INFO:transformers.trainer:{'loss': 3.0192588337659836, 'learning_rate': 2.8327089013467107e-05, 'epoch': 1.3003746591919738, 'step': 7220000}
INFO:transformers.trainer:{'loss': 3.0198717865943907, 'learning_rate': 2.8325588119354463e-05, 'epoch': 1.3004647128387323, 'step': 7220500}
INFO:transformers.trainer:{'loss': 3.121718715310097, 'learning_rate': 2.8324087225241826e-05, 'epoch': 1.3005547664854906, 'step': 7221000}
INFO:transformers.trainer:{'loss': 2.9967146161794664, 'learning_rate': 2.832258633112918e-05, 'epoch': 1.3006448201322491, 'step': 7221500}
INFO:transformers.trainer:{'loss': 3.040460556149483, 'learning_rate': 2.8321085437016544e-05, 'epoch': 1.3007348737790076, 'step': 7222000}
INFO:transformers.trainer:{'loss': 3.0108179104328157, 'learning_rate': 2.83195845429039e-05, 'epoch': 1.300824927425766, 'step': 7222500}
INFO:transformers.trainer:{'loss': 3.0334082193374634, 'learning_rate': 2.8318083648791262e-05, 'epoch': 1.3009149810725245, 'step': 7223000}
INFO:transformers.trainer:{'loss': 3.014545816540718, 'learning_rate': 2.8316582754678617e-05, 'epoch': 1.301005034719283, 'step': 7223500}
INFO:transformers.trainer:{'loss': 3.048674904823303, 'learning_rate': 2.831508186056598e-05, 'epoch': 1.3010950883660415, 'step': 7224000}
INFO:transformers.trainer:{'loss': 3.0446835860013963, 'learning_rate': 2.8313580966453335e-05, 'epoch': 1.3011851420128, 'step': 7224500}
INFO:transformers.trainer:{'loss': 3.0454913284778593, 'learning_rate': 2.8312080072340698e-05, 'epoch': 1.3012751956595583, 'step': 7225000}
INFO:transformers.trainer:{'loss': 2.9976196358203886, 'learning_rate': 2.8310579178228054e-05, 'epoch': 1.3013652493063168, 'step': 7225500}
INFO:transformers.trainer:{'loss': 3.073659437775612, 'learning_rate': 2.8309078284115416e-05, 'epoch': 1.3014553029530753, 'step': 7226000}
INFO:transformers.trainer:{'loss': 3.055628192663193, 'learning_rate': 2.8307577390002775e-05, 'epoch': 1.3015453565998336, 'step': 7226500}
INFO:transformers.trainer:{'loss': 3.0041365126371384, 'learning_rate': 2.8306076495890134e-05, 'epoch': 1.3016354102465921, 'step': 7227000}
INFO:transformers.trainer:{'loss': 3.033386527657509, 'learning_rate': 2.8304575601777493e-05, 'epoch': 1.3017254638933506, 'step': 7227500}
INFO:transformers.trainer:{'loss': 3.0191653875112534, 'learning_rate': 2.8303074707664852e-05, 'epoch': 1.301815517540109, 'step': 7228000}
INFO:transformers.trainer:{'loss': 3.071874888181686, 'learning_rate': 2.830157381355221e-05, 'epoch': 1.3019055711868674, 'step': 7228500}
INFO:transformers.trainer:{'loss': 3.0559774317741395, 'learning_rate': 2.830007291943957e-05, 'epoch': 1.301995624833626, 'step': 7229000}
INFO:transformers.trainer:{'loss': 3.0016848982572557, 'learning_rate': 2.829857202532693e-05, 'epoch': 1.3020856784803843, 'step': 7229500}
INFO:transformers.trainer:{'loss': 3.0461774110794066, 'learning_rate': 2.8297071131214285e-05, 'epoch': 1.3021757321271428, 'step': 7230000}
INFO:transformers.trainer:{'loss': 2.996155967116356, 'learning_rate': 2.8295570237101647e-05, 'epoch': 1.3022657857739013, 'step': 7230500}
INFO:transformers.trainer:{'loss': 3.024030170202255, 'learning_rate': 2.8294069342989003e-05, 'epoch': 1.3023558394206596, 'step': 7231000}
INFO:transformers.trainer:{'loss': 3.026202739238739, 'learning_rate': 2.8292568448876366e-05, 'epoch': 1.302445893067418, 'step': 7231500}
INFO:transformers.trainer:{'loss': 2.942817751765251, 'learning_rate': 2.829106755476372e-05, 'epoch': 1.3025359467141766, 'step': 7232000}
INFO:transformers.trainer:{'loss': 3.135145418405533, 'learning_rate': 2.8289566660651084e-05, 'epoch': 1.302626000360935, 'step': 7232500}
INFO:transformers.trainer:{'loss': 2.9961387012004854, 'learning_rate': 2.8288065766538446e-05, 'epoch': 1.3027160540076934, 'step': 7233000}
INFO:transformers.trainer:{'loss': 3.0474803717136383, 'learning_rate': 2.8286564872425802e-05, 'epoch': 1.302806107654452, 'step': 7233500}
INFO:transformers.trainer:{'loss': 3.0254124579429624, 'learning_rate': 2.8285063978313164e-05, 'epoch': 1.3028961613012102, 'step': 7234000}
INFO:transformers.trainer:{'loss': 3.097397316455841, 'learning_rate': 2.828356308420052e-05, 'epoch': 1.3029862149479687, 'step': 7234500}
INFO:transformers.trainer:{'loss': 3.0066781768798827, 'learning_rate': 2.8282062190087882e-05, 'epoch': 1.3030762685947272, 'step': 7235000}
INFO:transformers.trainer:{'loss': 3.033900374650955, 'learning_rate': 2.8280561295975238e-05, 'epoch': 1.3031663222414858, 'step': 7235500}
INFO:transformers.trainer:{'loss': 3.0080332909822465, 'learning_rate': 2.82790604018626e-05, 'epoch': 1.3032563758882443, 'step': 7236000}
INFO:transformers.trainer:{'loss': 3.0313169417381287, 'learning_rate': 2.8277559507749956e-05, 'epoch': 1.3033464295350026, 'step': 7236500}
INFO:transformers.trainer:{'loss': 2.9565397627353667, 'learning_rate': 2.827605861363732e-05, 'epoch': 1.303436483181761, 'step': 7237000}
INFO:transformers.trainer:{'loss': 3.0599990528821945, 'learning_rate': 2.8274557719524674e-05, 'epoch': 1.3035265368285196, 'step': 7237500}
INFO:transformers.trainer:{'loss': 2.986661873817444, 'learning_rate': 2.8273056825412037e-05, 'epoch': 1.303616590475278, 'step': 7238000}
INFO:transformers.trainer:{'loss': 3.0736686131954194, 'learning_rate': 2.8271555931299392e-05, 'epoch': 1.3037066441220364, 'step': 7238500}
INFO:transformers.trainer:{'loss': 3.0470834456682203, 'learning_rate': 2.8270055037186755e-05, 'epoch': 1.303796697768795, 'step': 7239000}
INFO:transformers.trainer:{'loss': 2.981797314167023, 'learning_rate': 2.826855414307411e-05, 'epoch': 1.3038867514155532, 'step': 7239500}
INFO:transformers.trainer:{'loss': 3.03960899746418, 'learning_rate': 2.8267053248961473e-05, 'epoch': 1.3039768050623117, 'step': 7240000}
INFO:transformers.trainer:{'loss': 2.9652081871032716, 'learning_rate': 2.8265552354848835e-05, 'epoch': 1.3040668587090702, 'step': 7240500}
INFO:transformers.trainer:{'loss': 3.0006543684005735, 'learning_rate': 2.826405146073619e-05, 'epoch': 1.3041569123558285, 'step': 7241000}
INFO:transformers.trainer:{'loss': 2.978744938850403, 'learning_rate': 2.8262550566623553e-05, 'epoch': 1.304246966002587, 'step': 7241500}
INFO:transformers.trainer:{'loss': 3.0348403701782227, 'learning_rate': 2.826104967251091e-05, 'epoch': 1.3043370196493456, 'step': 7242000}
INFO:transformers.trainer:{'loss': 3.045286756038666, 'learning_rate': 2.825954877839827e-05, 'epoch': 1.3044270732961039, 'step': 7242500}
INFO:transformers.trainer:{'loss': 2.991107279777527, 'learning_rate': 2.8258047884285627e-05, 'epoch': 1.3045171269428624, 'step': 7243000}
INFO:transformers.trainer:{'loss': 2.9957856528759, 'learning_rate': 2.825654699017299e-05, 'epoch': 1.3046071805896209, 'step': 7243500}
INFO:transformers.trainer:{'loss': 2.9855994820594787, 'learning_rate': 2.8255046096060345e-05, 'epoch': 1.3046972342363792, 'step': 7244000}
INFO:transformers.trainer:{'loss': 3.0348500124812126, 'learning_rate': 2.8253545201947708e-05, 'epoch': 1.3047872878831377, 'step': 7244500}
INFO:transformers.trainer:{'loss': 3.032824834823608, 'learning_rate': 2.8252044307835063e-05, 'epoch': 1.3048773415298962, 'step': 7245000}
INFO:transformers.trainer:{'loss': 2.9952667248249054, 'learning_rate': 2.8250543413722426e-05, 'epoch': 1.3049673951766545, 'step': 7245500}
INFO:transformers.trainer:{'loss': 3.0944448726177214, 'learning_rate': 2.824904251960978e-05, 'epoch': 1.305057448823413, 'step': 7246000}
INFO:transformers.trainer:{'loss': 2.974439677834511, 'learning_rate': 2.8247541625497144e-05, 'epoch': 1.3051475024701715, 'step': 7246500}
INFO:transformers.trainer:{'loss': 2.978388124704361, 'learning_rate': 2.8246040731384503e-05, 'epoch': 1.30523755611693, 'step': 7247000}
INFO:transformers.trainer:{'loss': 3.0228723073005677, 'learning_rate': 2.8244539837271862e-05, 'epoch': 1.3053276097636886, 'step': 7247500}
INFO:transformers.trainer:{'loss': 3.1145632977485658, 'learning_rate': 2.824303894315922e-05, 'epoch': 1.3054176634104468, 'step': 7248000}
INFO:transformers.trainer:{'loss': 2.9797963621616366, 'learning_rate': 2.824153804904658e-05, 'epoch': 1.3055077170572054, 'step': 7248500}
INFO:transformers.trainer:{'loss': 3.042069410443306, 'learning_rate': 2.824003715493394e-05, 'epoch': 1.3055977707039639, 'step': 7249000}
INFO:transformers.trainer:{'loss': 3.0319862920045852, 'learning_rate': 2.8238536260821298e-05, 'epoch': 1.3056878243507222, 'step': 7249500}
INFO:transformers.trainer:{'loss': 3.0183301672935485, 'learning_rate': 2.8237035366708657e-05, 'epoch': 1.3057778779974807, 'step': 7250000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7250000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7250000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7250000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7150000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.024492291927338, 'learning_rate': 2.8235534472596016e-05, 'epoch': 1.3058679316442392, 'step': 7250500}
INFO:transformers.trainer:{'loss': 2.9974113346338274, 'learning_rate': 2.8234033578483375e-05, 'epoch': 1.3059579852909975, 'step': 7251000}
INFO:transformers.trainer:{'loss': 3.0480508863925935, 'learning_rate': 2.8232532684370734e-05, 'epoch': 1.306048038937756, 'step': 7251500}
INFO:transformers.trainer:{'loss': 3.0392778075933458, 'learning_rate': 2.8231031790258093e-05, 'epoch': 1.3061380925845145, 'step': 7252000}
INFO:transformers.trainer:{'loss': 2.973927382946014, 'learning_rate': 2.8229530896145452e-05, 'epoch': 1.3062281462312728, 'step': 7252500}
INFO:transformers.trainer:{'loss': 3.004241884589195, 'learning_rate': 2.822803000203281e-05, 'epoch': 1.3063181998780313, 'step': 7253000}
INFO:transformers.trainer:{'loss': 3.0579143315553665, 'learning_rate': 2.8226529107920167e-05, 'epoch': 1.3064082535247898, 'step': 7253500}
INFO:transformers.trainer:{'loss': 3.029266343832016, 'learning_rate': 2.822502821380753e-05, 'epoch': 1.3064983071715481, 'step': 7254000}
INFO:transformers.trainer:{'loss': 2.9933375425338746, 'learning_rate': 2.8223527319694892e-05, 'epoch': 1.3065883608183066, 'step': 7254500}
INFO:transformers.trainer:{'loss': 2.979507842183113, 'learning_rate': 2.8222026425582248e-05, 'epoch': 1.3066784144650652, 'step': 7255000}
INFO:transformers.trainer:{'loss': 3.0447660435438157, 'learning_rate': 2.822052553146961e-05, 'epoch': 1.3067684681118235, 'step': 7255500}
INFO:transformers.trainer:{'loss': 3.034287812232971, 'learning_rate': 2.8219024637356966e-05, 'epoch': 1.306858521758582, 'step': 7256000}
INFO:transformers.trainer:{'loss': 2.996150020360947, 'learning_rate': 2.8217523743244328e-05, 'epoch': 1.3069485754053405, 'step': 7256500}
INFO:transformers.trainer:{'loss': 3.0425116585493086, 'learning_rate': 2.8216022849131684e-05, 'epoch': 1.307038629052099, 'step': 7257000}
INFO:transformers.trainer:{'loss': 3.010701101899147, 'learning_rate': 2.8214521955019046e-05, 'epoch': 1.3071286826988573, 'step': 7257500}
INFO:transformers.trainer:{'loss': 3.0657282090187072, 'learning_rate': 2.8213021060906402e-05, 'epoch': 1.3072187363456158, 'step': 7258000}
INFO:transformers.trainer:{'loss': 3.005309595108032, 'learning_rate': 2.8211520166793764e-05, 'epoch': 1.3073087899923743, 'step': 7258500}
INFO:transformers.trainer:{'loss': 3.0079266937971116, 'learning_rate': 2.821001927268112e-05, 'epoch': 1.3073988436391328, 'step': 7259000}
INFO:transformers.trainer:{'loss': 3.0600046350955963, 'learning_rate': 2.8208518378568483e-05, 'epoch': 1.3074888972858911, 'step': 7259500}
INFO:transformers.trainer:{'loss': 3.018160408258438, 'learning_rate': 2.8207017484455838e-05, 'epoch': 1.3075789509326496, 'step': 7260000}
INFO:transformers.trainer:{'loss': 3.0637466036081316, 'learning_rate': 2.82055165903432e-05, 'epoch': 1.3076690045794082, 'step': 7260500}
INFO:transformers.trainer:{'loss': 2.9886492519378662, 'learning_rate': 2.8204015696230563e-05, 'epoch': 1.3077590582261664, 'step': 7261000}
INFO:transformers.trainer:{'loss': 3.1149264521598816, 'learning_rate': 2.820251480211792e-05, 'epoch': 1.307849111872925, 'step': 7261500}
INFO:transformers.trainer:{'loss': 3.0001819264888763, 'learning_rate': 2.820101390800528e-05, 'epoch': 1.3079391655196835, 'step': 7262000}
INFO:transformers.trainer:{'loss': 3.0520591368675234, 'learning_rate': 2.8199513013892637e-05, 'epoch': 1.3080292191664418, 'step': 7262500}
INFO:transformers.trainer:{'loss': 3.0004223046302796, 'learning_rate': 2.819801211978e-05, 'epoch': 1.3081192728132003, 'step': 7263000}
INFO:transformers.trainer:{'loss': 3.033210931301117, 'learning_rate': 2.8196511225667355e-05, 'epoch': 1.3082093264599588, 'step': 7263500}
INFO:transformers.trainer:{'loss': 3.0498187551498415, 'learning_rate': 2.8195010331554717e-05, 'epoch': 1.308299380106717, 'step': 7264000}
INFO:transformers.trainer:{'loss': 2.9825626196861266, 'learning_rate': 2.8193509437442073e-05, 'epoch': 1.3083894337534756, 'step': 7264500}
INFO:transformers.trainer:{'loss': 3.0371295377016065, 'learning_rate': 2.8192008543329435e-05, 'epoch': 1.3084794874002341, 'step': 7265000}
INFO:transformers.trainer:{'loss': 2.974712939143181, 'learning_rate': 2.819050764921679e-05, 'epoch': 1.3085695410469924, 'step': 7265500}
INFO:transformers.trainer:{'loss': 3.058087023258209, 'learning_rate': 2.8189006755104154e-05, 'epoch': 1.308659594693751, 'step': 7266000}
INFO:transformers.trainer:{'loss': 3.029590543627739, 'learning_rate': 2.818750586099151e-05, 'epoch': 1.3087496483405094, 'step': 7266500}
INFO:transformers.trainer:{'loss': 3.028972129225731, 'learning_rate': 2.818600496687887e-05, 'epoch': 1.3088397019872677, 'step': 7267000}
INFO:transformers.trainer:{'loss': 3.0154536567926407, 'learning_rate': 2.818450407276623e-05, 'epoch': 1.3089297556340262, 'step': 7267500}
INFO:transformers.trainer:{'loss': 3.046520132303238, 'learning_rate': 2.818300317865359e-05, 'epoch': 1.3090198092807848, 'step': 7268000}
INFO:transformers.trainer:{'loss': 3.0923608549833297, 'learning_rate': 2.818150228454095e-05, 'epoch': 1.3091098629275433, 'step': 7268500}
INFO:transformers.trainer:{'loss': 3.0811222604513167, 'learning_rate': 2.8180001390428308e-05, 'epoch': 1.3091999165743016, 'step': 7269000}
INFO:transformers.trainer:{'loss': 3.012321689605713, 'learning_rate': 2.8178500496315667e-05, 'epoch': 1.30928997022106, 'step': 7269500}
INFO:transformers.trainer:{'loss': 3.008543581366539, 'learning_rate': 2.8176999602203026e-05, 'epoch': 1.3093800238678186, 'step': 7270000}
INFO:transformers.trainer:{'loss': 3.0452189897298814, 'learning_rate': 2.8175498708090385e-05, 'epoch': 1.3094700775145771, 'step': 7270500}
INFO:transformers.trainer:{'loss': 3.0216161320209505, 'learning_rate': 2.8173997813977744e-05, 'epoch': 1.3095601311613354, 'step': 7271000}
INFO:transformers.trainer:{'loss': 3.0201175150871276, 'learning_rate': 2.8172496919865103e-05, 'epoch': 1.309650184808094, 'step': 7271500}
INFO:transformers.trainer:{'loss': 3.0305283801555634, 'learning_rate': 2.8170996025752462e-05, 'epoch': 1.3097402384548524, 'step': 7272000}
INFO:transformers.trainer:{'loss': 3.0507143708467486, 'learning_rate': 2.816949513163982e-05, 'epoch': 1.3098302921016107, 'step': 7272500}
INFO:transformers.trainer:{'loss': 3.0343031084537504, 'learning_rate': 2.816799423752718e-05, 'epoch': 1.3099203457483692, 'step': 7273000}
INFO:transformers.trainer:{'loss': 3.020216879606247, 'learning_rate': 2.816649334341454e-05, 'epoch': 1.3100103993951278, 'step': 7273500}
INFO:transformers.trainer:{'loss': 3.0494503601789473, 'learning_rate': 2.81649924493019e-05, 'epoch': 1.310100453041886, 'step': 7274000}
INFO:transformers.trainer:{'loss': 3.0054300754070282, 'learning_rate': 2.8163491555189257e-05, 'epoch': 1.3101905066886446, 'step': 7274500}
INFO:transformers.trainer:{'loss': 3.1056846631765365, 'learning_rate': 2.816199066107662e-05, 'epoch': 1.310280560335403, 'step': 7275000}
INFO:transformers.trainer:{'loss': 3.051679423332214, 'learning_rate': 2.8160489766963976e-05, 'epoch': 1.3103706139821614, 'step': 7275500}
INFO:transformers.trainer:{'loss': 3.026695508480072, 'learning_rate': 2.8158988872851338e-05, 'epoch': 1.3104606676289199, 'step': 7276000}
INFO:transformers.trainer:{'loss': 3.001177336215973, 'learning_rate': 2.8157487978738694e-05, 'epoch': 1.3105507212756784, 'step': 7276500}
INFO:transformers.trainer:{'loss': 3.039493781089783, 'learning_rate': 2.8155987084626056e-05, 'epoch': 1.3106407749224367, 'step': 7277000}
INFO:transformers.trainer:{'loss': 3.0636365212202072, 'learning_rate': 2.8154486190513412e-05, 'epoch': 1.3107308285691952, 'step': 7277500}
INFO:transformers.trainer:{'loss': 3.0256119954586027, 'learning_rate': 2.8152985296400774e-05, 'epoch': 1.3108208822159537, 'step': 7278000}
INFO:transformers.trainer:{'loss': 3.06212451338768, 'learning_rate': 2.815148440228813e-05, 'epoch': 1.310910935862712, 'step': 7278500}
INFO:transformers.trainer:{'loss': 3.040910885095596, 'learning_rate': 2.8149983508175492e-05, 'epoch': 1.3110009895094705, 'step': 7279000}
INFO:transformers.trainer:{'loss': 3.0502435661554337, 'learning_rate': 2.8148482614062848e-05, 'epoch': 1.311091043156229, 'step': 7279500}
INFO:transformers.trainer:{'loss': 3.052426480770111, 'learning_rate': 2.814698171995021e-05, 'epoch': 1.3111810968029876, 'step': 7280000}
INFO:transformers.trainer:{'loss': 3.047964727163315, 'learning_rate': 2.8145480825837566e-05, 'epoch': 1.3112711504497458, 'step': 7280500}
INFO:transformers.trainer:{'loss': 3.0236108689308168, 'learning_rate': 2.814397993172493e-05, 'epoch': 1.3113612040965044, 'step': 7281000}
INFO:transformers.trainer:{'loss': 3.0439776346683503, 'learning_rate': 2.814247903761229e-05, 'epoch': 1.3114512577432629, 'step': 7281500}
INFO:transformers.trainer:{'loss': 3.008370186805725, 'learning_rate': 2.8140978143499647e-05, 'epoch': 1.3115413113900214, 'step': 7282000}
INFO:transformers.trainer:{'loss': 3.0510414292812347, 'learning_rate': 2.813947724938701e-05, 'epoch': 1.3116313650367797, 'step': 7282500}
INFO:transformers.trainer:{'loss': 2.9890285485982897, 'learning_rate': 2.8137976355274365e-05, 'epoch': 1.3117214186835382, 'step': 7283000}
INFO:transformers.trainer:{'loss': 3.0541729369163515, 'learning_rate': 2.8136475461161727e-05, 'epoch': 1.3118114723302967, 'step': 7283500}
INFO:transformers.trainer:{'loss': 3.015536950111389, 'learning_rate': 2.8134974567049083e-05, 'epoch': 1.311901525977055, 'step': 7284000}
INFO:transformers.trainer:{'loss': 3.007108788728714, 'learning_rate': 2.8133473672936445e-05, 'epoch': 1.3119915796238135, 'step': 7284500}
INFO:transformers.trainer:{'loss': 3.014951946020126, 'learning_rate': 2.81319727788238e-05, 'epoch': 1.312081633270572, 'step': 7285000}
INFO:transformers.trainer:{'loss': 3.012837831258774, 'learning_rate': 2.8130471884711163e-05, 'epoch': 1.3121716869173303, 'step': 7285500}
INFO:transformers.trainer:{'loss': 3.007076849937439, 'learning_rate': 2.812897099059852e-05, 'epoch': 1.3122617405640888, 'step': 7286000}
INFO:transformers.trainer:{'loss': 3.059526933670044, 'learning_rate': 2.812747009648588e-05, 'epoch': 1.3123517942108474, 'step': 7286500}
INFO:transformers.trainer:{'loss': 3.0631710975170137, 'learning_rate': 2.8125969202373237e-05, 'epoch': 1.3124418478576056, 'step': 7287000}
INFO:transformers.trainer:{'loss': 3.051419326663017, 'learning_rate': 2.81244683082606e-05, 'epoch': 1.3125319015043642, 'step': 7287500}
INFO:transformers.trainer:{'loss': 2.9657944118976594, 'learning_rate': 2.8122967414147955e-05, 'epoch': 1.3126219551511227, 'step': 7288000}
INFO:transformers.trainer:{'loss': 3.0558801739215853, 'learning_rate': 2.8121466520035318e-05, 'epoch': 1.312712008797881, 'step': 7288500}
INFO:transformers.trainer:{'loss': 3.0599710147380828, 'learning_rate': 2.811996562592268e-05, 'epoch': 1.3128020624446395, 'step': 7289000}
INFO:transformers.trainer:{'loss': 3.0144451603889464, 'learning_rate': 2.8118464731810036e-05, 'epoch': 1.312892116091398, 'step': 7289500}
INFO:transformers.trainer:{'loss': 3.0087949142456054, 'learning_rate': 2.8116963837697398e-05, 'epoch': 1.3129821697381563, 'step': 7290000}
INFO:transformers.trainer:{'loss': 2.9818307856321336, 'learning_rate': 2.8115462943584754e-05, 'epoch': 1.3130722233849148, 'step': 7290500}
INFO:transformers.trainer:{'loss': 3.029710322380066, 'learning_rate': 2.8113962049472116e-05, 'epoch': 1.3131622770316733, 'step': 7291000}
INFO:transformers.trainer:{'loss': 3.0075640747547148, 'learning_rate': 2.8112461155359472e-05, 'epoch': 1.3132523306784318, 'step': 7291500}
INFO:transformers.trainer:{'loss': 3.0925246250629423, 'learning_rate': 2.811096026124683e-05, 'epoch': 1.3133423843251901, 'step': 7292000}
INFO:transformers.trainer:{'loss': 3.078586387872696, 'learning_rate': 2.810945936713419e-05, 'epoch': 1.3134324379719486, 'step': 7292500}
INFO:transformers.trainer:{'loss': 3.0032502101659775, 'learning_rate': 2.810795847302155e-05, 'epoch': 1.3135224916187072, 'step': 7293000}
INFO:transformers.trainer:{'loss': 3.0516066200733185, 'learning_rate': 2.8106457578908908e-05, 'epoch': 1.3136125452654657, 'step': 7293500}
INFO:transformers.trainer:{'loss': 3.0907415833473206, 'learning_rate': 2.8104956684796267e-05, 'epoch': 1.313702598912224, 'step': 7294000}
INFO:transformers.trainer:{'loss': 2.9966512945890424, 'learning_rate': 2.8103455790683626e-05, 'epoch': 1.3137926525589825, 'step': 7294500}
INFO:transformers.trainer:{'loss': 2.9571084563732146, 'learning_rate': 2.8101954896570985e-05, 'epoch': 1.313882706205741, 'step': 7295000}
INFO:transformers.trainer:{'loss': 3.009427366256714, 'learning_rate': 2.8100454002458348e-05, 'epoch': 1.3139727598524993, 'step': 7295500}
INFO:transformers.trainer:{'loss': 2.983265257835388, 'learning_rate': 2.8098953108345703e-05, 'epoch': 1.3140628134992578, 'step': 7296000}
INFO:transformers.trainer:{'loss': 3.021959671020508, 'learning_rate': 2.8097452214233066e-05, 'epoch': 1.3141528671460163, 'step': 7296500}
INFO:transformers.trainer:{'loss': 3.005135839700699, 'learning_rate': 2.809595132012042e-05, 'epoch': 1.3142429207927746, 'step': 7297000}
INFO:transformers.trainer:{'loss': 2.996206025123596, 'learning_rate': 2.8094450426007784e-05, 'epoch': 1.3143329744395331, 'step': 7297500}
INFO:transformers.trainer:{'loss': 3.041927537918091, 'learning_rate': 2.809294953189514e-05, 'epoch': 1.3144230280862916, 'step': 7298000}
INFO:transformers.trainer:{'loss': 3.0324833966493605, 'learning_rate': 2.8091448637782502e-05, 'epoch': 1.31451308173305, 'step': 7298500}
INFO:transformers.trainer:{'loss': 3.035971836090088, 'learning_rate': 2.8089947743669858e-05, 'epoch': 1.3146031353798084, 'step': 7299000}
INFO:transformers.trainer:{'loss': 3.0349502425193786, 'learning_rate': 2.808844684955722e-05, 'epoch': 1.314693189026567, 'step': 7299500}
INFO:transformers.trainer:{'loss': 2.997392705440521, 'learning_rate': 2.8086945955444576e-05, 'epoch': 1.3147832426733252, 'step': 7300000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7300000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7300000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7300000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7200000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 2.9629752180576325, 'learning_rate': 2.8085445061331938e-05, 'epoch': 1.3148732963200838, 'step': 7300500}
INFO:transformers.trainer:{'loss': 3.118479721784592, 'learning_rate': 2.8083944167219294e-05, 'epoch': 1.3149633499668423, 'step': 7301000}
INFO:transformers.trainer:{'loss': 3.0350920617580415, 'learning_rate': 2.8082443273106656e-05, 'epoch': 1.3150534036136006, 'step': 7301500}
INFO:transformers.trainer:{'loss': 2.981378296613693, 'learning_rate': 2.8080942378994012e-05, 'epoch': 1.315143457260359, 'step': 7302000}
INFO:transformers.trainer:{'loss': 3.098044930577278, 'learning_rate': 2.8079441484881374e-05, 'epoch': 1.3152335109071176, 'step': 7302500}
INFO:transformers.trainer:{'loss': 2.9928191022872923, 'learning_rate': 2.8077940590768737e-05, 'epoch': 1.3153235645538761, 'step': 7303000}
INFO:transformers.trainer:{'loss': 2.9975255842208863, 'learning_rate': 2.8076439696656092e-05, 'epoch': 1.3154136182006344, 'step': 7303500}
INFO:transformers.trainer:{'loss': 3.060476210594177, 'learning_rate': 2.8074938802543455e-05, 'epoch': 1.315503671847393, 'step': 7304000}
INFO:transformers.trainer:{'loss': 2.979746205806732, 'learning_rate': 2.807343790843081e-05, 'epoch': 1.3155937254941514, 'step': 7304500}
INFO:transformers.trainer:{'loss': 3.0120747203826905, 'learning_rate': 2.8071937014318173e-05, 'epoch': 1.31568377914091, 'step': 7305000}
INFO:transformers.trainer:{'loss': 3.032013901591301, 'learning_rate': 2.807043612020553e-05, 'epoch': 1.3157738327876682, 'step': 7305500}
INFO:transformers.trainer:{'loss': 3.0569246475696565, 'learning_rate': 2.806893522609289e-05, 'epoch': 1.3158638864344268, 'step': 7306000}
INFO:transformers.trainer:{'loss': 3.071638209462166, 'learning_rate': 2.8067434331980247e-05, 'epoch': 1.3159539400811853, 'step': 7306500}
INFO:transformers.trainer:{'loss': 3.011086644768715, 'learning_rate': 2.806593343786761e-05, 'epoch': 1.3160439937279436, 'step': 7307000}
INFO:transformers.trainer:{'loss': 3.053572627425194, 'learning_rate': 2.8064432543754965e-05, 'epoch': 1.316134047374702, 'step': 7307500}
INFO:transformers.trainer:{'loss': 3.032018929004669, 'learning_rate': 2.8062931649642327e-05, 'epoch': 1.3162241010214606, 'step': 7308000}
INFO:transformers.trainer:{'loss': 3.067777407407761, 'learning_rate': 2.8061430755529683e-05, 'epoch': 1.3163141546682189, 'step': 7308500}
INFO:transformers.trainer:{'loss': 2.9723925713300705, 'learning_rate': 2.8059929861417045e-05, 'epoch': 1.3164042083149774, 'step': 7309000}
INFO:transformers.trainer:{'loss': 2.9713141450881957, 'learning_rate': 2.8058428967304408e-05, 'epoch': 1.316494261961736, 'step': 7309500}
INFO:transformers.trainer:{'loss': 3.023029385447502, 'learning_rate': 2.8056928073191764e-05, 'epoch': 1.3165843156084942, 'step': 7310000}
INFO:transformers.trainer:{'loss': 3.10925770175457, 'learning_rate': 2.8055427179079126e-05, 'epoch': 1.3166743692552527, 'step': 7310500}
INFO:transformers.trainer:{'loss': 3.06324590921402, 'learning_rate': 2.805392628496648e-05, 'epoch': 1.3167644229020112, 'step': 7311000}
INFO:transformers.trainer:{'loss': 3.010624440193176, 'learning_rate': 2.8052425390853844e-05, 'epoch': 1.3168544765487695, 'step': 7311500}
INFO:transformers.trainer:{'loss': 3.0851089119911195, 'learning_rate': 2.80509244967412e-05, 'epoch': 1.316944530195528, 'step': 7312000}
INFO:transformers.trainer:{'loss': 3.0197873018980026, 'learning_rate': 2.8049423602628562e-05, 'epoch': 1.3170345838422866, 'step': 7312500}
INFO:transformers.trainer:{'loss': 3.059551048517227, 'learning_rate': 2.8047922708515918e-05, 'epoch': 1.3171246374890448, 'step': 7313000}
INFO:transformers.trainer:{'loss': 3.0850555789470673, 'learning_rate': 2.804642181440328e-05, 'epoch': 1.3172146911358034, 'step': 7313500}
INFO:transformers.trainer:{'loss': 3.047628719806671, 'learning_rate': 2.8044920920290636e-05, 'epoch': 1.3173047447825619, 'step': 7314000}
INFO:transformers.trainer:{'loss': 3.0627566219568254, 'learning_rate': 2.8043420026178e-05, 'epoch': 1.3173947984293204, 'step': 7314500}
INFO:transformers.trainer:{'loss': 3.058017748594284, 'learning_rate': 2.8041919132065354e-05, 'epoch': 1.3174848520760787, 'step': 7315000}
INFO:transformers.trainer:{'loss': 2.995132859945297, 'learning_rate': 2.8040418237952713e-05, 'epoch': 1.3175749057228372, 'step': 7315500}
INFO:transformers.trainer:{'loss': 3.022931444168091, 'learning_rate': 2.8038917343840076e-05, 'epoch': 1.3176649593695957, 'step': 7316000}
INFO:transformers.trainer:{'loss': 3.070628200292587, 'learning_rate': 2.803741644972743e-05, 'epoch': 1.3177550130163542, 'step': 7316500}
INFO:transformers.trainer:{'loss': 2.986438658952713, 'learning_rate': 2.8035915555614794e-05, 'epoch': 1.3178450666631125, 'step': 7317000}
INFO:transformers.trainer:{'loss': 2.981668760061264, 'learning_rate': 2.803441466150215e-05, 'epoch': 1.317935120309871, 'step': 7317500}
INFO:transformers.trainer:{'loss': 3.03007481276989, 'learning_rate': 2.8032913767389512e-05, 'epoch': 1.3180251739566295, 'step': 7318000}
INFO:transformers.trainer:{'loss': 3.039357050418854, 'learning_rate': 2.8031412873276867e-05, 'epoch': 1.3181152276033878, 'step': 7318500}
INFO:transformers.trainer:{'loss': 2.972515352487564, 'learning_rate': 2.802991197916423e-05, 'epoch': 1.3182052812501464, 'step': 7319000}
INFO:transformers.trainer:{'loss': 2.9887906699180604, 'learning_rate': 2.8028411085051585e-05, 'epoch': 1.3182953348969049, 'step': 7319500}
INFO:transformers.trainer:{'loss': 2.9818280076980592, 'learning_rate': 2.8026910190938948e-05, 'epoch': 1.3183853885436632, 'step': 7320000}
INFO:transformers.trainer:{'loss': 3.02440219604969, 'learning_rate': 2.8025409296826304e-05, 'epoch': 1.3184754421904217, 'step': 7320500}
INFO:transformers.trainer:{'loss': 3.0268346388339995, 'learning_rate': 2.8023908402713666e-05, 'epoch': 1.3185654958371802, 'step': 7321000}
INFO:transformers.trainer:{'loss': 3.0135150748491286, 'learning_rate': 2.802240750860102e-05, 'epoch': 1.3186555494839385, 'step': 7321500}
INFO:transformers.trainer:{'loss': 3.0220061756372454, 'learning_rate': 2.8020906614488384e-05, 'epoch': 1.318745603130697, 'step': 7322000}
INFO:transformers.trainer:{'loss': 3.0091343697309494, 'learning_rate': 2.801940572037574e-05, 'epoch': 1.3188356567774555, 'step': 7322500}
INFO:transformers.trainer:{'loss': 2.9912741668224334, 'learning_rate': 2.8017904826263102e-05, 'epoch': 1.3189257104242138, 'step': 7323000}
INFO:transformers.trainer:{'loss': 3.025729853987694, 'learning_rate': 2.8016403932150465e-05, 'epoch': 1.3190157640709723, 'step': 7323500}
INFO:transformers.trainer:{'loss': 3.0342274475097657, 'learning_rate': 2.801490303803782e-05, 'epoch': 1.3191058177177308, 'step': 7324000}
INFO:transformers.trainer:{'loss': 2.973030026078224, 'learning_rate': 2.8013402143925183e-05, 'epoch': 1.3191958713644891, 'step': 7324500}
INFO:transformers.trainer:{'loss': 3.022482845902443, 'learning_rate': 2.801190124981254e-05, 'epoch': 1.3192859250112476, 'step': 7325000}
INFO:transformers.trainer:{'loss': 3.045213442325592, 'learning_rate': 2.80104003556999e-05, 'epoch': 1.3193759786580062, 'step': 7325500}
INFO:transformers.trainer:{'loss': 3.0102884838581083, 'learning_rate': 2.8008899461587257e-05, 'epoch': 1.3194660323047647, 'step': 7326000}
INFO:transformers.trainer:{'loss': 3.029564564704895, 'learning_rate': 2.800739856747462e-05, 'epoch': 1.319556085951523, 'step': 7326500}
INFO:transformers.trainer:{'loss': 3.0089507497549057, 'learning_rate': 2.8005897673361975e-05, 'epoch': 1.3196461395982815, 'step': 7327000}
INFO:transformers.trainer:{'loss': 3.0085148188471793, 'learning_rate': 2.8004396779249337e-05, 'epoch': 1.31973619324504, 'step': 7327500}
INFO:transformers.trainer:{'loss': 3.004235421657562, 'learning_rate': 2.8002895885136693e-05, 'epoch': 1.3198262468917985, 'step': 7328000}
INFO:transformers.trainer:{'loss': 3.047505553007126, 'learning_rate': 2.8001394991024055e-05, 'epoch': 1.3199163005385568, 'step': 7328500}
INFO:transformers.trainer:{'loss': 3.041467118024826, 'learning_rate': 2.799989409691141e-05, 'epoch': 1.3200063541853153, 'step': 7329000}
INFO:transformers.trainer:{'loss': 3.0155656118392944, 'learning_rate': 2.7998393202798773e-05, 'epoch': 1.3200964078320738, 'step': 7329500}
INFO:transformers.trainer:{'loss': 3.0581247942447662, 'learning_rate': 2.7996892308686136e-05, 'epoch': 1.3201864614788321, 'step': 7330000}
INFO:transformers.trainer:{'loss': 3.0191588413715365, 'learning_rate': 2.799539141457349e-05, 'epoch': 1.3202765151255906, 'step': 7330500}
INFO:transformers.trainer:{'loss': 3.0301974964141847, 'learning_rate': 2.7993890520460854e-05, 'epoch': 1.3203665687723491, 'step': 7331000}
INFO:transformers.trainer:{'loss': 2.9589122650623323, 'learning_rate': 2.799238962634821e-05, 'epoch': 1.3204566224191074, 'step': 7331500}
INFO:transformers.trainer:{'loss': 3.007785086989403, 'learning_rate': 2.7990888732235572e-05, 'epoch': 1.320546676065866, 'step': 7332000}
INFO:transformers.trainer:{'loss': 3.148787990808487, 'learning_rate': 2.7989387838122928e-05, 'epoch': 1.3206367297126245, 'step': 7332500}
INFO:transformers.trainer:{'loss': 3.027462466239929, 'learning_rate': 2.798788694401029e-05, 'epoch': 1.3207267833593828, 'step': 7333000}
INFO:transformers.trainer:{'loss': 3.1140134012699128, 'learning_rate': 2.7986386049897646e-05, 'epoch': 1.3208168370061413, 'step': 7333500}
INFO:transformers.trainer:{'loss': 3.073191444039345, 'learning_rate': 2.7984885155785008e-05, 'epoch': 1.3209068906528998, 'step': 7334000}
INFO:transformers.trainer:{'loss': 3.0106711024045945, 'learning_rate': 2.7983384261672364e-05, 'epoch': 1.320996944299658, 'step': 7334500}
INFO:transformers.trainer:{'loss': 3.049118701338768, 'learning_rate': 2.7981883367559726e-05, 'epoch': 1.3210869979464166, 'step': 7335000}
INFO:transformers.trainer:{'loss': 3.0203231961727144, 'learning_rate': 2.7980382473447082e-05, 'epoch': 1.3211770515931751, 'step': 7335500}
INFO:transformers.trainer:{'loss': 2.99298265004158, 'learning_rate': 2.7978881579334444e-05, 'epoch': 1.3212671052399334, 'step': 7336000}
INFO:transformers.trainer:{'loss': 3.047183015704155, 'learning_rate': 2.79773806852218e-05, 'epoch': 1.321357158886692, 'step': 7336500}
INFO:transformers.trainer:{'loss': 3.0135642156600952, 'learning_rate': 2.7975879791109162e-05, 'epoch': 1.3214472125334504, 'step': 7337000}
INFO:transformers.trainer:{'loss': 3.023283392429352, 'learning_rate': 2.797437889699652e-05, 'epoch': 1.321537266180209, 'step': 7337500}
INFO:transformers.trainer:{'loss': 3.0710121564865114, 'learning_rate': 2.797287800288388e-05, 'epoch': 1.3216273198269672, 'step': 7338000}
INFO:transformers.trainer:{'loss': 3.048305223226547, 'learning_rate': 2.797137710877124e-05, 'epoch': 1.3217173734737258, 'step': 7338500}
INFO:transformers.trainer:{'loss': 3.0554074578285215, 'learning_rate': 2.7969876214658595e-05, 'epoch': 1.3218074271204843, 'step': 7339000}
INFO:transformers.trainer:{'loss': 3.1132343566417693, 'learning_rate': 2.7968375320545958e-05, 'epoch': 1.3218974807672428, 'step': 7339500}
INFO:transformers.trainer:{'loss': 3.075286728620529, 'learning_rate': 2.7966874426433313e-05, 'epoch': 1.321987534414001, 'step': 7340000}
INFO:transformers.trainer:{'loss': 3.126496873855591, 'learning_rate': 2.7965373532320676e-05, 'epoch': 1.3220775880607596, 'step': 7340500}
INFO:transformers.trainer:{'loss': 3.0878219735622405, 'learning_rate': 2.796387263820803e-05, 'epoch': 1.322167641707518, 'step': 7341000}
INFO:transformers.trainer:{'loss': 3.039121203660965, 'learning_rate': 2.7962371744095394e-05, 'epoch': 1.3222576953542764, 'step': 7341500}
INFO:transformers.trainer:{'loss': 3.0101817890405655, 'learning_rate': 2.796087084998275e-05, 'epoch': 1.322347749001035, 'step': 7342000}
INFO:transformers.trainer:{'loss': 3.026360760331154, 'learning_rate': 2.7959369955870112e-05, 'epoch': 1.3224378026477934, 'step': 7342500}
INFO:transformers.trainer:{'loss': 2.995856749534607, 'learning_rate': 2.7957869061757468e-05, 'epoch': 1.3225278562945517, 'step': 7343000}
INFO:transformers.trainer:{'loss': 3.009847768545151, 'learning_rate': 2.795636816764483e-05, 'epoch': 1.3226179099413102, 'step': 7343500}
INFO:transformers.trainer:{'loss': 3.044994862794876, 'learning_rate': 2.7954867273532192e-05, 'epoch': 1.3227079635880687, 'step': 7344000}
INFO:transformers.trainer:{'loss': 2.9792228803634644, 'learning_rate': 2.7953366379419548e-05, 'epoch': 1.322798017234827, 'step': 7344500}
INFO:transformers.trainer:{'loss': 3.077214615702629, 'learning_rate': 2.795186548530691e-05, 'epoch': 1.3228880708815856, 'step': 7345000}
INFO:transformers.trainer:{'loss': 2.986331228971481, 'learning_rate': 2.7950364591194266e-05, 'epoch': 1.322978124528344, 'step': 7345500}
INFO:transformers.trainer:{'loss': 3.0236809804439546, 'learning_rate': 2.794886369708163e-05, 'epoch': 1.3230681781751024, 'step': 7346000}
INFO:transformers.trainer:{'loss': 3.0706140224933622, 'learning_rate': 2.7947362802968984e-05, 'epoch': 1.3231582318218609, 'step': 7346500}
INFO:transformers.trainer:{'loss': 3.01403568649292, 'learning_rate': 2.7945861908856347e-05, 'epoch': 1.3232482854686194, 'step': 7347000}
INFO:transformers.trainer:{'loss': 2.9963942539691923, 'learning_rate': 2.7944361014743702e-05, 'epoch': 1.3233383391153777, 'step': 7347500}
INFO:transformers.trainer:{'loss': 2.9705590674877165, 'learning_rate': 2.7942860120631065e-05, 'epoch': 1.3234283927621362, 'step': 7348000}
INFO:transformers.trainer:{'loss': 2.992821567952633, 'learning_rate': 2.794135922651842e-05, 'epoch': 1.3235184464088947, 'step': 7348500}
INFO:transformers.trainer:{'loss': 3.0372869275808334, 'learning_rate': 2.7939858332405783e-05, 'epoch': 1.3236085000556532, 'step': 7349000}
INFO:transformers.trainer:{'loss': 3.016866843342781, 'learning_rate': 2.793835743829314e-05, 'epoch': 1.3236985537024115, 'step': 7349500}
INFO:transformers.trainer:{'loss': 2.961754314661026, 'learning_rate': 2.79368565441805e-05, 'epoch': 1.32378860734917, 'step': 7350000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7350000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7350000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7350000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7250000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0520210881233214, 'learning_rate': 2.7935355650067857e-05, 'epoch': 1.3238786609959285, 'step': 7350500}
INFO:transformers.trainer:{'loss': 3.055039796590805, 'learning_rate': 2.793385475595522e-05, 'epoch': 1.323968714642687, 'step': 7351000}
INFO:transformers.trainer:{'loss': 3.0241121821403505, 'learning_rate': 2.793235386184258e-05, 'epoch': 1.3240587682894454, 'step': 7351500}
INFO:transformers.trainer:{'loss': 3.0799721661806108, 'learning_rate': 2.7930852967729937e-05, 'epoch': 1.3241488219362039, 'step': 7352000}
INFO:transformers.trainer:{'loss': 3.0521186443567276, 'learning_rate': 2.79293520736173e-05, 'epoch': 1.3242388755829624, 'step': 7352500}
INFO:transformers.trainer:{'loss': 3.017965737938881, 'learning_rate': 2.7927851179504655e-05, 'epoch': 1.3243289292297207, 'step': 7353000}
INFO:transformers.trainer:{'loss': 3.0073613276481628, 'learning_rate': 2.7926350285392018e-05, 'epoch': 1.3244189828764792, 'step': 7353500}
INFO:transformers.trainer:{'loss': 3.043619076013565, 'learning_rate': 2.7924849391279373e-05, 'epoch': 1.3245090365232377, 'step': 7354000}
INFO:transformers.trainer:{'loss': 3.0060302357673647, 'learning_rate': 2.7923348497166736e-05, 'epoch': 1.324599090169996, 'step': 7354500}
INFO:transformers.trainer:{'loss': 2.996561245203018, 'learning_rate': 2.792184760305409e-05, 'epoch': 1.3246891438167545, 'step': 7355000}
INFO:transformers.trainer:{'loss': 3.0559284143447876, 'learning_rate': 2.7920346708941454e-05, 'epoch': 1.324779197463513, 'step': 7355500}
INFO:transformers.trainer:{'loss': 3.076710563659668, 'learning_rate': 2.791884581482881e-05, 'epoch': 1.3248692511102713, 'step': 7356000}
INFO:transformers.trainer:{'loss': 3.054595999479294, 'learning_rate': 2.7917344920716172e-05, 'epoch': 1.3249593047570298, 'step': 7356500}
INFO:transformers.trainer:{'loss': 3.013209393143654, 'learning_rate': 2.7915844026603528e-05, 'epoch': 1.3250493584037883, 'step': 7357000}
INFO:transformers.trainer:{'loss': 3.0408726110458373, 'learning_rate': 2.791434313249089e-05, 'epoch': 1.3251394120505466, 'step': 7357500}
INFO:transformers.trainer:{'loss': 3.0392641701698304, 'learning_rate': 2.791284223837825e-05, 'epoch': 1.3252294656973052, 'step': 7358000}
INFO:transformers.trainer:{'loss': 3.058341267108917, 'learning_rate': 2.791134134426561e-05, 'epoch': 1.3253195193440637, 'step': 7358500}
INFO:transformers.trainer:{'loss': 3.0474819095134733, 'learning_rate': 2.7909840450152967e-05, 'epoch': 1.325409572990822, 'step': 7359000}
INFO:transformers.trainer:{'loss': 2.9840143105983734, 'learning_rate': 2.7908339556040326e-05, 'epoch': 1.3254996266375805, 'step': 7359500}
INFO:transformers.trainer:{'loss': 3.056936709403992, 'learning_rate': 2.7906838661927685e-05, 'epoch': 1.325589680284339, 'step': 7360000}
INFO:transformers.trainer:{'loss': 2.980730292081833, 'learning_rate': 2.7905337767815045e-05, 'epoch': 1.3256797339310975, 'step': 7360500}
INFO:transformers.trainer:{'loss': 3.004168585896492, 'learning_rate': 2.7903836873702404e-05, 'epoch': 1.325769787577856, 'step': 7361000}
INFO:transformers.trainer:{'loss': 3.070259074449539, 'learning_rate': 2.7902335979589763e-05, 'epoch': 1.3258598412246143, 'step': 7361500}
INFO:transformers.trainer:{'loss': 2.9946218328475953, 'learning_rate': 2.790083508547712e-05, 'epoch': 1.3259498948713728, 'step': 7362000}
INFO:transformers.trainer:{'loss': 3.0738864986896517, 'learning_rate': 2.7899334191364477e-05, 'epoch': 1.3260399485181313, 'step': 7362500}
INFO:transformers.trainer:{'loss': 3.1016498920917512, 'learning_rate': 2.789783329725184e-05, 'epoch': 1.3261300021648896, 'step': 7363000}
INFO:transformers.trainer:{'loss': 3.030180176615715, 'learning_rate': 2.7896332403139195e-05, 'epoch': 1.3262200558116481, 'step': 7363500}
INFO:transformers.trainer:{'loss': 3.03999986410141, 'learning_rate': 2.7894831509026558e-05, 'epoch': 1.3263101094584067, 'step': 7364000}
INFO:transformers.trainer:{'loss': 3.074480664253235, 'learning_rate': 2.7893330614913914e-05, 'epoch': 1.326400163105165, 'step': 7364500}
INFO:transformers.trainer:{'loss': 3.0454337136745453, 'learning_rate': 2.7891829720801276e-05, 'epoch': 1.3264902167519235, 'step': 7365000}
INFO:transformers.trainer:{'loss': 3.0500381088256834, 'learning_rate': 2.789032882668864e-05, 'epoch': 1.326580270398682, 'step': 7365500}
INFO:transformers.trainer:{'loss': 3.0220607273578644, 'learning_rate': 2.7888827932575994e-05, 'epoch': 1.3266703240454403, 'step': 7366000}
INFO:transformers.trainer:{'loss': 3.0166483072042465, 'learning_rate': 2.7887327038463356e-05, 'epoch': 1.3267603776921988, 'step': 7366500}
INFO:transformers.trainer:{'loss': 3.0510070135593415, 'learning_rate': 2.7885826144350712e-05, 'epoch': 1.3268504313389573, 'step': 7367000}
INFO:transformers.trainer:{'loss': 3.0757681765556337, 'learning_rate': 2.7884325250238075e-05, 'epoch': 1.3269404849857156, 'step': 7367500}
INFO:transformers.trainer:{'loss': 3.0087598378658296, 'learning_rate': 2.788282435612543e-05, 'epoch': 1.327030538632474, 'step': 7368000}
INFO:transformers.trainer:{'loss': 2.97928590798378, 'learning_rate': 2.7881323462012793e-05, 'epoch': 1.3271205922792326, 'step': 7368500}
INFO:transformers.trainer:{'loss': 3.104965717315674, 'learning_rate': 2.787982256790015e-05, 'epoch': 1.327210645925991, 'step': 7369000}
INFO:transformers.trainer:{'loss': 3.035316078066826, 'learning_rate': 2.787832167378751e-05, 'epoch': 1.3273006995727494, 'step': 7369500}
INFO:transformers.trainer:{'loss': 3.051701922297478, 'learning_rate': 2.7876820779674866e-05, 'epoch': 1.327390753219508, 'step': 7370000}
INFO:transformers.trainer:{'loss': 3.0458813190460203, 'learning_rate': 2.787531988556223e-05, 'epoch': 1.3274808068662662, 'step': 7370500}
INFO:transformers.trainer:{'loss': 3.0821476283073426, 'learning_rate': 2.7873818991449585e-05, 'epoch': 1.3275708605130248, 'step': 7371000}
INFO:transformers.trainer:{'loss': 3.0492761073112487, 'learning_rate': 2.7872318097336947e-05, 'epoch': 1.3276609141597833, 'step': 7371500}
INFO:transformers.trainer:{'loss': 3.0135112655162812, 'learning_rate': 2.787081720322431e-05, 'epoch': 1.3277509678065418, 'step': 7372000}
INFO:transformers.trainer:{'loss': 3.0370091733932494, 'learning_rate': 2.7869316309111665e-05, 'epoch': 1.3278410214533003, 'step': 7372500}
INFO:transformers.trainer:{'loss': 3.0235632438659668, 'learning_rate': 2.7867815414999028e-05, 'epoch': 1.3279310751000586, 'step': 7373000}
INFO:transformers.trainer:{'loss': 3.00856223487854, 'learning_rate': 2.7866314520886383e-05, 'epoch': 1.328021128746817, 'step': 7373500}
INFO:transformers.trainer:{'loss': 3.067419999718666, 'learning_rate': 2.7864813626773746e-05, 'epoch': 1.3281111823935756, 'step': 7374000}
INFO:transformers.trainer:{'loss': 3.036646961927414, 'learning_rate': 2.78633127326611e-05, 'epoch': 1.328201236040334, 'step': 7374500}
INFO:transformers.trainer:{'loss': 2.976413750886917, 'learning_rate': 2.7861811838548464e-05, 'epoch': 1.3282912896870924, 'step': 7375000}
INFO:transformers.trainer:{'loss': 3.006680738449097, 'learning_rate': 2.786031094443582e-05, 'epoch': 1.328381343333851, 'step': 7375500}
INFO:transformers.trainer:{'loss': 2.987839607834816, 'learning_rate': 2.7858810050323182e-05, 'epoch': 1.3284713969806092, 'step': 7376000}
INFO:transformers.trainer:{'loss': 3.0693235899209976, 'learning_rate': 2.7857309156210538e-05, 'epoch': 1.3285614506273677, 'step': 7376500}
INFO:transformers.trainer:{'loss': 2.972278191447258, 'learning_rate': 2.78558082620979e-05, 'epoch': 1.3286515042741263, 'step': 7377000}
INFO:transformers.trainer:{'loss': 2.998993330001831, 'learning_rate': 2.7854307367985256e-05, 'epoch': 1.3287415579208846, 'step': 7377500}
INFO:transformers.trainer:{'loss': 3.012423292160034, 'learning_rate': 2.7852806473872618e-05, 'epoch': 1.328831611567643, 'step': 7378000}
INFO:transformers.trainer:{'loss': 2.9926606434583665, 'learning_rate': 2.7851305579759977e-05, 'epoch': 1.3289216652144016, 'step': 7378500}
INFO:transformers.trainer:{'loss': 3.0755910102128983, 'learning_rate': 2.7849804685647336e-05, 'epoch': 1.3290117188611599, 'step': 7379000}
INFO:transformers.trainer:{'loss': 3.0595226080417635, 'learning_rate': 2.7848303791534695e-05, 'epoch': 1.3291017725079184, 'step': 7379500}
INFO:transformers.trainer:{'loss': 3.0431424185037614, 'learning_rate': 2.7846802897422054e-05, 'epoch': 1.329191826154677, 'step': 7380000}
INFO:transformers.trainer:{'loss': 3.0177278527021407, 'learning_rate': 2.7845302003309413e-05, 'epoch': 1.3292818798014352, 'step': 7380500}
INFO:transformers.trainer:{'loss': 2.9831631493568422, 'learning_rate': 2.7843801109196772e-05, 'epoch': 1.3293719334481937, 'step': 7381000}
INFO:transformers.trainer:{'loss': 3.0527366492748262, 'learning_rate': 2.784230021508413e-05, 'epoch': 1.3294619870949522, 'step': 7381500}
INFO:transformers.trainer:{'loss': 3.0533925292491912, 'learning_rate': 2.784079932097149e-05, 'epoch': 1.3295520407417105, 'step': 7382000}
INFO:transformers.trainer:{'loss': 3.035360431432724, 'learning_rate': 2.783929842685885e-05, 'epoch': 1.329642094388469, 'step': 7382500}
INFO:transformers.trainer:{'loss': 3.073205483317375, 'learning_rate': 2.783779753274621e-05, 'epoch': 1.3297321480352275, 'step': 7383000}
INFO:transformers.trainer:{'loss': 2.991317270278931, 'learning_rate': 2.7836296638633568e-05, 'epoch': 1.329822201681986, 'step': 7383500}
INFO:transformers.trainer:{'loss': 3.019290183067322, 'learning_rate': 2.7834795744520927e-05, 'epoch': 1.3299122553287446, 'step': 7384000}
INFO:transformers.trainer:{'loss': 2.9689743044376375, 'learning_rate': 2.7833294850408286e-05, 'epoch': 1.3300023089755029, 'step': 7384500}
INFO:transformers.trainer:{'loss': 3.0509317384958266, 'learning_rate': 2.7831793956295645e-05, 'epoch': 1.3300923626222614, 'step': 7385000}
INFO:transformers.trainer:{'loss': 2.979497816085815, 'learning_rate': 2.7830293062183004e-05, 'epoch': 1.33018241626902, 'step': 7385500}
INFO:transformers.trainer:{'loss': 2.997367170572281, 'learning_rate': 2.7828792168070366e-05, 'epoch': 1.3302724699157782, 'step': 7386000}
INFO:transformers.trainer:{'loss': 3.0589164851903914, 'learning_rate': 2.7827291273957722e-05, 'epoch': 1.3303625235625367, 'step': 7386500}
INFO:transformers.trainer:{'loss': 2.98210201382637, 'learning_rate': 2.7825790379845084e-05, 'epoch': 1.3304525772092952, 'step': 7387000}
INFO:transformers.trainer:{'loss': 2.9763883049488067, 'learning_rate': 2.782428948573244e-05, 'epoch': 1.3305426308560535, 'step': 7387500}
INFO:transformers.trainer:{'loss': 2.9973326828479765, 'learning_rate': 2.7822788591619802e-05, 'epoch': 1.330632684502812, 'step': 7388000}
INFO:transformers.trainer:{'loss': 2.975166966915131, 'learning_rate': 2.7821287697507158e-05, 'epoch': 1.3307227381495705, 'step': 7388500}
INFO:transformers.trainer:{'loss': 2.999041098117828, 'learning_rate': 2.781978680339452e-05, 'epoch': 1.3308127917963288, 'step': 7389000}
INFO:transformers.trainer:{'loss': 3.0175186586380005, 'learning_rate': 2.7818285909281876e-05, 'epoch': 1.3309028454430873, 'step': 7389500}
INFO:transformers.trainer:{'loss': 3.0250654871463776, 'learning_rate': 2.781678501516924e-05, 'epoch': 1.3309928990898459, 'step': 7390000}
INFO:transformers.trainer:{'loss': 2.968159519672394, 'learning_rate': 2.7815284121056594e-05, 'epoch': 1.3310829527366042, 'step': 7390500}
INFO:transformers.trainer:{'loss': 3.0503691880702974, 'learning_rate': 2.7813783226943957e-05, 'epoch': 1.3311730063833627, 'step': 7391000}
INFO:transformers.trainer:{'loss': 2.9820362515449523, 'learning_rate': 2.7812282332831312e-05, 'epoch': 1.3312630600301212, 'step': 7391500}
INFO:transformers.trainer:{'loss': 3.034643690109253, 'learning_rate': 2.7810781438718675e-05, 'epoch': 1.3313531136768795, 'step': 7392000}
INFO:transformers.trainer:{'loss': 3.056749252319336, 'learning_rate': 2.7809280544606037e-05, 'epoch': 1.331443167323638, 'step': 7392500}
INFO:transformers.trainer:{'loss': 2.9766119635105133, 'learning_rate': 2.7807779650493393e-05, 'epoch': 1.3315332209703965, 'step': 7393000}
INFO:transformers.trainer:{'loss': 3.0568197166919706, 'learning_rate': 2.7806278756380755e-05, 'epoch': 1.3316232746171548, 'step': 7393500}
INFO:transformers.trainer:{'loss': 3.0541092183589935, 'learning_rate': 2.780477786226811e-05, 'epoch': 1.3317133282639133, 'step': 7394000}
INFO:transformers.trainer:{'loss': 2.9669656205177306, 'learning_rate': 2.7803276968155473e-05, 'epoch': 1.3318033819106718, 'step': 7394500}
INFO:transformers.trainer:{'loss': 3.0500546532869337, 'learning_rate': 2.780177607404283e-05, 'epoch': 1.3318934355574303, 'step': 7395000}
INFO:transformers.trainer:{'loss': 3.0347924566268922, 'learning_rate': 2.780027517993019e-05, 'epoch': 1.3319834892041889, 'step': 7395500}
INFO:transformers.trainer:{'loss': 3.0246307282447815, 'learning_rate': 2.7798774285817547e-05, 'epoch': 1.3320735428509471, 'step': 7396000}
INFO:transformers.trainer:{'loss': 3.0507446331977843, 'learning_rate': 2.779727339170491e-05, 'epoch': 1.3321635964977057, 'step': 7396500}
INFO:transformers.trainer:{'loss': 3.041363387584686, 'learning_rate': 2.7795772497592265e-05, 'epoch': 1.3322536501444642, 'step': 7397000}
INFO:transformers.trainer:{'loss': 3.034617220878601, 'learning_rate': 2.7794271603479628e-05, 'epoch': 1.3323437037912225, 'step': 7397500}
INFO:transformers.trainer:{'loss': 3.049285423398018, 'learning_rate': 2.7792770709366983e-05, 'epoch': 1.332433757437981, 'step': 7398000}
INFO:transformers.trainer:{'loss': 3.068051337122917, 'learning_rate': 2.7791269815254346e-05, 'epoch': 1.3325238110847395, 'step': 7398500}
INFO:transformers.trainer:{'loss': 3.0468081011772155, 'learning_rate': 2.77897689211417e-05, 'epoch': 1.3326138647314978, 'step': 7399000}
INFO:transformers.trainer:{'loss': 2.9376647424697877, 'learning_rate': 2.7788268027029064e-05, 'epoch': 1.3327039183782563, 'step': 7399500}
INFO:transformers.trainer:{'loss': 3.0158735041618345, 'learning_rate': 2.7786767132916426e-05, 'epoch': 1.3327939720250148, 'step': 7400000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7400000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7400000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7400000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7300000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.006020788192749, 'learning_rate': 2.7785266238803782e-05, 'epoch': 1.332884025671773, 'step': 7400500}
INFO:transformers.trainer:{'loss': 2.9938846093416216, 'learning_rate': 2.778376534469114e-05, 'epoch': 1.3329740793185316, 'step': 7401000}
INFO:transformers.trainer:{'loss': 3.0622082594633104, 'learning_rate': 2.77822644505785e-05, 'epoch': 1.3330641329652901, 'step': 7401500}
INFO:transformers.trainer:{'loss': 3.0747255635261537, 'learning_rate': 2.778076355646586e-05, 'epoch': 1.3331541866120484, 'step': 7402000}
INFO:transformers.trainer:{'loss': 3.000087943315506, 'learning_rate': 2.7779262662353218e-05, 'epoch': 1.333244240258807, 'step': 7402500}
INFO:transformers.trainer:{'loss': 3.0185491769313813, 'learning_rate': 2.7777761768240577e-05, 'epoch': 1.3333342939055655, 'step': 7403000}
INFO:transformers.trainer:{'loss': 3.0544227199554443, 'learning_rate': 2.7776260874127936e-05, 'epoch': 1.3334243475523238, 'step': 7403500}
INFO:transformers.trainer:{'loss': 3.079295488357544, 'learning_rate': 2.7774759980015295e-05, 'epoch': 1.3335144011990823, 'step': 7404000}
INFO:transformers.trainer:{'loss': 3.0551175322532655, 'learning_rate': 2.7773259085902654e-05, 'epoch': 1.3336044548458408, 'step': 7404500}
INFO:transformers.trainer:{'loss': 2.9913996424674987, 'learning_rate': 2.7771758191790014e-05, 'epoch': 1.333694508492599, 'step': 7405000}
INFO:transformers.trainer:{'loss': 3.050813837170601, 'learning_rate': 2.7770257297677373e-05, 'epoch': 1.3337845621393576, 'step': 7405500}
INFO:transformers.trainer:{'loss': 3.068750425577164, 'learning_rate': 2.776875640356473e-05, 'epoch': 1.333874615786116, 'step': 7406000}
INFO:transformers.trainer:{'loss': 3.057838258743286, 'learning_rate': 2.7767255509452094e-05, 'epoch': 1.3339646694328746, 'step': 7406500}
INFO:transformers.trainer:{'loss': 3.0342350442409516, 'learning_rate': 2.776575461533945e-05, 'epoch': 1.3340547230796331, 'step': 7407000}
INFO:transformers.trainer:{'loss': 3.035483460187912, 'learning_rate': 2.7764253721226812e-05, 'epoch': 1.3341447767263914, 'step': 7407500}
INFO:transformers.trainer:{'loss': 3.062183024287224, 'learning_rate': 2.7762752827114168e-05, 'epoch': 1.33423483037315, 'step': 7408000}
INFO:transformers.trainer:{'loss': 3.021153042554855, 'learning_rate': 2.776125193300153e-05, 'epoch': 1.3343248840199085, 'step': 7408500}
INFO:transformers.trainer:{'loss': 2.9786195073127746, 'learning_rate': 2.7759751038888886e-05, 'epoch': 1.3344149376666667, 'step': 7409000}
INFO:transformers.trainer:{'loss': 3.04901283621788, 'learning_rate': 2.775825014477625e-05, 'epoch': 1.3345049913134253, 'step': 7409500}
INFO:transformers.trainer:{'loss': 2.9906375645399095, 'learning_rate': 2.7756749250663604e-05, 'epoch': 1.3345950449601838, 'step': 7410000}
INFO:transformers.trainer:{'loss': 3.080488938808441, 'learning_rate': 2.7755248356550966e-05, 'epoch': 1.334685098606942, 'step': 7410500}
INFO:transformers.trainer:{'loss': 3.0313549536466597, 'learning_rate': 2.7753747462438322e-05, 'epoch': 1.3347751522537006, 'step': 7411000}
INFO:transformers.trainer:{'loss': 3.0569485142230985, 'learning_rate': 2.7752246568325685e-05, 'epoch': 1.334865205900459, 'step': 7411500}
INFO:transformers.trainer:{'loss': 2.9977939836978913, 'learning_rate': 2.775074567421304e-05, 'epoch': 1.3349552595472174, 'step': 7412000}
INFO:transformers.trainer:{'loss': 3.0176247572898864, 'learning_rate': 2.7749244780100403e-05, 'epoch': 1.335045313193976, 'step': 7412500}
INFO:transformers.trainer:{'loss': 2.986925904750824, 'learning_rate': 2.774774388598776e-05, 'epoch': 1.3351353668407344, 'step': 7413000}
INFO:transformers.trainer:{'loss': 3.0278858076334, 'learning_rate': 2.774624299187512e-05, 'epoch': 1.3352254204874927, 'step': 7413500}
INFO:transformers.trainer:{'loss': 3.0115844752788545, 'learning_rate': 2.7744742097762483e-05, 'epoch': 1.3353154741342512, 'step': 7414000}
INFO:transformers.trainer:{'loss': 3.02096982896328, 'learning_rate': 2.774324120364984e-05, 'epoch': 1.3354055277810097, 'step': 7414500}
INFO:transformers.trainer:{'loss': 3.049810134768486, 'learning_rate': 2.77417403095372e-05, 'epoch': 1.335495581427768, 'step': 7415000}
INFO:transformers.trainer:{'loss': 3.044672981142998, 'learning_rate': 2.7740239415424557e-05, 'epoch': 1.3355856350745265, 'step': 7415500}
INFO:transformers.trainer:{'loss': 3.0091500697135927, 'learning_rate': 2.773873852131192e-05, 'epoch': 1.335675688721285, 'step': 7416000}
INFO:transformers.trainer:{'loss': 3.0316744718551636, 'learning_rate': 2.7737237627199275e-05, 'epoch': 1.3357657423680436, 'step': 7416500}
INFO:transformers.trainer:{'loss': 3.0346733527183534, 'learning_rate': 2.7735736733086637e-05, 'epoch': 1.3358557960148019, 'step': 7417000}
INFO:transformers.trainer:{'loss': 3.049444105148315, 'learning_rate': 2.7734235838973993e-05, 'epoch': 1.3359458496615604, 'step': 7417500}
INFO:transformers.trainer:{'loss': 2.998874339580536, 'learning_rate': 2.7732734944861356e-05, 'epoch': 1.336035903308319, 'step': 7418000}
INFO:transformers.trainer:{'loss': 3.0371210293769835, 'learning_rate': 2.773123405074871e-05, 'epoch': 1.3361259569550774, 'step': 7418500}
INFO:transformers.trainer:{'loss': 3.027103391647339, 'learning_rate': 2.7729733156636074e-05, 'epoch': 1.3362160106018357, 'step': 7419000}
INFO:transformers.trainer:{'loss': 2.9953220946788788, 'learning_rate': 2.772823226252343e-05, 'epoch': 1.3363060642485942, 'step': 7419500}
INFO:transformers.trainer:{'loss': 2.999412144780159, 'learning_rate': 2.7726731368410792e-05, 'epoch': 1.3363961178953527, 'step': 7420000}
INFO:transformers.trainer:{'loss': 2.982444919705391, 'learning_rate': 2.7725230474298154e-05, 'epoch': 1.336486171542111, 'step': 7420500}
INFO:transformers.trainer:{'loss': 3.0488870049715042, 'learning_rate': 2.772372958018551e-05, 'epoch': 1.3365762251888695, 'step': 7421000}
INFO:transformers.trainer:{'loss': 3.01755376458168, 'learning_rate': 2.7722228686072872e-05, 'epoch': 1.336666278835628, 'step': 7421500}
INFO:transformers.trainer:{'loss': 3.0377840666770934, 'learning_rate': 2.7720727791960228e-05, 'epoch': 1.3367563324823863, 'step': 7422000}
INFO:transformers.trainer:{'loss': 3.018751986503601, 'learning_rate': 2.771922689784759e-05, 'epoch': 1.3368463861291449, 'step': 7422500}
INFO:transformers.trainer:{'loss': 3.030597777843475, 'learning_rate': 2.7717726003734946e-05, 'epoch': 1.3369364397759034, 'step': 7423000}
INFO:transformers.trainer:{'loss': 2.95477085518837, 'learning_rate': 2.771622510962231e-05, 'epoch': 1.3370264934226617, 'step': 7423500}
INFO:transformers.trainer:{'loss': 3.0045123208761213, 'learning_rate': 2.7714724215509664e-05, 'epoch': 1.3371165470694202, 'step': 7424000}
INFO:transformers.trainer:{'loss': 3.0429422370195387, 'learning_rate': 2.7713223321397023e-05, 'epoch': 1.3372066007161787, 'step': 7424500}
INFO:transformers.trainer:{'loss': 3.036646990299225, 'learning_rate': 2.7711722427284382e-05, 'epoch': 1.337296654362937, 'step': 7425000}
INFO:transformers.trainer:{'loss': 2.9961617341041564, 'learning_rate': 2.771022153317174e-05, 'epoch': 1.3373867080096955, 'step': 7425500}
INFO:transformers.trainer:{'loss': 3.0432829678058626, 'learning_rate': 2.77087206390591e-05, 'epoch': 1.337476761656454, 'step': 7426000}
INFO:transformers.trainer:{'loss': 3.04690322637558, 'learning_rate': 2.770721974494646e-05, 'epoch': 1.3375668153032123, 'step': 7426500}
INFO:transformers.trainer:{'loss': 3.00274427652359, 'learning_rate': 2.7705718850833822e-05, 'epoch': 1.3376568689499708, 'step': 7427000}
INFO:transformers.trainer:{'loss': 3.0701390676498415, 'learning_rate': 2.7704217956721178e-05, 'epoch': 1.3377469225967293, 'step': 7427500}
INFO:transformers.trainer:{'loss': 3.0210854268074034, 'learning_rate': 2.770271706260854e-05, 'epoch': 1.3378369762434879, 'step': 7428000}
INFO:transformers.trainer:{'loss': 3.0494258875846865, 'learning_rate': 2.7701216168495896e-05, 'epoch': 1.3379270298902461, 'step': 7428500}
INFO:transformers.trainer:{'loss': 3.0557204327583314, 'learning_rate': 2.7699715274383258e-05, 'epoch': 1.3380170835370047, 'step': 7429000}
INFO:transformers.trainer:{'loss': 3.053012677311897, 'learning_rate': 2.7698214380270614e-05, 'epoch': 1.3381071371837632, 'step': 7429500}
INFO:transformers.trainer:{'loss': 3.0602995090484617, 'learning_rate': 2.7696713486157976e-05, 'epoch': 1.3381971908305217, 'step': 7430000}
INFO:transformers.trainer:{'loss': 2.9972974677085875, 'learning_rate': 2.7695212592045332e-05, 'epoch': 1.33828724447728, 'step': 7430500}
INFO:transformers.trainer:{'loss': 3.014930433034897, 'learning_rate': 2.7693711697932694e-05, 'epoch': 1.3383772981240385, 'step': 7431000}
INFO:transformers.trainer:{'loss': 3.0183140480518342, 'learning_rate': 2.769221080382005e-05, 'epoch': 1.338467351770797, 'step': 7431500}
INFO:transformers.trainer:{'loss': 3.0449279580116273, 'learning_rate': 2.7690709909707412e-05, 'epoch': 1.3385574054175553, 'step': 7432000}
INFO:transformers.trainer:{'loss': 3.0340599279403686, 'learning_rate': 2.7689209015594768e-05, 'epoch': 1.3386474590643138, 'step': 7432500}
INFO:transformers.trainer:{'loss': 3.015284324645996, 'learning_rate': 2.768770812148213e-05, 'epoch': 1.3387375127110723, 'step': 7433000}
INFO:transformers.trainer:{'loss': 3.042643306016922, 'learning_rate': 2.7686207227369486e-05, 'epoch': 1.3388275663578306, 'step': 7433500}
INFO:transformers.trainer:{'loss': 2.9978484290838243, 'learning_rate': 2.768470633325685e-05, 'epoch': 1.3389176200045891, 'step': 7434000}
INFO:transformers.trainer:{'loss': 2.99532798743248, 'learning_rate': 2.768320543914421e-05, 'epoch': 1.3390076736513477, 'step': 7434500}
INFO:transformers.trainer:{'loss': 3.0371111078858375, 'learning_rate': 2.7681704545031567e-05, 'epoch': 1.339097727298106, 'step': 7435000}
INFO:transformers.trainer:{'loss': 2.9657417982816696, 'learning_rate': 2.768020365091893e-05, 'epoch': 1.3391877809448645, 'step': 7435500}
INFO:transformers.trainer:{'loss': 3.025484399318695, 'learning_rate': 2.7678702756806285e-05, 'epoch': 1.339277834591623, 'step': 7436000}
INFO:transformers.trainer:{'loss': 3.0304974658489225, 'learning_rate': 2.7677201862693647e-05, 'epoch': 1.3393678882383813, 'step': 7436500}
INFO:transformers.trainer:{'loss': 2.9961489456892014, 'learning_rate': 2.7675700968581003e-05, 'epoch': 1.3394579418851398, 'step': 7437000}
INFO:transformers.trainer:{'loss': 3.035018787384033, 'learning_rate': 2.7674200074468365e-05, 'epoch': 1.3395479955318983, 'step': 7437500}
INFO:transformers.trainer:{'loss': 3.025066487789154, 'learning_rate': 2.767269918035572e-05, 'epoch': 1.3396380491786566, 'step': 7438000}
INFO:transformers.trainer:{'loss': 3.0068812198638915, 'learning_rate': 2.7671198286243083e-05, 'epoch': 1.339728102825415, 'step': 7438500}
INFO:transformers.trainer:{'loss': 3.0312516758441923, 'learning_rate': 2.766969739213044e-05, 'epoch': 1.3398181564721736, 'step': 7439000}
INFO:transformers.trainer:{'loss': 3.032520452618599, 'learning_rate': 2.76681964980178e-05, 'epoch': 1.3399082101189321, 'step': 7439500}
INFO:transformers.trainer:{'loss': 3.071931470155716, 'learning_rate': 2.7666695603905157e-05, 'epoch': 1.3399982637656904, 'step': 7440000}
INFO:transformers.trainer:{'loss': 3.050821272134781, 'learning_rate': 2.766519470979252e-05, 'epoch': 1.340088317412449, 'step': 7440500}
INFO:transformers.trainer:{'loss': 2.9907084472179415, 'learning_rate': 2.7663693815679882e-05, 'epoch': 1.3401783710592075, 'step': 7441000}
INFO:transformers.trainer:{'loss': 3.0091552329063416, 'learning_rate': 2.7662192921567238e-05, 'epoch': 1.340268424705966, 'step': 7441500}
INFO:transformers.trainer:{'loss': 3.0299556148052216, 'learning_rate': 2.76606920274546e-05, 'epoch': 1.3403584783527243, 'step': 7442000}
INFO:transformers.trainer:{'loss': 3.017228744506836, 'learning_rate': 2.7659191133341956e-05, 'epoch': 1.3404485319994828, 'step': 7442500}
INFO:transformers.trainer:{'loss': 3.001088751077652, 'learning_rate': 2.7657690239229318e-05, 'epoch': 1.3405385856462413, 'step': 7443000}
INFO:transformers.trainer:{'loss': 2.9852207721471786, 'learning_rate': 2.7656189345116674e-05, 'epoch': 1.3406286392929996, 'step': 7443500}
INFO:transformers.trainer:{'loss': 2.983842351436615, 'learning_rate': 2.7654688451004036e-05, 'epoch': 1.340718692939758, 'step': 7444000}
INFO:transformers.trainer:{'loss': 3.0131393091678618, 'learning_rate': 2.7653187556891392e-05, 'epoch': 1.3408087465865166, 'step': 7444500}
INFO:transformers.trainer:{'loss': 2.9974854587316515, 'learning_rate': 2.7651686662778754e-05, 'epoch': 1.340898800233275, 'step': 7445000}
INFO:transformers.trainer:{'loss': 3.0546637320518495, 'learning_rate': 2.765018576866611e-05, 'epoch': 1.3409888538800334, 'step': 7445500}
INFO:transformers.trainer:{'loss': 3.0357153836488724, 'learning_rate': 2.7648684874553473e-05, 'epoch': 1.341078907526792, 'step': 7446000}
INFO:transformers.trainer:{'loss': 3.023509690284729, 'learning_rate': 2.7647183980440828e-05, 'epoch': 1.3411689611735502, 'step': 7446500}
INFO:transformers.trainer:{'loss': 3.047219458937645, 'learning_rate': 2.764568308632819e-05, 'epoch': 1.3412590148203087, 'step': 7447000}
INFO:transformers.trainer:{'loss': 2.9986176644563676, 'learning_rate': 2.7644182192215546e-05, 'epoch': 1.3413490684670673, 'step': 7447500}
INFO:transformers.trainer:{'loss': 2.9913109910488127, 'learning_rate': 2.764268129810291e-05, 'epoch': 1.3414391221138255, 'step': 7448000}
INFO:transformers.trainer:{'loss': 3.0228538496494295, 'learning_rate': 2.7641180403990268e-05, 'epoch': 1.341529175760584, 'step': 7448500}
INFO:transformers.trainer:{'loss': 3.017288770675659, 'learning_rate': 2.7639679509877623e-05, 'epoch': 1.3416192294073426, 'step': 7449000}
INFO:transformers.trainer:{'loss': 3.0144672050476076, 'learning_rate': 2.7638178615764986e-05, 'epoch': 1.3417092830541009, 'step': 7449500}
INFO:transformers.trainer:{'loss': 3.0928414363861085, 'learning_rate': 2.763667772165234e-05, 'epoch': 1.3417993367008594, 'step': 7450000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7450000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7450000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7450000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7350000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0051738638877867, 'learning_rate': 2.7635176827539704e-05, 'epoch': 1.341889390347618, 'step': 7450500}
INFO:transformers.trainer:{'loss': 3.044212282180786, 'learning_rate': 2.763367593342706e-05, 'epoch': 1.3419794439943764, 'step': 7451000}
INFO:transformers.trainer:{'loss': 3.0382623846530916, 'learning_rate': 2.7632175039314422e-05, 'epoch': 1.3420694976411347, 'step': 7451500}
INFO:transformers.trainer:{'loss': 3.0376669857501986, 'learning_rate': 2.7630674145201778e-05, 'epoch': 1.3421595512878932, 'step': 7452000}
INFO:transformers.trainer:{'loss': 2.979483794271946, 'learning_rate': 2.762917325108914e-05, 'epoch': 1.3422496049346517, 'step': 7452500}
INFO:transformers.trainer:{'loss': 3.0776322346925737, 'learning_rate': 2.7627672356976496e-05, 'epoch': 1.3423396585814102, 'step': 7453000}
INFO:transformers.trainer:{'loss': 3.0303140165805815, 'learning_rate': 2.762617146286386e-05, 'epoch': 1.3424297122281685, 'step': 7453500}
INFO:transformers.trainer:{'loss': 3.055300010204315, 'learning_rate': 2.7624670568751214e-05, 'epoch': 1.342519765874927, 'step': 7454000}
INFO:transformers.trainer:{'loss': 3.0959742105007173, 'learning_rate': 2.7623169674638576e-05, 'epoch': 1.3426098195216856, 'step': 7454500}
INFO:transformers.trainer:{'loss': 3.0759070518016816, 'learning_rate': 2.762166878052594e-05, 'epoch': 1.3426998731684439, 'step': 7455000}
INFO:transformers.trainer:{'loss': 3.0190995775461196, 'learning_rate': 2.7620167886413295e-05, 'epoch': 1.3427899268152024, 'step': 7455500}
INFO:transformers.trainer:{'loss': 3.07188707780838, 'learning_rate': 2.7618666992300657e-05, 'epoch': 1.3428799804619609, 'step': 7456000}
INFO:transformers.trainer:{'loss': 3.031257889509201, 'learning_rate': 2.7617166098188013e-05, 'epoch': 1.3429700341087192, 'step': 7456500}
INFO:transformers.trainer:{'loss': 3.0813008052110673, 'learning_rate': 2.7615665204075375e-05, 'epoch': 1.3430600877554777, 'step': 7457000}
INFO:transformers.trainer:{'loss': 2.999789710879326, 'learning_rate': 2.761416430996273e-05, 'epoch': 1.3431501414022362, 'step': 7457500}
INFO:transformers.trainer:{'loss': 3.096110486149788, 'learning_rate': 2.7612663415850093e-05, 'epoch': 1.3432401950489945, 'step': 7458000}
INFO:transformers.trainer:{'loss': 3.0308830754756926, 'learning_rate': 2.761116252173745e-05, 'epoch': 1.343330248695753, 'step': 7458500}
INFO:transformers.trainer:{'loss': 2.9949984757900237, 'learning_rate': 2.760966162762481e-05, 'epoch': 1.3434203023425115, 'step': 7459000}
INFO:transformers.trainer:{'loss': 3.1082316485643386, 'learning_rate': 2.7608160733512167e-05, 'epoch': 1.3435103559892698, 'step': 7459500}
INFO:transformers.trainer:{'loss': 3.0682251510620118, 'learning_rate': 2.760665983939953e-05, 'epoch': 1.3436004096360283, 'step': 7460000}
INFO:transformers.trainer:{'loss': 3.013654200792313, 'learning_rate': 2.7605158945286885e-05, 'epoch': 1.3436904632827869, 'step': 7460500}
INFO:transformers.trainer:{'loss': 3.0452621343135835, 'learning_rate': 2.7603658051174247e-05, 'epoch': 1.3437805169295451, 'step': 7461000}
INFO:transformers.trainer:{'loss': 3.084941441655159, 'learning_rate': 2.7602157157061603e-05, 'epoch': 1.3438705705763037, 'step': 7461500}
INFO:transformers.trainer:{'loss': 3.0614646730422974, 'learning_rate': 2.7600656262948966e-05, 'epoch': 1.3439606242230622, 'step': 7462000}
INFO:transformers.trainer:{'loss': 3.077784073352814, 'learning_rate': 2.7599155368836328e-05, 'epoch': 1.3440506778698207, 'step': 7462500}
INFO:transformers.trainer:{'loss': 3.0502034208774567, 'learning_rate': 2.7597654474723684e-05, 'epoch': 1.344140731516579, 'step': 7463000}
INFO:transformers.trainer:{'loss': 2.9896350266933442, 'learning_rate': 2.7596153580611046e-05, 'epoch': 1.3442307851633375, 'step': 7463500}
INFO:transformers.trainer:{'loss': 3.0103464448451995, 'learning_rate': 2.7594652686498402e-05, 'epoch': 1.344320838810096, 'step': 7464000}
INFO:transformers.trainer:{'loss': 3.024864926338196, 'learning_rate': 2.7593151792385764e-05, 'epoch': 1.3444108924568545, 'step': 7464500}
INFO:transformers.trainer:{'loss': 3.051931451320648, 'learning_rate': 2.759165089827312e-05, 'epoch': 1.3445009461036128, 'step': 7465000}
INFO:transformers.trainer:{'loss': 3.0382023737430575, 'learning_rate': 2.7590150004160482e-05, 'epoch': 1.3445909997503713, 'step': 7465500}
INFO:transformers.trainer:{'loss': 3.018186612248421, 'learning_rate': 2.7588649110047838e-05, 'epoch': 1.3446810533971298, 'step': 7466000}
INFO:transformers.trainer:{'loss': 2.963196581363678, 'learning_rate': 2.75871482159352e-05, 'epoch': 1.3447711070438881, 'step': 7466500}
INFO:transformers.trainer:{'loss': 3.058578233003616, 'learning_rate': 2.7585647321822556e-05, 'epoch': 1.3448611606906467, 'step': 7467000}
INFO:transformers.trainer:{'loss': 3.008017730116844, 'learning_rate': 2.758414642770992e-05, 'epoch': 1.3449512143374052, 'step': 7467500}
INFO:transformers.trainer:{'loss': 2.9963502781391145, 'learning_rate': 2.7582645533597274e-05, 'epoch': 1.3450412679841635, 'step': 7468000}
INFO:transformers.trainer:{'loss': 3.0256214119195937, 'learning_rate': 2.7581144639484637e-05, 'epoch': 1.345131321630922, 'step': 7468500}
INFO:transformers.trainer:{'loss': 3.059722486257553, 'learning_rate': 2.7579643745371996e-05, 'epoch': 1.3452213752776805, 'step': 7469000}
INFO:transformers.trainer:{'loss': 3.0630345096588134, 'learning_rate': 2.7578142851259355e-05, 'epoch': 1.3453114289244388, 'step': 7469500}
INFO:transformers.trainer:{'loss': 3.0873303899765014, 'learning_rate': 2.7576641957146714e-05, 'epoch': 1.3454014825711973, 'step': 7470000}
INFO:transformers.trainer:{'loss': 2.962387500166893, 'learning_rate': 2.7575141063034073e-05, 'epoch': 1.3454915362179558, 'step': 7470500}
INFO:transformers.trainer:{'loss': 2.9919112634658815, 'learning_rate': 2.7573640168921432e-05, 'epoch': 1.345581589864714, 'step': 7471000}
INFO:transformers.trainer:{'loss': 3.0207073603868486, 'learning_rate': 2.757213927480879e-05, 'epoch': 1.3456716435114726, 'step': 7471500}
INFO:transformers.trainer:{'loss': 2.971888800740242, 'learning_rate': 2.757063838069615e-05, 'epoch': 1.3457616971582311, 'step': 7472000}
INFO:transformers.trainer:{'loss': 3.0415108687877654, 'learning_rate': 2.7569137486583506e-05, 'epoch': 1.3458517508049894, 'step': 7472500}
INFO:transformers.trainer:{'loss': 3.0386643974781036, 'learning_rate': 2.7567636592470868e-05, 'epoch': 1.345941804451748, 'step': 7473000}
INFO:transformers.trainer:{'loss': 3.0518753982782365, 'learning_rate': 2.7566135698358224e-05, 'epoch': 1.3460318580985065, 'step': 7473500}
INFO:transformers.trainer:{'loss': 3.022845379829407, 'learning_rate': 2.7564634804245586e-05, 'epoch': 1.346121911745265, 'step': 7474000}
INFO:transformers.trainer:{'loss': 2.975083200454712, 'learning_rate': 2.7563133910132942e-05, 'epoch': 1.3462119653920233, 'step': 7474500}
INFO:transformers.trainer:{'loss': 3.0126696050167086, 'learning_rate': 2.7561633016020304e-05, 'epoch': 1.3463020190387818, 'step': 7475000}
INFO:transformers.trainer:{'loss': 3.0098731487989427, 'learning_rate': 2.7560132121907667e-05, 'epoch': 1.3463920726855403, 'step': 7475500}
INFO:transformers.trainer:{'loss': 3.0159921445846556, 'learning_rate': 2.7558631227795022e-05, 'epoch': 1.3464821263322988, 'step': 7476000}
INFO:transformers.trainer:{'loss': 3.125722127199173, 'learning_rate': 2.7557130333682385e-05, 'epoch': 1.346572179979057, 'step': 7476500}
INFO:transformers.trainer:{'loss': 3.106587928771973, 'learning_rate': 2.755562943956974e-05, 'epoch': 1.3466622336258156, 'step': 7477000}
INFO:transformers.trainer:{'loss': 3.004080160856247, 'learning_rate': 2.7554128545457103e-05, 'epoch': 1.3467522872725741, 'step': 7477500}
INFO:transformers.trainer:{'loss': 3.037323565006256, 'learning_rate': 2.755262765134446e-05, 'epoch': 1.3468423409193324, 'step': 7478000}
INFO:transformers.trainer:{'loss': 2.986572097659111, 'learning_rate': 2.755112675723182e-05, 'epoch': 1.346932394566091, 'step': 7478500}
INFO:transformers.trainer:{'loss': 3.008320641756058, 'learning_rate': 2.7549625863119177e-05, 'epoch': 1.3470224482128494, 'step': 7479000}
INFO:transformers.trainer:{'loss': 3.041038456559181, 'learning_rate': 2.754812496900654e-05, 'epoch': 1.3471125018596077, 'step': 7479500}
INFO:transformers.trainer:{'loss': 2.982055190563202, 'learning_rate': 2.7546624074893895e-05, 'epoch': 1.3472025555063663, 'step': 7480000}
INFO:transformers.trainer:{'loss': 3.0077837380170824, 'learning_rate': 2.7545123180781257e-05, 'epoch': 1.3472926091531248, 'step': 7480500}
INFO:transformers.trainer:{'loss': 3.0026720054149627, 'learning_rate': 2.7543622286668613e-05, 'epoch': 1.347382662799883, 'step': 7481000}
INFO:transformers.trainer:{'loss': 3.066843257665634, 'learning_rate': 2.7542121392555975e-05, 'epoch': 1.3474727164466416, 'step': 7481500}
INFO:transformers.trainer:{'loss': 2.925381112575531, 'learning_rate': 2.754062049844333e-05, 'epoch': 1.3475627700934, 'step': 7482000}
INFO:transformers.trainer:{'loss': 3.082904757022858, 'learning_rate': 2.7539119604330693e-05, 'epoch': 1.3476528237401584, 'step': 7482500}
INFO:transformers.trainer:{'loss': 3.031325914144516, 'learning_rate': 2.7537618710218056e-05, 'epoch': 1.347742877386917, 'step': 7483000}
INFO:transformers.trainer:{'loss': 3.0023103337287904, 'learning_rate': 2.753611781610541e-05, 'epoch': 1.3478329310336754, 'step': 7483500}
INFO:transformers.trainer:{'loss': 3.1066423168182373, 'learning_rate': 2.7534616921992774e-05, 'epoch': 1.3479229846804337, 'step': 7484000}
INFO:transformers.trainer:{'loss': 3.0064152135849, 'learning_rate': 2.753311602788013e-05, 'epoch': 1.3480130383271922, 'step': 7484500}
INFO:transformers.trainer:{'loss': 3.0198298124074934, 'learning_rate': 2.7531615133767492e-05, 'epoch': 1.3481030919739507, 'step': 7485000}
INFO:transformers.trainer:{'loss': 3.021328637957573, 'learning_rate': 2.7530114239654848e-05, 'epoch': 1.3481931456207092, 'step': 7485500}
INFO:transformers.trainer:{'loss': 3.0063160798549653, 'learning_rate': 2.752861334554221e-05, 'epoch': 1.3482831992674675, 'step': 7486000}
INFO:transformers.trainer:{'loss': 2.998655685186386, 'learning_rate': 2.7527112451429566e-05, 'epoch': 1.348373252914226, 'step': 7486500}
INFO:transformers.trainer:{'loss': 3.0199045820236208, 'learning_rate': 2.7525611557316928e-05, 'epoch': 1.3484633065609846, 'step': 7487000}
INFO:transformers.trainer:{'loss': 3.0601539990901947, 'learning_rate': 2.7524110663204284e-05, 'epoch': 1.348553360207743, 'step': 7487500}
INFO:transformers.trainer:{'loss': 2.999770433187485, 'learning_rate': 2.7522609769091646e-05, 'epoch': 1.3486434138545014, 'step': 7488000}
INFO:transformers.trainer:{'loss': 3.0223228328227996, 'learning_rate': 2.7521108874979002e-05, 'epoch': 1.3487334675012599, 'step': 7488500}
INFO:transformers.trainer:{'loss': 3.0032191474437715, 'learning_rate': 2.7519607980866364e-05, 'epoch': 1.3488235211480184, 'step': 7489000}
INFO:transformers.trainer:{'loss': 3.064892396688461, 'learning_rate': 2.7518107086753723e-05, 'epoch': 1.3489135747947767, 'step': 7489500}
INFO:transformers.trainer:{'loss': 3.0546679968833925, 'learning_rate': 2.7516606192641083e-05, 'epoch': 1.3490036284415352, 'step': 7490000}
INFO:transformers.trainer:{'loss': 3.0645977466106413, 'learning_rate': 2.751510529852844e-05, 'epoch': 1.3490936820882937, 'step': 7490500}
INFO:transformers.trainer:{'loss': 3.0519341294765474, 'learning_rate': 2.75136044044158e-05, 'epoch': 1.349183735735052, 'step': 7491000}
INFO:transformers.trainer:{'loss': 3.007195476293564, 'learning_rate': 2.751210351030316e-05, 'epoch': 1.3492737893818105, 'step': 7491500}
INFO:transformers.trainer:{'loss': 2.973101783156395, 'learning_rate': 2.751060261619052e-05, 'epoch': 1.349363843028569, 'step': 7492000}
INFO:transformers.trainer:{'loss': 3.015120798587799, 'learning_rate': 2.7509101722077878e-05, 'epoch': 1.3494538966753273, 'step': 7492500}
INFO:transformers.trainer:{'loss': 3.0447635053396227, 'learning_rate': 2.7507600827965237e-05, 'epoch': 1.3495439503220859, 'step': 7493000}
INFO:transformers.trainer:{'loss': 2.9891825649738313, 'learning_rate': 2.7506099933852596e-05, 'epoch': 1.3496340039688444, 'step': 7493500}
INFO:transformers.trainer:{'loss': 3.053996493220329, 'learning_rate': 2.7504599039739955e-05, 'epoch': 1.3497240576156027, 'step': 7494000}
INFO:transformers.trainer:{'loss': 2.9395915875434877, 'learning_rate': 2.7503098145627314e-05, 'epoch': 1.3498141112623612, 'step': 7494500}
INFO:transformers.trainer:{'loss': 3.017604551553726, 'learning_rate': 2.7501597251514673e-05, 'epoch': 1.3499041649091197, 'step': 7495000}
INFO:transformers.trainer:{'loss': 3.1158501327037813, 'learning_rate': 2.7500096357402032e-05, 'epoch': 1.349994218555878, 'step': 7495500}
INFO:transformers.trainer:{'loss': 3.0260494878292086, 'learning_rate': 2.7498595463289388e-05, 'epoch': 1.3500842722026365, 'step': 7496000}
INFO:transformers.trainer:{'loss': 3.014204948067665, 'learning_rate': 2.749709456917675e-05, 'epoch': 1.350174325849395, 'step': 7496500}
INFO:transformers.trainer:{'loss': 3.0333139635324478, 'learning_rate': 2.7495593675064113e-05, 'epoch': 1.3502643794961535, 'step': 7497000}
INFO:transformers.trainer:{'loss': 3.0670181237459184, 'learning_rate': 2.7494092780951468e-05, 'epoch': 1.3503544331429118, 'step': 7497500}
INFO:transformers.trainer:{'loss': 3.024410101175308, 'learning_rate': 2.749259188683883e-05, 'epoch': 1.3504444867896703, 'step': 7498000}
INFO:transformers.trainer:{'loss': 2.9953338297605514, 'learning_rate': 2.7491090992726186e-05, 'epoch': 1.3505345404364288, 'step': 7498500}
INFO:transformers.trainer:{'loss': 3.059199527263641, 'learning_rate': 2.748959009861355e-05, 'epoch': 1.3506245940831874, 'step': 7499000}
INFO:transformers.trainer:{'loss': 2.975342177152634, 'learning_rate': 2.7488089204500904e-05, 'epoch': 1.3507146477299456, 'step': 7499500}
INFO:transformers.trainer:{'loss': 3.0646984498500824, 'learning_rate': 2.7486588310388267e-05, 'epoch': 1.3508047013767042, 'step': 7500000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7500000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7500000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7500000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7400000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.042608600139618, 'learning_rate': 2.7485087416275623e-05, 'epoch': 1.3508947550234627, 'step': 7500500}
INFO:transformers.trainer:{'loss': 3.041074376344681, 'learning_rate': 2.7483586522162985e-05, 'epoch': 1.350984808670221, 'step': 7501000}
INFO:transformers.trainer:{'loss': 2.983729013085365, 'learning_rate': 2.748208562805034e-05, 'epoch': 1.3510748623169795, 'step': 7501500}
INFO:transformers.trainer:{'loss': 3.0473281252384186, 'learning_rate': 2.7480584733937703e-05, 'epoch': 1.351164915963738, 'step': 7502000}
INFO:transformers.trainer:{'loss': 2.9845058624744416, 'learning_rate': 2.747908383982506e-05, 'epoch': 1.3512549696104963, 'step': 7502500}
INFO:transformers.trainer:{'loss': 3.0038350336551667, 'learning_rate': 2.747758294571242e-05, 'epoch': 1.3513450232572548, 'step': 7503000}
INFO:transformers.trainer:{'loss': 3.030548362970352, 'learning_rate': 2.7476082051599784e-05, 'epoch': 1.3514350769040133, 'step': 7503500}
INFO:transformers.trainer:{'loss': 3.048477985262871, 'learning_rate': 2.747458115748714e-05, 'epoch': 1.3515251305507716, 'step': 7504000}
INFO:transformers.trainer:{'loss': 3.046081421136856, 'learning_rate': 2.7473080263374502e-05, 'epoch': 1.3516151841975301, 'step': 7504500}
INFO:transformers.trainer:{'loss': 3.0698974232673644, 'learning_rate': 2.7471579369261857e-05, 'epoch': 1.3517052378442886, 'step': 7505000}
INFO:transformers.trainer:{'loss': 2.9847354967594146, 'learning_rate': 2.747007847514922e-05, 'epoch': 1.351795291491047, 'step': 7505500}
INFO:transformers.trainer:{'loss': 2.9895082902908325, 'learning_rate': 2.7468577581036576e-05, 'epoch': 1.3518853451378054, 'step': 7506000}
INFO:transformers.trainer:{'loss': 3.0077210886478425, 'learning_rate': 2.7467076686923938e-05, 'epoch': 1.351975398784564, 'step': 7506500}
INFO:transformers.trainer:{'loss': 2.9735163835287093, 'learning_rate': 2.7465575792811294e-05, 'epoch': 1.3520654524313223, 'step': 7507000}
INFO:transformers.trainer:{'loss': 3.0384519726037977, 'learning_rate': 2.7464074898698656e-05, 'epoch': 1.3521555060780808, 'step': 7507500}
INFO:transformers.trainer:{'loss': 3.0180860230922697, 'learning_rate': 2.7462574004586012e-05, 'epoch': 1.3522455597248393, 'step': 7508000}
INFO:transformers.trainer:{'loss': 3.0312206279039384, 'learning_rate': 2.7461073110473374e-05, 'epoch': 1.3523356133715978, 'step': 7508500}
INFO:transformers.trainer:{'loss': 3.0590656952857973, 'learning_rate': 2.745957221636073e-05, 'epoch': 1.352425667018356, 'step': 7509000}
INFO:transformers.trainer:{'loss': 3.0871242055892942, 'learning_rate': 2.7458071322248092e-05, 'epoch': 1.3525157206651146, 'step': 7509500}
INFO:transformers.trainer:{'loss': 3.040564477443695, 'learning_rate': 2.7456570428135448e-05, 'epoch': 1.3526057743118731, 'step': 7510000}
INFO:transformers.trainer:{'loss': 3.043761259555817, 'learning_rate': 2.745506953402281e-05, 'epoch': 1.3526958279586316, 'step': 7510500}
INFO:transformers.trainer:{'loss': 3.031635200381279, 'learning_rate': 2.745356863991017e-05, 'epoch': 1.35278588160539, 'step': 7511000}
INFO:transformers.trainer:{'loss': 3.0576861834526063, 'learning_rate': 2.745206774579753e-05, 'epoch': 1.3528759352521484, 'step': 7511500}
INFO:transformers.trainer:{'loss': 2.965219976186752, 'learning_rate': 2.7450566851684887e-05, 'epoch': 1.352965988898907, 'step': 7512000}
INFO:transformers.trainer:{'loss': 2.9976218168735502, 'learning_rate': 2.7449065957572247e-05, 'epoch': 1.3530560425456652, 'step': 7512500}
INFO:transformers.trainer:{'loss': 3.000846473097801, 'learning_rate': 2.7447565063459606e-05, 'epoch': 1.3531460961924238, 'step': 7513000}
INFO:transformers.trainer:{'loss': 3.0102528933286665, 'learning_rate': 2.7446064169346965e-05, 'epoch': 1.3532361498391823, 'step': 7513500}
INFO:transformers.trainer:{'loss': 3.086820697069168, 'learning_rate': 2.7444563275234324e-05, 'epoch': 1.3533262034859406, 'step': 7514000}
INFO:transformers.trainer:{'loss': 3.0320715264081954, 'learning_rate': 2.7443062381121683e-05, 'epoch': 1.353416257132699, 'step': 7514500}
INFO:transformers.trainer:{'loss': 2.9503393802642823, 'learning_rate': 2.7441561487009042e-05, 'epoch': 1.3535063107794576, 'step': 7515000}
INFO:transformers.trainer:{'loss': 3.059481289386749, 'learning_rate': 2.74400605928964e-05, 'epoch': 1.353596364426216, 'step': 7515500}
INFO:transformers.trainer:{'loss': 3.0048097143173216, 'learning_rate': 2.743855969878376e-05, 'epoch': 1.3536864180729744, 'step': 7516000}
INFO:transformers.trainer:{'loss': 3.006555498838425, 'learning_rate': 2.743705880467112e-05, 'epoch': 1.353776471719733, 'step': 7516500}
INFO:transformers.trainer:{'loss': 3.0515455127954483, 'learning_rate': 2.7435557910558478e-05, 'epoch': 1.3538665253664912, 'step': 7517000}
INFO:transformers.trainer:{'loss': 2.980381327629089, 'learning_rate': 2.743405701644584e-05, 'epoch': 1.3539565790132497, 'step': 7517500}
INFO:transformers.trainer:{'loss': 3.0286104204654696, 'learning_rate': 2.7432556122333196e-05, 'epoch': 1.3540466326600082, 'step': 7518000}
INFO:transformers.trainer:{'loss': 3.015357298374176, 'learning_rate': 2.743105522822056e-05, 'epoch': 1.3541366863067665, 'step': 7518500}
INFO:transformers.trainer:{'loss': 3.0023810884952544, 'learning_rate': 2.7429554334107914e-05, 'epoch': 1.354226739953525, 'step': 7519000}
INFO:transformers.trainer:{'loss': 3.0433290185928343, 'learning_rate': 2.7428053439995277e-05, 'epoch': 1.3543167936002836, 'step': 7519500}
INFO:transformers.trainer:{'loss': 2.9805605113506317, 'learning_rate': 2.7426552545882632e-05, 'epoch': 1.354406847247042, 'step': 7520000}
INFO:transformers.trainer:{'loss': 2.996847193956375, 'learning_rate': 2.7425051651769995e-05, 'epoch': 1.3544969008938006, 'step': 7520500}
INFO:transformers.trainer:{'loss': 3.031936409473419, 'learning_rate': 2.742355075765735e-05, 'epoch': 1.3545869545405589, 'step': 7521000}
INFO:transformers.trainer:{'loss': 3.0375613164901734, 'learning_rate': 2.7422049863544713e-05, 'epoch': 1.3546770081873174, 'step': 7521500}
INFO:transformers.trainer:{'loss': 3.034178216934204, 'learning_rate': 2.742054896943207e-05, 'epoch': 1.354767061834076, 'step': 7522000}
INFO:transformers.trainer:{'loss': 2.981663871526718, 'learning_rate': 2.741904807531943e-05, 'epoch': 1.3548571154808342, 'step': 7522500}
INFO:transformers.trainer:{'loss': 3.0264722492694855, 'learning_rate': 2.7417547181206787e-05, 'epoch': 1.3549471691275927, 'step': 7523000}
INFO:transformers.trainer:{'loss': 3.0789066431522367, 'learning_rate': 2.741604628709415e-05, 'epoch': 1.3550372227743512, 'step': 7523500}
INFO:transformers.trainer:{'loss': 3.0834505202770233, 'learning_rate': 2.7414545392981505e-05, 'epoch': 1.3551272764211095, 'step': 7524000}
INFO:transformers.trainer:{'loss': 3.0466885302066804, 'learning_rate': 2.7413044498868867e-05, 'epoch': 1.355217330067868, 'step': 7524500}
INFO:transformers.trainer:{'loss': 3.072691788673401, 'learning_rate': 2.741154360475623e-05, 'epoch': 1.3553073837146266, 'step': 7525000}
INFO:transformers.trainer:{'loss': 3.0000511001348498, 'learning_rate': 2.7410042710643585e-05, 'epoch': 1.3553974373613848, 'step': 7525500}
INFO:transformers.trainer:{'loss': 2.998182609796524, 'learning_rate': 2.7408541816530948e-05, 'epoch': 1.3554874910081434, 'step': 7526000}
INFO:transformers.trainer:{'loss': 2.998915605068207, 'learning_rate': 2.7407040922418303e-05, 'epoch': 1.3555775446549019, 'step': 7526500}
INFO:transformers.trainer:{'loss': 3.002492212057114, 'learning_rate': 2.7405540028305666e-05, 'epoch': 1.3556675983016602, 'step': 7527000}
INFO:transformers.trainer:{'loss': 3.028150819182396, 'learning_rate': 2.740403913419302e-05, 'epoch': 1.3557576519484187, 'step': 7527500}
INFO:transformers.trainer:{'loss': 2.9914467121362684, 'learning_rate': 2.7402538240080384e-05, 'epoch': 1.3558477055951772, 'step': 7528000}
INFO:transformers.trainer:{'loss': 3.048600058555603, 'learning_rate': 2.740103734596774e-05, 'epoch': 1.3559377592419355, 'step': 7528500}
INFO:transformers.trainer:{'loss': 3.0426542847156526, 'learning_rate': 2.7399536451855102e-05, 'epoch': 1.356027812888694, 'step': 7529000}
INFO:transformers.trainer:{'loss': 3.0208162308931352, 'learning_rate': 2.7398035557742458e-05, 'epoch': 1.3561178665354525, 'step': 7529500}
INFO:transformers.trainer:{'loss': 3.0219398173093794, 'learning_rate': 2.739653466362982e-05, 'epoch': 1.3562079201822108, 'step': 7530000}
INFO:transformers.trainer:{'loss': 2.9878936920166015, 'learning_rate': 2.7395033769517176e-05, 'epoch': 1.3562979738289693, 'step': 7530500}
INFO:transformers.trainer:{'loss': 3.0173412528038024, 'learning_rate': 2.7393532875404538e-05, 'epoch': 1.3563880274757278, 'step': 7531000}
INFO:transformers.trainer:{'loss': 3.008889813184738, 'learning_rate': 2.73920319812919e-05, 'epoch': 1.3564780811224864, 'step': 7531500}
INFO:transformers.trainer:{'loss': 3.005244878053665, 'learning_rate': 2.7390531087179256e-05, 'epoch': 1.3565681347692449, 'step': 7532000}
INFO:transformers.trainer:{'loss': 2.95884362077713, 'learning_rate': 2.738903019306662e-05, 'epoch': 1.3566581884160032, 'step': 7532500}
INFO:transformers.trainer:{'loss': 3.0512475005984308, 'learning_rate': 2.7387529298953974e-05, 'epoch': 1.3567482420627617, 'step': 7533000}
INFO:transformers.trainer:{'loss': 3.032994173049927, 'learning_rate': 2.7386028404841337e-05, 'epoch': 1.3568382957095202, 'step': 7533500}
INFO:transformers.trainer:{'loss': 3.0148581420183183, 'learning_rate': 2.7384527510728692e-05, 'epoch': 1.3569283493562785, 'step': 7534000}
INFO:transformers.trainer:{'loss': 3.0370423290729525, 'learning_rate': 2.738302661661605e-05, 'epoch': 1.357018403003037, 'step': 7534500}
INFO:transformers.trainer:{'loss': 3.011234304189682, 'learning_rate': 2.738152572250341e-05, 'epoch': 1.3571084566497955, 'step': 7535000}
INFO:transformers.trainer:{'loss': 3.043525591611862, 'learning_rate': 2.738002482839077e-05, 'epoch': 1.3571985102965538, 'step': 7535500}
INFO:transformers.trainer:{'loss': 3.0104413678646087, 'learning_rate': 2.737852393427813e-05, 'epoch': 1.3572885639433123, 'step': 7536000}
INFO:transformers.trainer:{'loss': 3.088261373758316, 'learning_rate': 2.7377023040165488e-05, 'epoch': 1.3573786175900708, 'step': 7536500}
INFO:transformers.trainer:{'loss': 3.030141520023346, 'learning_rate': 2.7375522146052847e-05, 'epoch': 1.3574686712368291, 'step': 7537000}
INFO:transformers.trainer:{'loss': 3.052342146873474, 'learning_rate': 2.7374021251940206e-05, 'epoch': 1.3575587248835876, 'step': 7537500}
INFO:transformers.trainer:{'loss': 3.0403185987472536, 'learning_rate': 2.7372520357827568e-05, 'epoch': 1.3576487785303462, 'step': 7538000}
INFO:transformers.trainer:{'loss': 3.0339073481559753, 'learning_rate': 2.7371019463714924e-05, 'epoch': 1.3577388321771044, 'step': 7538500}
INFO:transformers.trainer:{'loss': 3.0288238940238954, 'learning_rate': 2.7369518569602286e-05, 'epoch': 1.357828885823863, 'step': 7539000}
INFO:transformers.trainer:{'loss': 3.065192536830902, 'learning_rate': 2.7368017675489642e-05, 'epoch': 1.3579189394706215, 'step': 7539500}
INFO:transformers.trainer:{'loss': 3.0150321571826937, 'learning_rate': 2.7366516781377004e-05, 'epoch': 1.3580089931173798, 'step': 7540000}
INFO:transformers.trainer:{'loss': 3.0245647580623625, 'learning_rate': 2.736501588726436e-05, 'epoch': 1.3580990467641383, 'step': 7540500}
INFO:transformers.trainer:{'loss': 3.0198422830104827, 'learning_rate': 2.7363514993151723e-05, 'epoch': 1.3581891004108968, 'step': 7541000}
INFO:transformers.trainer:{'loss': 2.9593408231735228, 'learning_rate': 2.7362014099039078e-05, 'epoch': 1.358279154057655, 'step': 7541500}
INFO:transformers.trainer:{'loss': 3.0574264780282974, 'learning_rate': 2.736051320492644e-05, 'epoch': 1.3583692077044136, 'step': 7542000}
INFO:transformers.trainer:{'loss': 2.9950599827766418, 'learning_rate': 2.7359012310813796e-05, 'epoch': 1.3584592613511721, 'step': 7542500}
INFO:transformers.trainer:{'loss': 3.038945508956909, 'learning_rate': 2.735751141670116e-05, 'epoch': 1.3585493149979306, 'step': 7543000}
INFO:transformers.trainer:{'loss': 2.991577242732048, 'learning_rate': 2.7356010522588514e-05, 'epoch': 1.3586393686446891, 'step': 7543500}
INFO:transformers.trainer:{'loss': 3.021973731279373, 'learning_rate': 2.7354509628475877e-05, 'epoch': 1.3587294222914474, 'step': 7544000}
INFO:transformers.trainer:{'loss': 3.0260523924827574, 'learning_rate': 2.7353008734363233e-05, 'epoch': 1.358819475938206, 'step': 7544500}
INFO:transformers.trainer:{'loss': 3.0227144013643263, 'learning_rate': 2.7351507840250595e-05, 'epoch': 1.3589095295849645, 'step': 7545000}
INFO:transformers.trainer:{'loss': 3.0054378736019136, 'learning_rate': 2.7350006946137957e-05, 'epoch': 1.3589995832317228, 'step': 7545500}
INFO:transformers.trainer:{'loss': 3.0273556953668592, 'learning_rate': 2.7348506052025313e-05, 'epoch': 1.3590896368784813, 'step': 7546000}
INFO:transformers.trainer:{'loss': 2.997735966682434, 'learning_rate': 2.7347005157912675e-05, 'epoch': 1.3591796905252398, 'step': 7546500}
INFO:transformers.trainer:{'loss': 2.9821936786174774, 'learning_rate': 2.734550426380003e-05, 'epoch': 1.359269744171998, 'step': 7547000}
INFO:transformers.trainer:{'loss': 3.040912767767906, 'learning_rate': 2.7344003369687394e-05, 'epoch': 1.3593597978187566, 'step': 7547500}
INFO:transformers.trainer:{'loss': 3.0183339718580244, 'learning_rate': 2.734250247557475e-05, 'epoch': 1.3594498514655151, 'step': 7548000}
INFO:transformers.trainer:{'loss': 3.0015600123405455, 'learning_rate': 2.7341001581462112e-05, 'epoch': 1.3595399051122734, 'step': 7548500}
INFO:transformers.trainer:{'loss': 3.0269153374433517, 'learning_rate': 2.7339500687349467e-05, 'epoch': 1.359629958759032, 'step': 7549000}
INFO:transformers.trainer:{'loss': 3.0409926767349242, 'learning_rate': 2.733799979323683e-05, 'epoch': 1.3597200124057904, 'step': 7549500}
INFO:transformers.trainer:{'loss': 2.931123115301132, 'learning_rate': 2.7336498899124185e-05, 'epoch': 1.3598100660525487, 'step': 7550000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7550000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7550000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7550000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7450000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.008275490283966, 'learning_rate': 2.7334998005011548e-05, 'epoch': 1.3599001196993072, 'step': 7550500}
INFO:transformers.trainer:{'loss': 3.0093331347703933, 'learning_rate': 2.7333497110898904e-05, 'epoch': 1.3599901733460658, 'step': 7551000}
INFO:transformers.trainer:{'loss': 3.0612926261425017, 'learning_rate': 2.7331996216786266e-05, 'epoch': 1.360080226992824, 'step': 7551500}
INFO:transformers.trainer:{'loss': 3.165654771089554, 'learning_rate': 2.733049532267363e-05, 'epoch': 1.3601702806395826, 'step': 7552000}
INFO:transformers.trainer:{'loss': 3.03634328186512, 'learning_rate': 2.7328994428560984e-05, 'epoch': 1.360260334286341, 'step': 7552500}
INFO:transformers.trainer:{'loss': 3.0347555692195893, 'learning_rate': 2.7327493534448347e-05, 'epoch': 1.3603503879330994, 'step': 7553000}
INFO:transformers.trainer:{'loss': 3.047828569173813, 'learning_rate': 2.7325992640335702e-05, 'epoch': 1.3604404415798579, 'step': 7553500}
INFO:transformers.trainer:{'loss': 3.042953055500984, 'learning_rate': 2.7324491746223065e-05, 'epoch': 1.3605304952266164, 'step': 7554000}
INFO:transformers.trainer:{'loss': 3.0118147127628325, 'learning_rate': 2.732299085211042e-05, 'epoch': 1.360620548873375, 'step': 7554500}
INFO:transformers.trainer:{'loss': 3.0817411254644393, 'learning_rate': 2.7321489957997783e-05, 'epoch': 1.3607106025201334, 'step': 7555000}
INFO:transformers.trainer:{'loss': 3.0340781106948853, 'learning_rate': 2.731998906388514e-05, 'epoch': 1.3608006561668917, 'step': 7555500}
INFO:transformers.trainer:{'loss': 3.0445430178642274, 'learning_rate': 2.73184881697725e-05, 'epoch': 1.3608907098136502, 'step': 7556000}
INFO:transformers.trainer:{'loss': 3.011093160748482, 'learning_rate': 2.7316987275659856e-05, 'epoch': 1.3609807634604087, 'step': 7556500}
INFO:transformers.trainer:{'loss': 3.0256704909801484, 'learning_rate': 2.731548638154722e-05, 'epoch': 1.361070817107167, 'step': 7557000}
INFO:transformers.trainer:{'loss': 3.0006553223133086, 'learning_rate': 2.7313985487434575e-05, 'epoch': 1.3611608707539256, 'step': 7557500}
INFO:transformers.trainer:{'loss': 2.9767804915905, 'learning_rate': 2.7312484593321934e-05, 'epoch': 1.361250924400684, 'step': 7558000}
INFO:transformers.trainer:{'loss': 2.954115881323814, 'learning_rate': 2.7310983699209293e-05, 'epoch': 1.3613409780474424, 'step': 7558500}
INFO:transformers.trainer:{'loss': 3.01707146191597, 'learning_rate': 2.7309482805096652e-05, 'epoch': 1.3614310316942009, 'step': 7559000}
INFO:transformers.trainer:{'loss': 3.0212171325683594, 'learning_rate': 2.7307981910984014e-05, 'epoch': 1.3615210853409594, 'step': 7559500}
INFO:transformers.trainer:{'loss': 3.056301017522812, 'learning_rate': 2.730648101687137e-05, 'epoch': 1.3616111389877177, 'step': 7560000}
INFO:transformers.trainer:{'loss': 3.0081641570329665, 'learning_rate': 2.7304980122758732e-05, 'epoch': 1.3617011926344762, 'step': 7560500}
INFO:transformers.trainer:{'loss': 2.9840526704788206, 'learning_rate': 2.7303479228646088e-05, 'epoch': 1.3617912462812347, 'step': 7561000}
INFO:transformers.trainer:{'loss': 2.974363832950592, 'learning_rate': 2.730197833453345e-05, 'epoch': 1.361881299927993, 'step': 7561500}
INFO:transformers.trainer:{'loss': 3.031792118549347, 'learning_rate': 2.7300477440420806e-05, 'epoch': 1.3619713535747515, 'step': 7562000}
INFO:transformers.trainer:{'loss': 3.06063455247879, 'learning_rate': 2.729897654630817e-05, 'epoch': 1.36206140722151, 'step': 7562500}
INFO:transformers.trainer:{'loss': 3.035895203590393, 'learning_rate': 2.7297475652195524e-05, 'epoch': 1.3621514608682683, 'step': 7563000}
INFO:transformers.trainer:{'loss': 3.0865085651874544, 'learning_rate': 2.7295974758082887e-05, 'epoch': 1.3622415145150268, 'step': 7563500}
INFO:transformers.trainer:{'loss': 2.974675373315811, 'learning_rate': 2.7294473863970242e-05, 'epoch': 1.3623315681617854, 'step': 7564000}
INFO:transformers.trainer:{'loss': 3.038186601638794, 'learning_rate': 2.7292972969857605e-05, 'epoch': 1.3624216218085436, 'step': 7564500}
INFO:transformers.trainer:{'loss': 2.9992168521881104, 'learning_rate': 2.729147207574496e-05, 'epoch': 1.3625116754553022, 'step': 7565000}
INFO:transformers.trainer:{'loss': 3.04599065887928, 'learning_rate': 2.7289971181632323e-05, 'epoch': 1.3626017291020607, 'step': 7565500}
INFO:transformers.trainer:{'loss': 2.9705555443763734, 'learning_rate': 2.7288470287519685e-05, 'epoch': 1.3626917827488192, 'step': 7566000}
INFO:transformers.trainer:{'loss': 3.000632487535477, 'learning_rate': 2.728696939340704e-05, 'epoch': 1.3627818363955777, 'step': 7566500}
INFO:transformers.trainer:{'loss': 3.0189337606430056, 'learning_rate': 2.7285468499294403e-05, 'epoch': 1.362871890042336, 'step': 7567000}
INFO:transformers.trainer:{'loss': 3.053301218748093, 'learning_rate': 2.728396760518176e-05, 'epoch': 1.3629619436890945, 'step': 7567500}
INFO:transformers.trainer:{'loss': 2.98706264257431, 'learning_rate': 2.728246671106912e-05, 'epoch': 1.363051997335853, 'step': 7568000}
INFO:transformers.trainer:{'loss': 3.002672080278397, 'learning_rate': 2.7280965816956477e-05, 'epoch': 1.3631420509826113, 'step': 7568500}
INFO:transformers.trainer:{'loss': 3.0129221494197846, 'learning_rate': 2.727946492284384e-05, 'epoch': 1.3632321046293698, 'step': 7569000}
INFO:transformers.trainer:{'loss': 3.031140523195267, 'learning_rate': 2.7277964028731195e-05, 'epoch': 1.3633221582761283, 'step': 7569500}
INFO:transformers.trainer:{'loss': 3.0054729059934617, 'learning_rate': 2.7276463134618558e-05, 'epoch': 1.3634122119228866, 'step': 7570000}
INFO:transformers.trainer:{'loss': 2.995667018055916, 'learning_rate': 2.7274962240505913e-05, 'epoch': 1.3635022655696452, 'step': 7570500}
INFO:transformers.trainer:{'loss': 3.0314958329200743, 'learning_rate': 2.7273461346393276e-05, 'epoch': 1.3635923192164037, 'step': 7571000}
INFO:transformers.trainer:{'loss': 3.10390576171875, 'learning_rate': 2.727196045228063e-05, 'epoch': 1.363682372863162, 'step': 7571500}
INFO:transformers.trainer:{'loss': 2.973741751432419, 'learning_rate': 2.7270459558167994e-05, 'epoch': 1.3637724265099205, 'step': 7572000}
INFO:transformers.trainer:{'loss': 2.9911885266304017, 'learning_rate': 2.726895866405535e-05, 'epoch': 1.363862480156679, 'step': 7572500}
INFO:transformers.trainer:{'loss': 2.999195633292198, 'learning_rate': 2.7267457769942712e-05, 'epoch': 1.3639525338034373, 'step': 7573000}
INFO:transformers.trainer:{'loss': 3.035440802335739, 'learning_rate': 2.7265956875830074e-05, 'epoch': 1.3640425874501958, 'step': 7573500}
INFO:transformers.trainer:{'loss': 2.970059998869896, 'learning_rate': 2.726445598171743e-05, 'epoch': 1.3641326410969543, 'step': 7574000}
INFO:transformers.trainer:{'loss': 3.0209068961143495, 'learning_rate': 2.7262955087604792e-05, 'epoch': 1.3642226947437126, 'step': 7574500}
INFO:transformers.trainer:{'loss': 3.004765470266342, 'learning_rate': 2.7261454193492148e-05, 'epoch': 1.3643127483904711, 'step': 7575000}
INFO:transformers.trainer:{'loss': 2.981226938247681, 'learning_rate': 2.725995329937951e-05, 'epoch': 1.3644028020372296, 'step': 7575500}
INFO:transformers.trainer:{'loss': 2.996878021478653, 'learning_rate': 2.7258452405266866e-05, 'epoch': 1.3644928556839881, 'step': 7576000}
INFO:transformers.trainer:{'loss': 3.011865692138672, 'learning_rate': 2.725695151115423e-05, 'epoch': 1.3645829093307464, 'step': 7576500}
INFO:transformers.trainer:{'loss': 3.038675565958023, 'learning_rate': 2.7255450617041584e-05, 'epoch': 1.364672962977505, 'step': 7577000}
INFO:transformers.trainer:{'loss': 2.9706110942363737, 'learning_rate': 2.7253949722928947e-05, 'epoch': 1.3647630166242635, 'step': 7577500}
INFO:transformers.trainer:{'loss': 3.058262876629829, 'learning_rate': 2.7252448828816302e-05, 'epoch': 1.364853070271022, 'step': 7578000}
INFO:transformers.trainer:{'loss': 2.923731605410576, 'learning_rate': 2.7250947934703665e-05, 'epoch': 1.3649431239177803, 'step': 7578500}
INFO:transformers.trainer:{'loss': 3.0003709399700167, 'learning_rate': 2.724944704059102e-05, 'epoch': 1.3650331775645388, 'step': 7579000}
INFO:transformers.trainer:{'loss': 3.0347376678586007, 'learning_rate': 2.7247946146478383e-05, 'epoch': 1.3651232312112973, 'step': 7579500}
INFO:transformers.trainer:{'loss': 3.045627743959427, 'learning_rate': 2.7246445252365742e-05, 'epoch': 1.3652132848580556, 'step': 7580000}
INFO:transformers.trainer:{'loss': 2.978178964853287, 'learning_rate': 2.72449443582531e-05, 'epoch': 1.3653033385048141, 'step': 7580500}
INFO:transformers.trainer:{'loss': 3.0593838384151457, 'learning_rate': 2.724344346414046e-05, 'epoch': 1.3653933921515726, 'step': 7581000}
INFO:transformers.trainer:{'loss': 3.0547636218070986, 'learning_rate': 2.7241942570027816e-05, 'epoch': 1.365483445798331, 'step': 7581500}
INFO:transformers.trainer:{'loss': 2.9802431000471117, 'learning_rate': 2.7240441675915178e-05, 'epoch': 1.3655734994450894, 'step': 7582000}
INFO:transformers.trainer:{'loss': 2.969490764141083, 'learning_rate': 2.7238940781802534e-05, 'epoch': 1.365663553091848, 'step': 7582500}
INFO:transformers.trainer:{'loss': 3.070005023956299, 'learning_rate': 2.7237439887689896e-05, 'epoch': 1.3657536067386062, 'step': 7583000}
INFO:transformers.trainer:{'loss': 3.0166048332452773, 'learning_rate': 2.7235938993577252e-05, 'epoch': 1.3658436603853648, 'step': 7583500}
INFO:transformers.trainer:{'loss': 3.006308448314667, 'learning_rate': 2.7234438099464614e-05, 'epoch': 1.3659337140321233, 'step': 7584000}
INFO:transformers.trainer:{'loss': 3.016330337047577, 'learning_rate': 2.723293720535197e-05, 'epoch': 1.3660237676788816, 'step': 7584500}
INFO:transformers.trainer:{'loss': 3.0187031998634337, 'learning_rate': 2.7231436311239333e-05, 'epoch': 1.36611382132564, 'step': 7585000}
INFO:transformers.trainer:{'loss': 3.0368754618167877, 'learning_rate': 2.7229935417126688e-05, 'epoch': 1.3662038749723986, 'step': 7585500}
INFO:transformers.trainer:{'loss': 3.02461003780365, 'learning_rate': 2.722843452301405e-05, 'epoch': 1.3662939286191569, 'step': 7586000}
INFO:transformers.trainer:{'loss': 3.0027124810218813, 'learning_rate': 2.7226933628901413e-05, 'epoch': 1.3663839822659154, 'step': 7586500}
INFO:transformers.trainer:{'loss': 3.0433559606075287, 'learning_rate': 2.722543273478877e-05, 'epoch': 1.366474035912674, 'step': 7587000}
INFO:transformers.trainer:{'loss': 3.047832987308502, 'learning_rate': 2.722393184067613e-05, 'epoch': 1.3665640895594324, 'step': 7587500}
INFO:transformers.trainer:{'loss': 2.993026029109955, 'learning_rate': 2.7222430946563487e-05, 'epoch': 1.3666541432061907, 'step': 7588000}
INFO:transformers.trainer:{'loss': 3.0339065375328063, 'learning_rate': 2.722093005245085e-05, 'epoch': 1.3667441968529492, 'step': 7588500}
INFO:transformers.trainer:{'loss': 3.047265797972679, 'learning_rate': 2.7219429158338205e-05, 'epoch': 1.3668342504997077, 'step': 7589000}
INFO:transformers.trainer:{'loss': 3.019344178199768, 'learning_rate': 2.7217928264225567e-05, 'epoch': 1.3669243041464663, 'step': 7589500}
INFO:transformers.trainer:{'loss': 2.9652960560321806, 'learning_rate': 2.7216427370112923e-05, 'epoch': 1.3670143577932246, 'step': 7590000}
INFO:transformers.trainer:{'loss': 2.9984726662635803, 'learning_rate': 2.7214926476000285e-05, 'epoch': 1.367104411439983, 'step': 7590500}
INFO:transformers.trainer:{'loss': 3.0077189984321593, 'learning_rate': 2.721342558188764e-05, 'epoch': 1.3671944650867416, 'step': 7591000}
INFO:transformers.trainer:{'loss': 3.027274069547653, 'learning_rate': 2.7211924687775004e-05, 'epoch': 1.3672845187334999, 'step': 7591500}
INFO:transformers.trainer:{'loss': 2.9999796648025514, 'learning_rate': 2.721042379366236e-05, 'epoch': 1.3673745723802584, 'step': 7592000}
INFO:transformers.trainer:{'loss': 2.998664532184601, 'learning_rate': 2.720892289954972e-05, 'epoch': 1.367464626027017, 'step': 7592500}
INFO:transformers.trainer:{'loss': 3.0311390161514282, 'learning_rate': 2.7207422005437077e-05, 'epoch': 1.3675546796737752, 'step': 7593000}
INFO:transformers.trainer:{'loss': 3.027132122159004, 'learning_rate': 2.720592111132444e-05, 'epoch': 1.3676447333205337, 'step': 7593500}
INFO:transformers.trainer:{'loss': 3.0156976269483566, 'learning_rate': 2.7204420217211802e-05, 'epoch': 1.3677347869672922, 'step': 7594000}
INFO:transformers.trainer:{'loss': 3.074471381187439, 'learning_rate': 2.7202919323099158e-05, 'epoch': 1.3678248406140505, 'step': 7594500}
INFO:transformers.trainer:{'loss': 3.035655663728714, 'learning_rate': 2.720141842898652e-05, 'epoch': 1.367914894260809, 'step': 7595000}
INFO:transformers.trainer:{'loss': 3.077105091571808, 'learning_rate': 2.7199917534873876e-05, 'epoch': 1.3680049479075675, 'step': 7595500}
INFO:transformers.trainer:{'loss': 3.080742281079292, 'learning_rate': 2.719841664076124e-05, 'epoch': 1.3680950015543258, 'step': 7596000}
INFO:transformers.trainer:{'loss': 2.9780332455635072, 'learning_rate': 2.7196915746648594e-05, 'epoch': 1.3681850552010844, 'step': 7596500}
INFO:transformers.trainer:{'loss': 3.0058727765083315, 'learning_rate': 2.7195414852535956e-05, 'epoch': 1.3682751088478429, 'step': 7597000}
INFO:transformers.trainer:{'loss': 3.0235660799741746, 'learning_rate': 2.7193913958423312e-05, 'epoch': 1.3683651624946012, 'step': 7597500}
INFO:transformers.trainer:{'loss': 3.0661413016319274, 'learning_rate': 2.7192413064310675e-05, 'epoch': 1.3684552161413597, 'step': 7598000}
INFO:transformers.trainer:{'loss': 3.0621883471012117, 'learning_rate': 2.719091217019803e-05, 'epoch': 1.3685452697881182, 'step': 7598500}
INFO:transformers.trainer:{'loss': 3.024004335165024, 'learning_rate': 2.7189411276085393e-05, 'epoch': 1.3686353234348767, 'step': 7599000}
INFO:transformers.trainer:{'loss': 3.078679983496666, 'learning_rate': 2.718791038197275e-05, 'epoch': 1.368725377081635, 'step': 7599500}
INFO:transformers.trainer:{'loss': 3.043926647186279, 'learning_rate': 2.718640948786011e-05, 'epoch': 1.3688154307283935, 'step': 7600000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7600000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7600000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7600000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7500000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 2.965611791729927, 'learning_rate': 2.718490859374747e-05, 'epoch': 1.368905484375152, 'step': 7600500}
INFO:transformers.trainer:{'loss': 3.01804012298584, 'learning_rate': 2.718340769963483e-05, 'epoch': 1.3689955380219105, 'step': 7601000}
INFO:transformers.trainer:{'loss': 3.0874619863033295, 'learning_rate': 2.7181906805522188e-05, 'epoch': 1.3690855916686688, 'step': 7601500}
INFO:transformers.trainer:{'loss': 3.017770087480545, 'learning_rate': 2.7180405911409547e-05, 'epoch': 1.3691756453154273, 'step': 7602000}
INFO:transformers.trainer:{'loss': 2.9786391294002534, 'learning_rate': 2.7178905017296906e-05, 'epoch': 1.3692656989621859, 'step': 7602500}
INFO:transformers.trainer:{'loss': 3.0243104674816133, 'learning_rate': 2.7177404123184265e-05, 'epoch': 1.3693557526089442, 'step': 7603000}
INFO:transformers.trainer:{'loss': 3.0672828192710875, 'learning_rate': 2.7175903229071624e-05, 'epoch': 1.3694458062557027, 'step': 7603500}
INFO:transformers.trainer:{'loss': 3.006523173570633, 'learning_rate': 2.7174402334958983e-05, 'epoch': 1.3695358599024612, 'step': 7604000}
INFO:transformers.trainer:{'loss': 3.0258621406555175, 'learning_rate': 2.7172901440846342e-05, 'epoch': 1.3696259135492195, 'step': 7604500}
INFO:transformers.trainer:{'loss': 3.0568577482700348, 'learning_rate': 2.71714005467337e-05, 'epoch': 1.369715967195978, 'step': 7605000}
INFO:transformers.trainer:{'loss': 2.993451707363129, 'learning_rate': 2.716989965262106e-05, 'epoch': 1.3698060208427365, 'step': 7605500}
INFO:transformers.trainer:{'loss': 2.9785858047008515, 'learning_rate': 2.7168398758508416e-05, 'epoch': 1.3698960744894948, 'step': 7606000}
INFO:transformers.trainer:{'loss': 3.0184034674167632, 'learning_rate': 2.716689786439578e-05, 'epoch': 1.3699861281362533, 'step': 7606500}
INFO:transformers.trainer:{'loss': 3.0008195245265963, 'learning_rate': 2.7165396970283134e-05, 'epoch': 1.3700761817830118, 'step': 7607000}
INFO:transformers.trainer:{'loss': 3.0335894161462784, 'learning_rate': 2.7163896076170497e-05, 'epoch': 1.3701662354297701, 'step': 7607500}
INFO:transformers.trainer:{'loss': 2.9661033076047896, 'learning_rate': 2.716239518205786e-05, 'epoch': 1.3702562890765286, 'step': 7608000}
INFO:transformers.trainer:{'loss': 3.038647545337677, 'learning_rate': 2.7160894287945215e-05, 'epoch': 1.3703463427232871, 'step': 7608500}
INFO:transformers.trainer:{'loss': 2.9752778251171113, 'learning_rate': 2.7159393393832577e-05, 'epoch': 1.3704363963700454, 'step': 7609000}
INFO:transformers.trainer:{'loss': 3.004776514172554, 'learning_rate': 2.7157892499719933e-05, 'epoch': 1.370526450016804, 'step': 7609500}
INFO:transformers.trainer:{'loss': 2.99088595187664, 'learning_rate': 2.7156391605607295e-05, 'epoch': 1.3706165036635625, 'step': 7610000}
INFO:transformers.trainer:{'loss': 3.0776848785877227, 'learning_rate': 2.715489071149465e-05, 'epoch': 1.370706557310321, 'step': 7610500}
INFO:transformers.trainer:{'loss': 3.0309203896522523, 'learning_rate': 2.7153389817382013e-05, 'epoch': 1.3707966109570793, 'step': 7611000}
INFO:transformers.trainer:{'loss': 3.034643331050873, 'learning_rate': 2.715188892326937e-05, 'epoch': 1.3708866646038378, 'step': 7611500}
INFO:transformers.trainer:{'loss': 3.0509929999113083, 'learning_rate': 2.715038802915673e-05, 'epoch': 1.3709767182505963, 'step': 7612000}
INFO:transformers.trainer:{'loss': 3.0167386095523834, 'learning_rate': 2.7148887135044087e-05, 'epoch': 1.3710667718973548, 'step': 7612500}
INFO:transformers.trainer:{'loss': 3.0219176025390624, 'learning_rate': 2.714738624093145e-05, 'epoch': 1.3711568255441131, 'step': 7613000}
INFO:transformers.trainer:{'loss': 3.037163748025894, 'learning_rate': 2.7145885346818805e-05, 'epoch': 1.3712468791908716, 'step': 7613500}
INFO:transformers.trainer:{'loss': 3.0453719811439512, 'learning_rate': 2.7144384452706168e-05, 'epoch': 1.3713369328376301, 'step': 7614000}
INFO:transformers.trainer:{'loss': 3.0423482323884965, 'learning_rate': 2.714288355859353e-05, 'epoch': 1.3714269864843884, 'step': 7614500}
INFO:transformers.trainer:{'loss': 3.0188506368398667, 'learning_rate': 2.7141382664480886e-05, 'epoch': 1.371517040131147, 'step': 7615000}
INFO:transformers.trainer:{'loss': 3.036261863231659, 'learning_rate': 2.7139881770368248e-05, 'epoch': 1.3716070937779055, 'step': 7615500}
INFO:transformers.trainer:{'loss': 2.9937926465272904, 'learning_rate': 2.7138380876255604e-05, 'epoch': 1.3716971474246638, 'step': 7616000}
INFO:transformers.trainer:{'loss': 2.98931001830101, 'learning_rate': 2.7136879982142966e-05, 'epoch': 1.3717872010714223, 'step': 7616500}
INFO:transformers.trainer:{'loss': 2.9753632432222368, 'learning_rate': 2.7135379088030322e-05, 'epoch': 1.3718772547181808, 'step': 7617000}
INFO:transformers.trainer:{'loss': 2.997634718418121, 'learning_rate': 2.7133878193917684e-05, 'epoch': 1.371967308364939, 'step': 7617500}
INFO:transformers.trainer:{'loss': 2.985595198869705, 'learning_rate': 2.713237729980504e-05, 'epoch': 1.3720573620116976, 'step': 7618000}
INFO:transformers.trainer:{'loss': 3.039318491458893, 'learning_rate': 2.7130876405692402e-05, 'epoch': 1.372147415658456, 'step': 7618500}
INFO:transformers.trainer:{'loss': 2.9931044644117355, 'learning_rate': 2.7129375511579758e-05, 'epoch': 1.3722374693052144, 'step': 7619000}
INFO:transformers.trainer:{'loss': 2.9781931457519533, 'learning_rate': 2.712787461746712e-05, 'epoch': 1.372327522951973, 'step': 7619500}
INFO:transformers.trainer:{'loss': 2.9279087805747985, 'learning_rate': 2.7126373723354476e-05, 'epoch': 1.3724175765987314, 'step': 7620000}
INFO:transformers.trainer:{'loss': 3.027799783349037, 'learning_rate': 2.712487282924184e-05, 'epoch': 1.3725076302454897, 'step': 7620500}
INFO:transformers.trainer:{'loss': 3.079493335723877, 'learning_rate': 2.7123371935129194e-05, 'epoch': 1.3725976838922482, 'step': 7621000}
INFO:transformers.trainer:{'loss': 3.026581191778183, 'learning_rate': 2.7121871041016557e-05, 'epoch': 1.3726877375390067, 'step': 7621500}
INFO:transformers.trainer:{'loss': 2.97141576731205, 'learning_rate': 2.7120370146903916e-05, 'epoch': 1.3727777911857653, 'step': 7622000}
INFO:transformers.trainer:{'loss': 3.029776643872261, 'learning_rate': 2.7118869252791275e-05, 'epoch': 1.3728678448325236, 'step': 7622500}
INFO:transformers.trainer:{'loss': 2.990052045583725, 'learning_rate': 2.7117368358678634e-05, 'epoch': 1.372957898479282, 'step': 7623000}
INFO:transformers.trainer:{'loss': 2.9967888085842134, 'learning_rate': 2.7115867464565993e-05, 'epoch': 1.3730479521260406, 'step': 7623500}
INFO:transformers.trainer:{'loss': 3.0192482331991197, 'learning_rate': 2.7114366570453352e-05, 'epoch': 1.373138005772799, 'step': 7624000}
INFO:transformers.trainer:{'loss': 3.0247614030838013, 'learning_rate': 2.711286567634071e-05, 'epoch': 1.3732280594195574, 'step': 7624500}
INFO:transformers.trainer:{'loss': 3.0626069648265837, 'learning_rate': 2.711136478222807e-05, 'epoch': 1.373318113066316, 'step': 7625000}
INFO:transformers.trainer:{'loss': 3.057290815114975, 'learning_rate': 2.710986388811543e-05, 'epoch': 1.3734081667130744, 'step': 7625500}
INFO:transformers.trainer:{'loss': 3.083856823205948, 'learning_rate': 2.7108362994002788e-05, 'epoch': 1.3734982203598327, 'step': 7626000}
INFO:transformers.trainer:{'loss': 3.0108935079574586, 'learning_rate': 2.7106862099890147e-05, 'epoch': 1.3735882740065912, 'step': 7626500}
INFO:transformers.trainer:{'loss': 3.0655942335128783, 'learning_rate': 2.7105361205777506e-05, 'epoch': 1.3736783276533497, 'step': 7627000}
INFO:transformers.trainer:{'loss': 3.0438523857593536, 'learning_rate': 2.7103860311664865e-05, 'epoch': 1.373768381300108, 'step': 7627500}
INFO:transformers.trainer:{'loss': 3.0531143958568574, 'learning_rate': 2.7102359417552224e-05, 'epoch': 1.3738584349468665, 'step': 7628000}
INFO:transformers.trainer:{'loss': 2.9966626732349395, 'learning_rate': 2.7100858523439587e-05, 'epoch': 1.373948488593625, 'step': 7628500}
INFO:transformers.trainer:{'loss': 3.001692436695099, 'learning_rate': 2.7099357629326942e-05, 'epoch': 1.3740385422403834, 'step': 7629000}
INFO:transformers.trainer:{'loss': 2.975622407436371, 'learning_rate': 2.7097856735214305e-05, 'epoch': 1.3741285958871419, 'step': 7629500}
INFO:transformers.trainer:{'loss': 3.095851753592491, 'learning_rate': 2.709635584110166e-05, 'epoch': 1.3742186495339004, 'step': 7630000}
INFO:transformers.trainer:{'loss': 3.0021053144931793, 'learning_rate': 2.7094854946989023e-05, 'epoch': 1.3743087031806587, 'step': 7630500}
INFO:transformers.trainer:{'loss': 2.9683186786174773, 'learning_rate': 2.709335405287638e-05, 'epoch': 1.3743987568274172, 'step': 7631000}
INFO:transformers.trainer:{'loss': 3.0613950307369233, 'learning_rate': 2.709185315876374e-05, 'epoch': 1.3744888104741757, 'step': 7631500}
INFO:transformers.trainer:{'loss': 3.000612864732742, 'learning_rate': 2.7090352264651097e-05, 'epoch': 1.374578864120934, 'step': 7632000}
INFO:transformers.trainer:{'loss': 2.9998429770469666, 'learning_rate': 2.708885137053846e-05, 'epoch': 1.3746689177676925, 'step': 7632500}
INFO:transformers.trainer:{'loss': 3.048537827253342, 'learning_rate': 2.7087350476425815e-05, 'epoch': 1.374758971414451, 'step': 7633000}
INFO:transformers.trainer:{'loss': 3.0517123755216597, 'learning_rate': 2.7085849582313177e-05, 'epoch': 1.3748490250612095, 'step': 7633500}
INFO:transformers.trainer:{'loss': 3.009509625196457, 'learning_rate': 2.7084348688200533e-05, 'epoch': 1.3749390787079678, 'step': 7634000}
INFO:transformers.trainer:{'loss': 3.0255397683382035, 'learning_rate': 2.7082847794087895e-05, 'epoch': 1.3750291323547263, 'step': 7634500}
INFO:transformers.trainer:{'loss': 3.064772968292236, 'learning_rate': 2.7081346899975258e-05, 'epoch': 1.3751191860014849, 'step': 7635000}
INFO:transformers.trainer:{'loss': 2.9839915894269944, 'learning_rate': 2.7079846005862614e-05, 'epoch': 1.3752092396482434, 'step': 7635500}
INFO:transformers.trainer:{'loss': 3.0500883464813233, 'learning_rate': 2.7078345111749976e-05, 'epoch': 1.3752992932950017, 'step': 7636000}
INFO:transformers.trainer:{'loss': 3.0257576498985292, 'learning_rate': 2.707684421763733e-05, 'epoch': 1.3753893469417602, 'step': 7636500}
INFO:transformers.trainer:{'loss': 3.0242169151306153, 'learning_rate': 2.7075343323524694e-05, 'epoch': 1.3754794005885187, 'step': 7637000}
INFO:transformers.trainer:{'loss': 2.994309665441513, 'learning_rate': 2.707384242941205e-05, 'epoch': 1.375569454235277, 'step': 7637500}
INFO:transformers.trainer:{'loss': 3.0467828850746157, 'learning_rate': 2.7072341535299412e-05, 'epoch': 1.3756595078820355, 'step': 7638000}
INFO:transformers.trainer:{'loss': 2.9535864531993865, 'learning_rate': 2.7070840641186768e-05, 'epoch': 1.375749561528794, 'step': 7638500}
INFO:transformers.trainer:{'loss': 2.947213762640953, 'learning_rate': 2.706933974707413e-05, 'epoch': 1.3758396151755523, 'step': 7639000}
INFO:transformers.trainer:{'loss': 3.0493427636623385, 'learning_rate': 2.7067838852961486e-05, 'epoch': 1.3759296688223108, 'step': 7639500}
INFO:transformers.trainer:{'loss': 3.0400209283828734, 'learning_rate': 2.706633795884885e-05, 'epoch': 1.3760197224690693, 'step': 7640000}
INFO:transformers.trainer:{'loss': 2.9485173411369323, 'learning_rate': 2.7064837064736204e-05, 'epoch': 1.3761097761158276, 'step': 7640500}
INFO:transformers.trainer:{'loss': 3.062870642900467, 'learning_rate': 2.7063336170623566e-05, 'epoch': 1.3761998297625861, 'step': 7641000}
INFO:transformers.trainer:{'loss': 2.998927836060524, 'learning_rate': 2.7061835276510922e-05, 'epoch': 1.3762898834093447, 'step': 7641500}
INFO:transformers.trainer:{'loss': 2.9947419936656954, 'learning_rate': 2.7060334382398285e-05, 'epoch': 1.376379937056103, 'step': 7642000}
INFO:transformers.trainer:{'loss': 3.004018976211548, 'learning_rate': 2.7058833488285647e-05, 'epoch': 1.3764699907028615, 'step': 7642500}
INFO:transformers.trainer:{'loss': 3.055717900753021, 'learning_rate': 2.7057332594173003e-05, 'epoch': 1.37656004434962, 'step': 7643000}
INFO:transformers.trainer:{'loss': 2.985936192035675, 'learning_rate': 2.7055831700060362e-05, 'epoch': 1.3766500979963783, 'step': 7643500}
INFO:transformers.trainer:{'loss': 3.0527280082702637, 'learning_rate': 2.705433080594772e-05, 'epoch': 1.3767401516431368, 'step': 7644000}
INFO:transformers.trainer:{'loss': 3.012321643233299, 'learning_rate': 2.705282991183508e-05, 'epoch': 1.3768302052898953, 'step': 7644500}
INFO:transformers.trainer:{'loss': 3.0199439527988434, 'learning_rate': 2.705132901772244e-05, 'epoch': 1.3769202589366538, 'step': 7645000}
INFO:transformers.trainer:{'loss': 3.010464256286621, 'learning_rate': 2.7049828123609798e-05, 'epoch': 1.377010312583412, 'step': 7645500}
INFO:transformers.trainer:{'loss': 3.010061427235603, 'learning_rate': 2.7048327229497157e-05, 'epoch': 1.3771003662301706, 'step': 7646000}
INFO:transformers.trainer:{'loss': 2.9832850716114043, 'learning_rate': 2.7046826335384516e-05, 'epoch': 1.3771904198769291, 'step': 7646500}
INFO:transformers.trainer:{'loss': 3.086678948163986, 'learning_rate': 2.7045325441271875e-05, 'epoch': 1.3772804735236877, 'step': 7647000}
INFO:transformers.trainer:{'loss': 3.096484535098076, 'learning_rate': 2.7043824547159234e-05, 'epoch': 1.377370527170446, 'step': 7647500}
INFO:transformers.trainer:{'loss': 2.9356872643232346, 'learning_rate': 2.7042323653046593e-05, 'epoch': 1.3774605808172045, 'step': 7648000}
INFO:transformers.trainer:{'loss': 3.0507099013328554, 'learning_rate': 2.7040822758933952e-05, 'epoch': 1.377550634463963, 'step': 7648500}
INFO:transformers.trainer:{'loss': 2.934376258134842, 'learning_rate': 2.7039321864821315e-05, 'epoch': 1.3776406881107213, 'step': 7649000}
INFO:transformers.trainer:{'loss': 3.0212455410957335, 'learning_rate': 2.703782097070867e-05, 'epoch': 1.3777307417574798, 'step': 7649500}
INFO:transformers.trainer:{'loss': 2.970842144012451, 'learning_rate': 2.7036320076596033e-05, 'epoch': 1.3778207954042383, 'step': 7650000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7650000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7650000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7650000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7550000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.078743390083313, 'learning_rate': 2.703481918248339e-05, 'epoch': 1.3779108490509966, 'step': 7650500}
INFO:transformers.trainer:{'loss': 3.0653601665496826, 'learning_rate': 2.703331828837075e-05, 'epoch': 1.378000902697755, 'step': 7651000}
INFO:transformers.trainer:{'loss': 3.003617124795914, 'learning_rate': 2.7031817394258106e-05, 'epoch': 1.3780909563445136, 'step': 7651500}
INFO:transformers.trainer:{'loss': 3.0030554221272467, 'learning_rate': 2.703031650014547e-05, 'epoch': 1.378181009991272, 'step': 7652000}
INFO:transformers.trainer:{'loss': 3.064809845328331, 'learning_rate': 2.7028815606032825e-05, 'epoch': 1.3782710636380304, 'step': 7652500}
INFO:transformers.trainer:{'loss': 3.0556780965328216, 'learning_rate': 2.7027314711920187e-05, 'epoch': 1.378361117284789, 'step': 7653000}
INFO:transformers.trainer:{'loss': 2.9696721398830412, 'learning_rate': 2.7025813817807543e-05, 'epoch': 1.3784511709315472, 'step': 7653500}
INFO:transformers.trainer:{'loss': 3.0133285982608795, 'learning_rate': 2.7024312923694905e-05, 'epoch': 1.3785412245783057, 'step': 7654000}
INFO:transformers.trainer:{'loss': 2.9715065083503722, 'learning_rate': 2.702281202958226e-05, 'epoch': 1.3786312782250643, 'step': 7654500}
INFO:transformers.trainer:{'loss': 2.9785941662788393, 'learning_rate': 2.7021311135469623e-05, 'epoch': 1.3787213318718226, 'step': 7655000}
INFO:transformers.trainer:{'loss': 2.99316366314888, 'learning_rate': 2.701981024135698e-05, 'epoch': 1.378811385518581, 'step': 7655500}
INFO:transformers.trainer:{'loss': 3.073649026632309, 'learning_rate': 2.701830934724434e-05, 'epoch': 1.3789014391653396, 'step': 7656000}
INFO:transformers.trainer:{'loss': 2.986280894994736, 'learning_rate': 2.7016808453131704e-05, 'epoch': 1.378991492812098, 'step': 7656500}
INFO:transformers.trainer:{'loss': 2.9905513648986815, 'learning_rate': 2.701530755901906e-05, 'epoch': 1.3790815464588564, 'step': 7657000}
INFO:transformers.trainer:{'loss': 3.053524745464325, 'learning_rate': 2.7013806664906422e-05, 'epoch': 1.379171600105615, 'step': 7657500}
INFO:transformers.trainer:{'loss': 3.023017696619034, 'learning_rate': 2.7012305770793778e-05, 'epoch': 1.3792616537523734, 'step': 7658000}
INFO:transformers.trainer:{'loss': 2.933744097709656, 'learning_rate': 2.701080487668114e-05, 'epoch': 1.379351707399132, 'step': 7658500}
INFO:transformers.trainer:{'loss': 3.006590084552765, 'learning_rate': 2.7009303982568496e-05, 'epoch': 1.3794417610458902, 'step': 7659000}
INFO:transformers.trainer:{'loss': 3.0415262286663056, 'learning_rate': 2.7007803088455858e-05, 'epoch': 1.3795318146926487, 'step': 7659500}
INFO:transformers.trainer:{'loss': 3.0587168670892715, 'learning_rate': 2.7006302194343214e-05, 'epoch': 1.3796218683394073, 'step': 7660000}
INFO:transformers.trainer:{'loss': 3.036904684305191, 'learning_rate': 2.7004801300230576e-05, 'epoch': 1.3797119219861655, 'step': 7660500}
INFO:transformers.trainer:{'loss': 3.0025417714118956, 'learning_rate': 2.7003300406117932e-05, 'epoch': 1.379801975632924, 'step': 7661000}
INFO:transformers.trainer:{'loss': 2.944774250149727, 'learning_rate': 2.7001799512005294e-05, 'epoch': 1.3798920292796826, 'step': 7661500}
INFO:transformers.trainer:{'loss': 2.9842146940231324, 'learning_rate': 2.700029861789265e-05, 'epoch': 1.3799820829264409, 'step': 7662000}
INFO:transformers.trainer:{'loss': 3.021239739537239, 'learning_rate': 2.6998797723780012e-05, 'epoch': 1.3800721365731994, 'step': 7662500}
INFO:transformers.trainer:{'loss': 2.9882712548971178, 'learning_rate': 2.6997296829667375e-05, 'epoch': 1.380162190219958, 'step': 7663000}
INFO:transformers.trainer:{'loss': 2.9717366602420805, 'learning_rate': 2.699579593555473e-05, 'epoch': 1.3802522438667162, 'step': 7663500}
INFO:transformers.trainer:{'loss': 3.0170212745666505, 'learning_rate': 2.6994295041442093e-05, 'epoch': 1.3803422975134747, 'step': 7664000}
INFO:transformers.trainer:{'loss': 3.036847873926163, 'learning_rate': 2.699279414732945e-05, 'epoch': 1.3804323511602332, 'step': 7664500}
INFO:transformers.trainer:{'loss': 3.005977472662926, 'learning_rate': 2.699129325321681e-05, 'epoch': 1.3805224048069915, 'step': 7665000}
INFO:transformers.trainer:{'loss': 3.061157628417015, 'learning_rate': 2.6989792359104167e-05, 'epoch': 1.38061245845375, 'step': 7665500}
INFO:transformers.trainer:{'loss': 3.064186508655548, 'learning_rate': 2.698829146499153e-05, 'epoch': 1.3807025121005085, 'step': 7666000}
INFO:transformers.trainer:{'loss': 3.053482694149017, 'learning_rate': 2.6986790570878885e-05, 'epoch': 1.3807925657472668, 'step': 7666500}
INFO:transformers.trainer:{'loss': 2.9603670493364334, 'learning_rate': 2.6985289676766247e-05, 'epoch': 1.3808826193940253, 'step': 7667000}
INFO:transformers.trainer:{'loss': 2.969524672150612, 'learning_rate': 2.6983788782653603e-05, 'epoch': 1.3809726730407839, 'step': 7667500}
INFO:transformers.trainer:{'loss': 3.0402048642635346, 'learning_rate': 2.6982287888540962e-05, 'epoch': 1.3810627266875424, 'step': 7668000}
INFO:transformers.trainer:{'loss': 3.0188740097284317, 'learning_rate': 2.698078699442832e-05, 'epoch': 1.3811527803343007, 'step': 7668500}
INFO:transformers.trainer:{'loss': 3.010813171982765, 'learning_rate': 2.697928610031568e-05, 'epoch': 1.3812428339810592, 'step': 7669000}
INFO:transformers.trainer:{'loss': 2.9969289219379425, 'learning_rate': 2.697778520620304e-05, 'epoch': 1.3813328876278177, 'step': 7669500}
INFO:transformers.trainer:{'loss': 3.0054024000167847, 'learning_rate': 2.6976284312090398e-05, 'epoch': 1.3814229412745762, 'step': 7670000}
INFO:transformers.trainer:{'loss': 3.0085770921707153, 'learning_rate': 2.697478341797776e-05, 'epoch': 1.3815129949213345, 'step': 7670500}
INFO:transformers.trainer:{'loss': 2.983524433851242, 'learning_rate': 2.6973282523865116e-05, 'epoch': 1.381603048568093, 'step': 7671000}
INFO:transformers.trainer:{'loss': 3.0395588471889496, 'learning_rate': 2.697178162975248e-05, 'epoch': 1.3816931022148515, 'step': 7671500}
INFO:transformers.trainer:{'loss': 3.0803772020339966, 'learning_rate': 2.6970280735639834e-05, 'epoch': 1.3817831558616098, 'step': 7672000}
INFO:transformers.trainer:{'loss': 3.0449812051057816, 'learning_rate': 2.6968779841527197e-05, 'epoch': 1.3818732095083683, 'step': 7672500}
INFO:transformers.trainer:{'loss': 3.0236192474365233, 'learning_rate': 2.6967278947414552e-05, 'epoch': 1.3819632631551269, 'step': 7673000}
INFO:transformers.trainer:{'loss': 2.968573887348175, 'learning_rate': 2.6965778053301915e-05, 'epoch': 1.3820533168018851, 'step': 7673500}
INFO:transformers.trainer:{'loss': 3.0223423762321473, 'learning_rate': 2.696427715918927e-05, 'epoch': 1.3821433704486437, 'step': 7674000}
INFO:transformers.trainer:{'loss': 3.0223306665420533, 'learning_rate': 2.6962776265076633e-05, 'epoch': 1.3822334240954022, 'step': 7674500}
INFO:transformers.trainer:{'loss': 3.0681846874952314, 'learning_rate': 2.696127537096399e-05, 'epoch': 1.3823234777421605, 'step': 7675000}
INFO:transformers.trainer:{'loss': 3.019316544055939, 'learning_rate': 2.695977447685135e-05, 'epoch': 1.382413531388919, 'step': 7675500}
INFO:transformers.trainer:{'loss': 3.0309633371829987, 'learning_rate': 2.6958273582738707e-05, 'epoch': 1.3825035850356775, 'step': 7676000}
INFO:transformers.trainer:{'loss': 3.0674122915267943, 'learning_rate': 2.695677268862607e-05, 'epoch': 1.3825936386824358, 'step': 7676500}
INFO:transformers.trainer:{'loss': 3.0004502241015434, 'learning_rate': 2.695527179451343e-05, 'epoch': 1.3826836923291943, 'step': 7677000}
INFO:transformers.trainer:{'loss': 3.0517910100221632, 'learning_rate': 2.6953770900400787e-05, 'epoch': 1.3827737459759528, 'step': 7677500}
INFO:transformers.trainer:{'loss': 3.0384853955209254, 'learning_rate': 2.695227000628815e-05, 'epoch': 1.382863799622711, 'step': 7678000}
INFO:transformers.trainer:{'loss': 3.0204056326150894, 'learning_rate': 2.6950769112175505e-05, 'epoch': 1.3829538532694696, 'step': 7678500}
INFO:transformers.trainer:{'loss': 3.064876222252846, 'learning_rate': 2.6949268218062868e-05, 'epoch': 1.3830439069162281, 'step': 7679000}
INFO:transformers.trainer:{'loss': 3.0456986951828005, 'learning_rate': 2.6947767323950223e-05, 'epoch': 1.3831339605629867, 'step': 7679500}
INFO:transformers.trainer:{'loss': 3.001517566204071, 'learning_rate': 2.6946266429837586e-05, 'epoch': 1.3832240142097452, 'step': 7680000}
INFO:transformers.trainer:{'loss': 3.0321306293010712, 'learning_rate': 2.694476553572494e-05, 'epoch': 1.3833140678565035, 'step': 7680500}
INFO:transformers.trainer:{'loss': 2.961778513550758, 'learning_rate': 2.6943264641612304e-05, 'epoch': 1.383404121503262, 'step': 7681000}
INFO:transformers.trainer:{'loss': 3.0579528415203097, 'learning_rate': 2.694176374749966e-05, 'epoch': 1.3834941751500205, 'step': 7681500}
INFO:transformers.trainer:{'loss': 3.0056718847751616, 'learning_rate': 2.6940262853387022e-05, 'epoch': 1.3835842287967788, 'step': 7682000}
INFO:transformers.trainer:{'loss': 2.998087954759598, 'learning_rate': 2.6938761959274378e-05, 'epoch': 1.3836742824435373, 'step': 7682500}
INFO:transformers.trainer:{'loss': 3.023282035827637, 'learning_rate': 2.693726106516174e-05, 'epoch': 1.3837643360902958, 'step': 7683000}
INFO:transformers.trainer:{'loss': 3.0880292291641234, 'learning_rate': 2.6935760171049103e-05, 'epoch': 1.383854389737054, 'step': 7683500}
INFO:transformers.trainer:{'loss': 2.9899538230895994, 'learning_rate': 2.6934259276936458e-05, 'epoch': 1.3839444433838126, 'step': 7684000}
INFO:transformers.trainer:{'loss': 2.9891861498355867, 'learning_rate': 2.693275838282382e-05, 'epoch': 1.3840344970305711, 'step': 7684500}
INFO:transformers.trainer:{'loss': 3.046415974378586, 'learning_rate': 2.6931257488711176e-05, 'epoch': 1.3841245506773294, 'step': 7685000}
INFO:transformers.trainer:{'loss': 2.9493374066352844, 'learning_rate': 2.692975659459854e-05, 'epoch': 1.384214604324088, 'step': 7685500}
INFO:transformers.trainer:{'loss': 2.9722932562828066, 'learning_rate': 2.6928255700485895e-05, 'epoch': 1.3843046579708465, 'step': 7686000}
INFO:transformers.trainer:{'loss': 3.111617225408554, 'learning_rate': 2.6926754806373257e-05, 'epoch': 1.3843947116176047, 'step': 7686500}
INFO:transformers.trainer:{'loss': 3.015747056007385, 'learning_rate': 2.6925253912260613e-05, 'epoch': 1.3844847652643633, 'step': 7687000}
INFO:transformers.trainer:{'loss': 3.0477515592575073, 'learning_rate': 2.6923753018147975e-05, 'epoch': 1.3845748189111218, 'step': 7687500}
INFO:transformers.trainer:{'loss': 3.0695427749156954, 'learning_rate': 2.692225212403533e-05, 'epoch': 1.38466487255788, 'step': 7688000}
INFO:transformers.trainer:{'loss': 3.019863793492317, 'learning_rate': 2.6920751229922693e-05, 'epoch': 1.3847549262046386, 'step': 7688500}
INFO:transformers.trainer:{'loss': 3.0474539041519164, 'learning_rate': 2.691925033581005e-05, 'epoch': 1.384844979851397, 'step': 7689000}
INFO:transformers.trainer:{'loss': 3.031979563355446, 'learning_rate': 2.691774944169741e-05, 'epoch': 1.3849350334981554, 'step': 7689500}
INFO:transformers.trainer:{'loss': 3.0100588872432708, 'learning_rate': 2.6916248547584767e-05, 'epoch': 1.385025087144914, 'step': 7690000}
INFO:transformers.trainer:{'loss': 3.004058129668236, 'learning_rate': 2.691474765347213e-05, 'epoch': 1.3851151407916724, 'step': 7690500}
INFO:transformers.trainer:{'loss': 3.0237583384513855, 'learning_rate': 2.691324675935949e-05, 'epoch': 1.385205194438431, 'step': 7691000}
INFO:transformers.trainer:{'loss': 3.006353592157364, 'learning_rate': 2.6911745865246844e-05, 'epoch': 1.3852952480851894, 'step': 7691500}
INFO:transformers.trainer:{'loss': 2.9546953941583634, 'learning_rate': 2.6910244971134206e-05, 'epoch': 1.3853853017319477, 'step': 7692000}
INFO:transformers.trainer:{'loss': 3.040370445370674, 'learning_rate': 2.6908744077021562e-05, 'epoch': 1.3854753553787063, 'step': 7692500}
INFO:transformers.trainer:{'loss': 2.97825536441803, 'learning_rate': 2.6907243182908925e-05, 'epoch': 1.3855654090254648, 'step': 7693000}
INFO:transformers.trainer:{'loss': 3.038337300300598, 'learning_rate': 2.690574228879628e-05, 'epoch': 1.385655462672223, 'step': 7693500}
INFO:transformers.trainer:{'loss': 3.032791380405426, 'learning_rate': 2.6904241394683643e-05, 'epoch': 1.3857455163189816, 'step': 7694000}
INFO:transformers.trainer:{'loss': 3.0284922529458997, 'learning_rate': 2.6902740500571e-05, 'epoch': 1.38583556996574, 'step': 7694500}
INFO:transformers.trainer:{'loss': 3.036814602613449, 'learning_rate': 2.690123960645836e-05, 'epoch': 1.3859256236124984, 'step': 7695000}
INFO:transformers.trainer:{'loss': 3.0473748846054076, 'learning_rate': 2.6899738712345716e-05, 'epoch': 1.386015677259257, 'step': 7695500}
INFO:transformers.trainer:{'loss': 3.0166837091445924, 'learning_rate': 2.689823781823308e-05, 'epoch': 1.3861057309060154, 'step': 7696000}
INFO:transformers.trainer:{'loss': 3.079232635259628, 'learning_rate': 2.6896736924120435e-05, 'epoch': 1.3861957845527737, 'step': 7696500}
INFO:transformers.trainer:{'loss': 2.9727655246257783, 'learning_rate': 2.6895236030007797e-05, 'epoch': 1.3862858381995322, 'step': 7697000}
INFO:transformers.trainer:{'loss': 2.9726940138339994, 'learning_rate': 2.689373513589516e-05, 'epoch': 1.3863758918462907, 'step': 7697500}
INFO:transformers.trainer:{'loss': 3.0374433188438417, 'learning_rate': 2.6892234241782515e-05, 'epoch': 1.386465945493049, 'step': 7698000}
INFO:transformers.trainer:{'loss': 3.024999722838402, 'learning_rate': 2.6890733347669878e-05, 'epoch': 1.3865559991398075, 'step': 7698500}
INFO:transformers.trainer:{'loss': 3.0143102093935012, 'learning_rate': 2.6889232453557233e-05, 'epoch': 1.386646052786566, 'step': 7699000}
INFO:transformers.trainer:{'loss': 3.050233276605606, 'learning_rate': 2.6887731559444596e-05, 'epoch': 1.3867361064333243, 'step': 7699500}
INFO:transformers.trainer:{'loss': 3.025691157579422, 'learning_rate': 2.688623066533195e-05, 'epoch': 1.3868261600800829, 'step': 7700000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7700000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7700000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7700000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7600000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.020017873764038, 'learning_rate': 2.6884729771219314e-05, 'epoch': 1.3869162137268414, 'step': 7700500}
INFO:transformers.trainer:{'loss': 3.0819441039562223, 'learning_rate': 2.688322887710667e-05, 'epoch': 1.3870062673735997, 'step': 7701000}
INFO:transformers.trainer:{'loss': 3.0184943578243257, 'learning_rate': 2.6881727982994032e-05, 'epoch': 1.3870963210203582, 'step': 7701500}
INFO:transformers.trainer:{'loss': 2.986912912845612, 'learning_rate': 2.6880227088881387e-05, 'epoch': 1.3871863746671167, 'step': 7702000}
INFO:transformers.trainer:{'loss': 2.967112657546997, 'learning_rate': 2.687872619476875e-05, 'epoch': 1.3872764283138752, 'step': 7702500}
INFO:transformers.trainer:{'loss': 3.0161184811592103, 'learning_rate': 2.6877225300656106e-05, 'epoch': 1.3873664819606337, 'step': 7703000}
INFO:transformers.trainer:{'loss': 3.075975336909294, 'learning_rate': 2.6875724406543468e-05, 'epoch': 1.387456535607392, 'step': 7703500}
INFO:transformers.trainer:{'loss': 3.0407006177902223, 'learning_rate': 2.6874223512430824e-05, 'epoch': 1.3875465892541505, 'step': 7704000}
INFO:transformers.trainer:{'loss': 3.0089996099472045, 'learning_rate': 2.6872722618318186e-05, 'epoch': 1.387636642900909, 'step': 7704500}
INFO:transformers.trainer:{'loss': 3.041162137508392, 'learning_rate': 2.687122172420555e-05, 'epoch': 1.3877266965476673, 'step': 7705000}
INFO:transformers.trainer:{'loss': 3.0476808605194092, 'learning_rate': 2.6869720830092904e-05, 'epoch': 1.3878167501944259, 'step': 7705500}
INFO:transformers.trainer:{'loss': 3.05325750207901, 'learning_rate': 2.6868219935980267e-05, 'epoch': 1.3879068038411844, 'step': 7706000}
INFO:transformers.trainer:{'loss': 3.0002542778253556, 'learning_rate': 2.6866719041867622e-05, 'epoch': 1.3879968574879427, 'step': 7706500}
INFO:transformers.trainer:{'loss': 2.976656177043915, 'learning_rate': 2.6865218147754985e-05, 'epoch': 1.3880869111347012, 'step': 7707000}
INFO:transformers.trainer:{'loss': 3.0015294673442843, 'learning_rate': 2.686371725364234e-05, 'epoch': 1.3881769647814597, 'step': 7707500}
INFO:transformers.trainer:{'loss': 2.9830221408605575, 'learning_rate': 2.6862216359529703e-05, 'epoch': 1.388267018428218, 'step': 7708000}
INFO:transformers.trainer:{'loss': 3.008581339418888, 'learning_rate': 2.686071546541706e-05, 'epoch': 1.3883570720749765, 'step': 7708500}
INFO:transformers.trainer:{'loss': 2.9717414450645445, 'learning_rate': 2.685921457130442e-05, 'epoch': 1.388447125721735, 'step': 7709000}
INFO:transformers.trainer:{'loss': 2.973525102853775, 'learning_rate': 2.6857713677191777e-05, 'epoch': 1.3885371793684933, 'step': 7709500}
INFO:transformers.trainer:{'loss': 3.0155716125965117, 'learning_rate': 2.685621278307914e-05, 'epoch': 1.3886272330152518, 'step': 7710000}
INFO:transformers.trainer:{'loss': 3.0387607876062392, 'learning_rate': 2.6854711888966495e-05, 'epoch': 1.3887172866620103, 'step': 7710500}
INFO:transformers.trainer:{'loss': 2.986101974964142, 'learning_rate': 2.6853210994853857e-05, 'epoch': 1.3888073403087686, 'step': 7711000}
INFO:transformers.trainer:{'loss': 3.0299839338064194, 'learning_rate': 2.6851710100741216e-05, 'epoch': 1.3888973939555271, 'step': 7711500}
INFO:transformers.trainer:{'loss': 3.024025513589382, 'learning_rate': 2.6850209206628575e-05, 'epoch': 1.3889874476022857, 'step': 7712000}
INFO:transformers.trainer:{'loss': 3.0535802104473113, 'learning_rate': 2.6848708312515934e-05, 'epoch': 1.389077501249044, 'step': 7712500}
INFO:transformers.trainer:{'loss': 2.999520282149315, 'learning_rate': 2.6847207418403293e-05, 'epoch': 1.3891675548958025, 'step': 7713000}
INFO:transformers.trainer:{'loss': 3.037399512767792, 'learning_rate': 2.6845706524290652e-05, 'epoch': 1.389257608542561, 'step': 7713500}
INFO:transformers.trainer:{'loss': 3.047515184521675, 'learning_rate': 2.684420563017801e-05, 'epoch': 1.3893476621893195, 'step': 7714000}
INFO:transformers.trainer:{'loss': 2.99435395526886, 'learning_rate': 2.684270473606537e-05, 'epoch': 1.389437715836078, 'step': 7714500}
INFO:transformers.trainer:{'loss': 3.0711633182764055, 'learning_rate': 2.6841203841952726e-05, 'epoch': 1.3895277694828363, 'step': 7715000}
INFO:transformers.trainer:{'loss': 3.0189713163375855, 'learning_rate': 2.683970294784009e-05, 'epoch': 1.3896178231295948, 'step': 7715500}
INFO:transformers.trainer:{'loss': 3.0380501396656037, 'learning_rate': 2.6838202053727444e-05, 'epoch': 1.3897078767763533, 'step': 7716000}
INFO:transformers.trainer:{'loss': 2.9761915884017944, 'learning_rate': 2.6836701159614807e-05, 'epoch': 1.3897979304231116, 'step': 7716500}
INFO:transformers.trainer:{'loss': 2.9966206643581392, 'learning_rate': 2.6835200265502162e-05, 'epoch': 1.3898879840698701, 'step': 7717000}
INFO:transformers.trainer:{'loss': 2.9975308961868286, 'learning_rate': 2.6833699371389525e-05, 'epoch': 1.3899780377166286, 'step': 7717500}
INFO:transformers.trainer:{'loss': 2.9745825009346007, 'learning_rate': 2.683219847727688e-05, 'epoch': 1.390068091363387, 'step': 7718000}
INFO:transformers.trainer:{'loss': 3.0305440118312834, 'learning_rate': 2.6830697583164243e-05, 'epoch': 1.3901581450101455, 'step': 7718500}
INFO:transformers.trainer:{'loss': 3.0730534735918047, 'learning_rate': 2.6829196689051605e-05, 'epoch': 1.390248198656904, 'step': 7719000}
INFO:transformers.trainer:{'loss': 3.0159778909683226, 'learning_rate': 2.682769579493896e-05, 'epoch': 1.3903382523036623, 'step': 7719500}
INFO:transformers.trainer:{'loss': 3.0199322921037672, 'learning_rate': 2.6826194900826323e-05, 'epoch': 1.3904283059504208, 'step': 7720000}
INFO:transformers.trainer:{'loss': 3.026309137225151, 'learning_rate': 2.682469400671368e-05, 'epoch': 1.3905183595971793, 'step': 7720500}
INFO:transformers.trainer:{'loss': 3.02771272623539, 'learning_rate': 2.682319311260104e-05, 'epoch': 1.3906084132439376, 'step': 7721000}
INFO:transformers.trainer:{'loss': 3.028131751537323, 'learning_rate': 2.6821692218488397e-05, 'epoch': 1.390698466890696, 'step': 7721500}
INFO:transformers.trainer:{'loss': 3.0206159446239473, 'learning_rate': 2.682019132437576e-05, 'epoch': 1.3907885205374546, 'step': 7722000}
INFO:transformers.trainer:{'loss': 3.0199677591323852, 'learning_rate': 2.6818690430263115e-05, 'epoch': 1.390878574184213, 'step': 7722500}
INFO:transformers.trainer:{'loss': 3.0627574620246887, 'learning_rate': 2.6817189536150478e-05, 'epoch': 1.3909686278309714, 'step': 7723000}
INFO:transformers.trainer:{'loss': 3.0549303884506225, 'learning_rate': 2.6815688642037833e-05, 'epoch': 1.39105868147773, 'step': 7723500}
INFO:transformers.trainer:{'loss': 3.0246785900592803, 'learning_rate': 2.6814187747925196e-05, 'epoch': 1.3911487351244882, 'step': 7724000}
INFO:transformers.trainer:{'loss': 2.9835084947347643, 'learning_rate': 2.681268685381255e-05, 'epoch': 1.3912387887712467, 'step': 7724500}
INFO:transformers.trainer:{'loss': 3.0365114891529084, 'learning_rate': 2.6811185959699914e-05, 'epoch': 1.3913288424180053, 'step': 7725000}
INFO:transformers.trainer:{'loss': 2.9844440826177596, 'learning_rate': 2.6809685065587276e-05, 'epoch': 1.3914188960647638, 'step': 7725500}
INFO:transformers.trainer:{'loss': 2.9915124135017397, 'learning_rate': 2.6808184171474632e-05, 'epoch': 1.3915089497115223, 'step': 7726000}
INFO:transformers.trainer:{'loss': 2.9864964408874513, 'learning_rate': 2.6806683277361994e-05, 'epoch': 1.3915990033582806, 'step': 7726500}
INFO:transformers.trainer:{'loss': 3.099774353981018, 'learning_rate': 2.680518238324935e-05, 'epoch': 1.391689057005039, 'step': 7727000}
INFO:transformers.trainer:{'loss': 2.9966022433042525, 'learning_rate': 2.6803681489136713e-05, 'epoch': 1.3917791106517976, 'step': 7727500}
INFO:transformers.trainer:{'loss': 2.9437691670656205, 'learning_rate': 2.6802180595024068e-05, 'epoch': 1.391869164298556, 'step': 7728000}
INFO:transformers.trainer:{'loss': 3.003802445292473, 'learning_rate': 2.680067970091143e-05, 'epoch': 1.3919592179453144, 'step': 7728500}
INFO:transformers.trainer:{'loss': 3.022313341379166, 'learning_rate': 2.6799178806798786e-05, 'epoch': 1.392049271592073, 'step': 7729000}
INFO:transformers.trainer:{'loss': 2.9561166269779204, 'learning_rate': 2.679767791268615e-05, 'epoch': 1.3921393252388312, 'step': 7729500}
INFO:transformers.trainer:{'loss': 3.0747388303279877, 'learning_rate': 2.6796177018573504e-05, 'epoch': 1.3922293788855897, 'step': 7730000}
INFO:transformers.trainer:{'loss': 3.0486608877182007, 'learning_rate': 2.6794676124460867e-05, 'epoch': 1.3923194325323482, 'step': 7730500}
INFO:transformers.trainer:{'loss': 3.005923418045044, 'learning_rate': 2.6793175230348223e-05, 'epoch': 1.3924094861791065, 'step': 7731000}
INFO:transformers.trainer:{'loss': 2.970036711573601, 'learning_rate': 2.6791674336235585e-05, 'epoch': 1.392499539825865, 'step': 7731500}
INFO:transformers.trainer:{'loss': 3.0333592984676363, 'learning_rate': 2.679017344212294e-05, 'epoch': 1.3925895934726236, 'step': 7732000}
INFO:transformers.trainer:{'loss': 3.037287971138954, 'learning_rate': 2.6788672548010303e-05, 'epoch': 1.3926796471193819, 'step': 7732500}
INFO:transformers.trainer:{'loss': 2.984681747198105, 'learning_rate': 2.6787171653897662e-05, 'epoch': 1.3927697007661404, 'step': 7733000}
INFO:transformers.trainer:{'loss': 2.981687868952751, 'learning_rate': 2.678567075978502e-05, 'epoch': 1.3928597544128989, 'step': 7733500}
INFO:transformers.trainer:{'loss': 3.0274969154596327, 'learning_rate': 2.678416986567238e-05, 'epoch': 1.3929498080596572, 'step': 7734000}
INFO:transformers.trainer:{'loss': 3.0584209530353546, 'learning_rate': 2.678266897155974e-05, 'epoch': 1.3930398617064157, 'step': 7734500}
INFO:transformers.trainer:{'loss': 3.070652647137642, 'learning_rate': 2.67811680774471e-05, 'epoch': 1.3931299153531742, 'step': 7735000}
INFO:transformers.trainer:{'loss': 3.0697677519321442, 'learning_rate': 2.6779667183334457e-05, 'epoch': 1.3932199689999327, 'step': 7735500}
INFO:transformers.trainer:{'loss': 2.9959715130329134, 'learning_rate': 2.6778166289221816e-05, 'epoch': 1.393310022646691, 'step': 7736000}
INFO:transformers.trainer:{'loss': 3.080785601735115, 'learning_rate': 2.6776665395109175e-05, 'epoch': 1.3934000762934495, 'step': 7736500}
INFO:transformers.trainer:{'loss': 3.0496606382131577, 'learning_rate': 2.6775164500996535e-05, 'epoch': 1.393490129940208, 'step': 7737000}
INFO:transformers.trainer:{'loss': 2.96655039870739, 'learning_rate': 2.6773663606883894e-05, 'epoch': 1.3935801835869666, 'step': 7737500}
INFO:transformers.trainer:{'loss': 3.0344655981063844, 'learning_rate': 2.6772162712771253e-05, 'epoch': 1.3936702372337249, 'step': 7738000}
INFO:transformers.trainer:{'loss': 3.033018560886383, 'learning_rate': 2.6770661818658612e-05, 'epoch': 1.3937602908804834, 'step': 7738500}
INFO:transformers.trainer:{'loss': 3.0639581749439238, 'learning_rate': 2.676916092454597e-05, 'epoch': 1.3938503445272419, 'step': 7739000}
INFO:transformers.trainer:{'loss': 3.0325550236701964, 'learning_rate': 2.6767660030433333e-05, 'epoch': 1.3939403981740002, 'step': 7739500}
INFO:transformers.trainer:{'loss': 3.0366649827957155, 'learning_rate': 2.676615913632069e-05, 'epoch': 1.3940304518207587, 'step': 7740000}
INFO:transformers.trainer:{'loss': 2.9767131518125534, 'learning_rate': 2.676465824220805e-05, 'epoch': 1.3941205054675172, 'step': 7740500}
INFO:transformers.trainer:{'loss': 3.0717453632354736, 'learning_rate': 2.6763157348095407e-05, 'epoch': 1.3942105591142755, 'step': 7741000}
INFO:transformers.trainer:{'loss': 3.0477829654216766, 'learning_rate': 2.676165645398277e-05, 'epoch': 1.394300612761034, 'step': 7741500}
INFO:transformers.trainer:{'loss': 3.024264377951622, 'learning_rate': 2.6760155559870125e-05, 'epoch': 1.3943906664077925, 'step': 7742000}
INFO:transformers.trainer:{'loss': 2.985173779129982, 'learning_rate': 2.6758654665757487e-05, 'epoch': 1.3944807200545508, 'step': 7742500}
INFO:transformers.trainer:{'loss': 3.0920858609676363, 'learning_rate': 2.6757153771644843e-05, 'epoch': 1.3945707737013093, 'step': 7743000}
INFO:transformers.trainer:{'loss': 3.004107167124748, 'learning_rate': 2.6755652877532206e-05, 'epoch': 1.3946608273480678, 'step': 7743500}
INFO:transformers.trainer:{'loss': 3.0195759665966033, 'learning_rate': 2.675415198341956e-05, 'epoch': 1.3947508809948261, 'step': 7744000}
INFO:transformers.trainer:{'loss': 3.035442188858986, 'learning_rate': 2.6752651089306924e-05, 'epoch': 1.3948409346415847, 'step': 7744500}
INFO:transformers.trainer:{'loss': 3.0188158400058747, 'learning_rate': 2.675115019519428e-05, 'epoch': 1.3949309882883432, 'step': 7745000}
INFO:transformers.trainer:{'loss': 2.9474932676553727, 'learning_rate': 2.6749649301081642e-05, 'epoch': 1.3950210419351015, 'step': 7745500}
INFO:transformers.trainer:{'loss': 3.038819119215012, 'learning_rate': 2.6748148406969004e-05, 'epoch': 1.39511109558186, 'step': 7746000}
INFO:transformers.trainer:{'loss': 2.9960594010353088, 'learning_rate': 2.674664751285636e-05, 'epoch': 1.3952011492286185, 'step': 7746500}
INFO:transformers.trainer:{'loss': 2.9803036369085314, 'learning_rate': 2.6745146618743722e-05, 'epoch': 1.395291202875377, 'step': 7747000}
INFO:transformers.trainer:{'loss': 3.0442944054603576, 'learning_rate': 2.6743645724631078e-05, 'epoch': 1.3953812565221353, 'step': 7747500}
INFO:transformers.trainer:{'loss': 3.013854371070862, 'learning_rate': 2.674214483051844e-05, 'epoch': 1.3954713101688938, 'step': 7748000}
INFO:transformers.trainer:{'loss': 2.9739846992492676, 'learning_rate': 2.6740643936405796e-05, 'epoch': 1.3955613638156523, 'step': 7748500}
INFO:transformers.trainer:{'loss': 3.041762981414795, 'learning_rate': 2.673914304229316e-05, 'epoch': 1.3956514174624108, 'step': 7749000}
INFO:transformers.trainer:{'loss': 2.9383171339035035, 'learning_rate': 2.6737642148180514e-05, 'epoch': 1.3957414711091691, 'step': 7749500}
INFO:transformers.trainer:{'loss': 3.0040736602544786, 'learning_rate': 2.6736141254067877e-05, 'epoch': 1.3958315247559276, 'step': 7750000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7750000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7750000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7750000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7650000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0412956417798997, 'learning_rate': 2.6734640359955232e-05, 'epoch': 1.3959215784026862, 'step': 7750500}
INFO:transformers.trainer:{'loss': 2.9934019207954408, 'learning_rate': 2.6733139465842595e-05, 'epoch': 1.3960116320494445, 'step': 7751000}
INFO:transformers.trainer:{'loss': 2.9776498715877535, 'learning_rate': 2.673163857172995e-05, 'epoch': 1.396101685696203, 'step': 7751500}
INFO:transformers.trainer:{'loss': 3.009800403833389, 'learning_rate': 2.6730137677617313e-05, 'epoch': 1.3961917393429615, 'step': 7752000}
INFO:transformers.trainer:{'loss': 3.0403253313302994, 'learning_rate': 2.672863678350467e-05, 'epoch': 1.3962817929897198, 'step': 7752500}
INFO:transformers.trainer:{'loss': 2.9668880336284635, 'learning_rate': 2.672713588939203e-05, 'epoch': 1.3963718466364783, 'step': 7753000}
INFO:transformers.trainer:{'loss': 3.024721026659012, 'learning_rate': 2.672563499527939e-05, 'epoch': 1.3964619002832368, 'step': 7753500}
INFO:transformers.trainer:{'loss': 3.0322436354160307, 'learning_rate': 2.672413410116675e-05, 'epoch': 1.396551953929995, 'step': 7754000}
INFO:transformers.trainer:{'loss': 2.993108620285988, 'learning_rate': 2.6722633207054108e-05, 'epoch': 1.3966420075767536, 'step': 7754500}
INFO:transformers.trainer:{'loss': 2.994245506763458, 'learning_rate': 2.6721132312941467e-05, 'epoch': 1.3967320612235121, 'step': 7755000}
INFO:transformers.trainer:{'loss': 3.037543277978897, 'learning_rate': 2.6719631418828826e-05, 'epoch': 1.3968221148702704, 'step': 7755500}
INFO:transformers.trainer:{'loss': 3.028022446990013, 'learning_rate': 2.6718130524716185e-05, 'epoch': 1.396912168517029, 'step': 7756000}
INFO:transformers.trainer:{'loss': 3.0419744098186494, 'learning_rate': 2.6716629630603544e-05, 'epoch': 1.3970022221637874, 'step': 7756500}
INFO:transformers.trainer:{'loss': 2.9997179024219514, 'learning_rate': 2.6715128736490903e-05, 'epoch': 1.3970922758105457, 'step': 7757000}
INFO:transformers.trainer:{'loss': 3.0339219677448273, 'learning_rate': 2.6713627842378262e-05, 'epoch': 1.3971823294573043, 'step': 7757500}
INFO:transformers.trainer:{'loss': 3.0073219730854035, 'learning_rate': 2.671212694826562e-05, 'epoch': 1.3972723831040628, 'step': 7758000}
INFO:transformers.trainer:{'loss': 3.0456931419372557, 'learning_rate': 2.671062605415298e-05, 'epoch': 1.3973624367508213, 'step': 7758500}
INFO:transformers.trainer:{'loss': 3.0339012734889983, 'learning_rate': 2.670912516004034e-05, 'epoch': 1.3974524903975796, 'step': 7759000}
INFO:transformers.trainer:{'loss': 2.989615587949753, 'learning_rate': 2.67076242659277e-05, 'epoch': 1.397542544044338, 'step': 7759500}
INFO:transformers.trainer:{'loss': 2.993908757805824, 'learning_rate': 2.670612337181506e-05, 'epoch': 1.3976325976910966, 'step': 7760000}
INFO:transformers.trainer:{'loss': 2.982809142589569, 'learning_rate': 2.6704622477702417e-05, 'epoch': 1.3977226513378551, 'step': 7760500}
INFO:transformers.trainer:{'loss': 3.034750782608986, 'learning_rate': 2.670312158358978e-05, 'epoch': 1.3978127049846134, 'step': 7761000}
INFO:transformers.trainer:{'loss': 3.0168028054237364, 'learning_rate': 2.6701620689477135e-05, 'epoch': 1.397902758631372, 'step': 7761500}
INFO:transformers.trainer:{'loss': 2.989885069489479, 'learning_rate': 2.6700119795364497e-05, 'epoch': 1.3979928122781304, 'step': 7762000}
INFO:transformers.trainer:{'loss': 2.9773733674287794, 'learning_rate': 2.6698618901251853e-05, 'epoch': 1.3980828659248887, 'step': 7762500}
INFO:transformers.trainer:{'loss': 3.010698756456375, 'learning_rate': 2.6697118007139215e-05, 'epoch': 1.3981729195716472, 'step': 7763000}
INFO:transformers.trainer:{'loss': 3.0219121372699735, 'learning_rate': 2.669561711302657e-05, 'epoch': 1.3982629732184058, 'step': 7763500}
INFO:transformers.trainer:{'loss': 3.018941056966782, 'learning_rate': 2.6694116218913933e-05, 'epoch': 1.398353026865164, 'step': 7764000}
INFO:transformers.trainer:{'loss': 3.041163237452507, 'learning_rate': 2.669261532480129e-05, 'epoch': 1.3984430805119226, 'step': 7764500}
INFO:transformers.trainer:{'loss': 3.0412166061401367, 'learning_rate': 2.669111443068865e-05, 'epoch': 1.398533134158681, 'step': 7765000}
INFO:transformers.trainer:{'loss': 3.0549874238967893, 'learning_rate': 2.6689613536576007e-05, 'epoch': 1.3986231878054394, 'step': 7765500}
INFO:transformers.trainer:{'loss': 3.046322684288025, 'learning_rate': 2.668811264246337e-05, 'epoch': 1.3987132414521979, 'step': 7766000}
INFO:transformers.trainer:{'loss': 2.9685752713680267, 'learning_rate': 2.6686611748350725e-05, 'epoch': 1.3988032950989564, 'step': 7766500}
INFO:transformers.trainer:{'loss': 2.994241673231125, 'learning_rate': 2.6685110854238088e-05, 'epoch': 1.3988933487457147, 'step': 7767000}
INFO:transformers.trainer:{'loss': 3.063482555627823, 'learning_rate': 2.668360996012545e-05, 'epoch': 1.3989834023924732, 'step': 7767500}
INFO:transformers.trainer:{'loss': 2.9724957916736603, 'learning_rate': 2.6682109066012806e-05, 'epoch': 1.3990734560392317, 'step': 7768000}
INFO:transformers.trainer:{'loss': 3.0177409782409668, 'learning_rate': 2.6680608171900168e-05, 'epoch': 1.39916350968599, 'step': 7768500}
INFO:transformers.trainer:{'loss': 2.9898947167396543, 'learning_rate': 2.6679107277787524e-05, 'epoch': 1.3992535633327485, 'step': 7769000}
INFO:transformers.trainer:{'loss': 3.0215422027111054, 'learning_rate': 2.6677606383674886e-05, 'epoch': 1.399343616979507, 'step': 7769500}
INFO:transformers.trainer:{'loss': 3.056911736726761, 'learning_rate': 2.6676105489562242e-05, 'epoch': 1.3994336706262656, 'step': 7770000}
INFO:transformers.trainer:{'loss': 3.0177161355018614, 'learning_rate': 2.6674604595449604e-05, 'epoch': 1.3995237242730239, 'step': 7770500}
INFO:transformers.trainer:{'loss': 3.0528704863786698, 'learning_rate': 2.667310370133696e-05, 'epoch': 1.3996137779197824, 'step': 7771000}
INFO:transformers.trainer:{'loss': 3.0334312613010406, 'learning_rate': 2.6671602807224323e-05, 'epoch': 1.3997038315665409, 'step': 7771500}
INFO:transformers.trainer:{'loss': 3.0578946771621704, 'learning_rate': 2.6670101913111678e-05, 'epoch': 1.3997938852132994, 'step': 7772000}
INFO:transformers.trainer:{'loss': 3.0138500983715057, 'learning_rate': 2.666860101899904e-05, 'epoch': 1.3998839388600577, 'step': 7772500}
INFO:transformers.trainer:{'loss': 2.9912849162817, 'learning_rate': 2.6667100124886396e-05, 'epoch': 1.3999739925068162, 'step': 7773000}
INFO:transformers.trainer:{'loss': 2.9714488210678103, 'learning_rate': 2.666559923077376e-05, 'epoch': 1.4000640461535747, 'step': 7773500}
INFO:transformers.trainer:{'loss': 3.0084489142894744, 'learning_rate': 2.666409833666112e-05, 'epoch': 1.400154099800333, 'step': 7774000}
INFO:transformers.trainer:{'loss': 2.988965511918068, 'learning_rate': 2.6662597442548477e-05, 'epoch': 1.4002441534470915, 'step': 7774500}
INFO:transformers.trainer:{'loss': 3.0207534214258196, 'learning_rate': 2.666109654843584e-05, 'epoch': 1.40033420709385, 'step': 7775000}
INFO:transformers.trainer:{'loss': 3.021318609714508, 'learning_rate': 2.6659595654323195e-05, 'epoch': 1.4004242607406083, 'step': 7775500}
INFO:transformers.trainer:{'loss': 3.0034455008506775, 'learning_rate': 2.6658094760210557e-05, 'epoch': 1.4005143143873668, 'step': 7776000}
INFO:transformers.trainer:{'loss': 3.0418740744590758, 'learning_rate': 2.6656593866097913e-05, 'epoch': 1.4006043680341254, 'step': 7776500}
INFO:transformers.trainer:{'loss': 2.991292844772339, 'learning_rate': 2.6655092971985272e-05, 'epoch': 1.4006944216808837, 'step': 7777000}
INFO:transformers.trainer:{'loss': 3.0067406643629075, 'learning_rate': 2.665359207787263e-05, 'epoch': 1.4007844753276422, 'step': 7777500}
INFO:transformers.trainer:{'loss': 3.0343010425567627, 'learning_rate': 2.665209118375999e-05, 'epoch': 1.4008745289744007, 'step': 7778000}
INFO:transformers.trainer:{'loss': 3.0755028672218323, 'learning_rate': 2.665059028964735e-05, 'epoch': 1.400964582621159, 'step': 7778500}
INFO:transformers.trainer:{'loss': 2.9845413303375246, 'learning_rate': 2.6649089395534708e-05, 'epoch': 1.4010546362679175, 'step': 7779000}
INFO:transformers.trainer:{'loss': 3.020629629611969, 'learning_rate': 2.6647588501422067e-05, 'epoch': 1.401144689914676, 'step': 7779500}
INFO:transformers.trainer:{'loss': 3.013795652151108, 'learning_rate': 2.6646087607309426e-05, 'epoch': 1.4012347435614343, 'step': 7780000}
INFO:transformers.trainer:{'loss': 3.0595619220733643, 'learning_rate': 2.6644586713196785e-05, 'epoch': 1.4013247972081928, 'step': 7780500}
INFO:transformers.trainer:{'loss': 3.025423939704895, 'learning_rate': 2.6643085819084145e-05, 'epoch': 1.4014148508549513, 'step': 7781000}
INFO:transformers.trainer:{'loss': 3.028682246208191, 'learning_rate': 2.6641584924971507e-05, 'epoch': 1.4015049045017098, 'step': 7781500}
INFO:transformers.trainer:{'loss': 2.9563083209991454, 'learning_rate': 2.6640084030858863e-05, 'epoch': 1.4015949581484681, 'step': 7782000}
INFO:transformers.trainer:{'loss': 3.014624411344528, 'learning_rate': 2.6638583136746225e-05, 'epoch': 1.4016850117952266, 'step': 7782500}
INFO:transformers.trainer:{'loss': 3.00160050535202, 'learning_rate': 2.663708224263358e-05, 'epoch': 1.4017750654419852, 'step': 7783000}
INFO:transformers.trainer:{'loss': 3.0771973807811737, 'learning_rate': 2.6635581348520943e-05, 'epoch': 1.4018651190887437, 'step': 7783500}
INFO:transformers.trainer:{'loss': 3.0410618777275085, 'learning_rate': 2.66340804544083e-05, 'epoch': 1.401955172735502, 'step': 7784000}
INFO:transformers.trainer:{'loss': 2.9643428909778593, 'learning_rate': 2.663257956029566e-05, 'epoch': 1.4020452263822605, 'step': 7784500}
INFO:transformers.trainer:{'loss': 2.985713977456093, 'learning_rate': 2.6631078666183017e-05, 'epoch': 1.402135280029019, 'step': 7785000}
INFO:transformers.trainer:{'loss': 3.050506607532501, 'learning_rate': 2.662957777207038e-05, 'epoch': 1.4022253336757773, 'step': 7785500}
INFO:transformers.trainer:{'loss': 3.0436611223220824, 'learning_rate': 2.6628076877957735e-05, 'epoch': 1.4023153873225358, 'step': 7786000}
INFO:transformers.trainer:{'loss': 3.0066617953777315, 'learning_rate': 2.6626575983845097e-05, 'epoch': 1.4024054409692943, 'step': 7786500}
INFO:transformers.trainer:{'loss': 3.0048738840818405, 'learning_rate': 2.6625075089732453e-05, 'epoch': 1.4024954946160526, 'step': 7787000}
INFO:transformers.trainer:{'loss': 3.0146901400089265, 'learning_rate': 2.6623574195619816e-05, 'epoch': 1.4025855482628111, 'step': 7787500}
INFO:transformers.trainer:{'loss': 3.071707088470459, 'learning_rate': 2.6622073301507178e-05, 'epoch': 1.4026756019095696, 'step': 7788000}
INFO:transformers.trainer:{'loss': 3.000235985994339, 'learning_rate': 2.6620572407394534e-05, 'epoch': 1.402765655556328, 'step': 7788500}
INFO:transformers.trainer:{'loss': 3.000890103340149, 'learning_rate': 2.6619071513281896e-05, 'epoch': 1.4028557092030864, 'step': 7789000}
INFO:transformers.trainer:{'loss': 3.0571717188358307, 'learning_rate': 2.6617570619169252e-05, 'epoch': 1.402945762849845, 'step': 7789500}
INFO:transformers.trainer:{'loss': 3.006818845152855, 'learning_rate': 2.6616069725056614e-05, 'epoch': 1.4030358164966032, 'step': 7790000}
INFO:transformers.trainer:{'loss': 3.0383271379470824, 'learning_rate': 2.661456883094397e-05, 'epoch': 1.4031258701433618, 'step': 7790500}
INFO:transformers.trainer:{'loss': 3.048858471274376, 'learning_rate': 2.6613067936831332e-05, 'epoch': 1.4032159237901203, 'step': 7791000}
INFO:transformers.trainer:{'loss': 3.0497204303741454, 'learning_rate': 2.6611567042718688e-05, 'epoch': 1.4033059774368786, 'step': 7791500}
INFO:transformers.trainer:{'loss': 3.014530589938164, 'learning_rate': 2.661006614860605e-05, 'epoch': 1.403396031083637, 'step': 7792000}
INFO:transformers.trainer:{'loss': 2.987825155377388, 'learning_rate': 2.6608565254493406e-05, 'epoch': 1.4034860847303956, 'step': 7792500}
INFO:transformers.trainer:{'loss': 3.063140619277954, 'learning_rate': 2.660706436038077e-05, 'epoch': 1.4035761383771541, 'step': 7793000}
INFO:transformers.trainer:{'loss': 3.035492655992508, 'learning_rate': 2.6605563466268124e-05, 'epoch': 1.4036661920239124, 'step': 7793500}
INFO:transformers.trainer:{'loss': 2.993549082636833, 'learning_rate': 2.6604062572155487e-05, 'epoch': 1.403756245670671, 'step': 7794000}
INFO:transformers.trainer:{'loss': 3.0071442021131514, 'learning_rate': 2.660256167804285e-05, 'epoch': 1.4038462993174294, 'step': 7794500}
INFO:transformers.trainer:{'loss': 3.0298358964920045, 'learning_rate': 2.6601060783930205e-05, 'epoch': 1.403936352964188, 'step': 7795000}
INFO:transformers.trainer:{'loss': 2.9789940168857574, 'learning_rate': 2.6599559889817567e-05, 'epoch': 1.4040264066109462, 'step': 7795500}
INFO:transformers.trainer:{'loss': 3.021901933789253, 'learning_rate': 2.6598058995704923e-05, 'epoch': 1.4041164602577048, 'step': 7796000}
INFO:transformers.trainer:{'loss': 2.990070240020752, 'learning_rate': 2.6596558101592285e-05, 'epoch': 1.4042065139044633, 'step': 7796500}
INFO:transformers.trainer:{'loss': 3.031906357884407, 'learning_rate': 2.659505720747964e-05, 'epoch': 1.4042965675512216, 'step': 7797000}
INFO:transformers.trainer:{'loss': 2.9961612157821653, 'learning_rate': 2.6593556313367003e-05, 'epoch': 1.40438662119798, 'step': 7797500}
INFO:transformers.trainer:{'loss': 2.9578850214481354, 'learning_rate': 2.659205541925436e-05, 'epoch': 1.4044766748447386, 'step': 7798000}
INFO:transformers.trainer:{'loss': 3.0155675897598266, 'learning_rate': 2.659055452514172e-05, 'epoch': 1.4045667284914969, 'step': 7798500}
INFO:transformers.trainer:{'loss': 2.998168015599251, 'learning_rate': 2.6589053631029077e-05, 'epoch': 1.4046567821382554, 'step': 7799000}
INFO:transformers.trainer:{'loss': 3.037688392162323, 'learning_rate': 2.658755273691644e-05, 'epoch': 1.404746835785014, 'step': 7799500}
INFO:transformers.trainer:{'loss': 2.9865256521701813, 'learning_rate': 2.6586051842803795e-05, 'epoch': 1.4048368894317722, 'step': 7800000}
INFO:transformers.trainer:Saving model checkpoint to ../outputs/edin_tuned/roberta-finetuning/checkpoint-7800000
INFO:transformers.configuration_utils:Configuration saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7800000/config.json
INFO:transformers.modeling_utils:Model weights saved in ../outputs/edin_tuned/roberta-finetuning/checkpoint-7800000/pytorch_model.bin
INFO:transformers.trainer:Deleting older checkpoint [../outputs/edin_tuned/roberta-finetuning/checkpoint-7700000] due to args.save_total_limit
INFO:transformers.trainer:{'loss': 3.0027914175987243, 'learning_rate': 2.6584550948691154e-05, 'epoch': 1.4049269430785307, 'step': 7800500}
INFO:transformers.trainer:{'loss': 3.0430912512540815, 'learning_rate': 2.6583050054578513e-05, 'epoch': 1.4050169967252892, 'step': 7801000}
INFO:transformers.trainer:{'loss': 3.0102229504585267, 'learning_rate': 2.6581549160465872e-05, 'epoch': 1.4051070503720475, 'step': 7801500}
INFO:transformers.trainer:{'loss': 3.09054576587677, 'learning_rate': 2.6580048266353235e-05, 'epoch': 1.405197104018806, 'step': 7802000}
INFO:transformers.trainer:{'loss': 3.062294818162918, 'learning_rate': 2.657854737224059e-05, 'epoch': 1.4052871576655646, 'step': 7802500}
INFO:transformers.trainer:{'loss': 2.998116546869278, 'learning_rate': 2.6577046478127953e-05, 'epoch': 1.4053772113123228, 'step': 7803000}
INFO:transformers.trainer:{'loss': 2.94315158700943, 'learning_rate': 2.657554558401531e-05, 'epoch': 1.4054672649590814, 'step': 7803500}
INFO:transformers.trainer:{'loss': 3.058646504640579, 'learning_rate': 2.657404468990267e-05, 'epoch': 1.4055573186058399, 'step': 7804000}
INFO:transformers.trainer:{'loss': 3.047379358291626, 'learning_rate': 2.6572543795790027e-05, 'epoch': 1.4056473722525984, 'step': 7804500}
INFO:transformers.trainer:{'loss': 3.0187424463033676, 'learning_rate': 2.657104290167739e-05, 'epoch': 1.4057374258993567, 'step': 7805000}
INFO:transformers.trainer:{'loss': 3.085801134467125, 'learning_rate': 2.6569542007564745e-05, 'epoch': 1.4058274795461152, 'step': 7805500}
INFO:transformers.trainer:{'loss': 3.0339605345726013, 'learning_rate': 2.6568041113452107e-05, 'epoch': 1.4059175331928737, 'step': 7806000}
INFO:transformers.trainer:{'loss': 3.0206663901805877, 'learning_rate': 2.6566540219339463e-05, 'epoch': 1.4060075868396322, 'step': 7806500}
INFO:transformers.trainer:{'loss': 2.9949930131435396, 'learning_rate': 2.6565039325226825e-05, 'epoch': 1.4060976404863905, 'step': 7807000}
INFO:transformers.trainer:{'loss': 3.0399442739486693, 'learning_rate': 2.656353843111418e-05, 'epoch': 1.406187694133149, 'step': 7807500}
INFO:transformers.trainer:{'loss': 3.0671209638118744, 'learning_rate': 2.6562037537001543e-05, 'epoch': 1.4062777477799075, 'step': 7808000}
INFO:transformers.trainer:{'loss': 3.0169828245639803, 'learning_rate': 2.6560536642888906e-05, 'epoch': 1.4063678014266658, 'step': 7808500}
INFO:transformers.trainer:{'loss': 2.9787269285917284, 'learning_rate': 2.655903574877626e-05, 'epoch': 1.4064578550734244, 'step': 7809000}
INFO:transformers.trainer:{'loss': 3.0289699087142945, 'learning_rate': 2.6557534854663624e-05, 'epoch': 1.4065479087201829, 'step': 7809500}
INFO:transformers.trainer:{'loss': 2.946616949558258, 'learning_rate': 2.655603396055098e-05, 'epoch': 1.4066379623669412, 'step': 7810000}
INFO:transformers.trainer:{'loss': 3.0543607647418978, 'learning_rate': 2.6554533066438342e-05, 'epoch': 1.4067280160136997, 'step': 7810500}
INFO:transformers.trainer:{'loss': 3.0027757637500763, 'learning_rate': 2.6553032172325698e-05, 'epoch': 1.4068180696604582, 'step': 7811000}
INFO:transformers.trainer:{'loss': 2.9613858671188353, 'learning_rate': 2.655153127821306e-05, 'epoch': 1.4069081233072165, 'step': 7811500}
INFO:transformers.trainer:{'loss': 2.961014407634735, 'learning_rate': 2.6550030384100416e-05, 'epoch': 1.406998176953975, 'step': 7812000}
INFO:transformers.trainer:{'loss': 3.0631419916152955, 'learning_rate': 2.6548529489987778e-05, 'epoch': 1.4070882306007335, 'step': 7812500}
INFO:transformers.trainer:{'loss': 3.066372180104256, 'learning_rate': 2.6547028595875134e-05, 'epoch': 1.4071782842474918, 'step': 7813000}
INFO:transformers.trainer:{'loss': 2.983282261133194, 'learning_rate': 2.6545527701762496e-05, 'epoch': 1.4072683378942503, 'step': 7813500}
INFO:transformers.trainer:{'loss': 3.0031714453697202, 'learning_rate': 2.6544026807649852e-05, 'epoch': 1.4073583915410088, 'step': 7814000}
INFO:transformers.trainer:{'loss': 2.9363797128200533, 'learning_rate': 2.6542525913537214e-05, 'epoch': 1.4074484451877671, 'step': 7814500}
INFO:transformers.trainer:{'loss': 3.046646613240242, 'learning_rate': 2.654102501942457e-05, 'epoch': 1.4075384988345256, 'step': 7815000}
INFO:transformers.trainer:{'loss': 2.9883920545578, 'learning_rate': 2.6539524125311933e-05, 'epoch': 1.4076285524812842, 'step': 7815500}
INFO:transformers.trainer:{'loss': 3.040408370733261, 'learning_rate': 2.6538023231199295e-05, 'epoch': 1.4077186061280427, 'step': 7816000}
INFO:transformers.trainer:{'loss': 3.072839443683624, 'learning_rate': 2.653652233708665e-05, 'epoch': 1.407808659774801, 'step': 7816500}
INFO:transformers.trainer:{'loss': 2.9885117037296296, 'learning_rate': 2.6535021442974013e-05, 'epoch': 1.4078987134215595, 'step': 7817000}
INFO:transformers.trainer:{'loss': 3.075926900625229, 'learning_rate': 2.653352054886137e-05, 'epoch': 1.407988767068318, 'step': 7817500}
INFO:transformers.trainer:{'loss': 3.019489940881729, 'learning_rate': 2.653201965474873e-05, 'epoch': 1.4080788207150765, 'step': 7818000}
INFO:transformers.trainer:{'loss': 2.966715664625168, 'learning_rate': 2.6530518760636087e-05, 'epoch': 1.4081688743618348, 'step': 7818500}
INFO:transformers.trainer:{'loss': 3.001855337381363, 'learning_rate': 2.652901786652345e-05, 'epoch': 1.4082589280085933, 'step': 7819000}
INFO:transformers.trainer:{'loss': 2.9975382871627807, 'learning_rate': 2.6527516972410805e-05, 'epoch': 1.4083489816553518, 'step': 7819500}
INFO:transformers.trainer:{'loss': 3.06015795814991, 'learning_rate': 2.6526016078298167e-05, 'epoch': 1.4084390353021101, 'step': 7820000}
INFO:transformers.trainer:{'loss': 3.0092985943555832, 'learning_rate': 2.6524515184185523e-05, 'epoch': 1.4085290889488686, 'step': 7820500}
INFO:transformers.trainer:{'loss': 3.007904882311821, 'learning_rate': 2.6523014290072885e-05, 'epoch': 1.4086191425956271, 'step': 7821000}
INFO:transformers.trainer:{'loss': 2.968746197104454, 'learning_rate': 2.652151339596024e-05, 'epoch': 1.4087091962423854, 'step': 7821500}
INFO:transformers.trainer:{'loss': 2.983938949108124, 'learning_rate': 2.6520012501847604e-05, 'epoch': 1.408799249889144, 'step': 7822000}
INFO:transformers.trainer:{'loss': 2.966927853345871, 'learning_rate': 2.6518511607734963e-05, 'epoch': 1.4088893035359025, 'step': 7822500}
INFO:transformers.trainer:{'loss': 3.0196147124767303, 'learning_rate': 2.651701071362232e-05, 'epoch': 1.4089793571826608, 'step': 7823000}
INFO:transformers.trainer:{'loss': 2.985589721083641, 'learning_rate': 2.651550981950968e-05, 'epoch': 1.4090694108294193, 'step': 7823500}
INFO:transformers.trainer:{'loss': 3.027025670170784, 'learning_rate': 2.651400892539704e-05, 'epoch': 1.4091594644761778, 'step': 7824000}
INFO:transformers.trainer:{'loss': 2.9991544013023375, 'learning_rate': 2.65125080312844e-05, 'epoch': 1.409249518122936, 'step': 7824500}
INFO:transformers.trainer:{'loss': 2.96461607837677, 'learning_rate': 2.6511007137171754e-05, 'epoch': 1.4093395717696946, 'step': 7825000}
INFO:transformers.trainer:{'loss': 2.9795878727436067, 'learning_rate': 2.6509506243059117e-05, 'epoch': 1.4094296254164531, 'step': 7825500}
